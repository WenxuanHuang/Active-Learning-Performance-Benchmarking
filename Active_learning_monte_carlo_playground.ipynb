{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ioi13nGDPDvQ",
        "outputId": "4763f7b3-6c5b-45cb-f411-fd7c6ea8b38f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Automatically created module for IPython interactive environment\n"
          ]
        }
      ],
      "source": [
        "print(__doc__)\n",
        "\n",
        "import os\n",
        "import time\n",
        "import json\n",
        "import pickle\n",
        "import math\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.mlab as mlab\n",
        "from scipy.special import expit\n",
        "from scipy import stats\n",
        "from pylab import rcParams\n",
        "import mplcursors\n",
        "\n",
        "from sklearn.utils import check_random_state\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer\n",
        "from sklearn.pipeline import Pipeline, FeatureUnion\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import scale\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "\n",
        "from sklearn import linear_model\n",
        "from sklearn import neighbors\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.linear_model import RidgeCV, LassoCV, Ridge, Lasso\n",
        "from sklearn.svm import LinearSVC, SVC\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.utils import check_random_state\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics.pairwise import euclidean_distances\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.mixture import GaussianMixture\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import pairwise_distances_argmin_min\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import average_precision_score\n",
        "\n",
        "\n",
        "# pd.options.display.max_rows = 20\n",
        "pd.options.display.float_format = \"{:.1f}\".format\n",
        "\n",
        "max_queried = 500\n",
        "trainset_size = 1302"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def data_prep():\n",
        "    data = pd.read_csv(\"https://raw.githubusercontent.com/WenxuanHuang/ML-for-COVID-19-dataset/main/all_training.csv\", sep=',')\n",
        "    # Column selection\n",
        "    df = data.iloc[:,np.r_[3:34]].copy()\n",
        "    # define row and column index\n",
        "    col = df.columns\n",
        "    row = [i for i in range(df.shape[0])]\n",
        "    # define imputer\n",
        "    imputer = IterativeImputer(estimator=linear_model.BayesianRidge(), n_nearest_features=None, imputation_order='ascending')\n",
        "    # fit on the dataset\n",
        "    imputer.fit(df)\n",
        "    # transform the dataset\n",
        "    df_imputed = imputer.transform(df)\n",
        "    # convert back to pandas dataframe and rename back to df_normalized\n",
        "    df = pd.DataFrame(data=df_imputed, index=row, columns=col)\n",
        "    X = df\n",
        "    y = data.target    \n",
        "    # Recursive feature elimination\n",
        "    rdmreg = RandomForestClassifier(n_estimators=100)\n",
        "    # Define the method\n",
        "    rfe = RFE(estimator=rdmreg, n_features_to_select=10)\n",
        "    # Fit the model\n",
        "    rfe = rfe.fit(X, y.values.ravel())\n",
        "    print(rfe.support_)\n",
        "    # Drop columns that failed RFE test\n",
        "    col = df.columns[rfe.support_]\n",
        "    X = X[col]\n",
        "    X = X.to_numpy()\n",
        "    print ('df:', X.shape, y.shape)\n",
        "    return (X, y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "class BaseModel(object):\n",
        "\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def fit_predict(self):\n",
        "        pass\n",
        "\n",
        "\n",
        "class SvmModel(BaseModel):\n",
        "\n",
        "    model_type = 'Support Vector Machine with linear Kernel'\n",
        "    def fit_predict(self, X_train, y_train, X_val, X_test, c_weight):\n",
        "        print ('training svm...')\n",
        "        self.classifier = SVC(\n",
        "            C=1, \n",
        "            kernel='linear', \n",
        "            probability=True,\n",
        "            class_weight=c_weight\n",
        "            )\n",
        "        self.classifier.fit(X_train, y_train)\n",
        "        self.test_y_predicted = self.classifier.predict(X_test)\n",
        "        self.val_y_predicted = self.classifier.predict(X_val)\n",
        "        return (X_train, X_val, X_test, self.val_y_predicted,\n",
        "                self.test_y_predicted)\n",
        "\n",
        "class LogModel(BaseModel):\n",
        "\n",
        "    model_type = 'Logistic Regression' \n",
        "    def fit_predict(self, X_train, y_train, X_val, X_test, c_weight):\n",
        "        print ('training logistic regression...')\n",
        "        # train_samples = X_train.shape[0]\n",
        "        self.classifier = LogisticRegression(\n",
        "            # C=50. / train_samples,\n",
        "            penalty='l1',\n",
        "            solver='liblinear',\n",
        "            tol=0.1,\n",
        "            class_weight=c_weight\n",
        "            )\n",
        "        self.classifier.fit(X_train, y_train)\n",
        "        self.test_y_predicted = self.classifier.predict(X_test)\n",
        "        self.val_y_predicted = self.classifier.predict(X_val)\n",
        "        return (X_train, X_val, X_test, self.val_y_predicted,\n",
        "                self.test_y_predicted)\n",
        "\n",
        "class RfModel(BaseModel):\n",
        "\n",
        "    model_type = 'Random Forest'\n",
        "    def fit_predict(self, X_train, y_train, X_val, X_test, c_weight):\n",
        "        print ('training random forest...')\n",
        "        self.classifier = RandomForestClassifier(\n",
        "            n_estimators=500, \n",
        "            class_weight=c_weight, \n",
        "            n_jobs=-1\n",
        "            )\n",
        "        self.classifier.fit(X_train, y_train)\n",
        "        self.test_y_predicted = self.classifier.predict(X_test)\n",
        "        self.val_y_predicted = self.classifier.predict(X_val)\n",
        "        return (X_train, X_val, X_test, self.val_y_predicted, self.test_y_predicted)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "class TrainModel:\n",
        "\n",
        "    def __init__(self, model_object):        \n",
        "        self.accuracies = []\n",
        "        self.model_object = model_object()        \n",
        "\n",
        "    def print_model_type(self):\n",
        "        print (self.model_object.model_type)\n",
        "\n",
        "    # we train normally and use the probabilities to select the most uncertain samples\n",
        "    def train(self, X_train, y_train, X_val, X_test, c_weight):\n",
        "        print ('Train set:', X_train.shape)\n",
        "        print ('Validation set:', X_val.shape)\n",
        "        print ('Test set:', X_test.shape)\n",
        "        t0 = time.time()\n",
        "        (X_train, X_val, X_test, self.val_y_predicted,\n",
        "         self.test_y_predicted) = \\\n",
        "            self.model_object.fit_predict(X_train, y_train, X_val, X_test, c_weight)\n",
        "        self.run_time = time.time() - t0\n",
        "        return (X_train, X_val, X_test)\n",
        "\n",
        "    # we want accuracy only for the test set\n",
        "    def get_test_accuracy(self, i, y_test):\n",
        "        classif_rate = np.mean(self.test_y_predicted.ravel() == y_test.ravel()) * 100\n",
        "        self.accuracies.append(classif_rate)               \n",
        "        print('--------------------------------')\n",
        "        print('Iteration:',i)\n",
        "        # print('--------------------------------')\n",
        "        print('y-test set:',y_test.shape)\n",
        "        # print('Training run in %.3f s' % self.run_time,'\\n')\n",
        "        print(\"Accuracy rate is %f \" % (classif_rate))    \n",
        "        # print(\"Classification report for %s:\\n%s\\n\" % (self.model_object.classifier, metrics.classification_report(y_test, self.test_y_predicted)))\n",
        "        # print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(y_test, self.test_y_predicted))\n",
        "        print('--------------------------------')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Normalize(object):\n",
        "    \n",
        "    def normalize(self, X_train, X_val, X_test):\n",
        "        self.scaler = RobustScaler()\n",
        "        X_train = self.scaler.fit_transform(X_train)\n",
        "        X_val   = self.scaler.transform(X_val)\n",
        "        X_test  = self.scaler.transform(X_test)\n",
        "        return (X_train, X_val, X_test) \n",
        "    \n",
        "    def inverse(self, X_train, X_val, X_test):\n",
        "        X_train = self.scaler.inverse_transform(X_train)\n",
        "        X_val   = self.scaler.inverse_transform(X_val)\n",
        "        X_test  = self.scaler.inverse_transform(X_test)\n",
        "        return (X_train, X_val, X_test) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_random_samples(initial_samples, X_train_full, y_train_full):\n",
        "\n",
        "    permutation = np.random.choice(len(X_train_full),initial_samples,replace=False)\n",
        "    X_train = X_train_full[permutation]\n",
        "    y_train = y_train_full[permutation]\n",
        "    X_train = X_train.reshape((X_train.shape[0], -1))\n",
        "\n",
        "    return (permutation, X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "def log_loss(probs):\n",
        "\n",
        "    loss = 0\n",
        "    for i in range(len(probs)):\n",
        "        for prob in probs[i]:\n",
        "            if prob in [0,1]:\n",
        "                loss -= 0\n",
        "            else:\n",
        "                loss -= (prob*np.log(prob))\n",
        "    ll = loss/(len(probs)*1.)\n",
        "\n",
        "    return ll"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "class TheAlgorithm(object):\n",
        "\n",
        "    accuracies = []\n",
        "\n",
        "    def __init__(self, step, model_object):\n",
        "        self.step = step\n",
        "        self.model_object = model_object\n",
        "        \n",
        "    def run(self, X_train_full, y_train_full, X_test, y_test, initial_queried, max_queried):\n",
        "\n",
        "        (permutation, X_train, y_train) = get_random_samples(initial_queried, X_train_full, y_train_full)\n",
        "        self.queried = initial_queried\n",
        "\n",
        "        X_val = np.array([])\n",
        "        y_val = np.array([])\n",
        "        X_val = np.copy(X_train_full)\n",
        "        X_val = np.delete(X_val, permutation, axis=0)\n",
        "        y_val = np.copy(y_train_full)\n",
        "        y_val = np.delete(y_val, permutation, axis=0)\n",
        "\n",
        "        normalizer = Normalize()\n",
        "        X_train, X_val, X_test = normalizer.normalize(X_train, X_val, X_test)\n",
        "           \n",
        "        self.clf_model = TrainModel(self.model_object)\n",
        "        (X_train, X_val, X_test) = self.clf_model.train(X_train, y_train, X_val, X_test, 'balanced')\n",
        "        active_iteration = 1\n",
        "        self.clf_model.get_test_accuracy(1, y_test)\n",
        "\n",
        "        while self.queried <= max_queried-self.step:\n",
        "\n",
        "            active_iteration += 1\n",
        "            self.queried += self.step\n",
        "\n",
        "            # (mc_permutation, X_subset, y_subset) = \\\n",
        "            #     get_random_samples(200, X_val, y_val) # 100 is the subset size\n",
        "            # print('Indexes in the subset for X_val:', mc_permutation)\n",
        "            # print ('Subset:', X_subset.shape, y_subset.shape, monte_carlo_permutation.shape)\n",
        "            # print ('Train:', X_train.shape, y_train.shape, permutation.shape)\n",
        "\n",
        "            cand_probs = self.clf_model.model_object.classifier.predict_proba(X_val)\n",
        "\n",
        "            utils = []\n",
        "\n",
        "            for i in range(len(X_val)):\n",
        "                new_train_X = X_train\n",
        "                row_subset = X_val[i]\n",
        "                new_train_X = np.append(new_train_X, [row_subset], axis=0)\n",
        "                util = 0\n",
        "                for c in [0, 1]:\n",
        "                    new_train_y = y_train\n",
        "                    new_train_y = np.append(new_train_y, c)\n",
        "                    # print('Monte_carlo training set X:', new_train_X)\n",
        "                    # print('Monte_carlo training set y:', new_train_y)\n",
        "                    new_classifier = LogisticRegression(\n",
        "                        penalty='l1',\n",
        "                        solver='liblinear',\n",
        "                        tol=0.1,\n",
        "                        class_weight='balanced')\n",
        "                    new_classifier.fit(new_train_X, new_train_y)\n",
        "                    new_probs = self.clf_model.model_object.classifier.predict_proba(X_val)\n",
        "                    # print('Probabilities subset:', new_probs)\n",
        "                    util += cand_probs[i][c] * log_loss(new_probs)\n",
        "\n",
        "                utils.append(util)\n",
        "\n",
        "            uis = np.argsort(utils)\n",
        "            # print ('Monte-carlo selected indexes:', uis)\n",
        "  \n",
        "\n",
        "            X_uncertain = [X_val[i] for i in uis[:self.step]]\n",
        "            y_uncertain = [y_val[i] for i in uis[:self.step]]\n",
        "            uncertain_samples = uis[:self.step]\n",
        "            print ('Monte-carlo selected indexes:', uncertain_samples)\n",
        "            # print ('Monte-carlo selected samples:', X_uncertain)\n",
        "            # print ('Monte-carlo selected outcomes:', y_uncertain)\n",
        "\n",
        "            X_train, X_val, X_test = normalizer.inverse(X_train, X_val, X_test)   \n",
        "            X_train = np.concatenate((X_train, np.array(X_uncertain)))\n",
        "            y_train = np.concatenate((y_train, np.array(y_uncertain)))\n",
        "\n",
        "            X_val = np.delete(X_val, uncertain_samples, axis=0)\n",
        "            y_val = np.delete(y_val, uncertain_samples, axis=0)\n",
        "\n",
        "            normalizer = Normalize()\n",
        "            X_train, X_val, X_test = normalizer.normalize(X_train, X_val, X_test)               \n",
        "\n",
        "            (X_train, X_val, X_test) = self.clf_model.train(X_train, y_train, X_val, X_test, 'balanced')\n",
        "            self.clf_model.get_test_accuracy(active_iteration, y_test)\n",
        "\n",
        "        return self.clf_model.accuracies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "def pool_experiment(model,max_queried,initial_queried,step):\n",
        "\n",
        "    (X, y) = data_prep()\n",
        "    kf = KFold(n_splits=4)\n",
        "    for train_index, test_index in kf.split(X):\n",
        "        X_train_full, X_test = X[train_index], X[test_index]\n",
        "        y_train_full, y_test = y[train_index], y[test_index]\n",
        "        \n",
        "    act_alg = TheAlgorithm(step, model)\n",
        "    accuracies = act_alg.run(X_train_full,y_train_full,X_test,y_test,initial_queried,max_queried)\n",
        "\n",
        "    (permutation, X_train_selected, y_train_selected) = get_random_samples(initial_queried, X_train_full, y_train_full)\n",
        "    original_accuracies=[]\n",
        "    classifier_original = LogisticRegression(\n",
        "            penalty='l1',\n",
        "            solver='liblinear',\n",
        "            tol=0.1,\n",
        "            class_weight='balanced')\n",
        "    x_axis = []\n",
        "    for i in range(initial_queried-1,max_queried,step):\n",
        "        classifier_original.fit(X_train_selected[:i+1], y_train_selected[:i+1])\n",
        "        y_pred_original = classifier_original.predict(X_test)\n",
        "        original_accuracies.append(accuracy_score(y_test, y_pred_original)*100)\n",
        "        x_axis.append(i+1)\n",
        "\n",
        "    plt.plot(x_axis, accuracies, 'r',label='active') \n",
        "    plt.plot(x_axis, original_accuracies, 'blue',label='non-active') \n",
        "    plt.legend()\n",
        "    plt.xlabel('Sample Size')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ True False False False False False  True False  True  True False False\n",
            " False  True  True False False False False False False False False False\n",
            "  True  True  True False False  True False]\n",
            "df: (1736, 10) (1736,)\n",
            "Train set: (50, 10)\n",
            "Validation set: (1252, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 78.801843 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [ 278 1106 1176  271  254]\n",
            "Train set: (55, 10)\n",
            "Validation set: (1247, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 77.649770 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [1246  829 1113  423  827]\n",
            "Train set: (60, 10)\n",
            "Validation set: (1242, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 3\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 79.953917 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [  0 341  26 648 384]\n",
            "Train set: (65, 10)\n",
            "Validation set: (1237, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 4\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 78.110599 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [574 758 293 345 586]\n",
            "Train set: (70, 10)\n",
            "Validation set: (1232, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 5\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 77.880184 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [1064    0  824  823  822]\n",
            "Train set: (75, 10)\n",
            "Validation set: (1227, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 6\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 77.419355 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [1143  940  957   59  976]\n",
            "Train set: (80, 10)\n",
            "Validation set: (1222, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 7\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 72.580645 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [826 187 512 510 371]\n",
            "Train set: (85, 10)\n",
            "Validation set: (1217, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 8\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 71.428571 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [829 145   0 813 812]\n",
            "Train set: (90, 10)\n",
            "Validation set: (1212, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 9\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 67.050691 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [ 586  277  369  703 1142]\n",
            "Train set: (95, 10)\n",
            "Validation set: (1207, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 10\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 68.663594 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [1206  561  266   40 1086]\n",
            "Train set: (100, 10)\n",
            "Validation set: (1202, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 11\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 64.746544 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [  0 804 803 802 801]\n",
            "Train set: (105, 10)\n",
            "Validation set: (1197, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 12\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 65.668203 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [1196  863  864  335  331]\n",
            "Train set: (110, 10)\n",
            "Validation set: (1192, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 13\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 63.364055 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [  0 514 495 484 478]\n",
            "Train set: (115, 10)\n",
            "Validation set: (1187, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 14\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 61.751152 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [ 301  141  401 1049  698]\n",
            "Train set: (120, 10)\n",
            "Validation set: (1182, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 15\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 61.981567 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [1067  272 1003  559  132]\n",
            "Train set: (125, 10)\n",
            "Validation set: (1177, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 16\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 63.364055 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [ 588  456 1002 1001  998]\n",
            "Train set: (130, 10)\n",
            "Validation set: (1172, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 17\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 60.138249 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [291 362 652 937 235]\n",
            "Train set: (135, 10)\n",
            "Validation set: (1167, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 18\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 58.755760 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [1090 1127  837  838  926]\n",
            "Train set: (140, 10)\n",
            "Validation set: (1162, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 19\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 59.907834 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [580 269 275 894 281]\n",
            "Train set: (145, 10)\n",
            "Validation set: (1157, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 20\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 61.981567 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [1008  636  489 1059  404]\n",
            "Train set: (150, 10)\n",
            "Validation set: (1152, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 21\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 61.520737 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [579 812 916 234 356]\n",
            "Train set: (155, 10)\n",
            "Validation set: (1147, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 22\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 61.520737 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [1079  574  244  564  113]\n",
            "Train set: (160, 10)\n",
            "Validation set: (1142, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 23\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 63.133641 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [ 496  801 1105 1107  454]\n",
            "Train set: (165, 10)\n",
            "Validation set: (1137, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 24\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 60.599078 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [250 924 903 340 669]\n",
            "Train set: (170, 10)\n",
            "Validation set: (1132, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 25\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 64.055300 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [ 317  376 1017  242  120]\n",
            "Train set: (175, 10)\n",
            "Validation set: (1127, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 26\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 57.834101 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [961 518 120 538 508]\n",
            "Train set: (180, 10)\n",
            "Validation set: (1122, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 27\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 60.138249 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [ 565  128  126 1002  230]\n",
            "Train set: (185, 10)\n",
            "Validation set: (1117, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 28\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 61.290323 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [ 283  686  950  672 1002]\n",
            "Train set: (190, 10)\n",
            "Validation set: (1112, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 29\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 61.520737 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [928 477 756 929 628]\n",
            "Train set: (195, 10)\n",
            "Validation set: (1107, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 30\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 61.520737 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [538 934 394 690 149]\n",
            "Train set: (200, 10)\n",
            "Validation set: (1102, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 31\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 61.059908 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [  0 451 107 996 997]\n",
            "Train set: (205, 10)\n",
            "Validation set: (1097, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 32\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 58.986175 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [548 455 231 234 103]\n",
            "Train set: (210, 10)\n",
            "Validation set: (1092, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 33\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 63.364055 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [ 74 443 647 772 509]\n",
            "Train set: (215, 10)\n",
            "Validation set: (1087, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 34\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 61.520737 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [168 123 639 561  48]\n",
            "Train set: (220, 10)\n",
            "Validation set: (1082, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 35\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 63.594470 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [ 310  908 1051  314  144]\n",
            "Train set: (225, 10)\n",
            "Validation set: (1077, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 36\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 63.594470 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [1031 1037 1072 1000  455]\n",
            "Train set: (230, 10)\n",
            "Validation set: (1072, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 37\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 64.746544 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [ 674  593 1000  232 1002]\n",
            "Train set: (235, 10)\n",
            "Validation set: (1067, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 38\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 64.285714 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [ 574 1014  779  470  507]\n",
            "Train set: (240, 10)\n",
            "Validation set: (1062, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 39\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 63.364055 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [  0 668 385 667 158]\n",
            "Train set: (245, 10)\n",
            "Validation set: (1057, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 40\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 63.594470 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [ 19 555 907 512 739]\n",
            "Train set: (250, 10)\n",
            "Validation set: (1052, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 41\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 63.824885 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [130 861 366 129 660]\n",
            "Train set: (255, 10)\n",
            "Validation set: (1047, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 42\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 65.668203 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [597 614 201 841 603]\n",
            "Train set: (260, 10)\n",
            "Validation set: (1042, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 43\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 66.129032 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [  0 359 870 876 158]\n",
            "Train set: (265, 10)\n",
            "Validation set: (1037, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 44\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 63.824885 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [614 134 911 316  56]\n",
            "Train set: (270, 10)\n",
            "Validation set: (1032, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 45\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 63.594470 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [ 580  324  174    6 1024]\n",
            "Train set: (275, 10)\n",
            "Validation set: (1027, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 46\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 63.594470 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [131 558 214 115 972]\n",
            "Train set: (280, 10)\n",
            "Validation set: (1022, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 47\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 61.290323 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [  0 932  88 331 817]\n",
            "Train set: (285, 10)\n",
            "Validation set: (1017, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 48\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 63.594470 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [147 403 530 237 569]\n",
            "Train set: (290, 10)\n",
            "Validation set: (1012, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 49\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 63.824885 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [698 693  74 208 441]\n",
            "Train set: (295, 10)\n",
            "Validation set: (1007, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 50\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 61.981567 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [755 385 614 143 869]\n",
            "Train set: (300, 10)\n",
            "Validation set: (1002, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 51\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 62.442396 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [304 127  35 771 480]\n",
            "Train set: (305, 10)\n",
            "Validation set: (997, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 52\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 63.824885 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [271 256  34 476 719]\n",
            "Train set: (310, 10)\n",
            "Validation set: (992, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 53\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 63.133641 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [630 922  73 923 559]\n",
            "Train set: (315, 10)\n",
            "Validation set: (987, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 54\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 61.290323 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [492 152 776 322 176]\n",
            "Train set: (320, 10)\n",
            "Validation set: (982, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 55\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 62.442396 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [138 978 233 789 223]\n",
            "Train set: (325, 10)\n",
            "Validation set: (977, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 56\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 60.138249 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [741 471 952 857 168]\n",
            "Train set: (330, 10)\n",
            "Validation set: (972, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 57\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 61.751152 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [366 709 262 329 303]\n",
            "Train set: (335, 10)\n",
            "Validation set: (967, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 58\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 59.216590 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [787 608  84 778 637]\n",
            "Train set: (340, 10)\n",
            "Validation set: (962, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 59\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 61.981567 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [370 322  99 859  95]\n",
            "Train set: (345, 10)\n",
            "Validation set: (957, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 60\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 61.520737 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [714 585 352 176   0]\n",
            "Train set: (350, 10)\n",
            "Validation set: (952, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 61\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 63.364055 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [820 912 118 909 830]\n",
            "Train set: (355, 10)\n",
            "Validation set: (947, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 62\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 61.059908 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [946 604 129 125 592]\n",
            "Train set: (360, 10)\n",
            "Validation set: (942, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 63\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 61.520737 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [522 581 916   0 619]\n",
            "Train set: (365, 10)\n",
            "Validation set: (937, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 64\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 61.290323 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [ 39 218 605 328  37]\n",
            "Train set: (370, 10)\n",
            "Validation set: (932, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 65\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 62.442396 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [538 179 549  84  82]\n",
            "Train set: (375, 10)\n",
            "Validation set: (927, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 66\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 59.447005 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [ 35 259 326  29 265]\n",
            "Train set: (380, 10)\n",
            "Validation set: (922, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 67\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 61.059908 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [351 803 355 885 652]\n",
            "Train set: (385, 10)\n",
            "Validation set: (917, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 68\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 60.368664 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [  0 760 763 331 582]\n",
            "Train set: (390, 10)\n",
            "Validation set: (912, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 69\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 59.907834 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [124 153 762 334 580]\n",
            "Train set: (395, 10)\n",
            "Validation set: (907, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 70\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 58.755760 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [683 641   0 597 598]\n",
            "Train set: (400, 10)\n",
            "Validation set: (902, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 71\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 59.447005 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [775 581 318 105 801]\n",
            "Train set: (405, 10)\n",
            "Validation set: (897, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 72\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 61.520737 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [665 142 731 536 259]\n",
            "Train set: (410, 10)\n",
            "Validation set: (892, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 73\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 61.290323 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [559 251 350 577 861]\n",
            "Train set: (415, 10)\n",
            "Validation set: (887, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 74\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 61.520737 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [629 106 299 104 834]\n",
            "Train set: (420, 10)\n",
            "Validation set: (882, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 75\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 59.677419 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [701 610 631 420 675]\n",
            "Train set: (425, 10)\n",
            "Validation set: (877, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 76\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 62.211982 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [713 693 597 260 596]\n",
            "Train set: (430, 10)\n",
            "Validation set: (872, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 77\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 62.672811 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [601 635   0 573 574]\n",
            "Train set: (435, 10)\n",
            "Validation set: (867, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 78\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 60.138249 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [192 132 666 767 694]\n",
            "Train set: (440, 10)\n",
            "Validation set: (862, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 79\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 61.520737 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [676   0 568 569 570]\n",
            "Train set: (445, 10)\n",
            "Validation set: (857, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 80\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 60.599078 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [819 770 797 798 652]\n",
            "Train set: (450, 10)\n",
            "Validation set: (852, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 81\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 61.981567 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [136 252 402 373 824]\n",
            "Train set: (455, 10)\n",
            "Validation set: (847, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 82\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 60.599078 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [  0 558 559 560 561]\n",
            "Train set: (460, 10)\n",
            "Validation set: (842, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 83\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 62.442396 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [  0 554 555 556 557]\n",
            "Train set: (465, 10)\n",
            "Validation set: (837, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 84\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 57.142857 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [492   0 551 552 553]\n",
            "Train set: (470, 10)\n",
            "Validation set: (832, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 85\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 61.059908 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [ 51  80  29  93 550]\n",
            "Train set: (475, 10)\n",
            "Validation set: (827, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 86\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 60.368664 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [286 613   0 544 545]\n",
            "Train set: (480, 10)\n",
            "Validation set: (822, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 87\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 60.599078 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [ 74 198 740 693  25]\n",
            "Train set: (485, 10)\n",
            "Validation set: (817, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 88\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 57.373272 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [664 776 278 572 451]\n",
            "Train set: (490, 10)\n",
            "Validation set: (812, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 89\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 57.603687 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [600 101 319 756 784]\n",
            "Train set: (495, 10)\n",
            "Validation set: (807, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 90\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 60.138249 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [293 649 564 478  78]\n",
            "Train set: (500, 10)\n",
            "Validation set: (802, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 91\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 61.290323 \n",
            "--------------------------------\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "pool_experiment(LogModel,500,50,5)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyMfqalTRwiWuiIELJDbCQ7d",
      "mount_file_id": "1SZapm_bYNJDCJi8ECwmjrzaN8-1ruRgA",
      "name": "Logistic.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "5edc29c2ed010d6458d71a83433b383a96a8cbd3efe8531bc90c4b8a5b8bcec9"
    },
    "kernelspec": {
      "display_name": "Python 3.8.2 64-bit",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "metadata": {
      "interpreter": {
        "hash": "5edc29c2ed010d6458d71a83433b383a96a8cbd3efe8531bc90c4b8a5b8bcec9"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}