{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 201,
      "source": [
        "print(__doc__)\n",
        "\n",
        "import os\n",
        "import time\n",
        "import json\n",
        "import pickle\n",
        "import math\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.mlab as mlab\n",
        "from scipy.special import expit\n",
        "from scipy import stats\n",
        "from pylab import rcParams\n",
        "import mplcursors\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.datasets import load_digits\n",
        "\n",
        "from sklearn.utils import check_random_state\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer\n",
        "from sklearn.pipeline import Pipeline, FeatureUnion\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import scale\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "\n",
        "from sklearn import linear_model\n",
        "from sklearn import neighbors\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.linear_model import RidgeCV, LassoCV, Ridge, Lasso\n",
        "from sklearn.svm import LinearSVC, SVC\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.utils import check_random_state\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics.pairwise import euclidean_distances\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.mixture import GaussianMixture\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import pairwise_distances_argmin_min\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import average_precision_score\n",
        "\n",
        "\n",
        "# pd.options.display.max_rows = 20\n",
        "pd.options.display.float_format = \"{:.1f}\".format"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Automatically created module for IPython interactive environment\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ioi13nGDPDvQ",
        "outputId": "4763f7b3-6c5b-45cb-f411-fd7c6ea8b38f"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 202,
      "source": [
        "def fetch_data_iris():\n",
        "    iris = load_iris()\n",
        "    X = iris.data.astype('float64')\n",
        "    y = iris.target\n",
        "    print ('Dataset : ', X.shape, y.shape)\n",
        "    return (X, y)\n",
        "\n",
        "def fetch_data_mnist():\n",
        "    mnist = load_digits()\n",
        "    X = mnist.data.astype('float64')\n",
        "    y = mnist.target\n",
        "    print ('Dataset : ', X.shape, y.shape)\n",
        "    return (X, y)\n",
        "\n",
        "def fetch_data_recid():\n",
        "    \n",
        "    data = pd.read_csv(\"https://raw.githubusercontent.com/WenxuanHuang/Active-Learning-Performance-Benchmarking/main/RecidivismData_Normalized.csv\", sep=',')\n",
        "    df = data[(data['race']==2)|(data['race']==3)].copy()\n",
        "    X = df.iloc[:,np.r_[3,5,6,8:14]].to_numpy()\n",
        "    print(X)\n",
        "    y = df['two_year_recid'].to_numpy()\n",
        "    print(y)\n",
        "    print ('Shape of X and y:', X.shape, y.shape)\n",
        "    return (X, y)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 203,
      "source": [
        "class BaseModel(object):\n",
        "\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def fit_predict(self):\n",
        "        pass\n",
        "\n",
        "\n",
        "# class SvmModel(BaseModel):\n",
        "\n",
        "#     def fit_predict(self, X_train, y_train, X_val, X_test):\n",
        "#         print ('training svm...')\n",
        "#         self.classifier = SVC(\n",
        "#             C=1, \n",
        "#             kernel='linear', \n",
        "#             probability=True\n",
        "#             )\n",
        "#         self.classifier.fit(X_train, y_train)\n",
        "#         self.test_y_predicted = self.classifier.predict(X_test)\n",
        "#         self.val_y_predicted = self.classifier.predict(X_val)\n",
        "#         return (X_train, X_val, X_test, self.val_y_predicted,\n",
        "#                 self.test_y_predicted)\n",
        "\n",
        "class LogModel(BaseModel):\n",
        "\n",
        "    def fit_predict(self, X_train, y_train, X_test, y_test):\n",
        "        # print ('training logistic regression...')\n",
        "        # train_samples = X_train.shape[0]\n",
        "        self.classifier = LogisticRegression(\n",
        "            solver='liblinear'\n",
        "            )\n",
        "        self.classifier.fit(X_train, y_train)\n",
        "        self.score = self.classifier.score(X_test, y_test)\n",
        "        return (X_train, X_test, self.score)\n",
        "\n",
        "# class RfModel(BaseModel):\n",
        "\n",
        "#     def fit_predict(self, X_train, y_train, X_val, X_test):\n",
        "#         print ('training random forest...')\n",
        "#         self.classifier = RandomForestClassifier(\n",
        "#             n_estimators=100, \n",
        "#             n_jobs=-1\n",
        "#             )\n",
        "#         self.classifier.fit(X_train, y_train)\n",
        "#         self.test_y_predicted = self.classifier.predict(X_test)\n",
        "#         self.val_y_predicted = self.classifier.predict(X_val)\n",
        "#         return (X_train, X_val, X_test, self.val_y_predicted, self.test_y_predicted)\n",
        "\n"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 204,
      "source": [
        "class TrainModel:\n",
        "\n",
        "    def __init__(self, model_object):        \n",
        "        self.accuracies = []\n",
        "        self.model_object = model_object()        \n",
        "\n",
        "    def print_model_type(self):\n",
        "        print (self.model_object.model_type)\n",
        "\n",
        "    # we train normally and use the probabilities to select the most uncertain samples\n",
        "    def train(self, X_train, y_train, X_test, y_test):\n",
        "        t0 = time.time()\n",
        "        (X_train, X_test, self.score) = \\\n",
        "            self.model_object.fit_predict(X_train, y_train, X_test, y_test)\n",
        "        self.run_time = time.time() - t0\n",
        "        return (X_train, X_test)\n",
        "\n",
        "    # we want accuracy only for the test set\n",
        "    def get_test_accuracy(self, i):\n",
        "        classif_rate = self.score * 100\n",
        "        self.accuracies.append(classif_rate)               \n",
        "        print('--------------------------------')\n",
        "        print('Iteration:',i)\n",
        "        # print('--------------------------------')\n",
        "        # print('y-test set:',y_test.shape)\n",
        "        # print('Training run in %.3f s' % self.run_time,'\\n')\n",
        "        print(\"Accuracy rate is %f \" % (classif_rate))    \n",
        "        # print(\"Classification report for %s:\\n%s\\n\" % (self.model_object.classifier, metrics.classification_report(y_test, self.test_y_predicted)))\n",
        "        # print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(y_test, self.test_y_predicted))\n",
        "        print('--------------------------------')\n"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 205,
      "source": [
        "class QueryFunction(object):\n",
        "\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    # def stream_select(self):\n",
        "    #     pass\n",
        "\n",
        "    def pool_select(self):\n",
        "        pass\n",
        "\n",
        "\n",
        "class RandomSelection(QueryFunction):\n",
        "\n",
        "    @staticmethod\n",
        "    def pool_select(probas_val, batch_size):\n",
        "        random_state = check_random_state(0)\n",
        "        # probas_val.shape[0] is the size of validation set\n",
        "        selection = np.random.choice(probas_val.shape[0], batch_size, replace=False)\n",
        "        # print('uniques chosen:',np.unique(selection).shape[0],'<= should be equal to:',batch_size)\n",
        "        return selection\n",
        "\n",
        "\n",
        "class EntropySelection(QueryFunction):\n",
        "\n",
        "    @staticmethod\n",
        "    def pool_select(probas_val, batch_size):\n",
        "        e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
        "        selection = (np.argsort(e)[::-1])[:batch_size]\n",
        "        return selection\n",
        "\n",
        "class MinStdSelection(QueryFunction):\n",
        "\n",
        "    # select the samples where the std is smallest. There is uncertainty regarding the relevant class\n",
        "    # and then train on these \"hard\" to classify samples.\n",
        "    @staticmethod\n",
        "    def pool_select(probas_val, batch_size):\n",
        "        std = np.std(probas_val * 100, axis=1) \n",
        "        selection = std.argsort()[:batch_size]\n",
        "        selection = selection.astype('int64')\n",
        "        print('std',std.shape,std)\n",
        "        print('selection',selection, selection.shape, std[selection])\n",
        "        return selection\n",
        "\n",
        "class LeastConfidenceSelection(QueryFunction):\n",
        "\n",
        "    @staticmethod\n",
        "    def pool_select(probas_val, batch_size):\n",
        "        sort_prob = -np.sort(-probas_val, axis=1)\n",
        "        values = sort_prob[:, 0]\n",
        "        selection = np.argsort(values)[:batch_size]\n",
        "        return selection\n",
        "      \n",
        "      \n",
        "class MarginSelection(QueryFunction):\n",
        "\n",
        "    @staticmethod\n",
        "    def pool_select(probas_val, batch_size):\n",
        "        sort_prob = -np.sort(-probas_val, axis=1)\n",
        "        values = sort_prob[:, 0] - sort_prob[:, 1]\n",
        "        selection = np.argsort(values)[:batch_size]\n",
        "        return selection\n"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 206,
      "source": [
        "class Normalize(object):\n",
        "    \n",
        "    def normalize(self, X_train, X_val, X_test):\n",
        "        self.scaler = RobustScaler()\n",
        "        X_train = self.scaler.fit_transform(X_train)\n",
        "        X_val   = self.scaler.transform(X_val)\n",
        "        X_test  = self.scaler.transform(X_test)\n",
        "        return (X_train, X_val, X_test) \n",
        "    \n",
        "    def inverse(self, X_train, X_val, X_test):\n",
        "        X_train = self.scaler.inverse_transform(X_train)\n",
        "        X_val   = self.scaler.inverse_transform(X_val)\n",
        "        X_test  = self.scaler.inverse_transform(X_test)\n",
        "        return (X_train, X_val, X_test) "
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 207,
      "source": [
        "def get_random_samples(initial_samples, X_train_full,\n",
        "                         y_train_full):\n",
        "\n",
        "    random_state = check_random_state(0)\n",
        "\n",
        "    permutation = np.random.choice(len(X_train_full),initial_samples,replace=False)\n",
        "    \n",
        "    # print ()\n",
        "    # print(type(permutation))\n",
        "    # print ('initial random chosen samples', permutation)\n",
        "\n",
        "    X_train = X_train_full[permutation]\n",
        "    y_train = y_train_full[permutation]\n",
        "    X_train = X_train.reshape((X_train.shape[0], -1))\n",
        "\n",
        "    # bin_count = np.bincount(y_train.astype('int64'))\n",
        "    # unique = np.unique(y_train.astype('int64'))\n",
        "    # print (\n",
        "    #     'initial train set:',\n",
        "    #     X_train.shape,\n",
        "    #     y_train.shape,\n",
        "    #     'unique(labels):',\n",
        "    #     bin_count,\n",
        "    #     unique,\n",
        "    #     )\n",
        "    return (permutation, X_train, y_train)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 208,
      "source": [
        "class TheAlgorithm(object):\n",
        "\n",
        "    accuracies = []\n",
        "\n",
        "    def __init__(self, step, model_object, selection_function):\n",
        "        self.step = step\n",
        "        self.model_object = model_object\n",
        "        self.sample_selection_function = selection_function\n",
        "        \n",
        "# To-do: Move initiation selections as arguments\n",
        "    def run(self, X_train_full, y_train_full, X_test, y_test, initial_queried, max_queried):\n",
        "\n",
        "        # initialize process by applying base learner to labeled training data set to obtain Classifier\n",
        "        (permutation, X_train, y_train) = \\\n",
        "            get_random_samples(initial_queried, X_train_full, y_train_full)\n",
        "        self.queried = initial_queried\n",
        "        # self.samplecount = [self.initiation_selections]\n",
        "\n",
        "        # assign the val set the rest of the 'unlabelled' training data\n",
        "        X_val = np.array([])\n",
        "        y_val = np.array([])\n",
        "        X_val = np.copy(X_train_full)\n",
        "        X_val = np.delete(X_val, permutation, axis=0)\n",
        "        y_val = np.copy(y_train_full)\n",
        "        y_val = np.delete(y_val, permutation, axis=0)\n",
        "        print ('Val set:', X_val.shape, y_val.shape, permutation.shape)\n",
        "        # print ()\n",
        "\n",
        "        # normalize data\n",
        "        # normalizer = Normalize()\n",
        "        # X_train, X_val, X_test = normalizer.normalize(X_train, X_val, X_test)\n",
        "           \n",
        "        self.clf_model = TrainModel(self.model_object)\n",
        "        (X_train, X_test) = self.clf_model.train(X_train, y_train, X_test, y_test)\n",
        "        active_iteration = 1\n",
        "        self.clf_model.get_test_accuracy(active_iteration)\n",
        "\n",
        "        # queried_num = [self.queried]\n",
        "\n",
        "        while self.queried <= max_queried-self.step:\n",
        "\n",
        "            active_iteration += 1\n",
        "            self.queried += self.step\n",
        "            # queried_num.append(self.queried)\n",
        "            # get validation probabilities\n",
        "            probas_val = \\\n",
        "                self.clf_model.model_object.classifier.predict_proba(X_val)\n",
        "            # print('Classifier class:', self.clf_model.model_object.classifier.classes_)\n",
        "            # print('Probas_val:', probas_val)\n",
        "            # pred_val = \\\n",
        "            #     self.clf_model.val_y_predicted\n",
        "            # model_val = \\\n",
        "            #     self.clf_model\n",
        "            # print ('val predicted:',\n",
        "            #         self.clf_model.val_y_predicted.shape,\n",
        "            #         self.clf_model.val_y_predicted)\n",
        "            # display probability of binary value predictions of the validation set\n",
        "            # print ('probas_val value', probas_val)\n",
        "            # display which binary value has the highest probabilities of the validation set\n",
        "            # print ('probabilities:', probas_val.shape, '\\n',\n",
        "            #        np.argmax(probas_val, axis=1))\n",
        "\n",
        "            # select samples using a selection function\n",
        "            uncertain_samples = self.sample_selection_function.pool_select(probas_val, self.step)\n",
        "\n",
        "            # normalization needs to be inversed and recalculated based on the new train and test set.\n",
        "            # X_train, X_val, X_test = normalizer.inverse(X_train, X_val, X_test)   \n",
        "\n",
        "            # get the uncertain samples from the validation set\n",
        "            # print ('trainset before adding uncertain samples', X_train.shape, y_train.shape)\n",
        "            X_train = np.concatenate((X_train, X_val[uncertain_samples]))\n",
        "            y_train = np.concatenate((y_train, y_val[uncertain_samples]))\n",
        "            # print ('trainset after adding uncertain samples', X_train.shape, y_train.shape)\n",
        "            # self.samplecount.append(X_train.shape[0])\n",
        "\n",
        "            \n",
        "\n",
        "            # bin_count = np.bincount(y_train.astype('int64'))\n",
        "            # unique = np.unique(y_train.astype('int64'))\n",
        "            # print (\n",
        "            #     'updated train set:',\n",
        "            #     X_train.shape,\n",
        "            #     y_train.shape,\n",
        "            #     'unique(labels):',\n",
        "            #     bin_count,\n",
        "            #     unique,\n",
        "            #     )\n",
        "\n",
        "            X_val = np.delete(X_val, uncertain_samples, axis=0)\n",
        "            y_val = np.delete(y_val, uncertain_samples, axis=0)\n",
        "            # print ('val set:', X_val.shape, y_val.shape)\n",
        "            # print ()\n",
        "\n",
        "            # normalize again after creating the 'new' train/test sets\n",
        "            # normalizer = Normalize()\n",
        "            # X_train, X_val, X_test = normalizer.normalize(X_train, X_val, X_test)               \n",
        "\n",
        "            # self.queried += self.step\n",
        "\n",
        "            (X_train, X_test) = self.clf_model.train(X_train, y_train, X_test, y_test)\n",
        "            self.clf_model.get_test_accuracy(active_iteration)\n",
        "\n",
        "        # print('Queried numbers', queried_num)\n",
        "        return self.clf_model.accuracies\n",
        "        # print ('final active learning accuracies',\n",
        "        #        self.clf_model.accuracies)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 209,
      "source": [
        "def pool_experiment(model,sampling_method,max_queried,initial_queried,step):\n",
        "    (X, y) = fetch_data_recid()\n",
        "    # (X_train_full, X_test,y_train_full,  y_test) = train_test_split(X, y, test_size=0.25)\n",
        "    # print(type(X_train_full))\n",
        "\n",
        "    kf = KFold(n_splits=4)\n",
        "\n",
        "    for train_index, test_index in kf.split(X):\n",
        "        X_train_full, X_test = X[train_index], X[test_index]\n",
        "        y_train_full, y_test = y[train_index], y[test_index]\n",
        "        \n",
        "    act_alg = TheAlgorithm(step, model , sampling_method)\n",
        "    accuracies = act_alg.run(X_train_full,y_train_full,X_test,y_test,initial_queried,max_queried)\n",
        "\n",
        "    nonal_X_train = X_train_full\n",
        "    nonal_y_train = y_train_full\n",
        "    nonal_X_test = X_test\n",
        "    nonal_y_test = y_test\n",
        "\n",
        "    nonal_initial_query = 10 # temporary implementation\n",
        "    nonal_accuracies=[]\n",
        "    classifier_nonal = LogisticRegression(\n",
        "            solver='liblinear'\n",
        "            )\n",
        "    x_axis = []\n",
        "    \n",
        "    for i in range(nonal_initial_query-1,max_queried,step): \n",
        "        classifier_nonal.fit(nonal_X_train[:i+1], nonal_y_train[:i+1])\n",
        "        nonal_y_pred = classifier_nonal.predict(nonal_X_test)\n",
        "        nonal_accuracies.append(accuracy_score(nonal_y_test, nonal_y_pred)*100)\n",
        "        x_axis.append(i+1)\n",
        "\n",
        "    print(\"accuracies\",accuracies)\n",
        "    print(\"nonactive_accuracies\",nonal_accuracies)\n",
        "\n",
        "    # print(\"x-axis:\",x_axis)\n",
        "    # print(\"x-axis length:\",len(x_axis))\n",
        "    # x_axis = np.linspace(initial_queried,max_queried,num=(max_queried - initial_queried)//step +1,endpoint=True)\n",
        "    plt.plot(x_axis, accuracies, 'r',label='active')\n",
        "    plt.plot(x_axis, nonal_accuracies, 'blue',label='non-active')\n",
        "    plt.legend()\n",
        "    plt.xlabel('Sample Size')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.show()"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 210,
      "source": [
        "pool_experiment(LogModel,MarginSelection,500,10,10)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset :  (1797, 64) (1797,)\n",
            "Val set: (1338, 64) (1338,) (10,)\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "Accuracy rate is 50.111359 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "Accuracy rate is 73.719376 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 3\n",
            "Accuracy rate is 76.614699 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 4\n",
            "Accuracy rate is 78.619154 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 5\n",
            "Accuracy rate is 83.964365 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 6\n",
            "Accuracy rate is 84.409800 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 7\n",
            "Accuracy rate is 83.073497 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 8\n",
            "Accuracy rate is 85.746102 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 9\n",
            "Accuracy rate is 85.300668 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 10\n",
            "Accuracy rate is 85.968820 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 11\n",
            "Accuracy rate is 84.632517 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 12\n",
            "Accuracy rate is 84.855234 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 13\n",
            "Accuracy rate is 86.191537 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 14\n",
            "Accuracy rate is 87.527840 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 15\n",
            "Accuracy rate is 88.195991 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 16\n",
            "Accuracy rate is 88.418708 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 17\n",
            "Accuracy rate is 86.859688 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 18\n",
            "Accuracy rate is 87.750557 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 19\n",
            "Accuracy rate is 90.423163 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 20\n",
            "Accuracy rate is 91.314031 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 21\n",
            "Accuracy rate is 92.204900 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 22\n",
            "Accuracy rate is 90.645880 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 23\n",
            "Accuracy rate is 91.314031 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 24\n",
            "Accuracy rate is 91.982183 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 25\n",
            "Accuracy rate is 91.314031 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 26\n",
            "Accuracy rate is 90.868597 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 27\n",
            "Accuracy rate is 90.645880 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 28\n",
            "Accuracy rate is 90.868597 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 29\n",
            "Accuracy rate is 91.314031 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 30\n",
            "Accuracy rate is 91.536748 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 31\n",
            "Accuracy rate is 90.423163 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 32\n",
            "Accuracy rate is 90.645880 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 33\n",
            "Accuracy rate is 90.645880 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 34\n",
            "Accuracy rate is 89.309577 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 35\n",
            "Accuracy rate is 89.977728 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 36\n",
            "Accuracy rate is 89.977728 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 37\n",
            "Accuracy rate is 90.200445 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 38\n",
            "Accuracy rate is 90.645880 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 39\n",
            "Accuracy rate is 89.977728 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 40\n",
            "Accuracy rate is 90.200445 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 41\n",
            "Accuracy rate is 90.200445 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 42\n",
            "Accuracy rate is 90.200445 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 43\n",
            "Accuracy rate is 90.200445 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 44\n",
            "Accuracy rate is 90.200445 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 45\n",
            "Accuracy rate is 90.200445 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 46\n",
            "Accuracy rate is 90.200445 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 47\n",
            "Accuracy rate is 90.200445 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 48\n",
            "Accuracy rate is 90.200445 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 49\n",
            "Accuracy rate is 90.423163 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 50\n",
            "Accuracy rate is 90.200445 \n",
            "--------------------------------\n",
            "accuracies [50.11135857461024, 73.71937639198218, 76.61469933184856, 78.61915367483296, 83.96436525612472, 84.4097995545657, 83.07349665924276, 85.74610244988864, 85.30066815144765, 85.96881959910914, 84.63251670378618, 84.85523385300668, 86.19153674832963, 87.52783964365256, 88.19599109131403, 88.41870824053451, 86.8596881959911, 87.75055679287304, 90.42316258351893, 91.31403118040089, 92.20489977728286, 90.64587973273942, 91.31403118040089, 91.98218262806236, 91.31403118040089, 90.8685968819599, 90.64587973273942, 90.8685968819599, 91.31403118040089, 91.53674832962137, 90.42316258351893, 90.64587973273942, 90.64587973273942, 89.30957683741649, 89.97772828507794, 89.97772828507794, 90.20044543429844, 90.64587973273942, 89.97772828507794, 90.20044543429844, 90.20044543429844, 90.20044543429844, 90.20044543429844, 90.20044543429844, 90.20044543429844, 90.20044543429844, 90.20044543429844, 90.20044543429844, 90.42316258351893, 90.20044543429844]\n",
            "nonactive_accuracies [56.347438752783965, 73.4966592427617, 75.7238307349666, 75.7238307349666, 77.728285077951, 77.28285077951003, 77.50556792873051, 77.9510022271715, 81.51447661469933, 81.73719376391982, 82.40534521158129, 82.62806236080178, 79.73273942093542, 80.17817371937639, 81.51447661469933, 81.9599109131403, 81.73719376391982, 81.51447661469933, 83.51893095768375, 83.74164810690424, 83.51893095768375, 83.96436525612472, 84.18708240534521, 83.51893095768375, 83.07349665924276, 83.74164810690424, 86.63697104677061, 86.63697104677061, 86.63697104677061, 87.75055679287304, 87.08240534521158, 87.30512249443207, 86.19153674832963, 86.41425389755011, 86.41425389755011, 86.8596881959911, 87.75055679287304, 87.75055679287304, 89.53229398663697, 89.75501113585747, 89.53229398663697, 89.75501113585747, 88.8641425389755, 90.64587973273942, 89.53229398663697, 89.97772828507794, 89.97772828507794, 89.086859688196, 89.75501113585747, 89.53229398663697]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEGCAYAAABiq/5QAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAzhUlEQVR4nO3deXhU5fXA8e8hLGGTJQEFEaGAgKCgoGJRURH3rRTB1gWtlVI3rC0V64pLXXDXIqIg/MQiCCpqXUBkcWcHQUQFQVFUEgh7IMv5/XFuFiAJkzA3k8ycz/PMk9w7d+5970xy7jvvfd/ziqrinHMucVSJdQGcc86VLw/8zjmXYDzwO+dcgvHA75xzCcYDv3POJZiqsS5AJFJTU7VFixaxLoZzzlUq8+fPT1PVRnuurxSBv0WLFsybNy/WxXDOuUpFRNYUtd6bepxzLsF44HfOuQTjgd855xKMB37nnEswHvidcy7BeOB3zrkE44HfOecSjAd+Fz+WLYOxY8FTjTtXIg/8rvLLzob774ejj4YrroAHHti//eXkwJtvwocfRqV4zlU0Hvhd5bZ8OXTvDv/6F5x3HvTta79PmlT6feXmwsSJcMQRcP75cNJJcMopMHt29MvtXAx54HeVU04OPPIIHHUUfPstvPwyvPKKNfX89rdw2WUwZ05k+8rNtQtFp07Qrx+I2P6eeAK++gp69ICePeGjj8I9p+Kowk8/wbRpkZ+TcyVR1Qr/6NKlizqX7+uvVbt3VwXV889XXbdu9+d//VW1ZUvVAw9UXbOm+P3k5qq++qrqkUfavtq1Ux0/XjU7u2Cb7dtVH31UtXFj26ZXL9UPPlDNyQnn3HJzVefMUX3ySdUBA+w869e3Y+c97rnHtnNuH4B5WkRMjXlQj+Thgd+pqgXbJ55QrVnTguGLLxYfAJctUz3gANUjjlDdtGn353JzVV9/XbVzZ/sXOOww1XHjdg/4e9q2TfXhh1UbNbLXNG2qOmiQ6scf7/9FIDdXdd481cGDVQ89tCDAN2igesIJqn/5i10Ipk9Xvewye+6SS1R37Ni/47q454HfVW4rV6r26GF/smefrbp27b5fM3WqalKSbZ+VZQH2zTdVu3Sx/bRqpTp2rD0Xqa1b7VvBhReq1qhh+2nWTPVvf1OdPXvvi0xJ+/n0U9UhQ1R/8xvbT9WqqmedpTpmjOqPPxZ9UcvNVb3vPtv++ONVf/kl8rK7hFNc4Bd7rmLr2rWrelrmBJWbC88+C4MHQ1ISPP649dwRiez1I0bAX/9qbferVsHcudCyJdxxB1x6KVTdj8zkmzdb758JE+C992DXLlvfvDl06FDw+M1v4Pvvrbvp0qX2c/Vqq9cnJdn9g3794MILoWHDyI49aRJcfjk0bgxvvQUdO+69TWamnXNW1t7PicDhh+/f+ZfV+vVQpw7UrFn+xy7Grl2wfTvUrx/rkkSXiMxX1a57PVHU1SBaD2AQsBRYBtwYrGsITAO+CX422Nd+vMafoNasUe3ZU/Pb1ktqry/JjTfaPlq0UH3+edVdu6JbTlXVjRut+ei++1T/+EfVTp0KvhHkPapVU+3QQbVvX9W771adPFl1/fqyH3PuXNUmTVTr1rWmqvHjVW+7TfV3v7PmqypVdj/+no8TT1TdsiVa70DJ1q5Vffxx1d/+1o6dmqo6bJh984mx7Gz7M6tbV/Wdd2JQgK1b7T5VCPdtKO8av4h0BF4GjgV2Ae8CA4EBwAZVfUBEhgSB/+aS9uU1/gS0Ywccdhhs3Gi9dwYMiLyWv6fcXPjkEzj2WKhePbrlLEl2ttW4V62ybwFt2kC1atE9xtq11vV04UJbrlIFWrcu+LbRrh3UqrX36777Dv75TzjhBPjf/6B27eiWC+DHH+G116yL7Ecf2eXmyCOhd2/7PKZOtW8sN98MAwcWXU6wHlxpaaENzLv70drcOawuzZrm8NPPVXj87i1c96ftZf5zK5YqrFtn3/gKP777zp6vX7/gc+vYseD3xo3L/LdfXI0/zMB/EXCmql4VLN8O7ASuAk5W1XUi0gSYqaptS9qXB/4E9OSTMGgQfPCB9aV3xdu+3d6nQw6Btm0hOTmy1738MlxyiXVXfeut4gNvnm3big6+O3ZYt9fCTVnLllmTDlgQ69sXLrrILkR5Pv4Y7rwTpk+Hgw6CIUPg7LML9pX3WL7cmq1CMJMe9GQ6l/ASw7mGSxnHFC7krwznCQZRjexiX7uT6mSx94VcUGqzveQDV6tmn1VecK9Xz84z75w3bCjYduFC6Ny5TOcXi8DfHpgCHA/sAKYD84DLVLV+sI0AG/OWi+OBP8FkZkKrVlZDnjkz1qWJby+9ZPcKTjnF7lfs2e6uCu+/D3fdZbX0falbd/f7G6efbj9L8uGHdgGYMWP39c2a7X6fJCmpVKe2L+u3JNPpvouoWyOL+bdMok5yNrm5cMuU43ho6lH0av8DE/88jfq1duW/Jm1rMq8ubMnE+a2Y8XVTcrXooVBnd1zDyEtmc3D9bbs/kZpq59O6dfHf/lThl18KLgJXX13m+yHlHviDg14FXANsw9r5dwJXFA70IrJRVRsU8doBWLMQzZs377JmTZFTR7p49J//wHXXWU3w1FNjXZr49+KL0L8/nHYaTJlSEGRmzLCb4B99ZEH4z38uukmoWjVrluvQwb51lLWN5MMP2bpkFV8mH82yzFYs+67Wbl8eCleQ81pCDj0U1qwpiJF5XzhWroTf/x4eewwa7BVdrPXvnHPsFD//3MbuFTZmjLUutmplb8/ixXYP/4MPrOWpTRtrsUpN3Xvf6ek29q96dfvietllxb8ls2fbNXXu3KLPr3nzsr+dEKObu4UfwL+xi8AKoEmwrgmwYl+v9Zu7CSQz07pHnnCCD1IqT2PGqIqonn666rRpBV1nmzZVffpp+1xClJur+te/7n7vuUYNG2pxySV2f/6ss1SbNy/5fvUhh6ieeabqpZdaT96mTVXffnvv4z34oG3/zDPFl2nWLNWGDQv23aqV6i23qC5cuO8/zW++KXmM4UcfFfRbOOggG6rRq5fdqy98PnXqqH7xRanfznzEoh8/0Dj42Rz4CqgPDAOGBOuHAA/taz8e+BPI8OH2ZzltWqxLknhGjSqIOE2a2KCxchokNnq0HbZ/fxtMvWJF8ePpNm2yIRDPP2+dmJ5/3pb3HEIxd67q4Yfbfq+6quD5jz+2i8JFF+07gK9cqfrII6rz55e+HpKdba9NTrYLyPjxVs7TT7cyNW5sg8K3b9/9dRs2qH74oeqIEarXXx/50JCixCrwfwh8CSwGegbrUrD2/m+A94GG+9qPB/4EsXOnVdmOP95r+7EyebLqf/6zdzQK0bJlNhj71FNLHjxdFjt2qN58s/VsPeQQ1UmT7GfLlqoZGdE9VnGWL1c97riCa2qjRuXXk7W4wO8DuFzFMXIk/OUv8O67cMYZsS6NKwfbt1sv2/XrYdEiaNIknON89pmN+1uxwm5JfPwxHHNMOMcqSnY2PP+89Vv4859t/Fp5KK6NPwbD9pwrwq5d8O9/w3HHWU8QlxBuuAG+/NIGPocV9AG6dbNekQ89ZD1KyzPogw2QHjiwfI9ZEg/8bv+owg8/7N7vOiXFJkYpzWClF1+07hnDh+9fNwZXabz0EowaZdMn9OoV/vFq1rReo84DvyuLDRssZ87UqVZd27Kl4LnGjeHXX2HTJmu6iSSIZ2XBffdB165w1lmhFdtVHF9/bTXg7t1h6NBYlybxeOB3kdu4ER591Dopb91qw/0vv3z3ATspKVaFu/9+65j8j3/se7/jxtmw9Sef9Np+AsjMtJx01avD+PGxyROX6Pwtd/uWkWE1/Mces4yUffrYd+aiMkIC3HsvfPON5YJp3dqyThYnPd1q+0cfbSNqXLFmzoRPP7X735Em8YyVDRusjpCevvdzX39tN3LfeMPGe7kYKKqrT0V7eHfOGMnNVX3ooYIZoHr3Vl28OLLXbtumeswxqrVqWSfookyZYrNkVa1qufNdsYYPt77nYFkkb7/d+ntXRG++aYOSkpKsr/qejwMPVL333liXMjHgE7G4UsnNLUhnfM45NlyxtNats07TTZvuPnHKhg0FM0l16qS6aFG0Sh13srJsEE/ex/Dpp6p9+thyvXqqd921d3/0rCzVL79UfeUVy4T888/lU9aNG1WvuMLKdsQRqgsWlM9xXfE88LvI5eaq3nST/XkMGrR/g6kWL7Zx50cdZbnf337bLgRJSVZt3bkzasWONxkZqmecYR/DTTftPrhp0SJLuw/2hez661UvvtgCbvXqutuw/+bNI/+iVlbvvmuZNpKSVG+91T/WisIDv4tMbq7N/Qqq110XnRG0b71lQyfzphjs0MHmmHXFWrXK0g1Urao6cmTx2y1YYLlgRGyemXPOUf3nP21GyXnzLD1B06Z27X3zzeiXc+VK1auvto+1fXubJ95VHMUFfh+56wqoWo+cBx6Aa66Bp5+OXi+bp5+Gv/3NevncdRfUqBGd/VZwqnYTs3CP133Ztg1uu81Ge06eHFmC0pyc4rMW//gjXHABLFgADz9sH8P+fKyrV8Mrr9j8KvPm2dwvf/873H135FMBuPIRk7TM0eKBvxyoWrT597+t28jw4fYfHU27dpXvDFgVwMSJ1nWxtNq0sblRDjssOuXYvt163k6ebOndn356748iPX3vOUAKW7nSAv7nn9vyMccUzK9y6KHRKaeLLk/Z4Ep2550W9P/853CCPiRc0FeFYcMsiP/vf6WrZTdvHt23q1YtuwjdcYf1nv32W7j44t1z2P/yy773c/TR9oWwb1+bs95VTh74K7NffrHv1vXq7d9+hg6Fe+6BP/0Jnn02nKCfgGbNsqaQESMs+MdalSo2xKJtW7u+z5hhF4QOHWzAdN4YvIMOKvoi1bChXZBc5eeBvyJZtw4OPHDfgXftWqudP/+8zYw0a1bZR8Lcc4+1uV9xBTz3nAf9KBo2DBo1siaWiuSyy6BnT9i505po/CNPPP6RVxTTpkHTptCihd0p+/zzvSe2/uknuP56mw/u+efhj3+0htlTTrGLQWn9+9/23f+yy2x/HgGiZtkyePtt+7jKOF1qqJo2taYa/8gTk3/sFYGqBeCmTaFzZ7vz1q2b/WcOHmxj9W+80SacHjHCqpBff20Tg773niVFO/VU674RqQcfhFtvhUsugRdeiPpE1onu4YetGeWaa2JdEueKUFQfz4r2iPt+/FOnWkfo4cNteeNG64h9zjmq1arZc0lJqn/6k3Wc3tPHH1tH7cMOU/3pp30fb9gw2+cf/hD9KY+crl1rH9t118W6JC7R4f34KyhVOPFEy0X/7bd792/fuBGmT4ejjrImnuJ89BGceaa1+c+caXfoivLoo9aU1K+fZcX01IhRd/PNVuP/9lvv+eJiy7tzVlQzZtg8cE8/XfSgpgYNLBvmvpxwArzzjnXPOPVU+33jxt0nSFm2zDpjX3SRB/2QbN5srXF9+njQdxWX/+fH2tCh1rZ/1VX7v68TT7QO42efbTeJ81StaiOBjj4a/vpXm+/Og34onnvOgv/gwbEuiXPF8//+aFu/Hl591UbL1KxpM03UrVv0tjNnwuzZNrFJtMa69+hh3Tvfecc6bHfoYJ3IE2zwVCxkZdm0BSefbJOJOVdReeCPhrQ0eO01C/YffAC5uRZsV62yyUXefhvq1Nn7dXffbW3xV18d3fJ07eqRpwhZWdbunjdSNa/lq2dPmzOmUaP92/+ECdardsSI6JTXubB4d8799Y9/WPAeMMCyV91yCyxeDCtW2GzSH38M555rmbcK+/BDa9+/+eaK2dE7DqjaR3HrrdCpE9SuDYcfbukG7r7bZoE64AC7392yJQwZYtfwsh5r2DDbv08b7Co679WzP7Zuhfr1rTfNvfdadNlzrPv48XDppdYE89Zb1rkb4LTTrOq5alXBOleknTvtOlr4HnV2tgXZvDQD7dvb26hqb+vEifb4+msbotCjhyUVy9u+XbuCt/2rr2wA8/jxdnG44Qbr+BTp9IY7dsAjj8Dtt8Po0XDlleG9F86VRnG9emLeRz+SR4Xtx//ee9Yf/t13S95u3DjLR9+zp+r27aoffWSve/jh8ilnJZSbq3rLLart2hVMOZg3nKFdu70nHBGxdP+HHWbLeW/3s8+q/vprZMdctky1Xz/bV926NgfNJ5+o5uQUvf2OHapPPqnapIkd86yzVDMzo/YWOLff8H78Ibj1VhsBm5FRdBt+YS++CP37W00/Jwe++AK++86qmG4v48YV5JTp1s1q6R07WuekvF6v2dnWZl84w+TWrXD++dC7NzRuXLZjL11qX+Bef92+bRxyiPWA7dsXjj3Wsks//zzcf78Nlu7Rwzpn9egRtdN3Lio8H38Yune3IP7ZZ5FtP2aMZcBUhYce8j5/xfj5Z2vGadfOboXEKpvE5s02icrEifDuu3Zz+NBD7SNfu9Z6zw4daqmSnKuIfABXtG3fDnPn2nRGkbriCsuK9d//Wn96txdVy2+zfbu1l8cyhdABB9jtmUsvtS91U6bYRSAry9Ib9ewZvQnKnCtPHvjL6tNPLQKcfHLpXnf55eWep7fwAN4dOyxjZEXNyTZxovWMffBBq/FXFPXrW0td//6xLolz+88Df1nNnGm19+7dY12SvcyebcEzL9j/9NPuzzdvbm3gFc369XDdddb75qabYl0a5+KX9+Mvq1mzLAXCAQfEuiT5PvzQ0vT06GETaW3YYPeSH3zQepKuXGl53h56aO9U/xXBdddZu/oLL3hGCefC5P9eZbFjh02UcsMNsS4JYGPE7rzTkngeeKClDRgwoOhxYTfdBNdea8k8TzwxuuVQhQULrO9827bWtz7SsWl5WS7uvdd68DjnwuOBvyw++8z69MWo/54qfP89LFliST2nTrWui488AgMHljwe7IorbM6XYcOiE/jzRsfmDZhaubLgORGbO6Zjx4KBUx062EWhcGqi9HS7133UUZY6wTkXLg/8ZTFrlkW1E04ol8MtWQLvv1/QX/3LL62/OkBqqjXdXHNNZEMCatWyGv/dd8Py5VYrL4vvvoNRoyzYf/ON3Szu2dMyVnTtarX+wiNt33rLukGC3Rpp3brgQrBggTVLTZ0K1aqVrTzOuch5P/6yOOUUa4yePz/0Q/30k+WR2bXLavWFa84dOkCXLqXP+LB+vd3gveQSG4hUWosX272EjAx7K/r2tZvFqanFv2bnzr0vBsuW2QCs3FxrqrrrrtKXxTlXPO/HHy2ZmdaVs5wmUx03zoL+okWWCigaGjWyJp/Roy1HTZMmkb92yRKr2deqZS1ebdpE9roaNeCII+xRWGamNVtFuh/n3P7zXj2lNWeOVV9L23+/DFRh7Fg4/vjoBf08N91kwxCeeiry1yxdakE/OdkSi0YjWCcnWxoGHwjlXPnxwF9aee370e4SU4T58609P4xBQ23awO9+B888A1u27Hv7Zcusead6dQv6rVtHv0zOufIRauAXkb+JyDIRWSoi40UkWURaisjnIvKtiEwQkco1NdTMmXDkkTYXbsjGjrUmkn79wtn/4MHWTj9qVMnbLV9uQb9qVZtnxptlnKvcQgv8InIwcAPQVVU7AknAxcCDwGOq2hrYCERhstlysmuXte+XQzPPrl2WH/6CCyxdQBi6dbOOSY89Zs0+RfnqK7uBW6WKBf22bcMpi3Ou/ITd1FMVqCkiVYFawDrgVGBS8PxY4MKQyxA9c+fa4K1y6L//v/9Z//awc8MMHmw3V195pWDdzp3w5puWFvmYY2zdBx9UrNw5zrmyC61Xj6r+KCIPA98DO4CpwHwgQ1Wzg83WAgeHVYaomznTfpZD+/7YsTaj4+mnh3ucc8+1gD5smH2zmDDB8tBv3mytWf362aCqww4LtxzOufITWuAXkQbABUBLIAN4BTizFK8fAAwAaN68eQglLINZs6w/Ykkd1qNg/Xqr8Q8aFH7OmipVbJrBq6+2eeHr1bM++X37Wg+e6pXrDoxzLgJhhpXTgO9UdT2AiLwKdAfqi0jVoNbfDPixqBer6khgJNgArhDLGZmsLEuK86c/hX6o8eNtdqnySgF8+eU2yfgRR0CvXh7snYt3YQb+74FuIlILa+rpCcwDZgB9gJeB/sCUEMsQPfPm2ewg5dC+P3as5a3Zc7BTWKpXhyFDyudYzrnYC+3mrqp+jt3EXQB8ERxrJHAzcJOIfAukAPvoTFhBzJplP086KdTDLF1quWt8wg/nXFhCbUFW1TuBO/dYvQo4NszjhmLWLJsItqwzeEdo7Fhr1//jH0M9jHMugfnI3UhkZloC+5CbebKzLTfP2WdbPh3nnAuDB/5IDB1qeZD79g31MNOmwc8/ezOPcy5cHvj3Zd486+R+5ZWhj9gdOxYaNrRulc45FxYP/CXZudMC/oEHwqOPhnaY7GybhOT1161tv0aN0A7lnHOej79E991n3WzefLPYhDmvv26tQOefX7p517OzYfZsGyn76qvWj75Bg3JL8++cS2Ae+IuzaBHcfz9ceqnlNSjCnDnw+9/bDFI1asCZZ9ptgPPOg7p1d982M9MSni1bZuPAJk+GX3+16RLPO89SI5xxRuSTkzvnXFl54C9KVpY18aSkwBNPFLlJXitQ06YwZozNKfvKKzBlik0ucvbZlgPnyy8t2K9caRcIsOB+7rkW7M86q/RTJzrn3P7wwF+UBx+0Gv+rr9rd1iLcc48F9bfftpw2PXvCI49Y1uaJEwsuAq1b2wjciy+Gjh1tntw2bTwtgnMudnyy9T0tXQpHH22Zyl5+uchNFiyAY4+1VqAxY4reTW6uteN7gHfOxUpxk617r57CsrOt/aZ+/WIno921yzZp3NgmMClOlSoe9J1zFZM39RT24ovWb//ll4sdOvvAA7BkiTXjlMPsi845F3Xe1JMnN9ca4atXh4ULbUL1PXzxBXTpAn36wH//G25xnHNufxXX1OM1/jzvvGOzir/4YpFBP68VqEEDePLJGJTPOeeixAN/nmHD4JBD2NCrH9vX7v30qFEwf7711gl5Ai7nnAuVB36wSdRnzWLKla/Tp1k1srOL3qxPH3s451xl5oEfYNgwth9wENdPO4+2beHGG/fepEYN6+HpnHOV3T4Dv4icB/xPVXPLoTzlb9UqmDyZ+4+byg+fVmH2f+HEE2NdKOecC08k/fj7Ad+IyEMi0i7sApW7Rx/l2yqH8dD8U7nkEg/6zrn4t8/Ar6qXAkcBK4ExIvKpiAwQkbr7eGnFl5YGo0dz40EvU7268NBDsS6Qc86FL6KRu6q6GZs4/WWgCfA7YIGIXB9i2cI3fDhv7TiV/63txJ13WsI155yLd5G08Z8PXAm0Bv4POFZVfxWRWsCXQNG5DSq6HTvIfOo5BtWaQ/tDYdCgWBfIOefKRyS9en4PPKaqswuvVNXtInJVOMUqB2PH8nBaf1bRhGlPQrVqsS6Qc86Vj0gC/13AurwFEakJHKiqq1V1elgFC1VODmseGM+/q7xHn97KaaftPVLXOefiVSRt/K8Ahbty5gTrKq833+Tva66HqlV55BEP+s65xBJJ4K+qqrvyFoLfK3XC4RkT1zOZPtx6WxWaN491aZxzrnxFEvjXBzd4ARCRC4C08IoUvve+OpRq7OLvg306Audc4omkjX8g8JKIPA0I8ANweailCln6lmqkJm0kOfnAWBfFOefK3T4Dv6quBLqJSJ1geWvopQpZ2tZkUqttAjzwO+cST0RJ2kTkHKADkCxBrnpVvTvEcoUqbXttUmtU+uuXc86VyT4buUVkBJav53qsqeci4NCQyxWqtJ11Sa21PdbFcM65mIjk7uZvVfVyYKOqDgWOBw4Lt1jhSs86gJTambEuhnPOxUQkgT8vQm4XkaZAFpavp1LKzYX03Pqk1tu1742dcy4ORdLG/6aI1AeGAQsABZ4Ls1BhysiAXJJIrZ8T66I451xMlBj4RaQKMF1VM4DJIvIWkKyqm8qjcGFI+3EnUIPUhvE5r4xzzu1LiU09waxb/ym0vLMyB32A9O+3AZDSyAdvOecSUyTRb7qI/F7y+nFWcmlr7ZZFamMP/M65xBRJ9PsLlpRtp4hsFpEtIrI55HKFJu0nu6mb2sTzMDvnElMkI3cr/xSLhaT9nA1A6iE1Y1wS55yLjUhm4DqpqPV7TsxSxOvaAhMKrfoNcAc2i9cEoAWwGuirqhsjK+7+S09TqrOT2o1rl9chnXOuQomkO+fgQr8nA8cC84FTS3qRqq4AOgOISBLwI/AaMATrKfSAiAwJlm8udcnLKC0NUklD6h1QXod0zrkKJZKmnvMKL4vIIcDjpTxOT2Clqq4J0jqfHKwfC8ykPAP/xiRSSYN6PrO6cy4xlaVry1qgfSlfczEwPvj9QFXNm8rxZ8o5RWba5moW+A/wGr9zLjFF0sb/FDZaF+xC0RkbwRsREakOnA/csudzqqoionu/CkRkADAAoHkUp8lK31KDI6pshBo1orZP55yrTCJp459X6PdsYLyqflyKY5wFLFDVX4LlX0SkiaquE5EmwK9FvUhVRwIjAbp27VrkxaEs0rbXJLX6lmjtzjnnKp1IAv8kIFNVc8Bu1IpILVWNNK/xHyho5gF4A+gPPBD8nFKK8u6XnBzYsLM2qfU9F79zLnFFNHIXKNzpvSbwfiQ7F5HaQC/g1UKrHwB6icg3wGnBcrnIyIBcrUJKLU/J7JxLXJHU+JMLT7eoqltFpFYkO1fVbUDKHuvSsV4+5S493X6mHuApmZ1ziSuSGv82ETk6b0FEugA7witSeNLS7GdqvazYFsQ552Iokhr/jcArIvITNvXiQdhUjJVOfuBv4Ln4nXOJK5IBXHNFpB3QNli1QlUrZZU5L/CnpMZFolHnnCuTSCZbvxaorapLVXUpUEdErgm/aNGXnma9Qj0ls3MukUUSAa8OZuACIEiodnVoJQpR2s/Z1CCT2inJsS6Kc87FTCSBP6nwJCxBwrXq4RUpPGk/Z1mCtvr1Yl0U55yLmUhu7r4LTBCRZ4PlvwDvhFek8KT9kksK6Z6nxzmX0CIJ/DdjOXMGBstLsJ49lU56unqCNudcwttnU08w4frn2KQpx2J5+JeHW6xwpG2oEqRk9qYe51ziKrbGLyKHYXl2/gCkEcympaqnlE/Roi8to2pQ42+7742dcy5OldTU8xXwIXCuqn4LICJ/K5dShSAnBzZsrW5t/F7jd84lsJKaenoD64AZIvKciPTERu5WShkZoCrexu+cS3jFBn5VfV1VLwbaATOw1A2NReQZETm9nMoXNfnpGjzwO+cSXCQ3d7ep6n+DuXebAQspxzlyoyU/8FffAtWqxbYwzjkXQ6XKXaCqG1V1pKrGJK3y/sjP01NnZ2wL4pxzMZYwSWs8F79zzpmECfyektk550xCBf7kKjupVb9SphlyzrmoSajAn1IlA6nnPXqcc4ktYQJ/ejqkiqdrcM65hAn8aWmQquu9D79zLuElUOBXUrJ/9cDvnEt4iRP410Mq672pxzmX8BIi8OfkwMYMT9fgnHOQIIF/40ZP0Oacc3kSIvDnp2vwlMzOOZdYgd9r/M45lyCBPz9Pjwd+55xLjMC/W43fm3qccwkuoQJ/Cule43fOJbyECfzJVbOoxXaoWzfWxXHOuZgqabL1uJGeDqnJ2xCtDVUT4pSdc65YCREF09IgtcZmqO7NPM45lzBNPSlJm7x93znnSKDAn1rFB2855xwkSOBPT4dU9T78zjkHCRD4s7MtV09qrqdkds45SIDAbwnaICVrnTf1OOccIQd+EakvIpNE5CsRWS4ix4tIQxGZJiLfBD8bhFmG/FG7O3/0Gr9zzhF+jf8J4F1VbQd0ApYDQ4DpqtoGmB4shyY/T8+OtR74nXOOEAO/iNQDTgJGAajqLlXNAC4AxgabjQUuDKsMUDhPj8++5ZxzEG6NvyWwHnhBRBaKyPMiUhs4UFXXBdv8DBxY1ItFZICIzBOReevXry9zITxPj3PO7S7MwF8VOBp4RlWPAraxR7OOqiqgRb1YVUeqaldV7dqoUaMyF2K3lMxe43fOuVAD/1pgrap+HixPwi4Ev4hIE4Dg568hloG0NKhZI4da7PAav3POEWLgV9WfgR9EpG2wqifwJfAG0D9Y1x+YElYZIBi1e8AuW/DA75xzoSdpux54SUSqA6uAK7GLzUQRuQpYA/QNswBpaZBSO9PuNnhTj3POhRv4VXUR0LWIp3qGedzC0tMhteZ2W/Aav3POxf/IXUvJvMUWPPA751xiBP6UapttwWffcs65+A78+QnaqmywoF8lrk/XOeciEteRcONG+5kqPnjLOefyxHXgz0/XoL96jx7nnAskROBPyfrFa/zOORdIiMCfuusnD/zOOReI68Cfn6cnc6039TjnXCCuA39+U8/WNV7jd865QNwH/po1odZWn2/XOefyxH3gT01V2LrVm3qccy4Q14E/PR1SG+TYgtf4nXMOCD87Z0wNGgTbVm+Eq/HA75xzgbgO/KedBiz9xRa8qce5mMnKymLt2rVkZmbGuihxKTk5mWbNmlGtWrWIto/rwA/Apk3202v8zsXM2rVrqVu3Li1atEBEYl2cuKKqpKens3btWlq2bBnRa+K6jR+AzUFmTg/8zsVMZmYmKSkpHvRDICKkpKSU6ttU4gR+b+pxLqY86IentO9t/Ad+b+pxzrndxH/g96Ye51wpzJw5k08++SR/ecSIEfzf//1fDEsUfYlxc1cE6tSJdUmcc5XAzJkzqVOnDr/97W8BGDhwYIxLFH3xH/g3b7bavrcvOlcx3HgjLFoU3X127gyPP17iJhdeeCE//PADmZmZDBo0iAEDBvDuu+/yr3/9i5ycHFJTUxk1ahQjRowgKSmJcePG8dRTTzF9+nTq1KnDueeey+WXX86cOXMAWL16Needdx5ffPEF8+fP56abbmLr1q2kpqYyZswYmjRpEt1zjKLECfzOuYQ2evRoGjZsyI4dOzjmmGO44IILuPrqq5k9ezYtW7Zkw4YNNGzYkIEDB1KnTh3+8Y9/ADB9+nQA2rVrx65du/juu+9o2bIlEyZMoF+/fmRlZXH99dczZcoUGjVqxIQJE7j11lsZPXp0LE+3RPEf+Ddt8h49zlUk+6iZh+XJJ5/ktddeA+CHH35g5MiRnHTSSfl93xs2bLjPffTt25cJEyYwZMgQJkyYwIQJE1ixYgVLly6lV69eAOTk5FTo2j4kQuD3Gr9zCW/mzJm8//77fPrpp9SqVYuTTz6Zzp0789VXX5VqP/369eOiiy6id+/eiAht2rThiy++oEOHDnz66achlT76EqNXj9f4nUtomzZtokGDBtSqVYuvvvqKzz77jMzMTGbPns13330HwIYNGwCoW7cuW7ZsKXI/rVq1IikpiXvuuYd+/foB0LZtW9avX58f+LOysli2bFk5nFXZxX/g37TJa/zOJbgzzzyT7Oxs2rdvz5AhQ+jWrRuNGjVi5MiR9O7dm06dOuUH8vPOO4/XXnuNzp078+GHH+61r379+jFu3Dj69u0LQPXq1Zk0aRI333wznTp1onPnzrt1B62IRFVjXYZ96tq1q86bN69sL27SBM47D0aOjG6hnHMRW758Oe3bt491MeJaUe+xiMxX1a57bhv/NX5v6nHOud3Ed+DPyoLt272pxznnConvwJ93g8YDv3PO5YvvwO+ZOZ1zbi/xHfg9M6dzzu0lvgO/Z+Z0zrm9JEbg96Ye51wFkJGRwfDhw/OXf/rpJ/r06VPu5YjvwO9NPc65CmTPwN+0aVMmTZpU7uWI71w93tTjXIUTo6zMrF69mrPOOosTTjiBTz75hIMPPpgpU6awYsUKBg4cyPbt22nVqhWjR4+mQYMGnHzyyRx33HHMmDGDjIwMRo0axYknnrjXfp977jlGjhzJrl27aN26NS+++CK1atXil19+YeDAgaxatQqAZ555hieffJKVK1fSuXNnevXqxbXXXsu5557L0qVL6datG6NGjaJDhw4AnHzyyTz88MO0b9+e66+/nqVLl5KVlcVdd93FBRdcsF/vV3zX+L2pxzlXyDfffMO1117LsmXLqF+/PpMnT+byyy/nwQcfZMmSJRxxxBEMHTo0f/vs7GzmzJnD448/vtv6wnr37s3cuXNZvHgx7du3Z9SoUQDccMMN9OjRg8WLF7NgwQI6dOjAAw88QKtWrVi0aBHDhg3bbT/9+vVj4sSJAKxbt45169bRtWtX7rvvPk499VTmzJnDjBkzGDx4MNu2bduv9yG+a/ybNkFSEtSsGeuSOOcCMcrKDEDLli3p3LkzAF26dGHlypVkZGTQo0cPAPr3789FF12Uv33v3r3zt129enWR+1y6dCm33XYbGRkZbN26lTPOOAOADz74IH/KxqSkJOrVq8fGjRuLLVvfvn05/fTTGTp0KBMnTsxv+586dSpvvPEGDz/8MACZmZl8//33+5UCI9TALyKrgS1ADpCtql1FpCEwAWgBrAb6qmrx78b+8Nm3nHOF1KhRI//3pKQkMjIyIto+KSmJ7OxsAK688koWLlxI06ZNefvtt7niiit4/fXX6dSpE2PGjGHmzJllKtvBBx9MSkoKS5YsYcKECYwYMQIAVWXy5Mm0bdu2TPstSnk09Zyiqp0LJQoaAkxX1TbA9GA5HJ6nxzlXgnr16tGgQYP8LJwvvvhifu2/OC+88AKLFi3i7bffBmDLli00adKErKwsXnrppfztevbsyTPPPAPY5CybNm0qMeUzWHPPQw89xKZNmzjyyCMBOOOMM3jqqafIS6i5cOHCsp9wIBZt/BcAY4PfxwIXhnYkT8nsnNuHsWPHMnjwYI488kgWLVrEHXfcUarX33PPPRx33HF0796ddu3a5a9/4oknmDFjBkcccQRdunThyy+/JCUlhe7du9OxY0cGDx6817769OnDyy+/nJ/yGeD2228nKyuLI488kg4dOnD77beX/WQDoaZlFpHvgI2AAs+q6kgRyVDV+sHzAmzMW97jtQOAAQDNmzfvsmbNmtIX4P77Lfg/8ECZz8E5t/88LXP4SpOWOeybuyeo6o8i0hiYJiK7zXOmqioiRV55VHUkMBIsH3+Zjn7LLWV6mXPOxbNQm3pU9cfg56/Aa8CxwC8i0gQg+PlrmGVwzjm3u9ACv4jUFpG6eb8DpwNLgTeA/sFm/YEpYZXBOVdxVIbZ/iqr0r63YTb1HAi8Zs34VAX+q6rvishcYKKIXAWsAfqWsA/nXBxITk4mPT2dlJQUxLtXR5Wqkp6eTnJycsSvCS3wq+oqoFMR69OBnmEd1zlX8TRr1oy1a9eyfv36WBclLiUnJ9OsWbOIt4/vkbvOuQqhWrVqtGzZMtbFcIH4ztXjnHNuLx74nXMuwXjgd865BBPqyN1oEZH1WA+gkqQCaeVQnIrGzzux+Hknlv0970NVtdGeKytF4I+EiMwramhyvPPzTix+3oklrPP2ph7nnEswHvidcy7BxFPgHxnrAsSIn3di8fNOLKGcd9y08TvnnItMPNX4nXPORcADv3POJZhKH/hF5EwRWSEi34pIePP3xoiIjBaRX0VkaaF1DUVkmoh8E/xsEKwXEXkyeC+WiMjRsSt52YnIISIyQ0S+FJFlIjIoWB/X5w0gIskiMkdEFgfnPjRY31JEPg/OcYKIVA/W1wiWvw2ebxHTE9gPIpIkIgtF5K1gOe7PGUBEVovIFyKySETmBetC/Vuv1IFfRJKA/wBnAYcDfxCRw2NbqqgbA5y5x7riJqw/C2gTPAYAz5RTGaMtG/i7qh4OdAOuDT7XeD9vgJ3AqaraCegMnCki3YAHgcdUtTU2nelVwfZXYdOXtgYeC7arrAYBywstJ8I55zlFVTsX6rMf7t+6qlbaB3A88F6h5VuAW2JdrhDOswWwtNDyCqBJ8HsTYEXw+7PAH4rarjI/sMl6eiXgedcCFgDHYaM3qwbr8//ugfeA44PfqwbbSazLXoZzbRYEuFOBtwCJ93MudO6rgdQ91oX6t16pa/zAwcAPhZbXBuvi3YGqui74/Wds0huIw/cj+Bp/FPA5CXLeQZPHImxa0mnASiBDVbODTQqfX/65B89vAlLKtcDR8TjwTyA3WE4h/s85jwJTRWS+iAwI1oX6t+75+Cs51eInrK/sRKQOMBm4UVU3F565KZ7PW1VzgM4iUh+bq7pdbEsULhE5F/hVVeeLyMkxLk4snKCqP4pIY2CaiHxV+Mkw/tYre43/R+CQQsvNgnXxrrgJ6+Pm/RCRaljQf0lVXw1Wx/15F6aqGcAMrJmjvojkVdQKn1/+uQfP1wPSy7ek+607cL6IrAZexpp7niC+zzmfqv4Y/PwVu9AfS8h/65U98M8F2gR3/6sDF2OTuce74iasfwO4PLjz3w3YVOjrYqUhVrUfBSxX1UcLPRXX5w0gIo2Cmj4iUhO7t7EcuwD0CTbb89zz3pM+wAcaNP5WFqp6i6o2U9UW2P/wB6p6CXF8znlEpLaI1M37HTgdWErYf+uxvrERhRsjZwNfY+2gt8a6PCGc33hgHZCFteddhbVnTge+Ad4HGgbbCtbLaSXwBdA11uUv4zmfgLV7LgEWBY+z4/28g3M5ElgYnPtS4I5g/W+AOcC3wCtAjWB9crD8bfD8b2J9Dvt5/icDbyXKOQfnuDh4LMuLYWH/rXvKBuecSzCVvanHOedcKXngd865BOOB3znnEowHfuecSzAe+J1zLsF44HdxQ0RuDTJaLgkyHR4X8vFmikjEE2GLSLcgm+QiEVkuIncF68+XOMws6youT9ng4oKIHA+cCxytqjtFJBWoHuNi7Wks0FdVFweZZdsCqOobJMbAQ1dBeI3fxYsmQJqq7gRQ1TRV/QlARO4QkbkislRERgYjg/Nq7I+JyLygBn6MiLwa5EC/N9imhYh8JSIvBdtMEpFaex5cRE4XkU9FZIGIvBLkGdpTY2wwHqqao6pfBq+9QkSeDn5fVOixQ0R6BKM7R4vl6V8oIheE8P65BOKB38WLqcAhIvK1iAwXkR6FnntaVY9R1Y5ATeybQZ5dajnQR2DD4q8FOgJXiEhexse2wHBVbQ9sBq4pfODg28VtwGmqejQwD7ipiDI+BqwQkddE5C8ikrznBmo52TsDtwf7+QS4FUtLcCxwCjAsGN7vXJl44HdxQVW3Al2wySnWAxNE5Irg6VOCtvUvsARgHQq9NK+J5QtgmaquC741rKIgGdYPqvpx8Ps4LKVEYd2wiYA+DtIp9wcOLaKMdwNdsYvUH4F3izoXEWkDDMOahbKw/C1Dgn3PxFIWNC/h7XCuRN7G7+KGWjrjmcDMIMj3F5GXgeFYTpMfghuqhWvaO4OfuYV+z1vO+//YM6/JnssCTFPVP0RQxpXAMyLyHLC+0LcK25E1EU0ErtaC5FsC/F5VV+xr/85Fwmv8Li6ISNugppynM7CGgiCfFgTVPnu+NgLNg5vHYDX1j/Z4/jOgu4i0DspSW0QOK6KM5+TdX8CmzssBMvbYbDTwgqp+WGjde8D1he5NHFWGc3Aun9f4XbyoAzwVpDTOxjI3DlDVjKB2vRSbyWhuGfa9Apv3dzTwJXvMc6qq64NmpfEiUiNYfRuWNbawy4DHRGR7UMZLVDUn71ogIodiF6bDRORPwWv+DNyDzVC1RESqAN+x+30K50rFs3M6VwKxqR/fCm4MOxcXvKnHOecSjNf4nXMuwXiN3znnEowHfuecSzAe+J1zLsF44HfOuQTjgd855xLM/wMm+O1orb/uZQAAAABJRU5ErkJggg=="
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "metadata": {}
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyMfqalTRwiWuiIELJDbCQ7d",
      "mount_file_id": "1SZapm_bYNJDCJi8ECwmjrzaN8-1ruRgA",
      "name": "Logistic.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "a2ef89d34cbfddaf50816f8d91581a3ca0913b9280767ed31a38c2db7dcc022c"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.2 64-bit ('ML-for-COVID-19-dataset': venv)"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "metadata": {
      "interpreter": {
        "hash": "5edc29c2ed010d6458d71a83433b383a96a8cbd3efe8531bc90c4b8a5b8bcec9"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}