{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ioi13nGDPDvQ",
        "outputId": "4763f7b3-6c5b-45cb-f411-fd7c6ea8b38f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Automatically created module for IPython interactive environment\n"
          ]
        }
      ],
      "source": [
        "print(__doc__)\n",
        "\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.utils import check_random_state\n",
        "from sklearn.impute import IterativeImputer\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "\n",
        "from sklearn import linear_model\n",
        "from sklearn import neighbors\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.utils import check_random_state\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from sklearn import metrics\n",
        "\n",
        "# pd.options.display.max_rows = 20\n",
        "pd.options.display.float_format = \"{:.1f}\".format\n",
        "\n",
        "max_queried = 500\n",
        "trainset_size = 1302"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {},
      "outputs": [],
      "source": [
        "def data_prep():\n",
        "    data = pd.read_csv(\"https://raw.githubusercontent.com/WenxuanHuang/ML-for-COVID-19-dataset/main/all_training.csv\", sep=',')\n",
        "    # Column selection\n",
        "    df = data.iloc[:,np.r_[3:34]].copy()\n",
        "    # define row and column index\n",
        "    col = df.columns\n",
        "    row = [i for i in range(df.shape[0])]\n",
        "    # define imputer\n",
        "    imputer = IterativeImputer(estimator=linear_model.BayesianRidge(), n_nearest_features=None, imputation_order='ascending')\n",
        "    # fit on the dataset\n",
        "    imputer.fit(df)\n",
        "    # transform the dataset\n",
        "    df_imputed = imputer.transform(df)\n",
        "    # convert back to pandas dataframe and rename back to df_normalized\n",
        "    df = pd.DataFrame(data=df_imputed, index=row, columns=col)\n",
        "    X = df\n",
        "    y = data.target    \n",
        "    # Recursive feature elimination\n",
        "    rdmreg = RandomForestClassifier(n_estimators=100)\n",
        "    # Define the method\n",
        "    rfe = RFE(estimator=rdmreg, n_features_to_select=10)\n",
        "    # Fit the model\n",
        "    rfe = rfe.fit(X, y.values.ravel())\n",
        "    print(rfe.support_)\n",
        "    # Drop columns that failed RFE test\n",
        "    col = df.columns[rfe.support_]\n",
        "    X = X[col]\n",
        "    X = X.to_numpy()\n",
        "    print ('df:', X.shape, y.shape)\n",
        "    return (X, y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {},
      "outputs": [],
      "source": [
        "class BaseModel(object):\n",
        "\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def fit_predict(self):\n",
        "        pass\n",
        "\n",
        "\n",
        "class SvmModel(BaseModel):\n",
        "\n",
        "    model_type = 'Support Vector Machine with linear Kernel'\n",
        "    def fit_predict(self, X_train, y_train, X_val, X_test, c_weight):\n",
        "        print ('training svm...')\n",
        "        self.classifier = SVC(\n",
        "            C=1, \n",
        "            kernel='linear', \n",
        "            probability=True,\n",
        "            class_weight=c_weight\n",
        "            )\n",
        "        self.classifier.fit(X_train, y_train)\n",
        "        self.test_y_predicted = self.classifier.predict(X_test)\n",
        "        self.val_y_predicted = self.classifier.predict(X_val)\n",
        "        return (X_train, X_val, X_test, self.val_y_predicted,\n",
        "                self.test_y_predicted)\n",
        "\n",
        "class LogModel(BaseModel):\n",
        "\n",
        "    model_type = 'Logistic Regression' \n",
        "    def fit_predict(self, X_train, y_train, X_val, X_test, c_weight):\n",
        "        print ('training logistic regression...')\n",
        "        # train_samples = X_train.shape[0]\n",
        "        self.classifier = LogisticRegression(\n",
        "            # C=50. / train_samples,\n",
        "            penalty='l1',\n",
        "            solver='liblinear',\n",
        "            tol=0.1,\n",
        "            class_weight=c_weight\n",
        "            )\n",
        "        self.classifier.fit(X_train, y_train)\n",
        "        self.test_y_predicted = self.classifier.predict(X_test)\n",
        "        self.val_y_predicted = self.classifier.predict(X_val)\n",
        "        return (X_train, X_val, X_test, self.val_y_predicted,\n",
        "                self.test_y_predicted)\n",
        "\n",
        "class RfModel(BaseModel):\n",
        "\n",
        "    model_type = 'Random Forest'\n",
        "    def fit_predict(self, X_train, y_train, X_val, X_test, c_weight):\n",
        "        print ('training random forest...')\n",
        "        self.classifier = RandomForestClassifier(\n",
        "            n_estimators=500, \n",
        "            class_weight=c_weight, \n",
        "            n_jobs=-1\n",
        "            )\n",
        "        self.classifier.fit(X_train, y_train)\n",
        "        self.test_y_predicted = self.classifier.predict(X_test)\n",
        "        self.val_y_predicted = self.classifier.predict(X_val)\n",
        "        return (X_train, X_val, X_test, self.val_y_predicted, self.test_y_predicted)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {},
      "outputs": [],
      "source": [
        "class TrainModel:\n",
        "\n",
        "    def __init__(self, model_object):        \n",
        "        self.accuracies = []\n",
        "        self.model_object = model_object()        \n",
        "\n",
        "    def print_model_type(self):\n",
        "        print (self.model_object.model_type)\n",
        "\n",
        "    # we train normally and use the probabilities to select the most uncertain samples\n",
        "    def train(self, X_train, y_train, X_val, X_test, c_weight):\n",
        "        print ('Train set:', X_train.shape)\n",
        "        print ('Validation set:', X_val.shape)\n",
        "        print ('Test set:', X_test.shape)\n",
        "        t0 = time.time()\n",
        "        (X_train, X_val, X_test, self.val_y_predicted,\n",
        "         self.test_y_predicted) = \\\n",
        "            self.model_object.fit_predict(X_train, y_train, X_val, X_test, c_weight)\n",
        "        self.run_time = time.time() - t0\n",
        "        return (X_train, X_val, X_test)\n",
        "\n",
        "    # we want accuracy only for the test set\n",
        "    def get_test_accuracy(self, i, y_test):\n",
        "        classif_rate = np.mean(self.test_y_predicted.ravel() == y_test.ravel()) * 100\n",
        "        self.accuracies.append(classif_rate)               \n",
        "        print('--------------------------------')\n",
        "        print('Iteration:',i)\n",
        "        # print('--------------------------------')\n",
        "        print('y-test set:',y_test.shape)\n",
        "        # print('Training run in %.3f s' % self.run_time,'\\n')\n",
        "        print(\"Accuracy rate is %f \" % (classif_rate))    \n",
        "        # print(\"Classification report for %s:\\n%s\\n\" % (self.model_object.classifier, metrics.classification_report(y_test, self.test_y_predicted)))\n",
        "        # print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(y_test, self.test_y_predicted))\n",
        "        print('--------------------------------')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Normalize(object):\n",
        "    \n",
        "    def normalize(self, X_train, X_val, X_test):\n",
        "        self.scaler = RobustScaler()\n",
        "        X_train = self.scaler.fit_transform(X_train)\n",
        "        X_val   = self.scaler.transform(X_val)\n",
        "        X_test  = self.scaler.transform(X_test)\n",
        "        return (X_train, X_val, X_test) \n",
        "    \n",
        "    def inverse(self, X_train, X_val, X_test):\n",
        "        X_train = self.scaler.inverse_transform(X_train)\n",
        "        X_val   = self.scaler.inverse_transform(X_val)\n",
        "        X_test  = self.scaler.inverse_transform(X_test)\n",
        "        return (X_train, X_val, X_test) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_random_samples(initial_samples, X_train_full, y_train_full):\n",
        "\n",
        "    permutation = np.random.choice(len(X_train_full),initial_samples,replace=False)\n",
        "    X_train = X_train_full[permutation]\n",
        "    y_train = y_train_full[permutation]\n",
        "    X_train = X_train.reshape((X_train.shape[0], -1))\n",
        "\n",
        "    return (permutation, X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "metadata": {},
      "outputs": [],
      "source": [
        "def log_loss(probs):\n",
        "\n",
        "    loss = 0\n",
        "    for i in range(len(probs)):\n",
        "        for prob in probs[i]:\n",
        "            if prob in [0,1]:\n",
        "                loss -= 0\n",
        "            else:\n",
        "                loss -= (prob*np.log(prob))\n",
        "    ll = loss/(len(probs)*1.)\n",
        "\n",
        "    return ll"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {},
      "outputs": [],
      "source": [
        "class TheAlgorithm(object):\n",
        "\n",
        "    accuracies = []\n",
        "\n",
        "    def __init__(self, step, model_object, selection_function):\n",
        "        self.step = step\n",
        "        self.model_object = model_object\n",
        "        self.sample_selection_function = selection_function\n",
        "        \n",
        "    def run(self, X_train_full, y_train_full, X_test, y_test, initial_queried, max_queried):\n",
        "\n",
        "        (permutation, X_train, y_train) = get_random_samples(initial_queried, X_train_full, y_train_full)\n",
        "        self.queried = initial_queried\n",
        "\n",
        "        X_val = np.array([])\n",
        "        y_val = np.array([])\n",
        "        X_val = np.copy(X_train_full)\n",
        "        X_val = np.delete(X_val, permutation, axis=0)\n",
        "        y_val = np.copy(y_train_full)\n",
        "        y_val = np.delete(y_val, permutation, axis=0)\n",
        "\n",
        "        normalizer = Normalize()\n",
        "        X_train, X_val, X_test = normalizer.normalize(X_train, X_val, X_test)\n",
        "           \n",
        "        self.clf_model = TrainModel(self.model_object)\n",
        "        (X_train, X_val, X_test) = self.clf_model.train(X_train, y_train, X_val, X_test, 'balanced')\n",
        "        active_iteration = 1\n",
        "        self.clf_model.get_test_accuracy(1, y_test)\n",
        "\n",
        "        while self.queried <= max_queried-self.step:\n",
        "\n",
        "            active_iteration += 1\n",
        "            self.queried += self.step\n",
        "            (mc_permutation, X_subset, y_subset) = \\\n",
        "                get_random_samples(200, X_val, y_val) # 100 is the subset size\n",
        "            # print('Indexes in the subset for X_val:', mc_permutation)\n",
        "            # print ('Subset:', X_subset.shape, y_subset.shape, monte_carlo_permutation.shape)\n",
        "            # print ('Train:', X_train.shape, y_train.shape, permutation.shape)\n",
        "\n",
        "            cand_probs = self.clf_model.model_object.classifier.predict_proba(X_subset)\n",
        "\n",
        "            utils = []\n",
        "\n",
        "            for i in range(len(X_subset)):\n",
        "                new_train_X = X_train\n",
        "                row_subset = X_subset[i]\n",
        "                new_train_X = np.append(new_train_X, [row_subset], axis=0)\n",
        "                util = 0\n",
        "                for c in [0, 1]:\n",
        "                    new_train_y = y_train\n",
        "                    new_train_y = np.append(new_train_y, c)\n",
        "                    # print('Monte_carlo training set X:', new_train_X)\n",
        "                    # print('Monte_carlo training set y:', new_train_y)\n",
        "                    new_classifier = LogisticRegression(\n",
        "                        penalty='l1',\n",
        "                        solver='liblinear',\n",
        "                        tol=0.1,\n",
        "                        class_weight='balanced')\n",
        "                    new_classifier.fit(new_train_X, new_train_y)\n",
        "                    new_probs = self.clf_model.model_object.classifier.predict_proba(X_subset)\n",
        "                    # print('Probabilities subset:', new_probs)\n",
        "                    util += cand_probs[i][c] * log_loss(new_probs)\n",
        "\n",
        "                utils.append(util)\n",
        "\n",
        "            uis = np.argsort(utils)\n",
        "            # print ('Monte-carlo selected indexes:', uis)\n",
        "  \n",
        "\n",
        "            X_uncertain = [X_subset[i] for i in uis[:self.step]]\n",
        "            y_uncertain = [y_subset[i] for i in uis[:self.step]]\n",
        "            uncertain_samples = mc_permutation[uis[:self.step]]\n",
        "            print ('Monte-carlo selected indexes:', uncertain_samples)\n",
        "            # print ('Monte-carlo selected samples:', X_uncertain)\n",
        "            # print ('Monte-carlo selected outcomes:', y_uncertain)\n",
        "\n",
        "            X_train, X_val, X_test = normalizer.inverse(X_train, X_val, X_test)   \n",
        "            X_train = np.concatenate((X_train, np.array(X_uncertain)))\n",
        "            y_train = np.concatenate((y_train, np.array(y_uncertain)))\n",
        "\n",
        "            X_val = np.delete(X_val, uncertain_samples, axis=0)\n",
        "            y_val = np.delete(y_val, uncertain_samples, axis=0)\n",
        "\n",
        "            normalizer = Normalize()\n",
        "            X_train, X_val, X_test = normalizer.normalize(X_train, X_val, X_test)               \n",
        "\n",
        "            (X_train, X_val, X_test) = self.clf_model.train(X_train, y_train, X_val, X_test, 'balanced')\n",
        "            self.clf_model.get_test_accuracy(active_iteration, y_test)\n",
        "\n",
        "        return self.clf_model.accuracies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "metadata": {},
      "outputs": [],
      "source": [
        "def pool_experiment(model,sampling_method,max_queried,initial_queried,step):\n",
        "\n",
        "    (X, y) = data_prep()\n",
        "    kf = KFold(n_splits=4)\n",
        "    for train_index, test_index in kf.split(X):\n",
        "        X_train_full, X_test = X[train_index], X[test_index]\n",
        "        y_train_full, y_test = y[train_index], y[test_index]\n",
        "        \n",
        "    act_alg = TheAlgorithm(step, model , sampling_method)\n",
        "    accuracies = act_alg.run(X_train_full,y_train_full,X_test,y_test,initial_queried,max_queried)\n",
        "\n",
        "    (permutation, X_train_selected, y_train_selected) = get_random_samples(initial_queried, X_train_full, y_train_full)\n",
        "    original_accuracies=[]\n",
        "    classifier_original = LogisticRegression(\n",
        "            penalty='l1',\n",
        "            solver='liblinear',\n",
        "            tol=0.1,\n",
        "            class_weight='balanced')\n",
        "    x_axis = []\n",
        "    for i in range(initial_queried-1,max_queried,step):\n",
        "        classifier_original.fit(X_train_selected[:i+1], y_train_selected[:i+1])\n",
        "        y_pred_original = classifier_original.predict(X_test)\n",
        "        original_accuracies.append(accuracy_score(y_test, y_pred_original)*100)\n",
        "        x_axis.append(i+1)\n",
        "\n",
        "    plt.plot(x_axis, accuracies, 'r',label='active') \n",
        "    plt.plot(x_axis, original_accuracies, 'blue',label='non-active') \n",
        "    plt.legend()\n",
        "    plt.xlabel('Sample Size')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ True False False False False False  True False  True  True False False\n",
            " False  True  True False False False False False False False False False\n",
            "  True False  True  True False  True False]\n",
            "df: (1736, 10) (1736,)\n",
            "Train set: (50, 10)\n",
            "Validation set: (1252, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 79.723502 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [ 375 1224  902  782   31]\n",
            "Train set: (55, 10)\n",
            "Validation set: (1247, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 80.875576 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [391  45 801 790 526]\n",
            "Train set: (60, 10)\n",
            "Validation set: (1242, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 3\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 78.801843 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [135 136 243 107 138]\n",
            "Train set: (65, 10)\n",
            "Validation set: (1237, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 4\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 74.654378 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [611 553 411 976 951]\n",
            "Train set: (70, 10)\n",
            "Validation set: (1232, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 5\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 77.419355 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [ 416  854  938  815 1210]\n",
            "Train set: (75, 10)\n",
            "Validation set: (1227, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 6\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 77.188940 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [600   2 718 372 226]\n",
            "Train set: (80, 10)\n",
            "Validation set: (1222, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 7\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 76.497696 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [567 171 962 251 422]\n",
            "Train set: (85, 10)\n",
            "Validation set: (1217, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 8\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 77.188940 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [ 252 1101   51   84  427]\n",
            "Train set: (90, 10)\n",
            "Validation set: (1212, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 9\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 77.188940 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [481 331 664 927 952]\n",
            "Train set: (95, 10)\n",
            "Validation set: (1207, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 10\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 76.497696 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [1152  137 1051  771  692]\n",
            "Train set: (100, 10)\n",
            "Validation set: (1202, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 11\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 75.115207 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [602 925 656 382 302]\n",
            "Train set: (105, 10)\n",
            "Validation set: (1197, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 12\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 76.497696 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [196 935  33 186 540]\n",
            "Train set: (110, 10)\n",
            "Validation set: (1192, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 13\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 76.036866 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [1107  581  122  723  731]\n",
            "Train set: (115, 10)\n",
            "Validation set: (1187, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 14\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 76.497696 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [930 297 968  75 120]\n",
            "Train set: (120, 10)\n",
            "Validation set: (1182, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 15\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 76.728111 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [831 498 927 282 752]\n",
            "Train set: (125, 10)\n",
            "Validation set: (1177, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 16\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 73.041475 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [ 639  366  490 1122  883]\n",
            "Train set: (130, 10)\n",
            "Validation set: (1172, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 17\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 76.958525 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [ 402 1000  997  341  325]\n",
            "Train set: (135, 10)\n",
            "Validation set: (1167, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 18\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 72.811060 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [ 185  889  549 1029  603]\n",
            "Train set: (140, 10)\n",
            "Validation set: (1162, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 19\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 76.958525 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [274 182 568 870 188]\n",
            "Train set: (145, 10)\n",
            "Validation set: (1157, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 20\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 73.732719 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [1064  523   89  755  641]\n",
            "Train set: (150, 10)\n",
            "Validation set: (1152, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 21\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 72.580645 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [383 240   4 815 197]\n",
            "Train set: (155, 10)\n",
            "Validation set: (1147, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 22\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 76.728111 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [ 836  785  222  894 1095]\n",
            "Train set: (160, 10)\n",
            "Validation set: (1142, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 23\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 77.419355 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [455 760 976 152 898]\n",
            "Train set: (165, 10)\n",
            "Validation set: (1137, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 24\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 77.419355 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [884 969 765 239 869]\n",
            "Train set: (170, 10)\n",
            "Validation set: (1132, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 25\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 70.506912 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [343 904 767 689 301]\n",
            "Train set: (175, 10)\n",
            "Validation set: (1127, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 26\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 72.350230 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [415 514 766 337 436]\n",
            "Train set: (180, 10)\n",
            "Validation set: (1122, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 27\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 71.658986 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [ 65 887 511 939  27]\n",
            "Train set: (185, 10)\n",
            "Validation set: (1117, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 28\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 71.428571 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [110 243 379 234 834]\n",
            "Train set: (190, 10)\n",
            "Validation set: (1112, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 29\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 71.658986 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [162 255  35 773 149]\n",
            "Train set: (195, 10)\n",
            "Validation set: (1107, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 30\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 72.350230 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [ 467  708 1044  264  864]\n",
            "Train set: (200, 10)\n",
            "Validation set: (1102, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 31\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 72.119816 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [916 217 467 130 372]\n",
            "Train set: (205, 10)\n",
            "Validation set: (1097, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 32\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 72.811060 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [211 319 502 427 747]\n",
            "Train set: (210, 10)\n",
            "Validation set: (1092, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 33\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 70.737327 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [898 762 372 568 178]\n",
            "Train set: (215, 10)\n",
            "Validation set: (1087, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 34\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 70.737327 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [504 689 634 649 372]\n",
            "Train set: (220, 10)\n",
            "Validation set: (1082, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 35\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 71.428571 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [928 426 840 680 476]\n",
            "Train set: (225, 10)\n",
            "Validation set: (1077, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 36\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 70.046083 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [ 74  13 756 378 926]\n",
            "Train set: (230, 10)\n",
            "Validation set: (1072, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 37\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 72.119816 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [ 236  620  443  713 1016]\n",
            "Train set: (235, 10)\n",
            "Validation set: (1067, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 38\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 68.894009 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [ 47 509 657 274 574]\n",
            "Train set: (240, 10)\n",
            "Validation set: (1062, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 39\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 70.737327 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [447 115 518 397 284]\n",
            "Train set: (245, 10)\n",
            "Validation set: (1057, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 40\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 70.506912 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [749 115 135 408 905]\n",
            "Train set: (250, 10)\n",
            "Validation set: (1052, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 41\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 70.046083 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [150 154 725 536 882]\n",
            "Train set: (255, 10)\n",
            "Validation set: (1047, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 42\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 70.967742 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [176 893 853 796 988]\n",
            "Train set: (260, 10)\n",
            "Validation set: (1042, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 43\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 68.894009 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [803 412  76 833 731]\n",
            "Train set: (265, 10)\n",
            "Validation set: (1037, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 44\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 69.124424 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [176 140 253 203 316]\n",
            "Train set: (270, 10)\n",
            "Validation set: (1032, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 45\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 68.433180 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [481 538 995 129 506]\n",
            "Train set: (275, 10)\n",
            "Validation set: (1027, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 46\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 70.506912 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [960 754  34 991 971]\n",
            "Train set: (280, 10)\n",
            "Validation set: (1022, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 47\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 68.202765 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [846 901 302 500 860]\n",
            "Train set: (285, 10)\n",
            "Validation set: (1017, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 48\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 67.050691 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [670 980 946 360 442]\n",
            "Train set: (290, 10)\n",
            "Validation set: (1012, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 49\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 70.046083 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [619 440 632 300 177]\n",
            "Train set: (295, 10)\n",
            "Validation set: (1007, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 50\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 67.511521 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [ 130  292 1006  370  493]\n",
            "Train set: (300, 10)\n",
            "Validation set: (1002, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 51\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 67.741935 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [994 534 370 617 668]\n",
            "Train set: (305, 10)\n",
            "Validation set: (997, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 52\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 68.663594 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [502 206  65 100 283]\n",
            "Train set: (310, 10)\n",
            "Validation set: (992, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 53\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 68.663594 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [248 346 657 345 558]\n",
            "Train set: (315, 10)\n",
            "Validation set: (987, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 54\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 69.124424 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [180 218 206  36 450]\n",
            "Train set: (320, 10)\n",
            "Validation set: (982, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 55\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 68.663594 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [240 490 274 286 118]\n",
            "Train set: (325, 10)\n",
            "Validation set: (977, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 56\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 68.433180 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [949 640 233  17 819]\n",
            "Train set: (330, 10)\n",
            "Validation set: (972, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 57\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 70.046083 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [ 65 686 469 188 877]\n",
            "Train set: (335, 10)\n",
            "Validation set: (967, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 58\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 69.585253 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [479 363 757 627 358]\n",
            "Train set: (340, 10)\n",
            "Validation set: (962, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 59\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 69.124424 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [431 844 685 108 612]\n",
            "Train set: (345, 10)\n",
            "Validation set: (957, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 60\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 68.202765 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [763   1 749 802 125]\n",
            "Train set: (350, 10)\n",
            "Validation set: (952, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 61\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 69.354839 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [825 494 852 921 130]\n",
            "Train set: (355, 10)\n",
            "Validation set: (947, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 62\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 70.506912 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [801 707 546 590 127]\n",
            "Train set: (360, 10)\n",
            "Validation set: (942, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 63\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 67.972350 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [795 372 557 749 811]\n",
            "Train set: (365, 10)\n",
            "Validation set: (937, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 64\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 69.354839 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [385 845   5 102 366]\n",
            "Train set: (370, 10)\n",
            "Validation set: (932, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 65\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 69.124424 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [405 800 188 180 191]\n",
            "Train set: (375, 10)\n",
            "Validation set: (927, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 66\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 70.046083 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [ 31 742 165 183 745]\n",
            "Train set: (380, 10)\n",
            "Validation set: (922, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 67\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 67.972350 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [450 649 100 599  23]\n",
            "Train set: (385, 10)\n",
            "Validation set: (917, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 68\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 67.741935 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [678 855 439 149 848]\n",
            "Train set: (390, 10)\n",
            "Validation set: (912, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 69\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 69.815668 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [155 337 737 522 465]\n",
            "Train set: (395, 10)\n",
            "Validation set: (907, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 70\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 69.124424 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [517 389 344 476 427]\n",
            "Train set: (400, 10)\n",
            "Validation set: (902, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 71\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 67.972350 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [625 760  79 872 400]\n",
            "Train set: (405, 10)\n",
            "Validation set: (897, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 72\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 68.202765 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [496  50 505 174 298]\n",
            "Train set: (410, 10)\n",
            "Validation set: (892, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 73\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 69.585253 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [700 456 187 336 400]\n",
            "Train set: (415, 10)\n",
            "Validation set: (887, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 74\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 68.202765 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [623 485 564 415 248]\n",
            "Train set: (420, 10)\n",
            "Validation set: (882, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 75\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 70.506912 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [648 449 652 814 728]\n",
            "Train set: (425, 10)\n",
            "Validation set: (877, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 76\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 69.585253 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [463 770 462   7 774]\n",
            "Train set: (430, 10)\n",
            "Validation set: (872, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 77\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 70.506912 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [294 278 251 786 590]\n",
            "Train set: (435, 10)\n",
            "Validation set: (867, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 78\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 69.585253 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [551 195 262 285   4]\n",
            "Train set: (440, 10)\n",
            "Validation set: (862, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 79\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 69.585253 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [293 709 233 401 143]\n",
            "Train set: (445, 10)\n",
            "Validation set: (857, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 80\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 69.585253 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [ 34 535 376 578 234]\n",
            "Train set: (450, 10)\n",
            "Validation set: (852, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 81\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 69.815668 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [474 815 768 340 351]\n",
            "Train set: (455, 10)\n",
            "Validation set: (847, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 82\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 70.967742 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [395  38 219 289 757]\n",
            "Train set: (460, 10)\n",
            "Validation set: (842, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 83\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 69.124424 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [263 830 279 785 838]\n",
            "Train set: (465, 10)\n",
            "Validation set: (837, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 84\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 68.894009 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [750 250 178 595 206]\n",
            "Train set: (470, 10)\n",
            "Validation set: (832, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 85\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 70.276498 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [578  18 625 219 390]\n",
            "Train set: (475, 10)\n",
            "Validation set: (827, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 86\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 68.663594 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [759 110 459  41 280]\n",
            "Train set: (480, 10)\n",
            "Validation set: (822, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 87\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 68.202765 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [277 185 587 661 671]\n",
            "Train set: (485, 10)\n",
            "Validation set: (817, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 88\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 70.276498 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [601  19 503 312  75]\n",
            "Train set: (490, 10)\n",
            "Validation set: (812, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 89\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 69.585253 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [616 407 500 197  84]\n",
            "Train set: (495, 10)\n",
            "Validation set: (807, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 90\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 69.124424 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [696 633 413 495 689]\n",
            "Train set: (500, 10)\n",
            "Validation set: (802, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 91\n",
            "y-test set: (434,)\n",
            "Accuracy rate is 69.354839 \n",
            "--------------------------------\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "pool_experiment(LogModel,MarginSamplingSelection,500,50,5)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyMfqalTRwiWuiIELJDbCQ7d",
      "mount_file_id": "1SZapm_bYNJDCJi8ECwmjrzaN8-1ruRgA",
      "name": "Logistic.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "5edc29c2ed010d6458d71a83433b383a96a8cbd3efe8531bc90c4b8a5b8bcec9"
    },
    "kernelspec": {
      "display_name": "Python 3.8.2 64-bit",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "metadata": {
      "interpreter": {
        "hash": "5edc29c2ed010d6458d71a83433b383a96a8cbd3efe8531bc90c4b8a5b8bcec9"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}