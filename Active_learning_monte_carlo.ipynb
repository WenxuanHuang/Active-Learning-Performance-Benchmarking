{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 49,
      "source": [
        "print(__doc__)\n",
        "\n",
        "import os\n",
        "import time\n",
        "import json\n",
        "import pickle\n",
        "import math\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.mlab as mlab\n",
        "from scipy.special import expit\n",
        "from scipy import stats\n",
        "from pylab import rcParams\n",
        "import mplcursors\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.datasets import load_digits\n",
        "\n",
        "from sklearn.utils import check_random_state\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer\n",
        "from sklearn.pipeline import Pipeline, FeatureUnion\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import scale\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "\n",
        "from sklearn import linear_model\n",
        "from sklearn import neighbors\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.linear_model import RidgeCV, LassoCV, Ridge, Lasso\n",
        "from sklearn.svm import LinearSVC, SVC\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.utils import check_random_state\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics.pairwise import euclidean_distances\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.mixture import GaussianMixture\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import pairwise_distances_argmin_min\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import average_precision_score\n",
        "\n",
        "\n",
        "# pd.options.display.max_rows = 20\n",
        "pd.options.display.float_format = \"{:.1f}\".format\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Automatically created module for IPython interactive environment\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ioi13nGDPDvQ",
        "outputId": "4763f7b3-6c5b-45cb-f411-fd7c6ea8b38f"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "source": [
        "def fetch_data_corona():\n",
        "    data = pd.read_csv(\"https://raw.githubusercontent.com/WenxuanHuang/ML-for-COVID-19-dataset/main/all_training.csv\", sep=',')\n",
        "    # Column selection\n",
        "    df = data.iloc[:,np.r_[3:34]].copy()\n",
        "    # define row and column index\n",
        "    col = df.columns\n",
        "    row = [i for i in range(df.shape[0])]\n",
        "    # define imputer\n",
        "    imputer = IterativeImputer(estimator=linear_model.BayesianRidge(), n_nearest_features=None, imputation_order='ascending')\n",
        "    # fit on the dataset\n",
        "    imputer.fit(df)\n",
        "    # transform the dataset\n",
        "    df_imputed = imputer.transform(df)\n",
        "    # convert back to pandas dataframe and rename back to df_normalized\n",
        "    df = pd.DataFrame(data=df_imputed, index=row, columns=col)\n",
        "    X = df\n",
        "    y = data.target    \n",
        "    # # Recursive feature elimination\n",
        "    # rdmreg = RandomForestClassifier(n_estimators=100)\n",
        "    # # Define the method\n",
        "    # rfe = RFE(estimator=rdmreg, n_features_to_select=10)\n",
        "    # # Fit the model\n",
        "    # rfe = rfe.fit(X, y.values.ravel())\n",
        "    # print(rfe.support_)\n",
        "    # # Drop columns that failed RFE test\n",
        "    # col = df.columns[rfe.support_]\n",
        "    # X = X[col]\n",
        "    X = X.to_numpy()\n",
        "    print ('df:', X.shape, y.shape)\n",
        "    return (X, y)\n"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "source": [
        "def fetch_data_iris():\n",
        "    iris = load_iris()\n",
        "    X = iris.data.astype('float64')\n",
        "    y = iris.target\n",
        "    # print ('Dataset : ', X.shape, y.shape)\n",
        "    return (X, y)\n",
        "\n",
        "def fetch_data_mnist():\n",
        "    mnist = load_digits()\n",
        "    X = mnist.data.astype('float64')\n",
        "    y = mnist.target\n",
        "    # print ('Dataset : ', X.shape, y.shape)\n",
        "    return (X, y)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# def fetch_data_wine():\n",
        "#     data = pd.read_csv(\"https://raw.githubusercontent.com/WenxuanHuang/ML-for-COVID-19-dataset/main/all_training.csv\", sep=';')\n",
        "#     # Column selection\n",
        "#     df = data.iloc[:,np.r_[3:34]].copy()\n",
        "#     # define row and column index\n",
        "#     col = df.columns\n",
        "#     row = [i for i in range(df.shape[0])]\n",
        "#     # define imputer\n",
        "#     imputer = IterativeImputer(estimator=linear_model.BayesianRidge(), n_nearest_features=None, imputation_order='ascending')\n",
        "#     # fit on the dataset\n",
        "#     imputer.fit(df)\n",
        "#     # transform the dataset\n",
        "#     df_imputed = imputer.transform(df)\n",
        "#     # convert back to pandas dataframe and rename back to df_normalized\n",
        "#     df = pd.DataFrame(data=df_imputed, index=row, columns=col)\n",
        "#     X = df\n",
        "#     y = data.target    \n",
        "#     # # Recursive feature elimination\n",
        "#     # rdmreg = RandomForestClassifier(n_estimators=100)\n",
        "#     # # Define the method\n",
        "#     # rfe = RFE(estimator=rdmreg, n_features_to_select=10)\n",
        "#     # # Fit the model\n",
        "#     # rfe = rfe.fit(X, y.values.ravel())\n",
        "#     # print(rfe.support_)\n",
        "#     # # Drop columns that failed RFE test\n",
        "#     # col = df.columns[rfe.support_]\n",
        "#     # X = X[col]\n",
        "#     X = X.to_numpy()\n",
        "#     print ('df:', X.shape, y.shape)\n",
        "#     return (X, y)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "source": [
        "class BaseModel(object):\n",
        "\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def fit_predict(self):\n",
        "        pass\n",
        "\n",
        "\n",
        "class SvmModel(BaseModel):\n",
        "\n",
        "    model_type = 'Support Vector Machine with linear Kernel'\n",
        "    def fit_predict(self, X_train, y_train, X_val, X_test):\n",
        "        print ('training svm...')\n",
        "        self.classifier = SVC(\n",
        "            kernel='linear', \n",
        "            probability=True\n",
        "            )\n",
        "        self.classifier.fit(X_train, y_train)\n",
        "        self.test_y_predicted = self.classifier.predict(X_test)\n",
        "        self.val_y_predicted = self.classifier.predict(X_val)\n",
        "        return (X_train, X_val, X_test, self.val_y_predicted,\n",
        "                self.test_y_predicted)\n",
        "\n",
        "class LogModel(BaseModel):\n",
        "\n",
        "    model_type = 'Logistic Regression' \n",
        "    def fit_predict(self, X_train, y_train, X_val, X_test):\n",
        "        # print ('training logistic regression...')\n",
        "        train_samples = X_train.shape[0]\n",
        "        self.classifier = LogisticRegression(\n",
        "            # C=50. / train_samples,\n",
        "            penalty='l1',\n",
        "            solver='liblinear',\n",
        "            tol=0.1\n",
        "            )\n",
        "        self.classifier.fit(X_train, y_train)\n",
        "        self.test_y_predicted = self.classifier.predict(X_test)\n",
        "        self.val_y_predicted = self.classifier.predict(X_val)\n",
        "        return (X_train, X_val, X_test, self.val_y_predicted,\n",
        "                self.test_y_predicted)\n",
        "\n",
        "class RfModel(BaseModel):\n",
        "\n",
        "    model_type = 'Random Forest'\n",
        "    def fit_predict(self, X_train, y_train, X_val, X_test):\n",
        "        print ('training random forest...')\n",
        "        self.classifier = RandomForestClassifier(\n",
        "            n_jobs=-1\n",
        "            )\n",
        "        self.classifier.fit(X_train, y_train)\n",
        "        self.test_y_predicted = self.classifier.predict(X_test)\n",
        "        self.val_y_predicted = self.classifier.predict(X_val)\n",
        "        return (X_train, X_val, X_test, self.val_y_predicted, self.test_y_predicted)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "source": [
        "class TrainModel:\n",
        "\n",
        "    def __init__(self, model_object):        \n",
        "        self.accuracies = []\n",
        "        self.model_object = model_object()        \n",
        "\n",
        "    def print_model_type(self):\n",
        "        print (self.model_object.model_type)\n",
        "\n",
        "    # we train normally and use the probabilities to select the most uncertain samples\n",
        "    def train(self, X_train, y_train, X_val, X_test):\n",
        "        print ('Train set:', X_train.shape)\n",
        "        print ('Validation set:', X_val.shape)\n",
        "        print ('Test set:', X_test.shape)\n",
        "        t0 = time.time()\n",
        "        (X_train, X_val, X_test, self.val_y_predicted,\n",
        "         self.test_y_predicted) = \\\n",
        "            self.model_object.fit_predict(X_train, y_train, X_val, X_test)\n",
        "        self.run_time = time.time() - t0\n",
        "        return (X_train, X_val, X_test)\n",
        "\n",
        "    # we want accuracy only for the test set\n",
        "    def get_test_accuracy(self, i, y_test):\n",
        "        classif_rate = np.mean(self.test_y_predicted.ravel() == y_test.ravel()) * 100\n",
        "        self.accuracies.append(classif_rate)               \n",
        "        print('--------------------------------')\n",
        "        print('Iteration:',i)\n",
        "        # print('--------------------------------')\n",
        "        # print('y-test set:',y_test.shape)\n",
        "        # print('Training run in %.3f s' % self.run_time,'\\n')\n",
        "        print(\"Accuracy rate is %f \" % (classif_rate))    \n",
        "        # print(\"Classification report for %s:\\n%s\\n\" % (self.model_object.classifier, metrics.classification_report(y_test, self.test_y_predicted)))\n",
        "        # print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(y_test, self.test_y_predicted))\n",
        "        print('--------------------------------')\n"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "source": [
        "class Normalize(object):\n",
        "    \n",
        "    def normalize(self, X_train, X_val, X_test):\n",
        "        self.scaler = RobustScaler()\n",
        "        X_train = self.scaler.fit_transform(X_train)\n",
        "        X_val   = self.scaler.transform(X_val)\n",
        "        X_test  = self.scaler.transform(X_test)\n",
        "        return (X_train, X_val, X_test) \n",
        "    \n",
        "    def inverse(self, X_train, X_val, X_test):\n",
        "        X_train = self.scaler.inverse_transform(X_train)\n",
        "        X_val   = self.scaler.inverse_transform(X_val)\n",
        "        X_test  = self.scaler.inverse_transform(X_test)\n",
        "        return (X_train, X_val, X_test) "
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "source": [
        "def get_random_samples(initial_samples, X_train_full, y_train_full):\n",
        "\n",
        "    permutation = np.random.choice(len(X_train_full),initial_samples,replace=False)\n",
        "    X_train = X_train_full[permutation]\n",
        "    y_train = y_train_full[permutation]\n",
        "    X_train = X_train.reshape((X_train.shape[0], -1))\n",
        "\n",
        "    return (permutation, X_train, y_train)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "source": [
        "def log_loss(labels, probs):\n",
        "\n",
        "    eps = np.finfo(probs.dtype).eps\n",
        "    probs = np.clip(probs, eps, 1 - eps)\n",
        "    loss = 0\n",
        "\n",
        "    for i in range(len(probs)):\n",
        "        for prob in probs[i]:\n",
        "            loss -= (labels[i]*np.log(prob))\n",
        " \n",
        "    ll = loss/(len(probs)*1.)\n",
        "\n",
        "    return ll"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "source": [
        "def mse_loss(labels, preds):\n",
        "    loss = 0\n",
        "\n",
        "    for i in range(len(labels)):\n",
        "        loss += ((labels[i] - preds[i]) ** 2)\n",
        "\n",
        "    return loss/len(labels)\n",
        "    "
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "source": [
        "class TheAlgorithm(object):\n",
        "\n",
        "    accuracies = []\n",
        "\n",
        "    def __init__(self, step, model_object):\n",
        "        self.step = step\n",
        "        self.model_object = model_object\n",
        "        \n",
        "    def run(self, X_train_full, y_train_full, X_test, y_test, initial_queried, max_queried):\n",
        "\n",
        "        (permutation, X_train, y_train) = get_random_samples(initial_queried, X_train_full, y_train_full)\n",
        "        self.queried = initial_queried\n",
        "\n",
        "        X_val = np.array([])\n",
        "        y_val = np.array([])\n",
        "        X_val = np.copy(X_train_full)\n",
        "        X_val = np.delete(X_val, permutation, axis=0)\n",
        "        y_val = np.copy(y_train_full)\n",
        "        y_val = np.delete(y_val, permutation, axis=0)\n",
        "\n",
        "        normalizer = Normalize()\n",
        "        X_train, X_val, X_test = normalizer.normalize(X_train, X_val, X_test)\n",
        "           \n",
        "        self.clf_model = TrainModel(self.model_object)\n",
        "        (X_train, X_val, X_test) = self.clf_model.train(X_train, y_train, X_val, X_test)\n",
        "        active_iteration = 1\n",
        "        self.clf_model.get_test_accuracy(1, y_test)\n",
        "\n",
        "        while self.queried <= max_queried-self.step:\n",
        "\n",
        "            active_iteration += 1\n",
        "            self.queried += self.step\n",
        "            (mc_permutation, X_subset, y_subset) = \\\n",
        "                get_random_samples(10, X_val, y_val) # 10 is the subset size\n",
        "            # print('Indexes in the subset for X_val:', mc_permutation)\n",
        "            # print ('Subset:', X_subset.shape, y_subset.shape, monte_carlo_permutation.shape)\n",
        "            # print ('Train:', X_train.shape, y_train.shape, permutation.shape)\n",
        "\n",
        "            cand_probs = self.clf_model.model_object.classifier.predict_proba(X_subset)\n",
        "            # print(\"structure of cand_probs:\", cand_probs)\n",
        "\n",
        "            utils = []\n",
        "\n",
        "            for i in range(len(X_subset)):\n",
        "                new_train_X = X_train\n",
        "                row_subset = X_subset[i]\n",
        "                new_train_X = np.append(new_train_X, [row_subset], axis=0)\n",
        "                util = 0\n",
        "                new_label_y = np.random.randint(0, 9, size=len(X_subset))\n",
        "                # new_label_y = np.random.choice([0, 1], size=len(X_subset),)\n",
        "                # print(\"Newly assigned labels:\", new_label_y)\n",
        "                # To-do: random.randint is too inefficient\n",
        "                for label in new_label_y:\n",
        "                    new_train_y = y_train\n",
        "                    new_train_y = np.append(new_train_y, label)\n",
        "                    # print('Monte_carlo training set X:', new_train_X)\n",
        "                    # print('Monte_carlo training set y:', new_train_y)\n",
        "                    new_classifier = self.clf_model.model_object.classifier\n",
        "                    new_classifier.fit(new_train_X, new_train_y)\n",
        "                    new_probs = new_classifier.predict_proba(X_subset)\n",
        "                    # new_preds = new_classifier.predict(X_subset)\n",
        "                    # print(\"structure of new_probs:\", cand_probs)\n",
        "                    # util for log_loss\n",
        "                    util += cand_probs[i][label] * log_loss(y_subset, new_probs)\n",
        "                    # util for mse_loss\n",
        "                    # util += cand_probs[i][label] * mse_loss(y_subset, new_preds)\n",
        "\n",
        "                utils.append(util)\n",
        "                \n",
        "            uis = np.argsort(utils)\n",
        "            # need to check validity\n",
        "            # print ('Monte-carlo selected indexes:', uis)\n",
        "  \n",
        "\n",
        "            X_uncertain = [X_subset[i] for i in uis[:self.step]]\n",
        "            y_uncertain = [y_subset[i] for i in uis[:self.step]]\n",
        "            uncertain_samples = mc_permutation[uis[:self.step]]\n",
        "            # print ('Monte-carlo selected indexes:', uncertain_samples)\n",
        "            # print ('Monte-carlo selected samples:', X_uncertain)\n",
        "            # print ('Monte-carlo selected outcomes:', y_uncertain)\n",
        "\n",
        "            X_train, X_val, X_test = normalizer.inverse(X_train, X_val, X_test)   \n",
        "            X_train = np.concatenate((X_train, np.array(X_uncertain)))\n",
        "            y_train = np.concatenate((y_train, np.array(y_uncertain)))\n",
        "\n",
        "            X_val = np.delete(X_val, uncertain_samples, axis=0)\n",
        "            y_val = np.delete(y_val, uncertain_samples, axis=0)\n",
        "\n",
        "            normalizer = Normalize()\n",
        "            X_train, X_val, X_test = normalizer.normalize(X_train, X_val, X_test)               \n",
        "\n",
        "            (X_train, X_val, X_test) = self.clf_model.train(X_train, y_train, X_val, X_test)\n",
        "            self.clf_model.get_test_accuracy(active_iteration, y_test)\n",
        "\n",
        "        return self.clf_model.accuracies"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "source": [
        "def pool_experiment(model,max_queried,initial_queried,step):\n",
        "\n",
        "    (X, y) = fetch_data_mnist()\n",
        "\n",
        "    # print(\"min/max:\",min(y),max(y))\n",
        "\n",
        "    kf = KFold(n_splits=4)\n",
        "    for train_index, test_index in kf.split(X):\n",
        "        X_train_full, X_test = X[train_index], X[test_index]\n",
        "        y_train_full, y_test = y[train_index], y[test_index]\n",
        "        \n",
        "    act_alg = TheAlgorithm(step, model)\n",
        "    accuracies = act_alg.run(X_train_full,y_train_full,X_test,y_test,initial_queried,max_queried)\n",
        "\n",
        "    (permutation, X_train_selected, y_train_selected) = get_random_samples(initial_queried, X_train_full, y_train_full)\n",
        "    original_accuracies=[]\n",
        "    classifier_original = LogisticRegression(\n",
        "                            penalty='l1',\n",
        "                            solver='liblinear',\n",
        "                            tol=0.1\n",
        "                            )\n",
        "    x_axis = []\n",
        "    for i in range(initial_queried-1,max_queried,step):\n",
        "        classifier_original.fit(X_train_selected[:i+1], y_train_selected[:i+1])\n",
        "        y_pred_original = classifier_original.predict(X_test)\n",
        "        original_accuracies.append(accuracy_score(y_test, y_pred_original)*100)\n",
        "        x_axis.append(i+1)\n",
        "    print(\"accuracies\",accuracies)\n",
        "    print(\"nonactive_accuracies\",original_accuracies)\n",
        "    plt.plot(x_axis, accuracies, 'r',label='active')\n",
        "    plt.plot(x_axis, original_accuracies, 'blue',label='non-active')\n",
        "    plt.legend()\n",
        "    plt.xlabel('Sample Size')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.show()"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "source": [
        "pool_experiment(LogModel,500,25,5)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set: (25, 64)\n",
            "Validation set: (1323, 64)\n",
            "Test set: (449, 64)\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "Accuracy rate is 41.870824 \n",
            "--------------------------------\n",
            "Train set: (30, 64)\n",
            "Validation set: (1318, 64)\n",
            "Test set: (449, 64)\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "Accuracy rate is 40.979955 \n",
            "--------------------------------\n",
            "Train set: (35, 64)\n",
            "Validation set: (1313, 64)\n",
            "Test set: (449, 64)\n",
            "--------------------------------\n",
            "Iteration: 3\n",
            "Accuracy rate is 52.783964 \n",
            "--------------------------------\n",
            "Train set: (40, 64)\n",
            "Validation set: (1308, 64)\n",
            "Test set: (449, 64)\n",
            "--------------------------------\n",
            "Iteration: 4\n",
            "Accuracy rate is 54.565702 \n",
            "--------------------------------\n",
            "Train set: (45, 64)\n",
            "Validation set: (1303, 64)\n",
            "Test set: (449, 64)\n",
            "--------------------------------\n",
            "Iteration: 5\n",
            "Accuracy rate is 56.792873 \n",
            "--------------------------------\n",
            "Train set: (50, 64)\n",
            "Validation set: (1298, 64)\n",
            "Test set: (449, 64)\n",
            "--------------------------------\n",
            "Iteration: 6\n",
            "Accuracy rate is 57.015590 \n",
            "--------------------------------\n",
            "Train set: (55, 64)\n",
            "Validation set: (1293, 64)\n",
            "Test set: (449, 64)\n",
            "--------------------------------\n",
            "Iteration: 7\n",
            "Accuracy rate is 60.579065 \n",
            "--------------------------------\n",
            "Train set: (60, 64)\n",
            "Validation set: (1288, 64)\n",
            "Test set: (449, 64)\n",
            "--------------------------------\n",
            "Iteration: 8\n",
            "Accuracy rate is 66.815145 \n",
            "--------------------------------\n",
            "Train set: (65, 64)\n",
            "Validation set: (1283, 64)\n",
            "Test set: (449, 64)\n",
            "--------------------------------\n",
            "Iteration: 9\n",
            "Accuracy rate is 63.251670 \n",
            "--------------------------------\n",
            "Train set: (70, 64)\n",
            "Validation set: (1278, 64)\n",
            "Test set: (449, 64)\n",
            "--------------------------------\n",
            "Iteration: 10\n",
            "Accuracy rate is 65.256125 \n",
            "--------------------------------\n",
            "Train set: (75, 64)\n",
            "Validation set: (1273, 64)\n",
            "Test set: (449, 64)\n",
            "--------------------------------\n",
            "Iteration: 11\n",
            "Accuracy rate is 63.919822 \n",
            "--------------------------------\n",
            "Train set: (80, 64)\n",
            "Validation set: (1268, 64)\n",
            "Test set: (449, 64)\n",
            "--------------------------------\n",
            "Iteration: 12\n",
            "Accuracy rate is 69.265033 \n",
            "--------------------------------\n",
            "Train set: (85, 64)\n",
            "Validation set: (1263, 64)\n",
            "Test set: (449, 64)\n",
            "--------------------------------\n",
            "Iteration: 13\n",
            "Accuracy rate is 68.819599 \n",
            "--------------------------------\n",
            "Train set: (90, 64)\n",
            "Validation set: (1258, 64)\n",
            "Test set: (449, 64)\n",
            "--------------------------------\n",
            "Iteration: 14\n",
            "Accuracy rate is 69.933185 \n",
            "--------------------------------\n",
            "Train set: (95, 64)\n",
            "Validation set: (1253, 64)\n",
            "Test set: (449, 64)\n",
            "--------------------------------\n",
            "Iteration: 15\n",
            "Accuracy rate is 71.937639 \n",
            "--------------------------------\n",
            "Train set: (100, 64)\n",
            "Validation set: (1248, 64)\n",
            "Test set: (449, 64)\n",
            "--------------------------------\n",
            "Iteration: 16\n",
            "Accuracy rate is 72.160356 \n",
            "--------------------------------\n",
            "Train set: (105, 64)\n",
            "Validation set: (1243, 64)\n",
            "Test set: (449, 64)\n",
            "--------------------------------\n",
            "Iteration: 17\n",
            "Accuracy rate is 74.164811 \n",
            "--------------------------------\n",
            "Train set: (110, 64)\n",
            "Validation set: (1238, 64)\n",
            "Test set: (449, 64)\n",
            "--------------------------------\n",
            "Iteration: 18\n",
            "Accuracy rate is 78.619154 \n",
            "--------------------------------\n",
            "Train set: (115, 64)\n",
            "Validation set: (1233, 64)\n",
            "Test set: (449, 64)\n",
            "--------------------------------\n",
            "Iteration: 19\n",
            "Accuracy rate is 78.841871 \n",
            "--------------------------------\n",
            "Train set: (120, 64)\n",
            "Validation set: (1228, 64)\n",
            "Test set: (449, 64)\n",
            "--------------------------------\n",
            "Iteration: 20\n",
            "Accuracy rate is 79.287305 \n",
            "--------------------------------\n",
            "Train set: (125, 64)\n",
            "Validation set: (1223, 64)\n",
            "Test set: (449, 64)\n",
            "--------------------------------\n",
            "Iteration: 21\n",
            "Accuracy rate is 78.619154 \n",
            "--------------------------------\n",
            "Train set: (130, 64)\n",
            "Validation set: (1218, 64)\n",
            "Test set: (449, 64)\n",
            "--------------------------------\n",
            "Iteration: 22\n",
            "Accuracy rate is 80.623608 \n",
            "--------------------------------\n",
            "Train set: (135, 64)\n",
            "Validation set: (1213, 64)\n",
            "Test set: (449, 64)\n",
            "--------------------------------\n",
            "Iteration: 23\n",
            "Accuracy rate is 81.069042 \n",
            "--------------------------------\n",
            "Train set: (140, 64)\n",
            "Validation set: (1208, 64)\n",
            "Test set: (449, 64)\n",
            "--------------------------------\n",
            "Iteration: 24\n",
            "Accuracy rate is 83.073497 \n",
            "--------------------------------\n",
            "Train set: (145, 64)\n",
            "Validation set: (1203, 64)\n",
            "Test set: (449, 64)\n",
            "--------------------------------\n",
            "Iteration: 25\n",
            "Accuracy rate is 79.955457 \n",
            "--------------------------------\n",
            "Train set: (150, 64)\n",
            "Validation set: (1198, 64)\n",
            "Test set: (449, 64)\n",
            "--------------------------------\n",
            "Iteration: 26\n",
            "Accuracy rate is 81.959911 \n",
            "--------------------------------\n",
            "Train set: (155, 64)\n",
            "Validation set: (1193, 64)\n",
            "Test set: (449, 64)\n",
            "--------------------------------\n",
            "Iteration: 27\n",
            "Accuracy rate is 79.732739 \n",
            "--------------------------------\n",
            "Train set: (160, 64)\n",
            "Validation set: (1188, 64)\n",
            "Test set: (449, 64)\n",
            "--------------------------------\n",
            "Iteration: 28\n",
            "Accuracy rate is 80.178174 \n",
            "--------------------------------\n",
            "Train set: (165, 64)\n",
            "Validation set: (1183, 64)\n",
            "Test set: (449, 64)\n",
            "--------------------------------\n",
            "Iteration: 29\n",
            "Accuracy rate is 82.850780 \n",
            "--------------------------------\n",
            "Train set: (170, 64)\n",
            "Validation set: (1178, 64)\n",
            "Test set: (449, 64)\n",
            "--------------------------------\n",
            "Iteration: 30\n",
            "Accuracy rate is 81.514477 \n",
            "--------------------------------\n",
            "Train set: (175, 64)\n",
            "Validation set: (1173, 64)\n",
            "Test set: (449, 64)\n",
            "--------------------------------\n",
            "Iteration: 31\n",
            "Accuracy rate is 82.628062 \n",
            "--------------------------------\n",
            "Train set: (180, 64)\n",
            "Validation set: (1168, 64)\n",
            "Test set: (449, 64)\n",
            "--------------------------------\n",
            "Iteration: 32\n",
            "Accuracy rate is 82.850780 \n",
            "--------------------------------\n",
            "Train set: (185, 64)\n",
            "Validation set: (1163, 64)\n",
            "Test set: (449, 64)\n",
            "--------------------------------\n",
            "Iteration: 33\n",
            "Accuracy rate is 83.741648 \n",
            "--------------------------------\n",
            "Train set: (190, 64)\n",
            "Validation set: (1158, 64)\n",
            "Test set: (449, 64)\n",
            "--------------------------------\n",
            "Iteration: 34\n",
            "Accuracy rate is 85.077951 \n",
            "--------------------------------\n",
            "Train set: (195, 64)\n",
            "Validation set: (1153, 64)\n",
            "Test set: (449, 64)\n",
            "--------------------------------\n",
            "Iteration: 35\n",
            "Accuracy rate is 84.855234 \n",
            "--------------------------------\n",
            "Train set: (200, 64)\n",
            "Validation set: (1148, 64)\n",
            "Test set: (449, 64)\n",
            "--------------------------------\n",
            "Iteration: 36\n",
            "Accuracy rate is 83.518931 \n",
            "--------------------------------\n",
            "Train set: (205, 64)\n",
            "Validation set: (1143, 64)\n",
            "Test set: (449, 64)\n",
            "--------------------------------\n",
            "Iteration: 37\n",
            "Accuracy rate is 83.741648 \n",
            "--------------------------------\n",
            "Train set: (210, 64)\n",
            "Validation set: (1138, 64)\n",
            "Test set: (449, 64)\n",
            "--------------------------------\n",
            "Iteration: 38\n",
            "Accuracy rate is 84.632517 \n",
            "--------------------------------\n",
            "Train set: (215, 64)\n",
            "Validation set: (1133, 64)\n",
            "Test set: (449, 64)\n",
            "--------------------------------\n",
            "Iteration: 39\n",
            "Accuracy rate is 84.855234 \n",
            "--------------------------------\n",
            "Train set: (220, 64)\n",
            "Validation set: (1128, 64)\n",
            "Test set: (449, 64)\n",
            "--------------------------------\n",
            "Iteration: 40\n",
            "Accuracy rate is 82.850780 \n",
            "--------------------------------\n",
            "Train set: (225, 64)\n",
            "Validation set: (1123, 64)\n",
            "Test set: (449, 64)\n",
            "--------------------------------\n",
            "Iteration: 41\n",
            "Accuracy rate is 83.518931 \n",
            "--------------------------------\n",
            "Train set: (230, 64)\n",
            "Validation set: (1118, 64)\n",
            "Test set: (449, 64)\n",
            "--------------------------------\n",
            "Iteration: 42\n",
            "Accuracy rate is 85.746102 \n",
            "--------------------------------\n",
            "Train set: (235, 64)\n",
            "Validation set: (1113, 64)\n",
            "Test set: (449, 64)\n",
            "--------------------------------\n",
            "Iteration: 43\n",
            "Accuracy rate is 83.073497 \n",
            "--------------------------------\n",
            "Train set: (240, 64)\n",
            "Validation set: (1108, 64)\n",
            "Test set: (449, 64)\n",
            "--------------------------------\n",
            "Iteration: 44\n",
            "Accuracy rate is 83.518931 \n",
            "--------------------------------\n",
            "Train set: (245, 64)\n",
            "Validation set: (1103, 64)\n",
            "Test set: (449, 64)\n",
            "--------------------------------\n",
            "Iteration: 45\n",
            "Accuracy rate is 83.296214 \n",
            "--------------------------------\n",
            "Train set: (250, 64)\n",
            "Validation set: (1098, 64)\n",
            "Test set: (449, 64)\n",
            "--------------------------------\n",
            "Iteration: 46\n",
            "Accuracy rate is 85.968820 \n",
            "--------------------------------\n",
            "Train set: (255, 64)\n",
            "Validation set: (1093, 64)\n",
            "Test set: (449, 64)\n",
            "--------------------------------\n",
            "Iteration: 47\n",
            "Accuracy rate is 85.077951 \n",
            "--------------------------------\n",
            "Train set: (260, 64)\n",
            "Validation set: (1088, 64)\n",
            "Test set: (449, 64)\n",
            "--------------------------------\n",
            "Iteration: 48\n",
            "Accuracy rate is 84.409800 \n",
            "--------------------------------\n",
            "Train set: (265, 64)\n",
            "Validation set: (1083, 64)\n",
            "Test set: (449, 64)\n",
            "--------------------------------\n",
            "Iteration: 49\n",
            "Accuracy rate is 85.077951 \n",
            "--------------------------------\n",
            "Train set: (270, 64)\n",
            "Validation set: (1078, 64)\n",
            "Test set: (449, 64)\n",
            "--------------------------------\n",
            "Iteration: 50\n",
            "Accuracy rate is 83.964365 \n",
            "--------------------------------\n",
            "Train set: (275, 64)\n",
            "Validation set: (1073, 64)\n",
            "Test set: (449, 64)\n",
            "--------------------------------\n",
            "Iteration: 51\n",
            "Accuracy rate is 85.077951 \n",
            "--------------------------------\n",
            "Train set: (280, 64)\n",
            "Validation set: (1068, 64)\n",
            "Test set: (449, 64)\n",
            "--------------------------------\n",
            "Iteration: 52\n",
            "Accuracy rate is 85.077951 \n",
            "--------------------------------\n",
            "Train set: (285, 64)\n",
            "Validation set: (1063, 64)\n",
            "Test set: (449, 64)\n",
            "--------------------------------\n",
            "Iteration: 53\n",
            "Accuracy rate is 86.414254 \n",
            "--------------------------------\n",
            "Train set: (290, 64)\n",
            "Validation set: (1058, 64)\n",
            "Test set: (449, 64)\n",
            "--------------------------------\n",
            "Iteration: 54\n",
            "Accuracy rate is 86.859688 \n",
            "--------------------------------\n",
            "Train set: (295, 64)\n",
            "Validation set: (1053, 64)\n",
            "Test set: (449, 64)\n",
            "--------------------------------\n",
            "Iteration: 55\n",
            "Accuracy rate is 85.746102 \n",
            "--------------------------------\n",
            "Train set: (300, 64)\n",
            "Validation set: (1048, 64)\n",
            "Test set: (449, 64)\n",
            "--------------------------------\n",
            "Iteration: 56\n",
            "Accuracy rate is 86.191537 \n",
            "--------------------------------\n",
            "Train set: (305, 64)\n",
            "Validation set: (1043, 64)\n",
            "Test set: (449, 64)\n",
            "--------------------------------\n",
            "Iteration: 57\n",
            "Accuracy rate is 85.523385 \n",
            "--------------------------------\n",
            "Train set: (310, 64)\n",
            "Validation set: (1038, 64)\n",
            "Test set: (449, 64)\n",
            "--------------------------------\n",
            "Iteration: 58\n",
            "Accuracy rate is 85.746102 \n",
            "--------------------------------\n",
            "Train set: (315, 64)\n",
            "Validation set: (1033, 64)\n",
            "Test set: (449, 64)\n",
            "--------------------------------\n",
            "Iteration: 59\n",
            "Accuracy rate is 86.636971 \n",
            "--------------------------------\n",
            "Train set: (320, 64)\n",
            "Validation set: (1028, 64)\n",
            "Test set: (449, 64)\n",
            "--------------------------------\n",
            "Iteration: 60\n",
            "Accuracy rate is 85.746102 \n",
            "--------------------------------\n",
            "Train set: (325, 64)\n",
            "Validation set: (1023, 64)\n",
            "Test set: (449, 64)\n",
            "--------------------------------\n",
            "Iteration: 61\n",
            "Accuracy rate is 86.859688 \n",
            "--------------------------------\n",
            "Train set: (330, 64)\n",
            "Validation set: (1018, 64)\n",
            "Test set: (449, 64)\n",
            "--------------------------------\n",
            "Iteration: 62\n",
            "Accuracy rate is 86.414254 \n",
            "--------------------------------\n",
            "Train set: (335, 64)\n",
            "Validation set: (1013, 64)\n",
            "Test set: (449, 64)\n",
            "--------------------------------\n",
            "Iteration: 63\n",
            "Accuracy rate is 85.968820 \n",
            "--------------------------------\n",
            "Train set: (340, 64)\n",
            "Validation set: (1008, 64)\n",
            "Test set: (449, 64)\n",
            "--------------------------------\n",
            "Iteration: 64\n",
            "Accuracy rate is 85.968820 \n",
            "--------------------------------\n",
            "Train set: (345, 64)\n",
            "Validation set: (1003, 64)\n",
            "Test set: (449, 64)\n",
            "--------------------------------\n",
            "Iteration: 65\n",
            "Accuracy rate is 87.527840 \n",
            "--------------------------------\n",
            "Train set: (350, 64)\n",
            "Validation set: (998, 64)\n",
            "Test set: (449, 64)\n",
            "--------------------------------\n",
            "Iteration: 66\n",
            "Accuracy rate is 88.195991 \n",
            "--------------------------------\n",
            "Train set: (355, 64)\n",
            "Validation set: (993, 64)\n",
            "Test set: (449, 64)\n",
            "--------------------------------\n",
            "Iteration: 67\n",
            "Accuracy rate is 88.418708 \n",
            "--------------------------------\n",
            "Train set: (360, 64)\n",
            "Validation set: (988, 64)\n",
            "Test set: (449, 64)\n",
            "--------------------------------\n",
            "Iteration: 68\n",
            "Accuracy rate is 89.309577 \n",
            "--------------------------------\n",
            "Train set: (365, 64)\n",
            "Validation set: (983, 64)\n",
            "Test set: (449, 64)\n",
            "--------------------------------\n",
            "Iteration: 69\n",
            "Accuracy rate is 87.750557 \n",
            "--------------------------------\n",
            "Train set: (370, 64)\n",
            "Validation set: (978, 64)\n",
            "Test set: (449, 64)\n",
            "--------------------------------\n",
            "Iteration: 70\n",
            "Accuracy rate is 89.977728 \n",
            "--------------------------------\n",
            "Train set: (375, 64)\n",
            "Validation set: (973, 64)\n",
            "Test set: (449, 64)\n",
            "--------------------------------\n",
            "Iteration: 71\n",
            "Accuracy rate is 88.418708 \n",
            "--------------------------------\n",
            "Train set: (380, 64)\n",
            "Validation set: (968, 64)\n",
            "Test set: (449, 64)\n",
            "--------------------------------\n",
            "Iteration: 72\n",
            "Accuracy rate is 88.418708 \n",
            "--------------------------------\n",
            "Train set: (385, 64)\n",
            "Validation set: (963, 64)\n",
            "Test set: (449, 64)\n",
            "--------------------------------\n",
            "Iteration: 73\n",
            "Accuracy rate is 88.418708 \n",
            "--------------------------------\n",
            "Train set: (390, 64)\n",
            "Validation set: (958, 64)\n",
            "Test set: (449, 64)\n",
            "--------------------------------\n",
            "Iteration: 74\n",
            "Accuracy rate is 88.864143 \n",
            "--------------------------------\n",
            "Train set: (395, 64)\n",
            "Validation set: (953, 64)\n",
            "Test set: (449, 64)\n",
            "--------------------------------\n",
            "Iteration: 75\n",
            "Accuracy rate is 89.086860 \n",
            "--------------------------------\n",
            "Train set: (400, 64)\n",
            "Validation set: (948, 64)\n",
            "Test set: (449, 64)\n",
            "--------------------------------\n",
            "Iteration: 76\n",
            "Accuracy rate is 89.086860 \n",
            "--------------------------------\n",
            "Train set: (405, 64)\n",
            "Validation set: (943, 64)\n",
            "Test set: (449, 64)\n",
            "--------------------------------\n",
            "Iteration: 77\n",
            "Accuracy rate is 88.195991 \n",
            "--------------------------------\n",
            "Train set: (410, 64)\n",
            "Validation set: (938, 64)\n",
            "Test set: (449, 64)\n",
            "--------------------------------\n",
            "Iteration: 78\n",
            "Accuracy rate is 89.309577 \n",
            "--------------------------------\n",
            "Train set: (415, 64)\n",
            "Validation set: (933, 64)\n",
            "Test set: (449, 64)\n",
            "--------------------------------\n",
            "Iteration: 79\n",
            "Accuracy rate is 88.195991 \n",
            "--------------------------------\n",
            "Train set: (420, 64)\n",
            "Validation set: (928, 64)\n",
            "Test set: (449, 64)\n",
            "--------------------------------\n",
            "Iteration: 80\n",
            "Accuracy rate is 88.864143 \n",
            "--------------------------------\n",
            "Train set: (425, 64)\n",
            "Validation set: (923, 64)\n",
            "Test set: (449, 64)\n",
            "--------------------------------\n",
            "Iteration: 81\n",
            "Accuracy rate is 89.309577 \n",
            "--------------------------------\n",
            "Train set: (430, 64)\n",
            "Validation set: (918, 64)\n",
            "Test set: (449, 64)\n",
            "--------------------------------\n",
            "Iteration: 82\n",
            "Accuracy rate is 88.641425 \n",
            "--------------------------------\n",
            "Train set: (435, 64)\n",
            "Validation set: (913, 64)\n",
            "Test set: (449, 64)\n",
            "--------------------------------\n",
            "Iteration: 83\n",
            "Accuracy rate is 89.309577 \n",
            "--------------------------------\n",
            "Train set: (440, 64)\n",
            "Validation set: (908, 64)\n",
            "Test set: (449, 64)\n",
            "--------------------------------\n",
            "Iteration: 84\n",
            "Accuracy rate is 89.755011 \n",
            "--------------------------------\n",
            "Train set: (445, 64)\n",
            "Validation set: (903, 64)\n",
            "Test set: (449, 64)\n",
            "--------------------------------\n",
            "Iteration: 85\n",
            "Accuracy rate is 89.086860 \n",
            "--------------------------------\n",
            "Train set: (450, 64)\n",
            "Validation set: (898, 64)\n",
            "Test set: (449, 64)\n",
            "--------------------------------\n",
            "Iteration: 86\n",
            "Accuracy rate is 88.864143 \n",
            "--------------------------------\n",
            "Train set: (455, 64)\n",
            "Validation set: (893, 64)\n",
            "Test set: (449, 64)\n",
            "--------------------------------\n",
            "Iteration: 87\n",
            "Accuracy rate is 89.086860 \n",
            "--------------------------------\n",
            "Train set: (460, 64)\n",
            "Validation set: (888, 64)\n",
            "Test set: (449, 64)\n",
            "--------------------------------\n",
            "Iteration: 88\n",
            "Accuracy rate is 88.864143 \n",
            "--------------------------------\n",
            "Train set: (465, 64)\n",
            "Validation set: (883, 64)\n",
            "Test set: (449, 64)\n",
            "--------------------------------\n",
            "Iteration: 89\n",
            "Accuracy rate is 88.418708 \n",
            "--------------------------------\n",
            "Train set: (470, 64)\n",
            "Validation set: (878, 64)\n",
            "Test set: (449, 64)\n",
            "--------------------------------\n",
            "Iteration: 90\n",
            "Accuracy rate is 89.309577 \n",
            "--------------------------------\n",
            "Train set: (475, 64)\n",
            "Validation set: (873, 64)\n",
            "Test set: (449, 64)\n",
            "--------------------------------\n",
            "Iteration: 91\n",
            "Accuracy rate is 89.309577 \n",
            "--------------------------------\n",
            "Train set: (480, 64)\n",
            "Validation set: (868, 64)\n",
            "Test set: (449, 64)\n",
            "--------------------------------\n",
            "Iteration: 92\n",
            "Accuracy rate is 89.086860 \n",
            "--------------------------------\n",
            "Train set: (485, 64)\n",
            "Validation set: (863, 64)\n",
            "Test set: (449, 64)\n",
            "--------------------------------\n",
            "Iteration: 93\n",
            "Accuracy rate is 89.086860 \n",
            "--------------------------------\n",
            "Train set: (490, 64)\n",
            "Validation set: (858, 64)\n",
            "Test set: (449, 64)\n",
            "--------------------------------\n",
            "Iteration: 94\n",
            "Accuracy rate is 89.755011 \n",
            "--------------------------------\n",
            "Train set: (495, 64)\n",
            "Validation set: (853, 64)\n",
            "Test set: (449, 64)\n",
            "--------------------------------\n",
            "Iteration: 95\n",
            "Accuracy rate is 88.195991 \n",
            "--------------------------------\n",
            "Train set: (500, 64)\n",
            "Validation set: (848, 64)\n",
            "Test set: (449, 64)\n",
            "--------------------------------\n",
            "Iteration: 96\n",
            "Accuracy rate is 89.309577 \n",
            "--------------------------------\n",
            "accuracies [41.87082405345212, 40.97995545657015, 52.78396436525612, 54.56570155902004, 56.792873051224944, 57.01559020044543, 60.57906458797328, 66.815144766147, 63.25167037861915, 65.25612472160356, 63.91982182628062, 69.26503340757239, 68.8195991091314, 69.93318485523386, 71.93763919821826, 72.16035634743875, 74.16481069042317, 78.61915367483296, 78.84187082405344, 79.28730512249443, 78.61915367483296, 80.62360801781738, 81.06904231625836, 83.07349665924276, 79.9554565701559, 81.9599109131403, 79.73273942093542, 80.17817371937639, 82.85077951002228, 81.51447661469933, 82.62806236080178, 82.85077951002228, 83.74164810690424, 85.07795100222717, 84.85523385300668, 83.51893095768375, 83.74164810690424, 84.63251670378618, 84.85523385300668, 82.85077951002228, 83.51893095768375, 85.74610244988864, 83.07349665924276, 83.51893095768375, 83.29621380846325, 85.96881959910914, 85.07795100222717, 84.4097995545657, 85.07795100222717, 83.96436525612472, 85.07795100222717, 85.07795100222717, 86.41425389755011, 86.8596881959911, 85.74610244988864, 86.19153674832963, 85.52338530066815, 85.74610244988864, 86.63697104677061, 85.74610244988864, 86.8596881959911, 86.41425389755011, 85.96881959910914, 85.96881959910914, 87.52783964365256, 88.19599109131403, 88.41870824053451, 89.30957683741649, 87.75055679287304, 89.97772828507794, 88.41870824053451, 88.41870824053451, 88.41870824053451, 88.8641425389755, 89.086859688196, 89.086859688196, 88.19599109131403, 89.30957683741649, 88.19599109131403, 88.8641425389755, 89.30957683741649, 88.64142538975501, 89.30957683741649, 89.75501113585747, 89.086859688196, 88.8641425389755, 89.086859688196, 88.8641425389755, 88.41870824053451, 89.30957683741649, 89.30957683741649, 89.086859688196, 89.086859688196, 89.75501113585747, 88.19599109131403, 89.30957683741649]\n",
            "nonactive_accuracies [65.03340757238307, 65.70155902004454, 65.70155902004454, 65.03340757238307, 63.02895322939867, 63.69710467706013, 65.25612472160356, 68.59688195991092, 70.15590200445433, 62.80623608017817, 65.03340757238307, 70.15590200445433, 65.25612472160356, 63.02895322939867, 61.69265033407573, 65.70155902004454, 63.02895322939867, 62.360801781737194, 65.25612472160356, 66.36971046770601, 66.14699331848553, 64.58797327394208, 63.474387527839646, 67.48329621380846, 66.14699331848553, 64.14253897550111, 64.14253897550111, 65.70155902004454, 66.36971046770601, 63.02895322939867, 64.58797327394208, 63.02895322939867, 61.915367483296215, 65.25612472160356, 65.70155902004454, 63.91982182628062, 64.58797327394208, 64.14253897550111, 63.474387527839646, 63.25167037861915, 67.70601336302894, 65.25612472160356, 63.25167037861915, 64.58797327394208, 64.58797327394208, 64.58797327394208, 64.81069042316258, 60.801781737193764, 66.36971046770601, 65.47884187082406, 65.47884187082406, 63.474387527839646, 65.47884187082406, 63.25167037861915, 64.3652561247216, 64.58797327394208, 65.25612472160356, 70.60133630289532, 62.80623608017817, 61.24721603563474, 65.92427616926503, 66.36971046770601, 61.02449888641426, 66.815144766147, 64.81069042316258, 66.815144766147, 59.46547884187082, 61.915367483296215, 65.70155902004454, 62.360801781737194, 63.69710467706013, 65.70155902004454, 64.14253897550111, 64.3652561247216, 64.14253897550111, 67.70601336302894, 65.70155902004454, 65.03340757238307, 62.58351893095768, 63.02895322939867, 65.03340757238307, 68.15144766146993, 65.03340757238307, 65.03340757238307, 65.03340757238307, 66.59242761692651, 64.81069042316258, 67.92873051224944, 66.815144766147, 67.03786191536749, 61.02449888641426, 63.474387527839646, 65.70155902004454, 65.47884187082406, 65.25612472160356, 62.80623608017817]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "metadata": {}
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyMfqalTRwiWuiIELJDbCQ7d",
      "mount_file_id": "1SZapm_bYNJDCJi8ECwmjrzaN8-1ruRgA",
      "name": "Logistic.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "5edc29c2ed010d6458d71a83433b383a96a8cbd3efe8531bc90c4b8a5b8bcec9"
    },
    "kernelspec": {
      "display_name": "Python 3.8.2 64-bit",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "metadata": {
      "interpreter": {
        "hash": "5edc29c2ed010d6458d71a83433b383a96a8cbd3efe8531bc90c4b8a5b8bcec9"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}