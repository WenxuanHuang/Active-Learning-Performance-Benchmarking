{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "source": [
        "print(__doc__)\n",
        "\n",
        "import os\n",
        "import time\n",
        "import json\n",
        "import pickle\n",
        "import math\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.mlab as mlab\n",
        "from scipy.special import expit\n",
        "from scipy import stats\n",
        "from pylab import rcParams\n",
        "import mplcursors\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.datasets import load_digits\n",
        "\n",
        "from sklearn.utils import check_random_state\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer\n",
        "from sklearn.pipeline import Pipeline, FeatureUnion\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import scale\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "\n",
        "from sklearn import linear_model\n",
        "from sklearn import neighbors\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.linear_model import RidgeCV, LassoCV, Ridge, Lasso\n",
        "from sklearn.svm import LinearSVC, SVC\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.utils import check_random_state\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics.pairwise import euclidean_distances\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.mixture import GaussianMixture\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import pairwise_distances_argmin_min\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import average_precision_score\n",
        "\n",
        "\n",
        "# pd.options.display.max_rows = 20\n",
        "pd.options.display.float_format = \"{:.1f}\".format\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Automatically created module for IPython interactive environment\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ioi13nGDPDvQ",
        "outputId": "4763f7b3-6c5b-45cb-f411-fd7c6ea8b38f"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "source": [
        "def fetch_data_corona():\n",
        "    data = pd.read_csv(\"https://raw.githubusercontent.com/WenxuanHuang/ML-for-COVID-19-dataset/main/all_training.csv\", sep=',')\n",
        "    # Column selection\n",
        "    df = data.iloc[:,np.r_[3:34]].copy()\n",
        "    # define row and column index\n",
        "    col = df.columns\n",
        "    row = [i for i in range(df.shape[0])]\n",
        "    # define imputer\n",
        "    imputer = IterativeImputer(estimator=linear_model.BayesianRidge(), n_nearest_features=None, imputation_order='ascending')\n",
        "    # fit on the dataset\n",
        "    imputer.fit(df)\n",
        "    # transform the dataset\n",
        "    df_imputed = imputer.transform(df)\n",
        "    # convert back to pandas dataframe and rename back to df_normalized\n",
        "    df = pd.DataFrame(data=df_imputed, index=row, columns=col)\n",
        "    X = df\n",
        "    y = data.target    \n",
        "    # Recursive feature elimination\n",
        "    rdmreg = RandomForestClassifier(n_estimators=100)\n",
        "    # Define the method\n",
        "    rfe = RFE(estimator=rdmreg, n_features_to_select=10)\n",
        "    # Fit the model\n",
        "    rfe = rfe.fit(X, y.values.ravel())\n",
        "    print(rfe.support_)\n",
        "    # Drop columns that failed RFE test\n",
        "    col = df.columns[rfe.support_]\n",
        "    X = X[col]\n",
        "    X = X.to_numpy()\n",
        "    print ('df:', X.shape, y.shape)\n",
        "    return (X, y)\n"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "source": [
        "def fetch_data_iris():\n",
        "    iris = load_iris()\n",
        "    X = iris.data.astype('float64')\n",
        "    y = iris.target\n",
        "    # print ('Dataset : ', X.shape, y.shape)\n",
        "    return (X, y)\n",
        "\n",
        "def fetch_data_mnist():\n",
        "    mnist = load_digits()\n",
        "    X = mnist.data.astype('float64')\n",
        "    y = mnist.target\n",
        "    # print ('Dataset : ', X.shape, y.shape)\n",
        "    return (X, y)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "source": [
        "class BaseModel(object):\n",
        "\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def fit_predict(self):\n",
        "        pass\n",
        "\n",
        "\n",
        "class SvmModel(BaseModel):\n",
        "\n",
        "    model_type = 'Support Vector Machine with linear Kernel'\n",
        "    def fit_predict(self, X_train, y_train, X_val, X_test, c_weight):\n",
        "        print ('training svm...')\n",
        "        self.classifier = SVC(\n",
        "            C=1, \n",
        "            kernel='linear', \n",
        "            probability=True,\n",
        "            class_weight=c_weight\n",
        "            )\n",
        "        self.classifier.fit(X_train, y_train)\n",
        "        self.test_y_predicted = self.classifier.predict(X_test)\n",
        "        self.val_y_predicted = self.classifier.predict(X_val)\n",
        "        return (X_train, X_val, X_test, self.val_y_predicted,\n",
        "                self.test_y_predicted)\n",
        "\n",
        "class LogModel(BaseModel):\n",
        "\n",
        "    model_type = 'Logistic Regression' \n",
        "    def fit_predict(self, X_train, y_train, X_val, X_test, c_weight):\n",
        "        # print ('training logistic regression...')\n",
        "        # train_samples = X_train.shape[0]\n",
        "        self.classifier = LogisticRegression(\n",
        "            # C=50. / train_samples,\n",
        "            penalty='l1',\n",
        "            solver='liblinear',\n",
        "            tol=0.1,\n",
        "            class_weight=c_weight\n",
        "            )\n",
        "        self.classifier.fit(X_train, y_train)\n",
        "        self.test_y_predicted = self.classifier.predict(X_test)\n",
        "        self.val_y_predicted = self.classifier.predict(X_val)\n",
        "        return (X_train, X_val, X_test, self.val_y_predicted,\n",
        "                self.test_y_predicted)\n",
        "\n",
        "class RfModel(BaseModel):\n",
        "\n",
        "    model_type = 'Random Forest'\n",
        "    def fit_predict(self, X_train, y_train, X_val, X_test, c_weight):\n",
        "        print ('training random forest...')\n",
        "        self.classifier = RandomForestClassifier(\n",
        "            n_estimators=500, \n",
        "            class_weight=c_weight, \n",
        "            n_jobs=-1\n",
        "            )\n",
        "        self.classifier.fit(X_train, y_train)\n",
        "        self.test_y_predicted = self.classifier.predict(X_test)\n",
        "        self.val_y_predicted = self.classifier.predict(X_val)\n",
        "        return (X_train, X_val, X_test, self.val_y_predicted, self.test_y_predicted)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "source": [
        "class TrainModel:\n",
        "\n",
        "    def __init__(self, model_object):        \n",
        "        self.accuracies = []\n",
        "        self.model_object = model_object()        \n",
        "\n",
        "    def print_model_type(self):\n",
        "        print (self.model_object.model_type)\n",
        "\n",
        "    # we train normally and use the probabilities to select the most uncertain samples\n",
        "    def train(self, X_train, y_train, X_val, X_test, c_weight):\n",
        "        # print ('Train set:', X_train.shape)\n",
        "        # print ('Validation set:', X_val.shape)\n",
        "        # print ('Test set:', X_test.shape)\n",
        "        t0 = time.time()\n",
        "        (X_train, X_val, X_test, self.val_y_predicted,\n",
        "         self.test_y_predicted) = \\\n",
        "            self.model_object.fit_predict(X_train, y_train, X_val, X_test, c_weight)\n",
        "        self.run_time = time.time() - t0\n",
        "        return (X_train, X_val, X_test)\n",
        "\n",
        "    # we want accuracy only for the test set\n",
        "    def get_test_accuracy(self, i, y_test):\n",
        "        classif_rate = np.mean(self.test_y_predicted.ravel() == y_test.ravel()) * 100\n",
        "        self.accuracies.append(classif_rate)               \n",
        "        print('--------------------------------')\n",
        "        print('Iteration:',i)\n",
        "        # print('--------------------------------')\n",
        "        # print('y-test set:',y_test.shape)\n",
        "        # print('Training run in %.3f s' % self.run_time,'\\n')\n",
        "        print(\"Accuracy rate is %f \" % (classif_rate))    \n",
        "        # print(\"Classification report for %s:\\n%s\\n\" % (self.model_object.classifier, metrics.classification_report(y_test, self.test_y_predicted)))\n",
        "        # print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(y_test, self.test_y_predicted))\n",
        "        print('--------------------------------')\n"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "source": [
        "class Normalize(object):\n",
        "    \n",
        "    def normalize(self, X_train, X_val, X_test):\n",
        "        self.scaler = RobustScaler()\n",
        "        X_train = self.scaler.fit_transform(X_train)\n",
        "        X_val   = self.scaler.transform(X_val)\n",
        "        X_test  = self.scaler.transform(X_test)\n",
        "        return (X_train, X_val, X_test) \n",
        "    \n",
        "    def inverse(self, X_train, X_val, X_test):\n",
        "        X_train = self.scaler.inverse_transform(X_train)\n",
        "        X_val   = self.scaler.inverse_transform(X_val)\n",
        "        X_test  = self.scaler.inverse_transform(X_test)\n",
        "        return (X_train, X_val, X_test) "
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "source": [
        "def get_random_samples(initial_samples, X_train_full, y_train_full):\n",
        "\n",
        "    permutation = np.random.choice(len(X_train_full),initial_samples,replace=False)\n",
        "    X_train = X_train_full[permutation]\n",
        "    y_train = y_train_full[permutation]\n",
        "    X_train = X_train.reshape((X_train.shape[0], -1))\n",
        "\n",
        "    return (permutation, X_train, y_train)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "source": [
        "def log_loss(probs):\n",
        "\n",
        "    loss = 0\n",
        "    for i in range(len(probs)):\n",
        "        label = 0\n",
        "        for prob in probs[i]:\n",
        "            loss -= (label*np.log(prob+np.finfo(float).eps))\n",
        "            label += 1\n",
        "    ll = loss/(len(probs)*1.)\n",
        "\n",
        "    return ll"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "source": [
        "def mse_loss(probs):\n",
        "\n",
        "    loss = 0\n",
        "    "
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "source": [
        "class TheAlgorithm(object):\n",
        "\n",
        "    accuracies = []\n",
        "\n",
        "    def __init__(self, step, model_object):\n",
        "        self.step = step\n",
        "        self.model_object = model_object\n",
        "        \n",
        "    def run(self, X_train_full, y_train_full, X_test, y_test, initial_queried, max_queried):\n",
        "\n",
        "        (permutation, X_train, y_train) = get_random_samples(initial_queried, X_train_full, y_train_full)\n",
        "        self.queried = initial_queried\n",
        "\n",
        "        X_val = np.array([])\n",
        "        y_val = np.array([])\n",
        "        X_val = np.copy(X_train_full)\n",
        "        X_val = np.delete(X_val, permutation, axis=0)\n",
        "        y_val = np.copy(y_train_full)\n",
        "        y_val = np.delete(y_val, permutation, axis=0)\n",
        "\n",
        "        normalizer = Normalize()\n",
        "        X_train, X_val, X_test = normalizer.normalize(X_train, X_val, X_test)\n",
        "           \n",
        "        self.clf_model = TrainModel(self.model_object)\n",
        "        (X_train, X_val, X_test) = self.clf_model.train(X_train, y_train, X_val, X_test, 'balanced')\n",
        "        active_iteration = 1\n",
        "        self.clf_model.get_test_accuracy(1, y_test)\n",
        "\n",
        "        while self.queried <= max_queried-self.step:\n",
        "\n",
        "            active_iteration += 1\n",
        "            self.queried += self.step\n",
        "            (mc_permutation, X_subset, y_subset) = \\\n",
        "                get_random_samples(10, X_val, y_val) # 100 is the subset size\n",
        "            # print('Indexes in the subset for X_val:', mc_permutation)\n",
        "            # print ('Subset:', X_subset.shape, y_subset.shape, monte_carlo_permutation.shape)\n",
        "            # print ('Train:', X_train.shape, y_train.shape, permutation.shape)\n",
        "\n",
        "            cand_probs = self.clf_model.model_object.classifier.predict_proba(X_subset)\n",
        "            # print(\"structure of cand_probs:\", cand_probs)\n",
        "\n",
        "            utils = []\n",
        "\n",
        "            for i in range(len(X_subset)):\n",
        "                new_train_X = X_train\n",
        "                row_subset = X_subset[i]\n",
        "                new_train_X = np.append(new_train_X, [row_subset], axis=0)\n",
        "                util = 0\n",
        "                new_label_y = np.random.randint(0, 9, size=len(X_subset))\n",
        "                # new_label_y = np.random.choice([0, 1], size=len(X_subset),)\n",
        "                # print(\"Newly assigned labels:\", new_label_y)\n",
        "                # To-do: random.randint is too inefficient\n",
        "                for label in new_label_y:\n",
        "                    new_train_y = y_train\n",
        "                    new_train_y = np.append(new_train_y, label)\n",
        "                    # print('Monte_carlo training set X:', new_train_X)\n",
        "                    # print('Monte_carlo training set y:', new_train_y)\n",
        "                    new_classifier = self.clf_model.model_object.classifier\n",
        "                    new_classifier.fit(new_train_X, new_train_y)\n",
        "                    new_probs = new_classifier.predict_proba(X_subset)\n",
        "                    # print(\"structure of new_probs:\", cand_probs)\n",
        "                    util += cand_probs[i][label] * log_loss(new_probs)\n",
        "                    # need to check validity\n",
        "\n",
        "                utils.append(util)\n",
        "                \n",
        "            uis = np.argsort(utils)\n",
        "            # need to check validity\n",
        "            # print ('Monte-carlo selected indexes:', uis)\n",
        "  \n",
        "\n",
        "            X_uncertain = [X_subset[i] for i in uis[:self.step]]\n",
        "            y_uncertain = [y_subset[i] for i in uis[:self.step]]\n",
        "            uncertain_samples = mc_permutation[uis[:self.step]]\n",
        "            # print ('Monte-carlo selected indexes:', uncertain_samples)\n",
        "            # print ('Monte-carlo selected samples:', X_uncertain)\n",
        "            # print ('Monte-carlo selected outcomes:', y_uncertain)\n",
        "\n",
        "            X_train, X_val, X_test = normalizer.inverse(X_train, X_val, X_test)   \n",
        "            X_train = np.concatenate((X_train, np.array(X_uncertain)))\n",
        "            y_train = np.concatenate((y_train, np.array(y_uncertain)))\n",
        "\n",
        "            X_val = np.delete(X_val, uncertain_samples, axis=0)\n",
        "            y_val = np.delete(y_val, uncertain_samples, axis=0)\n",
        "\n",
        "            normalizer = Normalize()\n",
        "            X_train, X_val, X_test = normalizer.normalize(X_train, X_val, X_test)               \n",
        "\n",
        "            (X_train, X_val, X_test) = self.clf_model.train(X_train, y_train, X_val, X_test, 'balanced')\n",
        "            self.clf_model.get_test_accuracy(active_iteration, y_test)\n",
        "\n",
        "        return self.clf_model.accuracies"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "source": [
        "def pool_experiment(model,max_queried,initial_queried,step):\n",
        "\n",
        "    (X, y) = fetch_data_mnist()\n",
        "\n",
        "    print(\"min/max:\",min(y),max(y))\n",
        "\n",
        "    kf = KFold(n_splits=4)\n",
        "    for train_index, test_index in kf.split(X):\n",
        "        X_train_full, X_test = X[train_index], X[test_index]\n",
        "        y_train_full, y_test = y[train_index], y[test_index]\n",
        "        \n",
        "    act_alg = TheAlgorithm(step, model)\n",
        "    accuracies = act_alg.run(X_train_full,y_train_full,X_test,y_test,initial_queried,max_queried)\n",
        "\n",
        "    (permutation, X_train_selected, y_train_selected) = get_random_samples(initial_queried, X_train_full, y_train_full)\n",
        "    original_accuracies=[]\n",
        "    classifier_original = LogisticRegression(\n",
        "            penalty='l1',\n",
        "            solver='liblinear',\n",
        "            tol=0.1,\n",
        "            class_weight='balanced')\n",
        "    x_axis = []\n",
        "    for i in range(initial_queried-1,max_queried,step):\n",
        "        classifier_original.fit(X_train_selected[:i+1], y_train_selected[:i+1])\n",
        "        y_pred_original = classifier_original.predict(X_test)\n",
        "        original_accuracies.append(accuracy_score(y_test, y_pred_original)*100)\n",
        "        x_axis.append(i+1)\n",
        "    print(\"accuracies\",accuracies)\n",
        "    print(\"nonactive_accuracies\",original_accuracies)\n",
        "    plt.plot(x_axis, accuracies, 'r',label='active')\n",
        "    plt.plot(x_axis, original_accuracies, 'blue',label='non-active')\n",
        "    plt.legend()\n",
        "    plt.xlabel('Sample Size')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.show()"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "source": [
        "pool_experiment(LogModel,500,25,5)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "min/max: 0 9\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "Accuracy rate is 41.425390 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "Accuracy rate is 42.316258 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 3\n",
            "Accuracy rate is 46.325167 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 4\n",
            "Accuracy rate is 51.893096 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 5\n",
            "Accuracy rate is 54.342984 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 6\n",
            "Accuracy rate is 59.688196 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 7\n",
            "Accuracy rate is 61.247216 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 8\n",
            "Accuracy rate is 64.810690 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 9\n",
            "Accuracy rate is 65.033408 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 10\n",
            "Accuracy rate is 65.478842 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 11\n",
            "Accuracy rate is 67.928731 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 12\n",
            "Accuracy rate is 73.942094 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 13\n",
            "Accuracy rate is 74.610245 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 14\n",
            "Accuracy rate is 76.169265 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 15\n",
            "Accuracy rate is 76.391982 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 16\n",
            "Accuracy rate is 77.282851 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 17\n",
            "Accuracy rate is 77.728285 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 18\n",
            "Accuracy rate is 76.614699 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 19\n",
            "Accuracy rate is 76.391982 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 20\n",
            "Accuracy rate is 83.518931 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 21\n",
            "Accuracy rate is 79.510022 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 22\n",
            "Accuracy rate is 82.850780 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 23\n",
            "Accuracy rate is 82.405345 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 24\n",
            "Accuracy rate is 82.405345 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 25\n",
            "Accuracy rate is 81.959911 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 26\n",
            "Accuracy rate is 82.850780 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 27\n",
            "Accuracy rate is 84.409800 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 28\n",
            "Accuracy rate is 85.077951 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 29\n",
            "Accuracy rate is 82.850780 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 30\n",
            "Accuracy rate is 83.964365 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 31\n",
            "Accuracy rate is 83.296214 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 32\n",
            "Accuracy rate is 83.741648 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 33\n",
            "Accuracy rate is 84.187082 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 34\n",
            "Accuracy rate is 83.518931 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 35\n",
            "Accuracy rate is 85.077951 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 36\n",
            "Accuracy rate is 84.409800 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 37\n",
            "Accuracy rate is 84.409800 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 38\n",
            "Accuracy rate is 84.855234 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 39\n",
            "Accuracy rate is 85.968820 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 40\n",
            "Accuracy rate is 86.636971 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 41\n",
            "Accuracy rate is 85.300668 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 42\n",
            "Accuracy rate is 86.859688 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 43\n",
            "Accuracy rate is 86.191537 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 44\n",
            "Accuracy rate is 87.527840 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 45\n",
            "Accuracy rate is 86.414254 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 46\n",
            "Accuracy rate is 86.636971 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 47\n",
            "Accuracy rate is 85.968820 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 48\n",
            "Accuracy rate is 85.077951 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 49\n",
            "Accuracy rate is 85.300668 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 50\n",
            "Accuracy rate is 86.636971 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 51\n",
            "Accuracy rate is 86.859688 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 52\n",
            "Accuracy rate is 86.636971 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 53\n",
            "Accuracy rate is 86.191537 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 54\n",
            "Accuracy rate is 86.636971 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 55\n",
            "Accuracy rate is 86.859688 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 56\n",
            "Accuracy rate is 85.968820 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 57\n",
            "Accuracy rate is 87.305122 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 58\n",
            "Accuracy rate is 87.750557 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 59\n",
            "Accuracy rate is 88.418708 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 60\n",
            "Accuracy rate is 86.636971 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 61\n",
            "Accuracy rate is 87.973274 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 62\n",
            "Accuracy rate is 87.305122 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 63\n",
            "Accuracy rate is 88.195991 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 64\n",
            "Accuracy rate is 85.523385 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 65\n",
            "Accuracy rate is 86.636971 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 66\n",
            "Accuracy rate is 87.527840 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 67\n",
            "Accuracy rate is 87.305122 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 68\n",
            "Accuracy rate is 87.082405 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 69\n",
            "Accuracy rate is 87.973274 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 70\n",
            "Accuracy rate is 87.527840 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 71\n",
            "Accuracy rate is 86.636971 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 72\n",
            "Accuracy rate is 86.859688 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 73\n",
            "Accuracy rate is 87.973274 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 74\n",
            "Accuracy rate is 87.082405 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 75\n",
            "Accuracy rate is 86.636971 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 76\n",
            "Accuracy rate is 87.527840 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 77\n",
            "Accuracy rate is 87.305122 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 78\n",
            "Accuracy rate is 87.527840 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 79\n",
            "Accuracy rate is 87.527840 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 80\n",
            "Accuracy rate is 88.641425 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 81\n",
            "Accuracy rate is 88.864143 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 82\n",
            "Accuracy rate is 87.527840 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 83\n",
            "Accuracy rate is 89.755011 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 84\n",
            "Accuracy rate is 88.195991 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 85\n",
            "Accuracy rate is 88.195991 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 86\n",
            "Accuracy rate is 88.864143 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 87\n",
            "Accuracy rate is 88.418708 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 88\n",
            "Accuracy rate is 88.418708 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 89\n",
            "Accuracy rate is 88.641425 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 90\n",
            "Accuracy rate is 88.864143 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 91\n",
            "Accuracy rate is 88.864143 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 92\n",
            "Accuracy rate is 88.418708 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 93\n",
            "Accuracy rate is 87.750557 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 94\n",
            "Accuracy rate is 88.864143 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 95\n",
            "Accuracy rate is 88.864143 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 96\n",
            "Accuracy rate is 88.195991 \n",
            "--------------------------------\n",
            "accuracies [41.42538975501114, 42.31625835189309, 46.32516703786192, 51.89309576837417, 54.342984409799556, 59.68819599109132, 61.24721603563474, 64.81069042316258, 65.03340757238307, 65.47884187082406, 67.92873051224944, 73.94209354120267, 74.61024498886414, 76.16926503340757, 76.39198218262806, 77.28285077951003, 77.728285077951, 76.61469933184856, 76.39198218262806, 83.51893095768375, 79.51002227171492, 82.85077951002228, 82.40534521158129, 82.40534521158129, 81.9599109131403, 82.85077951002228, 84.4097995545657, 85.07795100222717, 82.85077951002228, 83.96436525612472, 83.29621380846325, 83.74164810690424, 84.18708240534521, 83.51893095768375, 85.07795100222717, 84.4097995545657, 84.4097995545657, 84.85523385300668, 85.96881959910914, 86.63697104677061, 85.30066815144765, 86.8596881959911, 86.19153674832963, 87.52783964365256, 86.41425389755011, 86.63697104677061, 85.96881959910914, 85.07795100222717, 85.30066815144765, 86.63697104677061, 86.8596881959911, 86.63697104677061, 86.19153674832963, 86.63697104677061, 86.8596881959911, 85.96881959910914, 87.30512249443207, 87.75055679287304, 88.41870824053451, 86.63697104677061, 87.97327394209354, 87.30512249443207, 88.19599109131403, 85.52338530066815, 86.63697104677061, 87.52783964365256, 87.30512249443207, 87.08240534521158, 87.97327394209354, 87.52783964365256, 86.63697104677061, 86.8596881959911, 87.97327394209354, 87.08240534521158, 86.63697104677061, 87.52783964365256, 87.30512249443207, 87.52783964365256, 87.52783964365256, 88.64142538975501, 88.8641425389755, 87.52783964365256, 89.75501113585747, 88.19599109131403, 88.19599109131403, 88.8641425389755, 88.41870824053451, 88.41870824053451, 88.64142538975501, 88.8641425389755, 88.8641425389755, 88.41870824053451, 87.75055679287304, 88.8641425389755, 88.8641425389755, 88.19599109131403]\n",
            "nonactive_accuracies [67.70601336302894, 71.49220489977728, 69.04231625835189, 68.15144766146993, 69.48775055679288, 69.93318485523386, 67.48329621380846, 67.92873051224944, 70.15590200445433, 70.60133630289532, 67.26057906458797, 69.93318485523386, 68.8195991091314, 66.14699331848553, 65.03340757238307, 66.36971046770601, 67.03786191536749, 71.26948775055679, 70.8240534521158, 67.03786191536749, 73.05122494432071, 66.59242761692651, 70.37861915367483, 69.26503340757239, 65.47884187082406, 67.92873051224944, 65.47884187082406, 67.03786191536749, 72.60579064587974, 68.37416481069042, 68.59688195991092, 69.93318485523386, 68.8195991091314, 69.48775055679288, 70.60133630289532, 69.71046770601336, 70.37861915367483, 65.25612472160356, 66.14699331848553, 69.71046770601336, 66.59242761692651, 71.93763919821826, 70.60133630289532, 69.48775055679288, 67.70601336302894, 69.04231625835189, 70.15590200445433, 69.26503340757239, 69.71046770601336, 69.04231625835189, 69.93318485523386, 68.8195991091314, 67.48329621380846, 69.93318485523386, 69.48775055679288, 70.37861915367483, 70.37861915367483, 66.815144766147, 69.26503340757239, 66.36971046770601, 66.36971046770601, 66.815144766147, 70.37861915367483, 69.93318485523386, 66.59242761692651, 68.8195991091314, 71.71492204899778, 69.48775055679288, 68.37416481069042, 69.71046770601336, 69.48775055679288, 69.26503340757239, 69.26503340757239, 69.48775055679288, 64.81069042316258, 67.48329621380846, 71.26948775055679, 67.70601336302894, 68.59688195991092, 69.26503340757239, 66.815144766147, 68.37416481069042, 71.93763919821826, 66.36971046770601, 67.92873051224944, 67.03786191536749, 73.4966592427617, 66.36971046770601, 69.04231625835189, 68.8195991091314, 69.71046770601336, 68.8195991091314, 67.92873051224944, 69.04231625835189, 64.58797327394208, 66.815144766147]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEGCAYAAABiq/5QAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Z1A+gAAAACXBIWXMAAAsTAAALEwEAmpwYAABDrklEQVR4nO2dd3gUVffHv4dQQy+h994JEKQqCALSBEOzg6KIr2IF5ffaQKyggqCC+IJgD1IEERGkqEgNvfcWCBCQhJae8/vjzLAlu8km2ZLsns/z7DM7d+7MnNmd+c6Zc++cS8wMRVEUJXDI52sDFEVRFO+iwq8oihJgqPAriqIEGCr8iqIoAYYKv6IoSoCR39cGuEK5cuW4Zs2avjZDURQlT7Ft27ZLzBxiX54nhL9mzZqIjIz0tRmKoih5CiI65ahcQz2KoigBhgq/oihKgKHCryiKEmCo8CuKogQYHhV+InqOiPYS0T4iet4oK0NEq4joiDEt7UkbFEVRFFs8JvxE1BTAEwBuA9ACQF8iqgtgHIDVzFwPwGpjXlEURfESnvT4GwHYzMw3mTkFwJ8AwgH0BzDPqDMPwAAP2qAoiqLY4Unh3wvgdiIqS0TBAHoDqAagAjNHG3XOA6jgaGUiGklEkUQUGRMT40EzFUUJOCIigJMnfW2Fz/CY8DPzAQAfAFgJYAWAnQBS7eowAIcDAjDzLGYOY+awkJB0L54piqJkj+PHgfvuA5580teW+AyPNu4y82xmbs3MdwC4AuAwgAtEVAkAjOlFT9qgKIpiww8/yHTlSmDDBt/a4iM83aunvDGtDonvfw9gKYBhRpVhAJZ40gZFUZRbMAPffQe0aQOULw+MH+9ri3yCp/vxLySi/QB+AfA0M8cCeB9AdyI6AuAuY15RFMU9XLgAzJsn4Zw77gD+/deybPdu4MAB4LHHgJdfBlatAv75x/F2vv0WaN8e+OknuWFkxLFjwGefAX37AnXqWD4tWwI//pjx+q+8YrtOjx7A2bNZP+6swMy5/tO6dWtWFMUJaWnyUZhffZVZZJa5QgXmfPmYn3nGsvzll5nz52eOiWG+fp25fHnmu+6y3UZaGvPrr8s2iheXaadOzJs3M9+4IZ+4OOYVK5iffZa5Xj3LPuvUYb7/fuaHHpJP8+ZS3r69rG/Pd9/J8rvukvoPPshcrBhz5crM27fn+OcAEMkONNXnou7KR4VfUZywZ48Iz7hxWVsvIcEz9viSFStE0u67T0QzNZX56adF/Hftkvlq1Zj79LGs89FHss7PPzMfP8589KisDzA/9hhzfDzzrFlygzDF3fpTuDBzr17Mn3zCfPhweptSUphnz2auWFHqv/GG5SZ98iRzyZLMHTtKPZNdu8TOokWZly7N0U+iwq8o/saKFRaPtEgR5kuXbJenpDCfPZt+vT//ZA4OZv76a/fYcfGieMBZITraVuxySkyMiGvjxsw3b1rKL19mLlOGuXNnOW5AvGyTGzfkycBe0N9/3/YpKi6O+fPPmT/4wPL57TfbfWXE1avMw4fLtu+/X/bbubN498ePp69/7hxz69bMRMwbN2bnF2FmFX5F8R/S0pg//ZQ5KIi5RQsRIID5vfds640eLXU+/9xStm8fc6lSUr9nz5zbcvCgCGuZMszTpjEnJWW+ztatzAUKMA8Y4B7xT0tjDg+Xbe7YkX75jBlyvA0ayA3v2jXb5Xv2MM+da/ls2JBzm5zZ+d57YkvlyjL96ivn9a9fZ54+PUdhPBV+RXHGli3iteYFtm6VeDPA3LevRcTuuou5ShWL8O7cKSGOkBCp+8ILzGfOMFevLp7x4MHMhQqJuDjj0iXm+fOZz593vPz8eeZatWQfXbvKfho2ZP7jD+fbvH6duX598XQBuTk5E7YrV5gjItI/tVy4wPzjj8xffCGfMWNkW5MmOd5OSgpzaKjF2/Y18+dLiGjQII+3zajwK4oj9uwRrzg0lDkx0dfWOOfaNeZhw+SSLV9e4s7W3vKvv8qy778XMbnjDuayZeWG9uyzsqxoUfls2ybiDDAvWeJ8f61b863QR6tW0nC6fj1zcrIIeFiYhJg2b5Z9Ll0q7Q0FCjCvXu14u089JdtbvVpuRgDzhx+mr3fzJnOHDpb9t2jBPGqU7JOI04VmevbM+Olh/XrmggUzvil5k5gY94a6nKDCryj2pKWJpxocLJfCK6/42iLnvPCCCN7LLzuOp6emSiijTRvmH36Q45k507J8+nS5YSxfLvOJidI+MHJk+m0lJzP37i1PDDNnMr/zjjxlBAXJdkuVEs8+X770N47YWOamTZlLlGDevdt22bJlsv5LL1lsHjRIymbMkHlmEcTwcDne6dMl3t65s9xkOnZknjhRnnzOnrV8zHUzIj4+8zp+hgq/EticPs384ou2YYuFC+US+Owz5ieeEKFZty7n+0pNlfDRW28xP/mkhCX+/TfjdRITxQseO1Zi5dbs2yddEJ94IuNtfP65HE/JkswtW6b3KO3DCuHhzFWr2panpcl+7G8czBJ6+ekn5hEjpNviF184tuP0aYlhV6ki4aUTJ8S28uWle6N1j6L4eEuYqE0b5n/+YX7uOZn/+OOMj1fJFBV+xf9JTpbucvbCySyxXYC5Rg3mvXsllFCjhghRcrKENurWlRh4VJSELZ56SoT7yhXXbZg+3RJXByyx7Hz5mG+/PX2o4dgx5gcekBAMYAljfPqpLE9Lk/h9yZKZt0Ncv85curSsv3595rbOni11d+60lE2aJGX/93+uH7Mjdu6UJwrzaQqQ33fv3vR1U1OZ582zNHgCIv5KjlHhV/ybuDjpTw1ISMI6zLBvnwjq4MHSsFmihCXEYO3hb9pkCWcAIlr58zM3auS4y509+/dL/dtvZ/7mG2mETE4WL/a11+RGAzD368ccGSlhm4IFZT8jR0pf8itXZLkZRlm8WNb55BPXfoe5cyU04wrR0bLtt9+W+S1bxH53NTquWSM9d6ZMkd4/mW3z+nXmCRPkycwL8e9AQIVf8V9On2Zu1kxEe/Jk8XrvvNMiNEOHiucdEyN1zbcphw5Nv62vv5ZeIn/8ISGJtWtleyEhGXfzS0tj7tFDPPMLFxzXiY+XeLXZ9x6Qvt32vVauX5ewR5Ei4gU3aeJaN8ns0Lq1vFVq9rapVi3zsJSSZ1DhV/yTS5dErEqUYP79dyn77DM5tX/6SUILRLahi6tXJaThTKDtOXhQYtqFCjlvA/j5Z9nn1KmZb+/8eenJEhnpvM6FC8y1a8s2PdkT5Y035PcZOlSma9Z4bl+K13Em/CTLcjdhYWEcGRnpazOU3AYzMGgQ8Msvkl43LEzKU1OB1q2BK1eA0FBgzRoZdKNs2ezv69IlSfgVHS1JvRo3tixLSJD54GBgxw6gQIGcHJWFM2eA7duB/v3dsz1HbNkCtG0r38eOBSZN8ty+FK9DRNuYOcy+PL8vjFEUtzB3LrBokYhVmNW5HRQETJsGdO4MnD4N/Pe/ORN9AChXDli+XLI19uoFbNwIVK4MpKQAb78NnDgB/PGH+0QfAKpVk48nCQuT4wgJASZO9Oy+lFyDevxK1klJAf78E7jzTiCfmzN7Hz4MEAH16mVc79gx8ebDwkRwg4LS13n4YRHrw4dzLvwm27eL51+nDtCwoaT1vXIFGDwYmD/fPfvwNseOAaVKue83UnINzjx+T+fjV/yNq1eBe+4B7rpLcp67k/h4oEsXoEUL8eQzsuHhh0Xs581zLPqALDtyxL2C1qqV5Gffvx/4+29gwAAR/K+/dt8+vE2dOir6AYYKv+I6p08DnTrJkHWlS8tIRu5k1iyJoVevDgwcKCEc6yfS1FSpU7euhFq++ELqOiNfPqBMGffaCEio59IlGSxjzhzx9gsXdv9+FMVDaIxfcY2DByW0c/Mm8Ntv0sD51lvAuXMSI84p8fHA+++Lx798OTB8uIxMtHIlUKGC1Nm1C9i3T24+y5fbxvW9TcmSvtu3ouQQ9fgV1xg7VnqvbNgAdO8O3H+/eOMREVnf1p9/yrB4W7ZYymbOBM6fByZMAIoUkQGxJ0yQp4wtW+RTuLCEWf76y7eiryh5HG3cVTInMlIGp377beDVVy3lYWHSELt1q8wzyw2CCHj33fQ9XI4dk3FOzfh94cLAN98AvXsDtWsDTZoAq1d755gUJQDQxl0l+4wfL7Hy0aNtyx94QG4Khw/L/DffAB99BHz4IdCnDxAXJ+VxcSL4jRsDv/8u3QZPnZKG0sGDRfgvXJD9KIricVT4/Y377wfeeMN929uyBfj1V+Cll4ASJWyXDR0q3v0PP0g/9meeka6OX34JrF0LdOgATJkiXTMnTxbbDh8GXntNGmVXr5aQz59/At26Abff7j67FUVxioZ6/I1y5YBKlYA9e9yzvT59gE2b5M3X4sXTL+/aFYiKAsqXl33u3g3UqCHCHx4OxMaKoE+ZIm/T2pOWBvz4ozTYZtRDR1GULKNv7gYC8fHA5cvyQtHNm5JCwCQlBTh6VF46cpXNm6X3zLvvOhZ9QMI9Tzwh/eW//VZEH5AeQNu2SXmPHvJk4Ih8+WQbiqJ4DQ31+BNnz8o0LS29xz9jBtCokcTTDxzIfFtxccDjj8uLPc8847zewIFyg7nvvvQCXrs20LOnc9FXFMUnqMfvT0RFWb5v325JvgVIPL10aemO2awZMGIE0KCBLMuXT0I6ZpqEpCQJ0xw8CKxY4dzbB2Sb+/dLX34VeEXJE6jw+xNnzsiUSITfhBlYv17SC3zwgfSe+eILeRPW5OWXxbN/7TXguecko+W8edLomhlmeEdRlDyBhnr8CdPjb9/eVvgPHZLYf6dOkoXxs8+Aa9cknBMXJ10rhw0Dpk4FqlSRWP3EicAjj/jkMBRF8Swq/P5EVJSEXm6/XWL8SUlSvn69TDt1stQtUkS6Z5YoIb1pvvxSbhZdu0rXTesXtRRF8Ss01ONPREVJ/vZWrYDkZMlr07KlCH9ISOapjkNDpc++oih+jXr8/kRUFFC1qgg/YAn3rF8v3r42viqKAhV+/8IU/tq1JYSzbZukOT52zDbMoyhKQKPC7y8kJgIXL4rw58snIZ7t2yV9MqDCryjKLTwq/ET0AhHtI6K9RPQDERUmolpEtJmIjhJRBBEV9KQNAYP58lbVqjJt1Ury169bJw25LVv6zDRFUXIXHhN+IqoC4FkAYczcFEAQgPsAfABgCjPXBXAFwAhP2RBQmF05rYU/IQH4/nugXTv3DgKuKEqextOhnvwAihBRfgDBAKIBdAWwwFg+D8AAD9sQGJjCX62aTM0G3itXNMyjKIoNHhN+Zj4L4EMApyGCHwdgG4BYZk4xqkUBqOJofSIaSUSRRBQZExPjKTP9B1P4qxg/Z4MGEuIBVPgVRbHBk6Ge0gD6A6gFoDKAogDudnV9Zp7FzGHMHBYSEuIhK/2IqCgZB9bMqxMUJP3y8+WTUI+iKIqBJ1/gugvACWaOAQAiWgSgI4BSRJTf8PqrAjjrQRsChzNnLPF9k4cfllGv7AdQURQloPGk8J8G0I6IggHEA+gGIBLAWgCDAPwIYBiAJR60IXAw+/Bb89RTvrFFUZRcjSdj/JshjbjbAewx9jULwCsAXiSiowDKApjtKRsCCkfCryiK4gCP5uph5jcBvGlXfBzAbZ7cb8CRlCSDlavwK4riAvrmrj8QHS05982unIqiKBmgwu8P2L+8pSiKkgEq/HmFuDhgxw7Hy1T4FUXJAir8uZ2UFGDmTKBuXXkbd+XK9HXMIRdV+BVFcQEV/tzM5s2SXO2pp6Q/fsOGwPDhMoyiNVFRQLFi2l9fURSXUOHPrezZA/ToAVy9CixcKFk2f/gBuHQJGDlSGnNNzK6cOtCKoiguoMKfG4mKAnr3Fi9+/XogPFxEPTQUeOcdYNEiYN482/rao0dRFBfRMXdzG3FxIvpxccDff6cX9BdfBJYvB0aPlpG1evWSGH/Pnr6xV1GUPId6/LmBtDQgMhKYOBHo0AE4cEDCOy1apK8bFAR8/TXQujXw7rtAx47AuXOWrJyKoiiZoB6/r4mNleyZhw5JOCcsDJg/H+je3fk61apJzP/KFWDVKhle8aGHvGWxoih5HBV+X/PJJyL6X3wBDBgAlC/v+rqlSwNDhshHURTFRVT4fUlsLDBligj+yJG+tkZRlABBY/y+ZOpUacR90z6PnaIoiudQ4fcVV66It3/vvdJNU1EUxUuo8PuKKVPk5azx431tiaIoAYYKvy84f14adQcOBJo397U1iqIEGCr83mbfPum+mZys3r6iKD5Bhd+brFwpL2glJgJ//gk0beprixRFCUBU+L3FmjWSiqFGDcm62aaNry1SFCVA0X783mL5cqBAAUm6pumTFUXxIerxe4vjx4FatVT0FSUPcuECUL2680Hw8hoq/N7ixAkRfi+SmAhcu+bVXSqKX7JzpyTB3bzZ15a4BxV+b8AsHn/t2l7d7dixQOfOXt2lovglp07J1BzeOq+jwu8NrlyRl7W87PHv2CEDeaWmenY/27bJ4SmKv2IKvzm8dV5Hhd8bnDghUy97/MePy1jt0dGe20dCgvRQnTTJc/tQFF+jHr+SdUzh96LHn5Ag47MAlpPWExw/DiQlyTgyiuKvnDwpUxV+xXWOH5epF4XfWuw9KfxHj8p01y7P7cMdnD8PvPYaEB/va0uU3MCUKcD+/a7Xt/b4mT1jkzdR4fcGJ04AZct6tSunea8BvCP8589Ll7fcysKFMk795Mm+tiRvcvkyMGIEcOmSry3JOefOydDVM2e6Vj85WdYpUQK4eVOG0cjrBIzwr14NDBsmw9t6HbMPvxcxo0v583tH+IHc7fUfPizT997z7O/hr8yfD8yZA8yd62tLco7ZJfPYMdfqR0WJbrRvb5nP6wSM8H/1lYxR7pNYtJv78EdFAbfdBnz0kcTXne2yUCFJ/ulJoTtyBKhbV77v3Om5/eSUI0dkqGIi6eaqZI1Vq2T6/fe+2X90NNC2ra2jkV02bpSpq9syr5+OHWXqDz17Akb4t26V6aJFXt5xaqqcOW7s0bNqlRzPmDFA48bAzz+njzsePw7UrCkfT3v8t90moprbPf727YH/+z/gp5+AtWt9bVHeISVFnphLlJAuwgcOeN+GVauALVuAX37J+bY2bZLpiRNybJlhL/zq8ecRYmMtj/oLF3q2ceb6dTsv/Nw5KXCjx79rFxAcLOl/ChWSQby+/tq2zokTcq+pUUNOXE8cc2IicPq0ePwtWrhH+OPjnT/FZJekJOmVUa+e3Cxr1gSefda1i14RJ+PqVeDtt4F8+YAffvCNDYBFtLNLcrI89ZcpI99d8d5N4W/bVo5fhT8DiKgBEe20+lwloueJqAwRrSKiI8a0tKdsMNm2TaYDBoiHum+f+/dx4wYwYQJQvrw0HN3CA105d+4EmjUDevUSsa1SBfj9d9s6ZnSpRg1pkLp82Xb5wYM5vxmcPCmxT1P4Dx6UbqTZ5cYNoHVroFUreefNmpQUuclkhxMn5MGrfn2gSBHg44+BvXtlmptJSgL++kueTtautZzH7uDkSdf/q1WrJET2wANAt24S7vF2zxZT+M0wTXbZvVuci6FDZd6VcM+pU0DFikDRokClSgEi/ETUj4iyfINg5kPMHMrMoQBaA7gJYDGAcQBWM3M9AKuNeY9ixvXffltOYHeHe+bPBxo0kHFVChUCfvvNaqGbX95iFrE3h+nNn19CLeaFAYhoxsZahB+wDfds3gw0aiRd2nKCedHUrSv2pKbm7KY6ZozcPA4flqeYxEQpj4uTjNZ16mQvvnrkiEzr1ZPpgAHAoEHSvdPVpFvJycCGDd4TvKQkoE8fSbnRtat8wsJs/+fscvGinK+NGknYK7NjWrlSbshly4r4HzvmHjtcJSlJnJ2SJeX/P3s2+9synxgeekimrgq/eR1VrRogwg9gKIAjRDSJiBpmcz/dABxj5lMA+gOYZ5TPAzAgm9t0ma1bRXebNJG3TBcvdn297dszrnPwoHgPFStKxuXXX5f4uvnyFI4fB4hwKbg6li3L0WEAkBM/NlY8bJM2beQENr1k63uNI+Ffv16m//d/4gFlF2vhN+1x1sB7/Trw66/ORWbZMuleN2YMMG+ejFMzfLj8fB06iNeZkpI9e03hr19fpkSyr5AQ4MEHXevbP2aMxHgnTHB9v9HRwB9/ZF5vwwZJrWHCDDzxhKz74YfAunWW2Pbff7u+f2ds3ChimpYGDBkC3HGHJRRqz9WrIpY9esj8vfeKc+PNRt69e8UJGDFC5nOSKG3TJvHa27WTp79AFX4wc6YfACUAPAlgE4CNAEYCKO7Kusb6cwA8Y3yPtSon63m7dUYCiAQQWb16dc4J1aszDx0q3z/6iBlgPnbMef0TJ5iHDJF6lSoxp6Y6r/v668z58jGfOyfzmzfLevPnGxUefpi5enV+8UW78myyZIls559/LGWrVknZypUy/9NPMr99O/Ply/L9448t9YcOZa5YUT5NmzLHx2fPlmeeYS5RgjktTX6jokWZR492XPfRR8WOGTPSLzt/njkkhLlFC+aEBCl7/32pX6gQc6lSlmP66KOMbVq/3va3YWYeNYq5dOn0dVeulG06s9lkxQqpV7WqTGfPtixLSGD+4gvmyEjbdWJimOvVk/rLlzvf9vXrzEWKMBMxjxjBHB3N/Nprst5bb9nWrVmTedCgjG11hVdeYS5QQPb95ZfMJUsy33OP47rm+bZ2raVs4EDmChWYU1LS19+6lXnaNOYDB+S8cAczZ4oNBw8yFyzIPGZM9rdVty7zvffK96ZNnR+3SWqq7HPsWJl/7jnmYsVcO7YLF+R8T0rKvr05BUAkO9JXR4UOKwJlATwP4CSA3wAcATDahfUKArgEoALbCb8xfyWzbbRu3TrbB37hghzlhx/K/PHjtvP2fPCBiE2RIsx9+6YXWWvS0pjr1GG+6y5LWVKSrPvss0ZBp07MnTtz/fqyrdKlmaOisn04/NZbIhJXr1rKrlyRbb/zjsxPmiTzsbFiY7FicsKa1K4tF+9vv0m9F17Ini13383cqpVlvn175ttvT1/PvBkWLy6/zcGDlmWJicy9eslvvnevpTwtjfmll5ibN7fUL1uWeeTIjG1q1Ii5cWPbsm7dmNu2dVz/+efFtt9/d7w8JkZukI0bM8fFMffowRwUJDeDRYvk/zdvUD/+KOvcvCm/ReHCsrxiReaLFx1vf+FCWX/AABHjIkVk/vHH04vLfffJzSendO7MfNttlvkRI5jLlHHs4Dz9NHNwsOWGbG3zihW2da9fZ65WTZYBcqMaNUpuHteupd92UhLzX38xv/GG7Y3FnhEj5L9PS2Nu104uqexw8aLY9cEHMj9gQPpzxZ5z52SdTz+V+cmTLddWRly9ytyypdQdPtx9N8Gskm3hB3APJDa/B8BYAOWN8mAAJ11Yvz+AlVbzhwBUMr5XAnAos23kRPiXLZOj/PNPS1nLlswdOqSvu3691O3fn/nMGflzCxQQAXKEKWhz5tiW33kn8y2TK1fmI+Ev3/Isg4PlRpHRU0RGDBwoXos99erJiczM/NRTth5ukyZyTMzMly6Jze+/L/PPPCPz69Zl3Za6deXJyGTUKPEerU/y1FQRmYoVRcDLlJHfJjFRnkY6d3b+JGBPhw5S3xnmDRCQG75JtWrMDz3keJ34eBHnNm3SX5xpaczh4XIO7NghZXFx8mSSL5/sp3Fj5gULRIwA5okTxaMkEoHctUs8xv79HV/8Dz4oopaczHz4sHj0Dzzg2EucOlX2ceaMbfnkyelF2BnJyXIO3nJMmPmrr2S7+/alr1+/vtyYrYmPZ65cWW6yN29ayl9/3fJUO3OmHHOxYlJWoIA4BX37yqdHDzlXzP+rSxfnNjdvLk4GszgphQs796K/+875U+Evv9hqwZgxcsPO6FrcuFHW+eUXmf/hB5m3dlLsSUpi7tlTHITBg6X+G284r+9JciL88wDc4WRZNxfW/xHAo1bzkwGMM76PAzAps23kRPjffFMuUmuPY+JEOfJDhyxlKSlyQ6haVTwXk169mGvVcnzRPvecnDj2d38z/HP1YjwzwFN7rbgVXpo1S/Y9ZUr2jqdOHRF/ex54gLlKFfnes6etJ967N3NoqHw3wxarV8v8jRsSrhk1Kmt2JCUx58/P/N//WsrMR/ITJyxlpqh8/bXMm97iiBEiKgULMn/zjWv7fOwxuYE4wzw2gDkiQspu3mSHYRNrPvvM8ZPdvHlSPmmSbfnZsyJen30mQsosHvGDD1r2P3Wqpb4ZXvzyS9vtJCbKb//YYxkft4npaCxYYCm7eFHOtY4dXdvGjh2yje+/t5QdOSJlX3xhW/fkSefnqhkme+YZmT9+XK6FBx6wrZeYyLxmjYRK2rWT87JVK7n5P/64nA9DhzKXL+/Y3hs3REBff13mIyJkv/ahtdRU5pdflmVEEj6059VXZVs3bsi8eb6ePu1438zyFAcw794t83//nf5pZ/JkuWF/+aXclB97TOr873+iG9bzjpg40fZ8cSc5Ef5aAApbzRcBUDOz9Yy6RQFcBlDSqqwspDfPEQB/ACiT2XZyIvy9e4vHa83p0+J51qsnj/LMctIDlsd1ky+/lHLT4zNJSZE4Z3h4+n3+/russ2rOaWaAuzc9yw0byrK0NIkrFiokF0tWuHrV4lXaM2WKLDt3TgTVOhZs/QRg3vSsb1Zdu1o9objI0aPpn3ZM72jxYpmPjZXfqH17W6/KjPeXLSsXkqt88EF6260ZP14u+qJF5ZiZ5YIFxFNzxrVr0o4weLCl7MoVaXfo0MFxLNsRaWnSlmIfRkxNlXBTcLDtTdEMtS1b5tr2ExPlvLF+Av3f/2QbQUHyNJIZn38u9a3PvbQ0+Z8efti2rumkOPNuzTDZ8uXylFO0aPbCmOaN0bwWrTGfwpcskflTp2R++nRLnRs35Do0n9YBsd2ebt1sHaI//pC6a9Y4t80858zf1rwZmiKelCQ37wIFLDd9wHKjMuuYTwD27T1mG4qjp3h3kBPhjwRQ0Gq+IICtma3nzk92hT8tTS7e4cPTL1u/Xi6i9u3FgytblvmOO9J79hcuiEdl/6hmNqhae18mcXGyzpsPHOZrKMoFC6TaXKzmyTN5ctaO559/ZL2lSx0fD8D888+2jVHMlobSq1flptOgge26ZmOfdRw3M0zv+q+/LGXXr4vwPvgg87hxEgogkgY/a65elQvj6FHX98csxwaI5+uIu+9mbtZMbvaNGkmZ+YSxbVvG2375ZfnPTp6U+eefF9szW89VTp8W4bd2FEaOlHaPrDSut29v69337m0RHVMcM+KRR0Tk7c/zgQPlydaa7t2lPchZfDo+XpyqEiVk/+++6/pxWGPeAB2FG60dGmaxpVIlOceYRfQ7dpT/asoUS7ubGRoySUmRsNN//mMpM69DRzcJE/uwaWKi7Gv8eJlfs8bi7OzZI0+Hkyal/82uXpWn7qJFLedUdDRzuXKWpxTrSIO7yInw73RQtiuz9dz5ya7wm3/sZ585Xv7TT/KDly0rF/3OnY7rde4sPQCsefRROeGtY5zWtGzJ3K3BaV6M/g69imbNMo5rOsIMSTh6NL1+XY7BfKz8/HPLMjMuuWePXDT28e4FCzIWVEd8+qntBWnSsKGU588vv5urYRxXOHCAbcJG1qSmitf+xBOWxu3oaOb33rPc9DLi9GnxyMaMkVh3UBDzk0+6z3ZmaXwHxGlISZHwxn33ZW0bL74oMe7ERHnyKVhQwi3BwZawS0bUr29p77HGFFjTY4+OlvPptdcy3t7OnWJDnTrZ7x12+rTz69Q6hGkSHi77S0mRdi0i295yY8fKzfDKFUuZ+TRqfe6kpIjtL7/s3DbrMKlJxYoSqmSWp6+CBR03Xttz9qz0MKxYUZ78eveW/9J8Ct+yJfNtZJWcCP8qAPdYzfeHvICV64Xf7AKY0Q9qnvBmaMARZqOa2SYQHy+i7+hJwmT0aOaiBRJ4WL6vuUSJtHSNUePGiThm1jvAmpEjxftw5oE1aybL7WOQGzZYPBuA+ZNPbNczH5/Nngsm1687jpUyi0ccHJzelshI8X5cCTtklcREEeRXX02/zLwpzJ4t/7cZtsusXcCaoUOlwfGOO+Qm4ij0kBPi48WDbtxY2lis2yJcZf58WW/rVonTm20TvXqJqGeE2bD/3nvpl23damvPJ5/I/P79mdu0cWPG3aMzIy1Nridrb9zEutOCiXljf/hhx+ezeb5/+62lrF8/+U/tr7eGDW2fwhITbTsGWHeMMAkLk9CNuX737i4dJjNL2KxkSct1Om2aNOqb5667yYnw1zH6758GcAbABgB1M1vPnZ/sCv/LL7sWwtiwIeM6pjC+/77EpMPC2KaB1BFmI1QBJDnse202EmWlX3/bthk/JZjevn3D9dmzUtajh0w3bLBdzwyJDRtmWz58uDR2O4px9+0rvS28Tb16jvuym43I+/dLg2vx4uKxd+okQu4KpldoH0N2J2ZMt2pVCTVm9iRij+kdT5smbRIVK8rTzscfS/mpU87X/fVXqeOo62Rysu17GLfdlt7T9STt2qXvsWXfTdnkr78s/9OLL6bfVmqqPNmagm7e1By1jdmfx/fdJ79DZKSlK7R1DyhmuRE1aSI3O/uGfFdYu1aeEnr2FFtTUqQb7/PPZ207ruCOfvzFABRztb47P9kV/jvvFJF2B2FhckIA8uhp7U04IurA1Vsn51dfpV+enCx3fXuxdYYrJ8eMGXwrXmh9IzNfQgkKkqcMR+Gp3r1t+zQnJFhit9ZxfBN7T8lb9O0rTzb2PPmkeFJmI3KfPtKWUaGC5bHcFW6/Xbprmr113E1amlzwgHih2Vm/cmVLY6r5pLpnD9s0OjrC7G3mLJbcrZuEKM1ePva9mTzJiBHifFhj/2KiyY0bcmMfMsR5V8z//EeeSG/ckHOmdGnHT6HWT667dvGthvIKFSQWD6TvHvrMM3KuTZsmy48cyfrxnjxpe42Ghcnv726cCb9LOXiIqA+A/wB4kYjeIKI3XFnP10REyOv/7uDRR+UV9/HjgUOH5FX/jKiyazlqQYbB6tUr/fL8+YG775YMm64MDnP0qKQWsE7VYE+bNsa+q8hr9Sb58kna5NRUoGlTeVXd0boHDgDXrsn8mjXyuj6QPrdRaqqkUjDz8HuThg0lBUNqqm35xo2W7IkA0KWL/E8XLlhSNbjCb79JSov8+d1msg1EwNSpQLFiwCOPZG/99u0lFfeNG5JCAZB0JJUqSV4dZ2zaJOMzFC3qeHmnTpIH6osvZP6++7JuX3Zp0gSIiZGPyd9/y/8ZFmZbNzhYzr8ffrD83/aEh0tywnfekXQgL73keAC8unWl3vnzko6jRAnZb1IS0LOn1DHTNZhUqyb5oyIiJOdRdq6DGjVsr9FmzWzTdngaV5K0zYTk6xkNSbEwGECNDFfKJYSESL56d/DUU5Jv5s03nV84NixahPuLLsW9AxgVKjiu0qePnOiuJLzaskWmGQl/s2ZAwYKOE4GaJ695c7CnTRt5PjFzEy1aBBQvDnTvLt/loU+IipILwxfC36CBZJW0ztR57ZrkczFHSAJE+E3M5GyuULSoiLInadgQ+PdfSRSXHdq1k/+jVCnLcRLJf7V6tWNHIi1Ncty0a+d8u506Sb1p0yR/T7Vq2bMvOzRpIlPrJH+//ir2lnaQv7dcOeeiD4j9ZcoA774r09GjHdczz40FC+Q8f/55OY+WLLE4PvbCX7WqTP/5R65hd9CsmSTPu3jRPdvLDFc8/g7M/AgktcIEAO0BZMGH8g+IMj7RbEhIAH79Fe88dBCLFpPTanffLdv89deMN/fLL3LjqVXLcoE4omBBSWQVHp5+mSvCD8hNKDVVPMo+fSQb4+nTtlkszXzszrblSRo0kOmhQ5ayyEgRLGtRCw21eHhZ8fi9RYEC2V/XPM577rHdTvfukn7bUcbRZctEyDIS/rZtgaAguak/8ED27csO9sIfHS1pqLMrrAUKyO8DSII9Z8Ndm87Lf/8r2T9feEHmb78d+O47edpoaJea0hR+wL3CD9h6/bt2yTG4Y9SxdDiK/1h/AGwxppsAVAZQCMDRzNZz5ycnL3D5hKVLJfjnLAGMFR072r5UYo35QhCRxADtu05mhfHjxST7F9GsqV5d4qbr1lkani9dsu1Jc/WqdH+1f43fW5i5l6wb1Mxukv/+a1u3b1/57bLbzTC3kpAgMX779yOiozldr51jx6SPPsBco4ZtjxVHtG4t7UCXLrnd7AxJS5O4udlmMXu22Oysi7UrbN0q7SgZNaAnJ8vxAvKWvyuYjbrFi0svIHdw/rxs0/otabNbak7+C+SgV8/rAEoBGAjgPIBoAG9ltp47P3lO+IcPl7PYhbPi3XfZYX94ZuYJE2RZeLjlNfPssm+fNEpl9BbqwIHS3fDZZ6XHidk3uVs3ywtRpr1Z6fPvTtLSpFuedffbfv341pvR1qxd67scKb6ieXPpiVKnjnwKFpTGy7fecu0cWrDAeQJDT9O+vaVnT3i49HzyRnKzevXkcrXu958RCQlyDThKnZITQkIs6TtSU+X4s9MBwJpsCT8kFNTBar4QrNIveOuTp4Q/KUnyQTjLCmaH2ZPAvufAgQPiidx/f/YTumUV8w3fkBDbdLXmy1qbN8uh9enjHXuc0batpJlgFg+2dOmM36kIJJYtk7dazc8LL0h33rzA44/Lm6yJieJNZ5aJ1V1ERMhb4Vlh6tSMn56zQ9eukiyQ2fLUnVGqEVfIice/I7M6nv7kKeE3E4AsWuRS9bQ0ydYZHCwvcphlPXtKd8rMHs3diflSEcA8d66lPCqKb4UKPPWGYVZ45BHpUnv9ulwoRYqkT9ql5D3MlynNN82zKsZ5HbNraWqq3PSKFs15Ggdnwu9Kc+VqIhpIRM5bKRULixdLf0mzL1gmEAFz50rXrocekiH+li2TMXTNMXy9RevWMg0KAvr1s5RXqSKNgqdOAX37+qZR15oGDWT4vYEDpQHwxx8ttit5F7OBd9Ik6ajQrZtv7fE2zZpJ19KDB2VIzAEDXOxBmA1cEf4nAfwEINEYMP0aEV31jDl5mNhY6T4wa5aoY3Cwy6tWqSKrbdki48C+8IKMh/r0054z1xElS0o/77vuki5w1gweLDepN9/0rk2OMHtZ/P47MH26pfeGkrcxhX/HDumm6ulutbkNs2fPhx/KMKoe7Vnl6DEgt31ydajn3DlJFlKunHQheewx58MtZcKwYZZQi/3bit7i7FnHvQiSkjIefMKbHDsmP3VGybWUvIfZcO8o/04gcOOGnNf58knPOXcM2QgnoZ5M308kojuc3DD+cvtdKK+QkiKvBP78s2V08S5dgI8/Blq2zPZmp02Tl2xatZI+2b6gcmXH5QUKZPwOgTepXVtCPRUr+toSxZ0QyTnmzhej8hLBwUCdOtJvf8iQnL3rkRmuvJg+1up7YQC3AdgGoKtHLMoL/PST5G7o2BF47z15E6tFCzlzc0CJEsDu3Z5LF+BPVKrkawsUT9Crl7R31anja0t8Q7NmIvyefoEuU4lh5n7W80RUDcBUTxmUJ9i4UVpd1q1zu0p78i6vKLmdV1+VT6ASHi45mDp08Ox+XE1CYE0UgEbuNiRPsWmTdG1R11xRFDfy0EPSacHl9DDZxJUY/3QAZoqufABCAWz3oE25m/h46XYwZoyvLVEURckWrriskVbfUwD8wMz/eMie3M/27dK4a50KUlEUJQ/hivAvAJDAzKkAQERBRBTMzDc9a1ouZdMmmbZt61s7FEVRsolLb+4CsB66owiAPzxjTh5g0ybJj+wsyb6iKEouxxXhL8zM180Z47vrr6X6Gxs3ZpzUXFEUJZfjivDfIKJW5gwRtQYQ7zmTcjFRUfLmkMb3FUXJw7gS438ewE9EdA4y9GJFyFCMgYcZ31ePX1GUPIwrL3BtJaKGAIxB73CImZM9a1YuZeNGea0wo4FvFUVRcjmuDLb+NICizLyXmfcCKEZE//G8abmQTZsk/2/Bgr62RFEUJdu4EuN/gpljzRlmvgLgCY9ZlFtJSpLk7xrfVxQlj+OK8AdZD8JCREEAAs/l3bULSEzU+L6iKHkeVxp3VwCIIKIvjPknAfzmOZNyKX/+KVMVfkVR8jiuCP8rAEYCGGXM74b07AkcEhMlWX779kDVqr62RlEUJUe40qsnjYg2A6gDYAiAcgAWetqwXMWcOcCZM8D//udrSxRFUXKMU+EnovoA7jc+lwBEAAAz3+nqxomoFID/AWgKyfD5GIBDxrZqAjgJYIjRYJw7SUwE3n1XEmT7algsRVEUN5JR4+5ByChbfZm5EzNPB5Caxe1/AmAFMzcE0ALAAQDjAKxm5nqQPEDjsm62F5k9W97YnTAhxyNsKYqi5AYyEv5wANEA1hLRl0TUDfLmrksQUUkAdwCYDQDMnGR0C+0PYJ5RbR6AAVk320skJIi337Ej0K2br61RFEVxC06Fn5l/Zub7ADQEsBaSuqE8Ec0goh4ubLsWgBgAXxHRDiL6HxEVBVCBmaONOucBOExzSUQjiSiSiCJjYmKycEhuZPZsyc2j3r6iKH5Epv34mfkGM39vjL1bFcAOSE+fzMgPoBWAGczcEsAN2IV1mJlhGd3Lfr+zmDmMmcNCQkJc2J0HWLRI0jN0Ddxx5RVF8T+yNLIjM18xBNmVuEcUgChm3mzML4DcCC4QUSUAMKYXs2KDVzl8WIRfvX1FUfwIjw3py8znAZwhIjO5WzcA+wEsBTDMKBsGYImnbMgRN29Ko269er62RFEUxa248gJXThgN4DsiKgjgOIBHITeb+UQ0AsApyLsBuY+jR2Vav75v7VAURXEzHhV+Zt4JIMzBotzfRebIEZmqx68oip/hsVBPnufwYZmq8CuK4meo8DvjyBGgUiWgWDFfW6IoiuJWVPidcfiwxvcVRfFLVPidcfiwhnkURfFLVPgdERsLxMSox68oil+iwu8I7dGjKIofo8LvCBV+RVH8GBV+Rxw+LGka6tTxtSWKoihuR4XfEUeOANWrA4UL+9oSRVEUt6PC7wjtyqkoih+jwm8Ps3j8Gt9XFMVPUeG3JyYGiItTj19RFL9Fhd8e7dGjKIqfo8Jvj5mcTT1+RVH8FBV+e44cAfLnB2rW9LUliqIoHkGF357Dh4HatUX8FUVR/BAVfnu0R4+iKH6OCr81MTHA3r1Aq1a+tkRRFMVjqPBb88svQFoacO+9vrZEURTFY6jwW7NokTTqhob62hJFURSPocJvcvUqsGoVEB4uCdoURVH8FBV+k+XLgaQkEX5FURQ/RoXfZNEioGJFoH17X1uiKIriUVT4ASAhQTz+AQOAfPqTKIri36jKARLbv3FDwzyKogQEKvyAhHlKlQK6dPG1JYqiKB5HhT8lBVi6FOjXDyhQwNfWKIqieBwV/sOHgX//Bbp397UliqIoXkGF/+hRmTZo4Fs7FEVRvIQKvyn8dev61g5FURQvocJ/9ChQujRQpoyvLVEURfEKKvxHj6q3ryhKQOFR4Seik0S0h4h2ElGkUVaGiFYR0RFjWtqTNmSKCr+iKAGGNzz+O5k5lJnDjPlxAFYzcz0Aq41535CUBJw6pcKvKEpA4YtQT38A84zv8wAM8IENwsmTkn9fhV9RlADC08LPAFYS0TYiGmmUVWDmaOP7eQAVHK1IRCOJKJKIImNiYjxjnfboURQlAPH0iOKdmPksEZUHsIqIDlovZGYmIna0IjPPAjALAMLCwhzWyTEq/IqiBCAe9fiZ+awxvQhgMYDbAFwgokoAYEwvetKGDDl6FCheHAgJ8ZkJiqIo3sZjwk9ERYmouPkdQA8AewEsBTDMqDYMwBJP2ZApZo8eHXFLUZQAwpOhngoAFpOIan4A3zPzCiLaCmA+EY0AcArAEA/akDFHj+r4uoqiBBweE35mPg6ghYPyywC6eWq/LpOSApw4AQwa5GtLFEVRvErgvrl7+rSIvzbsKooSYHi6V0/uRXv0KIrXSE5ORlRUFBISEnxtil9SuHBhVK1aFQVcHFNEhV+FX1E8TlRUFIoXL46aNWuCtDOFW2FmXL58GVFRUahVq5ZL6wRuqOfoUaBIEaBSJV9boih+T0JCAsqWLaui7wGICGXLls3S01RgC7925VQUr6Gi7zmy+tuq8CuKogQYgSn8qanAsWMq/IqipGPdunXYsGHDrfmZM2fi66+/9qFF7icwG3fPnpWUzCr8iqLYsW7dOhQrVgwdOnQAAIwaNcrHFrmfwBR+s0dPnTq+tUNRApHnnwd27nTvNkNDgalTM6wyYMAAnDlzBgkJCXjuuecwcuRIrFixAv/973+RmpqKcuXKYfbs2Zg5cyaCgoLw7bffYvr06Vi9ejWKFSuGvn374pFHHsGWLVsAACdPnkS/fv2wZ88ebNu2DS+++CKuX7+OcuXKYe7cuaiUizuOBKbw794t0yZNfGuHoiheY86cOShTpgzi4+PRpk0b9O/fH0888QT++usv1KpVC//++y/KlCmDUaNGoVixYhgzZgwAYPXq1QCAhg0bIikpCSdOnECtWrUQERGBoUOHIjk5GaNHj8aSJUsQEhKCiIgIvPrqq5gzZ44vDzdDAlP4t28HKlcGKlb0tSWKEnhk4pl7imnTpmHx4sUAgDNnzmDWrFm44447bvV9L1OmTKbbGDJkCCIiIjBu3DhEREQgIiIChw4dwt69e9G9e3cAQGpqaq729oFAFv5WrXxthaIoXmLdunX4448/sHHjRgQHB6NLly4IDQ3FwYMHM1/ZiqFDh2Lw4MEIDw8HEaFevXrYs2cPmjRpgo0bN3rIevcTeL16bt4EDhxQ4VeUACIuLg6lS5dGcHAwDh48iE2bNiEhIQF//fUXTpw4AQD4999/AQDFixfHtWvXHG6nTp06CAoKwsSJEzF06FAAQIMGDRATE3NL+JOTk7Fv3z4vHFX2CTzh371bxtlV4VeUgOHuu+9GSkoKGjVqhHHjxqFdu3YICQnBrFmzEB4ejhYtWtwS8n79+mHx4sUIDQ3F33//nW5bQ4cOxbfffoshQySjfMGCBbFgwQK88soraNGiBUJDQ226g+ZGiNkzoxq6k7CwMI6MjHTPxj7/HHj6acnOWa2ae7apKEqGHDhwAI0aNfK1GX6No9+YiLYxc5h93cDz+LdvB8qVA6pW9bUliqIoPiEwhb9VK83RoyhKwBJYwp+YCOzdq/F9RVECmsAS/n37gORkFX5FUQKawBL+7dtlqsKvKEoAE3jCX7IkULu2ry1RFEXxGYEn/C1basOuoig+ITY2Fp9//vmt+XPnzmHQoEFetyNwhD8lBdi1S8M8iqL4DHvhr1y5MhYsWOB1OwInV8/Bg0BCggq/ovgYH2VlxsmTJ9GrVy906tQJGzZsQJUqVbBkyRIcOnQIo0aNws2bN1GnTh3MmTMHpUuXRpcuXdC2bVusXbsWsbGxmD17Nm6//fZ02/3yyy8xa9YsJCUloW7duvjmm28QHByMCxcuYNSoUTh+/DgAYMaMGZg2bRqOHTuG0NBQdO/eHU8//TT69u2LvXv3ol27dpg9ezaaGFmDu3Tpgg8//BCNGjXC6NGjsXfvXiQnJ2P8+PHo379/jn6vwPH4t22TqQq/ogQsR44cwdNPP419+/ahVKlSWLhwIR555BF88MEH2L17N5o1a4YJEybcqp+SkoItW7Zg6tSpNuXWhIeHY+vWrdi1axcaNWqE2bNnAwCeffZZdO7cGbt27cL27dvRpEkTvP/++6hTpw527tyJyZMn22xn6NChmD9/PgAgOjoa0dHRCAsLwzvvvIOuXbtiy5YtWLt2LcaOHYsbN27k6HcIDI//wgVgwgSgUiWgfn1fW6MoAY2PsjIDAGrVqoXQ0FAAQOvWrXHs2DHExsaic+fOAIBhw4Zh8ODBt+qHh4ffqnvy5EmH29y7dy9ee+01xMbG4vr16+jZsycAYM2aNbeGbAwKCkLJkiVx5coVp7YNGTIEPXr0wIQJEzB//vxbsf+VK1di6dKl+PDDDwEACQkJOH36dI5SYPi/8N+4AfTtC5w/D6xbBwQF+doiRVF8RKFChW59DwoKQmxsrEv1g4KCkJKSAgB49NFHsWPHDlSuXBnLly/H8OHD8fPPP6NFixaYO3cu1q1bly3bqlSpgrJly2L37t2IiIjAzJkzAQDMjIULF6JBgwbZ2q4j/DvUk5ICDB0qvXkiIoDbbvO1RYqi5CJKliyJ0qVL38rC+c0339zy/p3x1VdfYefOnVi+fDkA4Nq1a6hUqRKSk5Px3Xff3arXrVs3zJgxA4AMzhIXF5dhymdAwj2TJk1CXFwcmjdvDgDo2bMnpk+fDjOh5o4dO7J/wAb+K/zMwDPPAL/+Cnz2GdCvn68tUhQlFzJv3jyMHTsWzZs3x86dO/HGG29kaf2JEyeibdu26NixIxo2bHir/JNPPsHatWvRrFkztG7dGvv370fZsmXRsWNHNG3aFGPHjk23rUGDBuHHH3+8lfIZAF5//XUkJyejefPmaNKkCV5//fXsH6yBf6dlnjIFuHQJeOcd9xulKIrLaFpmz5OVtMz+HeN/4QVfW6AoipLr8N9Qj6IoiuIQjws/EQUR0Q4iWmbM1yKizUR0lIgiiKigp21QFMX35IWwcl4lq7+tNzz+5wAcsJr/AMAUZq4L4AqAEV6wQVEUH1K4cGFcvnxZxd8DMDMuX76MwoULu7yOR2P8RFQVQB8A7wB4kYgIQFcADxhV5gEYD2CGJ+1QFMW3VK1aFVFRUYiJifG1KX5J4cKFUTULw8l6unF3KoCXARQ35ssCiGXmFGM+CkAVRysS0UgAIwGgevXqnrVSURSPUqBAAdSqVcvXZigGHgv1EFFfABeZeVt21mfmWcwcxsxhISEhbrZOURQlcPGkx98RwD1E1BtAYQAlAHwCoBQR5Te8/qoAznrQBkVRFMUOj3n8zPx/zFyVmWsCuA/AGmZ+EMBaAObIA8MALPGUDYqiKEp6vPLmLhF1ATCGmfsSUW0APwIoA2AHgIeYOTGT9WMAnPK0nbmUcgAu+doIH6LHr8evx599ajBzulh5nkjZEMgQUaSjV64DBT1+PX49fvcfv765qyiKEmCo8CuKogQYKvy5n1m+NsDH6PEHNnr8HkBj/IqiKAGGevyKoigBhgq/oihKgKHC72OIaA4RXSSivVZlZYhoFREdMaaljXIiomlGSuvdRNTKd5bnHCKqRkRriWg/Ee0joueM8oA4fgAgosJEtIWIdhm/wQSj3GH6ciIqZMwfNZbX9OkBuAFXU7f747EDABGdJKI9RLSTiCKNMo9eAyr8vmcugLvtysYBWM3M9QCsNuYBoBeAesZnJPJ+VtMUAC8xc2MA7QA8TUSNETjHDwCJALoycwsAoQDuJqJ2cJ6+fASAK0b5FKNeXsfV1O3+eOwmdzJzqFWffc9eA8ysHx9/ANQEsNdq/hCASsb3SgAOGd+/AHC/o3r+8IGk7+gewMcfDGA7gLaQtzXzG+XtAfxufP8dQHvje36jHvna9hwcc1VD2LoCWAaAAuXYrX6DkwDK2ZV59BpQjz93UoGZo43v5wFUML5XAXDGqp7TtNZ5DeOxvSWAzQiw4zdCHTsBXASwCsAxOE9ffus3MJbHQdKd51WmQlK3pxnzGaVu97djN2EAK4lom5GOHvDwNeDfg637AczMROTXfW6JqBiAhQCeZ+arMl6PEAjHz8ypAEKJqBSAxQAa+tYi72Cdut3I5xWodGLms0RUHsAqIjpovdAT14B6/LmTC0RUCQCM6UWj/CyAalb18nxaayIqABH975h5kVEcMMdvDTPHQrLXtoeRvtxYZH2ct34DY3lJAJe9a6nbMFO3n4QkbuwKq9TtRh1/PfZbMPNZY3oRcuO/DR6+BlT4cydLISmrAdvU1UsBPGK07LcDEGf1OJjnIHHtZwM4wMwfWy0KiOMHACIKMTx9EFERSBvHAThPX2792wyCpDvPk09EnPXU7X5z7CZEVJSIipvfAfQAsBeevgZ83bAR6B8APwCIBpAMideNgMQtVwM4AuAPAGWMugTgM0gMeA+AMF/bn8Nj7wSJb+4GsNP49A6U4zeOqTkkPflu44J/wyivDWALgKMAfgJQyCgvbMwfNZbX9vUxuOl36AJgWaAdu3Gsu4zPPgCvGuUevQY0ZYOiKEqAoaEeRVGUAEOFX1EUJcBQ4VcURQkwVPgVRVECDBV+RVGUAEOFX/EbiOhVI8PlbiPTYVsP728dEbk8EDYRtTOySu4kogNENN4ov4eIxmWyuqK4DU3ZoPgFRNQeQF8ArZg5kYjKASjoY7PsmQdgCDPvIqIgAA0AgJmXQl7MURSvoB6/4i9UAnCJmRMBgJkvMfM5ACCiN4hoKxHtJaJZxhvDpsc+hYgiDQ+8DREtMnKgv23UqUlEB4noO6POAiIKtt85EfUgoo1EtJ2IfjLyD9lTHvKyHpg5lZn3G+sOJ6JPje87rT7xRNTZeLtzDkne/h1E1N8Dv58SQKjwK/7CSgDViOgwEX1ORJ2tln3KzG2YuSmAIpAnA5MklhzoMyGvxT8NoCmA4URkZn5sAOBzZm4E4CqA/1jv2Hi6eA3AXczcCkAkgBcd2DgFwCEiWkxETxJRYfsKLDnZQwG8bmxnA4BXIekJbgNwJ4DJxuv9ipItVPgVv4CZrwNoDRmcIgZABBENNxbfacTW90ASgTWxWtUMsewBsI+Zo42nhuOwJMM6w8z/GN+/haSasKYdgMYA/jHSKw8DUMOBjW8BCIPcpB4AsMLRsRBRPQCTIWGhZEj+lnHGttdBUhdUz+DnUJQM0Ri/4jewpDdeB2CdIfLDiOhHAJ9DcpqcMRpUrT3tRGOaZvXdnDevD/u8JvbzBGAVM9/vgo3HAMwgoi8BxFg9VciGJEQ0H8ATbEm+RQAGMvOhzLavKK6gHr/iFxBRA8NTNgkFcAoWkb9kiOog+3VdoLrReAyIp77ebvkmAB2JqK5hS1Eiqu/Axj5m+wJk6LxUALF21eYA+IqZ/7Yq+x3AaKu2iZbZOAZFuYV6/Iq/UAzAdCPFcQokg+NIZo41vOu9kJGMtmZj24cg4wHPAbAfduOcMnOMEVb6gYgKGcWvAThst52HAUwhopuGjQ8yc6p5LyCiGpAbU30iesxY53EAEyEjVe0monwATsC2nUJRsoRm51SUDCAZEnKZ0TCsKH6BhnoURVECDPX4FUVRAgz1+BVFUQIMFX5FUZQAQ4VfURQlwFDhVxRFCTBU+BVFUQKM/wd6nLEvous0xQAAAABJRU5ErkJggg=="
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "metadata": {}
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyMfqalTRwiWuiIELJDbCQ7d",
      "mount_file_id": "1SZapm_bYNJDCJi8ECwmjrzaN8-1ruRgA",
      "name": "Logistic.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "5edc29c2ed010d6458d71a83433b383a96a8cbd3efe8531bc90c4b8a5b8bcec9"
    },
    "kernelspec": {
      "display_name": "Python 3.8.2 64-bit",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "metadata": {
      "interpreter": {
        "hash": "5edc29c2ed010d6458d71a83433b383a96a8cbd3efe8531bc90c4b8a5b8bcec9"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}