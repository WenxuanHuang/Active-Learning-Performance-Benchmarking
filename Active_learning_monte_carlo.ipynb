{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ioi13nGDPDvQ",
        "outputId": "4763f7b3-6c5b-45cb-f411-fd7c6ea8b38f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Automatically created module for IPython interactive environment\n"
          ]
        }
      ],
      "source": [
        "print(__doc__)\n",
        "\n",
        "import os\n",
        "import time\n",
        "import json\n",
        "import pickle\n",
        "import math\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.mlab as mlab\n",
        "from scipy.special import expit\n",
        "from scipy import stats\n",
        "from pylab import rcParams\n",
        "import mplcursors\n",
        "\n",
        "from sklearn.utils import check_random_state\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer\n",
        "from sklearn.pipeline import Pipeline, FeatureUnion\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import scale\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "\n",
        "from sklearn import linear_model\n",
        "from sklearn import neighbors\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.linear_model import RidgeCV, LassoCV, Ridge, Lasso\n",
        "from sklearn.svm import LinearSVC, SVC\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.utils import check_random_state\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics.pairwise import euclidean_distances\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.mixture import GaussianMixture\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import pairwise_distances_argmin_min\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import average_precision_score\n",
        "\n",
        "\n",
        "# pd.options.display.max_rows = 20\n",
        "pd.options.display.float_format = \"{:.1f}\".format\n",
        "\n",
        "max_queried = 500\n",
        "trainset_size = 1302"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "def data_prep():\n",
        "    data = pd.read_csv(\"https://raw.githubusercontent.com/WenxuanHuang/ML-for-COVID-19-dataset/main/all_training.csv\", sep=',')\n",
        "    # Column selection\n",
        "    df = data.iloc[:,np.r_[3:34]].copy()\n",
        "    # define row and column index\n",
        "    col = df.columns\n",
        "    row = [i for i in range(df.shape[0])]\n",
        "    # define imputer\n",
        "    imputer = IterativeImputer(estimator=linear_model.BayesianRidge(), n_nearest_features=None, imputation_order='ascending')\n",
        "    # fit on the dataset\n",
        "    imputer.fit(df)\n",
        "    # transform the dataset\n",
        "    df_imputed = imputer.transform(df)\n",
        "    # convert back to pandas dataframe and rename back to df_normalized\n",
        "    df = pd.DataFrame(data=df_imputed, index=row, columns=col)\n",
        "    X = df\n",
        "    y = data.target    \n",
        "    # Recursive feature elimination\n",
        "    rdmreg = RandomForestClassifier(n_estimators=100)\n",
        "    # Define the method\n",
        "    rfe = RFE(estimator=rdmreg, n_features_to_select=10)\n",
        "    # Fit the model\n",
        "    rfe = rfe.fit(X, y.values.ravel())\n",
        "    print(rfe.support_)\n",
        "    # Drop columns that failed RFE test\n",
        "    col = df.columns[rfe.support_]\n",
        "    X = X[col]\n",
        "    X = X.to_numpy()\n",
        "    print ('df:', X.shape, y.shape)\n",
        "    return (X, y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "class BaseModel(object):\n",
        "\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def fit_predict(self):\n",
        "        pass\n",
        "\n",
        "\n",
        "class SvmModel(BaseModel):\n",
        "\n",
        "    model_type = 'Support Vector Machine with linear Kernel'\n",
        "    def fit_predict(self, X_train, y_train, X_val, X_test, c_weight):\n",
        "        print ('training svm...')\n",
        "        self.classifier = SVC(\n",
        "            C=1, \n",
        "            kernel='linear', \n",
        "            probability=True,\n",
        "            class_weight=c_weight\n",
        "            )\n",
        "        self.classifier.fit(X_train, y_train)\n",
        "        self.test_y_predicted = self.classifier.predict(X_test)\n",
        "        self.val_y_predicted = self.classifier.predict(X_val)\n",
        "        return (X_train, X_val, X_test, self.val_y_predicted,\n",
        "                self.test_y_predicted)\n",
        "\n",
        "class LogModel(BaseModel):\n",
        "\n",
        "    model_type = 'Logistic Regression' \n",
        "    def fit_predict(self, X_train, y_train, X_val, X_test, c_weight):\n",
        "        print ('training logistic regression...')\n",
        "        # train_samples = X_train.shape[0]\n",
        "        self.classifier = LogisticRegression(\n",
        "            # C=50. / train_samples,\n",
        "            penalty='l1',\n",
        "            solver='liblinear',\n",
        "            tol=0.1,\n",
        "            class_weight=c_weight\n",
        "            )\n",
        "        self.classifier.fit(X_train, y_train)\n",
        "        self.test_y_predicted = self.classifier.predict(X_test)\n",
        "        self.val_y_predicted = self.classifier.predict(X_val)\n",
        "        return (X_train, X_val, X_test, self.val_y_predicted,\n",
        "                self.test_y_predicted)\n",
        "\n",
        "class RfModel(BaseModel):\n",
        "\n",
        "    model_type = 'Random Forest'\n",
        "    def fit_predict(self, X_train, y_train, X_val, X_test, c_weight):\n",
        "        print ('training random forest...')\n",
        "        self.classifier = RandomForestClassifier(\n",
        "            n_estimators=500, \n",
        "            class_weight=c_weight, \n",
        "            n_jobs=-1\n",
        "            )\n",
        "        self.classifier.fit(X_train, y_train)\n",
        "        self.test_y_predicted = self.classifier.predict(X_test)\n",
        "        self.val_y_predicted = self.classifier.predict(X_val)\n",
        "        return (X_train, X_val, X_test, self.val_y_predicted, self.test_y_predicted)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "class TrainModel:\n",
        "\n",
        "    def __init__(self, model_object):        \n",
        "        self.accuracies = []\n",
        "        self.model_object = model_object()        \n",
        "\n",
        "    def print_model_type(self):\n",
        "        print (self.model_object.model_type)\n",
        "\n",
        "    # we train normally and use the probabilities to select the most uncertain samples\n",
        "    def train(self, X_train, y_train, X_val, X_test, c_weight):\n",
        "        print ('Train set:', X_train.shape)\n",
        "        print ('Validation set:', X_val.shape)\n",
        "        print ('Test set:', X_test.shape)\n",
        "        t0 = time.time()\n",
        "        (X_train, X_val, X_test, self.val_y_predicted,\n",
        "         self.test_y_predicted) = \\\n",
        "            self.model_object.fit_predict(X_train, y_train, X_val, X_test, c_weight)\n",
        "        self.run_time = time.time() - t0\n",
        "        return (X_train, X_val, X_test)\n",
        "\n",
        "    # we want accuracy only for the test set\n",
        "    def get_test_accuracy(self, i, y_test):\n",
        "        classif_rate = np.mean(self.test_y_predicted.ravel() == y_test.ravel()) * 100\n",
        "        self.accuracies.append(classif_rate)               \n",
        "        print('--------------------------------')\n",
        "        print('Iteration:',i)\n",
        "        # print('--------------------------------')\n",
        "        # print('y-test set:',y_test.shape)\n",
        "        # print('Training run in %.3f s' % self.run_time,'\\n')\n",
        "        print(\"Accuracy rate is %f \" % (classif_rate))    \n",
        "        # print(\"Classification report for %s:\\n%s\\n\" % (self.model_object.classifier, metrics.classification_report(y_test, self.test_y_predicted)))\n",
        "        # print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(y_test, self.test_y_predicted))\n",
        "        print('--------------------------------')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Normalize(object):\n",
        "    \n",
        "    def normalize(self, X_train, X_val, X_test):\n",
        "        self.scaler = RobustScaler()\n",
        "        X_train = self.scaler.fit_transform(X_train)\n",
        "        X_val   = self.scaler.transform(X_val)\n",
        "        X_test  = self.scaler.transform(X_test)\n",
        "        return (X_train, X_val, X_test) \n",
        "    \n",
        "    def inverse(self, X_train, X_val, X_test):\n",
        "        X_train = self.scaler.inverse_transform(X_train)\n",
        "        X_val   = self.scaler.inverse_transform(X_val)\n",
        "        X_test  = self.scaler.inverse_transform(X_test)\n",
        "        return (X_train, X_val, X_test) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_random_samples(initial_samples, X_train_full, y_train_full):\n",
        "\n",
        "    permutation = np.random.choice(len(X_train_full),initial_samples,replace=False)\n",
        "    X_train = X_train_full[permutation]\n",
        "    y_train = y_train_full[permutation]\n",
        "    X_train = X_train.reshape((X_train.shape[0], -1))\n",
        "\n",
        "    return (permutation, X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "def log_loss(probs):\n",
        "\n",
        "    loss = 0\n",
        "    for i in range(len(probs)):\n",
        "        for prob in probs[i]:\n",
        "            # if prob in [0,1]:\n",
        "            #     loss -= 0\n",
        "            # else:\n",
        "            #     loss -= (prob*np.log(prob))\n",
        "            loss -= (prob*np.log(prob+np.finfo(float).eps))\n",
        "    ll = loss/(len(probs)*1.)\n",
        "\n",
        "    return ll"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "class TheAlgorithm(object):\n",
        "\n",
        "    accuracies = []\n",
        "\n",
        "    def __init__(self, step, model_object):\n",
        "        self.step = step\n",
        "        self.model_object = model_object\n",
        "        \n",
        "    def run(self, X_train_full, y_train_full, X_test, y_test, initial_queried, max_queried):\n",
        "\n",
        "        (permutation, X_train, y_train) = get_random_samples(initial_queried, X_train_full, y_train_full)\n",
        "        self.queried = initial_queried\n",
        "\n",
        "        X_val = np.array([])\n",
        "        y_val = np.array([])\n",
        "        X_val = np.copy(X_train_full)\n",
        "        X_val = np.delete(X_val, permutation, axis=0)\n",
        "        y_val = np.copy(y_train_full)\n",
        "        y_val = np.delete(y_val, permutation, axis=0)\n",
        "\n",
        "        normalizer = Normalize()\n",
        "        X_train, X_val, X_test = normalizer.normalize(X_train, X_val, X_test)\n",
        "           \n",
        "        self.clf_model = TrainModel(self.model_object)\n",
        "        (X_train, X_val, X_test) = self.clf_model.train(X_train, y_train, X_val, X_test, 'balanced')\n",
        "        active_iteration = 1\n",
        "        self.clf_model.get_test_accuracy(1, y_test)\n",
        "\n",
        "        while self.queried <= max_queried-self.step:\n",
        "\n",
        "            active_iteration += 1\n",
        "            self.queried += self.step\n",
        "            (mc_permutation, X_subset, y_subset) = \\\n",
        "                get_random_samples(100, X_val, y_val) # 100 is the subset size\n",
        "            # print('Indexes in the subset for X_val:', mc_permutation)\n",
        "            # print ('Subset:', X_subset.shape, y_subset.shape, monte_carlo_permutation.shape)\n",
        "            # print ('Train:', X_train.shape, y_train.shape, permutation.shape)\n",
        "\n",
        "            cand_probs = self.clf_model.model_object.classifier.predict_proba(X_subset)\n",
        "\n",
        "            utils = []\n",
        "\n",
        "            for i in range(len(X_subset)):\n",
        "                new_train_X = X_train\n",
        "                row_subset = X_subset[i]\n",
        "                new_train_X = np.append(new_train_X, [row_subset], axis=0)\n",
        "                util = 0\n",
        "                for c in [0, 1]:\n",
        "                    new_train_y = y_train\n",
        "                    new_train_y = np.append(new_train_y, c)\n",
        "                    # print('Monte_carlo training set X:', new_train_X)\n",
        "                    # print('Monte_carlo training set y:', new_train_y)\n",
        "                    new_classifier = self.clf_model.model_object.classifier\n",
        "                    new_classifier.fit(new_train_X, new_train_y)\n",
        "                    new_probs = new_classifier.predict_proba(X_subset)\n",
        "                    # print('Probabilities subset:', new_probs)\n",
        "                    util += cand_probs[i][c] * log_loss(new_probs)\n",
        "                    # need to check validity\n",
        "\n",
        "                utils.append(util)\n",
        "\n",
        "            uis = np.argsort(utils)\n",
        "            # need to check validity\n",
        "            # print ('Monte-carlo selected indexes:', uis)\n",
        "  \n",
        "\n",
        "            X_uncertain = [X_subset[i] for i in uis[:self.step]]\n",
        "            y_uncertain = [y_subset[i] for i in uis[:self.step]]\n",
        "            uncertain_samples = mc_permutation[uis[:self.step]]\n",
        "            print ('Monte-carlo selected indexes:', uncertain_samples)\n",
        "            # print ('Monte-carlo selected samples:', X_uncertain)\n",
        "            # print ('Monte-carlo selected outcomes:', y_uncertain)\n",
        "\n",
        "            X_train, X_val, X_test = normalizer.inverse(X_train, X_val, X_test)   \n",
        "            X_train = np.concatenate((X_train, np.array(X_uncertain)))\n",
        "            y_train = np.concatenate((y_train, np.array(y_uncertain)))\n",
        "\n",
        "            X_val = np.delete(X_val, uncertain_samples, axis=0)\n",
        "            y_val = np.delete(y_val, uncertain_samples, axis=0)\n",
        "\n",
        "            normalizer = Normalize()\n",
        "            X_train, X_val, X_test = normalizer.normalize(X_train, X_val, X_test)               \n",
        "\n",
        "            (X_train, X_val, X_test) = self.clf_model.train(X_train, y_train, X_val, X_test, 'balanced')\n",
        "            self.clf_model.get_test_accuracy(active_iteration, y_test)\n",
        "\n",
        "        return self.clf_model.accuracies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "def pool_experiment(model,max_queried,initial_queried,step):\n",
        "\n",
        "    (X, y) = data_prep()\n",
        "    kf = KFold(n_splits=4)\n",
        "    for train_index, test_index in kf.split(X):\n",
        "        X_train_full, X_test = X[train_index], X[test_index]\n",
        "        y_train_full, y_test = y[train_index], y[test_index]\n",
        "        \n",
        "    act_alg = TheAlgorithm(step, model)\n",
        "    accuracies = act_alg.run(X_train_full,y_train_full,X_test,y_test,initial_queried,max_queried)\n",
        "\n",
        "    (permutation, X_train_selected, y_train_selected) = get_random_samples(initial_queried, X_train_full, y_train_full)\n",
        "    original_accuracies=[]\n",
        "    classifier_original = LogisticRegression(\n",
        "            penalty='l1',\n",
        "            solver='liblinear',\n",
        "            tol=0.1,\n",
        "            class_weight='balanced')\n",
        "    x_axis = []\n",
        "    for i in range(initial_queried-1,max_queried,step):\n",
        "        classifier_original.fit(X_train_selected[:i+1], y_train_selected[:i+1])\n",
        "        y_pred_original = classifier_original.predict(X_test)\n",
        "        original_accuracies.append(accuracy_score(y_test, y_pred_original)*100)\n",
        "        x_axis.append(i+1)\n",
        "\n",
        "    plt.plot(x_axis, accuracies, 'r',label='active')\n",
        "    plt.plot(x_axis, original_accuracies, 'blue',label='non-active')\n",
        "    plt.legend()\n",
        "    plt.xlabel('Sample Size')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ True False False False False False  True False  True  True False False\n",
            " False  True  True False False False False False False False False False\n",
            "  True False  True  True False  True False]\n",
            "df: (1736, 10) (1736,)\n",
            "Train set: (50, 10)\n",
            "Validation set: (1252, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "Accuracy rate is 78.341014 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [ 159 1130   21  982 1242]\n",
            "Train set: (55, 10)\n",
            "Validation set: (1247, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "Accuracy rate is 78.341014 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [ 419  858 1042  585  966]\n",
            "Train set: (60, 10)\n",
            "Validation set: (1242, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 3\n",
            "Accuracy rate is 77.419355 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [1080 1235  151  323  334]\n",
            "Train set: (65, 10)\n",
            "Validation set: (1237, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 4\n",
            "Accuracy rate is 77.649770 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [ 29 118 280 353  87]\n",
            "Train set: (70, 10)\n",
            "Validation set: (1232, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 5\n",
            "Accuracy rate is 73.271889 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [807 816 972 589 313]\n",
            "Train set: (75, 10)\n",
            "Validation set: (1227, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 6\n",
            "Accuracy rate is 72.119816 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [726 969 582 627 384]\n",
            "Train set: (80, 10)\n",
            "Validation set: (1222, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 7\n",
            "Accuracy rate is 74.423963 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [1216  603  235  343  846]\n",
            "Train set: (85, 10)\n",
            "Validation set: (1217, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 8\n",
            "Accuracy rate is 75.576037 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [ 803  927 1094  476  511]\n",
            "Train set: (90, 10)\n",
            "Validation set: (1212, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 9\n",
            "Accuracy rate is 74.884793 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [ 181  722 1181    4  105]\n",
            "Train set: (95, 10)\n",
            "Validation set: (1207, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 10\n",
            "Accuracy rate is 76.958525 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [ 824 1029  679  932   23]\n",
            "Train set: (100, 10)\n",
            "Validation set: (1202, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 11\n",
            "Accuracy rate is 76.036866 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [1118  777  622  966  795]\n",
            "Train set: (105, 10)\n",
            "Validation set: (1197, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 12\n",
            "Accuracy rate is 75.115207 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [526 505 559 260 413]\n",
            "Train set: (110, 10)\n",
            "Validation set: (1192, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 13\n",
            "Accuracy rate is 76.267281 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [ 861   92  884  266 1009]\n",
            "Train set: (115, 10)\n",
            "Validation set: (1187, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 14\n",
            "Accuracy rate is 76.728111 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [ 184 1151  722   63  510]\n",
            "Train set: (120, 10)\n",
            "Validation set: (1182, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 15\n",
            "Accuracy rate is 77.419355 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [652 817 360 947 363]\n",
            "Train set: (125, 10)\n",
            "Validation set: (1177, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 16\n",
            "Accuracy rate is 76.497696 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [ 777  877  714  623 1019]\n",
            "Train set: (130, 10)\n",
            "Validation set: (1172, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 17\n",
            "Accuracy rate is 76.267281 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [1059  835 1073   82  631]\n",
            "Train set: (135, 10)\n",
            "Validation set: (1167, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 18\n",
            "Accuracy rate is 76.728111 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [ 123  409  440  732 1047]\n",
            "Train set: (140, 10)\n",
            "Validation set: (1162, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 19\n",
            "Accuracy rate is 76.267281 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [ 844  377 1103  845  853]\n",
            "Train set: (145, 10)\n",
            "Validation set: (1157, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 20\n",
            "Accuracy rate is 75.345622 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [ 244  379  814  275 1007]\n",
            "Train set: (150, 10)\n",
            "Validation set: (1152, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 21\n",
            "Accuracy rate is 76.497696 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [175 151 524   3 421]\n",
            "Train set: (155, 10)\n",
            "Validation set: (1147, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 22\n",
            "Accuracy rate is 75.806452 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [771 740  67 744 518]\n",
            "Train set: (160, 10)\n",
            "Validation set: (1142, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 23\n",
            "Accuracy rate is 75.115207 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [924 398 529 721 329]\n",
            "Train set: (165, 10)\n",
            "Validation set: (1137, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 24\n",
            "Accuracy rate is 75.345622 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [ 863  835  193  519 1056]\n",
            "Train set: (170, 10)\n",
            "Validation set: (1132, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 25\n",
            "Accuracy rate is 75.806452 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [784  58 492 706 462]\n",
            "Train set: (175, 10)\n",
            "Validation set: (1127, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 26\n",
            "Accuracy rate is 78.571429 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [286 686 382 660 383]\n",
            "Train set: (180, 10)\n",
            "Validation set: (1122, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 27\n",
            "Accuracy rate is 76.267281 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [ 80 835 769 337 541]\n",
            "Train set: (185, 10)\n",
            "Validation set: (1117, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 28\n",
            "Accuracy rate is 76.958525 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [126 306  91 366 127]\n",
            "Train set: (190, 10)\n",
            "Validation set: (1112, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 29\n",
            "Accuracy rate is 77.649770 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [ 314  652  896  552 1078]\n",
            "Train set: (195, 10)\n",
            "Validation set: (1107, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 30\n",
            "Accuracy rate is 77.419355 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [615 467  66  40 760]\n",
            "Train set: (200, 10)\n",
            "Validation set: (1102, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 31\n",
            "Accuracy rate is 79.262673 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [1028 1076  955  299  296]\n",
            "Train set: (205, 10)\n",
            "Validation set: (1097, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 32\n",
            "Accuracy rate is 77.419355 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [105 606 812 238  76]\n",
            "Train set: (210, 10)\n",
            "Validation set: (1092, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 33\n",
            "Accuracy rate is 79.032258 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [ 843 1069  115  123  223]\n",
            "Train set: (215, 10)\n",
            "Validation set: (1087, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 34\n",
            "Accuracy rate is 78.110599 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [ 77 330 637 119 219]\n",
            "Train set: (220, 10)\n",
            "Validation set: (1082, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 35\n",
            "Accuracy rate is 78.801843 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [972 918 209 439 844]\n",
            "Train set: (225, 10)\n",
            "Validation set: (1077, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 36\n",
            "Accuracy rate is 78.110599 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [ 564  897 1030  220  398]\n",
            "Train set: (230, 10)\n",
            "Validation set: (1072, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 37\n",
            "Accuracy rate is 78.341014 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [476  75 553 199 118]\n",
            "Train set: (235, 10)\n",
            "Validation set: (1067, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 38\n",
            "Accuracy rate is 79.723502 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [160 801 528  31 485]\n",
            "Train set: (240, 10)\n",
            "Validation set: (1062, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 39\n",
            "Accuracy rate is 78.341014 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [ 728  443 1032  842  469]\n",
            "Train set: (245, 10)\n",
            "Validation set: (1057, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 40\n",
            "Accuracy rate is 78.571429 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [272 843 249 917  14]\n",
            "Train set: (250, 10)\n",
            "Validation set: (1052, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 41\n",
            "Accuracy rate is 79.493088 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [ 893 1051  807  303  771]\n",
            "Train set: (255, 10)\n",
            "Validation set: (1047, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 42\n",
            "Accuracy rate is 78.341014 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [974 780 910 168   9]\n",
            "Train set: (260, 10)\n",
            "Validation set: (1042, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 43\n",
            "Accuracy rate is 78.110599 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [687 639 471 155 303]\n",
            "Train set: (265, 10)\n",
            "Validation set: (1037, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 44\n",
            "Accuracy rate is 77.188940 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [207  47  41 525 323]\n",
            "Train set: (270, 10)\n",
            "Validation set: (1032, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 45\n",
            "Accuracy rate is 76.267281 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [295 878  21 127 515]\n",
            "Train set: (275, 10)\n",
            "Validation set: (1027, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 46\n",
            "Accuracy rate is 77.880184 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [475 914 992 666 336]\n",
            "Train set: (280, 10)\n",
            "Validation set: (1022, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 47\n",
            "Accuracy rate is 78.341014 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [710 947 267 412 542]\n",
            "Train set: (285, 10)\n",
            "Validation set: (1017, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 48\n",
            "Accuracy rate is 79.262673 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [341 789 129 732 609]\n",
            "Train set: (290, 10)\n",
            "Validation set: (1012, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 49\n",
            "Accuracy rate is 78.801843 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [877 357 543  93 747]\n",
            "Train set: (295, 10)\n",
            "Validation set: (1007, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 50\n",
            "Accuracy rate is 78.571429 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [ 53 815 316 182 395]\n",
            "Train set: (300, 10)\n",
            "Validation set: (1002, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 51\n",
            "Accuracy rate is 78.341014 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [312 171 901 808 366]\n",
            "Train set: (305, 10)\n",
            "Validation set: (997, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 52\n",
            "Accuracy rate is 79.493088 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [413 836 817 519 897]\n",
            "Train set: (310, 10)\n",
            "Validation set: (992, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 53\n",
            "Accuracy rate is 78.571429 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [827  87 120 174 978]\n",
            "Train set: (315, 10)\n",
            "Validation set: (987, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 54\n",
            "Accuracy rate is 79.032258 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [549   0 901 674 225]\n",
            "Train set: (320, 10)\n",
            "Validation set: (982, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 55\n",
            "Accuracy rate is 78.801843 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [105 770 446 534 489]\n",
            "Train set: (325, 10)\n",
            "Validation set: (977, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 56\n",
            "Accuracy rate is 77.880184 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [386 650 946 848 353]\n",
            "Train set: (330, 10)\n",
            "Validation set: (972, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 57\n",
            "Accuracy rate is 77.649770 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [553 546 396 388 802]\n",
            "Train set: (335, 10)\n",
            "Validation set: (967, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 58\n",
            "Accuracy rate is 79.953917 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [357 114  34 356 498]\n",
            "Train set: (340, 10)\n",
            "Validation set: (962, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 59\n",
            "Accuracy rate is 77.880184 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [851  47 469 858 443]\n",
            "Train set: (345, 10)\n",
            "Validation set: (957, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 60\n",
            "Accuracy rate is 77.649770 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [486 268 568 141 759]\n",
            "Train set: (350, 10)\n",
            "Validation set: (952, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 61\n",
            "Accuracy rate is 77.880184 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [666 573  77 641 471]\n",
            "Train set: (355, 10)\n",
            "Validation set: (947, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 62\n",
            "Accuracy rate is 78.801843 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [139 530   9 323 553]\n",
            "Train set: (360, 10)\n",
            "Validation set: (942, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 63\n",
            "Accuracy rate is 78.801843 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [ 66 410  40 478 705]\n",
            "Train set: (365, 10)\n",
            "Validation set: (937, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 64\n",
            "Accuracy rate is 78.801843 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [393 697 827 332 496]\n",
            "Train set: (370, 10)\n",
            "Validation set: (932, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 65\n",
            "Accuracy rate is 77.649770 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [636 769 502 278 228]\n",
            "Train set: (375, 10)\n",
            "Validation set: (927, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 66\n",
            "Accuracy rate is 78.110599 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [741  83 380 827 619]\n",
            "Train set: (380, 10)\n",
            "Validation set: (922, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 67\n",
            "Accuracy rate is 78.801843 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [321 189 689 279  63]\n",
            "Train set: (385, 10)\n",
            "Validation set: (917, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 68\n",
            "Accuracy rate is 79.032258 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [733 894 577 600 596]\n",
            "Train set: (390, 10)\n",
            "Validation set: (912, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 69\n",
            "Accuracy rate is 78.110599 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [408 647 503 223 197]\n",
            "Train set: (395, 10)\n",
            "Validation set: (907, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 70\n",
            "Accuracy rate is 79.032258 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [481 591 311 154 519]\n",
            "Train set: (400, 10)\n",
            "Validation set: (902, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 71\n",
            "Accuracy rate is 77.880184 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [ 44 726 380 619 361]\n",
            "Train set: (405, 10)\n",
            "Validation set: (897, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 72\n",
            "Accuracy rate is 77.419355 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [660 810 811 283 137]\n",
            "Train set: (410, 10)\n",
            "Validation set: (892, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 73\n",
            "Accuracy rate is 79.032258 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [520 277 375 440 437]\n",
            "Train set: (415, 10)\n",
            "Validation set: (887, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 74\n",
            "Accuracy rate is 78.801843 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [741 633   3 286 755]\n",
            "Train set: (420, 10)\n",
            "Validation set: (882, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 75\n",
            "Accuracy rate is 78.571429 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [573 610 876 367 661]\n",
            "Train set: (425, 10)\n",
            "Validation set: (877, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 76\n",
            "Accuracy rate is 77.419355 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [199 735 820 280 170]\n",
            "Train set: (430, 10)\n",
            "Validation set: (872, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 77\n",
            "Accuracy rate is 79.262673 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [670 867 503  70 238]\n",
            "Train set: (435, 10)\n",
            "Validation set: (867, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 78\n",
            "Accuracy rate is 79.032258 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [524 806 193 810 583]\n",
            "Train set: (440, 10)\n",
            "Validation set: (862, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 79\n",
            "Accuracy rate is 79.493088 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [438 857 106 131 392]\n",
            "Train set: (445, 10)\n",
            "Validation set: (857, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 80\n",
            "Accuracy rate is 78.801843 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [265  48  65  75 291]\n",
            "Train set: (450, 10)\n",
            "Validation set: (852, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 81\n",
            "Accuracy rate is 78.341014 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [ 78 271 387 220 640]\n",
            "Train set: (455, 10)\n",
            "Validation set: (847, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 82\n",
            "Accuracy rate is 78.801843 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [714 591 541 666 840]\n",
            "Train set: (460, 10)\n",
            "Validation set: (842, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 83\n",
            "Accuracy rate is 78.571429 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [495 554 382 641 203]\n",
            "Train set: (465, 10)\n",
            "Validation set: (837, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 84\n",
            "Accuracy rate is 78.571429 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [497 692  24 108 704]\n",
            "Train set: (470, 10)\n",
            "Validation set: (832, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 85\n",
            "Accuracy rate is 79.262673 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [326 435 162 260 637]\n",
            "Train set: (475, 10)\n",
            "Validation set: (827, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 86\n",
            "Accuracy rate is 79.032258 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [271  86 719 427 188]\n",
            "Train set: (480, 10)\n",
            "Validation set: (822, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 87\n",
            "Accuracy rate is 78.801843 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [609 624  10 330 415]\n",
            "Train set: (485, 10)\n",
            "Validation set: (817, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 88\n",
            "Accuracy rate is 78.110599 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [ 76 642 134 575  37]\n",
            "Train set: (490, 10)\n",
            "Validation set: (812, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 89\n",
            "Accuracy rate is 78.341014 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [175 227 652 795 332]\n",
            "Train set: (495, 10)\n",
            "Validation set: (807, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 90\n",
            "Accuracy rate is 78.571429 \n",
            "--------------------------------\n",
            "Monte-carlo selected indexes: [613 695 154 418 625]\n",
            "Train set: (500, 10)\n",
            "Validation set: (802, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 91\n",
            "Accuracy rate is 80.414747 \n",
            "--------------------------------\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "pool_experiment(LogModel,500,50,5)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyMfqalTRwiWuiIELJDbCQ7d",
      "mount_file_id": "1SZapm_bYNJDCJi8ECwmjrzaN8-1ruRgA",
      "name": "Logistic.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "5edc29c2ed010d6458d71a83433b383a96a8cbd3efe8531bc90c4b8a5b8bcec9"
    },
    "kernelspec": {
      "display_name": "Python 3.8.2 64-bit",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "metadata": {
      "interpreter": {
        "hash": "5edc29c2ed010d6458d71a83433b383a96a8cbd3efe8531bc90c4b8a5b8bcec9"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}