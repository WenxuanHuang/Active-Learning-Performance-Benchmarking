{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 15,
      "source": [
        "print(__doc__)\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.datasets import load_digits\n",
        "\n",
        "from sklearn.utils import check_random_state\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn import preprocessing\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.utils import check_random_state\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "pd.options.display.float_format = \"{:.1f}\".format\n",
        "\n",
        "# normalization (done)\n",
        "# option to reduce load time (done)\n",
        "# result plots\n",
        "# presentation"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Automatically created module for IPython interactive environment\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ioi13nGDPDvQ",
        "outputId": "4763f7b3-6c5b-45cb-f411-fd7c6ea8b38f"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "source": [
        "def retrieve_data_recid():\n",
        "    attributes = ['MarriageStatus','age','juv_fel_count', 'juv_misd_count', 'juv_other_count','priors_count', 'days_b_screening_arrest','c_days_from_compas','c_charge_degree']\n",
        "    bias = 'race'\n",
        "    target = 'two_year_recid'\n",
        "\n",
        "    np.random.seed(42)\n",
        "\n",
        "    data = pd.read_csv(\"https://raw.githubusercontent.com/WenxuanHuang/Active-Learning-Performance-Benchmarking/main/RecidivismData_Normalized.csv\", sep=',')\n",
        "    data_col = data.columns\n",
        "    df = data[(data[bias]==2)|(data[bias]==3)].copy().values\n",
        "\n",
        "    kf = KFold(n_splits=4) #differ from original method\n",
        "    for train_index, test_index in kf.split(df):\n",
        "        train, test = df[train_index], df[test_index]\n",
        "        # print(\"Size of X_train_full, X_test:\", train.shape, test.shape)\n",
        "\n",
        "    df_train = pd.DataFrame(data=train, columns=data_col)\n",
        "    df_test = pd.DataFrame(data=test, columns=data_col)\n",
        "\n",
        "    labeled = df_train.groupby(target, group_keys=False).apply(lambda x: x.sample(n=5, random_state = 42)) # ten sample in total labeled initially\n",
        "    df_X_labeled = labeled[attributes]\n",
        "    df_y_labeled = labeled[target]\n",
        "    X_labeled = df_X_labeled.values\n",
        "    y_labeled = df_y_labeled.values.astype('int64')\n",
        "    b_labeled = labeled[bias].values-2\n",
        "    (row_size, col_size) = X_labeled.shape\n",
        "\n",
        "    unlabeled = df_train.drop(df_X_labeled.index)\n",
        "    df_X_unlabeled = unlabeled[attributes]\n",
        "    df_y_unlabeled = unlabeled[target]\n",
        "    X_unlabeled = df_X_unlabeled.values\n",
        "    y_unlabeled = df_y_unlabeled.values.astype('int64')\n",
        "    b_unlabeled = unlabeled[bias].values-2\n",
        "\n",
        "    X_test = df_test[attributes].values\n",
        "    y_test = df_test[target].values\n",
        "    y_test=y_test.astype('int')\n",
        "    b_test = df_test[bias].values-2\n",
        "\n",
        "    X_fair_est = X_unlabeled\n",
        "    y_fair_est = y_unlabeled\n",
        "    b_fair_est = b_unlabeled\n",
        "    \n",
        "    return (X_labeled, y_labeled, b_labeled, row_size, col_size, X_unlabeled, y_unlabeled, b_unlabeled, X_test, y_test, b_test, X_fair_est, y_fair_est, b_fair_est)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "source": [
        "class BaseModel(object):\n",
        "\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def fit_predict(self):\n",
        "        pass\n",
        "\n",
        "class LogModel(BaseModel):\n",
        "\n",
        "    def fit_predict(self, X_labeled, y_labeled, X_test, y_test):\n",
        "        self.classifier = LogisticRegression(\n",
        "            solver='liblinear'\n",
        "            )\n",
        "        self.classifier.fit(X_labeled, y_labeled)\n",
        "        # self.y_test_predicted = self.classifier.predict(X_test)\n",
        "        # self.y_unlabeled_predicted = self.classifier.predict(X_unlabeled)\n",
        "        self.y_test_score = self.classifier.score(X_test, y_test)\n",
        "        return (X_labeled, X_test, self.y_test_score)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "source": [
        "class TrainModel:\n",
        "\n",
        "    def __init__(self, model_object):        \n",
        "        self.accuracies = []\n",
        "        self.model_object = model_object()        \n",
        "\n",
        "    def print_model_type(self):\n",
        "        print (self.model_object.model_type)\n",
        "\n",
        "    def train(self, X_labeled, y_labeled, X_test, y_test):\n",
        "        (X_labeled, X_test, self.y_test_score) = \\\n",
        "            self.model_object.fit_predict(X_labeled, y_labeled, X_test, y_test)\n",
        "        return (X_labeled, X_test)\n",
        "\n",
        "    def get_test_accuracy(self, i):\n",
        "        classif_rate = self.y_test_score * 100\n",
        "        self.accuracies.append(classif_rate)               \n",
        "        print('--------------------------------')\n",
        "        print('Iteration:',i)\n",
        "        print(\"Accuracy rate is %f \" % (classif_rate))"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "source": [
        "class QueryFunction(object):\n",
        "\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def pool_select(self):\n",
        "        pass\n",
        "\n",
        "\n",
        "# class RandomSelection(QueryFunction):\n",
        "\n",
        "#     @staticmethod\n",
        "#     def pool_select(probas_val, batch_size):\n",
        "#         random_state = check_random_state(0)\n",
        "#         # probas_val.shape[0] is the size of validation set\n",
        "#         selection = np.random.choice(probas_val.shape[0], batch_size, replace=False)\n",
        "#         # print('uniques chosen:',np.unique(selection).shape[0],'<= should be equal to:',batch_size)\n",
        "#         return selection\n",
        "\n",
        "\n",
        "# class EntropySelection(QueryFunction):\n",
        "\n",
        "#     @staticmethod\n",
        "#     def pool_select(probas_val, batch_size):\n",
        "#         e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
        "#         selection = (np.argsort(e)[::-1])[:batch_size]\n",
        "#         return selection\n",
        "\n",
        "# class MinStdSelection(QueryFunction):\n",
        "\n",
        "#     # select the samples where the std is smallest. There is uncertainty regarding the relevant class\n",
        "#     # and then train on these \"hard\" to classify samples.\n",
        "#     @staticmethod\n",
        "#     def pool_select(probas_val, batch_size):\n",
        "#         std = np.std(probas_val * 100, axis=1) \n",
        "#         selection = std.argsort()[:batch_size]\n",
        "#         selection = selection.astype('int64')\n",
        "#         print('std',std.shape,std)\n",
        "#         print('selection',selection, selection.shape, std[selection])\n",
        "#         return selection\n",
        "\n",
        "# class LeastConfidenceSelection(QueryFunction):\n",
        "\n",
        "#     @staticmethod\n",
        "#     def pool_select(probas_val, batch_size):\n",
        "#         sort_prob = -np.sort(-probas_val, axis=1)\n",
        "#         values = sort_prob[:, 0]\n",
        "#         selection = np.argsort(values)[:batch_size]\n",
        "#         return selection\n",
        "      \n",
        "      \n",
        "class MarginSelection(QueryFunction):\n",
        "\n",
        "    @staticmethod\n",
        "    def pool_select(probas_val, batch_size):\n",
        "        sort_prob = -np.sort(-probas_val, axis=1)\n",
        "        values = sort_prob[:, 0] - sort_prob[:, 1]\n",
        "        selection = np.argsort(values)[:batch_size]\n",
        "        return selection\n"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "source": [
        "def normalizer(e_loss, f_loss):\n",
        "    e_loss = np.reshape(e_loss, (1,len(e_loss)))\n",
        "    f_loss = np.reshape(f_loss, (1,len(f_loss)))\n",
        "    e_scaled = preprocessing.normalize(e_loss)\n",
        "    # e_scaled=((e_loss-e_loss.min())/(e_loss.max()-e_loss.min()))\n",
        "    f_scaled = preprocessing.normalize(f_loss)\n",
        "    # f_scaled=((f_loss-f_loss.min())/(f_loss.max()-f_loss.min()))\n",
        "    return (e_scaled, f_scaled)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "source": [
        "def log_loss(probas_val):\n",
        "    \n",
        "    eps = np.finfo(probas_val.dtype).eps\n",
        "    probas_val = np.clip(probas_val, eps, 1 - eps)\n",
        "    e_loss = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
        "\n",
        "    return e_loss"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "source": [
        "# separation \\ equalized odds - Hardt, Price, Srebro (2016)\n",
        "\n",
        "def eqods(X_fair_est, y_fair_est, b_fair_est, classifier):\n",
        "    \n",
        "    y_fair_pred = classifier.predict(X_fair_est)\n",
        "\n",
        "    b0p1=X_fair_est[(b_fair_est==0)&(y_fair_pred==1)&(y_fair_est==1)].shape[0]\n",
        "    b0=X_fair_est[(b_fair_est==0)&(y_fair_est==1)].shape[0]\n",
        "    b1p1=X_fair_est[(b_fair_est==1)&(y_fair_pred==1)&(y_fair_est==1)].shape[0]\n",
        "    b1=X_fair_est[(b_fair_est==1)&(y_fair_est==1)].shape[0]\n",
        "\n",
        "    f_loss=(b0/(b0p1+b0))-(b1/(b1p1+b1))\n",
        "    # print(\"Debug fair_loss shape:\", b0p1, b0, b1p1, b1)\n",
        "    \n",
        "    return abs(f_loss)\n",
        "    "
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "source": [
        "# selecting fairness criteria\n",
        "\n",
        "def fair_loss(X_fair_est, y_fair_est, b_fair_est, classifier=None, criteria=0):\n",
        "\n",
        "    if criteria == 'equalized_odds':\n",
        "        return eqods(X_fair_est, y_fair_est, b_fair_est, classifier)\n",
        "    else: return 0"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "source": [
        "def error_reduction_sampling(query_size, X_unlabeled, X_labeled, y_labeled, classifier, X_fair_est, y_fair_est, b_fair_est, probas_val, step):\n",
        "    # further to be defined, now assume only fairness loss\n",
        "    # query size used here\n",
        "    div = 0\n",
        "\n",
        "    unlabeled_size = len(X_unlabeled)\n",
        "    f_loss = np.zeros(unlabeled_size)\n",
        "    for i in range(unlabeled_size):\n",
        "        f_loss_temp = []\n",
        "        for j in range(2):\n",
        "            X_labeled_temp = np.append(X_labeled, [X_unlabeled[i]], axis = 0)\n",
        "            y_labeled_temp = np.append(y_labeled, [j], axis = 0)\n",
        "            classifier_temp = LogisticRegression(solver='liblinear').fit(X_labeled_temp, y_labeled_temp)\n",
        "            f_loss_temp = np.append(f_loss_temp, fair_loss(X_fair_est, y_fair_est, b_fair_est, classifier=classifier_temp, criteria='equalized_odds'))\n",
        "            f_loss_temp[np.isnan(f_loss_temp)] = 0\n",
        "            \n",
        "        proba_0 = classifier.predict_proba(X_unlabeled)[i][0]\n",
        "        proba_1 = 1 - proba_0\n",
        "        f_loss[i] = (f_loss_temp).dot([proba_0, proba_1])\n",
        "\n",
        "    e_loss = log_loss(probas_val)\n",
        "\n",
        "    e_scaled, f_scaled = normalizer(e_loss, f_loss)\n",
        "    f_scaled[np.isnan(f_scaled)] = 0\n",
        "\n",
        "    loss = div*(e_loss)+(1-div)*f_loss\n",
        "    \n",
        "    selection = np.argsort(loss)[::-1][:step]\n",
        "\n",
        "    return selection"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "source": [
        "class active_learning(object):\n",
        "\n",
        "    def __init__(self, step, budget, model_object, selection_function):\n",
        "        self.step = step\n",
        "        self.budget = budget\n",
        "        self.model_object = model_object\n",
        "        self.sample_selection_function = selection_function\n",
        "        \n",
        "    def run(self, X_labeled, y_labeled, b_labeled, row_size, col_size, X_unlabeled, y_unlabeled, b_unlabeled, X_test, y_test, b_test, X_fair_est, y_fair_est, b_fair_est, sub_option):\n",
        "  \n",
        "        self.clf_model = TrainModel(self.model_object)\n",
        "        (X_labeled, X_test) = self.clf_model.train(X_labeled, y_labeled, X_test, y_test)\n",
        "        active_iteration = 1\n",
        "        self.clf_model.get_test_accuracy(active_iteration)\n",
        "\n",
        "        self.query_size = len(X_labeled)\n",
        "\n",
        "        while self.query_size <= self.budget-self.step:\n",
        "\n",
        "            active_iteration += 1\n",
        "            self.query_size += self.step\n",
        "\n",
        "            probas_val = \\\n",
        "                self.clf_model.model_object.classifier.predict_proba(X_unlabeled)\n",
        "\n",
        "            # y_unlabeled_predicted = \\\n",
        "            #     self.clf_model.model_object.classifier.predict(X_unlabeled)\n",
        "            \n",
        "            # print(\"Debug predicted:\", y_unlabeled_predicted.shape)\n",
        "            # print(\"Debug probas_val:\", probas_val.shape)\n",
        "\n",
        "            if sub_option == True:\n",
        "                candidates = self.sample_selection_function.pool_select(probas_val, self.budget)\n",
        "                uncertain_samples = error_reduction_sampling(self.query_size, X_unlabeled[candidates], X_labeled, y_labeled, self.clf_model.model_object.classifier, X_fair_est[candidates], y_fair_est[candidates], b_fair_est[candidates], probas_val[candidates], self.step)\n",
        "            else: \n",
        "                uncertain_samples = error_reduction_sampling(self.query_size, X_unlabeled, X_labeled, y_labeled, self.clf_model.model_object.classifier, X_fair_est, y_fair_est, b_fair_est, probas_val, self.step)\n",
        "\n",
        "            # print(\"Debug shape of X_unlabeled and loss:\", selection)\n",
        "\n",
        "            # uncertain_samples = self.sample_selection_function.pool_select(probas_val, self.step)\n",
        "\n",
        "            X_labeled = np.concatenate((X_labeled, X_unlabeled[uncertain_samples]))\n",
        "            y_labeled = np.concatenate((y_labeled, y_unlabeled[uncertain_samples]))\n",
        "            X_unlabeled = np.delete(X_unlabeled, uncertain_samples, axis=0)\n",
        "            y_unlabeled = np.delete(y_unlabeled, uncertain_samples, axis=0)\n",
        "\n",
        "            (X_labeled, X_test) = self.clf_model.train(X_labeled, y_labeled, X_test, y_test)\n",
        "            self.clf_model.get_test_accuracy(active_iteration)\n",
        "\n",
        "        return self.clf_model.accuracies"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "source": [
        "def non_active_learning(X_unlabeled, y_unlabeled, X_labeled,y_labeled, X_test, y_test, budget, step):\n",
        "    \n",
        "    nonal_X_train = np.concatenate((X_unlabeled, X_labeled))\n",
        "    nonal_y_train = np.concatenate((y_unlabeled, y_labeled))\n",
        "    nonal_X_test = X_test\n",
        "    nonal_y_test = y_test\n",
        "\n",
        "    nonal_initial_query = 10 # temporary implementation\n",
        "    nonal_accuracies=[]\n",
        "\n",
        "    classifier_nonal = LogisticRegression(\n",
        "            solver='liblinear'\n",
        "            )\n",
        "    x_axis = [] \n",
        "    for i in range(nonal_initial_query-1,budget,step): \n",
        "        classifier_nonal.fit(nonal_X_train[:i+1], nonal_y_train[:i+1])\n",
        "        nonal_y_pred = classifier_nonal.predict(nonal_X_test)\n",
        "        nonal_accuracies.append(accuracy_score(nonal_y_test, nonal_y_pred)*100)\n",
        "        x_axis.append(i+1)\n",
        "\n",
        "    return x_axis, nonal_accuracies"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "source": [
        "def experiment(model,sampling_method,budget,step, sub_option=False):\n",
        "    \n",
        "    (X_labeled, y_labeled, b_labeled, row_size, col_size, X_unlabeled, y_unlabeled, b_unlabeled, X_test, y_test, b_test, X_fair_est, y_fair_est, b_fair_est) = retrieve_data_recid()\n",
        "        \n",
        "    act_alg = active_learning(step, budget, model , sampling_method)\n",
        "\n",
        "    accuracies = act_alg.run(X_labeled, y_labeled, b_labeled, row_size, col_size, X_unlabeled, y_unlabeled, b_unlabeled, X_test, y_test, b_test, X_fair_est, y_fair_est, b_fair_est, sub_option)\n",
        "\n",
        "    x_axis, nonal_accuracies = non_active_learning(X_unlabeled, y_unlabeled, X_labeled,y_labeled, X_test, y_test, budget, step)\n",
        "\n",
        "    # print(\"active_accuracies\",accuracies)\n",
        "    # print(\"nonactive_accuracies\",nonal_accuracies)\n",
        "    \n",
        "    plt.plot(x_axis, accuracies, 'r',label='active')\n",
        "    plt.plot(x_axis, nonal_accuracies, 'b',label='non-active')\n",
        "    plt.legend()\n",
        "    plt.xlabel('Sample Size')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.show()"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "source": [
        "experiment(LogModel,MarginSelection,510,25,True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------\n",
            "Iteration: 1\n",
            "Accuracy rate is 57.629428 \n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "Accuracy rate is 61.239782 \n",
            "--------------------------------\n",
            "Iteration: 3\n",
            "Accuracy rate is 64.373297 \n",
            "--------------------------------\n",
            "Iteration: 4\n",
            "Accuracy rate is 64.373297 \n",
            "--------------------------------\n",
            "Iteration: 5\n",
            "Accuracy rate is 64.237057 \n",
            "--------------------------------\n",
            "Iteration: 6\n",
            "Accuracy rate is 64.305177 \n",
            "--------------------------------\n",
            "Iteration: 7\n",
            "Accuracy rate is 65.735695 \n",
            "--------------------------------\n",
            "Iteration: 8\n",
            "Accuracy rate is 64.782016 \n",
            "--------------------------------\n",
            "Iteration: 9\n",
            "Accuracy rate is 67.029973 \n",
            "--------------------------------\n",
            "Iteration: 10\n",
            "Accuracy rate is 66.212534 \n",
            "--------------------------------\n",
            "Iteration: 11\n",
            "Accuracy rate is 67.234332 \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "metadata": {}
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyMfqalTRwiWuiIELJDbCQ7d",
      "mount_file_id": "1SZapm_bYNJDCJi8ECwmjrzaN8-1ruRgA",
      "name": "Logistic.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "a2ef89d34cbfddaf50816f8d91581a3ca0913b9280767ed31a38c2db7dcc022c"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.2 64-bit ('ML-for-COVID-19-dataset': venv)"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "metadata": {
      "interpreter": {
        "hash": "5edc29c2ed010d6458d71a83433b383a96a8cbd3efe8531bc90c4b8a5b8bcec9"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}