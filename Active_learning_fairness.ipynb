{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 27,
      "source": [
        "print(__doc__)\n",
        "\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.datasets import load_digits\n",
        "\n",
        "from sklearn.utils import check_random_state\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn import preprocessing\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.utils import check_random_state\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "pd.options.display.float_format = \"{:.1f}\".format\n",
        "\n",
        "# normalization (done)\n",
        "# option to reduce load time (delayed)\n",
        "# result plots\n",
        "# presentation"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Automatically created module for IPython interactive environment\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ioi13nGDPDvQ",
        "outputId": "4763f7b3-6c5b-45cb-f411-fd7c6ea8b38f"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "source": [
        "def retrieve_data_recid():\n",
        "    attributes = ['MarriageStatus','age','juv_fel_count', 'juv_misd_count', 'juv_other_count','priors_count', 'days_b_screening_arrest','c_days_from_compas','c_charge_degree']\n",
        "    bias = 'race'\n",
        "    target = 'two_year_recid'\n",
        "\n",
        "    np.random.seed(42)\n",
        "\n",
        "    data = pd.read_csv(\"https://raw.githubusercontent.com/WenxuanHuang/Active-Learning-Performance-Benchmarking/main/RecidivismData_Normalized.csv\", sep=',')\n",
        "    data_col = data.columns\n",
        "    df = data[(data[bias]==2)|(data[bias]==3)].copy().values\n",
        "\n",
        "    kf = KFold(n_splits=4) #differ from original method\n",
        "    for train_index, test_index in kf.split(df):\n",
        "        train, test = df[train_index], df[test_index]\n",
        "        # print(\"Size of X_train_full, X_test:\", train.shape, test.shape)\n",
        "\n",
        "    df_train = pd.DataFrame(data=train, columns=data_col)\n",
        "    df_test = pd.DataFrame(data=test, columns=data_col)\n",
        "\n",
        "    labeled = df_train.groupby(target, group_keys=False).apply(lambda x: x.sample(n=5, random_state = 42)) # ten sample in total labeled initially\n",
        "    df_X_labeled = labeled[attributes]\n",
        "    df_y_labeled = labeled[target]\n",
        "    X_labeled = df_X_labeled.values\n",
        "    y_labeled = df_y_labeled.values.astype('int64')\n",
        "    b_labeled = labeled[bias].values-2\n",
        "    (row_size, col_size) = X_labeled.shape\n",
        "\n",
        "    unlabeled = df_train.drop(df_X_labeled.index)\n",
        "    df_X_unlabeled = unlabeled[attributes]\n",
        "    df_y_unlabeled = unlabeled[target]\n",
        "    X_unlabeled = df_X_unlabeled.values\n",
        "    y_unlabeled = df_y_unlabeled.values.astype('int64')\n",
        "    b_unlabeled = unlabeled[bias].values-2\n",
        "\n",
        "    X_test = df_test[attributes].values\n",
        "    y_test = df_test[target].values\n",
        "    y_test=y_test.astype('int')\n",
        "    b_test = df_test[bias].values-2\n",
        "\n",
        "    X_fair_est = X_unlabeled\n",
        "    y_fair_est = y_unlabeled\n",
        "    b_fair_est = b_unlabeled\n",
        "    \n",
        "    return (X_labeled, y_labeled, b_labeled, row_size, col_size, X_unlabeled, y_unlabeled, b_unlabeled, X_test, y_test, b_test, X_fair_est, y_fair_est, b_fair_est)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "source": [
        "class BaseModel(object):\n",
        "\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def fit_predict(self):\n",
        "        pass\n",
        "\n",
        "class LogModel(BaseModel):\n",
        "\n",
        "    def fit_predict(self, X_labeled, y_labeled, X_test, y_test):\n",
        "        self.classifier = LogisticRegression(\n",
        "            solver='liblinear'\n",
        "            )\n",
        "        self.classifier.fit(X_labeled, y_labeled)\n",
        "        # self.y_test_predicted = self.classifier.predict(X_test)\n",
        "        # self.y_unlabeled_predicted = self.classifier.predict(X_unlabeled)\n",
        "        self.y_test_score = self.classifier.score(X_test, y_test)\n",
        "        return (X_labeled, X_test, self.y_test_score)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "source": [
        "class TrainModel:\n",
        "\n",
        "    def __init__(self, model_object):        \n",
        "        self.accuracies = []\n",
        "        self.model_object = model_object()        \n",
        "\n",
        "    def print_model_type(self):\n",
        "        print (self.model_object.model_type)\n",
        "\n",
        "    def train(self, X_labeled, y_labeled, X_test, y_test):\n",
        "        t0 = time.time()\n",
        "        (X_labeled, X_test, self.y_test_score) = \\\n",
        "            self.model_object.fit_predict(X_labeled, y_labeled, X_test, y_test)\n",
        "        self.run_time = time.time() - t0\n",
        "        return (X_labeled, X_test)\n",
        "\n",
        "    def get_test_accuracy(self, i):\n",
        "        classif_rate = self.y_test_score * 100\n",
        "        self.accuracies.append(classif_rate)               \n",
        "        print('--------------------------------')\n",
        "        print('Iteration:',i)\n",
        "        print(\"Accuracy rate is %f \" % (classif_rate))"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "source": [
        "class QueryFunction(object):\n",
        "\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def pool_select(self):\n",
        "        pass\n",
        "\n",
        "\n",
        "# class RandomSelection(QueryFunction):\n",
        "\n",
        "#     @staticmethod\n",
        "#     def pool_select(probas_val, batch_size):\n",
        "#         random_state = check_random_state(0)\n",
        "#         # probas_val.shape[0] is the size of validation set\n",
        "#         selection = np.random.choice(probas_val.shape[0], batch_size, replace=False)\n",
        "#         # print('uniques chosen:',np.unique(selection).shape[0],'<= should be equal to:',batch_size)\n",
        "#         return selection\n",
        "\n",
        "\n",
        "# class EntropySelection(QueryFunction):\n",
        "\n",
        "#     @staticmethod\n",
        "#     def pool_select(probas_val, batch_size):\n",
        "#         e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
        "#         selection = (np.argsort(e)[::-1])[:batch_size]\n",
        "#         return selection\n",
        "\n",
        "# class MinStdSelection(QueryFunction):\n",
        "\n",
        "#     # select the samples where the std is smallest. There is uncertainty regarding the relevant class\n",
        "#     # and then train on these \"hard\" to classify samples.\n",
        "#     @staticmethod\n",
        "#     def pool_select(probas_val, batch_size):\n",
        "#         std = np.std(probas_val * 100, axis=1) \n",
        "#         selection = std.argsort()[:batch_size]\n",
        "#         selection = selection.astype('int64')\n",
        "#         print('std',std.shape,std)\n",
        "#         print('selection',selection, selection.shape, std[selection])\n",
        "#         return selection\n",
        "\n",
        "# class LeastConfidenceSelection(QueryFunction):\n",
        "\n",
        "#     @staticmethod\n",
        "#     def pool_select(probas_val, batch_size):\n",
        "#         sort_prob = -np.sort(-probas_val, axis=1)\n",
        "#         values = sort_prob[:, 0]\n",
        "#         selection = np.argsort(values)[:batch_size]\n",
        "#         return selection\n",
        "      \n",
        "      \n",
        "class MarginSelection(QueryFunction):\n",
        "\n",
        "    @staticmethod\n",
        "    def pool_select(probas_val, batch_size):\n",
        "        sort_prob = -np.sort(-probas_val, axis=1)\n",
        "        values = sort_prob[:, 0] - sort_prob[:, 1]\n",
        "        selection = np.argsort(values)[:batch_size]\n",
        "        return selection\n"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "source": [
        "def normalizer(e_loss, f_loss):\n",
        "    e_loss = np.reshape(e_loss, (1,len(e_loss)))\n",
        "    f_loss = np.reshape(f_loss, (1,len(f_loss)))\n",
        "    e_scaled = preprocessing.normalize(e_loss)\n",
        "    # e_scaled=((e_loss-e_loss.min())/(e_loss.max()-e_loss.min()))\n",
        "    f_scaled = preprocessing.normalize(f_loss)\n",
        "    # f_scaled=((f_loss-f_loss.min())/(f_loss.max()-f_loss.min()))\n",
        "    return (e_scaled, f_scaled)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "source": [
        "def log_loss(probas_val):\n",
        "    \n",
        "    eps = np.finfo(probas_val.dtype).eps\n",
        "    probas_val = np.clip(probas_val, eps, 1 - eps)\n",
        "    e_loss = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
        "\n",
        "    return e_loss"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "source": [
        "# separation \\ equalized odds - Hardt, Price, Srebro (2016)\n",
        "\n",
        "def eqods(X_fair_est, y_fair_est, b_fair_est, classifier):\n",
        "    \n",
        "    y_fair_pred = classifier.predict(X_fair_est)\n",
        "\n",
        "    b0p1=X_fair_est[(b_fair_est==0)&(y_fair_pred==1)&(y_fair_est==1)].shape[0]\n",
        "    b0=X_fair_est[(b_fair_est==0)&(y_fair_est==1)].shape[0]\n",
        "    b1p1=X_fair_est[(b_fair_est==1)&(y_fair_pred==1)&(y_fair_est==1)].shape[0]\n",
        "    b1=X_fair_est[(b_fair_est==1)&(y_fair_est==1)].shape[0]\n",
        "\n",
        "    f_loss=(b0/(b0p1+b0))-(b1/(b1p1+b1))\n",
        "    # print(\"Debug fair_loss shape:\", b0p1, b0, b1p1, b1)\n",
        "    \n",
        "    return abs(f_loss)\n",
        "    "
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "source": [
        "# selecting fairness criteria\n",
        "\n",
        "def fair_loss(X_fair_est, y_fair_est, b_fair_est, classifier=None, criteria=0):\n",
        "\n",
        "    if criteria == 'equalized_odds':\n",
        "        return eqods(X_fair_est, y_fair_est, b_fair_est, classifier)\n",
        "    else: return 0"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "source": [
        "def error_reduction_sampling(query_size, X_unlabeled, X_labeled, y_labeled, classifier, X_fair_est, y_fair_est, b_fair_est, probas_val, step):\n",
        "    # further to be defined, now assume only fairness loss\n",
        "    div = 0\n",
        "\n",
        "    unlabeled_size = len(X_unlabeled)\n",
        "    f_loss = np.zeros(unlabeled_size)\n",
        "    for i in range(unlabeled_size):\n",
        "        f_loss_temp = []\n",
        "        for j in range(2):\n",
        "            X_labeled_temp = np.append(X_labeled, [X_unlabeled[i]], axis = 0)\n",
        "            y_labeled_temp = np.append(y_labeled, [j], axis = 0)\n",
        "            classifier_temp = LogisticRegression(solver='liblinear').fit(X_labeled_temp, y_labeled_temp)\n",
        "            f_loss_temp = np.append(f_loss_temp, fair_loss(X_fair_est, y_fair_est, b_fair_est, classifier=classifier_temp, criteria='equalized_odds'))\n",
        "            f_loss_temp[np.isnan(f_loss_temp)] = 0\n",
        "            \n",
        "        proba_0 = classifier.predict_proba(X_unlabeled)[i][0]\n",
        "        proba_1 = 1 - proba_0\n",
        "        f_loss[i] = (f_loss_temp).dot([proba_0, proba_1])\n",
        "\n",
        "    e_loss = log_loss(probas_val)\n",
        "\n",
        "    e_scaled, f_scaled = normalizer(e_loss, f_loss)\n",
        "    f_scaled[np.isnan(f_scaled)] = 0\n",
        "\n",
        "    loss = div*(e_loss)+(1-div)*f_loss\n",
        "    \n",
        "    selection = np.argsort(loss)[::-1][:step]\n",
        "\n",
        "    return selection"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "source": [
        "class active_learning(object):\n",
        "\n",
        "    def __init__(self, step, model_object, selection_function):\n",
        "        self.step = step\n",
        "        self.model_object = model_object\n",
        "        self.sample_selection_function = selection_function\n",
        "        \n",
        "    def run(self, X_labeled, y_labeled, b_labeled, row_size, col_size, X_unlabeled, y_unlabeled, b_unlabeled, X_test, y_test, b_test, X_fair_est, y_fair_est, b_fair_est, budget):\n",
        "  \n",
        "        self.clf_model = TrainModel(self.model_object)\n",
        "        (X_labeled, X_test) = self.clf_model.train(X_labeled, y_labeled, X_test, y_test)\n",
        "        active_iteration = 1\n",
        "        self.clf_model.get_test_accuracy(active_iteration)\n",
        "\n",
        "        self.query_size = len(X_labeled)\n",
        "\n",
        "        while self.query_size <= budget-self.step:\n",
        "\n",
        "            active_iteration += 1\n",
        "            self.query_size += self.step\n",
        "\n",
        "            probas_val = \\\n",
        "                self.clf_model.model_object.classifier.predict_proba(X_unlabeled)\n",
        "\n",
        "            # y_unlabeled_predicted = \\\n",
        "            #     self.clf_model.model_object.classifier.predict(X_unlabeled)\n",
        "            \n",
        "            # print(\"Debug predicted:\", y_unlabeled_predicted.shape)\n",
        "            # print(\"Debug probas_val:\", probas_val.shape)\n",
        "\n",
        "\n",
        "            uncertain_samples = error_reduction_sampling(self.query_size, X_unlabeled, X_labeled, y_labeled, self.clf_model.model_object.classifier, X_fair_est, y_fair_est, b_fair_est, probas_val, self.step)\n",
        "\n",
        "            # print(\"Debug shape of X_unlabeled and loss:\", selection)\n",
        "\n",
        "            # uncertain_samples = self.sample_selection_function.pool_select(probas_val, self.step)\n",
        "\n",
        "            X_labeled = np.concatenate((X_labeled, X_unlabeled[uncertain_samples]))\n",
        "            y_labeled = np.concatenate((y_labeled, y_unlabeled[uncertain_samples]))\n",
        "            X_unlabeled = np.delete(X_unlabeled, uncertain_samples, axis=0)\n",
        "            y_unlabeled = np.delete(y_unlabeled, uncertain_samples, axis=0)\n",
        "\n",
        "            (X_labeled, X_test) = self.clf_model.train(X_labeled, y_labeled, X_test, y_test)\n",
        "            self.clf_model.get_test_accuracy(active_iteration)\n",
        "\n",
        "        return self.clf_model.accuracies"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "source": [
        "def non_active_learning(X_unlabeled, y_unlabeled, X_labeled,y_labeled, X_test, y_test, budget, step):\n",
        "    \n",
        "    nonal_X_train = np.concatenate((X_unlabeled, X_labeled))\n",
        "    nonal_y_train = np.concatenate((y_unlabeled, y_labeled))\n",
        "    nonal_X_test = X_test\n",
        "    nonal_y_test = y_test\n",
        "\n",
        "    nonal_initial_query = 10 # temporary implementation\n",
        "    nonal_accuracies=[]\n",
        "\n",
        "    classifier_nonal = LogisticRegression(\n",
        "            solver='liblinear'\n",
        "            )\n",
        "    x_axis = [] \n",
        "    for i in range(nonal_initial_query-1,budget,step): \n",
        "        classifier_nonal.fit(nonal_X_train[:i+1], nonal_y_train[:i+1])\n",
        "        nonal_y_pred = classifier_nonal.predict(nonal_X_test)\n",
        "        nonal_accuracies.append(accuracy_score(nonal_y_test, nonal_y_pred)*100)\n",
        "        x_axis.append(i+1)\n",
        "\n",
        "    return x_axis, nonal_accuracies"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "source": [
        "def experiment(model,sampling_method,budget,step):\n",
        "    \n",
        "    (X_labeled, y_labeled, b_labeled, row_size, col_size, X_unlabeled, y_unlabeled, b_unlabeled, X_test, y_test, b_test, X_fair_est, y_fair_est, b_fair_est) = retrieve_data_recid()\n",
        "        \n",
        "    act_alg = active_learning(step, model , sampling_method)\n",
        "\n",
        "    accuracies = act_alg.run(X_labeled, y_labeled, b_labeled, row_size, col_size, X_unlabeled, y_unlabeled, b_unlabeled, X_test, y_test, b_test, X_fair_est, y_fair_est, b_fair_est, budget)\n",
        "\n",
        "    x_axis, nonal_accuracies = non_active_learning(X_unlabeled, y_unlabeled, X_labeled,y_labeled, X_test, y_test, budget, step)\n",
        "\n",
        "    # print(\"active_accuracies\",accuracies)\n",
        "    # print(\"nonactive_accuracies\",nonal_accuracies)\n",
        "    \n",
        "    plt.plot(x_axis, accuracies, 'r',label='active')\n",
        "    plt.plot(x_axis, nonal_accuracies, 'b',label='non-active')\n",
        "    plt.legend()\n",
        "    plt.xlabel('Sample Size')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.show()"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "source": [
        "experiment(LogModel,MarginSelection,510,50)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------\n",
            "Iteration: 1\n",
            "Accuracy rate is 57.629428 \n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "Accuracy rate is 59.673025 \n",
            "--------------------------------\n",
            "Iteration: 3\n",
            "Accuracy rate is 58.787466 \n",
            "--------------------------------\n",
            "Iteration: 4\n",
            "Accuracy rate is 58.446866 \n",
            "--------------------------------\n",
            "Iteration: 5\n",
            "Accuracy rate is 61.920981 \n",
            "--------------------------------\n",
            "Iteration: 6\n",
            "Accuracy rate is 64.713896 \n",
            "--------------------------------\n",
            "Iteration: 7\n",
            "Accuracy rate is 66.008174 \n",
            "--------------------------------\n",
            "Iteration: 8\n",
            "Accuracy rate is 64.509537 \n",
            "--------------------------------\n",
            "Iteration: 9\n",
            "Accuracy rate is 64.305177 \n",
            "--------------------------------\n",
            "Iteration: 10\n",
            "Accuracy rate is 64.441417 \n"
          ]
        }
      ],
      "metadata": {}
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyMfqalTRwiWuiIELJDbCQ7d",
      "mount_file_id": "1SZapm_bYNJDCJi8ECwmjrzaN8-1ruRgA",
      "name": "Logistic.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "a2ef89d34cbfddaf50816f8d91581a3ca0913b9280767ed31a38c2db7dcc022c"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.2 64-bit ('ML-for-COVID-19-dataset': venv)"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "metadata": {
      "interpreter": {
        "hash": "5edc29c2ed010d6458d71a83433b383a96a8cbd3efe8531bc90c4b8a5b8bcec9"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}