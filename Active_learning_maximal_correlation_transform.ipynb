{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n"
     ]
    }
   ],
   "source": [
    "print(__doc__)\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.utils import check_random_state\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "from sklearn.metrics import mutual_info_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# from ace import model\n",
    "# from ace import ace\n",
    "import ace.model\n",
    "import ace.ace\n",
    "\n",
    "pd.options.display.float_format = \"{:.1f}\".format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_data_recid():\n",
    "\n",
    "    \"\"\" This function is used for retrieving dataset COMPAS and split data entries into labeled (training, testing) and unlabeled data (validation) \n",
    "    Prediction task is to determine whether a person will recidive after first prosecution\"\"\"\n",
    "\n",
    "    \"\"\" Binary classification\n",
    "    =================  ======================\n",
    "    samples total      5875\n",
    "    Dimensionality     9(Features)+1(Bias)\n",
    "    Features           real\n",
    "    Classes            2\n",
    "    =================  ======================\n",
    "\n",
    "    Source\n",
    "    ----------\n",
    "    How We Analyzed the COMPAS Recidivism Algorithm, by Jeff Larson, Surya Mattu, Lauren Kirchner and Julia Angwin, May 23, 2016\n",
    "    https://www.propublica.org/article/how-we-analyzed-the-compas-recidivism-algorithm\n",
    "    https://github.com/propublica/compas-analysis\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    none\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    X_labeled: training data, ndarray, shape (10, 9)\n",
    "    y_labeled: training target, ndarray, shape (10, ) \n",
    "    b_labeled: bias attribute of training set, ndarray, shape (10, )\n",
    "\n",
    "    X_unlabeled: sample pool data, ndarray, shape (4397, 9)\n",
    "    y_unlabeled: sample pool target, ndarray, shape (4397, )\n",
    "    b_unlabeled: bias attribute of sample pool set, ndarray, shape (4397, )\n",
    "\n",
    "    X_test: testing data, ndarray, shape (1468, 9)\n",
    "    y_test: testing target, ndarray, shape (1468, )\n",
    "    b_test: bias attribute of testing set, ndarray, shape (1468, )\n",
    "    \"\"\"\n",
    "    \n",
    "    mc_attributes = ['MarriageStatus','age','juv_fel_count', 'juv_misd_count', 'juv_other_count','priors_count', 'days_b_screening_arrest','c_days_from_compas','c_charge_degree','race']\n",
    "    attributes = ['MarriageStatus','age','juv_fel_count', 'juv_misd_count', 'juv_other_count','priors_count', 'days_b_screening_arrest','c_days_from_compas','c_charge_degree']\n",
    "    bias = 'race'\n",
    "    target = 'two_year_recid'\n",
    "\n",
    "    # np.random.seed(42)\n",
    "    data = pd.read_csv(\"https://raw.githubusercontent.com/WenxuanHuang/Active-Learning-Performance-Benchmarking/main/RecidivismData_Normalized.csv\", sep=',')\n",
    "    data_col = data.columns\n",
    "    df = data[(data[bias]==2)|(data[bias]==3)].copy().values\n",
    "    # print(df.shape)\n",
    "\n",
    "    kf = KFold(n_splits=4)\n",
    "    for train_index, test_index in kf.split(df):\n",
    "        train, test = df[train_index], df[test_index]\n",
    "        # print(\"Size of X_train_full, X_test:\", train.shape, test.shape)\n",
    "\n",
    "    df_train = pd.DataFrame(data=train, columns=data_col)\n",
    "    df_test = pd.DataFrame(data=test, columns=data_col)\n",
    "\n",
    "    labeled = df_train.groupby(target, group_keys=False).apply(lambda x: x.sample(n=5)) # ten sample in total labeled initially\n",
    "    # labeled = df_train.groupby(target, group_keys=False).apply(lambda x: x.sample(n=5, random_state=42)) # with a random state for stable output\n",
    "    df_X_labeled = labeled[attributes]\n",
    "    df_y_labeled = labeled[target]\n",
    "    X_labeled = df_X_labeled.values\n",
    "    y_labeled = df_y_labeled.values.astype('int64')\n",
    "    b_labeled = labeled[bias].values-2 #degrade bias into binary options\n",
    "    (row_size, col_size) = X_labeled.shape \n",
    "    # print(X_labeled.shape)\n",
    "\n",
    "    unlabeled = df_train.drop(df_X_labeled.index)\n",
    "    df_X_unlabeled = unlabeled[attributes]\n",
    "    df_y_unlabeled = unlabeled[target]\n",
    "    X_unlabeled = df_X_unlabeled.values\n",
    "    y_unlabeled = df_y_unlabeled.values.astype('int64')\n",
    "    b_unlabeled = unlabeled[bias].values-2\n",
    "    # print(X_unlabeled.shape)\n",
    "\n",
    "    X_test = df_test[attributes].values\n",
    "    y_test = df_test[target].values\n",
    "    y_test=y_test.astype('int')\n",
    "    b_test = df_test[bias].values-2\n",
    "    # print(X_test.shape)\n",
    "    \n",
    "    return (X_labeled, y_labeled, b_labeled, row_size, col_size, X_unlabeled, y_unlabeled, b_unlabeled, X_test, y_test, b_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maximal_correlation_transform(ace_model, x, y):\n",
    "    \n",
    "    ace_model.build_model_from_xy(x, y)\n",
    "    X_transformed = ace_model.ace.x_transforms\n",
    "    y_transformed = ace_model.ace.y_transform\n",
    "    \n",
    "    return X_transformed, y_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5875,)\n",
      "* Starting outer iteration 000. Current err =  1.00000E+00\n",
      "  Starting inner iteration 000. Current err =  1.00000E+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wenxuanhuang/Documents/Repo/Active-Learning-Performance-Benchmarking/thesis-project/lib/python3.8/site-packages/ace/smoother.py:309: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  (xi - self._mean_x_in_window) ** 2 /\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Starting inner iteration 001. Current err =  8.73472E-01\n",
      "  Starting inner iteration 002. Current err =  8.64213E-01\n",
      "  Starting inner iteration 003. Current err =  8.63233E-01\n",
      "  Starting inner iteration 004. Current err =  8.63047E-01\n",
      "  Starting inner iteration 005. Current err =  8.63005E-01\n",
      "  Starting inner iteration 006. Current err =  8.62982E-01\n",
      "* Starting outer iteration 001. Current err =  8.57015E-01\n",
      "  Starting inner iteration 000. Current err =  8.57015E-01\n",
      "  Starting inner iteration 001. Current err =  8.18797E-01\n",
      "  Starting inner iteration 002. Current err =  8.18692E-01\n",
      "* Starting outer iteration 002. Current err =  7.92400E-01\n",
      "  Starting inner iteration 000. Current err =  7.92400E-01\n",
      "  Starting inner iteration 001. Current err =  7.24373E-01\n",
      "* Starting outer iteration 003. Current err =  7.17737E-01\n",
      "  Starting inner iteration 000. Current err =  7.17737E-01\n",
      "  Starting inner iteration 001. Current err =  7.08043E-01\n",
      "* Starting outer iteration 004. Current err =  7.12135E-01\n",
      "  Starting inner iteration 000. Current err =  7.12135E-01\n",
      "  Starting inner iteration 001. Current err =  7.11164E-01\n",
      "* Starting outer iteration 000. Current err =  1.00000E+00\n",
      "  Starting inner iteration 000. Current err =  1.00000E+00\n",
      "  Starting inner iteration 001. Current err =  8.49414E-01\n",
      "  Starting inner iteration 002. Current err =  8.32433E-01\n",
      "  Starting inner iteration 003. Current err =  8.31899E-01\n",
      "* Starting outer iteration 001. Current err =  8.30561E-01\n",
      "  Starting inner iteration 000. Current err =  8.30561E-01\n",
      "  Starting inner iteration 001. Current err =  7.71747E-01\n",
      "  Starting inner iteration 002. Current err =  7.64250E-01\n",
      "  Starting inner iteration 003. Current err =  7.63219E-01\n",
      "* Starting outer iteration 002. Current err =  6.64598E-01\n",
      "  Starting inner iteration 000. Current err =  6.64598E-01\n",
      "  Starting inner iteration 001. Current err =  5.25933E-01\n",
      "  Starting inner iteration 002. Current err =  5.02942E-01\n",
      "  Starting inner iteration 003. Current err =  5.00923E-01\n",
      "  Starting inner iteration 004. Current err =  5.00297E-01\n",
      "  Starting inner iteration 005. Current err =  4.99487E-01\n",
      "  Starting inner iteration 006. Current err =  4.97919E-01\n",
      "  Starting inner iteration 007. Current err =  4.97835E-01\n",
      "* Starting outer iteration 003. Current err =  4.04432E-01\n",
      "  Starting inner iteration 000. Current err =  4.04432E-01\n",
      "  Starting inner iteration 001. Current err =  3.81168E-01\n",
      "  Starting inner iteration 002. Current err =  3.75468E-01\n",
      "  Starting inner iteration 003. Current err =  3.73709E-01\n",
      "  Starting inner iteration 004. Current err =  3.72512E-01\n",
      "  Starting inner iteration 005. Current err =  3.66524E-01\n",
      "  Starting inner iteration 006. Current err =  3.66317E-01\n",
      "* Starting outer iteration 004. Current err =  3.40634E-01\n",
      "  Starting inner iteration 000. Current err =  3.40634E-01\n",
      "* Starting outer iteration 005. Current err =  3.28008E-01\n",
      "  Starting inner iteration 000. Current err =  3.28008E-01\n",
      "  Starting inner iteration 001. Current err =  3.23338E-01\n",
      "  Starting inner iteration 002. Current err =  3.22143E-01\n",
      "  Starting inner iteration 003. Current err =  3.21249E-01\n",
      "  Starting inner iteration 004. Current err =  3.20955E-01\n",
      "  Starting inner iteration 005. Current err =  3.20572E-01\n",
      "  Starting inner iteration 006. Current err =  3.20261E-01\n",
      "  Starting inner iteration 007. Current err =  3.20128E-01\n",
      "  Starting inner iteration 008. Current err =  3.20071E-01\n",
      "  Starting inner iteration 009. Current err =  3.20052E-01\n",
      "  Starting inner iteration 010. Current err =  3.20047E-01\n",
      "  Starting inner iteration 011. Current err =  3.20047E-01\n",
      "  Starting inner iteration 012. Current err =  3.20046E-01\n",
      "* Starting outer iteration 006. Current err =  3.13562E-01\n",
      "  Starting inner iteration 000. Current err =  3.13562E-01\n",
      "  Starting inner iteration 001. Current err =  3.09635E-01\n",
      "* Starting outer iteration 007. Current err =  3.06065E-01\n",
      "  Starting inner iteration 000. Current err =  3.06065E-01\n",
      "  Starting inner iteration 001. Current err =  3.03443E-01\n",
      "* Starting outer iteration 008. Current err =  3.02390E-01\n",
      "  Starting inner iteration 000. Current err =  3.02390E-01\n",
      "  Starting inner iteration 001. Current err =  2.99900E-01\n",
      "* Starting outer iteration 009. Current err =  3.00810E-01\n",
      "  Starting inner iteration 000. Current err =  3.00810E-01\n",
      "  Starting inner iteration 001. Current err =  2.98292E-01\n",
      "* Starting outer iteration 010. Current err =  3.00763E-01\n",
      "  Starting inner iteration 000. Current err =  3.00763E-01\n",
      "  Starting inner iteration 001. Current err =  2.95203E-01\n",
      "* Starting outer iteration 011. Current err =  2.98143E-01\n",
      "  Starting inner iteration 000. Current err =  2.98143E-01\n",
      "  Starting inner iteration 001. Current err =  2.97090E-01\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "4 columns passed, passed data had 5875 columns",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/Documents/Repo/Active-Learning-Performance-Benchmarking/thesis-project/lib/python3.8/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36m_finalize_columns_and_data\u001b[0;34m(content, columns, dtype)\u001b[0m\n\u001b[1;32m    905\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 906\u001b[0;31m         \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_validate_or_indexify_columns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    907\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAssertionError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Repo/Active-Learning-Performance-Benchmarking/thesis-project/lib/python3.8/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36m_validate_or_indexify_columns\u001b[0;34m(content, columns)\u001b[0m\n\u001b[1;32m    953\u001b[0m             \u001b[0;31m# caller's responsibility to check for this...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 954\u001b[0;31m             raise AssertionError(\n\u001b[0m\u001b[1;32m    955\u001b[0m                 \u001b[0;34mf\"{len(columns)} columns passed, passed data had \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: 4 columns passed, passed data had 5875 columns",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/pc/f0ds212x5ql14xc9444c5gv00000gn/T/ipykernel_28547/2040836965.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mX_Xy_Mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_Xy_Mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaximal_correlation_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXy_ace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_Xb_Mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_Xb_Mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_Xy_Mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_Xy_Mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'X_Xb_Mc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'b_Xb_Mc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'X_Xy_Mc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'y_Xy_Mc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Repo/Active-Learning-Performance-Benchmarking/thesis-project/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    692\u001b[0m                         \u001b[0;31m# ndarray], Index, Series], Sequence[Any]]\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m                         \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 694\u001b[0;31m                     arrays, columns, index = nested_data_to_arrays(\n\u001b[0m\u001b[1;32m    695\u001b[0m                         \u001b[0;31m# error: Argument 3 to \"nested_data_to_arrays\" has incompatible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m                         \u001b[0;31m# type \"Optional[Collection[Any]]\"; expected \"Optional[Index]\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Repo/Active-Learning-Performance-Benchmarking/thesis-project/lib/python3.8/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mnested_data_to_arrays\u001b[0;34m(data, columns, index, dtype)\u001b[0m\n\u001b[1;32m    481\u001b[0m         \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fields\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 483\u001b[0;31m     \u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    484\u001b[0m     \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Repo/Active-Learning-Performance-Benchmarking/thesis-project/lib/python3.8/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mto_arrays\u001b[0;34m(data, columns, dtype)\u001b[0m\n\u001b[1;32m    805\u001b[0m         \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_list_to_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m     \u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_finalize_columns_and_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Repo/Active-Learning-Performance-Benchmarking/thesis-project/lib/python3.8/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36m_finalize_columns_and_data\u001b[0;34m(content, columns, dtype)\u001b[0m\n\u001b[1;32m    907\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAssertionError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m         \u001b[0;31m# GH#26429 do not raise user-facing AssertionError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 909\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    910\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcontents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobject_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: 4 columns passed, passed data had 5875 columns"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "(X,y,b) = retrieve_data_recid()\n",
    "\n",
    "Xb_ace = ace.model.Model()\n",
    "Xy_ace = ace.model.Model()\n",
    "\n",
    "X_Xb_Mc, b_Xb_Mc = maximal_correlation_transform(Xb_ace, X.T.tolist(), b.tolist())\n",
    "X_Xy_Mc, y_Xy_Mc = maximal_correlation_transform(Xy_ace, X.T.tolist(), y.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Xy_res = pd.DataFrame(data=np.array(X_Xy_Mc).T)\n",
    "X_Xy_res.to_csv('X_Xy_Mc.csv',sep=',')\n",
    "\n",
    "y_Xy_res = pd.DataFrame(data=np.array(y_Xy_Mc).T)\n",
    "y_Xy_res.to_csv('y_Xy_Mc.csv',sep=',')\n",
    "\n",
    "X_Xb_res = pd.DataFrame(data=np.array(X_Xb_Mc).T)\n",
    "X_Xb_res.to_csv('X_Xb_Mc.csv',sep=',')\n",
    "\n",
    "b_Xb_res = pd.DataFrame(data=np.array(b_Xb_Mc).T)\n",
    "b_Xb_res.to_csv('b_Xb_Mc.csv',sep=',')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b6d1a97b03e52be1c553c50910cdb19760ee3e4d178c0a737039468e0b0f9e5f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit ('thesis-project': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
