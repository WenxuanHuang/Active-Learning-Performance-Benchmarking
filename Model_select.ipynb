{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Logistic.ipynb",
      "provenance": [],
      "mount_file_id": "1SZapm_bYNJDCJi8ECwmjrzaN8-1ruRgA",
      "authorship_tag": "ABX9TyMfqalTRwiWuiIELJDbCQ7d"
    },
    "kernelspec": {
      "name": "python382jvsc74a57bd031f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6",
      "display_name": "Python 3.8.2 64-bit"
    },
    "metadata": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ioi13nGDPDvQ",
        "outputId": "4763f7b3-6c5b-45cb-f411-fd7c6ea8b38f"
      },
      "source": [
        "print(__doc__)\n",
        "\n",
        "!pip3 install statsmodels --upgrade\n",
        "\n",
        "import scipy.stats as scp_stats\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy\n",
        "from scipy.special import expit\n",
        "import statsmodels.api as sm\n",
        "\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer\n",
        "from sklearn import linear_model\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.pipeline import Pipeline, FeatureUnion\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn import metrics\n",
        "from sklearn.linear_model import RidgeCV, LassoCV, Ridge, Lasso\n",
        "\n",
        "import missingno as msno\n",
        "import seaborn as sns\n",
        "\n",
        "# pd.options.display.max_rows = 20\n",
        "pd.options.display.float_format = \"{:.1f}\".format\n",
        "df = pd.read_csv(\"https://raw.githubusercontent.com/WenxuanHuang/ML-for-COVID-19-dataset/main/all_training.csv\", sep=',')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Automatically created module for IPython interactive environment\n",
            "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
            "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
            "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: statsmodels in /Users/wenxuanhuang/Library/Python/3.8/lib/python/site-packages (0.12.2)\n",
            "Requirement already satisfied: scipy>=1.1 in /Users/wenxuanhuang/Library/Python/3.8/lib/python/site-packages (from statsmodels) (1.6.2)\n",
            "Requirement already satisfied: pandas>=0.21 in /Users/wenxuanhuang/Library/Python/3.8/lib/python/site-packages (from statsmodels) (1.2.3)\n",
            "Requirement already satisfied: patsy>=0.5 in /Users/wenxuanhuang/Library/Python/3.8/lib/python/site-packages (from statsmodels) (0.5.1)\n",
            "Requirement already satisfied: numpy>=1.15 in /Users/wenxuanhuang/Library/Python/3.8/lib/python/site-packages (from statsmodels) (1.20.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /Users/wenxuanhuang/Library/Python/3.8/lib/python/site-packages (from pandas>=0.21->statsmodels) (2021.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /Users/wenxuanhuang/Library/Python/3.8/lib/python/site-packages (from pandas>=0.21->statsmodels) (2.8.1)\n",
            "Requirement already satisfied: six in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/site-packages (from patsy>=0.5->statsmodels) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I5wm-nCFojyN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9a3f18c-5c4a-4fc5-f5fc-9b699e485fdd"
      },
      "source": [
        "#Using robust scaling as normalization method\n",
        "\n",
        "# Column selection\n",
        "df_features = df.iloc[:,np.r_[3,5:34]].copy()\n",
        "\n",
        "# create a scaler object\n",
        "scaler = RobustScaler()\n",
        "\n",
        "# fit and transform the data\n",
        "df_normalized = pd.DataFrame(scaler.fit_transform(df_features), columns=df_features.columns)\n",
        "n_samples, n_features = df_features.shape\n",
        "\n",
        "# define row and column index\n",
        "col = df_normalized.columns\n",
        "row = [i for i in range(df_normalized.shape[0])]\n",
        "\n",
        "# define imputer\n",
        "imputer = IterativeImputer(estimator=linear_model.BayesianRidge(), n_nearest_features=None, imputation_order='ascending')\n",
        "\n",
        "# fit on the dataset\n",
        "imputer.fit(df_normalized)\n",
        "\n",
        "# transform the dataset\n",
        "df_normalized_imputed = imputer.transform(df_normalized)\n",
        "\n",
        "# convert back to pandas dataframe and rename back to df_normalized\n",
        "df_normalized = pd.DataFrame(data=df_normalized_imputed, index=row, columns=col)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/Users/wenxuanhuang/Library/Python/3.8/lib/python/site-packages/sklearn/impute/_iterative.py:685: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n  warnings.warn(\"[IterativeImputer] Early stopping criterion not\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTChXqRGYTBR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc129e7a-062e-4b20-951d-474768d269e8"
      },
      "source": [
        "# Logistic regression\n",
        "\n",
        "# Data preparation\n",
        "X = df_normalized\n",
        "y = df.target\n",
        "X = X.to_numpy()\n",
        "\n",
        "# Cross validation\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
          ]
        }
      ],
      "source": [
        "# Create first pipeline for base without reducing features.\n",
        "\n",
        "pipe = Pipeline([('classifier' , RandomForestClassifier())])\n",
        "# pipe = Pipeline([('classifier', RandomForestClassifier())])\n",
        "\n",
        "# Create param grid.\n",
        "\n",
        "param_grid = [\n",
        "    {'classifier' : [LogisticRegression()],\n",
        "     'classifier__penalty' : ['l1', 'l2'],\n",
        "    'classifier__C' : np.logspace(-4, 4, 20),\n",
        "    'classifier__solver' : ['liblinear']},\n",
        "    {'classifier' : [RandomForestClassifier()],\n",
        "    'classifier__n_estimators' : list(range(10,101,10)),\n",
        "    'classifier__max_features' : list(range(4, 10))}\n",
        "]\n",
        "\n",
        "# Create grid search object\n",
        "\n",
        "clf = GridSearchCV(pipe, param_grid = param_grid, cv = 5, verbose=True, n_jobs=-1)\n",
        "\n",
        "# Fit on data\n",
        "\n",
        "best_clf = clf.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(max_features=4, n_estimators=90)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "best_clf.best_estimator_.get_params()['classifier']"
      ]
    }
  ]
}