{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 11,
      "source": [
        "print(__doc__)\n",
        "\n",
        "import os\n",
        "import time\n",
        "import json\n",
        "import pickle\n",
        "import math\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.mlab as mlab\n",
        "from scipy.special import expit\n",
        "from scipy import stats\n",
        "from pylab import rcParams\n",
        "import mplcursors\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.datasets import load_digits\n",
        "\n",
        "from sklearn.utils import check_random_state\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer\n",
        "from sklearn.pipeline import Pipeline, FeatureUnion\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import scale\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "\n",
        "from sklearn import linear_model\n",
        "from sklearn import neighbors\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.linear_model import RidgeCV, LassoCV, Ridge, Lasso\n",
        "from sklearn.svm import LinearSVC, SVC\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.utils import check_random_state\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics.pairwise import euclidean_distances\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.mixture import GaussianMixture\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import pairwise_distances_argmin_min\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import average_precision_score\n",
        "\n",
        "\n",
        "# pd.options.display.max_rows = 20\n",
        "pd.options.display.float_format = \"{:.1f}\".format"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Automatically created module for IPython interactive environment\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ioi13nGDPDvQ",
        "outputId": "4763f7b3-6c5b-45cb-f411-fd7c6ea8b38f"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "source": [
        "def fetch_data_iris():\n",
        "    iris = load_iris()\n",
        "    X = iris.data.astype('float64')\n",
        "    y = iris.target\n",
        "    print ('Dataset : ', X.shape, y.shape)\n",
        "    return (X, y)\n",
        "\n",
        "def fetch_data_mnist():\n",
        "    mnist = load_digits()\n",
        "    X = mnist.data.astype('float64')\n",
        "    y = mnist.target\n",
        "    print ('Dataset : ', X.shape, y.shape)\n",
        "    return (X, y)\n",
        "\n",
        "def fetch_data_wine():\n",
        "    data = pd.read_csv(\"https://raw.githubusercontent.com/WenxuanHuang/Active-Learning-Performance-Benchmarking/main/winequality-white.csv\", sep=';')\n",
        "    df = data.iloc[:,np.r_[0:10]].copy()\n",
        "    X = df.to_numpy()\n",
        "    y = data.quality\n",
        "    print ('df:', X.shape, y.shape)\n",
        "    return (X, y)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "source": [
        "class BaseModel(object):\n",
        "\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def fit_predict(self):\n",
        "        pass\n",
        "\n",
        "\n",
        "class SvmModel(BaseModel):\n",
        "\n",
        "    def fit_predict(self, X_train, y_train, X_val, X_test):\n",
        "        print ('training svm...')\n",
        "        self.classifier = SVC(\n",
        "            C=1, \n",
        "            kernel='linear', \n",
        "            probability=True\n",
        "            )\n",
        "        self.classifier.fit(X_train, y_train)\n",
        "        self.test_y_predicted = self.classifier.predict(X_test)\n",
        "        self.val_y_predicted = self.classifier.predict(X_val)\n",
        "        return (X_train, X_val, X_test, self.val_y_predicted,\n",
        "                self.test_y_predicted)\n",
        "\n",
        "class LogModel(BaseModel):\n",
        "\n",
        "    def fit_predict(self, X_train, y_train, X_val, X_test):\n",
        "        # print ('training logistic regression...')\n",
        "        # train_samples = X_train.shape[0]\n",
        "        self.classifier = LogisticRegression(\n",
        "            # C=50. / train_samples,\n",
        "            penalty='l2',\n",
        "            solver='newton-cg'\n",
        "            )\n",
        "        self.classifier.fit(X_train, y_train)\n",
        "        self.test_y_predicted = self.classifier.predict(X_test)\n",
        "        self.val_y_predicted = self.classifier.predict(X_val)\n",
        "        return (X_train, X_val, X_test, self.val_y_predicted,\n",
        "                self.test_y_predicted)\n",
        "\n",
        "class RfModel(BaseModel):\n",
        "\n",
        "    def fit_predict(self, X_train, y_train, X_val, X_test):\n",
        "        print ('training random forest...')\n",
        "        self.classifier = RandomForestClassifier(\n",
        "            n_estimators=100, \n",
        "            n_jobs=-1\n",
        "            )\n",
        "        self.classifier.fit(X_train, y_train)\n",
        "        self.test_y_predicted = self.classifier.predict(X_test)\n",
        "        self.val_y_predicted = self.classifier.predict(X_val)\n",
        "        return (X_train, X_val, X_test, self.val_y_predicted, self.test_y_predicted)\n",
        "\n"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "source": [
        "class TrainModel:\n",
        "\n",
        "    def __init__(self, model_object):        \n",
        "        self.accuracies = []\n",
        "        self.model_object = model_object()        \n",
        "\n",
        "    def print_model_type(self):\n",
        "        print (self.model_object.model_type)\n",
        "\n",
        "    # we train normally and use the probabilities to select the most uncertain samples\n",
        "    def train(self, X_train, y_train, X_val, X_test):\n",
        "        t0 = time.time()\n",
        "        (X_train, X_val, X_test, self.val_y_predicted,\n",
        "         self.test_y_predicted) = \\\n",
        "            self.model_object.fit_predict(X_train, y_train, X_val, X_test)\n",
        "        self.run_time = time.time() - t0\n",
        "        return (X_train, X_val, X_test)\n",
        "\n",
        "    # we want accuracy only for the test set\n",
        "    def get_test_accuracy(self, i, y_test):\n",
        "        classif_rate = np.mean(self.test_y_predicted.ravel() == y_test.ravel()) * 100\n",
        "        self.accuracies.append(classif_rate)               \n",
        "        print('--------------------------------')\n",
        "        print('Iteration:',i)\n",
        "        # print('--------------------------------')\n",
        "        # print('y-test set:',y_test.shape)\n",
        "        # print('Training run in %.3f s' % self.run_time,'\\n')\n",
        "        print(\"Accuracy rate is %f \" % (classif_rate))    \n",
        "        # print(\"Classification report for %s:\\n%s\\n\" % (self.model_object.classifier, metrics.classification_report(y_test, self.test_y_predicted)))\n",
        "        # print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(y_test, self.test_y_predicted))\n",
        "        print('--------------------------------')\n"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "source": [
        "class QueryFunction(object):\n",
        "\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    # def stream_select(self):\n",
        "    #     pass\n",
        "\n",
        "    def pool_select(self):\n",
        "        pass\n",
        "\n",
        "\n",
        "class RandomSelection(QueryFunction):\n",
        "\n",
        "    @staticmethod\n",
        "    def pool_select(probas_val, batch_size):\n",
        "        random_state = check_random_state(0)\n",
        "        # probas_val.shape[0] is the size of validation set\n",
        "        selection = np.random.choice(probas_val.shape[0], batch_size, replace=False)\n",
        "        # print('uniques chosen:',np.unique(selection).shape[0],'<= should be equal to:',batch_size)\n",
        "        return selection\n",
        "\n",
        "\n",
        "class EntropySelection(QueryFunction):\n",
        "\n",
        "    @staticmethod\n",
        "    def pool_select(probas_val, batch_size):\n",
        "        e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
        "        selection = (np.argsort(e)[::-1])[:batch_size]\n",
        "        return selection\n",
        "\n",
        "class MinStdSelection(QueryFunction):\n",
        "\n",
        "    # select the samples where the std is smallest. There is uncertainty regarding the relevant class\n",
        "    # and then train on these \"hard\" to classify samples.\n",
        "    @staticmethod\n",
        "    def pool_select(probas_val, batch_size):\n",
        "        std = np.std(probas_val * 100, axis=1) \n",
        "        selection = std.argsort()[:batch_size]\n",
        "        selection = selection.astype('int64')\n",
        "        print('std',std.shape,std)\n",
        "        print('selection',selection, selection.shape, std[selection])\n",
        "        return selection\n",
        "\n",
        "class LeastConfidenceSelection(QueryFunction):\n",
        "\n",
        "    @staticmethod\n",
        "    def pool_select(probas_val, batch_size):\n",
        "        sort_prob = -np.sort(-probas_val, axis=1)\n",
        "        values = sort_prob[:, 0]\n",
        "        selection = np.argsort(values)[:batch_size]\n",
        "        return selection\n",
        "      \n",
        "      \n",
        "class MarginSelection(QueryFunction):\n",
        "\n",
        "    @staticmethod\n",
        "    def pool_select(probas_val, batch_size):\n",
        "        sort_prob = -np.sort(-probas_val, axis=1)\n",
        "        values = sort_prob[:, 0] - sort_prob[:, 1]\n",
        "        selection = np.argsort(values)[:batch_size]\n",
        "        return selection\n"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "source": [
        "class Normalize(object):\n",
        "    \n",
        "    def normalize(self, X_train, X_val, X_test):\n",
        "        self.scaler = RobustScaler()\n",
        "        X_train = self.scaler.fit_transform(X_train)\n",
        "        X_val   = self.scaler.transform(X_val)\n",
        "        X_test  = self.scaler.transform(X_test)\n",
        "        return (X_train, X_val, X_test) \n",
        "    \n",
        "    def inverse(self, X_train, X_val, X_test):\n",
        "        X_train = self.scaler.inverse_transform(X_train)\n",
        "        X_val   = self.scaler.inverse_transform(X_val)\n",
        "        X_test  = self.scaler.inverse_transform(X_test)\n",
        "        return (X_train, X_val, X_test) "
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "source": [
        "def get_random_samples(initial_samples, X_train_full,\n",
        "                         y_train_full):\n",
        "\n",
        "    random_state = check_random_state(0)\n",
        "\n",
        "    permutation = np.random.choice(len(X_train_full),initial_samples,replace=False)\n",
        "    \n",
        "    # print ()\n",
        "    # print(type(permutation))\n",
        "    # print ('initial random chosen samples', permutation)\n",
        "\n",
        "    X_train = X_train_full[permutation]\n",
        "    y_train = y_train_full[permutation]\n",
        "    X_train = X_train.reshape((X_train.shape[0], -1))\n",
        "\n",
        "    # bin_count = np.bincount(y_train.astype('int64'))\n",
        "    # unique = np.unique(y_train.astype('int64'))\n",
        "    # print (\n",
        "    #     'initial train set:',\n",
        "    #     X_train.shape,\n",
        "    #     y_train.shape,\n",
        "    #     'unique(labels):',\n",
        "    #     bin_count,\n",
        "    #     unique,\n",
        "    #     )\n",
        "    return (permutation, X_train, y_train)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "source": [
        "class TheAlgorithm(object):\n",
        "\n",
        "    accuracies = []\n",
        "\n",
        "    def __init__(self, step, model_object, selection_function):\n",
        "        self.step = step\n",
        "        self.model_object = model_object\n",
        "        self.sample_selection_function = selection_function\n",
        "        \n",
        "# To-do: Move initiation selections as arguments\n",
        "    def run(self, X_train_full, y_train_full, X_test, y_test, initial_queried, max_queried):\n",
        "\n",
        "        # initialize process by applying base learner to labeled training data set to obtain Classifier\n",
        "        (permutation, X_train, y_train) = \\\n",
        "            get_random_samples(initial_queried, X_train_full, y_train_full)\n",
        "        self.queried = initial_queried\n",
        "        # self.samplecount = [self.initiation_selections]\n",
        "\n",
        "        # assign the val set the rest of the 'unlabelled' training data\n",
        "        X_val = np.array([])\n",
        "        y_val = np.array([])\n",
        "        X_val = np.copy(X_train_full)\n",
        "        X_val = np.delete(X_val, permutation, axis=0)\n",
        "        y_val = np.copy(y_train_full)\n",
        "        y_val = np.delete(y_val, permutation, axis=0)\n",
        "        # print ('Val set:', X_val.shape, y_val.shape, permutation.shape)\n",
        "        # print ()\n",
        "\n",
        "        # normalize data\n",
        "        normalizer = Normalize()\n",
        "        X_train, X_val, X_test = normalizer.normalize(X_train, X_val, X_test)\n",
        "           \n",
        "        self.clf_model = TrainModel(self.model_object)\n",
        "        (X_train, X_val, X_test) = self.clf_model.train(X_train, y_train, X_val, X_test)\n",
        "        active_iteration = 1\n",
        "        self.clf_model.get_test_accuracy(1, y_test)\n",
        "\n",
        "        # queried_num = [self.queried]\n",
        "\n",
        "        while self.queried <= max_queried-self.step:\n",
        "\n",
        "            active_iteration += 1\n",
        "            self.queried += self.step\n",
        "            # queried_num.append(self.queried)\n",
        "            # get validation probabilities\n",
        "            probas_val = \\\n",
        "                self.clf_model.model_object.classifier.predict_proba(X_val)\n",
        "            # print('Classifier class:', self.clf_model.model_object.classifier.classes_)\n",
        "            # print('Probas_val:', probas_val)\n",
        "            # pred_val = \\\n",
        "            #     self.clf_model.val_y_predicted\n",
        "            # model_val = \\\n",
        "            #     self.clf_model\n",
        "            # print ('val predicted:',\n",
        "            #         self.clf_model.val_y_predicted.shape,\n",
        "            #         self.clf_model.val_y_predicted)\n",
        "            # display probability of binary value predictions of the validation set\n",
        "            # print ('probas_val value', probas_val)\n",
        "            # display which binary value has the highest probabilities of the validation set\n",
        "            # print ('probabilities:', probas_val.shape, '\\n',\n",
        "            #        np.argmax(probas_val, axis=1))\n",
        "\n",
        "            # select samples using a selection function\n",
        "            uncertain_samples = self.sample_selection_function.pool_select(probas_val, self.step)\n",
        "\n",
        "            # normalization needs to be inversed and recalculated based on the new train and test set.\n",
        "            X_train, X_val, X_test = normalizer.inverse(X_train, X_val, X_test)   \n",
        "\n",
        "            # get the uncertain samples from the validation set\n",
        "            # print ('trainset before adding uncertain samples', X_train.shape, y_train.shape)\n",
        "            X_train = np.concatenate((X_train, X_val[uncertain_samples]))\n",
        "            y_train = np.concatenate((y_train, y_val[uncertain_samples]))\n",
        "            # print ('trainset after adding uncertain samples', X_train.shape, y_train.shape)\n",
        "            # self.samplecount.append(X_train.shape[0])\n",
        "\n",
        "            \n",
        "\n",
        "            # bin_count = np.bincount(y_train.astype('int64'))\n",
        "            # unique = np.unique(y_train.astype('int64'))\n",
        "            # print (\n",
        "            #     'updated train set:',\n",
        "            #     X_train.shape,\n",
        "            #     y_train.shape,\n",
        "            #     'unique(labels):',\n",
        "            #     bin_count,\n",
        "            #     unique,\n",
        "            #     )\n",
        "\n",
        "            X_val = np.delete(X_val, uncertain_samples, axis=0)\n",
        "            y_val = np.delete(y_val, uncertain_samples, axis=0)\n",
        "            # print ('val set:', X_val.shape, y_val.shape)\n",
        "            # print ()\n",
        "\n",
        "            # normalize again after creating the 'new' train/test sets\n",
        "            normalizer = Normalize()\n",
        "            X_train, X_val, X_test = normalizer.normalize(X_train, X_val, X_test)               \n",
        "\n",
        "            # self.queried += self.step\n",
        "\n",
        "            (X_train, X_val, X_test) = self.clf_model.train(X_train, y_train, X_val, X_test)\n",
        "            self.clf_model.get_test_accuracy(active_iteration, y_test)\n",
        "\n",
        "        # print('Queried numbers', queried_num)\n",
        "        return self.clf_model.accuracies\n",
        "        # print ('final active learning accuracies',\n",
        "        #        self.clf_model.accuracies)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "source": [
        "def pool_experiment(model,sampling_method,max_queried,initial_queried,step):\n",
        "    (X, y) = fetch_data_mnist()\n",
        "    # (X_train_full, X_test,y_train_full,  y_test) = train_test_split(X, y, test_size=0.25)\n",
        "    # print(type(X_train_full))\n",
        "\n",
        "    kf = KFold(n_splits=4)\n",
        "\n",
        "    for train_index, test_index in kf.split(X):\n",
        "        X_train_full, X_test = X[train_index], X[test_index]\n",
        "        y_train_full, y_test = y[train_index], y[test_index]\n",
        "        \n",
        "    act_alg = TheAlgorithm(step, model , sampling_method)\n",
        "    accuracies = act_alg.run(X_train_full,y_train_full,X_test,y_test,initial_queried,max_queried)\n",
        "\n",
        "    (permutation, X_train_selected, y_train_selected) = get_random_samples(initial_queried, X_train_full, y_train_full)\n",
        "    original_accuracies=[]\n",
        "    classifier_original = LogisticRegression(\n",
        "            # C=50. / train_samples,\n",
        "            penalty='l2',\n",
        "            solver='newton-cg'\n",
        "            )\n",
        "    x_axis = []\n",
        "    for i in range(initial_queried-1,max_queried,step):\n",
        "        classifier_original.fit(X_train_selected[:i+1], y_train_selected[:i+1])\n",
        "        y_pred_original = classifier_original.predict(X_test)\n",
        "        original_accuracies.append(accuracy_score(y_test, y_pred_original)*100)\n",
        "        x_axis.append(i+1)\n",
        "    print(\"accuracies\",accuracies)\n",
        "    print(\"nonactive_accuracies\",original_accuracies)\n",
        "    print(\"x-axis:\",x_axis)\n",
        "    # print(\"x-axis length:\",len(x_axis))\n",
        "    # x_axis = np.linspace(initial_queried,max_queried,num=(max_queried - initial_queried)//step +1,endpoint=True)\n",
        "    plt.plot(x_axis, accuracies, 'r',label='active')\n",
        "    plt.plot(x_axis, original_accuracies, 'blue',label='non-active')\n",
        "    plt.legend()\n",
        "    plt.xlabel('Sample Size')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.show()"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "source": [
        "pool_experiment(LogModel,MarginSelection,500,10,10)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset :  (1797, 64) (1797,)\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "Accuracy rate is 28.730512 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "Accuracy rate is 42.984410 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 3\n",
            "Accuracy rate is 61.692650 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 4\n",
            "Accuracy rate is 73.051225 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 5\n",
            "Accuracy rate is 76.837416 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 6\n",
            "Accuracy rate is 82.850780 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 7\n",
            "Accuracy rate is 85.523385 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 8\n",
            "Accuracy rate is 84.855234 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 9\n",
            "Accuracy rate is 84.409800 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 10\n",
            "Accuracy rate is 83.964365 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 11\n",
            "Accuracy rate is 86.414254 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 12\n",
            "Accuracy rate is 88.641425 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 13\n",
            "Accuracy rate is 87.750557 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 14\n",
            "Accuracy rate is 87.305122 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 15\n",
            "Accuracy rate is 87.082405 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 16\n",
            "Accuracy rate is 87.527840 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 17\n",
            "Accuracy rate is 87.527840 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 18\n",
            "Accuracy rate is 87.305122 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 19\n",
            "Accuracy rate is 87.305122 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 20\n",
            "Accuracy rate is 88.195991 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 21\n",
            "Accuracy rate is 87.750557 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 22\n",
            "Accuracy rate is 88.195991 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 23\n",
            "Accuracy rate is 88.864143 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 24\n",
            "Accuracy rate is 89.309577 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 25\n",
            "Accuracy rate is 89.532294 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 26\n",
            "Accuracy rate is 88.864143 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 27\n",
            "Accuracy rate is 88.641425 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 28\n",
            "Accuracy rate is 89.532294 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 29\n",
            "Accuracy rate is 89.977728 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 30\n",
            "Accuracy rate is 89.755011 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 31\n",
            "Accuracy rate is 89.309577 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 32\n",
            "Accuracy rate is 89.755011 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 33\n",
            "Accuracy rate is 89.755011 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 34\n",
            "Accuracy rate is 89.086860 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 35\n",
            "Accuracy rate is 89.309577 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 36\n",
            "Accuracy rate is 89.309577 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 37\n",
            "Accuracy rate is 88.864143 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 38\n",
            "Accuracy rate is 89.532294 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 39\n",
            "Accuracy rate is 89.755011 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 40\n",
            "Accuracy rate is 90.423163 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 41\n",
            "Accuracy rate is 89.755011 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 42\n",
            "Accuracy rate is 90.200445 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 43\n",
            "Accuracy rate is 90.200445 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 44\n",
            "Accuracy rate is 89.977728 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 45\n",
            "Accuracy rate is 89.977728 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 46\n",
            "Accuracy rate is 90.200445 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 47\n",
            "Accuracy rate is 90.200445 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 48\n",
            "Accuracy rate is 90.200445 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 49\n",
            "Accuracy rate is 90.645880 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 50\n",
            "Accuracy rate is 90.868597 \n",
            "--------------------------------\n",
            "accuracies [28.73051224944321, 42.98440979955457, 61.69265033407573, 73.05122494432071, 76.83741648106904, 82.85077951002228, 85.52338530066815, 84.85523385300668, 84.4097995545657, 83.96436525612472, 86.41425389755011, 88.64142538975501, 87.75055679287304, 87.30512249443207, 87.08240534521158, 87.52783964365256, 87.52783964365256, 87.30512249443207, 87.30512249443207, 88.19599109131403, 87.75055679287304, 88.19599109131403, 88.8641425389755, 89.30957683741649, 89.53229398663697, 88.8641425389755, 88.64142538975501, 89.53229398663697, 89.97772828507794, 89.75501113585747, 89.30957683741649, 89.75501113585747, 89.75501113585747, 89.086859688196, 89.30957683741649, 89.30957683741649, 88.8641425389755, 89.53229398663697, 89.75501113585747, 90.42316258351893, 89.75501113585747, 90.20044543429844, 90.20044543429844, 89.97772828507794, 89.97772828507794, 90.20044543429844, 90.20044543429844, 90.20044543429844, 90.64587973273942, 90.8685968819599]\n",
            "nonactive_accuracies [45.657015590200444, 45.657015590200444, 45.657015590200444, 45.657015590200444, 45.657015590200444, 45.657015590200444, 45.657015590200444, 45.657015590200444, 45.657015590200444, 45.657015590200444, 45.657015590200444, 45.657015590200444, 45.657015590200444, 45.657015590200444, 45.657015590200444, 45.657015590200444, 45.657015590200444, 45.657015590200444, 45.657015590200444, 45.657015590200444, 45.657015590200444, 45.657015590200444, 45.657015590200444, 45.657015590200444, 45.657015590200444, 45.657015590200444, 45.657015590200444, 45.657015590200444, 45.657015590200444, 45.657015590200444, 45.657015590200444, 45.657015590200444, 45.657015590200444, 45.657015590200444, 45.657015590200444, 45.657015590200444, 45.657015590200444, 45.657015590200444, 45.657015590200444, 45.657015590200444, 45.657015590200444, 45.657015590200444, 45.657015590200444, 45.657015590200444, 45.657015590200444, 45.657015590200444, 45.657015590200444, 45.657015590200444, 45.657015590200444, 45.657015590200444]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "x and y must have same first dimension, but have shapes (49,) and (50,)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-1d482e99945a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpool_experiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLogModel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mMarginSelection\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-19-4fb0a8e64dcd>\u001b[0m in \u001b[0;36mpool_experiment\u001b[0;34m(model, sampling_method, max_queried, initial_queried, step)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;31m# print(\"x-axis length:\",len(x_axis))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;31m# x_axis = np.linspace(initial_queried,max_queried,num=(max_queried - initial_queried)//step +1,endpoint=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_axis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'active'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_axis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_accuracies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'blue'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'non-active'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2986\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0m_copy_docstring_and_deprecators\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2987\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscalex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaley\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2988\u001b[0;31m     return gca().plot(\n\u001b[0m\u001b[1;32m   2989\u001b[0m         \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscalex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscalex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaley\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscaley\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2990\u001b[0m         **({\"data\": data} if data is not None else {}), **kwargs)\n",
            "\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1603\u001b[0m         \"\"\"\n\u001b[1;32m   1604\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1605\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1606\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m    313\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_next_color\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs, return_kwargs)\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 501\u001b[0;31m             raise ValueError(f\"x and y must have same first dimension, but \"\n\u001b[0m\u001b[1;32m    502\u001b[0m                              f\"have shapes {x.shape} and {y.shape}\")\n\u001b[1;32m    503\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (49,) and (50,)"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "metadata": {}
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyMfqalTRwiWuiIELJDbCQ7d",
      "mount_file_id": "1SZapm_bYNJDCJi8ECwmjrzaN8-1ruRgA",
      "name": "Logistic.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "5edc29c2ed010d6458d71a83433b383a96a8cbd3efe8531bc90c4b8a5b8bcec9"
    },
    "kernelspec": {
      "display_name": "Python 3.8.2 64-bit",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "metadata": {
      "interpreter": {
        "hash": "5edc29c2ed010d6458d71a83433b383a96a8cbd3efe8531bc90c4b8a5b8bcec9"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}