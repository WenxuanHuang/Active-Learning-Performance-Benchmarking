{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ioi13nGDPDvQ",
        "outputId": "4763f7b3-6c5b-45cb-f411-fd7c6ea8b38f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Automatically created module for IPython interactive environment\n"
          ]
        }
      ],
      "source": [
        "print(__doc__)\n",
        "\n",
        "import os\n",
        "import time\n",
        "import json\n",
        "import pickle\n",
        "import math\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.mlab as mlab\n",
        "from scipy.special import expit\n",
        "from scipy import stats\n",
        "from pylab import rcParams\n",
        "import mplcursors\n",
        "\n",
        "from sklearn.utils import check_random_state\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer\n",
        "from sklearn.pipeline import Pipeline, FeatureUnion\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import scale\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "\n",
        "from sklearn import linear_model\n",
        "from sklearn import neighbors\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.linear_model import RidgeCV, LassoCV, Ridge, Lasso\n",
        "from sklearn.svm import LinearSVC, SVC\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.utils import check_random_state\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics.pairwise import euclidean_distances\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.mixture import GaussianMixture\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import pairwise_distances_argmin_min\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import average_precision_score\n",
        "\n",
        "\n",
        "# pd.options.display.max_rows = 20\n",
        "pd.options.display.float_format = \"{:.1f}\".format\n",
        "\n",
        "max_queried = 500\n",
        "trainset_size = 1302"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {},
      "outputs": [],
      "source": [
        "def data_prep():\n",
        "    data = pd.read_csv(\"https://raw.githubusercontent.com/WenxuanHuang/ML-for-COVID-19-dataset/main/all_training.csv\", sep=',')\n",
        "    # Column selection\n",
        "    df = data.iloc[:,np.r_[3:34]].copy()\n",
        "    # define row and column index\n",
        "    col = df.columns\n",
        "    row = [i for i in range(df.shape[0])]\n",
        "    # define imputer\n",
        "    imputer = IterativeImputer(estimator=linear_model.BayesianRidge(), n_nearest_features=None, imputation_order='ascending')\n",
        "    # fit on the dataset\n",
        "    imputer.fit(df)\n",
        "    # transform the dataset\n",
        "    df_imputed = imputer.transform(df)\n",
        "    # convert back to pandas dataframe and rename back to df_normalized\n",
        "    df = pd.DataFrame(data=df_imputed, index=row, columns=col)\n",
        "    X = df\n",
        "    y = data.target    \n",
        "    # Recursive feature elimination\n",
        "    rdmreg = RandomForestClassifier(n_estimators=100)\n",
        "    # Define the method\n",
        "    rfe = RFE(estimator=rdmreg, n_features_to_select=10)\n",
        "    # Fit the model\n",
        "    rfe = rfe.fit(X, y.values.ravel())\n",
        "    print(rfe.support_)\n",
        "    # Drop columns that failed RFE test\n",
        "    col = df.columns[rfe.support_]\n",
        "    X = X[col]\n",
        "    X = X.to_numpy()\n",
        "    print ('df:', X.shape, y.shape)\n",
        "    return (X, y)\n",
        "\n",
        "\n",
        "def split(train_size):\n",
        "    X_train_full = X[:train_size]\n",
        "    y_train_full = y[:train_size]\n",
        "    X_test = X[train_size:]\n",
        "    y_test = y[train_size:]   \n",
        "    return (X_train_full, y_train_full, X_test, y_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [],
      "source": [
        "class BaseModel(object):\n",
        "\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def fit_predict(self):\n",
        "        pass\n",
        "\n",
        "\n",
        "class SvmModel(BaseModel):\n",
        "\n",
        "    model_type = 'Support Vector Machine with linear Kernel'\n",
        "    def fit_predict(self, X_train, y_train, X_val, X_test, c_weight):\n",
        "        print ('training svm...')\n",
        "        self.classifier = SVC(\n",
        "            C=1, \n",
        "            kernel='linear', \n",
        "            probability=True,\n",
        "            class_weight=c_weight\n",
        "            )\n",
        "        self.classifier.fit(X_train, y_train)\n",
        "        self.test_y_predicted = self.classifier.predict(X_test)\n",
        "        self.val_y_predicted = self.classifier.predict(X_val)\n",
        "        return (X_train, X_val, X_test, self.val_y_predicted,\n",
        "                self.test_y_predicted)\n",
        "\n",
        "class LogModel(BaseModel):\n",
        "\n",
        "    model_type = 'Logistic Regression' \n",
        "    def fit_predict(self, X_train, y_train, X_val, X_test, c_weight):\n",
        "        print ('training logistic regression...')\n",
        "        # train_samples = X_train.shape[0]\n",
        "        self.classifier = LogisticRegression(\n",
        "            # C=50. / train_samples,\n",
        "            penalty='l1',\n",
        "            solver='liblinear',\n",
        "            tol=0.1,\n",
        "            class_weight=c_weight\n",
        "            )\n",
        "        self.classifier.fit(X_train, y_train)\n",
        "        self.test_y_predicted = self.classifier.predict(X_test)\n",
        "        self.val_y_predicted = self.classifier.predict(X_val)\n",
        "        return (X_train, X_val, X_test, self.val_y_predicted,\n",
        "                self.test_y_predicted)\n",
        "\n",
        "class RfModel(BaseModel):\n",
        "\n",
        "    model_type = 'Random Forest'\n",
        "    def fit_predict(self, X_train, y_train, X_val, X_test, c_weight):\n",
        "        print ('training random forest...')\n",
        "        self.classifier = RandomForestClassifier(\n",
        "            n_estimators=500, \n",
        "            class_weight=c_weight, \n",
        "            n_jobs=-1\n",
        "            )\n",
        "        self.classifier.fit(X_train, y_train)\n",
        "        self.test_y_predicted = self.classifier.predict(X_test)\n",
        "        self.val_y_predicted = self.classifier.predict(X_val)\n",
        "        return (X_train, X_val, X_test, self.val_y_predicted, self.test_y_predicted)\n",
        "\n",
        "class GDBCModel(BaseModel):\n",
        "\n",
        "    model_type = 'Gradient Boost classifier'\n",
        "    def fit_predict(self, X_train, y_train, X_val, X_test, c_weight):\n",
        "        print ('training GDBC...')\n",
        "        self.classifier = GradientBoostingClassifier(\n",
        "            n_estimators=1200,\n",
        "            max_depth=3,\n",
        "            subsample=0.5,\n",
        "            learning_rate=0.01,\n",
        "            min_samples_leaf=1,\n",
        "            random_state=3\n",
        "            )\n",
        "        self.classifier.fit(X_train, y_train)\n",
        "        self.test_y_predicted = self.classifier.predict(X_test)\n",
        "        self.val_y_predicted = self.classifier.predict(X_val)\n",
        "        return (X_train, X_val, X_test, self.val_y_predicted, self.test_y_predicted)\n",
        "\n",
        "class KnnModel(BaseModel):\n",
        "\n",
        "    model_type = 'Nearest Neighbour classifier'\n",
        "    def fit_predict(self, X_train, y_train, X_val, X_test, c_weight):\n",
        "        print ('training KNN...')\n",
        "        self.classifier = neighbors.KNeighborsClassifier(\n",
        "            n_neighbors = 10,\n",
        "            n_jobs = -1\n",
        "            )\n",
        "        self.classifier.fit(X_train, y_train)\n",
        "        self.test_y_predicted = self.classifier.predict(X_test)\n",
        "        self.val_y_predicted = self.classifier.predict(X_val)\n",
        "        return (X_train, X_val, X_test, self.val_y_predicted, self.test_y_predicted)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {},
      "outputs": [],
      "source": [
        "class TrainModel:\n",
        "\n",
        "    def __init__(self, model_object):        \n",
        "        self.accuracies = []\n",
        "        self.model_object = model_object()        \n",
        "\n",
        "    def print_model_type(self):\n",
        "        print (self.model_object.model_type)\n",
        "\n",
        "    # we train normally and use the probabilities to select the most uncertain samples\n",
        "    def train(self, X_train, y_train, X_val, X_test, c_weight):\n",
        "        print ('Train set:', X_train.shape)\n",
        "        print ('Validation set:', X_val.shape)\n",
        "        print ('Test set:', X_test.shape)\n",
        "        t0 = time.time()\n",
        "        (X_train, X_val, X_test, self.val_y_predicted,\n",
        "         self.test_y_predicted) = \\\n",
        "            self.model_object.fit_predict(X_train, y_train, X_val, X_test, c_weight)\n",
        "        self.run_time = time.time() - t0\n",
        "        return (X_train, X_val, X_test)\n",
        "\n",
        "    # we want accuracy only for the test set\n",
        "    def get_test_accuracy(self, i, y_test):\n",
        "        classif_rate = np.mean(self.test_y_predicted.ravel() == y_test.ravel()) * 100\n",
        "        self.accuracies.append(classif_rate)               \n",
        "        print('--------------------------------')\n",
        "        print('Iteration:',i)\n",
        "        print('--------------------------------')\n",
        "        print('y-test set:',y_test.shape)\n",
        "        print('Training run in %.3f s' % self.run_time,'\\n')\n",
        "        print(\"Accuracy rate is %f \" % (classif_rate))    \n",
        "        print(\"Classification report for %s:\\n%s\\n\" % (self.model_object.classifier, metrics.classification_report(y_test, self.test_y_predicted)))\n",
        "        print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(y_test, self.test_y_predicted))\n",
        "        print('--------------------------------')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {},
      "outputs": [],
      "source": [
        "class QueryFunction(object):\n",
        "\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def stream_select(self):\n",
        "        pass\n",
        "\n",
        "    def pool_select(self):\n",
        "        pass\n",
        "\n",
        "\n",
        "class RandomSelection(QueryFunction):\n",
        "\n",
        "    @staticmethod\n",
        "    def pool_select(probas_val, batch_size):\n",
        "        random_state = check_random_state(0)\n",
        "        # probas_val.shape[0] is the size of validation set\n",
        "        selection = np.random.choice(probas_val.shape[0], batch_size, replace=False)\n",
        "        print('uniques chosen:',np.unique(selection).shape[0],'<= should be equal to:',batch_size)\n",
        "        return selection\n",
        "\n",
        "\n",
        "class EntropySelection(QueryFunction):\n",
        "\n",
        "    @staticmethod\n",
        "    def pool_select(probas_val, batch_size):\n",
        "        e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
        "        selection = (np.argsort(e)[::-1])[:batch_size]\n",
        "        return selection\n",
        "\n",
        "class MinStdSelection(QueryFunction):\n",
        "\n",
        "    # select the samples where the std is smallest. There is uncertainty regarding the relevant class\n",
        "    # and then train on these \"hard\" to classify samples.\n",
        "    @staticmethod\n",
        "    def pool_select(probas_val, batch_size):\n",
        "        std = np.std(probas_val * 100, axis=1) \n",
        "        selection = std.argsort()[:batch_size]\n",
        "        selection = selection.astype('int64')\n",
        "        print('std',std.shape,std)\n",
        "        print('selection',selection, selection.shape, std[selection])\n",
        "        return selection\n",
        "\n",
        "class LeastConfidenceSelection(QueryFunction):\n",
        "\n",
        "    @staticmethod\n",
        "    def pool_select(probas_val, batch_size):\n",
        "        sort_prob = -np.sort(-probas_val, axis=1)\n",
        "        values = sort_prob[:, 0]\n",
        "        selection = np.argsort(values)[:batch_size]\n",
        "        return selection\n",
        "      \n",
        "      \n",
        "class MarginSamplingSelection(QueryFunction):\n",
        "\n",
        "    @staticmethod\n",
        "    def pool_select(probas_val, batch_size):\n",
        "        sort_prob = -np.sort(-probas_val, axis=1)\n",
        "        values = sort_prob[:, 0] - sort_prob[:, 1]\n",
        "        selection = np.argsort(values)[:batch_size]\n",
        "        return selection\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Normalize(object):\n",
        "    \n",
        "    def normalize(self, X_train, X_val, X_test):\n",
        "        self.scaler = RobustScaler()\n",
        "        X_train = self.scaler.fit_transform(X_train)\n",
        "        X_val   = self.scaler.transform(X_val)\n",
        "        X_test  = self.scaler.transform(X_test)\n",
        "        return (X_train, X_val, X_test) \n",
        "    \n",
        "    def inverse(self, X_train, X_val, X_test):\n",
        "        X_train = self.scaler.inverse_transform(X_train)\n",
        "        X_val   = self.scaler.inverse_transform(X_val)\n",
        "        X_test  = self.scaler.inverse_transform(X_test)\n",
        "        return (X_train, X_val, X_test) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_random_samples(initial_samples, X_train_full,\n",
        "                         y_train_full):\n",
        "\n",
        "    random_state = check_random_state(0)\n",
        "\n",
        "    permutation = np.random.choice(len(X_train_full),initial_samples,replace=False)\n",
        "    \n",
        "    # print ()\n",
        "    # print(type(permutation))\n",
        "    # print ('initial random chosen samples', permutation)\n",
        "\n",
        "    X_train = X_train_full[permutation]\n",
        "    y_train = y_train_full[permutation]\n",
        "    X_train = X_train.reshape((X_train.shape[0], -1))\n",
        "\n",
        "    # bin_count = np.bincount(y_train.astype('int64'))\n",
        "    # unique = np.unique(y_train.astype('int64'))\n",
        "    # print (\n",
        "    #     'initial train set:',\n",
        "    #     X_train.shape,\n",
        "    #     y_train.shape,\n",
        "    #     'unique(labels):',\n",
        "    #     bin_count,\n",
        "    #     unique,\n",
        "    #     )\n",
        "    return (permutation, X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {},
      "outputs": [],
      "source": [
        "class TheAlgorithm(object):\n",
        "\n",
        "    accuracies = []\n",
        "\n",
        "    def __init__(self, init_samples, model_object, selection_function):\n",
        "        self.init_samples = init_samples\n",
        "        self.model_object = model_object\n",
        "        self.sample_selection_function = selection_function\n",
        "        \n",
        "# To-do: Move initiation selections as arguments\n",
        "    def run(self, X_train_full, y_train_full, X_test, y_test, initial_queried, max_queried):\n",
        "\n",
        "        # initialize process by applying base learner to labeled training data set to obtain Classifier\n",
        "        (permutation, X_train, y_train) = \\\n",
        "            get_random_samples(initial_queried, X_train_full, y_train_full)\n",
        "        self.queried = initial_queried\n",
        "        # self.samplecount = [self.initiation_selections]\n",
        "\n",
        "        # assign the val set the rest of the 'unlabelled' training data\n",
        "        X_val = np.array([])\n",
        "        y_val = np.array([])\n",
        "        X_val = np.copy(X_train_full)\n",
        "        X_val = np.delete(X_val, permutation, axis=0)\n",
        "        y_val = np.copy(y_train_full)\n",
        "        y_val = np.delete(y_val, permutation, axis=0)\n",
        "        # print ('Val set:', X_val.shape, y_val.shape, permutation.shape)\n",
        "        # print ()\n",
        "\n",
        "        # normalize data\n",
        "        normalizer = Normalize()\n",
        "        X_train, X_val, X_test = normalizer.normalize(X_train, X_val, X_test)\n",
        "           \n",
        "        self.clf_model = TrainModel(self.model_object)\n",
        "        (X_train, X_val, X_test) = self.clf_model.train(X_train, y_train, X_val, X_test, 'balanced')\n",
        "        active_iteration = 1\n",
        "        self.clf_model.get_test_accuracy(1, y_test)\n",
        "\n",
        "        while self.queried < max_queried:\n",
        "\n",
        "            active_iteration += 1\n",
        "\n",
        "            # get validation probabilities\n",
        "            probas_val = \\\n",
        "                self.clf_model.model_object.classifier.predict_proba(X_val)\n",
        "            # print('Probas_val:', probas_val)\n",
        "            # pred_val = \\\n",
        "            #     self.clf_model.val_y_predicted\n",
        "            # model_val = \\\n",
        "            #     self.clf_model\n",
        "            # print ('val predicted:',\n",
        "            #         self.clf_model.val_y_predicted.shape,\n",
        "            #         self.clf_model.val_y_predicted)\n",
        "            # display probability of binary value predictions of the validation set\n",
        "            # print ('probas_val value', probas_val)\n",
        "            # display which binary value has the highest probabilities of the validation set\n",
        "            # print ('probabilities:', probas_val.shape, '\\n',\n",
        "            #        np.argmax(probas_val, axis=1))\n",
        "\n",
        "            # select samples using a selection function\n",
        "            uncertain_samples = self.sample_selection_function.pool_select(probas_val, self.init_samples)\n",
        "\n",
        "            # normalization needs to be inversed and recalculated based on the new train and test set.\n",
        "            X_train, X_val, X_test = normalizer.inverse(X_train, X_val, X_test)   \n",
        "\n",
        "            # get the uncertain samples from the validation set\n",
        "            # print ('trainset before adding uncertain samples', X_train.shape, y_train.shape)\n",
        "            X_train = np.concatenate((X_train, X_val[uncertain_samples]))\n",
        "            y_train = np.concatenate((y_train, y_val[uncertain_samples]))\n",
        "            # print ('trainset after adding uncertain samples', X_train.shape, y_train.shape)\n",
        "            # self.samplecount.append(X_train.shape[0])\n",
        "\n",
        "            # bin_count = np.bincount(y_train.astype('int64'))\n",
        "            # unique = np.unique(y_train.astype('int64'))\n",
        "            # print (\n",
        "            #     'updated train set:',\n",
        "            #     X_train.shape,\n",
        "            #     y_train.shape,\n",
        "            #     'unique(labels):',\n",
        "            #     bin_count,\n",
        "            #     unique,\n",
        "            #     )\n",
        "\n",
        "            X_val = np.delete(X_val, uncertain_samples, axis=0)\n",
        "            y_val = np.delete(y_val, uncertain_samples, axis=0)\n",
        "            # print ('val set:', X_val.shape, y_val.shape)\n",
        "            # print ()\n",
        "\n",
        "            # normalize again after creating the 'new' train/test sets\n",
        "            normalizer = Normalize()\n",
        "            X_train, X_val, X_test = normalizer.normalize(X_train, X_val, X_test)               \n",
        "\n",
        "            self.queried += self.init_samples\n",
        "            (X_train, X_val, X_test) = self.clf_model.train(X_train, y_train, X_val, X_test, 'balanced')\n",
        "            self.clf_model.get_test_accuracy(active_iteration, y_test)\n",
        "\n",
        "        return self.clf_model.accuracies\n",
        "        # print ('final active learning accuracies',\n",
        "        #        self.clf_model.accuracies)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {},
      "outputs": [],
      "source": [
        "def pool_experiment(model,sampling_method,max_queried,initial_queried):\n",
        "    (X, y) = data_prep()\n",
        "    # (X_train_full, X_test,y_train_full,  y_test) = train_test_split(X, y, test_size=0.25)\n",
        "    # print(type(X_train_full))\n",
        "\n",
        "    from sklearn.model_selection import KFold\n",
        "    kf = KFold(n_splits=4)\n",
        "\n",
        "    for train_index, test_index in kf.split(X):\n",
        "        X_train_full, X_test = X[train_index], X[test_index]\n",
        "        y_train_full, y_test = y[train_index], y[test_index]\n",
        "        \n",
        "    act_alg = TheAlgorithm(1,model , sampling_method)\n",
        "    accuracies = act_alg.run(X_train_full,y_train_full,X_test,y_test,initial_queried,max_queried)\n",
        "\n",
        "    (permutation, X_train_selected, y_train_selected) = get_random_samples(initial_queried, X_train_full, y_train_full)\n",
        "    original_accuracies=[]\n",
        "    classifier_original = LogisticRegression(C=50. / X_train_full.shape[0],\n",
        "            penalty='l1',\n",
        "            solver='liblinear',\n",
        "            tol=0.1,\n",
        "            class_weight='balanced')\n",
        "\n",
        "    for i in range(initial_queried-1,max_queried):\n",
        "        classifier_original.fit(X_train_selected[:i+1], y_train_selected[:i+1])\n",
        "        y_pred_random = classifier_original.predict(X_test)\n",
        "        original_accuracies.append(accuracy_score(y_test, y_pred_random)*100)\n",
        "    print(\"accuracies\",accuracies)\n",
        "    print(\"nonactive_accuracies\",original_accuracies)\n",
        "    x_axis = np.linspace(initial_queried,max_queried,num=max_queried - initial_queried +1,endpoint=True)\n",
        "    plt.plot(x_axis, accuracies, 'r',label='active') \n",
        "    plt.plot(x_axis, original_accuracies, 'blue',label='non-active') \n",
        "    plt.legend()\n",
        "    plt.xlabel('Sample Size')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "# print ('train:', X_train_full.shape, y_train_full.shape)\n",
        "# print ('test :', X_test.shape, y_test.shape)\n",
        "# classes = len(np.unique(y))\n",
        "# print ('unique classes', classes)\n",
        "\n",
        "# def pickle_save(fname, data):\n",
        "#   filehandler = open(fname,\"wb\")\n",
        "#   pickle.dump(data,filehandler)\n",
        "#   filehandler.close()\n",
        "#   print('saved', fname, os.getcwd(), os.listdir())\n",
        "\n",
        "# def pickle_load(fname):\n",
        "#   print(os.getcwd(), os.listdir())\n",
        "#   file = open(fname,'rb')\n",
        "#   data = pickle.load(file)\n",
        "#   file.close()\n",
        "#   print(data)\n",
        "#   return data\n",
        "  \n",
        "def batch_experiment(d, models, selection_functions, Ks, repeats, contfrom):\n",
        "\n",
        "    (X, y) = data_prep()\n",
        "    # (X_train_full, X_test,y_train_full,  y_test) = train_test_split(X, y, test_size=0.25)\n",
        "    # print(type(X_train_full))\n",
        "\n",
        "    from sklearn.model_selection import KFold\n",
        "    kf = KFold(n_splits=4)\n",
        "\n",
        "    for train_index, test_index in kf.split(X):\n",
        "        X_train_full, X_test = X[train_index], X[test_index]\n",
        "        y_train_full, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    algos_temp = []\n",
        "    print ('stopping at:', max_queried)\n",
        "    count = 0\n",
        "    for model_object in models:\n",
        "      if model_object.__name__ not in d:\n",
        "          d[model_object.__name__] = {}\n",
        "      \n",
        "      for selection_function in selection_functions:\n",
        "        if selection_function.__name__ not in d[model_object.__name__]:\n",
        "            d[model_object.__name__][selection_function.__name__] = {}\n",
        "        \n",
        "        for k in Ks:\n",
        "            d[model_object.__name__][selection_function.__name__][str(k)] = []           \n",
        "            \n",
        "            for i in range(0, repeats):\n",
        "                count+=1\n",
        "                if count >= contfrom:\n",
        "                    # print ('Count = %s, using model = %s, selection_function = %s, k = %s, iteration = %s.' % (count, model_object.__name__, selection_function.__name__, k, i))\n",
        "                    alg = TheAlgorithm(k, \n",
        "                                       model_object, \n",
        "                                       selection_function\n",
        "                                       )\n",
        "                    alg.run(X_train_full, y_train_full, X_test, y_test)\n",
        "                    d[model_object.__name__][selection_function.__name__][str(k)].append(alg.clf_model.accuracies)\n",
        "                    # fname = '/Users/wenxuanhuang/Documents/Repo/ML-for-COVID-19-dataset/Results/Active-learning-experiment-' + str(count) + '.pkl'\n",
        "                    # pickle_save(fname, d)\n",
        "                    # if count % 5 == 0:\n",
        "                    #     print(json.dumps(d, indent=2, sort_keys=True))\n",
        "                    # print ()\n",
        "                    # print ('---------------------------- FINISHED ---------------------------')\n",
        "                    # print ()\n",
        "    return d\n",
        "\n",
        "\n",
        "# max_queried = 500 \n",
        "# repeats = 1\n",
        "# models = [LogModel] \n",
        "# # models = [SvmModel, RfModel, LogModel, GDBCModel, KnnModel] \n",
        "# selection_functions = [LeastConfidenceSelection] \n",
        "# # selection_functions = [RandomSelection, MarginSamplingSelection, EntropySelection, MinStdSelection, LeastConfidenceSelection] \n",
        "# Ks = [250,125,50,25,10] \n",
        "# d = {}\n",
        "# stopped_at = -1 \n",
        "# # print('directory dump including pickle files:', os.getcwd(), np.sort(os.listdir()))  \n",
        "# # d = pickle_load('Active-learning-experiment-' + str(stopped_at) + '.pkl')  \n",
        "# # print(json.dumps(d, indent=2, sort_keys=True))\n",
        "# d = batch_experiment(d, models, selection_functions, Ks, repeats, stopped_at+1)\n",
        "# # print (d)\n",
        "# # results = json.loads(json.dumps(d, indent=2, sort_keys=True))\n",
        "# # print(results)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {},
      "outputs": [],
      "source": [
        "# %matplotlib widget\n",
        "# # %matplotlib inline\n",
        "# def performance_plot(fully_supervised_accuracy, dic, models, selection_functions, Ks, repeats):  \n",
        "#     fig, ax = plt.subplots()\n",
        "#     ax.plot([0,500],[fully_supervised_accuracy, fully_supervised_accuracy],label = 'upper-bound')\n",
        "#     for model_object in models:\n",
        "#       for selection_function in selection_functions:\n",
        "#         for idx, k in enumerate(Ks):\n",
        "#             x = np.arange(float(Ks[idx]), 500 + float(Ks[idx]), float(Ks[idx]))            \n",
        "#             Sum = np.array(dic[model_object][selection_function][k][0])\n",
        "#             for i in range(1, repeats):\n",
        "#                 Sum = Sum + np.array(dic[model_object][selection_function][k][i])\n",
        "#             mean = Sum / repeats\n",
        "#             ax.plot(x, mean, label = model_object[0:3] + '-' + selection_function[0:3] + '-' + str(k))\n",
        "#     ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "#     ax.set_xlim([50,500])\n",
        "#     ax.set_ylim([20,83])\n",
        "#     ax.grid(True)\n",
        "#     mplcursors.cursor()\n",
        "#     plt.tight_layout()\n",
        "#     plt.show()\n",
        "\n",
        "# # models_str = ['SvmModel', 'RfModel', 'LogModel','GDBCModel','KnnModel']\n",
        "# models_str = ['LogModel']\n",
        "# # selection_functions_str = ['RandomSelection', 'MarginSamplingSelection', 'EntropySelection', 'MinStdSelection','LeastConfidenceSelection']\n",
        "# selection_functions_str = ['LeastConfidenceSelection']\n",
        "# Ks_str = ['250','125','50','25','10'] \n",
        "# repeats = 10\n",
        "# # random_forest_upper_bound = 89.\n",
        "# # svm_upper_bound = 87.\n",
        "# log_upper_bound = 87.\n",
        "# # gdbc_upper_bound = 86.\n",
        "# # knn_upper_bound = 86.\n",
        "# total_experiments = len(models_str) * len(selection_functions_str) * len(Ks_str) * repeats\n",
        "\n",
        "# print('So which is the better model? under the stopping condition and hyper parameters')\n",
        "# # performance_plot(random_forest_upper_bound, d, ['RfModel'] , selection_functions_str    , Ks_str, 1)\n",
        "# # performance_plot(svm_upper_bound, d, ['SvmModel'] , selection_functions_str    , Ks_str, 1)\n",
        "# performance_plot(log_upper_bound, d, ['LogModel'] , selection_functions_str    , Ks_str, 1)\n",
        "# # performance_plot(gdbc_upper_bound, d, ['GDBCModel'] , selection_functions_str    , Ks_str, 1)\n",
        "# # performance_plot(log_upper_bound, d, ['KnnModel'] , selection_functions_str    , Ks_str, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ True False False False False False  True False  True  True False False\n",
            " False  True  True False False False False False False False False False\n",
            "  True False  True  True False  True False]\n",
            "df: (1736, 10) (1736,)\n",
            "Train set: (25, 10)\n",
            "Validation set: (1277, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.001 s \n",
            "\n",
            "Accuracy rate is 64.285714 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.61      0.72       321\n",
            "           1       0.40      0.74      0.52       113\n",
            "\n",
            "    accuracy                           0.64       434\n",
            "   macro avg       0.64      0.68      0.62       434\n",
            "weighted avg       0.75      0.64      0.66       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[195 126]\n",
            " [ 29  84]]\n",
            "--------------------------------\n",
            "Train set: (26, 10)\n",
            "Validation set: (1276, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 66.359447 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.64      0.74       321\n",
            "           1       0.42      0.73      0.53       113\n",
            "\n",
            "    accuracy                           0.66       434\n",
            "   macro avg       0.64      0.68      0.63       434\n",
            "weighted avg       0.75      0.66      0.68       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[206 115]\n",
            " [ 31  82]]\n",
            "--------------------------------\n",
            "Train set: (27, 10)\n",
            "Validation set: (1275, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 3\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 65.898618 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.63      0.73       321\n",
            "           1       0.41      0.75      0.53       113\n",
            "\n",
            "    accuracy                           0.66       434\n",
            "   macro avg       0.65      0.69      0.63       434\n",
            "weighted avg       0.76      0.66      0.68       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[201 120]\n",
            " [ 28  85]]\n",
            "--------------------------------\n",
            "Train set: (28, 10)\n",
            "Validation set: (1274, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 4\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 64.516129 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.61      0.72       321\n",
            "           1       0.40      0.75      0.52       113\n",
            "\n",
            "    accuracy                           0.65       434\n",
            "   macro avg       0.64      0.68      0.62       434\n",
            "weighted avg       0.75      0.65      0.67       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[195 126]\n",
            " [ 28  85]]\n",
            "--------------------------------\n",
            "Train set: (29, 10)\n",
            "Validation set: (1273, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 5\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 66.589862 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.64      0.74       321\n",
            "           1       0.42      0.74      0.54       113\n",
            "\n",
            "    accuracy                           0.67       434\n",
            "   macro avg       0.65      0.69      0.64       434\n",
            "weighted avg       0.76      0.67      0.69       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[205 116]\n",
            " [ 29  84]]\n",
            "--------------------------------\n",
            "Train set: (30, 10)\n",
            "Validation set: (1272, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 6\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 66.359447 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.63      0.74       321\n",
            "           1       0.42      0.75      0.54       113\n",
            "\n",
            "    accuracy                           0.66       434\n",
            "   macro avg       0.65      0.69      0.64       434\n",
            "weighted avg       0.76      0.66      0.68       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[203 118]\n",
            " [ 28  85]]\n",
            "--------------------------------\n",
            "Train set: (31, 10)\n",
            "Validation set: (1271, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 7\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 67.972350 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.66      0.75       321\n",
            "           1       0.43      0.73      0.54       113\n",
            "\n",
            "    accuracy                           0.68       434\n",
            "   macro avg       0.65      0.70      0.65       434\n",
            "weighted avg       0.76      0.68      0.70       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[212 109]\n",
            " [ 30  83]]\n",
            "--------------------------------\n",
            "Train set: (32, 10)\n",
            "Validation set: (1270, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 8\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 64.976959 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.62      0.72       321\n",
            "           1       0.40      0.73      0.52       113\n",
            "\n",
            "    accuracy                           0.65       434\n",
            "   macro avg       0.63      0.67      0.62       434\n",
            "weighted avg       0.75      0.65      0.67       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[200 121]\n",
            " [ 31  82]]\n",
            "--------------------------------\n",
            "Train set: (33, 10)\n",
            "Validation set: (1269, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 9\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 67.050691 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.65      0.75       321\n",
            "           1       0.42      0.73      0.53       113\n",
            "\n",
            "    accuracy                           0.67       434\n",
            "   macro avg       0.65      0.69      0.64       434\n",
            "weighted avg       0.75      0.67      0.69       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[209 112]\n",
            " [ 31  82]]\n",
            "--------------------------------\n",
            "Train set: (34, 10)\n",
            "Validation set: (1268, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 10\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 67.741935 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.66      0.75       321\n",
            "           1       0.43      0.73      0.54       113\n",
            "\n",
            "    accuracy                           0.68       434\n",
            "   macro avg       0.65      0.70      0.65       434\n",
            "weighted avg       0.76      0.68      0.70       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[211 110]\n",
            " [ 30  83]]\n",
            "--------------------------------\n",
            "Train set: (35, 10)\n",
            "Validation set: (1267, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 11\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 66.359447 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.65      0.74       321\n",
            "           1       0.41      0.69      0.52       113\n",
            "\n",
            "    accuracy                           0.66       434\n",
            "   macro avg       0.63      0.67      0.63       434\n",
            "weighted avg       0.74      0.66      0.68       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[210 111]\n",
            " [ 35  78]]\n",
            "--------------------------------\n",
            "Train set: (36, 10)\n",
            "Validation set: (1266, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 12\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 66.589862 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.64      0.74       321\n",
            "           1       0.42      0.74      0.54       113\n",
            "\n",
            "    accuracy                           0.67       434\n",
            "   macro avg       0.65      0.69      0.64       434\n",
            "weighted avg       0.76      0.67      0.69       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[205 116]\n",
            " [ 29  84]]\n",
            "--------------------------------\n",
            "Train set: (37, 10)\n",
            "Validation set: (1265, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 13\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 66.129032 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.64      0.74       321\n",
            "           1       0.41      0.71      0.52       113\n",
            "\n",
            "    accuracy                           0.66       434\n",
            "   macro avg       0.64      0.68      0.63       434\n",
            "weighted avg       0.75      0.66      0.68       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[207 114]\n",
            " [ 33  80]]\n",
            "--------------------------------\n",
            "Train set: (38, 10)\n",
            "Validation set: (1264, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 14\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 65.437788 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.63      0.73       321\n",
            "           1       0.41      0.73      0.52       113\n",
            "\n",
            "    accuracy                           0.65       434\n",
            "   macro avg       0.64      0.68      0.63       434\n",
            "weighted avg       0.75      0.65      0.68       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[202 119]\n",
            " [ 31  82]]\n",
            "--------------------------------\n",
            "Train set: (39, 10)\n",
            "Validation set: (1263, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 15\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 66.129032 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.64      0.74       321\n",
            "           1       0.41      0.73      0.53       113\n",
            "\n",
            "    accuracy                           0.66       434\n",
            "   macro avg       0.64      0.68      0.63       434\n",
            "weighted avg       0.75      0.66      0.68       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[205 116]\n",
            " [ 31  82]]\n",
            "--------------------------------\n",
            "Train set: (40, 10)\n",
            "Validation set: (1262, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 16\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 62.672811 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.60      0.70       321\n",
            "           1       0.38      0.70      0.49       113\n",
            "\n",
            "    accuracy                           0.63       434\n",
            "   macro avg       0.62      0.65      0.60       434\n",
            "weighted avg       0.73      0.63      0.65       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[193 128]\n",
            " [ 34  79]]\n",
            "--------------------------------\n",
            "Train set: (41, 10)\n",
            "Validation set: (1261, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 17\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 63.824885 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.62      0.72       321\n",
            "           1       0.39      0.68      0.50       113\n",
            "\n",
            "    accuracy                           0.64       434\n",
            "   macro avg       0.62      0.65      0.61       434\n",
            "weighted avg       0.73      0.64      0.66       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[200 121]\n",
            " [ 36  77]]\n",
            "--------------------------------\n",
            "Train set: (42, 10)\n",
            "Validation set: (1260, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 18\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 64.516129 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.63      0.72       321\n",
            "           1       0.40      0.69      0.50       113\n",
            "\n",
            "    accuracy                           0.65       434\n",
            "   macro avg       0.62      0.66      0.61       434\n",
            "weighted avg       0.73      0.65      0.67       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[202 119]\n",
            " [ 35  78]]\n",
            "--------------------------------\n",
            "Train set: (43, 10)\n",
            "Validation set: (1259, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 19\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 65.898618 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.64      0.73       321\n",
            "           1       0.41      0.73      0.53       113\n",
            "\n",
            "    accuracy                           0.66       434\n",
            "   macro avg       0.64      0.68      0.63       434\n",
            "weighted avg       0.75      0.66      0.68       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[204 117]\n",
            " [ 31  82]]\n",
            "--------------------------------\n",
            "Train set: (44, 10)\n",
            "Validation set: (1258, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 20\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 66.129032 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.65      0.74       321\n",
            "           1       0.41      0.70      0.52       113\n",
            "\n",
            "    accuracy                           0.66       434\n",
            "   macro avg       0.64      0.67      0.63       434\n",
            "weighted avg       0.74      0.66      0.68       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[208 113]\n",
            " [ 34  79]]\n",
            "--------------------------------\n",
            "Train set: (45, 10)\n",
            "Validation set: (1257, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 21\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 66.129032 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.65      0.74       321\n",
            "           1       0.41      0.69      0.51       113\n",
            "\n",
            "    accuracy                           0.66       434\n",
            "   macro avg       0.63      0.67      0.63       434\n",
            "weighted avg       0.74      0.66      0.68       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[209 112]\n",
            " [ 35  78]]\n",
            "--------------------------------\n",
            "Train set: (46, 10)\n",
            "Validation set: (1256, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 22\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.012 s \n",
            "\n",
            "Accuracy rate is 67.050691 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.65      0.75       321\n",
            "           1       0.42      0.72      0.53       113\n",
            "\n",
            "    accuracy                           0.67       434\n",
            "   macro avg       0.64      0.69      0.64       434\n",
            "weighted avg       0.75      0.67      0.69       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[210 111]\n",
            " [ 32  81]]\n",
            "--------------------------------\n",
            "Train set: (47, 10)\n",
            "Validation set: (1255, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 23\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 67.741935 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.67      0.76       321\n",
            "           1       0.43      0.69      0.53       113\n",
            "\n",
            "    accuracy                           0.68       434\n",
            "   macro avg       0.64      0.68      0.64       434\n",
            "weighted avg       0.75      0.68      0.70       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[216 105]\n",
            " [ 35  78]]\n",
            "--------------------------------\n",
            "Train set: (48, 10)\n",
            "Validation set: (1254, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 24\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.004 s \n",
            "\n",
            "Accuracy rate is 66.129032 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.64      0.74       321\n",
            "           1       0.41      0.73      0.53       113\n",
            "\n",
            "    accuracy                           0.66       434\n",
            "   macro avg       0.64      0.68      0.63       434\n",
            "weighted avg       0.75      0.66      0.68       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[205 116]\n",
            " [ 31  82]]\n",
            "--------------------------------\n",
            "Train set: (49, 10)\n",
            "Validation set: (1253, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 25\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 67.050691 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.67      0.75       321\n",
            "           1       0.42      0.67      0.52       113\n",
            "\n",
            "    accuracy                           0.67       434\n",
            "   macro avg       0.64      0.67      0.63       434\n",
            "weighted avg       0.74      0.67      0.69       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[215 106]\n",
            " [ 37  76]]\n",
            "--------------------------------\n",
            "Train set: (50, 10)\n",
            "Validation set: (1252, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 26\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 65.437788 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.65      0.73       321\n",
            "           1       0.40      0.67      0.50       113\n",
            "\n",
            "    accuracy                           0.65       434\n",
            "   macro avg       0.63      0.66      0.62       434\n",
            "weighted avg       0.73      0.65      0.67       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[208 113]\n",
            " [ 37  76]]\n",
            "--------------------------------\n",
            "Train set: (51, 10)\n",
            "Validation set: (1251, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 27\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 66.129032 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.65      0.74       321\n",
            "           1       0.41      0.68      0.51       113\n",
            "\n",
            "    accuracy                           0.66       434\n",
            "   macro avg       0.63      0.67      0.63       434\n",
            "weighted avg       0.74      0.66      0.68       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[210 111]\n",
            " [ 36  77]]\n",
            "--------------------------------\n",
            "Train set: (52, 10)\n",
            "Validation set: (1250, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 28\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 66.589862 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.67      0.75       321\n",
            "           1       0.41      0.66      0.51       113\n",
            "\n",
            "    accuracy                           0.67       434\n",
            "   macro avg       0.63      0.67      0.63       434\n",
            "weighted avg       0.74      0.67      0.68       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[214 107]\n",
            " [ 38  75]]\n",
            "--------------------------------\n",
            "Train set: (53, 10)\n",
            "Validation set: (1249, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 29\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 67.281106 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.67      0.75       321\n",
            "           1       0.42      0.68      0.52       113\n",
            "\n",
            "    accuracy                           0.67       434\n",
            "   macro avg       0.64      0.68      0.64       434\n",
            "weighted avg       0.74      0.67      0.69       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[215 106]\n",
            " [ 36  77]]\n",
            "--------------------------------\n",
            "Train set: (54, 10)\n",
            "Validation set: (1248, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 30\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 68.433180 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.68      0.76       321\n",
            "           1       0.43      0.69      0.53       113\n",
            "\n",
            "    accuracy                           0.68       434\n",
            "   macro avg       0.65      0.69      0.65       434\n",
            "weighted avg       0.75      0.68      0.70       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[219 102]\n",
            " [ 35  78]]\n",
            "--------------------------------\n",
            "Train set: (55, 10)\n",
            "Validation set: (1247, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 31\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 68.433180 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.69      0.76       321\n",
            "           1       0.43      0.68      0.53       113\n",
            "\n",
            "    accuracy                           0.68       434\n",
            "   macro avg       0.65      0.68      0.65       434\n",
            "weighted avg       0.75      0.68      0.70       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[220 101]\n",
            " [ 36  77]]\n",
            "--------------------------------\n",
            "Train set: (56, 10)\n",
            "Validation set: (1246, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 32\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 68.433180 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.69      0.76       321\n",
            "           1       0.43      0.66      0.52       113\n",
            "\n",
            "    accuracy                           0.68       434\n",
            "   macro avg       0.64      0.68      0.64       434\n",
            "weighted avg       0.74      0.68      0.70       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[222  99]\n",
            " [ 38  75]]\n",
            "--------------------------------\n",
            "Train set: (57, 10)\n",
            "Validation set: (1245, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 33\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 68.663594 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.69      0.76       321\n",
            "           1       0.44      0.69      0.53       113\n",
            "\n",
            "    accuracy                           0.69       434\n",
            "   macro avg       0.65      0.69      0.65       434\n",
            "weighted avg       0.75      0.69      0.70       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[220 101]\n",
            " [ 35  78]]\n",
            "--------------------------------\n",
            "Train set: (58, 10)\n",
            "Validation set: (1244, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 34\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 67.511521 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.69      0.76       321\n",
            "           1       0.42      0.65      0.51       113\n",
            "\n",
            "    accuracy                           0.68       434\n",
            "   macro avg       0.63      0.67      0.63       434\n",
            "weighted avg       0.74      0.68      0.69       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[220 101]\n",
            " [ 40  73]]\n",
            "--------------------------------\n",
            "Train set: (59, 10)\n",
            "Validation set: (1243, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 35\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 68.433180 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.70      0.77       321\n",
            "           1       0.43      0.65      0.52       113\n",
            "\n",
            "    accuracy                           0.68       434\n",
            "   macro avg       0.64      0.67      0.64       434\n",
            "weighted avg       0.74      0.68      0.70       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[224  97]\n",
            " [ 40  73]]\n",
            "--------------------------------\n",
            "Train set: (60, 10)\n",
            "Validation set: (1242, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 36\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.004 s \n",
            "\n",
            "Accuracy rate is 67.741935 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.69      0.76       321\n",
            "           1       0.42      0.63      0.50       113\n",
            "\n",
            "    accuracy                           0.68       434\n",
            "   macro avg       0.63      0.66      0.63       434\n",
            "weighted avg       0.73      0.68      0.69       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[223  98]\n",
            " [ 42  71]]\n",
            "--------------------------------\n",
            "Train set: (61, 10)\n",
            "Validation set: (1241, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 37\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 67.972350 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.69      0.76       321\n",
            "           1       0.42      0.64      0.51       113\n",
            "\n",
            "    accuracy                           0.68       434\n",
            "   macro avg       0.63      0.67      0.64       434\n",
            "weighted avg       0.74      0.68      0.70       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[223  98]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (62, 10)\n",
            "Validation set: (1240, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 38\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 68.433180 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.70      0.77       321\n",
            "           1       0.43      0.65      0.52       113\n",
            "\n",
            "    accuracy                           0.68       434\n",
            "   macro avg       0.64      0.67      0.64       434\n",
            "weighted avg       0.74      0.68      0.70       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[224  97]\n",
            " [ 40  73]]\n",
            "--------------------------------\n",
            "Train set: (63, 10)\n",
            "Validation set: (1239, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 39\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 68.202765 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.70      0.76       321\n",
            "           1       0.43      0.64      0.51       113\n",
            "\n",
            "    accuracy                           0.68       434\n",
            "   macro avg       0.64      0.67      0.64       434\n",
            "weighted avg       0.74      0.68      0.70       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[224  97]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (64, 10)\n",
            "Validation set: (1238, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 40\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 67.741935 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.69      0.76       321\n",
            "           1       0.42      0.64      0.51       113\n",
            "\n",
            "    accuracy                           0.68       434\n",
            "   macro avg       0.63      0.66      0.63       434\n",
            "weighted avg       0.73      0.68      0.69       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[222  99]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (65, 10)\n",
            "Validation set: (1237, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 41\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 68.433180 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.70      0.77       321\n",
            "           1       0.43      0.64      0.51       113\n",
            "\n",
            "    accuracy                           0.68       434\n",
            "   macro avg       0.64      0.67      0.64       434\n",
            "weighted avg       0.74      0.68      0.70       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[225  96]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (66, 10)\n",
            "Validation set: (1236, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 42\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 68.433180 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.70      0.77       321\n",
            "           1       0.43      0.65      0.52       113\n",
            "\n",
            "    accuracy                           0.68       434\n",
            "   macro avg       0.64      0.67      0.64       434\n",
            "weighted avg       0.74      0.68      0.70       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[224  97]\n",
            " [ 40  73]]\n",
            "--------------------------------\n",
            "Train set: (67, 10)\n",
            "Validation set: (1235, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 43\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 67.511521 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.68      0.76       321\n",
            "           1       0.42      0.66      0.52       113\n",
            "\n",
            "    accuracy                           0.68       434\n",
            "   macro avg       0.64      0.67      0.64       434\n",
            "weighted avg       0.74      0.68      0.69       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[218 103]\n",
            " [ 38  75]]\n",
            "--------------------------------\n",
            "Train set: (68, 10)\n",
            "Validation set: (1234, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 44\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 67.511521 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.68      0.76       321\n",
            "           1       0.42      0.65      0.51       113\n",
            "\n",
            "    accuracy                           0.68       434\n",
            "   macro avg       0.63      0.67      0.63       434\n",
            "weighted avg       0.74      0.68      0.69       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[219 102]\n",
            " [ 39  74]]\n",
            "--------------------------------\n",
            "Train set: (69, 10)\n",
            "Validation set: (1233, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 45\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 69.354839 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.70      0.77       321\n",
            "           1       0.44      0.66      0.53       113\n",
            "\n",
            "    accuracy                           0.69       434\n",
            "   macro avg       0.65      0.68      0.65       434\n",
            "weighted avg       0.75      0.69      0.71       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[226  95]\n",
            " [ 38  75]]\n",
            "--------------------------------\n",
            "Train set: (70, 10)\n",
            "Validation set: (1232, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 46\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 68.894009 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.71      0.77       321\n",
            "           1       0.43      0.64      0.52       113\n",
            "\n",
            "    accuracy                           0.69       434\n",
            "   macro avg       0.64      0.67      0.64       434\n",
            "weighted avg       0.74      0.69      0.70       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[227  94]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (71, 10)\n",
            "Validation set: (1231, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 47\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 70.046083 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.72      0.78       321\n",
            "           1       0.45      0.65      0.53       113\n",
            "\n",
            "    accuracy                           0.70       434\n",
            "   macro avg       0.65      0.68      0.65       434\n",
            "weighted avg       0.75      0.70      0.71       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[231  90]\n",
            " [ 40  73]]\n",
            "--------------------------------\n",
            "Train set: (72, 10)\n",
            "Validation set: (1230, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 48\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 70.737327 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.73      0.79       321\n",
            "           1       0.46      0.65      0.53       113\n",
            "\n",
            "    accuracy                           0.71       434\n",
            "   macro avg       0.66      0.69      0.66       434\n",
            "weighted avg       0.75      0.71      0.72       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[234  87]\n",
            " [ 40  73]]\n",
            "--------------------------------\n",
            "Train set: (73, 10)\n",
            "Validation set: (1229, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 49\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 70.737327 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.73      0.79       321\n",
            "           1       0.46      0.65      0.53       113\n",
            "\n",
            "    accuracy                           0.71       434\n",
            "   macro avg       0.66      0.69      0.66       434\n",
            "weighted avg       0.75      0.71      0.72       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[234  87]\n",
            " [ 40  73]]\n",
            "--------------------------------\n",
            "Train set: (74, 10)\n",
            "Validation set: (1228, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 50\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 70.967742 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.74      0.79       321\n",
            "           1       0.46      0.64      0.53       113\n",
            "\n",
            "    accuracy                           0.71       434\n",
            "   macro avg       0.66      0.69      0.66       434\n",
            "weighted avg       0.75      0.71      0.72       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[236  85]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (75, 10)\n",
            "Validation set: (1227, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 51\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 71.428571 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.74      0.79       321\n",
            "           1       0.47      0.65      0.54       113\n",
            "\n",
            "    accuracy                           0.71       434\n",
            "   macro avg       0.66      0.70      0.67       434\n",
            "weighted avg       0.76      0.71      0.73       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[236  85]\n",
            " [ 39  74]]\n",
            "--------------------------------\n",
            "Train set: (76, 10)\n",
            "Validation set: (1226, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 52\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 69.815668 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.72      0.78       321\n",
            "           1       0.44      0.64      0.52       113\n",
            "\n",
            "    accuracy                           0.70       434\n",
            "   macro avg       0.65      0.68      0.65       434\n",
            "weighted avg       0.74      0.70      0.71       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[231  90]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (77, 10)\n",
            "Validation set: (1225, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 53\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 69.354839 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.71      0.77       321\n",
            "           1       0.44      0.64      0.52       113\n",
            "\n",
            "    accuracy                           0.69       434\n",
            "   macro avg       0.64      0.68      0.65       434\n",
            "weighted avg       0.74      0.69      0.71       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[229  92]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (78, 10)\n",
            "Validation set: (1224, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 54\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 69.124424 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.71      0.77       321\n",
            "           1       0.44      0.64      0.52       113\n",
            "\n",
            "    accuracy                           0.69       434\n",
            "   macro avg       0.64      0.67      0.65       434\n",
            "weighted avg       0.74      0.69      0.71       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[228  93]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (79, 10)\n",
            "Validation set: (1223, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 55\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 69.354839 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.71      0.77       321\n",
            "           1       0.44      0.64      0.52       113\n",
            "\n",
            "    accuracy                           0.69       434\n",
            "   macro avg       0.64      0.68      0.65       434\n",
            "weighted avg       0.74      0.69      0.71       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[229  92]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (80, 10)\n",
            "Validation set: (1222, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 56\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 69.585253 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.71      0.78       321\n",
            "           1       0.44      0.65      0.53       113\n",
            "\n",
            "    accuracy                           0.70       434\n",
            "   macro avg       0.65      0.68      0.65       434\n",
            "weighted avg       0.75      0.70      0.71       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[228  93]\n",
            " [ 39  74]]\n",
            "--------------------------------\n",
            "Train set: (81, 10)\n",
            "Validation set: (1221, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 57\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 69.124424 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.71      0.77       321\n",
            "           1       0.44      0.64      0.52       113\n",
            "\n",
            "    accuracy                           0.69       434\n",
            "   macro avg       0.64      0.67      0.65       434\n",
            "weighted avg       0.74      0.69      0.71       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[228  93]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (82, 10)\n",
            "Validation set: (1220, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 58\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 69.815668 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.72      0.78       321\n",
            "           1       0.45      0.65      0.53       113\n",
            "\n",
            "    accuracy                           0.70       434\n",
            "   macro avg       0.65      0.68      0.65       434\n",
            "weighted avg       0.75      0.70      0.71       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[230  91]\n",
            " [ 40  73]]\n",
            "--------------------------------\n",
            "Train set: (83, 10)\n",
            "Validation set: (1219, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 59\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 69.124424 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.71      0.77       321\n",
            "           1       0.44      0.64      0.52       113\n",
            "\n",
            "    accuracy                           0.69       434\n",
            "   macro avg       0.64      0.67      0.65       434\n",
            "weighted avg       0.74      0.69      0.71       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[228  93]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (84, 10)\n",
            "Validation set: (1218, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 60\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 69.354839 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.71      0.77       321\n",
            "           1       0.44      0.65      0.52       113\n",
            "\n",
            "    accuracy                           0.69       434\n",
            "   macro avg       0.65      0.68      0.65       434\n",
            "weighted avg       0.74      0.69      0.71       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[228  93]\n",
            " [ 40  73]]\n",
            "--------------------------------\n",
            "Train set: (85, 10)\n",
            "Validation set: (1217, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 61\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.005 s \n",
            "\n",
            "Accuracy rate is 69.585253 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.71      0.78       321\n",
            "           1       0.44      0.65      0.53       113\n",
            "\n",
            "    accuracy                           0.70       434\n",
            "   macro avg       0.65      0.68      0.65       434\n",
            "weighted avg       0.74      0.70      0.71       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[229  92]\n",
            " [ 40  73]]\n",
            "--------------------------------\n",
            "Train set: (86, 10)\n",
            "Validation set: (1216, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 62\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 69.585253 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.72      0.78       321\n",
            "           1       0.44      0.64      0.52       113\n",
            "\n",
            "    accuracy                           0.70       434\n",
            "   macro avg       0.65      0.68      0.65       434\n",
            "weighted avg       0.74      0.70      0.71       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[230  91]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (87, 10)\n",
            "Validation set: (1215, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 63\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 69.354839 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.71      0.77       321\n",
            "           1       0.44      0.65      0.52       113\n",
            "\n",
            "    accuracy                           0.69       434\n",
            "   macro avg       0.65      0.68      0.65       434\n",
            "weighted avg       0.74      0.69      0.71       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[228  93]\n",
            " [ 40  73]]\n",
            "--------------------------------\n",
            "Train set: (88, 10)\n",
            "Validation set: (1214, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 64\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 69.124424 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.71      0.77       321\n",
            "           1       0.44      0.64      0.52       113\n",
            "\n",
            "    accuracy                           0.69       434\n",
            "   macro avg       0.64      0.67      0.65       434\n",
            "weighted avg       0.74      0.69      0.71       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[228  93]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (89, 10)\n",
            "Validation set: (1213, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 65\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 69.124424 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.71      0.77       321\n",
            "           1       0.44      0.65      0.52       113\n",
            "\n",
            "    accuracy                           0.69       434\n",
            "   macro avg       0.64      0.68      0.65       434\n",
            "weighted avg       0.74      0.69      0.71       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[227  94]\n",
            " [ 40  73]]\n",
            "--------------------------------\n",
            "Train set: (90, 10)\n",
            "Validation set: (1212, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 66\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 69.815668 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.72      0.78       321\n",
            "           1       0.45      0.65      0.53       113\n",
            "\n",
            "    accuracy                           0.70       434\n",
            "   macro avg       0.65      0.68      0.65       434\n",
            "weighted avg       0.75      0.70      0.71       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[230  91]\n",
            " [ 40  73]]\n",
            "--------------------------------\n",
            "Train set: (91, 10)\n",
            "Validation set: (1211, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 67\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 69.585253 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.71      0.78       321\n",
            "           1       0.44      0.65      0.53       113\n",
            "\n",
            "    accuracy                           0.70       434\n",
            "   macro avg       0.65      0.68      0.65       434\n",
            "weighted avg       0.74      0.70      0.71       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[229  92]\n",
            " [ 40  73]]\n",
            "--------------------------------\n",
            "Train set: (92, 10)\n",
            "Validation set: (1210, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 68\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 69.585253 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.71      0.78       321\n",
            "           1       0.44      0.65      0.53       113\n",
            "\n",
            "    accuracy                           0.70       434\n",
            "   macro avg       0.65      0.68      0.65       434\n",
            "weighted avg       0.75      0.70      0.71       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[228  93]\n",
            " [ 39  74]]\n",
            "--------------------------------\n",
            "Train set: (93, 10)\n",
            "Validation set: (1209, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 69\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 70.276498 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.72      0.78       321\n",
            "           1       0.45      0.65      0.53       113\n",
            "\n",
            "    accuracy                           0.70       434\n",
            "   macro avg       0.65      0.69      0.66       434\n",
            "weighted avg       0.75      0.70      0.72       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[231  90]\n",
            " [ 39  74]]\n",
            "--------------------------------\n",
            "Train set: (94, 10)\n",
            "Validation set: (1208, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 70\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 70.046083 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.72      0.78       321\n",
            "           1       0.45      0.65      0.53       113\n",
            "\n",
            "    accuracy                           0.70       434\n",
            "   macro avg       0.65      0.69      0.66       434\n",
            "weighted avg       0.75      0.70      0.72       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[230  91]\n",
            " [ 39  74]]\n",
            "--------------------------------\n",
            "Train set: (95, 10)\n",
            "Validation set: (1207, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 71\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.004 s \n",
            "\n",
            "Accuracy rate is 69.815668 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.71      0.78       321\n",
            "           1       0.45      0.65      0.53       113\n",
            "\n",
            "    accuracy                           0.70       434\n",
            "   macro avg       0.65      0.68      0.65       434\n",
            "weighted avg       0.75      0.70      0.71       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[229  92]\n",
            " [ 39  74]]\n",
            "--------------------------------\n",
            "Train set: (96, 10)\n",
            "Validation set: (1206, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 72\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.004 s \n",
            "\n",
            "Accuracy rate is 70.046083 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.71      0.78       321\n",
            "           1       0.45      0.66      0.54       113\n",
            "\n",
            "    accuracy                           0.70       434\n",
            "   macro avg       0.65      0.69      0.66       434\n",
            "weighted avg       0.75      0.70      0.72       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[229  92]\n",
            " [ 38  75]]\n",
            "--------------------------------\n",
            "Train set: (97, 10)\n",
            "Validation set: (1205, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 73\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.014 s \n",
            "\n",
            "Accuracy rate is 70.046083 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.72      0.78       321\n",
            "           1       0.45      0.65      0.53       113\n",
            "\n",
            "    accuracy                           0.70       434\n",
            "   macro avg       0.65      0.69      0.66       434\n",
            "weighted avg       0.75      0.70      0.72       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[230  91]\n",
            " [ 39  74]]\n",
            "--------------------------------\n",
            "Train set: (98, 10)\n",
            "Validation set: (1204, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 74\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.015 s \n",
            "\n",
            "Accuracy rate is 69.354839 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.71      0.77       321\n",
            "           1       0.44      0.65      0.53       113\n",
            "\n",
            "    accuracy                           0.69       434\n",
            "   macro avg       0.65      0.68      0.65       434\n",
            "weighted avg       0.75      0.69      0.71       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[227  94]\n",
            " [ 39  74]]\n",
            "--------------------------------\n",
            "Train set: (99, 10)\n",
            "Validation set: (1203, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 75\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.004 s \n",
            "\n",
            "Accuracy rate is 69.815668 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.71      0.78       321\n",
            "           1       0.45      0.67      0.54       113\n",
            "\n",
            "    accuracy                           0.70       434\n",
            "   macro avg       0.65      0.69      0.66       434\n",
            "weighted avg       0.75      0.70      0.71       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[227  94]\n",
            " [ 37  76]]\n",
            "--------------------------------\n",
            "Train set: (100, 10)\n",
            "Validation set: (1202, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 76\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 70.046083 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.71      0.78       321\n",
            "           1       0.45      0.68      0.54       113\n",
            "\n",
            "    accuracy                           0.70       434\n",
            "   macro avg       0.66      0.69      0.66       434\n",
            "weighted avg       0.76      0.70      0.72       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[227  94]\n",
            " [ 36  77]]\n",
            "--------------------------------\n",
            "Train set: (101, 10)\n",
            "Validation set: (1201, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 77\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.005 s \n",
            "\n",
            "Accuracy rate is 69.815668 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.71      0.78       321\n",
            "           1       0.45      0.66      0.53       113\n",
            "\n",
            "    accuracy                           0.70       434\n",
            "   macro avg       0.65      0.69      0.66       434\n",
            "weighted avg       0.75      0.70      0.71       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[228  93]\n",
            " [ 38  75]]\n",
            "--------------------------------\n",
            "Train set: (102, 10)\n",
            "Validation set: (1200, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 78\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.005 s \n",
            "\n",
            "Accuracy rate is 69.815668 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.71      0.78       321\n",
            "           1       0.45      0.67      0.54       113\n",
            "\n",
            "    accuracy                           0.70       434\n",
            "   macro avg       0.65      0.69      0.66       434\n",
            "weighted avg       0.75      0.70      0.71       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[227  94]\n",
            " [ 37  76]]\n",
            "--------------------------------\n",
            "Train set: (103, 10)\n",
            "Validation set: (1199, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 79\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 69.124424 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.70      0.77       321\n",
            "           1       0.44      0.67      0.53       113\n",
            "\n",
            "    accuracy                           0.69       434\n",
            "   macro avg       0.65      0.69      0.65       434\n",
            "weighted avg       0.75      0.69      0.71       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[224  97]\n",
            " [ 37  76]]\n",
            "--------------------------------\n",
            "Train set: (104, 10)\n",
            "Validation set: (1198, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 80\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 69.815668 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.71      0.78       321\n",
            "           1       0.45      0.66      0.53       113\n",
            "\n",
            "    accuracy                           0.70       434\n",
            "   macro avg       0.65      0.69      0.66       434\n",
            "weighted avg       0.75      0.70      0.71       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[228  93]\n",
            " [ 38  75]]\n",
            "--------------------------------\n",
            "Train set: (105, 10)\n",
            "Validation set: (1197, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 81\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.005 s \n",
            "\n",
            "Accuracy rate is 69.815668 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.71      0.78       321\n",
            "           1       0.45      0.66      0.53       113\n",
            "\n",
            "    accuracy                           0.70       434\n",
            "   macro avg       0.65      0.69      0.66       434\n",
            "weighted avg       0.75      0.70      0.71       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[228  93]\n",
            " [ 38  75]]\n",
            "--------------------------------\n",
            "Train set: (106, 10)\n",
            "Validation set: (1196, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 82\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 69.585253 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.71      0.78       321\n",
            "           1       0.44      0.65      0.53       113\n",
            "\n",
            "    accuracy                           0.70       434\n",
            "   macro avg       0.65      0.68      0.65       434\n",
            "weighted avg       0.74      0.70      0.71       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[229  92]\n",
            " [ 40  73]]\n",
            "--------------------------------\n",
            "Train set: (107, 10)\n",
            "Validation set: (1195, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 83\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 69.585253 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.71      0.78       321\n",
            "           1       0.44      0.65      0.53       113\n",
            "\n",
            "    accuracy                           0.70       434\n",
            "   macro avg       0.65      0.68      0.65       434\n",
            "weighted avg       0.74      0.70      0.71       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[229  92]\n",
            " [ 40  73]]\n",
            "--------------------------------\n",
            "Train set: (108, 10)\n",
            "Validation set: (1194, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 84\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.004 s \n",
            "\n",
            "Accuracy rate is 69.815668 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.72      0.78       321\n",
            "           1       0.45      0.65      0.53       113\n",
            "\n",
            "    accuracy                           0.70       434\n",
            "   macro avg       0.65      0.68      0.65       434\n",
            "weighted avg       0.75      0.70      0.71       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[230  91]\n",
            " [ 40  73]]\n",
            "--------------------------------\n",
            "Train set: (109, 10)\n",
            "Validation set: (1193, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 85\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 70.276498 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.72      0.78       321\n",
            "           1       0.45      0.65      0.53       113\n",
            "\n",
            "    accuracy                           0.70       434\n",
            "   macro avg       0.65      0.69      0.66       434\n",
            "weighted avg       0.75      0.70      0.72       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[231  90]\n",
            " [ 39  74]]\n",
            "--------------------------------\n",
            "Train set: (110, 10)\n",
            "Validation set: (1192, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 86\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 70.046083 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.72      0.78       321\n",
            "           1       0.45      0.65      0.53       113\n",
            "\n",
            "    accuracy                           0.70       434\n",
            "   macro avg       0.65      0.68      0.65       434\n",
            "weighted avg       0.75      0.70      0.71       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[231  90]\n",
            " [ 40  73]]\n",
            "--------------------------------\n",
            "Train set: (111, 10)\n",
            "Validation set: (1191, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 87\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 70.967742 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.73      0.79       321\n",
            "           1       0.46      0.66      0.54       113\n",
            "\n",
            "    accuracy                           0.71       434\n",
            "   macro avg       0.66      0.69      0.67       434\n",
            "weighted avg       0.76      0.71      0.72       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[233  88]\n",
            " [ 38  75]]\n",
            "--------------------------------\n",
            "Train set: (112, 10)\n",
            "Validation set: (1190, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 88\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 70.737327 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.72      0.79       321\n",
            "           1       0.46      0.66      0.54       113\n",
            "\n",
            "    accuracy                           0.71       434\n",
            "   macro avg       0.66      0.69      0.66       434\n",
            "weighted avg       0.75      0.71      0.72       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[232  89]\n",
            " [ 38  75]]\n",
            "--------------------------------\n",
            "Train set: (113, 10)\n",
            "Validation set: (1189, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 89\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 71.198157 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.73      0.79       321\n",
            "           1       0.46      0.67      0.55       113\n",
            "\n",
            "    accuracy                           0.71       434\n",
            "   macro avg       0.66      0.70      0.67       434\n",
            "weighted avg       0.76      0.71      0.73       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[233  88]\n",
            " [ 37  76]]\n",
            "--------------------------------\n",
            "Train set: (114, 10)\n",
            "Validation set: (1188, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 90\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 70.506912 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.73      0.78       321\n",
            "           1       0.45      0.65      0.53       113\n",
            "\n",
            "    accuracy                           0.71       434\n",
            "   macro avg       0.65      0.69      0.66       434\n",
            "weighted avg       0.75      0.71      0.72       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[233  88]\n",
            " [ 40  73]]\n",
            "--------------------------------\n",
            "Train set: (115, 10)\n",
            "Validation set: (1187, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 91\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.005 s \n",
            "\n",
            "Accuracy rate is 70.967742 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.73      0.79       321\n",
            "           1       0.46      0.65      0.54       113\n",
            "\n",
            "    accuracy                           0.71       434\n",
            "   macro avg       0.66      0.69      0.66       434\n",
            "weighted avg       0.75      0.71      0.72       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[234  87]\n",
            " [ 39  74]]\n",
            "--------------------------------\n",
            "Train set: (116, 10)\n",
            "Validation set: (1186, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 92\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 70.967742 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.73      0.79       321\n",
            "           1       0.46      0.65      0.54       113\n",
            "\n",
            "    accuracy                           0.71       434\n",
            "   macro avg       0.66      0.69      0.66       434\n",
            "weighted avg       0.75      0.71      0.72       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[235  86]\n",
            " [ 40  73]]\n",
            "--------------------------------\n",
            "Train set: (117, 10)\n",
            "Validation set: (1185, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 93\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 71.428571 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.74      0.79       321\n",
            "           1       0.47      0.65      0.54       113\n",
            "\n",
            "    accuracy                           0.71       434\n",
            "   macro avg       0.66      0.70      0.67       434\n",
            "weighted avg       0.76      0.71      0.73       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[236  85]\n",
            " [ 39  74]]\n",
            "--------------------------------\n",
            "Train set: (118, 10)\n",
            "Validation set: (1184, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 94\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.004 s \n",
            "\n",
            "Accuracy rate is 71.428571 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.74      0.79       321\n",
            "           1       0.47      0.65      0.54       113\n",
            "\n",
            "    accuracy                           0.71       434\n",
            "   macro avg       0.66      0.70      0.67       434\n",
            "weighted avg       0.76      0.71      0.73       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[236  85]\n",
            " [ 39  74]]\n",
            "--------------------------------\n",
            "Train set: (119, 10)\n",
            "Validation set: (1183, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 95\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.004 s \n",
            "\n",
            "Accuracy rate is 71.428571 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.74      0.79       321\n",
            "           1       0.47      0.65      0.54       113\n",
            "\n",
            "    accuracy                           0.71       434\n",
            "   macro avg       0.66      0.70      0.67       434\n",
            "weighted avg       0.76      0.71      0.73       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[236  85]\n",
            " [ 39  74]]\n",
            "--------------------------------\n",
            "Train set: (120, 10)\n",
            "Validation set: (1182, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 96\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 70.967742 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.73      0.79       321\n",
            "           1       0.46      0.65      0.54       113\n",
            "\n",
            "    accuracy                           0.71       434\n",
            "   macro avg       0.66      0.69      0.66       434\n",
            "weighted avg       0.75      0.71      0.72       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[235  86]\n",
            " [ 40  73]]\n",
            "--------------------------------\n",
            "Train set: (121, 10)\n",
            "Validation set: (1181, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 97\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.005 s \n",
            "\n",
            "Accuracy rate is 71.198157 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.74      0.79       321\n",
            "           1       0.46      0.65      0.54       113\n",
            "\n",
            "    accuracy                           0.71       434\n",
            "   macro avg       0.66      0.69      0.66       434\n",
            "weighted avg       0.75      0.71      0.73       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[236  85]\n",
            " [ 40  73]]\n",
            "--------------------------------\n",
            "Train set: (122, 10)\n",
            "Validation set: (1180, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 98\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 71.198157 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.74      0.79       321\n",
            "           1       0.46      0.64      0.54       113\n",
            "\n",
            "    accuracy                           0.71       434\n",
            "   macro avg       0.66      0.69      0.66       434\n",
            "weighted avg       0.75      0.71      0.72       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[237  84]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (123, 10)\n",
            "Validation set: (1179, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 99\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.004 s \n",
            "\n",
            "Accuracy rate is 71.198157 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.73      0.79       321\n",
            "           1       0.46      0.65      0.54       113\n",
            "\n",
            "    accuracy                           0.71       434\n",
            "   macro avg       0.66      0.69      0.67       434\n",
            "weighted avg       0.75      0.71      0.73       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[235  86]\n",
            " [ 39  74]]\n",
            "--------------------------------\n",
            "Train set: (124, 10)\n",
            "Validation set: (1178, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 100\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 70.967742 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.73      0.79       321\n",
            "           1       0.46      0.65      0.54       113\n",
            "\n",
            "    accuracy                           0.71       434\n",
            "   macro avg       0.66      0.69      0.66       434\n",
            "weighted avg       0.75      0.71      0.72       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[235  86]\n",
            " [ 40  73]]\n",
            "--------------------------------\n",
            "Train set: (125, 10)\n",
            "Validation set: (1177, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 101\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.006 s \n",
            "\n",
            "Accuracy rate is 71.198157 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.74      0.79       321\n",
            "           1       0.46      0.65      0.54       113\n",
            "\n",
            "    accuracy                           0.71       434\n",
            "   macro avg       0.66      0.69      0.66       434\n",
            "weighted avg       0.75      0.71      0.73       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[236  85]\n",
            " [ 40  73]]\n",
            "--------------------------------\n",
            "Train set: (126, 10)\n",
            "Validation set: (1176, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 102\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 70.737327 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.74      0.79       321\n",
            "           1       0.46      0.63      0.53       113\n",
            "\n",
            "    accuracy                           0.71       434\n",
            "   macro avg       0.65      0.68      0.66       434\n",
            "weighted avg       0.75      0.71      0.72       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[236  85]\n",
            " [ 42  71]]\n",
            "--------------------------------\n",
            "Train set: (127, 10)\n",
            "Validation set: (1175, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 103\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 71.198157 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.74      0.79       321\n",
            "           1       0.46      0.65      0.54       113\n",
            "\n",
            "    accuracy                           0.71       434\n",
            "   macro avg       0.66      0.69      0.66       434\n",
            "weighted avg       0.75      0.71      0.73       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[236  85]\n",
            " [ 40  73]]\n",
            "--------------------------------\n",
            "Train set: (128, 10)\n",
            "Validation set: (1174, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 104\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 70.737327 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.74      0.79       321\n",
            "           1       0.46      0.63      0.53       113\n",
            "\n",
            "    accuracy                           0.71       434\n",
            "   macro avg       0.65      0.68      0.66       434\n",
            "weighted avg       0.75      0.71      0.72       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[236  85]\n",
            " [ 42  71]]\n",
            "--------------------------------\n",
            "Train set: (129, 10)\n",
            "Validation set: (1173, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 105\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 70.967742 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.74      0.79       321\n",
            "           1       0.46      0.64      0.53       113\n",
            "\n",
            "    accuracy                           0.71       434\n",
            "   macro avg       0.66      0.69      0.66       434\n",
            "weighted avg       0.75      0.71      0.72       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[236  85]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (130, 10)\n",
            "Validation set: (1172, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 106\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 71.198157 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.74      0.79       321\n",
            "           1       0.46      0.65      0.54       113\n",
            "\n",
            "    accuracy                           0.71       434\n",
            "   macro avg       0.66      0.69      0.66       434\n",
            "weighted avg       0.75      0.71      0.73       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[236  85]\n",
            " [ 40  73]]\n",
            "--------------------------------\n",
            "Train set: (131, 10)\n",
            "Validation set: (1171, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 107\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.004 s \n",
            "\n",
            "Accuracy rate is 71.428571 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.74      0.79       321\n",
            "           1       0.46      0.64      0.54       113\n",
            "\n",
            "    accuracy                           0.71       434\n",
            "   macro avg       0.66      0.69      0.67       434\n",
            "weighted avg       0.75      0.71      0.73       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[238  83]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (132, 10)\n",
            "Validation set: (1170, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 108\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 71.658986 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.74      0.80       321\n",
            "           1       0.47      0.64      0.54       113\n",
            "\n",
            "    accuracy                           0.72       434\n",
            "   macro avg       0.66      0.69      0.67       434\n",
            "weighted avg       0.75      0.72      0.73       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[239  82]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (133, 10)\n",
            "Validation set: (1169, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 109\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.004 s \n",
            "\n",
            "Accuracy rate is 71.428571 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.74      0.79       321\n",
            "           1       0.46      0.64      0.54       113\n",
            "\n",
            "    accuracy                           0.71       434\n",
            "   macro avg       0.66      0.69      0.67       434\n",
            "weighted avg       0.75      0.71      0.73       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[238  83]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (134, 10)\n",
            "Validation set: (1168, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 110\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 71.198157 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.74      0.79       321\n",
            "           1       0.46      0.64      0.54       113\n",
            "\n",
            "    accuracy                           0.71       434\n",
            "   macro avg       0.66      0.69      0.66       434\n",
            "weighted avg       0.75      0.71      0.72       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[237  84]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (135, 10)\n",
            "Validation set: (1167, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 111\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.005 s \n",
            "\n",
            "Accuracy rate is 70.967742 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.74      0.79       321\n",
            "           1       0.46      0.63      0.53       113\n",
            "\n",
            "    accuracy                           0.71       434\n",
            "   macro avg       0.65      0.68      0.66       434\n",
            "weighted avg       0.75      0.71      0.72       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[237  84]\n",
            " [ 42  71]]\n",
            "--------------------------------\n",
            "Train set: (136, 10)\n",
            "Validation set: (1166, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 112\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 71.198157 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.74      0.79       321\n",
            "           1       0.46      0.62      0.53       113\n",
            "\n",
            "    accuracy                           0.71       434\n",
            "   macro avg       0.65      0.68      0.66       434\n",
            "weighted avg       0.75      0.71      0.72       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[239  82]\n",
            " [ 43  70]]\n",
            "--------------------------------\n",
            "Train set: (137, 10)\n",
            "Validation set: (1165, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 113\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.004 s \n",
            "\n",
            "Accuracy rate is 71.198157 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.74      0.79       321\n",
            "           1       0.46      0.63      0.53       113\n",
            "\n",
            "    accuracy                           0.71       434\n",
            "   macro avg       0.66      0.68      0.66       434\n",
            "weighted avg       0.75      0.71      0.72       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[238  83]\n",
            " [ 42  71]]\n",
            "--------------------------------\n",
            "Train set: (138, 10)\n",
            "Validation set: (1164, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 114\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 71.198157 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.74      0.79       321\n",
            "           1       0.46      0.63      0.53       113\n",
            "\n",
            "    accuracy                           0.71       434\n",
            "   macro avg       0.66      0.68      0.66       434\n",
            "weighted avg       0.75      0.71      0.72       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[238  83]\n",
            " [ 42  71]]\n",
            "--------------------------------\n",
            "Train set: (139, 10)\n",
            "Validation set: (1163, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 115\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 70.737327 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.74      0.79       321\n",
            "           1       0.45      0.62      0.52       113\n",
            "\n",
            "    accuracy                           0.71       434\n",
            "   macro avg       0.65      0.68      0.66       434\n",
            "weighted avg       0.74      0.71      0.72       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[237  84]\n",
            " [ 43  70]]\n",
            "--------------------------------\n",
            "Train set: (140, 10)\n",
            "Validation set: (1162, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 116\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 71.889401 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.74      0.80       321\n",
            "           1       0.47      0.65      0.54       113\n",
            "\n",
            "    accuracy                           0.72       434\n",
            "   macro avg       0.66      0.70      0.67       434\n",
            "weighted avg       0.76      0.72      0.73       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[239  82]\n",
            " [ 40  73]]\n",
            "--------------------------------\n",
            "Train set: (141, 10)\n",
            "Validation set: (1161, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 117\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 71.198157 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.74      0.79       321\n",
            "           1       0.46      0.64      0.54       113\n",
            "\n",
            "    accuracy                           0.71       434\n",
            "   macro avg       0.66      0.69      0.66       434\n",
            "weighted avg       0.75      0.71      0.72       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[237  84]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (142, 10)\n",
            "Validation set: (1160, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 118\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 71.198157 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.74      0.79       321\n",
            "           1       0.46      0.65      0.54       113\n",
            "\n",
            "    accuracy                           0.71       434\n",
            "   macro avg       0.66      0.69      0.66       434\n",
            "weighted avg       0.75      0.71      0.73       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[236  85]\n",
            " [ 40  73]]\n",
            "--------------------------------\n",
            "Train set: (143, 10)\n",
            "Validation set: (1159, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 119\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 71.198157 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.74      0.79       321\n",
            "           1       0.46      0.65      0.54       113\n",
            "\n",
            "    accuracy                           0.71       434\n",
            "   macro avg       0.66      0.69      0.66       434\n",
            "weighted avg       0.75      0.71      0.73       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[236  85]\n",
            " [ 40  73]]\n",
            "--------------------------------\n",
            "Train set: (144, 10)\n",
            "Validation set: (1158, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 120\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 70.967742 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.74      0.79       321\n",
            "           1       0.46      0.64      0.53       113\n",
            "\n",
            "    accuracy                           0.71       434\n",
            "   macro avg       0.66      0.69      0.66       434\n",
            "weighted avg       0.75      0.71      0.72       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[236  85]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (145, 10)\n",
            "Validation set: (1157, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 121\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 71.658986 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.74      0.79       321\n",
            "           1       0.47      0.65      0.54       113\n",
            "\n",
            "    accuracy                           0.72       434\n",
            "   macro avg       0.66      0.69      0.67       434\n",
            "weighted avg       0.76      0.72      0.73       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[238  83]\n",
            " [ 40  73]]\n",
            "--------------------------------\n",
            "Train set: (146, 10)\n",
            "Validation set: (1156, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 122\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 71.658986 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.74      0.79       321\n",
            "           1       0.47      0.65      0.54       113\n",
            "\n",
            "    accuracy                           0.72       434\n",
            "   macro avg       0.66      0.69      0.67       434\n",
            "weighted avg       0.76      0.72      0.73       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[238  83]\n",
            " [ 40  73]]\n",
            "--------------------------------\n",
            "Train set: (147, 10)\n",
            "Validation set: (1155, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 123\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 71.889401 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.74      0.80       321\n",
            "           1       0.47      0.65      0.54       113\n",
            "\n",
            "    accuracy                           0.72       434\n",
            "   macro avg       0.66      0.70      0.67       434\n",
            "weighted avg       0.76      0.72      0.73       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[239  82]\n",
            " [ 40  73]]\n",
            "--------------------------------\n",
            "Train set: (148, 10)\n",
            "Validation set: (1154, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 124\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 71.658986 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.74      0.79       321\n",
            "           1       0.47      0.65      0.54       113\n",
            "\n",
            "    accuracy                           0.72       434\n",
            "   macro avg       0.66      0.69      0.67       434\n",
            "weighted avg       0.76      0.72      0.73       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[238  83]\n",
            " [ 40  73]]\n",
            "--------------------------------\n",
            "Train set: (149, 10)\n",
            "Validation set: (1153, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 125\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 72.119816 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.75      0.80       321\n",
            "           1       0.47      0.65      0.55       113\n",
            "\n",
            "    accuracy                           0.72       434\n",
            "   macro avg       0.67      0.70      0.67       434\n",
            "weighted avg       0.76      0.72      0.73       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[240  81]\n",
            " [ 40  73]]\n",
            "--------------------------------\n",
            "Train set: (150, 10)\n",
            "Validation set: (1152, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 126\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 71.889401 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.74      0.80       321\n",
            "           1       0.47      0.65      0.54       113\n",
            "\n",
            "    accuracy                           0.72       434\n",
            "   macro avg       0.66      0.70      0.67       434\n",
            "weighted avg       0.76      0.72      0.73       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[239  82]\n",
            " [ 40  73]]\n",
            "--------------------------------\n",
            "Train set: (151, 10)\n",
            "Validation set: (1151, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 127\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 71.658986 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.74      0.79       321\n",
            "           1       0.47      0.65      0.54       113\n",
            "\n",
            "    accuracy                           0.72       434\n",
            "   macro avg       0.66      0.69      0.67       434\n",
            "weighted avg       0.76      0.72      0.73       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[238  83]\n",
            " [ 40  73]]\n",
            "--------------------------------\n",
            "Train set: (152, 10)\n",
            "Validation set: (1150, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 128\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 70.737327 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.73      0.79       321\n",
            "           1       0.46      0.65      0.53       113\n",
            "\n",
            "    accuracy                           0.71       434\n",
            "   macro avg       0.66      0.69      0.66       434\n",
            "weighted avg       0.75      0.71      0.72       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[234  87]\n",
            " [ 40  73]]\n",
            "--------------------------------\n",
            "Train set: (153, 10)\n",
            "Validation set: (1149, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 129\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 71.428571 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.74      0.79       321\n",
            "           1       0.46      0.64      0.54       113\n",
            "\n",
            "    accuracy                           0.71       434\n",
            "   macro avg       0.66      0.69      0.67       434\n",
            "weighted avg       0.75      0.71      0.73       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[238  83]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (154, 10)\n",
            "Validation set: (1148, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 130\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 71.198157 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.74      0.79       321\n",
            "           1       0.46      0.64      0.54       113\n",
            "\n",
            "    accuracy                           0.71       434\n",
            "   macro avg       0.66      0.69      0.66       434\n",
            "weighted avg       0.75      0.71      0.72       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[237  84]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (155, 10)\n",
            "Validation set: (1147, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 131\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 71.198157 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.74      0.79       321\n",
            "           1       0.46      0.64      0.54       113\n",
            "\n",
            "    accuracy                           0.71       434\n",
            "   macro avg       0.66      0.69      0.66       434\n",
            "weighted avg       0.75      0.71      0.72       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[237  84]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (156, 10)\n",
            "Validation set: (1146, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 132\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 70.967742 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.73      0.79       321\n",
            "           1       0.46      0.65      0.54       113\n",
            "\n",
            "    accuracy                           0.71       434\n",
            "   macro avg       0.66      0.69      0.66       434\n",
            "weighted avg       0.75      0.71      0.72       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[235  86]\n",
            " [ 40  73]]\n",
            "--------------------------------\n",
            "Train set: (157, 10)\n",
            "Validation set: (1145, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 133\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 71.198157 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.74      0.79       321\n",
            "           1       0.46      0.64      0.54       113\n",
            "\n",
            "    accuracy                           0.71       434\n",
            "   macro avg       0.66      0.69      0.66       434\n",
            "weighted avg       0.75      0.71      0.72       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[237  84]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (158, 10)\n",
            "Validation set: (1144, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 134\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 71.198157 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.74      0.79       321\n",
            "           1       0.46      0.64      0.54       113\n",
            "\n",
            "    accuracy                           0.71       434\n",
            "   macro avg       0.66      0.69      0.66       434\n",
            "weighted avg       0.75      0.71      0.72       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[237  84]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (159, 10)\n",
            "Validation set: (1143, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 135\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 71.198157 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.74      0.79       321\n",
            "           1       0.46      0.64      0.54       113\n",
            "\n",
            "    accuracy                           0.71       434\n",
            "   macro avg       0.66      0.69      0.66       434\n",
            "weighted avg       0.75      0.71      0.72       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[237  84]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (160, 10)\n",
            "Validation set: (1142, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 136\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 71.198157 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.74      0.79       321\n",
            "           1       0.46      0.64      0.54       113\n",
            "\n",
            "    accuracy                           0.71       434\n",
            "   macro avg       0.66      0.69      0.66       434\n",
            "weighted avg       0.75      0.71      0.72       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[237  84]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (161, 10)\n",
            "Validation set: (1141, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 137\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 71.428571 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.74      0.79       321\n",
            "           1       0.46      0.64      0.54       113\n",
            "\n",
            "    accuracy                           0.71       434\n",
            "   macro avg       0.66      0.69      0.67       434\n",
            "weighted avg       0.75      0.71      0.73       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[238  83]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (162, 10)\n",
            "Validation set: (1140, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 138\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 71.428571 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.74      0.79       321\n",
            "           1       0.46      0.64      0.54       113\n",
            "\n",
            "    accuracy                           0.71       434\n",
            "   macro avg       0.66      0.69      0.67       434\n",
            "weighted avg       0.75      0.71      0.73       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[238  83]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (163, 10)\n",
            "Validation set: (1139, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 139\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 71.658986 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.74      0.80       321\n",
            "           1       0.47      0.64      0.54       113\n",
            "\n",
            "    accuracy                           0.72       434\n",
            "   macro avg       0.66      0.69      0.67       434\n",
            "weighted avg       0.75      0.72      0.73       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[239  82]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (164, 10)\n",
            "Validation set: (1138, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 140\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 71.658986 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.74      0.80       321\n",
            "           1       0.47      0.64      0.54       113\n",
            "\n",
            "    accuracy                           0.72       434\n",
            "   macro avg       0.66      0.69      0.67       434\n",
            "weighted avg       0.75      0.72      0.73       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[239  82]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (165, 10)\n",
            "Validation set: (1137, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 141\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 71.428571 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.74      0.79       321\n",
            "           1       0.46      0.64      0.54       113\n",
            "\n",
            "    accuracy                           0.71       434\n",
            "   macro avg       0.66      0.69      0.67       434\n",
            "weighted avg       0.75      0.71      0.73       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[238  83]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (166, 10)\n",
            "Validation set: (1136, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 142\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 71.658986 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.74      0.80       321\n",
            "           1       0.47      0.64      0.54       113\n",
            "\n",
            "    accuracy                           0.72       434\n",
            "   macro avg       0.66      0.69      0.67       434\n",
            "weighted avg       0.75      0.72      0.73       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[239  82]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (167, 10)\n",
            "Validation set: (1135, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 143\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 71.889401 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.74      0.80       321\n",
            "           1       0.47      0.65      0.54       113\n",
            "\n",
            "    accuracy                           0.72       434\n",
            "   macro avg       0.66      0.70      0.67       434\n",
            "weighted avg       0.76      0.72      0.73       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[239  82]\n",
            " [ 40  73]]\n",
            "--------------------------------\n",
            "Train set: (168, 10)\n",
            "Validation set: (1134, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 144\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 71.658986 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.74      0.79       321\n",
            "           1       0.47      0.65      0.54       113\n",
            "\n",
            "    accuracy                           0.72       434\n",
            "   macro avg       0.66      0.69      0.67       434\n",
            "weighted avg       0.76      0.72      0.73       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[238  83]\n",
            " [ 40  73]]\n",
            "--------------------------------\n",
            "Train set: (169, 10)\n",
            "Validation set: (1133, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 145\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 71.889401 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.74      0.80       321\n",
            "           1       0.47      0.65      0.54       113\n",
            "\n",
            "    accuracy                           0.72       434\n",
            "   macro avg       0.66      0.70      0.67       434\n",
            "weighted avg       0.76      0.72      0.73       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[239  82]\n",
            " [ 40  73]]\n",
            "--------------------------------\n",
            "Train set: (170, 10)\n",
            "Validation set: (1132, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 146\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 72.119816 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.75      0.80       321\n",
            "           1       0.47      0.65      0.55       113\n",
            "\n",
            "    accuracy                           0.72       434\n",
            "   macro avg       0.67      0.70      0.67       434\n",
            "weighted avg       0.76      0.72      0.73       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[240  81]\n",
            " [ 40  73]]\n",
            "--------------------------------\n",
            "Train set: (171, 10)\n",
            "Validation set: (1131, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 147\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 71.889401 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.74      0.80       321\n",
            "           1       0.47      0.65      0.54       113\n",
            "\n",
            "    accuracy                           0.72       434\n",
            "   macro avg       0.66      0.70      0.67       434\n",
            "weighted avg       0.76      0.72      0.73       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[239  82]\n",
            " [ 40  73]]\n",
            "--------------------------------\n",
            "Train set: (172, 10)\n",
            "Validation set: (1130, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 148\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 71.658986 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.74      0.79       321\n",
            "           1       0.47      0.65      0.54       113\n",
            "\n",
            "    accuracy                           0.72       434\n",
            "   macro avg       0.66      0.69      0.67       434\n",
            "weighted avg       0.76      0.72      0.73       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[238  83]\n",
            " [ 40  73]]\n",
            "--------------------------------\n",
            "Train set: (173, 10)\n",
            "Validation set: (1129, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 149\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 71.198157 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.74      0.79       321\n",
            "           1       0.46      0.65      0.54       113\n",
            "\n",
            "    accuracy                           0.71       434\n",
            "   macro avg       0.66      0.69      0.66       434\n",
            "weighted avg       0.75      0.71      0.73       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[236  85]\n",
            " [ 40  73]]\n",
            "--------------------------------\n",
            "Train set: (174, 10)\n",
            "Validation set: (1128, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 150\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 71.658986 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.74      0.79       321\n",
            "           1       0.47      0.65      0.54       113\n",
            "\n",
            "    accuracy                           0.72       434\n",
            "   macro avg       0.66      0.69      0.67       434\n",
            "weighted avg       0.76      0.72      0.73       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[238  83]\n",
            " [ 40  73]]\n",
            "--------------------------------\n",
            "Train set: (175, 10)\n",
            "Validation set: (1127, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 151\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.004 s \n",
            "\n",
            "Accuracy rate is 71.428571 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.74      0.79       321\n",
            "           1       0.46      0.65      0.54       113\n",
            "\n",
            "    accuracy                           0.71       434\n",
            "   macro avg       0.66      0.69      0.67       434\n",
            "weighted avg       0.75      0.71      0.73       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[237  84]\n",
            " [ 40  73]]\n",
            "--------------------------------\n",
            "Train set: (176, 10)\n",
            "Validation set: (1126, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 152\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 71.889401 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.74      0.80       321\n",
            "           1       0.47      0.65      0.54       113\n",
            "\n",
            "    accuracy                           0.72       434\n",
            "   macro avg       0.66      0.70      0.67       434\n",
            "weighted avg       0.76      0.72      0.73       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[239  82]\n",
            " [ 40  73]]\n",
            "--------------------------------\n",
            "Train set: (177, 10)\n",
            "Validation set: (1125, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 153\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 72.580645 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.75      0.80       321\n",
            "           1       0.48      0.65      0.55       113\n",
            "\n",
            "    accuracy                           0.73       434\n",
            "   macro avg       0.67      0.70      0.68       434\n",
            "weighted avg       0.76      0.73      0.74       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[242  79]\n",
            " [ 40  73]]\n",
            "--------------------------------\n",
            "Train set: (178, 10)\n",
            "Validation set: (1124, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 154\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 72.119816 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.75      0.80       321\n",
            "           1       0.47      0.65      0.55       113\n",
            "\n",
            "    accuracy                           0.72       434\n",
            "   macro avg       0.67      0.70      0.67       434\n",
            "weighted avg       0.76      0.72      0.73       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[240  81]\n",
            " [ 40  73]]\n",
            "--------------------------------\n",
            "Train set: (179, 10)\n",
            "Validation set: (1123, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 155\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 72.119816 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.75      0.80       321\n",
            "           1       0.47      0.65      0.55       113\n",
            "\n",
            "    accuracy                           0.72       434\n",
            "   macro avg       0.67      0.70      0.67       434\n",
            "weighted avg       0.76      0.72      0.73       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[240  81]\n",
            " [ 40  73]]\n",
            "--------------------------------\n",
            "Train set: (180, 10)\n",
            "Validation set: (1122, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 156\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 72.119816 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.75      0.80       321\n",
            "           1       0.47      0.65      0.55       113\n",
            "\n",
            "    accuracy                           0.72       434\n",
            "   macro avg       0.67      0.70      0.67       434\n",
            "weighted avg       0.76      0.72      0.73       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[240  81]\n",
            " [ 40  73]]\n",
            "--------------------------------\n",
            "Train set: (181, 10)\n",
            "Validation set: (1121, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 157\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 72.350230 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.75      0.80       321\n",
            "           1       0.48      0.64      0.55       113\n",
            "\n",
            "    accuracy                           0.72       434\n",
            "   macro avg       0.67      0.70      0.67       434\n",
            "weighted avg       0.76      0.72      0.73       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[242  79]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (182, 10)\n",
            "Validation set: (1120, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 158\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 72.350230 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.75      0.80       321\n",
            "           1       0.48      0.64      0.55       113\n",
            "\n",
            "    accuracy                           0.72       434\n",
            "   macro avg       0.67      0.70      0.67       434\n",
            "weighted avg       0.76      0.72      0.73       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[242  79]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (183, 10)\n",
            "Validation set: (1119, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 159\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 72.350230 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.75      0.80       321\n",
            "           1       0.48      0.65      0.55       113\n",
            "\n",
            "    accuracy                           0.72       434\n",
            "   macro avg       0.67      0.70      0.67       434\n",
            "weighted avg       0.76      0.72      0.74       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[241  80]\n",
            " [ 40  73]]\n",
            "--------------------------------\n",
            "Train set: (184, 10)\n",
            "Validation set: (1118, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 160\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 72.119816 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.75      0.80       321\n",
            "           1       0.47      0.65      0.55       113\n",
            "\n",
            "    accuracy                           0.72       434\n",
            "   macro avg       0.67      0.70      0.67       434\n",
            "weighted avg       0.76      0.72      0.73       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[240  81]\n",
            " [ 40  73]]\n",
            "--------------------------------\n",
            "Train set: (185, 10)\n",
            "Validation set: (1117, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 161\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 72.350230 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.75      0.80       321\n",
            "           1       0.48      0.64      0.55       113\n",
            "\n",
            "    accuracy                           0.72       434\n",
            "   macro avg       0.67      0.70      0.67       434\n",
            "weighted avg       0.76      0.72      0.73       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[242  79]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (186, 10)\n",
            "Validation set: (1116, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 162\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 71.889401 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.74      0.80       321\n",
            "           1       0.47      0.65      0.54       113\n",
            "\n",
            "    accuracy                           0.72       434\n",
            "   macro avg       0.66      0.70      0.67       434\n",
            "weighted avg       0.76      0.72      0.73       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[239  82]\n",
            " [ 40  73]]\n",
            "--------------------------------\n",
            "Train set: (187, 10)\n",
            "Validation set: (1115, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 163\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 72.119816 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.75      0.80       321\n",
            "           1       0.47      0.65      0.55       113\n",
            "\n",
            "    accuracy                           0.72       434\n",
            "   macro avg       0.67      0.70      0.67       434\n",
            "weighted avg       0.76      0.72      0.73       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[240  81]\n",
            " [ 40  73]]\n",
            "--------------------------------\n",
            "Train set: (188, 10)\n",
            "Validation set: (1114, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 164\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 71.889401 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.74      0.80       321\n",
            "           1       0.47      0.65      0.54       113\n",
            "\n",
            "    accuracy                           0.72       434\n",
            "   macro avg       0.66      0.70      0.67       434\n",
            "weighted avg       0.76      0.72      0.73       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[239  82]\n",
            " [ 40  73]]\n",
            "--------------------------------\n",
            "Train set: (189, 10)\n",
            "Validation set: (1113, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 165\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 71.889401 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.74      0.80       321\n",
            "           1       0.47      0.65      0.54       113\n",
            "\n",
            "    accuracy                           0.72       434\n",
            "   macro avg       0.66      0.70      0.67       434\n",
            "weighted avg       0.76      0.72      0.73       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[239  82]\n",
            " [ 40  73]]\n",
            "--------------------------------\n",
            "Train set: (190, 10)\n",
            "Validation set: (1112, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 166\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 72.119816 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.75      0.80       321\n",
            "           1       0.47      0.64      0.54       113\n",
            "\n",
            "    accuracy                           0.72       434\n",
            "   macro avg       0.66      0.69      0.67       434\n",
            "weighted avg       0.76      0.72      0.73       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[241  80]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (191, 10)\n",
            "Validation set: (1111, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 167\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 72.580645 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.75      0.80       321\n",
            "           1       0.48      0.65      0.55       113\n",
            "\n",
            "    accuracy                           0.73       434\n",
            "   macro avg       0.67      0.70      0.68       434\n",
            "weighted avg       0.76      0.73      0.74       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[242  79]\n",
            " [ 40  73]]\n",
            "--------------------------------\n",
            "Train set: (192, 10)\n",
            "Validation set: (1110, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 168\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 72.350230 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.75      0.80       321\n",
            "           1       0.48      0.64      0.55       113\n",
            "\n",
            "    accuracy                           0.72       434\n",
            "   macro avg       0.67      0.70      0.67       434\n",
            "weighted avg       0.76      0.72      0.73       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[242  79]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (193, 10)\n",
            "Validation set: (1109, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 169\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 72.350230 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.75      0.80       321\n",
            "           1       0.48      0.64      0.55       113\n",
            "\n",
            "    accuracy                           0.72       434\n",
            "   macro avg       0.67      0.70      0.67       434\n",
            "weighted avg       0.76      0.72      0.73       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[242  79]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (194, 10)\n",
            "Validation set: (1108, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 170\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 72.580645 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.75      0.80       321\n",
            "           1       0.48      0.65      0.55       113\n",
            "\n",
            "    accuracy                           0.73       434\n",
            "   macro avg       0.67      0.70      0.68       434\n",
            "weighted avg       0.76      0.73      0.74       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[242  79]\n",
            " [ 40  73]]\n",
            "--------------------------------\n",
            "Train set: (195, 10)\n",
            "Validation set: (1107, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 171\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 72.119816 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.75      0.80       321\n",
            "           1       0.47      0.65      0.55       113\n",
            "\n",
            "    accuracy                           0.72       434\n",
            "   macro avg       0.67      0.70      0.67       434\n",
            "weighted avg       0.76      0.72      0.73       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[240  81]\n",
            " [ 40  73]]\n",
            "--------------------------------\n",
            "Train set: (196, 10)\n",
            "Validation set: (1106, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 172\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 72.119816 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.75      0.80       321\n",
            "           1       0.47      0.64      0.54       113\n",
            "\n",
            "    accuracy                           0.72       434\n",
            "   macro avg       0.66      0.69      0.67       434\n",
            "weighted avg       0.76      0.72      0.73       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[241  80]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (197, 10)\n",
            "Validation set: (1105, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 173\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 72.119816 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.75      0.80       321\n",
            "           1       0.47      0.64      0.54       113\n",
            "\n",
            "    accuracy                           0.72       434\n",
            "   macro avg       0.66      0.69      0.67       434\n",
            "weighted avg       0.76      0.72      0.73       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[241  80]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (198, 10)\n",
            "Validation set: (1104, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 174\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 72.350230 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.75      0.80       321\n",
            "           1       0.48      0.65      0.55       113\n",
            "\n",
            "    accuracy                           0.72       434\n",
            "   macro avg       0.67      0.70      0.67       434\n",
            "weighted avg       0.76      0.72      0.74       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[241  80]\n",
            " [ 40  73]]\n",
            "--------------------------------\n",
            "Train set: (199, 10)\n",
            "Validation set: (1103, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 175\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 72.350230 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.75      0.80       321\n",
            "           1       0.48      0.64      0.55       113\n",
            "\n",
            "    accuracy                           0.72       434\n",
            "   macro avg       0.67      0.70      0.67       434\n",
            "weighted avg       0.76      0.72      0.73       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[242  79]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (200, 10)\n",
            "Validation set: (1102, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 176\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 72.580645 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.76      0.80       321\n",
            "           1       0.48      0.64      0.55       113\n",
            "\n",
            "    accuracy                           0.73       434\n",
            "   macro avg       0.67      0.70      0.68       434\n",
            "weighted avg       0.76      0.73      0.74       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[243  78]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (201, 10)\n",
            "Validation set: (1101, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 177\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 72.350230 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.75      0.80       321\n",
            "           1       0.48      0.65      0.55       113\n",
            "\n",
            "    accuracy                           0.72       434\n",
            "   macro avg       0.67      0.70      0.67       434\n",
            "weighted avg       0.76      0.72      0.74       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[241  80]\n",
            " [ 40  73]]\n",
            "--------------------------------\n",
            "Train set: (202, 10)\n",
            "Validation set: (1100, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 178\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 72.119816 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.75      0.80       321\n",
            "           1       0.47      0.64      0.54       113\n",
            "\n",
            "    accuracy                           0.72       434\n",
            "   macro avg       0.66      0.69      0.67       434\n",
            "weighted avg       0.76      0.72      0.73       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[241  80]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (203, 10)\n",
            "Validation set: (1099, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 179\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 72.119816 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.75      0.80       321\n",
            "           1       0.47      0.64      0.54       113\n",
            "\n",
            "    accuracy                           0.72       434\n",
            "   macro avg       0.66      0.69      0.67       434\n",
            "weighted avg       0.76      0.72      0.73       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[241  80]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (204, 10)\n",
            "Validation set: (1098, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 180\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 72.350230 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.75      0.80       321\n",
            "           1       0.48      0.64      0.55       113\n",
            "\n",
            "    accuracy                           0.72       434\n",
            "   macro avg       0.67      0.70      0.67       434\n",
            "weighted avg       0.76      0.72      0.73       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[242  79]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (205, 10)\n",
            "Validation set: (1097, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 181\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 71.658986 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.74      0.80       321\n",
            "           1       0.47      0.64      0.54       113\n",
            "\n",
            "    accuracy                           0.72       434\n",
            "   macro avg       0.66      0.69      0.67       434\n",
            "weighted avg       0.75      0.72      0.73       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[239  82]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (206, 10)\n",
            "Validation set: (1096, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 182\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 71.889401 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.75      0.80       321\n",
            "           1       0.47      0.64      0.54       113\n",
            "\n",
            "    accuracy                           0.72       434\n",
            "   macro avg       0.66      0.69      0.67       434\n",
            "weighted avg       0.75      0.72      0.73       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[240  81]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (207, 10)\n",
            "Validation set: (1095, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 183\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 71.428571 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.74      0.79       321\n",
            "           1       0.46      0.64      0.54       113\n",
            "\n",
            "    accuracy                           0.71       434\n",
            "   macro avg       0.66      0.69      0.67       434\n",
            "weighted avg       0.75      0.71      0.73       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[238  83]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (208, 10)\n",
            "Validation set: (1094, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 184\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 71.198157 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.74      0.79       321\n",
            "           1       0.46      0.64      0.54       113\n",
            "\n",
            "    accuracy                           0.71       434\n",
            "   macro avg       0.66      0.69      0.66       434\n",
            "weighted avg       0.75      0.71      0.72       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[237  84]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (209, 10)\n",
            "Validation set: (1093, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 185\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 71.198157 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.74      0.79       321\n",
            "           1       0.46      0.64      0.54       113\n",
            "\n",
            "    accuracy                           0.71       434\n",
            "   macro avg       0.66      0.69      0.66       434\n",
            "weighted avg       0.75      0.71      0.72       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[237  84]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (210, 10)\n",
            "Validation set: (1092, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 186\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 72.350230 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.75      0.80       321\n",
            "           1       0.48      0.64      0.55       113\n",
            "\n",
            "    accuracy                           0.72       434\n",
            "   macro avg       0.67      0.70      0.67       434\n",
            "weighted avg       0.76      0.72      0.73       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[242  79]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (211, 10)\n",
            "Validation set: (1091, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 187\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 72.119816 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.75      0.80       321\n",
            "           1       0.47      0.64      0.54       113\n",
            "\n",
            "    accuracy                           0.72       434\n",
            "   macro avg       0.66      0.69      0.67       434\n",
            "weighted avg       0.76      0.72      0.73       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[241  80]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (212, 10)\n",
            "Validation set: (1090, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 188\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 72.350230 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.75      0.80       321\n",
            "           1       0.48      0.64      0.55       113\n",
            "\n",
            "    accuracy                           0.72       434\n",
            "   macro avg       0.67      0.70      0.67       434\n",
            "weighted avg       0.76      0.72      0.73       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[242  79]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (213, 10)\n",
            "Validation set: (1089, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 189\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 72.119816 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.75      0.80       321\n",
            "           1       0.47      0.64      0.54       113\n",
            "\n",
            "    accuracy                           0.72       434\n",
            "   macro avg       0.66      0.69      0.67       434\n",
            "weighted avg       0.76      0.72      0.73       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[241  80]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (214, 10)\n",
            "Validation set: (1088, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 190\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 72.119816 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.75      0.80       321\n",
            "           1       0.47      0.64      0.54       113\n",
            "\n",
            "    accuracy                           0.72       434\n",
            "   macro avg       0.66      0.69      0.67       434\n",
            "weighted avg       0.76      0.72      0.73       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[241  80]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (215, 10)\n",
            "Validation set: (1087, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 191\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 71.889401 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.75      0.80       321\n",
            "           1       0.47      0.64      0.54       113\n",
            "\n",
            "    accuracy                           0.72       434\n",
            "   macro avg       0.66      0.69      0.67       434\n",
            "weighted avg       0.75      0.72      0.73       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[240  81]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (216, 10)\n",
            "Validation set: (1086, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 192\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 71.889401 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.75      0.80       321\n",
            "           1       0.47      0.64      0.54       113\n",
            "\n",
            "    accuracy                           0.72       434\n",
            "   macro avg       0.66      0.69      0.67       434\n",
            "weighted avg       0.75      0.72      0.73       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[240  81]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (217, 10)\n",
            "Validation set: (1085, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 193\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 72.350230 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.75      0.80       321\n",
            "           1       0.48      0.64      0.55       113\n",
            "\n",
            "    accuracy                           0.72       434\n",
            "   macro avg       0.67      0.70      0.67       434\n",
            "weighted avg       0.76      0.72      0.73       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[242  79]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (218, 10)\n",
            "Validation set: (1084, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 194\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 72.119816 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.75      0.80       321\n",
            "           1       0.47      0.64      0.54       113\n",
            "\n",
            "    accuracy                           0.72       434\n",
            "   macro avg       0.66      0.69      0.67       434\n",
            "weighted avg       0.76      0.72      0.73       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[241  80]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (219, 10)\n",
            "Validation set: (1083, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 195\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 72.119816 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.75      0.80       321\n",
            "           1       0.47      0.64      0.54       113\n",
            "\n",
            "    accuracy                           0.72       434\n",
            "   macro avg       0.66      0.69      0.67       434\n",
            "weighted avg       0.76      0.72      0.73       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[241  80]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (220, 10)\n",
            "Validation set: (1082, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 196\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 72.350230 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.75      0.80       321\n",
            "           1       0.48      0.64      0.55       113\n",
            "\n",
            "    accuracy                           0.72       434\n",
            "   macro avg       0.67      0.70      0.67       434\n",
            "weighted avg       0.76      0.72      0.73       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[242  79]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (221, 10)\n",
            "Validation set: (1081, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 197\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.004 s \n",
            "\n",
            "Accuracy rate is 71.889401 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.75      0.80       321\n",
            "           1       0.47      0.64      0.54       113\n",
            "\n",
            "    accuracy                           0.72       434\n",
            "   macro avg       0.66      0.69      0.67       434\n",
            "weighted avg       0.75      0.72      0.73       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[240  81]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (222, 10)\n",
            "Validation set: (1080, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 198\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 71.889401 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.75      0.80       321\n",
            "           1       0.47      0.64      0.54       113\n",
            "\n",
            "    accuracy                           0.72       434\n",
            "   macro avg       0.66      0.69      0.67       434\n",
            "weighted avg       0.75      0.72      0.73       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[240  81]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (223, 10)\n",
            "Validation set: (1079, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 199\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 72.119816 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.75      0.80       321\n",
            "           1       0.47      0.64      0.54       113\n",
            "\n",
            "    accuracy                           0.72       434\n",
            "   macro avg       0.66      0.69      0.67       434\n",
            "weighted avg       0.76      0.72      0.73       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[241  80]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (224, 10)\n",
            "Validation set: (1078, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 200\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 71.889401 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.75      0.80       321\n",
            "           1       0.47      0.64      0.54       113\n",
            "\n",
            "    accuracy                           0.72       434\n",
            "   macro avg       0.66      0.69      0.67       434\n",
            "weighted avg       0.75      0.72      0.73       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[240  81]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (225, 10)\n",
            "Validation set: (1077, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 201\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 72.119816 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.75      0.80       321\n",
            "           1       0.47      0.64      0.54       113\n",
            "\n",
            "    accuracy                           0.72       434\n",
            "   macro avg       0.66      0.69      0.67       434\n",
            "weighted avg       0.76      0.72      0.73       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[241  80]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (226, 10)\n",
            "Validation set: (1076, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 202\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 72.119816 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.75      0.80       321\n",
            "           1       0.47      0.64      0.54       113\n",
            "\n",
            "    accuracy                           0.72       434\n",
            "   macro avg       0.66      0.69      0.67       434\n",
            "weighted avg       0.76      0.72      0.73       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[241  80]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (227, 10)\n",
            "Validation set: (1075, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 203\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 72.350230 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.75      0.80       321\n",
            "           1       0.48      0.64      0.55       113\n",
            "\n",
            "    accuracy                           0.72       434\n",
            "   macro avg       0.67      0.70      0.67       434\n",
            "weighted avg       0.76      0.72      0.73       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[242  79]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (228, 10)\n",
            "Validation set: (1074, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 204\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 72.119816 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.75      0.80       321\n",
            "           1       0.47      0.64      0.54       113\n",
            "\n",
            "    accuracy                           0.72       434\n",
            "   macro avg       0.66      0.69      0.67       434\n",
            "weighted avg       0.76      0.72      0.73       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[241  80]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (229, 10)\n",
            "Validation set: (1073, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 205\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 72.119816 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.75      0.80       321\n",
            "           1       0.47      0.64      0.54       113\n",
            "\n",
            "    accuracy                           0.72       434\n",
            "   macro avg       0.66      0.69      0.67       434\n",
            "weighted avg       0.76      0.72      0.73       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[241  80]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (230, 10)\n",
            "Validation set: (1072, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 206\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 72.119816 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.75      0.80       321\n",
            "           1       0.47      0.64      0.54       113\n",
            "\n",
            "    accuracy                           0.72       434\n",
            "   macro avg       0.66      0.69      0.67       434\n",
            "weighted avg       0.76      0.72      0.73       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[241  80]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (231, 10)\n",
            "Validation set: (1071, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 207\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 72.119816 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.75      0.80       321\n",
            "           1       0.47      0.64      0.54       113\n",
            "\n",
            "    accuracy                           0.72       434\n",
            "   macro avg       0.66      0.69      0.67       434\n",
            "weighted avg       0.76      0.72      0.73       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[241  80]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (232, 10)\n",
            "Validation set: (1070, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 208\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 72.119816 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.75      0.80       321\n",
            "           1       0.47      0.64      0.54       113\n",
            "\n",
            "    accuracy                           0.72       434\n",
            "   macro avg       0.66      0.69      0.67       434\n",
            "weighted avg       0.76      0.72      0.73       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[241  80]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (233, 10)\n",
            "Validation set: (1069, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 209\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 72.580645 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.76      0.80       321\n",
            "           1       0.48      0.64      0.55       113\n",
            "\n",
            "    accuracy                           0.73       434\n",
            "   macro avg       0.67      0.70      0.68       434\n",
            "weighted avg       0.76      0.73      0.74       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[243  78]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (234, 10)\n",
            "Validation set: (1068, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 210\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 72.811060 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.76      0.81       321\n",
            "           1       0.48      0.64      0.55       113\n",
            "\n",
            "    accuracy                           0.73       434\n",
            "   macro avg       0.67      0.70      0.68       434\n",
            "weighted avg       0.76      0.73      0.74       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[244  77]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (235, 10)\n",
            "Validation set: (1067, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 211\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.004 s \n",
            "\n",
            "Accuracy rate is 72.580645 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.76      0.80       321\n",
            "           1       0.48      0.64      0.55       113\n",
            "\n",
            "    accuracy                           0.73       434\n",
            "   macro avg       0.67      0.70      0.68       434\n",
            "weighted avg       0.76      0.73      0.74       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[243  78]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (236, 10)\n",
            "Validation set: (1066, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 212\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 72.811060 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.76      0.81       321\n",
            "           1       0.48      0.64      0.55       113\n",
            "\n",
            "    accuracy                           0.73       434\n",
            "   macro avg       0.67      0.70      0.68       434\n",
            "weighted avg       0.76      0.73      0.74       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[244  77]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (237, 10)\n",
            "Validation set: (1065, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 213\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 72.350230 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.75      0.80       321\n",
            "           1       0.48      0.64      0.55       113\n",
            "\n",
            "    accuracy                           0.72       434\n",
            "   macro avg       0.67      0.70      0.67       434\n",
            "weighted avg       0.76      0.72      0.73       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[242  79]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (238, 10)\n",
            "Validation set: (1064, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 214\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 72.350230 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.75      0.80       321\n",
            "           1       0.48      0.64      0.55       113\n",
            "\n",
            "    accuracy                           0.72       434\n",
            "   macro avg       0.67      0.70      0.67       434\n",
            "weighted avg       0.76      0.72      0.73       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[242  79]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (239, 10)\n",
            "Validation set: (1063, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 215\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 72.350230 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.75      0.80       321\n",
            "           1       0.48      0.64      0.55       113\n",
            "\n",
            "    accuracy                           0.72       434\n",
            "   macro avg       0.67      0.70      0.67       434\n",
            "weighted avg       0.76      0.72      0.73       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[242  79]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (240, 10)\n",
            "Validation set: (1062, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 216\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 72.350230 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.75      0.80       321\n",
            "           1       0.48      0.64      0.55       113\n",
            "\n",
            "    accuracy                           0.72       434\n",
            "   macro avg       0.67      0.70      0.67       434\n",
            "weighted avg       0.76      0.72      0.73       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[242  79]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (241, 10)\n",
            "Validation set: (1061, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 217\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 72.580645 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.76      0.80       321\n",
            "           1       0.48      0.64      0.55       113\n",
            "\n",
            "    accuracy                           0.73       434\n",
            "   macro avg       0.67      0.70      0.68       434\n",
            "weighted avg       0.76      0.73      0.74       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[243  78]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (242, 10)\n",
            "Validation set: (1060, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 218\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 72.350230 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.75      0.80       321\n",
            "           1       0.48      0.64      0.55       113\n",
            "\n",
            "    accuracy                           0.72       434\n",
            "   macro avg       0.67      0.70      0.67       434\n",
            "weighted avg       0.76      0.72      0.73       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[242  79]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (243, 10)\n",
            "Validation set: (1059, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 219\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 72.350230 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.75      0.80       321\n",
            "           1       0.48      0.64      0.55       113\n",
            "\n",
            "    accuracy                           0.72       434\n",
            "   macro avg       0.67      0.70      0.67       434\n",
            "weighted avg       0.76      0.72      0.73       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[242  79]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (244, 10)\n",
            "Validation set: (1058, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 220\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 72.811060 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.76      0.81       321\n",
            "           1       0.48      0.64      0.55       113\n",
            "\n",
            "    accuracy                           0.73       434\n",
            "   macro avg       0.67      0.70      0.68       434\n",
            "weighted avg       0.76      0.73      0.74       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[244  77]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (245, 10)\n",
            "Validation set: (1057, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 221\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 72.350230 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.75      0.80       321\n",
            "           1       0.48      0.64      0.55       113\n",
            "\n",
            "    accuracy                           0.72       434\n",
            "   macro avg       0.67      0.70      0.67       434\n",
            "weighted avg       0.76      0.72      0.73       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[242  79]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (246, 10)\n",
            "Validation set: (1056, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 222\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 72.811060 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.76      0.81       321\n",
            "           1       0.48      0.64      0.55       113\n",
            "\n",
            "    accuracy                           0.73       434\n",
            "   macro avg       0.67      0.70      0.68       434\n",
            "weighted avg       0.76      0.73      0.74       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[244  77]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (247, 10)\n",
            "Validation set: (1055, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 223\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 72.580645 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.76      0.80       321\n",
            "           1       0.48      0.64      0.55       113\n",
            "\n",
            "    accuracy                           0.73       434\n",
            "   macro avg       0.67      0.70      0.68       434\n",
            "weighted avg       0.76      0.73      0.74       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[243  78]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (248, 10)\n",
            "Validation set: (1054, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 224\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 72.811060 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.76      0.81       321\n",
            "           1       0.48      0.64      0.55       113\n",
            "\n",
            "    accuracy                           0.73       434\n",
            "   macro avg       0.67      0.70      0.68       434\n",
            "weighted avg       0.76      0.73      0.74       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[244  77]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (249, 10)\n",
            "Validation set: (1053, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 225\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 72.811060 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.76      0.81       321\n",
            "           1       0.48      0.64      0.55       113\n",
            "\n",
            "    accuracy                           0.73       434\n",
            "   macro avg       0.67      0.70      0.68       434\n",
            "weighted avg       0.76      0.73      0.74       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[244  77]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (250, 10)\n",
            "Validation set: (1052, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 226\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 72.350230 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.75      0.80       321\n",
            "           1       0.48      0.64      0.55       113\n",
            "\n",
            "    accuracy                           0.72       434\n",
            "   macro avg       0.67      0.70      0.67       434\n",
            "weighted avg       0.76      0.72      0.73       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[242  79]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (251, 10)\n",
            "Validation set: (1051, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 227\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 72.580645 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.76      0.80       321\n",
            "           1       0.48      0.64      0.55       113\n",
            "\n",
            "    accuracy                           0.73       434\n",
            "   macro avg       0.67      0.70      0.68       434\n",
            "weighted avg       0.76      0.73      0.74       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[243  78]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (252, 10)\n",
            "Validation set: (1050, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 228\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 72.350230 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.75      0.80       321\n",
            "           1       0.48      0.64      0.55       113\n",
            "\n",
            "    accuracy                           0.72       434\n",
            "   macro avg       0.67      0.70      0.67       434\n",
            "weighted avg       0.76      0.72      0.73       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[242  79]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (253, 10)\n",
            "Validation set: (1049, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 229\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 72.350230 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.75      0.80       321\n",
            "           1       0.48      0.64      0.55       113\n",
            "\n",
            "    accuracy                           0.72       434\n",
            "   macro avg       0.67      0.70      0.67       434\n",
            "weighted avg       0.76      0.72      0.73       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[242  79]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (254, 10)\n",
            "Validation set: (1048, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 230\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 72.811060 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.76      0.81       321\n",
            "           1       0.48      0.64      0.55       113\n",
            "\n",
            "    accuracy                           0.73       434\n",
            "   macro avg       0.67      0.70      0.68       434\n",
            "weighted avg       0.76      0.73      0.74       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[244  77]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (255, 10)\n",
            "Validation set: (1047, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 231\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 72.350230 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.75      0.80       321\n",
            "           1       0.48      0.64      0.55       113\n",
            "\n",
            "    accuracy                           0.72       434\n",
            "   macro avg       0.67      0.70      0.67       434\n",
            "weighted avg       0.76      0.72      0.73       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[242  79]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (256, 10)\n",
            "Validation set: (1046, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 232\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 72.350230 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.75      0.80       321\n",
            "           1       0.48      0.64      0.55       113\n",
            "\n",
            "    accuracy                           0.72       434\n",
            "   macro avg       0.67      0.70      0.67       434\n",
            "weighted avg       0.76      0.72      0.73       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[242  79]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (257, 10)\n",
            "Validation set: (1045, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 233\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 72.350230 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.75      0.80       321\n",
            "           1       0.48      0.64      0.55       113\n",
            "\n",
            "    accuracy                           0.72       434\n",
            "   macro avg       0.67      0.70      0.67       434\n",
            "weighted avg       0.76      0.72      0.73       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[242  79]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (258, 10)\n",
            "Validation set: (1044, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 234\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 72.350230 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.75      0.80       321\n",
            "           1       0.48      0.64      0.55       113\n",
            "\n",
            "    accuracy                           0.72       434\n",
            "   macro avg       0.67      0.70      0.67       434\n",
            "weighted avg       0.76      0.72      0.73       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[242  79]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (259, 10)\n",
            "Validation set: (1043, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 235\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 72.580645 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.76      0.80       321\n",
            "           1       0.48      0.64      0.55       113\n",
            "\n",
            "    accuracy                           0.73       434\n",
            "   macro avg       0.67      0.70      0.68       434\n",
            "weighted avg       0.76      0.73      0.74       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[243  78]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (260, 10)\n",
            "Validation set: (1042, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 236\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 72.580645 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.76      0.80       321\n",
            "           1       0.48      0.64      0.55       113\n",
            "\n",
            "    accuracy                           0.73       434\n",
            "   macro avg       0.67      0.70      0.68       434\n",
            "weighted avg       0.76      0.73      0.74       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[243  78]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (261, 10)\n",
            "Validation set: (1041, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 237\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 72.811060 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.76      0.81       321\n",
            "           1       0.48      0.64      0.55       113\n",
            "\n",
            "    accuracy                           0.73       434\n",
            "   macro avg       0.67      0.70      0.68       434\n",
            "weighted avg       0.76      0.73      0.74       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[244  77]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (262, 10)\n",
            "Validation set: (1040, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 238\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 72.580645 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.76      0.80       321\n",
            "           1       0.48      0.64      0.55       113\n",
            "\n",
            "    accuracy                           0.73       434\n",
            "   macro avg       0.67      0.70      0.68       434\n",
            "weighted avg       0.76      0.73      0.74       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[243  78]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (263, 10)\n",
            "Validation set: (1039, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 239\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 72.580645 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.76      0.80       321\n",
            "           1       0.48      0.64      0.55       113\n",
            "\n",
            "    accuracy                           0.73       434\n",
            "   macro avg       0.67      0.70      0.68       434\n",
            "weighted avg       0.76      0.73      0.74       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[243  78]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (264, 10)\n",
            "Validation set: (1038, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 240\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 72.580645 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.76      0.80       321\n",
            "           1       0.48      0.64      0.55       113\n",
            "\n",
            "    accuracy                           0.73       434\n",
            "   macro avg       0.67      0.70      0.68       434\n",
            "weighted avg       0.76      0.73      0.74       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[243  78]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (265, 10)\n",
            "Validation set: (1037, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 241\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 72.350230 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.75      0.80       321\n",
            "           1       0.48      0.64      0.55       113\n",
            "\n",
            "    accuracy                           0.72       434\n",
            "   macro avg       0.67      0.70      0.67       434\n",
            "weighted avg       0.76      0.72      0.73       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[242  79]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (266, 10)\n",
            "Validation set: (1036, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 242\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 72.119816 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.75      0.80       321\n",
            "           1       0.47      0.64      0.54       113\n",
            "\n",
            "    accuracy                           0.72       434\n",
            "   macro avg       0.66      0.69      0.67       434\n",
            "weighted avg       0.76      0.72      0.73       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[241  80]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (267, 10)\n",
            "Validation set: (1035, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 243\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 72.350230 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.75      0.80       321\n",
            "           1       0.48      0.64      0.55       113\n",
            "\n",
            "    accuracy                           0.72       434\n",
            "   macro avg       0.67      0.70      0.67       434\n",
            "weighted avg       0.76      0.72      0.73       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[242  79]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (268, 10)\n",
            "Validation set: (1034, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 244\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 72.119816 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.75      0.80       321\n",
            "           1       0.47      0.64      0.54       113\n",
            "\n",
            "    accuracy                           0.72       434\n",
            "   macro avg       0.66      0.69      0.67       434\n",
            "weighted avg       0.76      0.72      0.73       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[241  80]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (269, 10)\n",
            "Validation set: (1033, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 245\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 72.580645 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.76      0.80       321\n",
            "           1       0.48      0.64      0.55       113\n",
            "\n",
            "    accuracy                           0.73       434\n",
            "   macro avg       0.67      0.70      0.68       434\n",
            "weighted avg       0.76      0.73      0.74       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[243  78]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (270, 10)\n",
            "Validation set: (1032, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 246\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 72.811060 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.76      0.81       321\n",
            "           1       0.48      0.64      0.55       113\n",
            "\n",
            "    accuracy                           0.73       434\n",
            "   macro avg       0.67      0.70      0.68       434\n",
            "weighted avg       0.76      0.73      0.74       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[244  77]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (271, 10)\n",
            "Validation set: (1031, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 247\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 72.350230 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.75      0.80       321\n",
            "           1       0.48      0.64      0.55       113\n",
            "\n",
            "    accuracy                           0.72       434\n",
            "   macro avg       0.67      0.70      0.67       434\n",
            "weighted avg       0.76      0.72      0.73       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[242  79]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (272, 10)\n",
            "Validation set: (1030, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 248\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 72.580645 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.76      0.80       321\n",
            "           1       0.48      0.64      0.55       113\n",
            "\n",
            "    accuracy                           0.73       434\n",
            "   macro avg       0.67      0.70      0.68       434\n",
            "weighted avg       0.76      0.73      0.74       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[243  78]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (273, 10)\n",
            "Validation set: (1029, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 249\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 72.580645 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.76      0.80       321\n",
            "           1       0.48      0.64      0.55       113\n",
            "\n",
            "    accuracy                           0.73       434\n",
            "   macro avg       0.67      0.70      0.68       434\n",
            "weighted avg       0.76      0.73      0.74       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[243  78]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (274, 10)\n",
            "Validation set: (1028, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 250\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 72.580645 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.76      0.80       321\n",
            "           1       0.48      0.64      0.55       113\n",
            "\n",
            "    accuracy                           0.73       434\n",
            "   macro avg       0.67      0.70      0.68       434\n",
            "weighted avg       0.76      0.73      0.74       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[243  78]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (275, 10)\n",
            "Validation set: (1027, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 251\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 72.580645 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.76      0.80       321\n",
            "           1       0.48      0.64      0.55       113\n",
            "\n",
            "    accuracy                           0.73       434\n",
            "   macro avg       0.67      0.70      0.68       434\n",
            "weighted avg       0.76      0.73      0.74       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[243  78]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (276, 10)\n",
            "Validation set: (1026, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 252\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 72.350230 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.75      0.80       321\n",
            "           1       0.48      0.64      0.55       113\n",
            "\n",
            "    accuracy                           0.72       434\n",
            "   macro avg       0.67      0.70      0.67       434\n",
            "weighted avg       0.76      0.72      0.73       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[242  79]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (277, 10)\n",
            "Validation set: (1025, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 253\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.014 s \n",
            "\n",
            "Accuracy rate is 72.580645 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.76      0.80       321\n",
            "           1       0.48      0.64      0.55       113\n",
            "\n",
            "    accuracy                           0.73       434\n",
            "   macro avg       0.67      0.70      0.68       434\n",
            "weighted avg       0.76      0.73      0.74       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[243  78]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (278, 10)\n",
            "Validation set: (1024, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 254\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.009 s \n",
            "\n",
            "Accuracy rate is 72.119816 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.75      0.80       321\n",
            "           1       0.47      0.64      0.54       113\n",
            "\n",
            "    accuracy                           0.72       434\n",
            "   macro avg       0.66      0.69      0.67       434\n",
            "weighted avg       0.76      0.72      0.73       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[241  80]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (279, 10)\n",
            "Validation set: (1023, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 255\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 72.580645 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.76      0.80       321\n",
            "           1       0.48      0.64      0.55       113\n",
            "\n",
            "    accuracy                           0.73       434\n",
            "   macro avg       0.67      0.70      0.68       434\n",
            "weighted avg       0.76      0.73      0.74       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[243  78]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (280, 10)\n",
            "Validation set: (1022, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 256\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.004 s \n",
            "\n",
            "Accuracy rate is 72.580645 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.76      0.80       321\n",
            "           1       0.48      0.64      0.55       113\n",
            "\n",
            "    accuracy                           0.73       434\n",
            "   macro avg       0.67      0.70      0.68       434\n",
            "weighted avg       0.76      0.73      0.74       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[243  78]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (281, 10)\n",
            "Validation set: (1021, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 257\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 72.350230 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.75      0.80       321\n",
            "           1       0.48      0.64      0.55       113\n",
            "\n",
            "    accuracy                           0.72       434\n",
            "   macro avg       0.67      0.70      0.67       434\n",
            "weighted avg       0.76      0.72      0.73       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[242  79]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (282, 10)\n",
            "Validation set: (1020, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 258\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 72.350230 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.75      0.80       321\n",
            "           1       0.48      0.64      0.55       113\n",
            "\n",
            "    accuracy                           0.72       434\n",
            "   macro avg       0.67      0.70      0.67       434\n",
            "weighted avg       0.76      0.72      0.73       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[242  79]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (283, 10)\n",
            "Validation set: (1019, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 259\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 72.580645 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.76      0.80       321\n",
            "           1       0.48      0.64      0.55       113\n",
            "\n",
            "    accuracy                           0.73       434\n",
            "   macro avg       0.67      0.70      0.68       434\n",
            "weighted avg       0.76      0.73      0.74       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[243  78]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (284, 10)\n",
            "Validation set: (1018, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 260\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 72.350230 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.75      0.80       321\n",
            "           1       0.48      0.64      0.55       113\n",
            "\n",
            "    accuracy                           0.72       434\n",
            "   macro avg       0.67      0.70      0.67       434\n",
            "weighted avg       0.76      0.72      0.73       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[242  79]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (285, 10)\n",
            "Validation set: (1017, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 261\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 72.350230 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.75      0.80       321\n",
            "           1       0.48      0.64      0.55       113\n",
            "\n",
            "    accuracy                           0.72       434\n",
            "   macro avg       0.67      0.70      0.67       434\n",
            "weighted avg       0.76      0.72      0.73       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[242  79]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (286, 10)\n",
            "Validation set: (1016, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 262\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 72.119816 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.75      0.80       321\n",
            "           1       0.47      0.64      0.54       113\n",
            "\n",
            "    accuracy                           0.72       434\n",
            "   macro avg       0.66      0.69      0.67       434\n",
            "weighted avg       0.76      0.72      0.73       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[241  80]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (287, 10)\n",
            "Validation set: (1015, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 263\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 72.119816 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.75      0.80       321\n",
            "           1       0.47      0.63      0.54       113\n",
            "\n",
            "    accuracy                           0.72       434\n",
            "   macro avg       0.66      0.69      0.67       434\n",
            "weighted avg       0.75      0.72      0.73       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[242  79]\n",
            " [ 42  71]]\n",
            "--------------------------------\n",
            "Train set: (288, 10)\n",
            "Validation set: (1014, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 264\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 72.119816 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.75      0.80       321\n",
            "           1       0.47      0.63      0.54       113\n",
            "\n",
            "    accuracy                           0.72       434\n",
            "   macro avg       0.66      0.69      0.67       434\n",
            "weighted avg       0.75      0.72      0.73       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[242  79]\n",
            " [ 42  71]]\n",
            "--------------------------------\n",
            "Train set: (289, 10)\n",
            "Validation set: (1013, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 265\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 72.119816 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.75      0.80       321\n",
            "           1       0.47      0.63      0.54       113\n",
            "\n",
            "    accuracy                           0.72       434\n",
            "   macro avg       0.66      0.69      0.67       434\n",
            "weighted avg       0.75      0.72      0.73       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[242  79]\n",
            " [ 42  71]]\n",
            "--------------------------------\n",
            "Train set: (290, 10)\n",
            "Validation set: (1012, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 266\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 72.119816 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.75      0.80       321\n",
            "           1       0.47      0.63      0.54       113\n",
            "\n",
            "    accuracy                           0.72       434\n",
            "   macro avg       0.66      0.69      0.67       434\n",
            "weighted avg       0.75      0.72      0.73       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[242  79]\n",
            " [ 42  71]]\n",
            "--------------------------------\n",
            "Train set: (291, 10)\n",
            "Validation set: (1011, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 267\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 72.119816 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.75      0.80       321\n",
            "           1       0.47      0.64      0.54       113\n",
            "\n",
            "    accuracy                           0.72       434\n",
            "   macro avg       0.66      0.69      0.67       434\n",
            "weighted avg       0.76      0.72      0.73       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[241  80]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (292, 10)\n",
            "Validation set: (1010, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 268\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 72.350230 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.75      0.80       321\n",
            "           1       0.48      0.64      0.55       113\n",
            "\n",
            "    accuracy                           0.72       434\n",
            "   macro avg       0.67      0.70      0.67       434\n",
            "weighted avg       0.76      0.72      0.73       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[242  79]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (293, 10)\n",
            "Validation set: (1009, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 269\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 72.350230 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.75      0.80       321\n",
            "           1       0.48      0.64      0.55       113\n",
            "\n",
            "    accuracy                           0.72       434\n",
            "   macro avg       0.67      0.70      0.67       434\n",
            "weighted avg       0.76      0.72      0.73       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[242  79]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (294, 10)\n",
            "Validation set: (1008, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 270\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 72.580645 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.76      0.80       321\n",
            "           1       0.48      0.64      0.55       113\n",
            "\n",
            "    accuracy                           0.73       434\n",
            "   macro avg       0.67      0.70      0.68       434\n",
            "weighted avg       0.76      0.73      0.74       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[243  78]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (295, 10)\n",
            "Validation set: (1007, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 271\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 72.580645 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.76      0.80       321\n",
            "           1       0.48      0.64      0.55       113\n",
            "\n",
            "    accuracy                           0.73       434\n",
            "   macro avg       0.67      0.70      0.68       434\n",
            "weighted avg       0.76      0.73      0.74       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[243  78]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (296, 10)\n",
            "Validation set: (1006, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 272\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 72.580645 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.76      0.80       321\n",
            "           1       0.48      0.64      0.55       113\n",
            "\n",
            "    accuracy                           0.73       434\n",
            "   macro avg       0.67      0.70      0.68       434\n",
            "weighted avg       0.76      0.73      0.74       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[243  78]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (297, 10)\n",
            "Validation set: (1005, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 273\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 72.350230 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.75      0.80       321\n",
            "           1       0.48      0.64      0.55       113\n",
            "\n",
            "    accuracy                           0.72       434\n",
            "   macro avg       0.67      0.70      0.67       434\n",
            "weighted avg       0.76      0.72      0.73       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[242  79]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (298, 10)\n",
            "Validation set: (1004, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 274\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.004 s \n",
            "\n",
            "Accuracy rate is 72.811060 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.76      0.81       321\n",
            "           1       0.48      0.64      0.55       113\n",
            "\n",
            "    accuracy                           0.73       434\n",
            "   macro avg       0.67      0.70      0.68       434\n",
            "weighted avg       0.76      0.73      0.74       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[244  77]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (299, 10)\n",
            "Validation set: (1003, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 275\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 72.580645 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.76      0.80       321\n",
            "           1       0.48      0.64      0.55       113\n",
            "\n",
            "    accuracy                           0.73       434\n",
            "   macro avg       0.67      0.70      0.68       434\n",
            "weighted avg       0.76      0.73      0.74       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[243  78]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (300, 10)\n",
            "Validation set: (1002, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 276\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 72.811060 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.76      0.81       321\n",
            "           1       0.48      0.64      0.55       113\n",
            "\n",
            "    accuracy                           0.73       434\n",
            "   macro avg       0.67      0.70      0.68       434\n",
            "weighted avg       0.76      0.73      0.74       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[244  77]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (301, 10)\n",
            "Validation set: (1001, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 277\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 73.271889 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.77      0.81       321\n",
            "           1       0.49      0.64      0.55       113\n",
            "\n",
            "    accuracy                           0.73       434\n",
            "   macro avg       0.67      0.70      0.68       434\n",
            "weighted avg       0.76      0.73      0.74       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[246  75]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (302, 10)\n",
            "Validation set: (1000, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 278\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 73.271889 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.77      0.81       321\n",
            "           1       0.49      0.64      0.55       113\n",
            "\n",
            "    accuracy                           0.73       434\n",
            "   macro avg       0.67      0.70      0.68       434\n",
            "weighted avg       0.76      0.73      0.74       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[246  75]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (303, 10)\n",
            "Validation set: (999, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 279\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 73.271889 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.77      0.81       321\n",
            "           1       0.49      0.64      0.55       113\n",
            "\n",
            "    accuracy                           0.73       434\n",
            "   macro avg       0.67      0.70      0.68       434\n",
            "weighted avg       0.76      0.73      0.74       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[246  75]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (304, 10)\n",
            "Validation set: (998, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 280\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 73.271889 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.77      0.81       321\n",
            "           1       0.49      0.64      0.55       113\n",
            "\n",
            "    accuracy                           0.73       434\n",
            "   macro avg       0.67      0.70      0.68       434\n",
            "weighted avg       0.76      0.73      0.74       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[246  75]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (305, 10)\n",
            "Validation set: (997, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 281\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 73.041475 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.76      0.81       321\n",
            "           1       0.49      0.64      0.55       113\n",
            "\n",
            "    accuracy                           0.73       434\n",
            "   macro avg       0.67      0.70      0.68       434\n",
            "weighted avg       0.76      0.73      0.74       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[245  76]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (306, 10)\n",
            "Validation set: (996, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 282\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 72.811060 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.76      0.81       321\n",
            "           1       0.48      0.64      0.55       113\n",
            "\n",
            "    accuracy                           0.73       434\n",
            "   macro avg       0.67      0.70      0.68       434\n",
            "weighted avg       0.76      0.73      0.74       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[244  77]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (307, 10)\n",
            "Validation set: (995, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 283\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 73.041475 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.76      0.81       321\n",
            "           1       0.49      0.64      0.55       113\n",
            "\n",
            "    accuracy                           0.73       434\n",
            "   macro avg       0.67      0.70      0.68       434\n",
            "weighted avg       0.76      0.73      0.74       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[245  76]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (308, 10)\n",
            "Validation set: (994, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 284\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 73.271889 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.77      0.81       321\n",
            "           1       0.49      0.64      0.55       113\n",
            "\n",
            "    accuracy                           0.73       434\n",
            "   macro avg       0.67      0.70      0.68       434\n",
            "weighted avg       0.76      0.73      0.74       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[246  75]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (309, 10)\n",
            "Validation set: (993, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 285\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 73.041475 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.76      0.81       321\n",
            "           1       0.49      0.64      0.55       113\n",
            "\n",
            "    accuracy                           0.73       434\n",
            "   macro avg       0.67      0.70      0.68       434\n",
            "weighted avg       0.76      0.73      0.74       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[245  76]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (310, 10)\n",
            "Validation set: (992, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 286\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 73.271889 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.77      0.81       321\n",
            "           1       0.49      0.64      0.55       113\n",
            "\n",
            "    accuracy                           0.73       434\n",
            "   macro avg       0.67      0.70      0.68       434\n",
            "weighted avg       0.76      0.73      0.74       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[246  75]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (311, 10)\n",
            "Validation set: (991, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 287\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 72.811060 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.76      0.81       321\n",
            "           1       0.48      0.64      0.55       113\n",
            "\n",
            "    accuracy                           0.73       434\n",
            "   macro avg       0.67      0.70      0.68       434\n",
            "weighted avg       0.76      0.73      0.74       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[244  77]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (312, 10)\n",
            "Validation set: (990, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 288\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 73.041475 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.76      0.81       321\n",
            "           1       0.49      0.64      0.55       113\n",
            "\n",
            "    accuracy                           0.73       434\n",
            "   macro avg       0.67      0.70      0.68       434\n",
            "weighted avg       0.76      0.73      0.74       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[245  76]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (313, 10)\n",
            "Validation set: (989, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 289\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 72.811060 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.76      0.81       321\n",
            "           1       0.48      0.63      0.55       113\n",
            "\n",
            "    accuracy                           0.73       434\n",
            "   macro avg       0.67      0.70      0.68       434\n",
            "weighted avg       0.76      0.73      0.74       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[245  76]\n",
            " [ 42  71]]\n",
            "--------------------------------\n",
            "Train set: (314, 10)\n",
            "Validation set: (988, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 290\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 72.811060 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.76      0.81       321\n",
            "           1       0.48      0.64      0.55       113\n",
            "\n",
            "    accuracy                           0.73       434\n",
            "   macro avg       0.67      0.70      0.68       434\n",
            "weighted avg       0.76      0.73      0.74       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[244  77]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (315, 10)\n",
            "Validation set: (987, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 291\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 72.580645 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.76      0.80       321\n",
            "           1       0.48      0.63      0.54       113\n",
            "\n",
            "    accuracy                           0.73       434\n",
            "   macro avg       0.67      0.69      0.67       434\n",
            "weighted avg       0.76      0.73      0.74       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[244  77]\n",
            " [ 42  71]]\n",
            "--------------------------------\n",
            "Train set: (316, 10)\n",
            "Validation set: (986, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 292\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 73.041475 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.76      0.81       321\n",
            "           1       0.49      0.64      0.55       113\n",
            "\n",
            "    accuracy                           0.73       434\n",
            "   macro avg       0.67      0.70      0.68       434\n",
            "weighted avg       0.76      0.73      0.74       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[245  76]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (317, 10)\n",
            "Validation set: (985, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 293\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 73.041475 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.76      0.81       321\n",
            "           1       0.49      0.64      0.55       113\n",
            "\n",
            "    accuracy                           0.73       434\n",
            "   macro avg       0.67      0.70      0.68       434\n",
            "weighted avg       0.76      0.73      0.74       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[245  76]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (318, 10)\n",
            "Validation set: (984, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 294\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 72.580645 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.76      0.80       321\n",
            "           1       0.48      0.63      0.54       113\n",
            "\n",
            "    accuracy                           0.73       434\n",
            "   macro avg       0.67      0.69      0.67       434\n",
            "weighted avg       0.76      0.73      0.74       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[244  77]\n",
            " [ 42  71]]\n",
            "--------------------------------\n",
            "Train set: (319, 10)\n",
            "Validation set: (983, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 295\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 73.041475 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.76      0.81       321\n",
            "           1       0.49      0.64      0.55       113\n",
            "\n",
            "    accuracy                           0.73       434\n",
            "   macro avg       0.67      0.70      0.68       434\n",
            "weighted avg       0.76      0.73      0.74       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[245  76]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (320, 10)\n",
            "Validation set: (982, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 296\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 72.811060 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.76      0.81       321\n",
            "           1       0.48      0.63      0.55       113\n",
            "\n",
            "    accuracy                           0.73       434\n",
            "   macro avg       0.67      0.70      0.68       434\n",
            "weighted avg       0.76      0.73      0.74       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[245  76]\n",
            " [ 42  71]]\n",
            "--------------------------------\n",
            "Train set: (321, 10)\n",
            "Validation set: (981, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 297\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 72.811060 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.76      0.81       321\n",
            "           1       0.48      0.63      0.55       113\n",
            "\n",
            "    accuracy                           0.73       434\n",
            "   macro avg       0.67      0.70      0.68       434\n",
            "weighted avg       0.76      0.73      0.74       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[245  76]\n",
            " [ 42  71]]\n",
            "--------------------------------\n",
            "Train set: (322, 10)\n",
            "Validation set: (980, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 298\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 72.811060 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.76      0.81       321\n",
            "           1       0.48      0.63      0.55       113\n",
            "\n",
            "    accuracy                           0.73       434\n",
            "   macro avg       0.67      0.70      0.68       434\n",
            "weighted avg       0.76      0.73      0.74       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[245  76]\n",
            " [ 42  71]]\n",
            "--------------------------------\n",
            "Train set: (323, 10)\n",
            "Validation set: (979, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 299\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 72.580645 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.76      0.80       321\n",
            "           1       0.48      0.63      0.54       113\n",
            "\n",
            "    accuracy                           0.73       434\n",
            "   macro avg       0.67      0.69      0.67       434\n",
            "weighted avg       0.76      0.73      0.74       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[244  77]\n",
            " [ 42  71]]\n",
            "--------------------------------\n",
            "Train set: (324, 10)\n",
            "Validation set: (978, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 300\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 73.041475 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.77      0.81       321\n",
            "           1       0.49      0.63      0.55       113\n",
            "\n",
            "    accuracy                           0.73       434\n",
            "   macro avg       0.67      0.70      0.68       434\n",
            "weighted avg       0.76      0.73      0.74       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[246  75]\n",
            " [ 42  71]]\n",
            "--------------------------------\n",
            "Train set: (325, 10)\n",
            "Validation set: (977, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 301\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 73.271889 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.77      0.81       321\n",
            "           1       0.49      0.64      0.55       113\n",
            "\n",
            "    accuracy                           0.73       434\n",
            "   macro avg       0.67      0.70      0.68       434\n",
            "weighted avg       0.76      0.73      0.74       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[246  75]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (326, 10)\n",
            "Validation set: (976, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 302\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 73.041475 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.77      0.81       321\n",
            "           1       0.49      0.63      0.55       113\n",
            "\n",
            "    accuracy                           0.73       434\n",
            "   macro avg       0.67      0.70      0.68       434\n",
            "weighted avg       0.76      0.73      0.74       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[246  75]\n",
            " [ 42  71]]\n",
            "--------------------------------\n",
            "Train set: (327, 10)\n",
            "Validation set: (975, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 303\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 73.041475 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.77      0.81       321\n",
            "           1       0.49      0.63      0.55       113\n",
            "\n",
            "    accuracy                           0.73       434\n",
            "   macro avg       0.67      0.70      0.68       434\n",
            "weighted avg       0.76      0.73      0.74       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[246  75]\n",
            " [ 42  71]]\n",
            "--------------------------------\n",
            "Train set: (328, 10)\n",
            "Validation set: (974, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 304\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 72.811060 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.76      0.81       321\n",
            "           1       0.48      0.63      0.55       113\n",
            "\n",
            "    accuracy                           0.73       434\n",
            "   macro avg       0.67      0.70      0.68       434\n",
            "weighted avg       0.76      0.73      0.74       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[245  76]\n",
            " [ 42  71]]\n",
            "--------------------------------\n",
            "Train set: (329, 10)\n",
            "Validation set: (973, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 305\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 73.502304 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.77      0.81       321\n",
            "           1       0.49      0.64      0.56       113\n",
            "\n",
            "    accuracy                           0.74       434\n",
            "   macro avg       0.68      0.70      0.68       434\n",
            "weighted avg       0.76      0.74      0.74       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[247  74]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (330, 10)\n",
            "Validation set: (972, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 306\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 73.502304 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.77      0.81       321\n",
            "           1       0.49      0.64      0.56       113\n",
            "\n",
            "    accuracy                           0.74       434\n",
            "   macro avg       0.68      0.70      0.68       434\n",
            "weighted avg       0.76      0.74      0.74       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[247  74]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (331, 10)\n",
            "Validation set: (971, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 307\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 73.271889 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.77      0.81       321\n",
            "           1       0.49      0.64      0.55       113\n",
            "\n",
            "    accuracy                           0.73       434\n",
            "   macro avg       0.67      0.70      0.68       434\n",
            "weighted avg       0.76      0.73      0.74       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[246  75]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (332, 10)\n",
            "Validation set: (970, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 308\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 73.502304 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.77      0.81       321\n",
            "           1       0.49      0.64      0.56       113\n",
            "\n",
            "    accuracy                           0.74       434\n",
            "   macro avg       0.68      0.70      0.68       434\n",
            "weighted avg       0.76      0.74      0.74       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[247  74]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (333, 10)\n",
            "Validation set: (969, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 309\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 73.502304 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.77      0.81       321\n",
            "           1       0.49      0.64      0.56       113\n",
            "\n",
            "    accuracy                           0.74       434\n",
            "   macro avg       0.68      0.70      0.68       434\n",
            "weighted avg       0.76      0.74      0.74       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[247  74]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (334, 10)\n",
            "Validation set: (968, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 310\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 73.502304 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.77      0.81       321\n",
            "           1       0.49      0.64      0.56       113\n",
            "\n",
            "    accuracy                           0.74       434\n",
            "   macro avg       0.68      0.70      0.68       434\n",
            "weighted avg       0.76      0.74      0.74       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[247  74]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (335, 10)\n",
            "Validation set: (967, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 311\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 73.732719 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.77      0.81       321\n",
            "           1       0.50      0.64      0.56       113\n",
            "\n",
            "    accuracy                           0.74       434\n",
            "   macro avg       0.68      0.70      0.69       434\n",
            "weighted avg       0.76      0.74      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[248  73]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (336, 10)\n",
            "Validation set: (966, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 312\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 73.502304 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.77      0.81       321\n",
            "           1       0.49      0.64      0.56       113\n",
            "\n",
            "    accuracy                           0.74       434\n",
            "   macro avg       0.68      0.70      0.68       434\n",
            "weighted avg       0.76      0.74      0.74       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[247  74]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (337, 10)\n",
            "Validation set: (965, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 313\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 73.502304 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.77      0.81       321\n",
            "           1       0.49      0.64      0.56       113\n",
            "\n",
            "    accuracy                           0.74       434\n",
            "   macro avg       0.68      0.70      0.68       434\n",
            "weighted avg       0.76      0.74      0.74       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[247  74]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (338, 10)\n",
            "Validation set: (964, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 314\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 73.732719 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.77      0.81       321\n",
            "           1       0.50      0.64      0.56       113\n",
            "\n",
            "    accuracy                           0.74       434\n",
            "   macro avg       0.68      0.70      0.69       434\n",
            "weighted avg       0.76      0.74      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[248  73]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (339, 10)\n",
            "Validation set: (963, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 315\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 73.732719 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.77      0.81       321\n",
            "           1       0.50      0.64      0.56       113\n",
            "\n",
            "    accuracy                           0.74       434\n",
            "   macro avg       0.68      0.70      0.69       434\n",
            "weighted avg       0.76      0.74      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[248  73]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (340, 10)\n",
            "Validation set: (962, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 316\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 73.732719 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.77      0.81       321\n",
            "           1       0.50      0.64      0.56       113\n",
            "\n",
            "    accuracy                           0.74       434\n",
            "   macro avg       0.68      0.70      0.69       434\n",
            "weighted avg       0.76      0.74      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[248  73]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (341, 10)\n",
            "Validation set: (961, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 317\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 73.963134 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.78      0.82       321\n",
            "           1       0.50      0.64      0.56       113\n",
            "\n",
            "    accuracy                           0.74       434\n",
            "   macro avg       0.68      0.71      0.69       434\n",
            "weighted avg       0.77      0.74      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[249  72]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (342, 10)\n",
            "Validation set: (960, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 318\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 73.732719 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.77      0.81       321\n",
            "           1       0.50      0.64      0.56       113\n",
            "\n",
            "    accuracy                           0.74       434\n",
            "   macro avg       0.68      0.70      0.69       434\n",
            "weighted avg       0.76      0.74      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[248  73]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (343, 10)\n",
            "Validation set: (959, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 319\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 73.732719 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.77      0.81       321\n",
            "           1       0.50      0.64      0.56       113\n",
            "\n",
            "    accuracy                           0.74       434\n",
            "   macro avg       0.68      0.70      0.69       434\n",
            "weighted avg       0.76      0.74      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[248  73]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (344, 10)\n",
            "Validation set: (958, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 320\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 73.732719 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.77      0.81       321\n",
            "           1       0.50      0.64      0.56       113\n",
            "\n",
            "    accuracy                           0.74       434\n",
            "   macro avg       0.68      0.70      0.69       434\n",
            "weighted avg       0.76      0.74      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[248  73]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (345, 10)\n",
            "Validation set: (957, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 321\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 73.732719 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.77      0.81       321\n",
            "           1       0.50      0.64      0.56       113\n",
            "\n",
            "    accuracy                           0.74       434\n",
            "   macro avg       0.68      0.70      0.69       434\n",
            "weighted avg       0.76      0.74      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[248  73]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (346, 10)\n",
            "Validation set: (956, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 322\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 73.732719 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.77      0.81       321\n",
            "           1       0.50      0.64      0.56       113\n",
            "\n",
            "    accuracy                           0.74       434\n",
            "   macro avg       0.68      0.70      0.69       434\n",
            "weighted avg       0.76      0.74      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[248  73]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (347, 10)\n",
            "Validation set: (955, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 323\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 73.963134 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.78      0.82       321\n",
            "           1       0.50      0.64      0.56       113\n",
            "\n",
            "    accuracy                           0.74       434\n",
            "   macro avg       0.68      0.71      0.69       434\n",
            "weighted avg       0.77      0.74      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[249  72]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (348, 10)\n",
            "Validation set: (954, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 324\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 73.732719 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.77      0.81       321\n",
            "           1       0.50      0.64      0.56       113\n",
            "\n",
            "    accuracy                           0.74       434\n",
            "   macro avg       0.68      0.70      0.69       434\n",
            "weighted avg       0.76      0.74      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[248  73]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (349, 10)\n",
            "Validation set: (953, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 325\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 73.963134 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.78      0.82       321\n",
            "           1       0.50      0.64      0.56       113\n",
            "\n",
            "    accuracy                           0.74       434\n",
            "   macro avg       0.68      0.71      0.69       434\n",
            "weighted avg       0.77      0.74      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[249  72]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (350, 10)\n",
            "Validation set: (952, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 326\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 73.963134 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.78      0.82       321\n",
            "           1       0.50      0.64      0.56       113\n",
            "\n",
            "    accuracy                           0.74       434\n",
            "   macro avg       0.68      0.71      0.69       434\n",
            "weighted avg       0.77      0.74      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[249  72]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (351, 10)\n",
            "Validation set: (951, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 327\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.014 s \n",
            "\n",
            "Accuracy rate is 73.732719 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.77      0.81       321\n",
            "           1       0.50      0.64      0.56       113\n",
            "\n",
            "    accuracy                           0.74       434\n",
            "   macro avg       0.68      0.70      0.69       434\n",
            "weighted avg       0.76      0.74      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[248  73]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (352, 10)\n",
            "Validation set: (950, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 328\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 73.963134 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.78      0.82       321\n",
            "           1       0.50      0.64      0.56       113\n",
            "\n",
            "    accuracy                           0.74       434\n",
            "   macro avg       0.68      0.71      0.69       434\n",
            "weighted avg       0.77      0.74      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[249  72]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (353, 10)\n",
            "Validation set: (949, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 329\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 73.732719 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.77      0.81       321\n",
            "           1       0.50      0.64      0.56       113\n",
            "\n",
            "    accuracy                           0.74       434\n",
            "   macro avg       0.68      0.70      0.69       434\n",
            "weighted avg       0.76      0.74      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[248  73]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (354, 10)\n",
            "Validation set: (948, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 330\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 73.963134 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.78      0.82       321\n",
            "           1       0.50      0.64      0.56       113\n",
            "\n",
            "    accuracy                           0.74       434\n",
            "   macro avg       0.68      0.71      0.69       434\n",
            "weighted avg       0.77      0.74      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[249  72]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (355, 10)\n",
            "Validation set: (947, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 331\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 73.963134 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.78      0.82       321\n",
            "           1       0.50      0.64      0.56       113\n",
            "\n",
            "    accuracy                           0.74       434\n",
            "   macro avg       0.68      0.71      0.69       434\n",
            "weighted avg       0.77      0.74      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[249  72]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (356, 10)\n",
            "Validation set: (946, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 332\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 73.963134 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.78      0.82       321\n",
            "           1       0.50      0.64      0.56       113\n",
            "\n",
            "    accuracy                           0.74       434\n",
            "   macro avg       0.68      0.71      0.69       434\n",
            "weighted avg       0.77      0.74      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[249  72]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (357, 10)\n",
            "Validation set: (945, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 333\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 73.963134 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.78      0.82       321\n",
            "           1       0.50      0.64      0.56       113\n",
            "\n",
            "    accuracy                           0.74       434\n",
            "   macro avg       0.68      0.71      0.69       434\n",
            "weighted avg       0.77      0.74      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[249  72]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (358, 10)\n",
            "Validation set: (944, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 334\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 73.963134 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.78      0.82       321\n",
            "           1       0.50      0.64      0.56       113\n",
            "\n",
            "    accuracy                           0.74       434\n",
            "   macro avg       0.68      0.71      0.69       434\n",
            "weighted avg       0.77      0.74      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[249  72]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (359, 10)\n",
            "Validation set: (943, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 335\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 74.193548 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.78      0.82       321\n",
            "           1       0.50      0.64      0.56       113\n",
            "\n",
            "    accuracy                           0.74       434\n",
            "   macro avg       0.68      0.71      0.69       434\n",
            "weighted avg       0.77      0.74      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[250  71]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (360, 10)\n",
            "Validation set: (942, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 336\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 73.963134 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.78      0.82       321\n",
            "           1       0.50      0.64      0.56       113\n",
            "\n",
            "    accuracy                           0.74       434\n",
            "   macro avg       0.68      0.71      0.69       434\n",
            "weighted avg       0.77      0.74      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[249  72]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (361, 10)\n",
            "Validation set: (941, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 337\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 73.963134 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.78      0.82       321\n",
            "           1       0.50      0.64      0.56       113\n",
            "\n",
            "    accuracy                           0.74       434\n",
            "   macro avg       0.68      0.71      0.69       434\n",
            "weighted avg       0.77      0.74      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[249  72]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (362, 10)\n",
            "Validation set: (940, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 338\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 73.963134 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.78      0.82       321\n",
            "           1       0.50      0.64      0.56       113\n",
            "\n",
            "    accuracy                           0.74       434\n",
            "   macro avg       0.68      0.71      0.69       434\n",
            "weighted avg       0.77      0.74      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[249  72]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (363, 10)\n",
            "Validation set: (939, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 339\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 73.963134 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.78      0.82       321\n",
            "           1       0.50      0.64      0.56       113\n",
            "\n",
            "    accuracy                           0.74       434\n",
            "   macro avg       0.68      0.71      0.69       434\n",
            "weighted avg       0.77      0.74      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[249  72]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (364, 10)\n",
            "Validation set: (938, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 340\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 74.193548 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.78      0.82       321\n",
            "           1       0.50      0.64      0.56       113\n",
            "\n",
            "    accuracy                           0.74       434\n",
            "   macro avg       0.68      0.71      0.69       434\n",
            "weighted avg       0.77      0.74      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[250  71]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (365, 10)\n",
            "Validation set: (937, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 341\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 74.193548 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.78      0.82       321\n",
            "           1       0.50      0.64      0.56       113\n",
            "\n",
            "    accuracy                           0.74       434\n",
            "   macro avg       0.68      0.71      0.69       434\n",
            "weighted avg       0.77      0.74      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[250  71]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (366, 10)\n",
            "Validation set: (936, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 342\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 74.193548 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.78      0.82       321\n",
            "           1       0.50      0.64      0.56       113\n",
            "\n",
            "    accuracy                           0.74       434\n",
            "   macro avg       0.68      0.71      0.69       434\n",
            "weighted avg       0.77      0.74      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[250  71]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (367, 10)\n",
            "Validation set: (935, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 343\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 74.193548 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.78      0.82       321\n",
            "           1       0.50      0.64      0.56       113\n",
            "\n",
            "    accuracy                           0.74       434\n",
            "   macro avg       0.68      0.71      0.69       434\n",
            "weighted avg       0.77      0.74      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[250  71]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (368, 10)\n",
            "Validation set: (934, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 344\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 74.193548 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.78      0.82       321\n",
            "           1       0.50      0.64      0.56       113\n",
            "\n",
            "    accuracy                           0.74       434\n",
            "   macro avg       0.68      0.71      0.69       434\n",
            "weighted avg       0.77      0.74      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[250  71]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (369, 10)\n",
            "Validation set: (933, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 345\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 74.193548 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.78      0.82       321\n",
            "           1       0.50      0.64      0.56       113\n",
            "\n",
            "    accuracy                           0.74       434\n",
            "   macro avg       0.68      0.71      0.69       434\n",
            "weighted avg       0.77      0.74      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[250  71]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (370, 10)\n",
            "Validation set: (932, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 346\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 74.193548 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.78      0.82       321\n",
            "           1       0.50      0.64      0.56       113\n",
            "\n",
            "    accuracy                           0.74       434\n",
            "   macro avg       0.68      0.71      0.69       434\n",
            "weighted avg       0.77      0.74      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[250  71]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (371, 10)\n",
            "Validation set: (931, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 347\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.004 s \n",
            "\n",
            "Accuracy rate is 74.193548 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.78      0.82       321\n",
            "           1       0.50      0.64      0.56       113\n",
            "\n",
            "    accuracy                           0.74       434\n",
            "   macro avg       0.68      0.71      0.69       434\n",
            "weighted avg       0.77      0.74      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[250  71]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (372, 10)\n",
            "Validation set: (930, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 348\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 74.193548 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.78      0.82       321\n",
            "           1       0.50      0.64      0.56       113\n",
            "\n",
            "    accuracy                           0.74       434\n",
            "   macro avg       0.68      0.71      0.69       434\n",
            "weighted avg       0.77      0.74      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[250  71]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (373, 10)\n",
            "Validation set: (929, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 349\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.004 s \n",
            "\n",
            "Accuracy rate is 74.193548 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.78      0.82       321\n",
            "           1       0.50      0.64      0.56       113\n",
            "\n",
            "    accuracy                           0.74       434\n",
            "   macro avg       0.68      0.71      0.69       434\n",
            "weighted avg       0.77      0.74      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[250  71]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (374, 10)\n",
            "Validation set: (928, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 350\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 74.193548 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.78      0.82       321\n",
            "           1       0.50      0.64      0.56       113\n",
            "\n",
            "    accuracy                           0.74       434\n",
            "   macro avg       0.68      0.71      0.69       434\n",
            "weighted avg       0.77      0.74      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[250  71]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (375, 10)\n",
            "Validation set: (927, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 351\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 74.193548 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.78      0.82       321\n",
            "           1       0.50      0.64      0.56       113\n",
            "\n",
            "    accuracy                           0.74       434\n",
            "   macro avg       0.68      0.71      0.69       434\n",
            "weighted avg       0.77      0.74      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[250  71]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (376, 10)\n",
            "Validation set: (926, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 352\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 74.193548 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.78      0.82       321\n",
            "           1       0.50      0.64      0.56       113\n",
            "\n",
            "    accuracy                           0.74       434\n",
            "   macro avg       0.68      0.71      0.69       434\n",
            "weighted avg       0.77      0.74      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[250  71]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (377, 10)\n",
            "Validation set: (925, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 353\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 73.963134 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.78      0.82       321\n",
            "           1       0.50      0.64      0.56       113\n",
            "\n",
            "    accuracy                           0.74       434\n",
            "   macro avg       0.68      0.71      0.69       434\n",
            "weighted avg       0.77      0.74      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[249  72]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (378, 10)\n",
            "Validation set: (924, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 354\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 74.193548 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.78      0.82       321\n",
            "           1       0.50      0.64      0.56       113\n",
            "\n",
            "    accuracy                           0.74       434\n",
            "   macro avg       0.68      0.71      0.69       434\n",
            "weighted avg       0.77      0.74      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[250  71]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (379, 10)\n",
            "Validation set: (923, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 355\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 74.193548 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.78      0.82       321\n",
            "           1       0.50      0.64      0.56       113\n",
            "\n",
            "    accuracy                           0.74       434\n",
            "   macro avg       0.68      0.71      0.69       434\n",
            "weighted avg       0.77      0.74      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[250  71]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (380, 10)\n",
            "Validation set: (922, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 356\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 74.193548 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.78      0.82       321\n",
            "           1       0.50      0.64      0.56       113\n",
            "\n",
            "    accuracy                           0.74       434\n",
            "   macro avg       0.68      0.71      0.69       434\n",
            "weighted avg       0.77      0.74      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[250  71]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (381, 10)\n",
            "Validation set: (921, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 357\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 73.963134 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.78      0.82       321\n",
            "           1       0.50      0.64      0.56       113\n",
            "\n",
            "    accuracy                           0.74       434\n",
            "   macro avg       0.68      0.71      0.69       434\n",
            "weighted avg       0.77      0.74      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[249  72]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (382, 10)\n",
            "Validation set: (920, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 358\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 73.963134 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.78      0.82       321\n",
            "           1       0.50      0.64      0.56       113\n",
            "\n",
            "    accuracy                           0.74       434\n",
            "   macro avg       0.68      0.71      0.69       434\n",
            "weighted avg       0.77      0.74      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[249  72]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (383, 10)\n",
            "Validation set: (919, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 359\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 74.193548 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.78      0.82       321\n",
            "           1       0.50      0.64      0.56       113\n",
            "\n",
            "    accuracy                           0.74       434\n",
            "   macro avg       0.68      0.71      0.69       434\n",
            "weighted avg       0.77      0.74      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[250  71]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (384, 10)\n",
            "Validation set: (918, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 360\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 74.193548 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.78      0.82       321\n",
            "           1       0.50      0.64      0.56       113\n",
            "\n",
            "    accuracy                           0.74       434\n",
            "   macro avg       0.68      0.71      0.69       434\n",
            "weighted avg       0.77      0.74      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[250  71]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (385, 10)\n",
            "Validation set: (917, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 361\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 74.423963 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.78      0.82       321\n",
            "           1       0.51      0.64      0.56       113\n",
            "\n",
            "    accuracy                           0.74       434\n",
            "   macro avg       0.68      0.71      0.69       434\n",
            "weighted avg       0.77      0.74      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[251  70]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (386, 10)\n",
            "Validation set: (916, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 362\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 74.423963 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.78      0.82       321\n",
            "           1       0.51      0.64      0.56       113\n",
            "\n",
            "    accuracy                           0.74       434\n",
            "   macro avg       0.68      0.71      0.69       434\n",
            "weighted avg       0.77      0.74      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[251  70]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (387, 10)\n",
            "Validation set: (915, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 363\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 74.423963 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.78      0.82       321\n",
            "           1       0.51      0.64      0.56       113\n",
            "\n",
            "    accuracy                           0.74       434\n",
            "   macro avg       0.68      0.71      0.69       434\n",
            "weighted avg       0.77      0.74      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[251  70]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (388, 10)\n",
            "Validation set: (914, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 364\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 74.423963 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.78      0.82       321\n",
            "           1       0.51      0.64      0.56       113\n",
            "\n",
            "    accuracy                           0.74       434\n",
            "   macro avg       0.68      0.71      0.69       434\n",
            "weighted avg       0.77      0.74      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[251  70]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (389, 10)\n",
            "Validation set: (913, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 365\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.001 s \n",
            "\n",
            "Accuracy rate is 74.423963 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.78      0.82       321\n",
            "           1       0.51      0.64      0.56       113\n",
            "\n",
            "    accuracy                           0.74       434\n",
            "   macro avg       0.68      0.71      0.69       434\n",
            "weighted avg       0.77      0.74      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[251  70]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (390, 10)\n",
            "Validation set: (912, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 366\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 74.193548 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.78      0.82       321\n",
            "           1       0.50      0.64      0.56       113\n",
            "\n",
            "    accuracy                           0.74       434\n",
            "   macro avg       0.68      0.71      0.69       434\n",
            "weighted avg       0.77      0.74      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[250  71]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (391, 10)\n",
            "Validation set: (911, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 367\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 74.423963 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.78      0.82       321\n",
            "           1       0.51      0.64      0.56       113\n",
            "\n",
            "    accuracy                           0.74       434\n",
            "   macro avg       0.68      0.71      0.69       434\n",
            "weighted avg       0.77      0.74      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[251  70]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (392, 10)\n",
            "Validation set: (910, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 368\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 74.423963 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.78      0.82       321\n",
            "           1       0.51      0.64      0.56       113\n",
            "\n",
            "    accuracy                           0.74       434\n",
            "   macro avg       0.68      0.71      0.69       434\n",
            "weighted avg       0.77      0.74      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[251  70]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (393, 10)\n",
            "Validation set: (909, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 369\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.001 s \n",
            "\n",
            "Accuracy rate is 74.423963 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.78      0.82       321\n",
            "           1       0.51      0.64      0.56       113\n",
            "\n",
            "    accuracy                           0.74       434\n",
            "   macro avg       0.68      0.71      0.69       434\n",
            "weighted avg       0.77      0.74      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[251  70]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (394, 10)\n",
            "Validation set: (908, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 370\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 74.193548 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.78      0.82       321\n",
            "           1       0.50      0.64      0.56       113\n",
            "\n",
            "    accuracy                           0.74       434\n",
            "   macro avg       0.68      0.71      0.69       434\n",
            "weighted avg       0.77      0.74      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[250  71]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (395, 10)\n",
            "Validation set: (907, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 371\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 74.423963 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.78      0.82       321\n",
            "           1       0.51      0.64      0.56       113\n",
            "\n",
            "    accuracy                           0.74       434\n",
            "   macro avg       0.68      0.71      0.69       434\n",
            "weighted avg       0.77      0.74      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[251  70]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (396, 10)\n",
            "Validation set: (906, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 372\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 74.423963 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.78      0.82       321\n",
            "           1       0.51      0.64      0.56       113\n",
            "\n",
            "    accuracy                           0.74       434\n",
            "   macro avg       0.68      0.71      0.69       434\n",
            "weighted avg       0.77      0.74      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[251  70]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (397, 10)\n",
            "Validation set: (905, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 373\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 73.732719 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.77      0.81       321\n",
            "           1       0.50      0.64      0.56       113\n",
            "\n",
            "    accuracy                           0.74       434\n",
            "   macro avg       0.68      0.70      0.69       434\n",
            "weighted avg       0.76      0.74      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[248  73]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (398, 10)\n",
            "Validation set: (904, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 374\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 73.963134 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.78      0.82       321\n",
            "           1       0.50      0.64      0.56       113\n",
            "\n",
            "    accuracy                           0.74       434\n",
            "   macro avg       0.68      0.71      0.69       434\n",
            "weighted avg       0.77      0.74      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[249  72]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (399, 10)\n",
            "Validation set: (903, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 375\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.004 s \n",
            "\n",
            "Accuracy rate is 74.193548 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.78      0.82       321\n",
            "           1       0.50      0.64      0.56       113\n",
            "\n",
            "    accuracy                           0.74       434\n",
            "   macro avg       0.68      0.71      0.69       434\n",
            "weighted avg       0.77      0.74      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[250  71]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (400, 10)\n",
            "Validation set: (902, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 376\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 74.193548 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.78      0.82       321\n",
            "           1       0.50      0.64      0.56       113\n",
            "\n",
            "    accuracy                           0.74       434\n",
            "   macro avg       0.68      0.71      0.69       434\n",
            "weighted avg       0.77      0.74      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[250  71]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (401, 10)\n",
            "Validation set: (901, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 377\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 74.193548 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.78      0.82       321\n",
            "           1       0.50      0.64      0.56       113\n",
            "\n",
            "    accuracy                           0.74       434\n",
            "   macro avg       0.68      0.71      0.69       434\n",
            "weighted avg       0.77      0.74      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[250  71]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (402, 10)\n",
            "Validation set: (900, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 378\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 74.193548 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.78      0.82       321\n",
            "           1       0.50      0.64      0.56       113\n",
            "\n",
            "    accuracy                           0.74       434\n",
            "   macro avg       0.68      0.71      0.69       434\n",
            "weighted avg       0.77      0.74      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[250  71]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (403, 10)\n",
            "Validation set: (899, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 379\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 74.193548 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.78      0.82       321\n",
            "           1       0.50      0.64      0.56       113\n",
            "\n",
            "    accuracy                           0.74       434\n",
            "   macro avg       0.68      0.71      0.69       434\n",
            "weighted avg       0.77      0.74      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[250  71]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (404, 10)\n",
            "Validation set: (898, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 380\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.001 s \n",
            "\n",
            "Accuracy rate is 74.423963 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.78      0.82       321\n",
            "           1       0.51      0.64      0.56       113\n",
            "\n",
            "    accuracy                           0.74       434\n",
            "   macro avg       0.68      0.71      0.69       434\n",
            "weighted avg       0.77      0.74      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[251  70]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (405, 10)\n",
            "Validation set: (897, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 381\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 74.193548 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.78      0.82       321\n",
            "           1       0.50      0.64      0.56       113\n",
            "\n",
            "    accuracy                           0.74       434\n",
            "   macro avg       0.68      0.71      0.69       434\n",
            "weighted avg       0.77      0.74      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[250  71]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (406, 10)\n",
            "Validation set: (896, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 382\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 74.423963 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.78      0.82       321\n",
            "           1       0.51      0.64      0.56       113\n",
            "\n",
            "    accuracy                           0.74       434\n",
            "   macro avg       0.68      0.71      0.69       434\n",
            "weighted avg       0.77      0.74      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[251  70]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (407, 10)\n",
            "Validation set: (895, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 383\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 74.423963 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.78      0.82       321\n",
            "           1       0.51      0.64      0.56       113\n",
            "\n",
            "    accuracy                           0.74       434\n",
            "   macro avg       0.68      0.71      0.69       434\n",
            "weighted avg       0.77      0.74      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[251  70]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (408, 10)\n",
            "Validation set: (894, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 384\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.001 s \n",
            "\n",
            "Accuracy rate is 74.193548 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.78      0.82       321\n",
            "           1       0.50      0.64      0.56       113\n",
            "\n",
            "    accuracy                           0.74       434\n",
            "   macro avg       0.68      0.71      0.69       434\n",
            "weighted avg       0.77      0.74      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[250  71]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (409, 10)\n",
            "Validation set: (893, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 385\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 74.193548 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.78      0.82       321\n",
            "           1       0.50      0.64      0.56       113\n",
            "\n",
            "    accuracy                           0.74       434\n",
            "   macro avg       0.68      0.71      0.69       434\n",
            "weighted avg       0.77      0.74      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[250  71]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (410, 10)\n",
            "Validation set: (892, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 386\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 74.193548 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.78      0.82       321\n",
            "           1       0.50      0.64      0.56       113\n",
            "\n",
            "    accuracy                           0.74       434\n",
            "   macro avg       0.68      0.71      0.69       434\n",
            "weighted avg       0.77      0.74      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[250  71]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (411, 10)\n",
            "Validation set: (891, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 387\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 74.193548 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.78      0.82       321\n",
            "           1       0.50      0.64      0.56       113\n",
            "\n",
            "    accuracy                           0.74       434\n",
            "   macro avg       0.68      0.71      0.69       434\n",
            "weighted avg       0.77      0.74      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[250  71]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (412, 10)\n",
            "Validation set: (890, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 388\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.001 s \n",
            "\n",
            "Accuracy rate is 74.193548 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.78      0.82       321\n",
            "           1       0.50      0.64      0.56       113\n",
            "\n",
            "    accuracy                           0.74       434\n",
            "   macro avg       0.68      0.71      0.69       434\n",
            "weighted avg       0.77      0.74      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[250  71]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (413, 10)\n",
            "Validation set: (889, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 389\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 73.963134 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.78      0.82       321\n",
            "           1       0.50      0.64      0.56       113\n",
            "\n",
            "    accuracy                           0.74       434\n",
            "   macro avg       0.68      0.71      0.69       434\n",
            "weighted avg       0.77      0.74      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[249  72]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (414, 10)\n",
            "Validation set: (888, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 390\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 73.963134 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.78      0.82       321\n",
            "           1       0.50      0.64      0.56       113\n",
            "\n",
            "    accuracy                           0.74       434\n",
            "   macro avg       0.68      0.71      0.69       434\n",
            "weighted avg       0.77      0.74      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[249  72]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (415, 10)\n",
            "Validation set: (887, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 391\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 74.193548 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.78      0.82       321\n",
            "           1       0.50      0.64      0.56       113\n",
            "\n",
            "    accuracy                           0.74       434\n",
            "   macro avg       0.68      0.71      0.69       434\n",
            "weighted avg       0.77      0.74      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[250  71]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (416, 10)\n",
            "Validation set: (886, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 392\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 74.193548 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.78      0.82       321\n",
            "           1       0.50      0.64      0.56       113\n",
            "\n",
            "    accuracy                           0.74       434\n",
            "   macro avg       0.68      0.71      0.69       434\n",
            "weighted avg       0.77      0.74      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[250  71]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (417, 10)\n",
            "Validation set: (885, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 393\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.001 s \n",
            "\n",
            "Accuracy rate is 74.193548 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.78      0.82       321\n",
            "           1       0.50      0.64      0.56       113\n",
            "\n",
            "    accuracy                           0.74       434\n",
            "   macro avg       0.68      0.71      0.69       434\n",
            "weighted avg       0.77      0.74      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[250  71]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (418, 10)\n",
            "Validation set: (884, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 394\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 74.193548 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.78      0.82       321\n",
            "           1       0.50      0.64      0.56       113\n",
            "\n",
            "    accuracy                           0.74       434\n",
            "   macro avg       0.68      0.71      0.69       434\n",
            "weighted avg       0.77      0.74      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[250  71]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (419, 10)\n",
            "Validation set: (883, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 395\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.001 s \n",
            "\n",
            "Accuracy rate is 74.193548 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.78      0.82       321\n",
            "           1       0.50      0.64      0.56       113\n",
            "\n",
            "    accuracy                           0.74       434\n",
            "   macro avg       0.68      0.71      0.69       434\n",
            "weighted avg       0.77      0.74      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[250  71]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (420, 10)\n",
            "Validation set: (882, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 396\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.001 s \n",
            "\n",
            "Accuracy rate is 74.193548 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.78      0.82       321\n",
            "           1       0.50      0.64      0.56       113\n",
            "\n",
            "    accuracy                           0.74       434\n",
            "   macro avg       0.68      0.71      0.69       434\n",
            "weighted avg       0.77      0.74      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[250  71]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (421, 10)\n",
            "Validation set: (881, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 397\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 74.193548 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.78      0.82       321\n",
            "           1       0.50      0.64      0.56       113\n",
            "\n",
            "    accuracy                           0.74       434\n",
            "   macro avg       0.68      0.71      0.69       434\n",
            "weighted avg       0.77      0.74      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[250  71]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (422, 10)\n",
            "Validation set: (880, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 398\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 73.963134 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.78      0.82       321\n",
            "           1       0.50      0.64      0.56       113\n",
            "\n",
            "    accuracy                           0.74       434\n",
            "   macro avg       0.68      0.71      0.69       434\n",
            "weighted avg       0.77      0.74      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[249  72]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (423, 10)\n",
            "Validation set: (879, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 399\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 74.193548 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.78      0.82       321\n",
            "           1       0.50      0.64      0.56       113\n",
            "\n",
            "    accuracy                           0.74       434\n",
            "   macro avg       0.68      0.71      0.69       434\n",
            "weighted avg       0.77      0.74      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[250  71]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (424, 10)\n",
            "Validation set: (878, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 400\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 74.193548 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.78      0.82       321\n",
            "           1       0.50      0.64      0.56       113\n",
            "\n",
            "    accuracy                           0.74       434\n",
            "   macro avg       0.68      0.71      0.69       434\n",
            "weighted avg       0.77      0.74      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[250  71]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (425, 10)\n",
            "Validation set: (877, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 401\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 74.423963 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.78      0.82       321\n",
            "           1       0.51      0.64      0.56       113\n",
            "\n",
            "    accuracy                           0.74       434\n",
            "   macro avg       0.68      0.71      0.69       434\n",
            "weighted avg       0.77      0.74      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[251  70]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (426, 10)\n",
            "Validation set: (876, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 402\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 74.654378 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.79      0.82       321\n",
            "           1       0.51      0.64      0.57       113\n",
            "\n",
            "    accuracy                           0.75       434\n",
            "   macro avg       0.69      0.71      0.69       434\n",
            "weighted avg       0.77      0.75      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[252  69]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (427, 10)\n",
            "Validation set: (875, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 403\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.001 s \n",
            "\n",
            "Accuracy rate is 73.963134 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.78      0.82       321\n",
            "           1       0.50      0.64      0.56       113\n",
            "\n",
            "    accuracy                           0.74       434\n",
            "   macro avg       0.68      0.71      0.69       434\n",
            "weighted avg       0.77      0.74      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[249  72]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (428, 10)\n",
            "Validation set: (874, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 404\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 74.193548 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.78      0.82       321\n",
            "           1       0.50      0.64      0.56       113\n",
            "\n",
            "    accuracy                           0.74       434\n",
            "   macro avg       0.68      0.71      0.69       434\n",
            "weighted avg       0.77      0.74      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[250  71]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (429, 10)\n",
            "Validation set: (873, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 405\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 73.963134 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.78      0.82       321\n",
            "           1       0.50      0.64      0.56       113\n",
            "\n",
            "    accuracy                           0.74       434\n",
            "   macro avg       0.68      0.71      0.69       434\n",
            "weighted avg       0.77      0.74      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[249  72]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (430, 10)\n",
            "Validation set: (872, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 406\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 73.963134 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.78      0.82       321\n",
            "           1       0.50      0.64      0.56       113\n",
            "\n",
            "    accuracy                           0.74       434\n",
            "   macro avg       0.68      0.71      0.69       434\n",
            "weighted avg       0.77      0.74      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[249  72]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (431, 10)\n",
            "Validation set: (871, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 407\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 74.193548 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.78      0.82       321\n",
            "           1       0.50      0.64      0.56       113\n",
            "\n",
            "    accuracy                           0.74       434\n",
            "   macro avg       0.68      0.71      0.69       434\n",
            "weighted avg       0.77      0.74      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[250  71]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (432, 10)\n",
            "Validation set: (870, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 408\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 74.193548 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.78      0.82       321\n",
            "           1       0.50      0.64      0.56       113\n",
            "\n",
            "    accuracy                           0.74       434\n",
            "   macro avg       0.68      0.71      0.69       434\n",
            "weighted avg       0.77      0.74      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[250  71]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (433, 10)\n",
            "Validation set: (869, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 409\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 74.193548 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.78      0.82       321\n",
            "           1       0.50      0.64      0.56       113\n",
            "\n",
            "    accuracy                           0.74       434\n",
            "   macro avg       0.68      0.71      0.69       434\n",
            "weighted avg       0.77      0.74      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[250  71]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (434, 10)\n",
            "Validation set: (868, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 410\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 74.193548 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.78      0.82       321\n",
            "           1       0.50      0.64      0.56       113\n",
            "\n",
            "    accuracy                           0.74       434\n",
            "   macro avg       0.68      0.71      0.69       434\n",
            "weighted avg       0.77      0.74      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[250  71]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (435, 10)\n",
            "Validation set: (867, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 411\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 73.963134 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.78      0.82       321\n",
            "           1       0.50      0.64      0.56       113\n",
            "\n",
            "    accuracy                           0.74       434\n",
            "   macro avg       0.68      0.71      0.69       434\n",
            "weighted avg       0.77      0.74      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[249  72]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (436, 10)\n",
            "Validation set: (866, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 412\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.001 s \n",
            "\n",
            "Accuracy rate is 74.193548 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.78      0.82       321\n",
            "           1       0.50      0.64      0.56       113\n",
            "\n",
            "    accuracy                           0.74       434\n",
            "   macro avg       0.68      0.71      0.69       434\n",
            "weighted avg       0.77      0.74      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[250  71]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (437, 10)\n",
            "Validation set: (865, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 413\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 73.963134 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.78      0.82       321\n",
            "           1       0.50      0.64      0.56       113\n",
            "\n",
            "    accuracy                           0.74       434\n",
            "   macro avg       0.68      0.71      0.69       434\n",
            "weighted avg       0.77      0.74      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[249  72]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (438, 10)\n",
            "Validation set: (864, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 414\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 74.423963 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.78      0.82       321\n",
            "           1       0.51      0.64      0.56       113\n",
            "\n",
            "    accuracy                           0.74       434\n",
            "   macro avg       0.68      0.71      0.69       434\n",
            "weighted avg       0.77      0.74      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[251  70]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (439, 10)\n",
            "Validation set: (863, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 415\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 74.193548 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.78      0.82       321\n",
            "           1       0.50      0.64      0.56       113\n",
            "\n",
            "    accuracy                           0.74       434\n",
            "   macro avg       0.68      0.71      0.69       434\n",
            "weighted avg       0.77      0.74      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[250  71]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (440, 10)\n",
            "Validation set: (862, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 416\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 74.654378 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.79      0.82       321\n",
            "           1       0.51      0.64      0.57       113\n",
            "\n",
            "    accuracy                           0.75       434\n",
            "   macro avg       0.69      0.71      0.69       434\n",
            "weighted avg       0.77      0.75      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[252  69]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (441, 10)\n",
            "Validation set: (861, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 417\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 74.423963 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.78      0.82       321\n",
            "           1       0.51      0.64      0.56       113\n",
            "\n",
            "    accuracy                           0.74       434\n",
            "   macro avg       0.68      0.71      0.69       434\n",
            "weighted avg       0.77      0.74      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[251  70]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (442, 10)\n",
            "Validation set: (860, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 418\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 74.654378 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.79      0.82       321\n",
            "           1       0.51      0.64      0.57       113\n",
            "\n",
            "    accuracy                           0.75       434\n",
            "   macro avg       0.69      0.71      0.69       434\n",
            "weighted avg       0.77      0.75      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[252  69]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (443, 10)\n",
            "Validation set: (859, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 419\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 74.654378 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.79      0.82       321\n",
            "           1       0.51      0.64      0.57       113\n",
            "\n",
            "    accuracy                           0.75       434\n",
            "   macro avg       0.69      0.71      0.69       434\n",
            "weighted avg       0.77      0.75      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[252  69]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (444, 10)\n",
            "Validation set: (858, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 420\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 74.423963 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.78      0.82       321\n",
            "           1       0.51      0.64      0.56       113\n",
            "\n",
            "    accuracy                           0.74       434\n",
            "   macro avg       0.68      0.71      0.69       434\n",
            "weighted avg       0.77      0.74      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[251  70]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (445, 10)\n",
            "Validation set: (857, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 421\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.001 s \n",
            "\n",
            "Accuracy rate is 74.884793 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.79      0.82       321\n",
            "           1       0.51      0.64      0.57       113\n",
            "\n",
            "    accuracy                           0.75       434\n",
            "   macro avg       0.69      0.71      0.70       434\n",
            "weighted avg       0.77      0.75      0.76       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[253  68]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (446, 10)\n",
            "Validation set: (856, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 422\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 74.884793 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.79      0.82       321\n",
            "           1       0.51      0.64      0.57       113\n",
            "\n",
            "    accuracy                           0.75       434\n",
            "   macro avg       0.69      0.71      0.70       434\n",
            "weighted avg       0.77      0.75      0.76       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[253  68]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (447, 10)\n",
            "Validation set: (855, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 423\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 74.423963 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.78      0.82       321\n",
            "           1       0.51      0.64      0.56       113\n",
            "\n",
            "    accuracy                           0.74       434\n",
            "   macro avg       0.68      0.71      0.69       434\n",
            "weighted avg       0.77      0.74      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[251  70]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (448, 10)\n",
            "Validation set: (854, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 424\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.001 s \n",
            "\n",
            "Accuracy rate is 74.884793 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.79      0.82       321\n",
            "           1       0.51      0.64      0.57       113\n",
            "\n",
            "    accuracy                           0.75       434\n",
            "   macro avg       0.69      0.71      0.70       434\n",
            "weighted avg       0.77      0.75      0.76       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[253  68]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (449, 10)\n",
            "Validation set: (853, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 425\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 75.115207 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.79      0.82       321\n",
            "           1       0.52      0.64      0.57       113\n",
            "\n",
            "    accuracy                           0.75       434\n",
            "   macro avg       0.69      0.71      0.70       434\n",
            "weighted avg       0.77      0.75      0.76       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[254  67]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (450, 10)\n",
            "Validation set: (852, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 426\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 74.654378 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.79      0.82       321\n",
            "           1       0.51      0.64      0.57       113\n",
            "\n",
            "    accuracy                           0.75       434\n",
            "   macro avg       0.69      0.71      0.69       434\n",
            "weighted avg       0.77      0.75      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[252  69]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (451, 10)\n",
            "Validation set: (851, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 427\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.001 s \n",
            "\n",
            "Accuracy rate is 74.654378 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.79      0.82       321\n",
            "           1       0.51      0.64      0.57       113\n",
            "\n",
            "    accuracy                           0.75       434\n",
            "   macro avg       0.69      0.71      0.69       434\n",
            "weighted avg       0.77      0.75      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[252  69]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (452, 10)\n",
            "Validation set: (850, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 428\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 74.654378 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.79      0.82       321\n",
            "           1       0.51      0.64      0.57       113\n",
            "\n",
            "    accuracy                           0.75       434\n",
            "   macro avg       0.69      0.71      0.69       434\n",
            "weighted avg       0.77      0.75      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[252  69]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (453, 10)\n",
            "Validation set: (849, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 429\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 74.884793 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.79      0.82       321\n",
            "           1       0.51      0.64      0.57       113\n",
            "\n",
            "    accuracy                           0.75       434\n",
            "   macro avg       0.69      0.71      0.70       434\n",
            "weighted avg       0.77      0.75      0.76       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[253  68]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (454, 10)\n",
            "Validation set: (848, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 430\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.001 s \n",
            "\n",
            "Accuracy rate is 74.654378 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.79      0.82       321\n",
            "           1       0.51      0.64      0.57       113\n",
            "\n",
            "    accuracy                           0.75       434\n",
            "   macro avg       0.69      0.71      0.69       434\n",
            "weighted avg       0.77      0.75      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[252  69]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (455, 10)\n",
            "Validation set: (847, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 431\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 74.654378 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.79      0.82       321\n",
            "           1       0.51      0.64      0.57       113\n",
            "\n",
            "    accuracy                           0.75       434\n",
            "   macro avg       0.69      0.71      0.69       434\n",
            "weighted avg       0.77      0.75      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[252  69]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (456, 10)\n",
            "Validation set: (846, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 432\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.001 s \n",
            "\n",
            "Accuracy rate is 74.654378 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.79      0.82       321\n",
            "           1       0.51      0.64      0.57       113\n",
            "\n",
            "    accuracy                           0.75       434\n",
            "   macro avg       0.69      0.71      0.69       434\n",
            "weighted avg       0.77      0.75      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[252  69]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (457, 10)\n",
            "Validation set: (845, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 433\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.001 s \n",
            "\n",
            "Accuracy rate is 75.115207 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.79      0.82       321\n",
            "           1       0.52      0.64      0.57       113\n",
            "\n",
            "    accuracy                           0.75       434\n",
            "   macro avg       0.69      0.71      0.70       434\n",
            "weighted avg       0.77      0.75      0.76       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[254  67]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (458, 10)\n",
            "Validation set: (844, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 434\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 74.654378 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.79      0.82       321\n",
            "           1       0.51      0.64      0.57       113\n",
            "\n",
            "    accuracy                           0.75       434\n",
            "   macro avg       0.69      0.71      0.69       434\n",
            "weighted avg       0.77      0.75      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[252  69]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (459, 10)\n",
            "Validation set: (843, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 435\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 74.884793 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.79      0.82       321\n",
            "           1       0.51      0.64      0.57       113\n",
            "\n",
            "    accuracy                           0.75       434\n",
            "   macro avg       0.69      0.71      0.70       434\n",
            "weighted avg       0.77      0.75      0.76       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[253  68]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (460, 10)\n",
            "Validation set: (842, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 436\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.001 s \n",
            "\n",
            "Accuracy rate is 74.654378 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.79      0.82       321\n",
            "           1       0.51      0.64      0.57       113\n",
            "\n",
            "    accuracy                           0.75       434\n",
            "   macro avg       0.69      0.71      0.69       434\n",
            "weighted avg       0.77      0.75      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[252  69]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (461, 10)\n",
            "Validation set: (841, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 437\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 74.654378 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.79      0.82       321\n",
            "           1       0.51      0.64      0.57       113\n",
            "\n",
            "    accuracy                           0.75       434\n",
            "   macro avg       0.69      0.71      0.69       434\n",
            "weighted avg       0.77      0.75      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[252  69]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (462, 10)\n",
            "Validation set: (840, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 438\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 74.654378 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.79      0.82       321\n",
            "           1       0.51      0.64      0.57       113\n",
            "\n",
            "    accuracy                           0.75       434\n",
            "   macro avg       0.69      0.71      0.69       434\n",
            "weighted avg       0.77      0.75      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[252  69]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (463, 10)\n",
            "Validation set: (839, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 439\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 74.884793 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.79      0.82       321\n",
            "           1       0.51      0.64      0.57       113\n",
            "\n",
            "    accuracy                           0.75       434\n",
            "   macro avg       0.69      0.71      0.70       434\n",
            "weighted avg       0.77      0.75      0.76       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[253  68]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (464, 10)\n",
            "Validation set: (838, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 440\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 74.654378 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.79      0.82       321\n",
            "           1       0.51      0.64      0.57       113\n",
            "\n",
            "    accuracy                           0.75       434\n",
            "   macro avg       0.69      0.71      0.69       434\n",
            "weighted avg       0.77      0.75      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[252  69]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (465, 10)\n",
            "Validation set: (837, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 441\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.001 s \n",
            "\n",
            "Accuracy rate is 74.654378 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.79      0.82       321\n",
            "           1       0.51      0.64      0.57       113\n",
            "\n",
            "    accuracy                           0.75       434\n",
            "   macro avg       0.69      0.71      0.69       434\n",
            "weighted avg       0.77      0.75      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[252  69]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (466, 10)\n",
            "Validation set: (836, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 442\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.001 s \n",
            "\n",
            "Accuracy rate is 74.884793 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.79      0.82       321\n",
            "           1       0.51      0.64      0.57       113\n",
            "\n",
            "    accuracy                           0.75       434\n",
            "   macro avg       0.69      0.71      0.70       434\n",
            "weighted avg       0.77      0.75      0.76       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[253  68]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (467, 10)\n",
            "Validation set: (835, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 443\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 74.654378 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.79      0.82       321\n",
            "           1       0.51      0.64      0.57       113\n",
            "\n",
            "    accuracy                           0.75       434\n",
            "   macro avg       0.69      0.71      0.69       434\n",
            "weighted avg       0.77      0.75      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[252  69]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (468, 10)\n",
            "Validation set: (834, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 444\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 79.262673 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.86      0.86       321\n",
            "           1       0.60      0.59      0.60       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.73      0.73      0.73       434\n",
            "weighted avg       0.79      0.79      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[277  44]\n",
            " [ 46  67]]\n",
            "--------------------------------\n",
            "Train set: (469, 10)\n",
            "Validation set: (833, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 445\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 79.032258 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.86      0.86       321\n",
            "           1       0.60      0.59      0.60       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.73      0.73      0.73       434\n",
            "weighted avg       0.79      0.79      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[276  45]\n",
            " [ 46  67]]\n",
            "--------------------------------\n",
            "Train set: (470, 10)\n",
            "Validation set: (832, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 446\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 79.032258 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.86      0.86       321\n",
            "           1       0.60      0.59      0.60       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.73      0.73      0.73       434\n",
            "weighted avg       0.79      0.79      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[276  45]\n",
            " [ 46  67]]\n",
            "--------------------------------\n",
            "Train set: (471, 10)\n",
            "Validation set: (831, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 447\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.001 s \n",
            "\n",
            "Accuracy rate is 74.654378 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.79      0.82       321\n",
            "           1       0.51      0.64      0.57       113\n",
            "\n",
            "    accuracy                           0.75       434\n",
            "   macro avg       0.69      0.71      0.69       434\n",
            "weighted avg       0.77      0.75      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[252  69]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (472, 10)\n",
            "Validation set: (830, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 448\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 74.654378 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.79      0.82       321\n",
            "           1       0.51      0.64      0.57       113\n",
            "\n",
            "    accuracy                           0.75       434\n",
            "   macro avg       0.69      0.71      0.69       434\n",
            "weighted avg       0.77      0.75      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[252  69]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (473, 10)\n",
            "Validation set: (829, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 449\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 79.262673 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.86      0.86       321\n",
            "           1       0.60      0.59      0.60       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.73      0.73      0.73       434\n",
            "weighted avg       0.79      0.79      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[277  44]\n",
            " [ 46  67]]\n",
            "--------------------------------\n",
            "Train set: (474, 10)\n",
            "Validation set: (828, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 450\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 79.032258 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.86      0.86       321\n",
            "           1       0.60      0.59      0.60       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.73      0.73      0.73       434\n",
            "weighted avg       0.79      0.79      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[276  45]\n",
            " [ 46  67]]\n",
            "--------------------------------\n",
            "Train set: (475, 10)\n",
            "Validation set: (827, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 451\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 79.032258 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.86      0.86       321\n",
            "           1       0.60      0.59      0.60       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.73      0.73      0.73       434\n",
            "weighted avg       0.79      0.79      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[276  45]\n",
            " [ 46  67]]\n",
            "--------------------------------\n",
            "Train set: (476, 10)\n",
            "Validation set: (826, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 452\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 75.115207 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.79      0.82       321\n",
            "           1       0.52      0.64      0.57       113\n",
            "\n",
            "    accuracy                           0.75       434\n",
            "   macro avg       0.69      0.71      0.70       434\n",
            "weighted avg       0.77      0.75      0.76       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[254  67]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (477, 10)\n",
            "Validation set: (825, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 453\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 74.884793 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.79      0.82       321\n",
            "           1       0.51      0.64      0.57       113\n",
            "\n",
            "    accuracy                           0.75       434\n",
            "   macro avg       0.69      0.71      0.70       434\n",
            "weighted avg       0.77      0.75      0.76       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[253  68]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (478, 10)\n",
            "Validation set: (824, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 454\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 74.654378 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.79      0.82       321\n",
            "           1       0.51      0.64      0.57       113\n",
            "\n",
            "    accuracy                           0.75       434\n",
            "   macro avg       0.69      0.71      0.69       434\n",
            "weighted avg       0.77      0.75      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[252  69]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "Train set: (479, 10)\n",
            "Validation set: (823, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 455\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.004 s \n",
            "\n",
            "Accuracy rate is 79.262673 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.86      0.86       321\n",
            "           1       0.60      0.59      0.60       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.73      0.73      0.73       434\n",
            "weighted avg       0.79      0.79      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[277  44]\n",
            " [ 46  67]]\n",
            "--------------------------------\n",
            "Train set: (480, 10)\n",
            "Validation set: (822, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 456\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 79.493088 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.87      0.86       321\n",
            "           1       0.61      0.59      0.60       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.73      0.73      0.73       434\n",
            "weighted avg       0.79      0.79      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[278  43]\n",
            " [ 46  67]]\n",
            "--------------------------------\n",
            "Train set: (481, 10)\n",
            "Validation set: (821, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 457\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.001 s \n",
            "\n",
            "Accuracy rate is 79.493088 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.87      0.86       321\n",
            "           1       0.61      0.59      0.60       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.73      0.73      0.73       434\n",
            "weighted avg       0.79      0.79      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[278  43]\n",
            " [ 46  67]]\n",
            "--------------------------------\n",
            "Train set: (482, 10)\n",
            "Validation set: (820, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 458\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 79.262673 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.87      0.86       321\n",
            "           1       0.61      0.58      0.59       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.73      0.73      0.73       434\n",
            "weighted avg       0.79      0.79      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[278  43]\n",
            " [ 47  66]]\n",
            "--------------------------------\n",
            "Train set: (483, 10)\n",
            "Validation set: (819, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 459\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 79.262673 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.86      0.86       321\n",
            "           1       0.60      0.59      0.60       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.73      0.73      0.73       434\n",
            "weighted avg       0.79      0.79      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[277  44]\n",
            " [ 46  67]]\n",
            "--------------------------------\n",
            "Train set: (484, 10)\n",
            "Validation set: (818, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 460\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.001 s \n",
            "\n",
            "Accuracy rate is 79.493088 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.87      0.86       321\n",
            "           1       0.61      0.59      0.60       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.73      0.73      0.73       434\n",
            "weighted avg       0.79      0.79      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[278  43]\n",
            " [ 46  67]]\n",
            "--------------------------------\n",
            "Train set: (485, 10)\n",
            "Validation set: (817, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 461\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 79.493088 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.87      0.86       321\n",
            "           1       0.61      0.59      0.60       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.73      0.73      0.73       434\n",
            "weighted avg       0.79      0.79      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[278  43]\n",
            " [ 46  67]]\n",
            "--------------------------------\n",
            "Train set: (486, 10)\n",
            "Validation set: (816, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 462\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 79.493088 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.87      0.86       321\n",
            "           1       0.61      0.59      0.60       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.73      0.73      0.73       434\n",
            "weighted avg       0.79      0.79      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[278  43]\n",
            " [ 46  67]]\n",
            "--------------------------------\n",
            "Train set: (487, 10)\n",
            "Validation set: (815, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 463\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 79.262673 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.86      0.86       321\n",
            "           1       0.60      0.59      0.60       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.73      0.73      0.73       434\n",
            "weighted avg       0.79      0.79      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[277  44]\n",
            " [ 46  67]]\n",
            "--------------------------------\n",
            "Train set: (488, 10)\n",
            "Validation set: (814, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 464\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 79.493088 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.87      0.86       321\n",
            "           1       0.61      0.59      0.60       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.73      0.73      0.73       434\n",
            "weighted avg       0.79      0.79      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[278  43]\n",
            " [ 46  67]]\n",
            "--------------------------------\n",
            "Train set: (489, 10)\n",
            "Validation set: (813, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 465\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 79.493088 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.87      0.86       321\n",
            "           1       0.61      0.59      0.60       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.73      0.73      0.73       434\n",
            "weighted avg       0.79      0.79      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[278  43]\n",
            " [ 46  67]]\n",
            "--------------------------------\n",
            "Train set: (490, 10)\n",
            "Validation set: (812, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 466\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.004 s \n",
            "\n",
            "Accuracy rate is 79.493088 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.87      0.86       321\n",
            "           1       0.61      0.59      0.60       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.73      0.73      0.73       434\n",
            "weighted avg       0.79      0.79      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[278  43]\n",
            " [ 46  67]]\n",
            "--------------------------------\n",
            "Train set: (491, 10)\n",
            "Validation set: (811, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 467\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.003 s \n",
            "\n",
            "Accuracy rate is 79.723502 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.87      0.86       321\n",
            "           1       0.62      0.58      0.60       113\n",
            "\n",
            "    accuracy                           0.80       434\n",
            "   macro avg       0.74      0.73      0.73       434\n",
            "weighted avg       0.79      0.80      0.80       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[280  41]\n",
            " [ 47  66]]\n",
            "--------------------------------\n",
            "Train set: (492, 10)\n",
            "Validation set: (810, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 468\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.001 s \n",
            "\n",
            "Accuracy rate is 79.032258 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.86      0.86       321\n",
            "           1       0.60      0.58      0.59       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.73      0.72      0.73       434\n",
            "weighted avg       0.79      0.79      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[277  44]\n",
            " [ 47  66]]\n",
            "--------------------------------\n",
            "Train set: (493, 10)\n",
            "Validation set: (809, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 469\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.001 s \n",
            "\n",
            "Accuracy rate is 79.262673 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.87      0.86       321\n",
            "           1       0.61      0.58      0.59       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.73      0.73      0.73       434\n",
            "weighted avg       0.79      0.79      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[278  43]\n",
            " [ 47  66]]\n",
            "--------------------------------\n",
            "Train set: (494, 10)\n",
            "Validation set: (808, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 470\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 79.493088 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.87      0.86       321\n",
            "           1       0.61      0.58      0.60       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.73      0.73      0.73       434\n",
            "weighted avg       0.79      0.79      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[279  42]\n",
            " [ 47  66]]\n",
            "--------------------------------\n",
            "Train set: (495, 10)\n",
            "Validation set: (807, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 471\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.001 s \n",
            "\n",
            "Accuracy rate is 79.262673 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.86      0.86       321\n",
            "           1       0.60      0.59      0.60       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.73      0.73      0.73       434\n",
            "weighted avg       0.79      0.79      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[277  44]\n",
            " [ 46  67]]\n",
            "--------------------------------\n",
            "Train set: (496, 10)\n",
            "Validation set: (806, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 472\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 79.032258 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.86      0.86       321\n",
            "           1       0.60      0.58      0.59       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.73      0.72      0.73       434\n",
            "weighted avg       0.79      0.79      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[277  44]\n",
            " [ 47  66]]\n",
            "--------------------------------\n",
            "Train set: (497, 10)\n",
            "Validation set: (805, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 473\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 79.493088 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.87      0.86       321\n",
            "           1       0.61      0.58      0.60       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.73      0.73      0.73       434\n",
            "weighted avg       0.79      0.79      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[279  42]\n",
            " [ 47  66]]\n",
            "--------------------------------\n",
            "Train set: (498, 10)\n",
            "Validation set: (804, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 474\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.001 s \n",
            "\n",
            "Accuracy rate is 79.262673 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.87      0.86       321\n",
            "           1       0.61      0.58      0.59       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.73      0.73      0.73       434\n",
            "weighted avg       0.79      0.79      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[278  43]\n",
            " [ 47  66]]\n",
            "--------------------------------\n",
            "Train set: (499, 10)\n",
            "Validation set: (803, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 475\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.002 s \n",
            "\n",
            "Accuracy rate is 79.493088 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.87      0.86       321\n",
            "           1       0.61      0.58      0.60       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.73      0.73      0.73       434\n",
            "weighted avg       0.79      0.79      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[279  42]\n",
            " [ 47  66]]\n",
            "--------------------------------\n",
            "Train set: (500, 10)\n",
            "Validation set: (802, 10)\n",
            "Test set: (434, 10)\n",
            "training logistic regression...\n",
            "--------------------------------\n",
            "Iteration: 476\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.001 s \n",
            "\n",
            "Accuracy rate is 79.262673 \n",
            "Classification report for LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear',\n",
            "                   tol=0.1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.87      0.86       321\n",
            "           1       0.61      0.58      0.59       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.73      0.72      0.73       434\n",
            "weighted avg       0.79      0.79      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[279  42]\n",
            " [ 48  65]]\n",
            "--------------------------------\n",
            "accuracies [64.28571428571429, 66.3594470046083, 65.89861751152074, 64.51612903225806, 66.58986175115207, 66.3594470046083, 67.97235023041475, 64.97695852534562, 67.05069124423963, 67.74193548387096, 66.3594470046083, 66.58986175115207, 66.12903225806451, 65.43778801843318, 66.12903225806451, 62.67281105990783, 63.824884792626726, 64.51612903225806, 65.89861751152074, 66.12903225806451, 66.12903225806451, 67.05069124423963, 67.74193548387096, 66.12903225806451, 67.05069124423963, 65.43778801843318, 66.12903225806451, 66.58986175115207, 67.2811059907834, 68.4331797235023, 68.4331797235023, 68.4331797235023, 68.66359447004609, 67.51152073732719, 68.4331797235023, 67.74193548387096, 67.97235023041475, 68.4331797235023, 68.20276497695853, 67.74193548387096, 68.4331797235023, 68.4331797235023, 67.51152073732719, 67.51152073732719, 69.35483870967742, 68.89400921658986, 70.04608294930875, 70.73732718894009, 70.73732718894009, 70.96774193548387, 71.42857142857143, 69.81566820276498, 69.35483870967742, 69.12442396313364, 69.35483870967742, 69.5852534562212, 69.12442396313364, 69.81566820276498, 69.12442396313364, 69.35483870967742, 69.5852534562212, 69.5852534562212, 69.35483870967742, 69.12442396313364, 69.12442396313364, 69.81566820276498, 69.5852534562212, 69.5852534562212, 70.27649769585254, 70.04608294930875, 69.81566820276498, 70.04608294930875, 70.04608294930875, 69.35483870967742, 69.81566820276498, 70.04608294930875, 69.81566820276498, 69.81566820276498, 69.12442396313364, 69.81566820276498, 69.81566820276498, 69.5852534562212, 69.5852534562212, 69.81566820276498, 70.27649769585254, 70.04608294930875, 70.96774193548387, 70.73732718894009, 71.19815668202764, 70.50691244239631, 70.96774193548387, 70.96774193548387, 71.42857142857143, 71.42857142857143, 71.42857142857143, 70.96774193548387, 71.19815668202764, 71.19815668202764, 71.19815668202764, 70.96774193548387, 71.19815668202764, 70.73732718894009, 71.19815668202764, 70.73732718894009, 70.96774193548387, 71.19815668202764, 71.42857142857143, 71.6589861751152, 71.42857142857143, 71.19815668202764, 70.96774193548387, 71.19815668202764, 71.19815668202764, 71.19815668202764, 70.73732718894009, 71.88940092165899, 71.19815668202764, 71.19815668202764, 71.19815668202764, 70.96774193548387, 71.6589861751152, 71.6589861751152, 71.88940092165899, 71.6589861751152, 72.11981566820278, 71.88940092165899, 71.6589861751152, 70.73732718894009, 71.42857142857143, 71.19815668202764, 71.19815668202764, 70.96774193548387, 71.19815668202764, 71.19815668202764, 71.19815668202764, 71.19815668202764, 71.42857142857143, 71.42857142857143, 71.6589861751152, 71.6589861751152, 71.42857142857143, 71.6589861751152, 71.88940092165899, 71.6589861751152, 71.88940092165899, 72.11981566820278, 71.88940092165899, 71.6589861751152, 71.19815668202764, 71.6589861751152, 71.42857142857143, 71.88940092165899, 72.58064516129032, 72.11981566820278, 72.11981566820278, 72.11981566820278, 72.35023041474655, 72.35023041474655, 72.35023041474655, 72.11981566820278, 72.35023041474655, 71.88940092165899, 72.11981566820278, 71.88940092165899, 71.88940092165899, 72.11981566820278, 72.58064516129032, 72.35023041474655, 72.35023041474655, 72.58064516129032, 72.11981566820278, 72.11981566820278, 72.11981566820278, 72.35023041474655, 72.35023041474655, 72.58064516129032, 72.35023041474655, 72.11981566820278, 72.11981566820278, 72.35023041474655, 71.6589861751152, 71.88940092165899, 71.42857142857143, 71.19815668202764, 71.19815668202764, 72.35023041474655, 72.11981566820278, 72.35023041474655, 72.11981566820278, 72.11981566820278, 71.88940092165899, 71.88940092165899, 72.35023041474655, 72.11981566820278, 72.11981566820278, 72.35023041474655, 71.88940092165899, 71.88940092165899, 72.11981566820278, 71.88940092165899, 72.11981566820278, 72.11981566820278, 72.35023041474655, 72.11981566820278, 72.11981566820278, 72.11981566820278, 72.11981566820278, 72.11981566820278, 72.58064516129032, 72.81105990783409, 72.58064516129032, 72.81105990783409, 72.35023041474655, 72.35023041474655, 72.35023041474655, 72.35023041474655, 72.58064516129032, 72.35023041474655, 72.35023041474655, 72.81105990783409, 72.35023041474655, 72.81105990783409, 72.58064516129032, 72.81105990783409, 72.81105990783409, 72.35023041474655, 72.58064516129032, 72.35023041474655, 72.35023041474655, 72.81105990783409, 72.35023041474655, 72.35023041474655, 72.35023041474655, 72.35023041474655, 72.58064516129032, 72.58064516129032, 72.81105990783409, 72.58064516129032, 72.58064516129032, 72.58064516129032, 72.35023041474655, 72.11981566820278, 72.35023041474655, 72.11981566820278, 72.58064516129032, 72.81105990783409, 72.35023041474655, 72.58064516129032, 72.58064516129032, 72.58064516129032, 72.58064516129032, 72.35023041474655, 72.58064516129032, 72.11981566820278, 72.58064516129032, 72.58064516129032, 72.35023041474655, 72.35023041474655, 72.58064516129032, 72.35023041474655, 72.35023041474655, 72.11981566820278, 72.11981566820278, 72.11981566820278, 72.11981566820278, 72.11981566820278, 72.11981566820278, 72.35023041474655, 72.35023041474655, 72.58064516129032, 72.58064516129032, 72.58064516129032, 72.35023041474655, 72.81105990783409, 72.58064516129032, 72.81105990783409, 73.27188940092167, 73.27188940092167, 73.27188940092167, 73.27188940092167, 73.04147465437788, 72.81105990783409, 73.04147465437788, 73.27188940092167, 73.04147465437788, 73.27188940092167, 72.81105990783409, 73.04147465437788, 72.81105990783409, 72.81105990783409, 72.58064516129032, 73.04147465437788, 73.04147465437788, 72.58064516129032, 73.04147465437788, 72.81105990783409, 72.81105990783409, 72.81105990783409, 72.58064516129032, 73.04147465437788, 73.27188940092167, 73.04147465437788, 73.04147465437788, 72.81105990783409, 73.50230414746544, 73.50230414746544, 73.27188940092167, 73.50230414746544, 73.50230414746544, 73.50230414746544, 73.73271889400922, 73.50230414746544, 73.50230414746544, 73.73271889400922, 73.73271889400922, 73.73271889400922, 73.963133640553, 73.73271889400922, 73.73271889400922, 73.73271889400922, 73.73271889400922, 73.73271889400922, 73.963133640553, 73.73271889400922, 73.963133640553, 73.963133640553, 73.73271889400922, 73.963133640553, 73.73271889400922, 73.963133640553, 73.963133640553, 73.963133640553, 73.963133640553, 73.963133640553, 74.19354838709677, 73.963133640553, 73.963133640553, 73.963133640553, 73.963133640553, 74.19354838709677, 74.19354838709677, 74.19354838709677, 74.19354838709677, 74.19354838709677, 74.19354838709677, 74.19354838709677, 74.19354838709677, 74.19354838709677, 74.19354838709677, 74.19354838709677, 74.19354838709677, 74.19354838709677, 73.963133640553, 74.19354838709677, 74.19354838709677, 74.19354838709677, 73.963133640553, 73.963133640553, 74.19354838709677, 74.19354838709677, 74.42396313364056, 74.42396313364056, 74.42396313364056, 74.42396313364056, 74.42396313364056, 74.19354838709677, 74.42396313364056, 74.42396313364056, 74.42396313364056, 74.19354838709677, 74.42396313364056, 74.42396313364056, 73.73271889400922, 73.963133640553, 74.19354838709677, 74.19354838709677, 74.19354838709677, 74.19354838709677, 74.19354838709677, 74.42396313364056, 74.19354838709677, 74.42396313364056, 74.42396313364056, 74.19354838709677, 74.19354838709677, 74.19354838709677, 74.19354838709677, 74.19354838709677, 73.963133640553, 73.963133640553, 74.19354838709677, 74.19354838709677, 74.19354838709677, 74.19354838709677, 74.19354838709677, 74.19354838709677, 74.19354838709677, 73.963133640553, 74.19354838709677, 74.19354838709677, 74.42396313364056, 74.65437788018433, 73.963133640553, 74.19354838709677, 73.963133640553, 73.963133640553, 74.19354838709677, 74.19354838709677, 74.19354838709677, 74.19354838709677, 73.963133640553, 74.19354838709677, 73.963133640553, 74.42396313364056, 74.19354838709677, 74.65437788018433, 74.42396313364056, 74.65437788018433, 74.65437788018433, 74.42396313364056, 74.88479262672811, 74.88479262672811, 74.42396313364056, 74.88479262672811, 75.11520737327189, 74.65437788018433, 74.65437788018433, 74.65437788018433, 74.88479262672811, 74.65437788018433, 74.65437788018433, 74.65437788018433, 75.11520737327189, 74.65437788018433, 74.88479262672811, 74.65437788018433, 74.65437788018433, 74.65437788018433, 74.88479262672811, 74.65437788018433, 74.65437788018433, 74.88479262672811, 74.65437788018433, 79.26267281105991, 79.03225806451613, 79.03225806451613, 74.65437788018433, 74.65437788018433, 79.26267281105991, 79.03225806451613, 79.03225806451613, 75.11520737327189, 74.88479262672811, 74.65437788018433, 79.26267281105991, 79.49308755760369, 79.49308755760369, 79.26267281105991, 79.26267281105991, 79.49308755760369, 79.49308755760369, 79.49308755760369, 79.26267281105991, 79.49308755760369, 79.49308755760369, 79.49308755760369, 79.72350230414746, 79.03225806451613, 79.26267281105991, 79.49308755760369, 79.26267281105991, 79.03225806451613, 79.49308755760369, 79.26267281105991, 79.49308755760369, 79.26267281105991]\n",
            "random_accuracies [65.66820276497695, 64.51612903225806, 64.97695852534562, 65.89861751152074, 65.2073732718894, 65.89861751152074, 65.89861751152074, 65.43778801843318, 65.43778801843318, 66.3594470046083, 65.66820276497695, 65.2073732718894, 65.89861751152074, 65.2073732718894, 65.66820276497695, 65.66820276497695, 65.89861751152074, 65.66820276497695, 65.2073732718894, 66.12903225806451, 65.2073732718894, 65.2073732718894, 65.89861751152074, 65.66820276497695, 65.43778801843318, 65.2073732718894, 65.66820276497695, 65.66820276497695, 65.66820276497695, 65.66820276497695, 65.2073732718894, 65.43778801843318, 66.3594470046083, 65.43778801843318, 65.2073732718894, 65.2073732718894, 65.66820276497695, 65.2073732718894, 65.66820276497695, 65.43778801843318, 66.58986175115207, 65.66820276497695, 64.0552995391705, 65.43778801843318, 65.66820276497695, 65.89861751152074, 65.2073732718894, 65.43778801843318, 65.89861751152074, 65.43778801843318, 65.2073732718894, 64.74654377880185, 65.43778801843318, 65.2073732718894, 65.2073732718894, 65.89861751152074, 66.12903225806451, 65.43778801843318, 65.66820276497695, 65.66820276497695, 65.43778801843318, 65.2073732718894, 64.0552995391705, 65.2073732718894, 64.74654377880185, 65.43778801843318, 66.12903225806451, 65.2073732718894, 64.97695852534562, 65.66820276497695, 65.43778801843318, 65.89861751152074, 65.66820276497695, 65.43778801843318, 65.2073732718894, 65.89861751152074, 65.43778801843318, 66.12903225806451, 65.89861751152074, 65.43778801843318, 65.89861751152074, 66.12903225806451, 65.89861751152074, 65.66820276497695, 62.903225806451616, 63.133640552995395, 65.89861751152074, 65.66820276497695, 65.66820276497695, 65.66820276497695, 64.51612903225806, 65.2073732718894, 65.2073732718894, 65.43778801843318, 65.66820276497695, 64.74654377880185, 64.51612903225806, 65.43778801843318, 65.66820276497695, 65.43778801843318, 66.12903225806451, 65.43778801843318, 66.12903225806451, 65.66820276497695, 65.89861751152074, 65.43778801843318, 65.66820276497695, 65.2073732718894, 66.12903225806451, 65.43778801843318, 65.89861751152074, 65.43778801843318, 65.2073732718894, 65.2073732718894, 65.66820276497695, 65.66820276497695, 66.58986175115207, 63.594470046082954, 65.43778801843318, 64.51612903225806, 65.2073732718894, 65.2073732718894, 65.66820276497695, 65.89861751152074, 65.89861751152074, 65.2073732718894, 66.12903225806451, 66.3594470046083, 65.66820276497695, 64.74654377880185, 64.74654377880185, 65.66820276497695, 65.89861751152074, 65.2073732718894, 65.2073732718894, 65.66820276497695, 65.43778801843318, 66.58986175115207, 66.12903225806451, 64.74654377880185, 65.2073732718894, 65.66820276497695, 65.66820276497695, 65.43778801843318, 65.43778801843318, 66.12903225806451, 65.89861751152074, 65.43778801843318, 65.2073732718894, 66.12903225806451, 65.2073732718894, 64.97695852534562, 65.43778801843318, 65.43778801843318, 65.66820276497695, 65.89861751152074, 65.43778801843318, 65.43778801843318, 65.2073732718894, 65.66820276497695, 65.43778801843318, 65.43778801843318, 64.74654377880185, 65.66820276497695, 65.43778801843318, 65.43778801843318, 65.2073732718894, 65.43778801843318, 65.43778801843318, 65.43778801843318, 65.43778801843318, 65.43778801843318, 65.89861751152074, 66.12903225806451, 66.12903225806451, 65.66820276497695, 64.97695852534562, 65.66820276497695, 65.43778801843318, 65.66820276497695, 64.97695852534562, 65.2073732718894, 65.66820276497695, 65.66820276497695, 65.2073732718894, 65.43778801843318, 65.2073732718894, 65.89861751152074, 65.89861751152074, 66.3594470046083, 65.89861751152074, 65.2073732718894, 63.133640552995395, 65.89861751152074, 65.2073732718894, 65.43778801843318, 65.89861751152074, 65.89861751152074, 65.43778801843318, 64.74654377880185, 64.74654377880185, 65.43778801843318, 64.97695852534562, 65.2073732718894, 65.66820276497695, 64.51612903225806, 65.2073732718894, 65.43778801843318, 65.89861751152074, 65.66820276497695, 65.2073732718894, 66.12903225806451, 65.2073732718894, 64.97695852534562, 65.66820276497695, 63.36405529953917, 65.66820276497695, 65.66820276497695, 65.2073732718894, 66.58986175115207, 65.43778801843318, 65.43778801843318, 65.2073732718894, 65.89861751152074, 65.43778801843318, 64.28571428571429, 66.3594470046083, 65.43778801843318, 65.43778801843318, 65.2073732718894, 63.594470046082954, 65.89861751152074, 65.66820276497695, 65.66820276497695, 66.12903225806451, 64.74654377880185, 65.43778801843318, 65.66820276497695, 65.2073732718894, 66.12903225806451, 65.43778801843318, 65.43778801843318, 65.43778801843318, 66.12903225806451, 65.66820276497695, 65.43778801843318, 64.97695852534562, 66.12903225806451, 65.66820276497695, 65.89861751152074, 64.97695852534562, 63.36405529953917, 64.51612903225806, 65.2073732718894, 65.43778801843318, 65.66820276497695, 65.89861751152074, 65.66820276497695, 65.66820276497695, 65.43778801843318, 64.0552995391705, 64.0552995391705, 66.3594470046083, 64.97695852534562, 65.66820276497695, 65.43778801843318, 65.2073732718894, 65.43778801843318, 65.66820276497695, 65.43778801843318, 65.2073732718894, 65.2073732718894, 65.2073732718894, 65.2073732718894, 66.3594470046083, 65.89861751152074, 65.89861751152074, 66.3594470046083, 64.97695852534562, 64.74654377880185, 65.2073732718894, 65.66820276497695, 64.74654377880185, 65.43778801843318, 65.43778801843318, 65.2073732718894, 64.0552995391705, 65.66820276497695, 64.97695852534562, 65.66820276497695, 65.66820276497695, 65.89861751152074, 65.43778801843318, 66.3594470046083, 65.66820276497695, 65.43778801843318, 65.66820276497695, 65.2073732718894, 65.43778801843318, 65.66820276497695, 65.43778801843318, 65.66820276497695, 65.43778801843318, 65.89861751152074, 65.66820276497695, 64.97695852534562, 65.66820276497695, 65.89861751152074, 64.74654377880185, 65.89861751152074, 65.66820276497695, 64.74654377880185, 66.58986175115207, 65.66820276497695, 65.43778801843318, 65.43778801843318, 65.2073732718894, 65.2073732718894, 65.66820276497695, 65.2073732718894, 65.2073732718894, 65.89861751152074, 65.43778801843318, 65.66820276497695, 65.66820276497695, 65.89861751152074, 65.2073732718894, 65.2073732718894, 64.74654377880185, 66.12903225806451, 65.43778801843318, 64.74654377880185, 65.43778801843318, 64.97695852534562, 65.89861751152074, 65.43778801843318, 64.28571428571429, 65.66820276497695, 65.66820276497695, 66.12903225806451, 65.43778801843318, 65.2073732718894, 65.66820276497695, 65.66820276497695, 64.97695852534562, 65.43778801843318, 64.97695852534562, 66.3594470046083, 66.12903225806451, 64.51612903225806, 65.66820276497695, 66.12903225806451, 65.43778801843318, 65.2073732718894, 65.66820276497695, 65.43778801843318, 64.74654377880185, 65.89861751152074, 66.3594470046083, 64.74654377880185, 66.12903225806451, 65.43778801843318, 65.43778801843318, 66.12903225806451, 66.12903225806451, 65.2073732718894, 65.66820276497695, 65.66820276497695, 66.12903225806451, 65.2073732718894, 64.97695852534562, 65.89861751152074, 65.66820276497695, 65.66820276497695, 65.2073732718894, 65.2073732718894, 65.43778801843318, 65.43778801843318, 65.2073732718894, 66.82027649769586, 65.2073732718894, 65.2073732718894, 64.97695852534562, 65.2073732718894, 65.89861751152074, 65.43778801843318, 64.97695852534562, 65.89861751152074, 65.43778801843318, 65.43778801843318, 65.43778801843318, 65.66820276497695, 65.89861751152074, 65.2073732718894, 66.12903225806451, 64.97695852534562, 65.43778801843318, 65.89861751152074, 66.12903225806451, 64.97695852534562, 65.89861751152074, 65.66820276497695, 65.89861751152074, 65.2073732718894, 63.594470046082954, 66.12903225806451, 65.66820276497695, 64.97695852534562, 65.66820276497695, 65.89861751152074, 65.2073732718894, 65.66820276497695, 65.43778801843318, 65.66820276497695, 65.89861751152074, 65.2073732718894, 65.43778801843318, 65.2073732718894, 66.3594470046083, 65.43778801843318, 63.594470046082954, 65.66820276497695, 65.43778801843318, 64.28571428571429, 65.89861751152074, 66.3594470046083, 63.824884792626726, 65.2073732718894, 65.43778801843318, 65.66820276497695, 65.66820276497695, 65.43778801843318, 64.51612903225806, 65.66820276497695, 64.97695852534562, 65.43778801843318, 64.74654377880185, 65.89861751152074, 64.0552995391705, 66.12903225806451, 65.66820276497695, 65.66820276497695, 65.43778801843318, 66.12903225806451, 64.51612903225806, 65.43778801843318, 65.2073732718894, 65.66820276497695, 65.66820276497695, 63.133640552995395, 65.89861751152074, 65.2073732718894, 65.89861751152074, 65.43778801843318, 64.74654377880185, 65.2073732718894, 66.12903225806451, 65.89861751152074, 65.2073732718894, 65.43778801843318, 65.66820276497695, 64.97695852534562, 65.89861751152074, 64.97695852534562, 65.2073732718894, 66.3594470046083, 64.28571428571429, 64.51612903225806, 65.43778801843318, 65.2073732718894, 64.51612903225806, 65.2073732718894, 64.51612903225806, 65.66820276497695, 65.66820276497695, 65.43778801843318]\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "pool_experiment(LogModel,LeastConfidenceSelection,500,25)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyMfqalTRwiWuiIELJDbCQ7d",
      "mount_file_id": "1SZapm_bYNJDCJi8ECwmjrzaN8-1ruRgA",
      "name": "Logistic.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "5edc29c2ed010d6458d71a83433b383a96a8cbd3efe8531bc90c4b8a5b8bcec9"
    },
    "kernelspec": {
      "display_name": "Python 3.8.2 64-bit",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "metadata": {
      "interpreter": {
        "hash": "5edc29c2ed010d6458d71a83433b383a96a8cbd3efe8531bc90c4b8a5b8bcec9"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}