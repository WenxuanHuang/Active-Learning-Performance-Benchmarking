{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "source": [
        "print(__doc__)\n",
        "\n",
        "import os\n",
        "import time\n",
        "import json\n",
        "import pickle\n",
        "import math\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.mlab as mlab\n",
        "from scipy.special import expit\n",
        "from scipy import stats\n",
        "from pylab import rcParams\n",
        "import mplcursors\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.datasets import load_digits\n",
        "\n",
        "from sklearn.utils import check_random_state\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer\n",
        "from sklearn.pipeline import Pipeline, FeatureUnion\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import scale\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "\n",
        "from sklearn import linear_model\n",
        "from sklearn import neighbors\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.linear_model import RidgeCV, LassoCV, Ridge, Lasso\n",
        "from sklearn.svm import LinearSVC, SVC\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.utils import check_random_state\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics.pairwise import euclidean_distances\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.mixture import GaussianMixture\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import pairwise_distances_argmin_min\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import average_precision_score\n",
        "\n",
        "\n",
        "# pd.options.display.max_rows = 20\n",
        "pd.options.display.float_format = \"{:.1f}\".format"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Automatically created module for IPython interactive environment\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ioi13nGDPDvQ",
        "outputId": "4763f7b3-6c5b-45cb-f411-fd7c6ea8b38f"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "source": [
        "def fetch_data_corona():\n",
        "    data = pd.read_csv(\"https://raw.githubusercontent.com/WenxuanHuang/ML-for-COVID-19-dataset/main/all_training.csv\", sep=',')\n",
        "    # Column selection\n",
        "    df = data.iloc[:,np.r_[3:34]].copy()\n",
        "    # define row and column index\n",
        "    col = df.columns\n",
        "    row = [i for i in range(df.shape[0])]\n",
        "    # define imputer\n",
        "    imputer = IterativeImputer(estimator=linear_model.BayesianRidge(), n_nearest_features=None, imputation_order='ascending')\n",
        "    # fit on the dataset\n",
        "    imputer.fit(df)\n",
        "    # transform the dataset\n",
        "    df_imputed = imputer.transform(df)\n",
        "    # convert back to pandas dataframe and rename back to df_normalized\n",
        "    df = pd.DataFrame(data=df_imputed, index=row, columns=col)\n",
        "    X = df\n",
        "    y = data.target    \n",
        "    # # Recursive feature elimination\n",
        "    # rdmreg = RandomForestClassifier(n_estimators=100)\n",
        "    # # Define the method\n",
        "    # rfe = RFE(estimator=rdmreg, n_features_to_select=10)\n",
        "    # # Fit the model\n",
        "    # rfe = rfe.fit(X, y.values.ravel())\n",
        "    # print(rfe.support_)\n",
        "    # # Drop columns that failed RFE test\n",
        "    # col = df.columns[rfe.support_]\n",
        "    # X = X[col]\n",
        "    X = X.to_numpy()\n",
        "    print ('df:', X.shape, y.shape)\n",
        "    return (X, y)\n",
        "\n",
        "\n",
        "# def split(train_size):\n",
        "#     X_train_full = X[:train_size]\n",
        "#     y_train_full = y[:train_size]\n",
        "#     X_test = X[train_size:]\n",
        "#     y_test = y[train_size:]   \n",
        "#     return (X_train_full, y_train_full, X_test, y_test)\n"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "source": [
        "def fetch_data_iris():\n",
        "    iris = load_iris()\n",
        "    X = iris.data.astype('float64')\n",
        "    y = iris.target\n",
        "    print ('Dataset : ', X.shape, y.shape)\n",
        "    return (X, y)\n",
        "\n",
        "def fetch_data_mnist():\n",
        "    mnist = load_digits()\n",
        "    X = mnist.data.astype('float64')\n",
        "    y = mnist.target\n",
        "    print ('Dataset : ', X.shape, y.shape)\n",
        "    return (X, y)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "source": [
        "class BaseModel(object):\n",
        "\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def fit_predict(self):\n",
        "        pass\n",
        "\n",
        "\n",
        "class SvmModel(BaseModel):\n",
        "\n",
        "    model_type = 'Support Vector Machine with linear Kernel'\n",
        "    def fit_predict(self, X_train, y_train, X_val, X_test):\n",
        "        print ('training svm...')\n",
        "        self.classifier = SVC(\n",
        "            C=1, \n",
        "            kernel='linear', \n",
        "            probability=True\n",
        "            )\n",
        "        self.classifier.fit(X_train, y_train)\n",
        "        self.test_y_predicted = self.classifier.predict(X_test)\n",
        "        self.val_y_predicted = self.classifier.predict(X_val)\n",
        "        return (X_train, X_val, X_test, self.val_y_predicted,\n",
        "                self.test_y_predicted)\n",
        "\n",
        "class LogModel(BaseModel):\n",
        "\n",
        "    model_type = 'Logistic Regression' \n",
        "    def fit_predict(self, X_train, y_train, X_val, X_test):\n",
        "        # print ('training logistic regression...')\n",
        "        # train_samples = X_train.shape[0]\n",
        "        self.classifier = LogisticRegression(\n",
        "            # C=50. / train_samples,\n",
        "            penalty='l1',\n",
        "            solver='liblinear',\n",
        "            tol=0.1\n",
        "            )\n",
        "        self.classifier.fit(X_train, y_train)\n",
        "        self.test_y_predicted = self.classifier.predict(X_test)\n",
        "        self.val_y_predicted = self.classifier.predict(X_val)\n",
        "        return (X_train, X_val, X_test, self.val_y_predicted,\n",
        "                self.test_y_predicted)\n",
        "\n",
        "class RfModel(BaseModel):\n",
        "\n",
        "    model_type = 'Random Forest'\n",
        "    def fit_predict(self, X_train, y_train, X_val, X_test):\n",
        "        print ('training random forest...')\n",
        "        self.classifier = RandomForestClassifier(\n",
        "            n_estimators=100, \n",
        "            n_jobs=-1\n",
        "            )\n",
        "        self.classifier.fit(X_train, y_train)\n",
        "        self.test_y_predicted = self.classifier.predict(X_test)\n",
        "        self.val_y_predicted = self.classifier.predict(X_val)\n",
        "        return (X_train, X_val, X_test, self.val_y_predicted, self.test_y_predicted)\n",
        "\n",
        "class GDBCModel(BaseModel):\n",
        "\n",
        "    model_type = 'Gradient Boost classifier'\n",
        "    def fit_predict(self, X_train, y_train, X_val, X_test):\n",
        "        print ('training GDBC...')\n",
        "        self.classifier = GradientBoostingClassifier(\n",
        "            n_estimators=1200,\n",
        "            max_depth=3,\n",
        "            subsample=0.5,\n",
        "            learning_rate=0.01,\n",
        "            min_samples_leaf=1,\n",
        "            random_state=3\n",
        "            )\n",
        "        self.classifier.fit(X_train, y_train)\n",
        "        self.test_y_predicted = self.classifier.predict(X_test)\n",
        "        self.val_y_predicted = self.classifier.predict(X_val)\n",
        "        return (X_train, X_val, X_test, self.val_y_predicted, self.test_y_predicted)\n",
        "\n",
        "class KnnModel(BaseModel):\n",
        "\n",
        "    model_type = 'Nearest Neighbour classifier'\n",
        "    def fit_predict(self, X_train, y_train, X_val, X_test):\n",
        "        print ('training KNN...')\n",
        "        self.classifier = neighbors.KNeighborsClassifier(\n",
        "            n_neighbors = 10,\n",
        "            n_jobs = -1\n",
        "            )\n",
        "        self.classifier.fit(X_train, y_train)\n",
        "        self.test_y_predicted = self.classifier.predict(X_test)\n",
        "        self.val_y_predicted = self.classifier.predict(X_val)\n",
        "        return (X_train, X_val, X_test, self.val_y_predicted, self.test_y_predicted)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "source": [
        "class TrainModel:\n",
        "\n",
        "    def __init__(self, model_object):        \n",
        "        self.accuracies = []\n",
        "        self.model_object = model_object()        \n",
        "\n",
        "    def print_model_type(self):\n",
        "        print (self.model_object.model_type)\n",
        "\n",
        "    # we train normally and use the probabilities to select the most uncertain samples\n",
        "    def train(self, X_train, y_train, X_val, X_test):\n",
        "        t0 = time.time()\n",
        "        (X_train, X_val, X_test, self.val_y_predicted,\n",
        "         self.test_y_predicted) = \\\n",
        "            self.model_object.fit_predict(X_train, y_train, X_val, X_test)\n",
        "        self.run_time = time.time() - t0\n",
        "        return (X_train, X_val, X_test)\n",
        "\n",
        "    # we want accuracy only for the test set\n",
        "    def get_test_accuracy(self, i, y_test):\n",
        "        classif_rate = np.mean(self.test_y_predicted.ravel() == y_test.ravel()) * 100\n",
        "        self.accuracies.append(classif_rate)               \n",
        "        print('--------------------------------')\n",
        "        print('Iteration:',i)\n",
        "        # print('--------------------------------')\n",
        "        # print('y-test set:',y_test.shape)\n",
        "        # print('Training run in %.3f s' % self.run_time,'\\n')\n",
        "        print(\"Accuracy rate is %f \" % (classif_rate))    \n",
        "        # print(\"Classification report for %s:\\n%s\\n\" % (self.model_object.classifier, metrics.classification_report(y_test, self.test_y_predicted)))\n",
        "        # print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(y_test, self.test_y_predicted))\n",
        "        print('--------------------------------')\n"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "source": [
        "class QueryFunction(object):\n",
        "\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    # def stream_select(self):\n",
        "    #     pass\n",
        "\n",
        "    def pool_select(self):\n",
        "        pass\n",
        "\n",
        "\n",
        "class RandomSelection(QueryFunction):\n",
        "\n",
        "    @staticmethod\n",
        "    def pool_select(probas_val, batch_size):\n",
        "        random_state = check_random_state(0)\n",
        "        # probas_val.shape[0] is the size of validation set\n",
        "        selection = np.random.choice(probas_val.shape[0], batch_size, replace=False)\n",
        "        # print('uniques chosen:',np.unique(selection).shape[0],'<= should be equal to:',batch_size)\n",
        "        return selection\n",
        "\n",
        "\n",
        "class EntropySelection(QueryFunction):\n",
        "\n",
        "    @staticmethod\n",
        "    def pool_select(probas_val, batch_size):\n",
        "        e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
        "        selection = (np.argsort(e)[::-1])[:batch_size]\n",
        "        return selection\n",
        "\n",
        "class MinStdSelection(QueryFunction):\n",
        "\n",
        "    # select the samples where the std is smallest. There is uncertainty regarding the relevant class\n",
        "    # and then train on these \"hard\" to classify samples.\n",
        "    @staticmethod\n",
        "    def pool_select(probas_val, batch_size):\n",
        "        std = np.std(probas_val * 100, axis=1) \n",
        "        selection = std.argsort()[:batch_size]\n",
        "        selection = selection.astype('int64')\n",
        "        print('std',std.shape,std)\n",
        "        print('selection',selection, selection.shape, std[selection])\n",
        "        return selection\n",
        "\n",
        "class LeastConfidenceSelection(QueryFunction):\n",
        "\n",
        "    @staticmethod\n",
        "    def pool_select(probas_val, batch_size):\n",
        "        sort_prob = -np.sort(-probas_val, axis=1)\n",
        "        values = sort_prob[:, 0]\n",
        "        selection = np.argsort(values)[:batch_size]\n",
        "        return selection\n",
        "      \n",
        "      \n",
        "class MarginSelection(QueryFunction):\n",
        "\n",
        "    @staticmethod\n",
        "    def pool_select(probas_val, batch_size):\n",
        "        sort_prob = -np.sort(-probas_val, axis=1)\n",
        "        values = sort_prob[:, 0] - sort_prob[:, 1]\n",
        "        selection = np.argsort(values)[:batch_size]\n",
        "        return selection\n"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "source": [
        "class Normalize(object):\n",
        "    \n",
        "    def normalize(self, X_train, X_val, X_test):\n",
        "        self.scaler = RobustScaler()\n",
        "        X_train = self.scaler.fit_transform(X_train)\n",
        "        X_val   = self.scaler.transform(X_val)\n",
        "        X_test  = self.scaler.transform(X_test)\n",
        "        return (X_train, X_val, X_test) \n",
        "    \n",
        "    def inverse(self, X_train, X_val, X_test):\n",
        "        X_train = self.scaler.inverse_transform(X_train)\n",
        "        X_val   = self.scaler.inverse_transform(X_val)\n",
        "        X_test  = self.scaler.inverse_transform(X_test)\n",
        "        return (X_train, X_val, X_test) "
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "source": [
        "def get_random_samples(initial_samples, X_train_full,\n",
        "                         y_train_full):\n",
        "\n",
        "    random_state = check_random_state(0)\n",
        "\n",
        "    permutation = np.random.choice(len(X_train_full),initial_samples,replace=False)\n",
        "    \n",
        "    # print ()\n",
        "    # print(type(permutation))\n",
        "    # print ('initial random chosen samples', permutation)\n",
        "\n",
        "    X_train = X_train_full[permutation]\n",
        "    y_train = y_train_full[permutation]\n",
        "    X_train = X_train.reshape((X_train.shape[0], -1))\n",
        "\n",
        "    # bin_count = np.bincount(y_train.astype('int64'))\n",
        "    # unique = np.unique(y_train.astype('int64'))\n",
        "    # print (\n",
        "    #     'initial train set:',\n",
        "    #     X_train.shape,\n",
        "    #     y_train.shape,\n",
        "    #     'unique(labels):',\n",
        "    #     bin_count,\n",
        "    #     unique,\n",
        "    #     )\n",
        "    return (permutation, X_train, y_train)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "source": [
        "class TheAlgorithm(object):\n",
        "\n",
        "    accuracies = []\n",
        "\n",
        "    def __init__(self, step, model_object, selection_function):\n",
        "        self.step = step\n",
        "        self.model_object = model_object\n",
        "        self.sample_selection_function = selection_function\n",
        "        \n",
        "# To-do: Move initiation selections as arguments\n",
        "    def run(self, X_train_full, y_train_full, X_test, y_test, initial_queried, max_queried):\n",
        "\n",
        "        # initialize process by applying base learner to labeled training data set to obtain Classifier\n",
        "        (permutation, X_train, y_train) = \\\n",
        "            get_random_samples(initial_queried, X_train_full, y_train_full)\n",
        "        self.queried = initial_queried\n",
        "        # self.samplecount = [self.initiation_selections]\n",
        "\n",
        "        # assign the val set the rest of the 'unlabelled' training data\n",
        "        X_val = np.array([])\n",
        "        y_val = np.array([])\n",
        "        X_val = np.copy(X_train_full)\n",
        "        X_val = np.delete(X_val, permutation, axis=0)\n",
        "        y_val = np.copy(y_train_full)\n",
        "        y_val = np.delete(y_val, permutation, axis=0)\n",
        "        # print ('Val set:', X_val.shape, y_val.shape, permutation.shape)\n",
        "        # print ()\n",
        "\n",
        "        # normalize data\n",
        "        normalizer = Normalize()\n",
        "        X_train, X_val, X_test = normalizer.normalize(X_train, X_val, X_test)\n",
        "           \n",
        "        self.clf_model = TrainModel(self.model_object)\n",
        "        (X_train, X_val, X_test) = self.clf_model.train(X_train, y_train, X_val, X_test)\n",
        "        active_iteration = 1\n",
        "        self.clf_model.get_test_accuracy(1, y_test)\n",
        "\n",
        "        # queried_num = [self.queried]\n",
        "\n",
        "        while self.queried <= max_queried-self.step:\n",
        "\n",
        "            active_iteration += 1\n",
        "            self.queried += self.step\n",
        "            # queried_num.append(self.queried)\n",
        "            # get validation probabilities\n",
        "            probas_val = \\\n",
        "                self.clf_model.model_object.classifier.predict_proba(X_val)\n",
        "            # print('Classifier class:', self.clf_model.model_object.classifier.classes_)\n",
        "            # print('Probas_val:', probas_val)\n",
        "            # pred_val = \\\n",
        "            #     self.clf_model.val_y_predicted\n",
        "            # model_val = \\\n",
        "            #     self.clf_model\n",
        "            # print ('val predicted:',\n",
        "            #         self.clf_model.val_y_predicted.shape,\n",
        "            #         self.clf_model.val_y_predicted)\n",
        "            # display probability of binary value predictions of the validation set\n",
        "            # print ('probas_val value', probas_val)\n",
        "            # display which binary value has the highest probabilities of the validation set\n",
        "            # print ('probabilities:', probas_val.shape, '\\n',\n",
        "            #        np.argmax(probas_val, axis=1))\n",
        "\n",
        "            # select samples using a selection function\n",
        "            uncertain_samples = self.sample_selection_function.pool_select(probas_val, self.step)\n",
        "\n",
        "            # normalization needs to be inversed and recalculated based on the new train and test set.\n",
        "            X_train, X_val, X_test = normalizer.inverse(X_train, X_val, X_test)   \n",
        "\n",
        "            # get the uncertain samples from the validation set\n",
        "            # print ('trainset before adding uncertain samples', X_train.shape, y_train.shape)\n",
        "            X_train = np.concatenate((X_train, X_val[uncertain_samples]))\n",
        "            y_train = np.concatenate((y_train, y_val[uncertain_samples]))\n",
        "            # print ('trainset after adding uncertain samples', X_train.shape, y_train.shape)\n",
        "            # self.samplecount.append(X_train.shape[0])\n",
        "\n",
        "            \n",
        "\n",
        "            # bin_count = np.bincount(y_train.astype('int64'))\n",
        "            # unique = np.unique(y_train.astype('int64'))\n",
        "            # print (\n",
        "            #     'updated train set:',\n",
        "            #     X_train.shape,\n",
        "            #     y_train.shape,\n",
        "            #     'unique(labels):',\n",
        "            #     bin_count,\n",
        "            #     unique,\n",
        "            #     )\n",
        "\n",
        "            X_val = np.delete(X_val, uncertain_samples, axis=0)\n",
        "            y_val = np.delete(y_val, uncertain_samples, axis=0)\n",
        "            # print ('val set:', X_val.shape, y_val.shape)\n",
        "            # print ()\n",
        "\n",
        "            # normalize again after creating the 'new' train/test sets\n",
        "            normalizer = Normalize()\n",
        "            X_train, X_val, X_test = normalizer.normalize(X_train, X_val, X_test)               \n",
        "\n",
        "            # self.queried += self.step\n",
        "\n",
        "            (X_train, X_val, X_test) = self.clf_model.train(X_train, y_train, X_val, X_test)\n",
        "            self.clf_model.get_test_accuracy(active_iteration, y_test)\n",
        "\n",
        "        # print('Queried numbers', queried_num)\n",
        "        return self.clf_model.accuracies\n",
        "        # print ('final active learning accuracies',\n",
        "        #        self.clf_model.accuracies)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "source": [
        "def pool_experiment(model,sampling_method,max_queried,initial_queried,step):\n",
        "    (X, y) = fetch_data_mnist()\n",
        "    # (X_train_full, X_test,y_train_full,  y_test) = train_test_split(X, y, test_size=0.25)\n",
        "    # print(type(X_train_full))\n",
        "\n",
        "    kf = KFold(n_splits=4)\n",
        "\n",
        "    for train_index, test_index in kf.split(X):\n",
        "        X_train_full, X_test = X[train_index], X[test_index]\n",
        "        y_train_full, y_test = y[train_index], y[test_index]\n",
        "        \n",
        "    act_alg = TheAlgorithm(step, model , sampling_method)\n",
        "    accuracies = act_alg.run(X_train_full,y_train_full,X_test,y_test,initial_queried,max_queried)\n",
        "\n",
        "    (permutation, X_train_selected, y_train_selected) = get_random_samples(initial_queried, X_train_full, y_train_full)\n",
        "    original_accuracies=[]\n",
        "    classifier_original = LogisticRegression(\n",
        "            # C=50. / train_samples,\n",
        "            penalty='l1',\n",
        "            solver='liblinear',\n",
        "            tol=0.1\n",
        "            )\n",
        "    x_axis = []\n",
        "    for i in range(initial_queried-1,max_queried,step):\n",
        "        classifier_original.fit(X_train_selected[:i+1], y_train_selected[:i+1])\n",
        "        y_pred_original = classifier_original.predict(X_test)\n",
        "        original_accuracies.append(accuracy_score(y_test, y_pred_original)*100)\n",
        "        x_axis.append(i+1)\n",
        "    print(\"accuracies\",accuracies)\n",
        "    print(\"nonactive_accuracies\",original_accuracies)\n",
        "    # print(\"x-axis:\",x_axis)\n",
        "    # print(\"x-axis length:\",len(x_axis))\n",
        "    # x_axis = np.linspace(initial_queried,max_queried,num=(max_queried - initial_queried)//step +1,endpoint=True)\n",
        "    plt.plot(x_axis, accuracies, 'r',label='active')\n",
        "    plt.plot(x_axis, original_accuracies, 'blue',label='non-active')\n",
        "    plt.legend()\n",
        "    plt.xlabel('Sample Size')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.show()"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "source": [
        "# print ('train:', X_train_full.shape, y_train_full.shape)\n",
        "# print ('test :', X_test.shape, y_test.shape)\n",
        "# classes = len(np.unique(y))\n",
        "# print ('unique classes', classes)\n",
        "\n",
        "# def pickle_save(fname, data):\n",
        "#   filehandler = open(fname,\"wb\")\n",
        "#   pickle.dump(data,filehandler)\n",
        "#   filehandler.close()\n",
        "#   print('saved', fname, os.getcwd(), os.listdir())\n",
        "\n",
        "# def pickle_load(fname):\n",
        "#   print(os.getcwd(), os.listdir())\n",
        "#   file = open(fname,'rb')\n",
        "#   data = pickle.load(file)\n",
        "#   file.close()\n",
        "#   print(data)\n",
        "#   return data\n",
        "  \n",
        "# def batch_experiment(d, models, selection_functions, Ks, repeats, contfrom):\n",
        "\n",
        "#     (X, y) = data_prep()\n",
        "#     # (X_train_full, X_test,y_train_full,  y_test) = train_test_split(X, y, test_size=0.25)\n",
        "#     # print(type(X_train_full))\n",
        "\n",
        "#     from sklearn.model_selection import KFold\n",
        "#     kf = KFold(n_splits=4)\n",
        "\n",
        "#     for train_index, test_index in kf.split(X):\n",
        "#         X_train_full, X_test = X[train_index], X[test_index]\n",
        "#         y_train_full, y_test = y[train_index], y[test_index]\n",
        "\n",
        "#     algos_temp = []\n",
        "#     print ('stopping at:', max_queried)\n",
        "#     count = 0\n",
        "#     for model_object in models:\n",
        "#       if model_object.__name__ not in d:\n",
        "#           d[model_object.__name__] = {}\n",
        "      \n",
        "#       for selection_function in selection_functions:\n",
        "#         if selection_function.__name__ not in d[model_object.__name__]:\n",
        "#             d[model_object.__name__][selection_function.__name__] = {}\n",
        "        \n",
        "#         for k in Ks:\n",
        "#             d[model_object.__name__][selection_function.__name__][str(k)] = []           \n",
        "            \n",
        "#             for i in range(0, repeats):\n",
        "#                 count+=1\n",
        "#                 if count >= contfrom:\n",
        "#                     # print ('Count = %s, using model = %s, selection_function = %s, k = %s, iteration = %s.' % (count, model_object.__name__, selection_function.__name__, k, i))\n",
        "#                     alg = TheAlgorithm(k, \n",
        "#                                        model_object, \n",
        "#                                        selection_function\n",
        "#                                        )\n",
        "#                     alg.run(X_train_full, y_train_full, X_test, y_test)\n",
        "#                     d[model_object.__name__][selection_function.__name__][str(k)].append(alg.clf_model.accuracies)\n",
        "#                     # fname = '/Users/wenxuanhuang/Documents/Repo/ML-for-COVID-19-dataset/Results/Active-learning-experiment-' + str(count) + '.pkl'\n",
        "#                     # pickle_save(fname, d)\n",
        "#                     # if count % 5 == 0:\n",
        "#                     #     print(json.dumps(d, indent=2, sort_keys=True))\n",
        "#                     # print ()\n",
        "#                     # print ('---------------------------- FINISHED ---------------------------')\n",
        "#                     # print ()\n",
        "#     return d\n",
        "\n",
        "\n",
        "# max_queried = 500 \n",
        "# repeats = 1\n",
        "# models = [LogModel] \n",
        "# # models = [SvmModel, RfModel, LogModel, GDBCModel, KnnModel] \n",
        "# selection_functions = [LeastConfidenceSelection] \n",
        "# # selection_functions = [RandomSelection, MarginSamplingSelection, EntropySelection, MinStdSelection, LeastConfidenceSelection] \n",
        "# Ks = [250,125,50,25,10] \n",
        "# d = {}\n",
        "# stopped_at = -1 \n",
        "# # print('directory dump including pickle files:', os.getcwd(), np.sort(os.listdir()))  \n",
        "# # d = pickle_load('Active-learning-experiment-' + str(stopped_at) + '.pkl')  \n",
        "# # print(json.dumps(d, indent=2, sort_keys=True))\n",
        "# d = batch_experiment(d, models, selection_functions, Ks, repeats, stopped_at+1)\n",
        "# # print (d)\n",
        "# # results = json.loads(json.dumps(d, indent=2, sort_keys=True))\n",
        "# # print(results)\n"
      ],
      "outputs": [],
      "metadata": {
        "tags": []
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "source": [
        "# %matplotlib widget\n",
        "# # %matplotlib inline\n",
        "# def performance_plot(fully_supervised_accuracy, dic, models, selection_functions, Ks, repeats):  \n",
        "#     fig, ax = plt.subplots()\n",
        "#     ax.plot([0,500],[fully_supervised_accuracy, fully_supervised_accuracy],label = 'upper-bound')\n",
        "#     for model_object in models:\n",
        "#       for selection_function in selection_functions:\n",
        "#         for idx, k in enumerate(Ks):\n",
        "#             x = np.arange(float(Ks[idx]), 500 + float(Ks[idx]), float(Ks[idx]))            \n",
        "#             Sum = np.array(dic[model_object][selection_function][k][0])\n",
        "#             for i in range(1, repeats):\n",
        "#                 Sum = Sum + np.array(dic[model_object][selection_function][k][i])\n",
        "#             mean = Sum / repeats\n",
        "#             ax.plot(x, mean, label = model_object[0:3] + '-' + selection_function[0:3] + '-' + str(k))\n",
        "#     ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "#     ax.set_xlim([50,500])\n",
        "#     ax.set_ylim([20,83])\n",
        "#     ax.grid(True)\n",
        "#     mplcursors.cursor()\n",
        "#     plt.tight_layout()\n",
        "#     plt.show()\n",
        "\n",
        "# # models_str = ['SvmModel', 'RfModel', 'LogModel','GDBCModel','KnnModel']\n",
        "# models_str = ['LogModel']\n",
        "# # selection_functions_str = ['RandomSelection', 'MarginSamplingSelection', 'EntropySelection', 'MinStdSelection','LeastConfidenceSelection']\n",
        "# selection_functions_str = ['LeastConfidenceSelection']\n",
        "# Ks_str = ['250','125','50','25','10'] \n",
        "# repeats = 10\n",
        "# # random_forest_upper_bound = 89.\n",
        "# # svm_upper_bound = 87.\n",
        "# log_upper_bound = 87.\n",
        "# # gdbc_upper_bound = 86.\n",
        "# # knn_upper_bound = 86.\n",
        "# total_experiments = len(models_str) * len(selection_functions_str) * len(Ks_str) * repeats\n",
        "\n",
        "# print('So which is the better model? under the stopping condition and hyper parameters')\n",
        "# # performance_plot(random_forest_upper_bound, d, ['RfModel'] , selection_functions_str    , Ks_str, 1)\n",
        "# # performance_plot(svm_upper_bound, d, ['SvmModel'] , selection_functions_str    , Ks_str, 1)\n",
        "# performance_plot(log_upper_bound, d, ['LogModel'] , selection_functions_str    , Ks_str, 1)\n",
        "# # performance_plot(gdbc_upper_bound, d, ['GDBCModel'] , selection_functions_str    , Ks_str, 1)\n",
        "# # performance_plot(log_upper_bound, d, ['KnnModel'] , selection_functions_str    , Ks_str, 1)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "source": [
        "pool_experiment(LogModel,RandomSelection,500,25,5)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset :  (1797, 64) (1797,)\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "Accuracy rate is 46.102450 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "Accuracy rate is 41.202673 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 3\n",
            "Accuracy rate is 46.993318 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 4\n",
            "Accuracy rate is 51.224944 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 5\n",
            "Accuracy rate is 67.483296 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 6\n",
            "Accuracy rate is 65.701559 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 7\n",
            "Accuracy rate is 70.601336 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 8\n",
            "Accuracy rate is 69.710468 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 9\n",
            "Accuracy rate is 71.492205 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 10\n",
            "Accuracy rate is 74.832962 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 11\n",
            "Accuracy rate is 78.396437 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 12\n",
            "Accuracy rate is 78.396437 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 13\n",
            "Accuracy rate is 77.951002 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 14\n",
            "Accuracy rate is 77.505568 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 15\n",
            "Accuracy rate is 77.505568 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 16\n",
            "Accuracy rate is 78.619154 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 17\n",
            "Accuracy rate is 81.737194 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 18\n",
            "Accuracy rate is 80.623608 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 19\n",
            "Accuracy rate is 80.846325 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 20\n",
            "Accuracy rate is 79.287305 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 21\n",
            "Accuracy rate is 80.623608 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 22\n",
            "Accuracy rate is 82.182628 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 23\n",
            "Accuracy rate is 80.846325 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 24\n",
            "Accuracy rate is 82.405345 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 25\n",
            "Accuracy rate is 81.737194 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 26\n",
            "Accuracy rate is 82.850780 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 27\n",
            "Accuracy rate is 83.518931 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 28\n",
            "Accuracy rate is 85.300668 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 29\n",
            "Accuracy rate is 84.187082 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 30\n",
            "Accuracy rate is 83.741648 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 31\n",
            "Accuracy rate is 83.518931 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 32\n",
            "Accuracy rate is 85.523385 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 33\n",
            "Accuracy rate is 86.636971 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 34\n",
            "Accuracy rate is 85.077951 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 35\n",
            "Accuracy rate is 86.191537 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 36\n",
            "Accuracy rate is 84.187082 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 37\n",
            "Accuracy rate is 85.300668 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 38\n",
            "Accuracy rate is 85.968820 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 39\n",
            "Accuracy rate is 85.968820 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 40\n",
            "Accuracy rate is 86.636971 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 41\n",
            "Accuracy rate is 84.855234 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 42\n",
            "Accuracy rate is 85.746102 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 43\n",
            "Accuracy rate is 83.964365 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 44\n",
            "Accuracy rate is 85.746102 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 45\n",
            "Accuracy rate is 84.409800 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 46\n",
            "Accuracy rate is 85.746102 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 47\n",
            "Accuracy rate is 84.855234 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 48\n",
            "Accuracy rate is 84.409800 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 49\n",
            "Accuracy rate is 85.077951 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 50\n",
            "Accuracy rate is 84.409800 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 51\n",
            "Accuracy rate is 85.077951 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 52\n",
            "Accuracy rate is 85.077951 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 53\n",
            "Accuracy rate is 85.523385 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 54\n",
            "Accuracy rate is 84.855234 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 55\n",
            "Accuracy rate is 83.296214 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 56\n",
            "Accuracy rate is 85.077951 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 57\n",
            "Accuracy rate is 84.855234 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 58\n",
            "Accuracy rate is 85.300668 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 59\n",
            "Accuracy rate is 86.414254 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 60\n",
            "Accuracy rate is 86.191537 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 61\n",
            "Accuracy rate is 86.414254 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 62\n",
            "Accuracy rate is 86.191537 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 63\n",
            "Accuracy rate is 86.636971 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 64\n",
            "Accuracy rate is 86.414254 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 65\n",
            "Accuracy rate is 86.859688 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 66\n",
            "Accuracy rate is 85.968820 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 67\n",
            "Accuracy rate is 86.191537 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 68\n",
            "Accuracy rate is 86.636971 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 69\n",
            "Accuracy rate is 88.641425 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 70\n",
            "Accuracy rate is 87.305122 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 71\n",
            "Accuracy rate is 87.750557 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 72\n",
            "Accuracy rate is 86.859688 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 73\n",
            "Accuracy rate is 87.973274 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 74\n",
            "Accuracy rate is 87.527840 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 75\n",
            "Accuracy rate is 88.418708 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 76\n",
            "Accuracy rate is 87.973274 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 77\n",
            "Accuracy rate is 88.195991 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 78\n",
            "Accuracy rate is 88.418708 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 79\n",
            "Accuracy rate is 88.418708 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 80\n",
            "Accuracy rate is 87.527840 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 81\n",
            "Accuracy rate is 87.973274 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 82\n",
            "Accuracy rate is 88.641425 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 83\n",
            "Accuracy rate is 87.973274 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 84\n",
            "Accuracy rate is 87.082405 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 85\n",
            "Accuracy rate is 87.527840 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 86\n",
            "Accuracy rate is 88.418708 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 87\n",
            "Accuracy rate is 88.195991 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 88\n",
            "Accuracy rate is 88.195991 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 89\n",
            "Accuracy rate is 88.864143 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 90\n",
            "Accuracy rate is 88.864143 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 91\n",
            "Accuracy rate is 88.641425 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 92\n",
            "Accuracy rate is 88.418708 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 93\n",
            "Accuracy rate is 88.864143 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 94\n",
            "Accuracy rate is 88.195991 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 95\n",
            "Accuracy rate is 88.195991 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 96\n",
            "Accuracy rate is 88.418708 \n",
            "--------------------------------\n",
            "accuracies [46.10244988864143, 41.202672605790646, 46.99331848552338, 51.224944320712694, 67.48329621380846, 65.70155902004454, 70.60133630289532, 69.71046770601336, 71.49220489977728, 74.83296213808464, 78.39643652561247, 78.39643652561247, 77.9510022271715, 77.50556792873051, 77.50556792873051, 78.61915367483296, 81.73719376391982, 80.62360801781738, 80.84632516703786, 79.28730512249443, 80.62360801781738, 82.18262806236079, 80.84632516703786, 82.40534521158129, 81.73719376391982, 82.85077951002228, 83.51893095768375, 85.30066815144765, 84.18708240534521, 83.74164810690424, 83.51893095768375, 85.52338530066815, 86.63697104677061, 85.07795100222717, 86.19153674832963, 84.18708240534521, 85.30066815144765, 85.96881959910914, 85.96881959910914, 86.63697104677061, 84.85523385300668, 85.74610244988864, 83.96436525612472, 85.74610244988864, 84.4097995545657, 85.74610244988864, 84.85523385300668, 84.4097995545657, 85.07795100222717, 84.4097995545657, 85.07795100222717, 85.07795100222717, 85.52338530066815, 84.85523385300668, 83.29621380846325, 85.07795100222717, 84.85523385300668, 85.30066815144765, 86.41425389755011, 86.19153674832963, 86.41425389755011, 86.19153674832963, 86.63697104677061, 86.41425389755011, 86.8596881959911, 85.96881959910914, 86.19153674832963, 86.63697104677061, 88.64142538975501, 87.30512249443207, 87.75055679287304, 86.8596881959911, 87.97327394209354, 87.52783964365256, 88.41870824053451, 87.97327394209354, 88.19599109131403, 88.41870824053451, 88.41870824053451, 87.52783964365256, 87.97327394209354, 88.64142538975501, 87.97327394209354, 87.08240534521158, 87.52783964365256, 88.41870824053451, 88.19599109131403, 88.19599109131403, 88.8641425389755, 88.8641425389755, 88.64142538975501, 88.41870824053451, 88.8641425389755, 88.19599109131403, 88.19599109131403, 88.41870824053451]\n",
            "nonactive_accuracies [61.915367483296215, 63.474387527839646, 63.69710467706013, 63.02895322939867, 58.797327394209354, 60.801781737193764, 61.69265033407573, 64.3652561247216, 63.69710467706013, 65.92427616926503, 60.35634743875279, 60.35634743875279, 62.80623608017817, 61.915367483296215, 65.25612472160356, 62.360801781737194, 64.3652561247216, 62.1380846325167, 60.801781737193764, 62.58351893095768, 63.69710467706013, 63.25167037861915, 63.91982182628062, 60.13363028953229, 63.69710467706013, 63.91982182628062, 65.70155902004454, 59.68819599109132, 61.24721603563474, 63.25167037861915, 62.1380846325167, 61.02449888641426, 61.24721603563474, 61.02449888641426, 65.47884187082406, 59.910913140311806, 65.03340757238307, 61.915367483296215, 62.360801781737194, 59.46547884187082, 61.24721603563474, 62.58351893095768, 63.25167037861915, 64.14253897550111, 62.360801781737194, 59.02004454342984, 65.25612472160356, 61.24721603563474, 61.69265033407573, 61.02449888641426, 63.69710467706013, 63.474387527839646, 60.57906458797328, 65.25612472160356, 61.69265033407573, 62.58351893095768, 62.360801781737194, 62.360801781737194, 61.915367483296215, 60.57906458797328, 63.91982182628062, 64.3652561247216, 64.81069042316258, 63.474387527839646, 61.02449888641426, 59.68819599109132, 63.91982182628062, 61.915367483296215, 62.80623608017817, 60.13363028953229, 62.80623608017817, 61.915367483296215, 63.91982182628062, 65.03340757238307, 59.910913140311806, 65.92427616926503, 63.02895322939867, 63.91982182628062, 64.3652561247216, 62.1380846325167, 59.24276169265033, 59.68819599109132, 60.35634743875279, 63.02895322939867, 64.3652561247216, 64.14253897550111, 59.68819599109132, 60.57906458797328, 62.80623608017817, 63.69710467706013, 60.801781737193764, 66.59242761692651, 62.1380846325167, 63.02895322939867, 61.46993318485523, 59.910913140311806]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "metadata": {}
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyMfqalTRwiWuiIELJDbCQ7d",
      "mount_file_id": "1SZapm_bYNJDCJi8ECwmjrzaN8-1ruRgA",
      "name": "Logistic.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "5edc29c2ed010d6458d71a83433b383a96a8cbd3efe8531bc90c4b8a5b8bcec9"
    },
    "kernelspec": {
      "display_name": "Python 3.8.2 64-bit",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "metadata": {
      "interpreter": {
        "hash": "5edc29c2ed010d6458d71a83433b383a96a8cbd3efe8531bc90c4b8a5b8bcec9"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}