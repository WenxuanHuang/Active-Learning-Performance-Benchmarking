{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 40,
      "source": [
        "print(__doc__)\n",
        "\n",
        "import os\n",
        "import time\n",
        "import json\n",
        "import pickle\n",
        "import math\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.mlab as mlab\n",
        "from scipy.special import expit\n",
        "from scipy import stats\n",
        "from pylab import rcParams\n",
        "import mplcursors\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.datasets import load_digits\n",
        "\n",
        "from sklearn.utils import check_random_state\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer\n",
        "from sklearn.pipeline import Pipeline, FeatureUnion\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import scale\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "\n",
        "from sklearn import linear_model\n",
        "from sklearn import neighbors\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.linear_model import RidgeCV, LassoCV, Ridge, Lasso\n",
        "from sklearn.svm import LinearSVC, SVC\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.utils import check_random_state\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics.pairwise import euclidean_distances\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.mixture import GaussianMixture\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import pairwise_distances_argmin_min\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import average_precision_score\n",
        "\n",
        "\n",
        "# pd.options.display.max_rows = 20\n",
        "pd.options.display.float_format = \"{:.1f}\".format"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Automatically created module for IPython interactive environment\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ioi13nGDPDvQ",
        "outputId": "4763f7b3-6c5b-45cb-f411-fd7c6ea8b38f"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "source": [
        "def fetch_data_corona():\n",
        "    data = pd.read_csv(\"https://raw.githubusercontent.com/WenxuanHuang/ML-for-COVID-19-dataset/main/all_training.csv\", sep=',')\n",
        "    # Column selection\n",
        "    df = data.iloc[:,np.r_[3:34]].copy()\n",
        "    # define row and column index\n",
        "    col = df.columns\n",
        "    row = [i for i in range(df.shape[0])]\n",
        "    # define imputer\n",
        "    imputer = IterativeImputer(estimator=linear_model.BayesianRidge(), n_nearest_features=None, imputation_order='ascending')\n",
        "    # fit on the dataset\n",
        "    imputer.fit(df)\n",
        "    # transform the dataset\n",
        "    df_imputed = imputer.transform(df)\n",
        "    # convert back to pandas dataframe and rename back to df_normalized\n",
        "    df = pd.DataFrame(data=df_imputed, index=row, columns=col)\n",
        "    X = df\n",
        "    y = data.target    \n",
        "    # Recursive feature elimination\n",
        "    rdmreg = RandomForestClassifier(n_estimators=100)\n",
        "    # Define the method\n",
        "    rfe = RFE(estimator=rdmreg, n_features_to_select=10)\n",
        "    # Fit the model\n",
        "    rfe = rfe.fit(X, y.values.ravel())\n",
        "    print(rfe.support_)\n",
        "    # Drop columns that failed RFE test\n",
        "    col = df.columns[rfe.support_]\n",
        "    X = X[col]\n",
        "    X = X.to_numpy()\n",
        "    print ('df:', X.shape, y.shape)\n",
        "    return (X, y)\n",
        "\n",
        "\n",
        "# def split(train_size):\n",
        "#     X_train_full = X[:train_size]\n",
        "#     y_train_full = y[:train_size]\n",
        "#     X_test = X[train_size:]\n",
        "#     y_test = y[train_size:]   \n",
        "#     return (X_train_full, y_train_full, X_test, y_test)\n"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "source": [
        "def fetch_data_iris():\n",
        "    iris = load_iris()\n",
        "    X = iris.data.astype('float64')\n",
        "    y = iris.target\n",
        "    print ('Dataset : ', X.shape, y.shape)\n",
        "    return (X, y)\n",
        "\n",
        "def fetch_data_mnist():\n",
        "    mnist = load_digits()\n",
        "    X = mnist.data.astype('float64')\n",
        "    y = mnist.target\n",
        "    print ('Dataset : ', X.shape, y.shape)\n",
        "    return (X, y)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "source": [
        "class BaseModel(object):\n",
        "\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def fit_predict(self):\n",
        "        pass\n",
        "\n",
        "\n",
        "class SvmModel(BaseModel):\n",
        "\n",
        "    model_type = 'Support Vector Machine with linear Kernel'\n",
        "    def fit_predict(self, X_train, y_train, X_val, X_test, c_weight):\n",
        "        print ('training svm...')\n",
        "        self.classifier = SVC(\n",
        "            C=1, \n",
        "            kernel='linear', \n",
        "            probability=True,\n",
        "            class_weight=c_weight\n",
        "            )\n",
        "        self.classifier.fit(X_train, y_train)\n",
        "        self.test_y_predicted = self.classifier.predict(X_test)\n",
        "        self.val_y_predicted = self.classifier.predict(X_val)\n",
        "        return (X_train, X_val, X_test, self.val_y_predicted,\n",
        "                self.test_y_predicted)\n",
        "\n",
        "class LogModel(BaseModel):\n",
        "\n",
        "    model_type = 'Logistic Regression' \n",
        "    def fit_predict(self, X_train, y_train, X_val, X_test, c_weight):\n",
        "        # print ('training logistic regression...')\n",
        "        # train_samples = X_train.shape[0]\n",
        "        self.classifier = LogisticRegression(\n",
        "            # C=50. / train_samples,\n",
        "            penalty='l1',\n",
        "            solver='liblinear',\n",
        "            tol=0.1,\n",
        "            class_weight=c_weight\n",
        "            )\n",
        "        self.classifier.fit(X_train, y_train)\n",
        "        self.test_y_predicted = self.classifier.predict(X_test)\n",
        "        self.val_y_predicted = self.classifier.predict(X_val)\n",
        "        return (X_train, X_val, X_test, self.val_y_predicted,\n",
        "                self.test_y_predicted)\n",
        "\n",
        "class RfModel(BaseModel):\n",
        "\n",
        "    model_type = 'Random Forest'\n",
        "    def fit_predict(self, X_train, y_train, X_val, X_test, c_weight):\n",
        "        print ('training random forest...')\n",
        "        self.classifier = RandomForestClassifier(\n",
        "            n_estimators=500, \n",
        "            class_weight=c_weight, \n",
        "            n_jobs=-1\n",
        "            )\n",
        "        self.classifier.fit(X_train, y_train)\n",
        "        self.test_y_predicted = self.classifier.predict(X_test)\n",
        "        self.val_y_predicted = self.classifier.predict(X_val)\n",
        "        return (X_train, X_val, X_test, self.val_y_predicted, self.test_y_predicted)\n",
        "\n",
        "class GDBCModel(BaseModel):\n",
        "\n",
        "    model_type = 'Gradient Boost classifier'\n",
        "    def fit_predict(self, X_train, y_train, X_val, X_test, c_weight):\n",
        "        print ('training GDBC...')\n",
        "        self.classifier = GradientBoostingClassifier(\n",
        "            n_estimators=1200,\n",
        "            max_depth=3,\n",
        "            subsample=0.5,\n",
        "            learning_rate=0.01,\n",
        "            min_samples_leaf=1,\n",
        "            random_state=3\n",
        "            )\n",
        "        self.classifier.fit(X_train, y_train)\n",
        "        self.test_y_predicted = self.classifier.predict(X_test)\n",
        "        self.val_y_predicted = self.classifier.predict(X_val)\n",
        "        return (X_train, X_val, X_test, self.val_y_predicted, self.test_y_predicted)\n",
        "\n",
        "class KnnModel(BaseModel):\n",
        "\n",
        "    model_type = 'Nearest Neighbour classifier'\n",
        "    def fit_predict(self, X_train, y_train, X_val, X_test, c_weight):\n",
        "        print ('training KNN...')\n",
        "        self.classifier = neighbors.KNeighborsClassifier(\n",
        "            n_neighbors = 10,\n",
        "            n_jobs = -1\n",
        "            )\n",
        "        self.classifier.fit(X_train, y_train)\n",
        "        self.test_y_predicted = self.classifier.predict(X_test)\n",
        "        self.val_y_predicted = self.classifier.predict(X_val)\n",
        "        return (X_train, X_val, X_test, self.val_y_predicted, self.test_y_predicted)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "source": [
        "class TrainModel:\n",
        "\n",
        "    def __init__(self, model_object):        \n",
        "        self.accuracies = []\n",
        "        self.model_object = model_object()        \n",
        "\n",
        "    def print_model_type(self):\n",
        "        print (self.model_object.model_type)\n",
        "\n",
        "    # we train normally and use the probabilities to select the most uncertain samples\n",
        "    def train(self, X_train, y_train, X_val, X_test, c_weight):\n",
        "        # print ('Train set:', X_train.shape)\n",
        "        # print ('Validation set:', X_val.shape)\n",
        "        # print ('Test set:', X_test.shape)\n",
        "        t0 = time.time()\n",
        "        (X_train, X_val, X_test, self.val_y_predicted,\n",
        "         self.test_y_predicted) = \\\n",
        "            self.model_object.fit_predict(X_train, y_train, X_val, X_test, c_weight)\n",
        "        self.run_time = time.time() - t0\n",
        "        return (X_train, X_val, X_test)\n",
        "\n",
        "    # we want accuracy only for the test set\n",
        "    def get_test_accuracy(self, i, y_test):\n",
        "        classif_rate = np.mean(self.test_y_predicted.ravel() == y_test.ravel()) * 100\n",
        "        self.accuracies.append(classif_rate)               \n",
        "        print('--------------------------------')\n",
        "        print('Iteration:',i)\n",
        "        # print('--------------------------------')\n",
        "        # print('y-test set:',y_test.shape)\n",
        "        # print('Training run in %.3f s' % self.run_time,'\\n')\n",
        "        print(\"Accuracy rate is %f \" % (classif_rate))    \n",
        "        # print(\"Classification report for %s:\\n%s\\n\" % (self.model_object.classifier, metrics.classification_report(y_test, self.test_y_predicted)))\n",
        "        # print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(y_test, self.test_y_predicted))\n",
        "        print('--------------------------------')\n"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "source": [
        "class QueryFunction(object):\n",
        "\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    # def stream_select(self):\n",
        "    #     pass\n",
        "\n",
        "    def pool_select(self):\n",
        "        pass\n",
        "\n",
        "\n",
        "class RandomSelection(QueryFunction):\n",
        "\n",
        "    @staticmethod\n",
        "    def pool_select(probas_val, batch_size):\n",
        "        random_state = check_random_state(0)\n",
        "        # probas_val.shape[0] is the size of validation set\n",
        "        selection = np.random.choice(probas_val.shape[0], batch_size, replace=False)\n",
        "        # print('uniques chosen:',np.unique(selection).shape[0],'<= should be equal to:',batch_size)\n",
        "        return selection\n",
        "\n",
        "\n",
        "class EntropySelection(QueryFunction):\n",
        "\n",
        "    @staticmethod\n",
        "    def pool_select(probas_val, batch_size):\n",
        "        e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
        "        selection = (np.argsort(e)[::-1])[:batch_size]\n",
        "        return selection\n",
        "\n",
        "class MinStdSelection(QueryFunction):\n",
        "\n",
        "    # select the samples where the std is smallest. There is uncertainty regarding the relevant class\n",
        "    # and then train on these \"hard\" to classify samples.\n",
        "    @staticmethod\n",
        "    def pool_select(probas_val, batch_size):\n",
        "        std = np.std(probas_val * 100, axis=1) \n",
        "        selection = std.argsort()[:batch_size]\n",
        "        selection = selection.astype('int64')\n",
        "        print('std',std.shape,std)\n",
        "        print('selection',selection, selection.shape, std[selection])\n",
        "        return selection\n",
        "\n",
        "class LeastConfidenceSelection(QueryFunction):\n",
        "\n",
        "    @staticmethod\n",
        "    def pool_select(probas_val, batch_size):\n",
        "        sort_prob = -np.sort(-probas_val, axis=1)\n",
        "        values = sort_prob[:, 0]\n",
        "        selection = np.argsort(values)[:batch_size]\n",
        "        return selection\n",
        "      \n",
        "      \n",
        "class MarginSamplingSelection(QueryFunction):\n",
        "\n",
        "    @staticmethod\n",
        "    def pool_select(probas_val, batch_size):\n",
        "        sort_prob = -np.sort(-probas_val, axis=1)\n",
        "        values = sort_prob[:, 0] - sort_prob[:, 1]\n",
        "        selection = np.argsort(values)[:batch_size]\n",
        "        return selection\n"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "source": [
        "class Normalize(object):\n",
        "    \n",
        "    def normalize(self, X_train, X_val, X_test):\n",
        "        self.scaler = RobustScaler()\n",
        "        X_train = self.scaler.fit_transform(X_train)\n",
        "        X_val   = self.scaler.transform(X_val)\n",
        "        X_test  = self.scaler.transform(X_test)\n",
        "        return (X_train, X_val, X_test) \n",
        "    \n",
        "    def inverse(self, X_train, X_val, X_test):\n",
        "        X_train = self.scaler.inverse_transform(X_train)\n",
        "        X_val   = self.scaler.inverse_transform(X_val)\n",
        "        X_test  = self.scaler.inverse_transform(X_test)\n",
        "        return (X_train, X_val, X_test) "
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "source": [
        "def get_random_samples(initial_samples, X_train_full,\n",
        "                         y_train_full):\n",
        "\n",
        "    random_state = check_random_state(0)\n",
        "\n",
        "    permutation = np.random.choice(len(X_train_full),initial_samples,replace=False)\n",
        "    \n",
        "    # print ()\n",
        "    # print(type(permutation))\n",
        "    # print ('initial random chosen samples', permutation)\n",
        "\n",
        "    X_train = X_train_full[permutation]\n",
        "    y_train = y_train_full[permutation]\n",
        "    X_train = X_train.reshape((X_train.shape[0], -1))\n",
        "\n",
        "    # bin_count = np.bincount(y_train.astype('int64'))\n",
        "    # unique = np.unique(y_train.astype('int64'))\n",
        "    # print (\n",
        "    #     'initial train set:',\n",
        "    #     X_train.shape,\n",
        "    #     y_train.shape,\n",
        "    #     'unique(labels):',\n",
        "    #     bin_count,\n",
        "    #     unique,\n",
        "    #     )\n",
        "    return (permutation, X_train, y_train)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "source": [
        "class TheAlgorithm(object):\n",
        "\n",
        "    accuracies = []\n",
        "\n",
        "    def __init__(self, step, model_object, selection_function):\n",
        "        self.step = step\n",
        "        self.model_object = model_object\n",
        "        self.sample_selection_function = selection_function\n",
        "        \n",
        "# To-do: Move initiation selections as arguments\n",
        "    def run(self, X_train_full, y_train_full, X_test, y_test, initial_queried, max_queried):\n",
        "\n",
        "        # initialize process by applying base learner to labeled training data set to obtain Classifier\n",
        "        (permutation, X_train, y_train) = \\\n",
        "            get_random_samples(initial_queried, X_train_full, y_train_full)\n",
        "        self.queried = initial_queried\n",
        "        # self.samplecount = [self.initiation_selections]\n",
        "\n",
        "        # assign the val set the rest of the 'unlabelled' training data\n",
        "        X_val = np.array([])\n",
        "        y_val = np.array([])\n",
        "        X_val = np.copy(X_train_full)\n",
        "        X_val = np.delete(X_val, permutation, axis=0)\n",
        "        y_val = np.copy(y_train_full)\n",
        "        y_val = np.delete(y_val, permutation, axis=0)\n",
        "        # print ('Val set:', X_val.shape, y_val.shape, permutation.shape)\n",
        "        # print ()\n",
        "\n",
        "        # normalize data\n",
        "        normalizer = Normalize()\n",
        "        X_train, X_val, X_test = normalizer.normalize(X_train, X_val, X_test)\n",
        "           \n",
        "        self.clf_model = TrainModel(self.model_object)\n",
        "        (X_train, X_val, X_test) = self.clf_model.train(X_train, y_train, X_val, X_test, 'balanced')\n",
        "        active_iteration = 1\n",
        "        self.clf_model.get_test_accuracy(1, y_test)\n",
        "\n",
        "        # queried_num = [self.queried]\n",
        "\n",
        "        while self.queried <= max_queried-self.step:\n",
        "\n",
        "            active_iteration += 1\n",
        "            self.queried += self.step\n",
        "            # queried_num.append(self.queried)\n",
        "            # get validation probabilities\n",
        "            probas_val = \\\n",
        "                self.clf_model.model_object.classifier.predict_proba(X_val)\n",
        "            # print('Classifier class:', self.clf_model.model_object.classifier.classes_)\n",
        "            # print('Probas_val:', probas_val)\n",
        "            # pred_val = \\\n",
        "            #     self.clf_model.val_y_predicted\n",
        "            # model_val = \\\n",
        "            #     self.clf_model\n",
        "            # print ('val predicted:',\n",
        "            #         self.clf_model.val_y_predicted.shape,\n",
        "            #         self.clf_model.val_y_predicted)\n",
        "            # display probability of binary value predictions of the validation set\n",
        "            # print ('probas_val value', probas_val)\n",
        "            # display which binary value has the highest probabilities of the validation set\n",
        "            # print ('probabilities:', probas_val.shape, '\\n',\n",
        "            #        np.argmax(probas_val, axis=1))\n",
        "\n",
        "            # select samples using a selection function\n",
        "            uncertain_samples = self.sample_selection_function.pool_select(probas_val, self.step)\n",
        "\n",
        "            # normalization needs to be inversed and recalculated based on the new train and test set.\n",
        "            X_train, X_val, X_test = normalizer.inverse(X_train, X_val, X_test)   \n",
        "\n",
        "            # get the uncertain samples from the validation set\n",
        "            # print ('trainset before adding uncertain samples', X_train.shape, y_train.shape)\n",
        "            X_train = np.concatenate((X_train, X_val[uncertain_samples]))\n",
        "            y_train = np.concatenate((y_train, y_val[uncertain_samples]))\n",
        "            # print ('trainset after adding uncertain samples', X_train.shape, y_train.shape)\n",
        "            # self.samplecount.append(X_train.shape[0])\n",
        "\n",
        "            \n",
        "\n",
        "            # bin_count = np.bincount(y_train.astype('int64'))\n",
        "            # unique = np.unique(y_train.astype('int64'))\n",
        "            # print (\n",
        "            #     'updated train set:',\n",
        "            #     X_train.shape,\n",
        "            #     y_train.shape,\n",
        "            #     'unique(labels):',\n",
        "            #     bin_count,\n",
        "            #     unique,\n",
        "            #     )\n",
        "\n",
        "            X_val = np.delete(X_val, uncertain_samples, axis=0)\n",
        "            y_val = np.delete(y_val, uncertain_samples, axis=0)\n",
        "            # print ('val set:', X_val.shape, y_val.shape)\n",
        "            # print ()\n",
        "\n",
        "            # normalize again after creating the 'new' train/test sets\n",
        "            normalizer = Normalize()\n",
        "            X_train, X_val, X_test = normalizer.normalize(X_train, X_val, X_test)               \n",
        "\n",
        "            # self.queried += self.step\n",
        "\n",
        "            (X_train, X_val, X_test) = self.clf_model.train(X_train, y_train, X_val, X_test, 'balanced')\n",
        "            self.clf_model.get_test_accuracy(active_iteration, y_test)\n",
        "\n",
        "        # print('Queried numbers', queried_num)\n",
        "        return self.clf_model.accuracies\n",
        "        # print ('final active learning accuracies',\n",
        "        #        self.clf_model.accuracies)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "source": [
        "def pool_experiment(model,sampling_method,max_queried,initial_queried,step):\n",
        "    (X, y) = fetch_data_mnist()\n",
        "    # (X_train_full, X_test,y_train_full,  y_test) = train_test_split(X, y, test_size=0.25)\n",
        "    # print(type(X_train_full))\n",
        "\n",
        "    kf = KFold(n_splits=4)\n",
        "\n",
        "    for train_index, test_index in kf.split(X):\n",
        "        X_train_full, X_test = X[train_index], X[test_index]\n",
        "        y_train_full, y_test = y[train_index], y[test_index]\n",
        "        \n",
        "    act_alg = TheAlgorithm(step, model , sampling_method)\n",
        "    accuracies = act_alg.run(X_train_full,y_train_full,X_test,y_test,initial_queried,max_queried)\n",
        "\n",
        "    (permutation, X_train_selected, y_train_selected) = get_random_samples(initial_queried, X_train_full, y_train_full)\n",
        "    original_accuracies=[]\n",
        "    classifier_original = LogisticRegression(\n",
        "            # C=50. / X_train_full.shape[0],\n",
        "            penalty='l1',\n",
        "            solver='liblinear',\n",
        "            tol=0.1,\n",
        "            class_weight='balanced')\n",
        "    x_axis = []\n",
        "    for i in range(initial_queried-1,max_queried,step):\n",
        "        classifier_original.fit(X_train_selected[:i+1], y_train_selected[:i+1])\n",
        "        y_pred_original = classifier_original.predict(X_test)\n",
        "        original_accuracies.append(accuracy_score(y_test, y_pred_original)*100)\n",
        "        x_axis.append(i+1)\n",
        "    print(\"accuracies\",accuracies)\n",
        "    print(\"nonactive_accuracies\",original_accuracies)\n",
        "    # print(\"x-axis:\",x_axis)\n",
        "    # print(\"x-axis length:\",len(x_axis))\n",
        "    # x_axis = np.linspace(initial_queried,max_queried,num=(max_queried - initial_queried)//step +1,endpoint=True)\n",
        "    plt.plot(x_axis, accuracies, 'r',label='active')\n",
        "    plt.plot(x_axis, original_accuracies, 'blue',label='non-active')\n",
        "    plt.legend()\n",
        "    plt.xlabel('Sample Size')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.show()"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "source": [
        "# print ('train:', X_train_full.shape, y_train_full.shape)\n",
        "# print ('test :', X_test.shape, y_test.shape)\n",
        "# classes = len(np.unique(y))\n",
        "# print ('unique classes', classes)\n",
        "\n",
        "# def pickle_save(fname, data):\n",
        "#   filehandler = open(fname,\"wb\")\n",
        "#   pickle.dump(data,filehandler)\n",
        "#   filehandler.close()\n",
        "#   print('saved', fname, os.getcwd(), os.listdir())\n",
        "\n",
        "# def pickle_load(fname):\n",
        "#   print(os.getcwd(), os.listdir())\n",
        "#   file = open(fname,'rb')\n",
        "#   data = pickle.load(file)\n",
        "#   file.close()\n",
        "#   print(data)\n",
        "#   return data\n",
        "  \n",
        "def batch_experiment(d, models, selection_functions, Ks, repeats, contfrom):\n",
        "\n",
        "    (X, y) = data_prep()\n",
        "    # (X_train_full, X_test,y_train_full,  y_test) = train_test_split(X, y, test_size=0.25)\n",
        "    # print(type(X_train_full))\n",
        "\n",
        "    from sklearn.model_selection import KFold\n",
        "    kf = KFold(n_splits=4)\n",
        "\n",
        "    for train_index, test_index in kf.split(X):\n",
        "        X_train_full, X_test = X[train_index], X[test_index]\n",
        "        y_train_full, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    algos_temp = []\n",
        "    print ('stopping at:', max_queried)\n",
        "    count = 0\n",
        "    for model_object in models:\n",
        "      if model_object.__name__ not in d:\n",
        "          d[model_object.__name__] = {}\n",
        "      \n",
        "      for selection_function in selection_functions:\n",
        "        if selection_function.__name__ not in d[model_object.__name__]:\n",
        "            d[model_object.__name__][selection_function.__name__] = {}\n",
        "        \n",
        "        for k in Ks:\n",
        "            d[model_object.__name__][selection_function.__name__][str(k)] = []           \n",
        "            \n",
        "            for i in range(0, repeats):\n",
        "                count+=1\n",
        "                if count >= contfrom:\n",
        "                    # print ('Count = %s, using model = %s, selection_function = %s, k = %s, iteration = %s.' % (count, model_object.__name__, selection_function.__name__, k, i))\n",
        "                    alg = TheAlgorithm(k, \n",
        "                                       model_object, \n",
        "                                       selection_function\n",
        "                                       )\n",
        "                    alg.run(X_train_full, y_train_full, X_test, y_test)\n",
        "                    d[model_object.__name__][selection_function.__name__][str(k)].append(alg.clf_model.accuracies)\n",
        "                    # fname = '/Users/wenxuanhuang/Documents/Repo/ML-for-COVID-19-dataset/Results/Active-learning-experiment-' + str(count) + '.pkl'\n",
        "                    # pickle_save(fname, d)\n",
        "                    # if count % 5 == 0:\n",
        "                    #     print(json.dumps(d, indent=2, sort_keys=True))\n",
        "                    # print ()\n",
        "                    # print ('---------------------------- FINISHED ---------------------------')\n",
        "                    # print ()\n",
        "    return d\n",
        "\n",
        "\n",
        "# max_queried = 500 \n",
        "# repeats = 1\n",
        "# models = [LogModel] \n",
        "# # models = [SvmModel, RfModel, LogModel, GDBCModel, KnnModel] \n",
        "# selection_functions = [LeastConfidenceSelection] \n",
        "# # selection_functions = [RandomSelection, MarginSamplingSelection, EntropySelection, MinStdSelection, LeastConfidenceSelection] \n",
        "# Ks = [250,125,50,25,10] \n",
        "# d = {}\n",
        "# stopped_at = -1 \n",
        "# # print('directory dump including pickle files:', os.getcwd(), np.sort(os.listdir()))  \n",
        "# # d = pickle_load('Active-learning-experiment-' + str(stopped_at) + '.pkl')  \n",
        "# # print(json.dumps(d, indent=2, sort_keys=True))\n",
        "# d = batch_experiment(d, models, selection_functions, Ks, repeats, stopped_at+1)\n",
        "# # print (d)\n",
        "# # results = json.loads(json.dumps(d, indent=2, sort_keys=True))\n",
        "# # print(results)\n"
      ],
      "outputs": [],
      "metadata": {
        "tags": []
      }
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "source": [
        "# %matplotlib widget\n",
        "# # %matplotlib inline\n",
        "# def performance_plot(fully_supervised_accuracy, dic, models, selection_functions, Ks, repeats):  \n",
        "#     fig, ax = plt.subplots()\n",
        "#     ax.plot([0,500],[fully_supervised_accuracy, fully_supervised_accuracy],label = 'upper-bound')\n",
        "#     for model_object in models:\n",
        "#       for selection_function in selection_functions:\n",
        "#         for idx, k in enumerate(Ks):\n",
        "#             x = np.arange(float(Ks[idx]), 500 + float(Ks[idx]), float(Ks[idx]))            \n",
        "#             Sum = np.array(dic[model_object][selection_function][k][0])\n",
        "#             for i in range(1, repeats):\n",
        "#                 Sum = Sum + np.array(dic[model_object][selection_function][k][i])\n",
        "#             mean = Sum / repeats\n",
        "#             ax.plot(x, mean, label = model_object[0:3] + '-' + selection_function[0:3] + '-' + str(k))\n",
        "#     ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "#     ax.set_xlim([50,500])\n",
        "#     ax.set_ylim([20,83])\n",
        "#     ax.grid(True)\n",
        "#     mplcursors.cursor()\n",
        "#     plt.tight_layout()\n",
        "#     plt.show()\n",
        "\n",
        "# # models_str = ['SvmModel', 'RfModel', 'LogModel','GDBCModel','KnnModel']\n",
        "# models_str = ['LogModel']\n",
        "# # selection_functions_str = ['RandomSelection', 'MarginSamplingSelection', 'EntropySelection', 'MinStdSelection','LeastConfidenceSelection']\n",
        "# selection_functions_str = ['LeastConfidenceSelection']\n",
        "# Ks_str = ['250','125','50','25','10'] \n",
        "# repeats = 10\n",
        "# # random_forest_upper_bound = 89.\n",
        "# # svm_upper_bound = 87.\n",
        "# log_upper_bound = 87.\n",
        "# # gdbc_upper_bound = 86.\n",
        "# # knn_upper_bound = 86.\n",
        "# total_experiments = len(models_str) * len(selection_functions_str) * len(Ks_str) * repeats\n",
        "\n",
        "# print('So which is the better model? under the stopping condition and hyper parameters')\n",
        "# # performance_plot(random_forest_upper_bound, d, ['RfModel'] , selection_functions_str    , Ks_str, 1)\n",
        "# # performance_plot(svm_upper_bound, d, ['SvmModel'] , selection_functions_str    , Ks_str, 1)\n",
        "# performance_plot(log_upper_bound, d, ['LogModel'] , selection_functions_str    , Ks_str, 1)\n",
        "# # performance_plot(gdbc_upper_bound, d, ['GDBCModel'] , selection_functions_str    , Ks_str, 1)\n",
        "# # performance_plot(log_upper_bound, d, ['KnnModel'] , selection_functions_str    , Ks_str, 1)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "source": [
        "\n",
        "pool_experiment(LogModel,RandomSelection,500,25,5)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset :  (1797, 64) (1797,)\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "Accuracy rate is 37.861915 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "Accuracy rate is 45.657016 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 3\n",
            "Accuracy rate is 54.120267 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 4\n",
            "Accuracy rate is 55.902004 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 5\n",
            "Accuracy rate is 60.356347 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 6\n",
            "Accuracy rate is 60.801782 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 7\n",
            "Accuracy rate is 65.033408 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 8\n",
            "Accuracy rate is 65.701559 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 9\n",
            "Accuracy rate is 65.701559 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 10\n",
            "Accuracy rate is 65.701559 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 11\n",
            "Accuracy rate is 66.815145 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 12\n",
            "Accuracy rate is 66.592428 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 13\n",
            "Accuracy rate is 73.051225 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 14\n",
            "Accuracy rate is 73.496659 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 15\n",
            "Accuracy rate is 77.282851 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 16\n",
            "Accuracy rate is 78.396437 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 17\n",
            "Accuracy rate is 78.173719 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 18\n",
            "Accuracy rate is 78.841871 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 19\n",
            "Accuracy rate is 79.287305 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 20\n",
            "Accuracy rate is 81.737194 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 21\n",
            "Accuracy rate is 81.291759 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 22\n",
            "Accuracy rate is 79.955457 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 23\n",
            "Accuracy rate is 84.409800 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 24\n",
            "Accuracy rate is 82.628062 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 25\n",
            "Accuracy rate is 82.850780 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 26\n",
            "Accuracy rate is 82.405345 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 27\n",
            "Accuracy rate is 81.959911 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 28\n",
            "Accuracy rate is 81.514477 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 29\n",
            "Accuracy rate is 83.964365 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 30\n",
            "Accuracy rate is 81.291759 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 31\n",
            "Accuracy rate is 83.073497 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 32\n",
            "Accuracy rate is 81.959911 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 33\n",
            "Accuracy rate is 82.628062 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 34\n",
            "Accuracy rate is 83.741648 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 35\n",
            "Accuracy rate is 83.296214 \n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Iteration: 36\n",
            "Accuracy rate is 83.964365 \n",
            "--------------------------------\n",
            "accuracies [37.8619153674833, 45.657015590200444, 54.12026726057907, 55.90200445434298, 60.35634743875279, 60.801781737193764, 65.03340757238307, 65.70155902004454, 65.70155902004454, 65.70155902004454, 66.815144766147, 66.59242761692651, 73.05122494432071, 73.4966592427617, 77.28285077951003, 78.39643652561247, 78.17371937639199, 78.84187082405344, 79.28730512249443, 81.73719376391982, 81.29175946547885, 79.9554565701559, 84.4097995545657, 82.62806236080178, 82.85077951002228, 82.40534521158129, 81.9599109131403, 81.51447661469933, 83.96436525612472, 81.29175946547885, 83.07349665924276, 81.9599109131403, 82.62806236080178, 83.74164810690424, 83.29621380846325, 83.96436525612472]\n",
            "nonactive_accuracies [52.56124721603563, 55.45657015590201, 55.233853006681514, 52.11581291759465, 53.229398663697104, 51.89309576837417, 54.56570155902004, 52.338530066815146, 54.12026726057907, 53.00668151447662, 54.342984409799556, 55.233853006681514, 52.56124721603563, 52.338530066815146, 54.342984409799556, 52.78396436525612, 53.00668151447662, 53.89755011135857, 53.67483296213808, 56.347438752783965, 52.78396436525612, 52.338530066815146, 54.12026726057907, 53.89755011135857, 53.4521158129176, 54.78841870824054, 51.44766146993318, 52.338530066815146, 53.00668151447662, 53.00668151447662, 54.56570155902004, 53.67483296213808, 55.45657015590201, 54.56570155902004, 53.4521158129176, 54.12026726057907]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "metadata": {}
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyMfqalTRwiWuiIELJDbCQ7d",
      "mount_file_id": "1SZapm_bYNJDCJi8ECwmjrzaN8-1ruRgA",
      "name": "Logistic.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "5edc29c2ed010d6458d71a83433b383a96a8cbd3efe8531bc90c4b8a5b8bcec9"
    },
    "kernelspec": {
      "display_name": "Python 3.8.2 64-bit",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "metadata": {
      "interpreter": {
        "hash": "5edc29c2ed010d6458d71a83433b383a96a8cbd3efe8531bc90c4b8a5b8bcec9"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}