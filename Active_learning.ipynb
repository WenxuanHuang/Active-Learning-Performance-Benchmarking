{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Logistic.ipynb",
      "provenance": [],
      "mount_file_id": "1SZapm_bYNJDCJi8ECwmjrzaN8-1ruRgA",
      "authorship_tag": "ABX9TyMfqalTRwiWuiIELJDbCQ7d"
    },
    "kernelspec": {
      "name": "python382jvsc74a57bd031f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6",
      "display_name": "Python 3.8.2 64-bit"
    },
    "metadata": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ioi13nGDPDvQ",
        "outputId": "4763f7b3-6c5b-45cb-f411-fd7c6ea8b38f"
      },
      "source": [
        "print(__doc__)\n",
        "\n",
        "import os\n",
        "import time\n",
        "import json\n",
        "import pickle\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.mlab as mlab\n",
        "from scipy.special import expit\n",
        "from scipy import stats\n",
        "from pylab import rcParams\n",
        "\n",
        "from sklearn.utils import check_random_state\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer\n",
        "from sklearn.pipeline import Pipeline, FeatureUnion\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import scale\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "\n",
        "from sklearn import linear_model\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.linear_model import RidgeCV, LassoCV, Ridge, Lasso\n",
        "from sklearn.svm import LinearSVC, SVC\n",
        "from sklearn.ensemble import RandomForestClassifier, \\\n",
        "    GradientBoostingClassifier\n",
        "from sklearn import neighbors\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.mixture import GaussianMixture\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import pairwise_distances_argmin_min\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import average_precision_score\n",
        "\n",
        "\n",
        "# pd.options.display.max_rows = 20\n",
        "pd.options.display.float_format = \"{:.1f}\".format\n",
        "\n",
        "max_queried = 500\n",
        "trainset_size = 1302"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Automatically created module for IPython interactive environment\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        " def data_prep():\n",
        "    data = pd.read_csv(\"https://raw.githubusercontent.com/WenxuanHuang/ML-for-COVID-19-dataset/main/all_training.csv\", sep=',')\n",
        "    # Column selection\n",
        "    df = data.iloc[:,np.r_[3:34]].copy()\n",
        "    # define row and column index\n",
        "    col = df.columns\n",
        "    row = [i for i in range(df.shape[0])]\n",
        "    # define imputer\n",
        "    imputer = IterativeImputer(estimator=linear_model.BayesianRidge(), n_nearest_features=None, imputation_order='ascending')\n",
        "    # fit on the dataset\n",
        "    imputer.fit(df)\n",
        "    # transform the dataset\n",
        "    df_imputed = imputer.transform(df)\n",
        "    # convert back to pandas dataframe and rename back to df_normalized\n",
        "    df = pd.DataFrame(data=df_imputed, index=row, columns=col)\n",
        "    X = df\n",
        "    y = data.target    \n",
        "    # Recursive feature elimination\n",
        "    rdmreg = RandomForestClassifier(n_estimators=100)\n",
        "    # Define the method\n",
        "    rfe = RFE(estimator=rdmreg, n_features_to_select=10)\n",
        "    # Fit the model\n",
        "    rfe = rfe.fit(X, y.values.ravel())\n",
        "    print(rfe.support_)\n",
        "    # Drop columns that failed RFE test\n",
        "    col = df.columns[rfe.support_]\n",
        "    X = X[col]\n",
        "    X = X.to_numpy()\n",
        "    print ('df:', X.shape, y.shape)\n",
        "    return (X, y)\n",
        "\n",
        "\n",
        "def split(train_size):\n",
        "    X_train_full = X[:train_size]\n",
        "    y_train_full = y[:train_size]\n",
        "    X_test = X[train_size:]\n",
        "    y_test = y[train_size:]   \n",
        "    return (X_train_full, y_train_full, X_test, y_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "class BaseModel(object):\n",
        "\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def fit_predict(self):\n",
        "        pass\n",
        "\n",
        "\n",
        "# class SvmModel(BaseModel):\n",
        "\n",
        "#     model_type = 'Support Vector Machine with linear Kernel'\n",
        "#     def fit_predict(self, X_train, y_train, X_val, X_test, c_weight):\n",
        "#         print ('training svm...')\n",
        "#         self.classifier = SVC(\n",
        "#             C=1, \n",
        "#             kernel='linear', \n",
        "#             probability=True,\n",
        "#             class_weight=c_weight\n",
        "#             )\n",
        "#         self.classifier.fit(X_train, y_train)\n",
        "#         self.test_y_predicted = self.classifier.predict(X_test)\n",
        "#         self.val_y_predicted = self.classifier.predict(X_val)\n",
        "#         return (X_train, X_val, X_test, self.val_y_predicted,\n",
        "#                 self.test_y_predicted)\n",
        "\n",
        "# class LogModel(BaseModel):\n",
        "\n",
        "#     model_type = 'Logistic Regression' \n",
        "#     def fit_predict(self, X_train, y_train, X_val, X_test, c_weight):\n",
        "#         print ('training logistic regression...')\n",
        "#         train_samples = X_train.shape[0]\n",
        "#         self.classifier = LogisticRegression(\n",
        "#             C=50. / train_samples,\n",
        "#             penalty='l1',\n",
        "#             solver='liblinear',\n",
        "#             tol=0.1,\n",
        "#             class_weight=c_weight\n",
        "#             )\n",
        "#         self.classifier.fit(X_train, y_train)\n",
        "#         self.test_y_predicted = self.classifier.predict(X_test)\n",
        "#         self.val_y_predicted = self.classifier.predict(X_val)\n",
        "#         return (X_train, X_val, X_test, self.val_y_predicted,\n",
        "#                 self.test_y_predicted)\n",
        "\n",
        "# class RfModel(BaseModel):\n",
        "\n",
        "#     model_type = 'Random Forest'\n",
        "#     def fit_predict(self, X_train, y_train, X_val, X_test, c_weight):\n",
        "#         print ('training random forest...')\n",
        "#         self.classifier = RandomForestClassifier(\n",
        "#             n_estimators=500, \n",
        "#             class_weight=c_weight, \n",
        "#             n_jobs=-1\n",
        "#             )\n",
        "#         self.classifier.fit(X_train, y_train)\n",
        "#         self.test_y_predicted = self.classifier.predict(X_test)\n",
        "#         self.val_y_predicted = self.classifier.predict(X_val)\n",
        "#         return (X_train, X_val, X_test, self.val_y_predicted, self.test_y_predicted)\n",
        "\n",
        "class GDBCModel(BaseModel):\n",
        "\n",
        "    model_type = 'Gradient Boost classifier'\n",
        "    def fit_predict(self, X_train, y_train, X_val, X_test, c_weight):\n",
        "        print ('training GBDC...')\n",
        "        self.classifier = GradientBoostingClassifier(\n",
        "            n_estimators=1200,\n",
        "            max_depth=3,\n",
        "            subsample=0.5,\n",
        "            learning_rate=0.01,\n",
        "            min_samples_leaf=1,\n",
        "            random_state=3\n",
        "            )\n",
        "        self.classifier.fit(X_train, y_train)\n",
        "        self.test_y_predicted = self.classifier.predict(X_test)\n",
        "        self.val_y_predicted = self.classifier.predict(X_val)\n",
        "        return (X_train, X_val, X_test, self.val_y_predicted, self.test_y_predicted)\n",
        "\n",
        "class KnnModel(BaseModel):\n",
        "\n",
        "    model_type = 'Nearest Neighbour classifier'\n",
        "    def fit_predict(self, X_train, y_train, X_val, X_test, c_weight):\n",
        "        print ('training KNN...')\n",
        "        self.classifier = neighbors.KNeighborsClassifier(\n",
        "            n_neighbors = 10,\n",
        "            n_jobs = -1\n",
        "            )\n",
        "        self.classifier.fit(X_train, y_train)\n",
        "        self.test_y_predicted = self.classifier.predict(X_test)\n",
        "        self.val_y_predicted = self.classifier.predict(X_val)\n",
        "        return (X_train, X_val, X_test, self.val_y_predicted, self.test_y_predicted)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "class TrainModel:\n",
        "\n",
        "    def __init__(self, model_object):        \n",
        "        self.accuracies = []\n",
        "        self.model_object = model_object()        \n",
        "\n",
        "    def print_model_type(self):\n",
        "        print (self.model_object.model_type)\n",
        "\n",
        "    # we train normally and use the probabilities to select the most uncertain samples\n",
        "    def train(self, X_train, y_train, X_val, X_test, c_weight):\n",
        "        print ('Train set:', X_train.shape)\n",
        "        print ('Validation set:', X_val.shape)\n",
        "        print ('Test set:', X_test.shape)\n",
        "        t0 = time.time()\n",
        "        (X_train, X_val, X_test, self.val_y_predicted,\n",
        "         self.test_y_predicted) = \\\n",
        "            self.model_object.fit_predict(X_train, y_train, X_val, X_test, c_weight)\n",
        "        self.run_time = time.time() - t0\n",
        "        return (X_train, X_val, X_test)\n",
        "\n",
        "    # we want accuracy only for the test set\n",
        "    def get_test_accuracy(self, i, y_test):\n",
        "        classif_rate = np.mean(self.test_y_predicted.ravel() == y_test.ravel()) * 100\n",
        "        self.accuracies.append(classif_rate)               \n",
        "        print('--------------------------------')\n",
        "        print('Iteration:',i)\n",
        "        print('--------------------------------')\n",
        "        print('y-test set:',y_test.shape)\n",
        "        print('Training run in %.3f s' % self.run_time,'\\n')\n",
        "        print(\"Accuracy rate is %f \" % (classif_rate))    \n",
        "        print(\"Classification report for %s:\\n%s\\n\" % (self.model_object.classifier, metrics.classification_report(y_test, self.test_y_predicted)))\n",
        "        print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(y_test, self.test_y_predicted))\n",
        "        print('--------------------------------')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "class BaseSelectionFunction(object):\n",
        "\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def select(self):\n",
        "        pass\n",
        "\n",
        "\n",
        "class RandomSelection(BaseSelectionFunction):\n",
        "\n",
        "    @staticmethod\n",
        "    def select(probas_val, initial_labeled_samples):\n",
        "        random_state = check_random_state(0)\n",
        "        selection = np.random.choice(probas_val.shape[0], initial_labeled_samples, replace=False)\n",
        "        print('uniques chosen:',np.unique(selection).shape[0],'<= should be equal to:',initial_labeled_samples)\n",
        "        return selection\n",
        "\n",
        "\n",
        "class EntropySelection(BaseSelectionFunction):\n",
        "\n",
        "    @staticmethod\n",
        "    def select(probas_val, initial_labeled_samples):\n",
        "        e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
        "        selection = (np.argsort(e)[::-1])[:initial_labeled_samples]\n",
        "        return selection\n",
        "\n",
        "class MinStdSelection(BaseSelectionFunction):\n",
        "\n",
        "    # select the samples where the std is smallest. There is uncertainty regarding the relevant class\n",
        "    # and then train on these \"hard\" to classify samples.\n",
        "    @staticmethod\n",
        "    def select(probas_val, initial_labeled_samples):\n",
        "        std = np.std(probas_val * 100, axis=1)\n",
        "        selection = std.argsort()[:initial_labeled_samples]\n",
        "        selection = selection.astype('int64')\n",
        "        print('std',std.shape,std)\n",
        "        print('selection',selection, selection.shape, std[selection])\n",
        "        return selection\n",
        "      \n",
        "      \n",
        "class MarginSamplingSelection(BaseSelectionFunction):\n",
        "\n",
        "    @staticmethod\n",
        "    def select(probas_val, initial_labeled_samples):\n",
        "        rev = np.sort(probas_val, axis=1)[:, ::-1]\n",
        "        values = rev[:, 0] - rev[:, 1]\n",
        "        selection = np.argsort(values)[:initial_labeled_samples]\n",
        "        return selection\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Normalize(object):\n",
        "    \n",
        "    def normalize(self, X_train, X_val, X_test):\n",
        "        self.scaler = RobustScaler()\n",
        "        X_train = self.scaler.fit_transform(X_train)\n",
        "        X_val   = self.scaler.transform(X_val)\n",
        "        X_test  = self.scaler.transform(X_test)\n",
        "        return (X_train, X_val, X_test) \n",
        "    \n",
        "    def inverse(self, X_train, X_val, X_test):\n",
        "        X_train = self.scaler.inverse_transform(X_train)\n",
        "        X_val   = self.scaler.inverse_transform(X_val)\n",
        "        X_test  = self.scaler.inverse_transform(X_test)\n",
        "        return (X_train, X_val, X_test) "
      ]
    },
    {
      "source": [
        "def get_k_random_samples(initial_labeled_samples, X_train_full,\n",
        "                         y_train_full):\n",
        "    random_state = check_random_state(0)\n",
        "    permutation = np.random.choice(trainset_size,\n",
        "                                   initial_labeled_samples,\n",
        "                                   replace=False)\n",
        "    print ()\n",
        "    print ('initial random chosen samples', permutation.shape),\n",
        "    X_train = X_train_full[permutation]\n",
        "    y_train = y_train_full[permutation]\n",
        "    X_train = X_train.reshape((X_train.shape[0], -1))\n",
        "    bin_count = np.bincount(y_train.astype('int64'))\n",
        "    unique = np.unique(y_train.astype('int64'))\n",
        "    print (\n",
        "        'initial train set:',\n",
        "        X_train.shape,\n",
        "        y_train.shape,\n",
        "        'unique(labels):',\n",
        "        bin_count,\n",
        "        unique,\n",
        "        )\n",
        "    return (permutation, X_train, y_train)"
      ],
      "cell_type": "code",
      "metadata": {},
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [],
      "source": [
        "class TheAlgorithm(object):\n",
        "\n",
        "    accuracies = []\n",
        "\n",
        "    def __init__(self, initial_labeled_samples, model_object, selection_function):\n",
        "        self.initial_labeled_samples = initial_labeled_samples\n",
        "        self.model_object = model_object\n",
        "        self.sample_selection_function = selection_function\n",
        "\n",
        "    def run(self, X_train_full, y_train_full, X_test, y_test):\n",
        "\n",
        "        # initialize process by applying base learner to labeled training data set to obtain Classifier\n",
        "        (permutation, X_train, y_train) = \\\n",
        "            get_k_random_samples(self.initial_labeled_samples,\n",
        "                                 X_train_full, y_train_full)\n",
        "        self.queried = self.initial_labeled_samples\n",
        "        self.samplecount = [self.initial_labeled_samples]\n",
        "\n",
        "        # assign the val set the rest of the 'unlabelled' training data\n",
        "        X_val = np.array([])\n",
        "        y_val = np.array([])\n",
        "        X_val = np.copy(X_train_full)\n",
        "        X_val = np.delete(X_val, permutation, axis=0)\n",
        "        y_val = np.copy(y_train_full)\n",
        "        y_val = np.delete(y_val, permutation, axis=0)\n",
        "        print ('Val set:', X_val.shape, y_val.shape, permutation.shape)\n",
        "        print ()\n",
        "\n",
        "        # normalize data\n",
        "        normalizer = Normalize()\n",
        "        X_train, X_val, X_test = normalizer.normalize(X_train, X_val, X_test)   \n",
        "        self.clf_model = TrainModel(self.model_object)\n",
        "        (X_train, X_val, X_test) = self.clf_model.train(X_train, y_train, X_val, X_test, 'balanced')\n",
        "        active_iteration = 1\n",
        "        self.clf_model.get_test_accuracy(1, y_test)\n",
        "\n",
        "        while self.queried < max_queried:\n",
        "\n",
        "            active_iteration += 1\n",
        "\n",
        "            # get validation probabilities\n",
        "            probas_val = \\\n",
        "                self.clf_model.model_object.classifier.predict_proba(X_val)\n",
        "            print ('val predicted:',\n",
        "                   self.clf_model.val_y_predicted.shape,\n",
        "                   self.clf_model.val_y_predicted)\n",
        "            print ('probabilities:', probas_val.shape, '\\n',\n",
        "                   np.argmax(probas_val, axis=1))\n",
        "\n",
        "            # select samples using a selection function\n",
        "            uncertain_samples = \\\n",
        "                self.sample_selection_function.select(probas_val, self.initial_labeled_samples)\n",
        "\n",
        "            # normalization needs to be inversed and recalculated based on the new train and test set.\n",
        "            X_train, X_val, X_test = normalizer.inverse(X_train, X_val, X_test)   \n",
        "\n",
        "            # get the uncertain samples from the validation set\n",
        "            print ('trainset before adding uncertain samples', X_train.shape, y_train.shape)\n",
        "            X_train = np.concatenate((X_train, X_val[uncertain_samples]))\n",
        "            y_train = np.concatenate((y_train, y_val[uncertain_samples]))\n",
        "            print ('trainset after adding uncertain samples', X_train.shape, y_train.shape)\n",
        "            self.samplecount.append(X_train.shape[0])\n",
        "\n",
        "            bin_count = np.bincount(y_train.astype('int64'))\n",
        "            unique = np.unique(y_train.astype('int64'))\n",
        "            print (\n",
        "                'updated train set:',\n",
        "                X_train.shape,\n",
        "                y_train.shape,\n",
        "                'unique(labels):',\n",
        "                bin_count,\n",
        "                unique,\n",
        "                )\n",
        "\n",
        "            X_val = np.delete(X_val, uncertain_samples, axis=0)\n",
        "            y_val = np.delete(y_val, uncertain_samples, axis=0)\n",
        "            print ('val set:', X_val.shape, y_val.shape)\n",
        "            print ()\n",
        "\n",
        "            # normalize again after creating the 'new' train/test sets\n",
        "            normalizer = Normalize()\n",
        "            X_train, X_val, X_test = normalizer.normalize(X_train, X_val, X_test)               \n",
        "\n",
        "            self.queried += self.initial_labeled_samples\n",
        "            (X_train, X_val, X_test) = self.clf_model.train(X_train, y_train, X_val, X_test, 'balanced')\n",
        "            self.clf_model.get_test_accuracy(active_iteration, y_test)\n",
        "\n",
        "        print ('final active learning accuracies',\n",
        "               self.clf_model.accuracies)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ True False False False False False  True False  True  True False False\n",
            " False  True  True False False False False False False False False False\n",
            "  True False  True  True False  True False]\n",
            "df: (1736, 10) (1736,)\n",
            "train: (1302, 10) (1302,)\n",
            "test : (434, 10) (434,)\n",
            "unique classes 2\n",
            "stopping at: 500\n",
            "Count = 1, using model = GDBCModel, selection_function = RandomSelection, k = 250, iteration = 0.\n",
            "\n",
            "initial random chosen samples (250,)\n",
            "initial train set: (250, 10) (250,) unique(labels): [119 131] [0 1]\n",
            "Val set: (1052, 10) (1052,) (250,)\n",
            "\n",
            "Train set: (250, 10)\n",
            "Validation set: (1052, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.923 s \n",
            "\n",
            "Accuracy rate is 78.341014 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.90      0.86       321\n",
            "           1       0.61      0.46      0.53       113\n",
            "\n",
            "    accuracy                           0.78       434\n",
            "   macro avg       0.72      0.68      0.69       434\n",
            "weighted avg       0.77      0.78      0.77       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[288  33]\n",
            " [ 61  52]]\n",
            "--------------------------------\n",
            "val predicted: (1052,) [1 1 0 ... 0 0 0]\n",
            "probabilities: (1052, 2) \n",
            " [1 1 0 ... 0 0 0]\n",
            "uniques chosen: 250 <= should be equal to: 250\n",
            "trainset before adding uncertain samples (250, 10) (250,)\n",
            "trainset after adding uncertain samples (500, 10) (500,)\n",
            "updated train set: (500, 10) (500,) unique(labels): [236 264] [0 1]\n",
            "val set: (802, 10) (802,)\n",
            "\n",
            "Train set: (500, 10)\n",
            "Validation set: (802, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.226 s \n",
            "\n",
            "Accuracy rate is 79.953917 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.90      0.87       321\n",
            "           1       0.64      0.52      0.58       113\n",
            "\n",
            "    accuracy                           0.80       434\n",
            "   macro avg       0.74      0.71      0.72       434\n",
            "weighted avg       0.79      0.80      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[288  33]\n",
            " [ 54  59]]\n",
            "--------------------------------\n",
            "final active learning accuracies [78.3410138248848, 79.95391705069125]\n",
            "saved /Users/wenxuanhuang/Documents/Repo/ML-for-COVID-19-dataset/Results/Active-learning-experiment-1.pkl /Users/wenxuanhuang/Documents/Repo/ML-for-COVID-19-dataset ['Decision_tree.ipynb', 'dec_git.png', 'Logit_default_f10.pdf', 'Logistic.ipynb', 'SVC.ipynb', 'RF_f5e50_featureimp.pdf', 'log_al.png', 'dec_git.pdf', '.DS_Store', 'log_git.png', 'svm_git.png', 'Logistic_Scikit.ipynb', 'knn_git.pdf', 'knn_git.png', 'rf_al.png', 'Best classifier_RF_f5e50.pdf', 'KNN.ipynb', 'GBDC.ipynb', 'rf_git.png', 'README.md', 'all_training.csv', 'Results', 'svm_al.png', 'Log_ROC.png', 'Logit_default_f7(p_removal).pdf', 'Active_learning.ipynb', 'Random_forest.ipynb', 'Model_select.ipynb', 'gdbc_git.png', '.git', '.vscode', 'Untitled', 'RF_f5e50_modelselect.pdf', 'Logit_default_f8(std_removal).pdf']\n",
            "\n",
            "---------------------------- FINISHED ---------------------------\n",
            "\n",
            "Count = 2, using model = GDBCModel, selection_function = RandomSelection, k = 125, iteration = 0.\n",
            "\n",
            "initial random chosen samples (125,)\n",
            "initial train set: (125, 10) (125,) unique(labels): [51 74] [0 1]\n",
            "Val set: (1177, 10) (1177,) (125,)\n",
            "\n",
            "Train set: (125, 10)\n",
            "Validation set: (1177, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.760 s \n",
            "\n",
            "Accuracy rate is 72.580645 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.76      0.80       321\n",
            "           1       0.48      0.64      0.55       113\n",
            "\n",
            "    accuracy                           0.73       434\n",
            "   macro avg       0.67      0.70      0.68       434\n",
            "weighted avg       0.76      0.73      0.74       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[243  78]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "val predicted: (1177,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1177, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "uniques chosen: 125 <= should be equal to: 125\n",
            "trainset before adding uncertain samples (125, 10) (125,)\n",
            "trainset after adding uncertain samples (250, 10) (250,)\n",
            "updated train set: (250, 10) (250,) unique(labels): [110 140] [0 1]\n",
            "val set: (1052, 10) (1052,)\n",
            "\n",
            "Train set: (250, 10)\n",
            "Validation set: (1052, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.937 s \n",
            "\n",
            "Accuracy rate is 72.580645 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.79      0.81       321\n",
            "           1       0.48      0.55      0.51       113\n",
            "\n",
            "    accuracy                           0.73       434\n",
            "   macro avg       0.65      0.67      0.66       434\n",
            "weighted avg       0.74      0.73      0.73       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[253  68]\n",
            " [ 51  62]]\n",
            "--------------------------------\n",
            "val predicted: (1052,) [0 1 0 ... 1 0 0]\n",
            "probabilities: (1052, 2) \n",
            " [0 1 0 ... 1 0 0]\n",
            "uniques chosen: 125 <= should be equal to: 125\n",
            "trainset before adding uncertain samples (250, 10) (250,)\n",
            "trainset after adding uncertain samples (375, 10) (375,)\n",
            "updated train set: (375, 10) (375,) unique(labels): [175 200] [0 1]\n",
            "val set: (927, 10) (927,)\n",
            "\n",
            "Train set: (375, 10)\n",
            "Validation set: (927, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 3\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.111 s \n",
            "\n",
            "Accuracy rate is 76.036866 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.85      0.84       321\n",
            "           1       0.54      0.51      0.53       113\n",
            "\n",
            "    accuracy                           0.76       434\n",
            "   macro avg       0.69      0.68      0.68       434\n",
            "weighted avg       0.76      0.76      0.76       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[272  49]\n",
            " [ 55  58]]\n",
            "--------------------------------\n",
            "val predicted: (927,) [1 0 0 1 1 1 0 0 0 0 1 1 0 1 1 0 0 0 0 0 0 1 0 1 1 0 1 1 1 0 0 0 1 1 0 0 0\n",
            " 1 1 0 0 0 1 1 1 1 1 0 0 0 1 1 1 1 1 0 1 0 0 1 1 0 0 1 1 1 1 1 1 0 1 1 1 0\n",
            " 0 0 1 0 0 0 1 1 0 0 1 1 0 1 1 1 0 1 1 0 0 0 0 1 1 0 1 1 0 0 1 1 1 1 0 0 1\n",
            " 1 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 1 1 0 0 1 1 0 0 0 1 1 1 1 1 0 1 0 0\n",
            " 1 0 1 1 1 0 0 1 0 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 0 0 0 1 1 0\n",
            " 0 0 1 1 1 0 1 0 0 0 1 0 1 1 0 1 0 1 0 1 0 1 1 0 0 1 0 0 0 0 1 0 1 0 1 1 1\n",
            " 1 1 1 1 0 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 0 0 1 1 0 1 1 0\n",
            " 0 0 0 1 1 1 1 0 0 0 0 1 1 0 1 0 1 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 1 1\n",
            " 0 1 1 1 0 0 1 0 1 1 0 1 0 0 0 0 0 1 1 0 0 1 0 0 1 0 1 0 0 1 1 0 1 0 1 0 1\n",
            " 1 1 0 0 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 0 0 1 1 0 1 1 1 1\n",
            " 0 1 0 1 1 0 0 1 1 0 1 0 0 1 1 1 0 1 1 1 1 0 1 1 0 1 0 1 1 1 1 1 0 0 1 1 1\n",
            " 1 1 1 0 1 1 0 0 0 0 0 1 0 0 1 0 1 1 1 1 0 1 0 1 1 0 1 0 1 1 1 0 0 1 1 1 1\n",
            " 0 1 0 0 1 1 1 0 0 0 0 0 0 0 0 1 0 0 1 0 1 1 1 0 1 1 1 1 1 0 1 0 0 1 0 1 1\n",
            " 1 1 1 1 1 1 1 0 0 1 1 0 0 1 0 0 1 1 1 1 1 0 1 1 0 1 0 0 0 1 1 0 0 1 1 0 1\n",
            " 1 0 0 0 1 1 0 1 1 1 0 0 1 1 0 1 1 1 1 1 0 0 0 0 0 0 1 0 0 0 0 0 1 1 1 0 1\n",
            " 1 1 0 1 1 0 1 1 1 0 1 1 0 0 1 0 0 1 0 0 1 0 1 1 1 1 1 0 0 1 0 1 1 1 1 0 1\n",
            " 1 1 1 0 1 1 0 1 0 0 1 1 0 1 1 1 0 0 1 0 1 1 1 1 1 1 0 1 1 0 1 1 1 0 1 1 0\n",
            " 1 1 1 0 1 0 0 1 0 1 1 0 1 1 1 0 0 1 0 0 0 1 0 0 1 0 0 1 0 0 0 1 0 0 1 1 0\n",
            " 1 0 1 0 1 1 1 0 0 1 1 0 0 1 1 0 1 0 1 0 1 1 0 1 1 1 1 0 0 0 0 0 0 0 1 1 1\n",
            " 1 0 1 0 1 0 0 0 1 1 0 1 1 0 0 1 1 0 0 0 0 1 0 0 0 1 1 0 0 1 1 0 0 0 0 1 0\n",
            " 0 0 1 1 0 0 1 1 1 0 1 1 0 0 0 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 0 0 0 0\n",
            " 1 1 1 1 0 1 0 1 1 1 1 0 1 1 1 0 1 0 1 0 0 0 1 0 1 1 0 1 0 1 1 0 0 0 1 1 0\n",
            " 0 0 0 0 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 0 0 1 1 1 0 1 1 1 0 0 1 1 1 1 1\n",
            " 1 1 0 1 1 0 0 1 1 0 1 0 1 1 1 0 0 1 0 0 1 1 0 1 1 1 1 1 1 1 1 0 1 1 0 0 1\n",
            " 1 0 0 0 0 1 1 0 1 1 0 0 0 0 1 0 0 1 0 0 0 0 1 1 0 0 1 0 1 1 0 1 1 0 1 1 1\n",
            " 0 0]\n",
            "probabilities: (927, 2) \n",
            " [1 0 0 1 1 1 0 0 0 0 1 1 0 1 1 0 0 0 0 0 0 1 0 1 1 0 1 1 1 0 0 0 1 1 0 0 0\n",
            " 1 1 0 0 0 1 1 1 1 1 0 0 0 1 1 1 1 1 0 1 0 0 1 1 0 0 1 1 1 1 1 1 0 1 1 1 0\n",
            " 0 0 1 0 0 0 1 1 0 0 1 1 0 1 1 1 0 1 1 0 0 0 0 1 1 0 1 1 0 0 1 1 1 1 0 0 1\n",
            " 1 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 1 1 0 0 1 1 0 0 0 1 1 1 1 1 0 1 0 0\n",
            " 1 0 1 1 1 0 0 1 0 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 0 0 0 1 1 0\n",
            " 0 0 1 1 1 0 1 0 0 0 1 0 1 1 0 1 0 1 0 1 0 1 1 0 0 1 0 0 0 0 1 0 1 0 1 1 1\n",
            " 1 1 1 1 0 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 0 0 1 1 0 1 1 0\n",
            " 0 0 0 1 1 1 1 0 0 0 0 1 1 0 1 0 1 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 1 1\n",
            " 0 1 1 1 0 0 1 0 1 1 0 1 0 0 0 0 0 1 1 0 0 1 0 0 1 0 1 0 0 1 1 0 1 0 1 0 1\n",
            " 1 1 0 0 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 0 0 1 1 0 1 1 1 1\n",
            " 0 1 0 1 1 0 0 1 1 0 1 0 0 1 1 1 0 1 1 1 1 0 1 1 0 1 0 1 1 1 1 1 0 0 1 1 1\n",
            " 1 1 1 0 1 1 0 0 0 0 0 1 0 0 1 0 1 1 1 1 0 1 0 1 1 0 1 0 1 1 1 0 0 1 1 1 1\n",
            " 0 1 0 0 1 1 1 0 0 0 0 0 0 0 0 1 0 0 1 0 1 1 1 0 1 1 1 1 1 0 1 0 0 1 0 1 1\n",
            " 1 1 1 1 1 1 1 0 0 1 1 0 0 1 0 0 1 1 1 1 1 0 1 1 0 1 0 0 0 1 1 0 0 1 1 0 1\n",
            " 1 0 0 0 1 1 0 1 1 1 0 0 1 1 0 1 1 1 1 1 0 0 0 0 0 0 1 0 0 0 0 0 1 1 1 0 1\n",
            " 1 1 0 1 1 0 1 1 1 0 1 1 0 0 1 0 0 1 0 0 1 0 1 1 1 1 1 0 0 1 0 1 1 1 1 0 1\n",
            " 1 1 1 0 1 1 0 1 0 0 1 1 0 1 1 1 0 0 1 0 1 1 1 1 1 1 0 1 1 0 1 1 1 0 1 1 0\n",
            " 1 1 1 0 1 0 0 1 0 1 1 0 1 1 1 0 0 1 0 0 0 1 0 0 1 0 0 1 0 0 0 1 0 0 1 1 0\n",
            " 1 0 1 0 1 1 1 0 0 1 1 0 0 1 1 0 1 0 1 0 1 1 0 1 1 1 1 0 0 0 0 0 0 0 1 1 1\n",
            " 1 0 1 0 1 0 0 0 1 1 0 1 1 0 0 1 1 0 0 0 0 1 0 0 0 1 1 0 0 1 1 0 0 0 0 1 0\n",
            " 0 0 1 1 0 0 1 1 1 0 1 1 0 0 0 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 0 0 0 0\n",
            " 1 1 1 1 0 1 0 1 1 1 1 0 1 1 1 0 1 0 1 0 0 0 1 0 1 1 0 1 0 1 1 0 0 0 1 1 0\n",
            " 0 0 0 0 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 0 0 1 1 1 0 1 1 1 0 0 1 1 1 1 1\n",
            " 1 1 0 1 1 0 0 1 1 0 1 0 1 1 1 0 0 1 0 0 1 1 0 1 1 1 1 1 1 1 1 0 1 1 0 0 1\n",
            " 1 0 0 0 0 1 1 0 1 1 0 0 0 0 1 0 0 1 0 0 0 0 1 1 0 0 1 0 1 1 0 1 1 0 1 1 1\n",
            " 0 0]\n",
            "uniques chosen: 125 <= should be equal to: 125\n",
            "trainset before adding uncertain samples (375, 10) (375,)\n",
            "trainset after adding uncertain samples (500, 10) (500,)\n",
            "updated train set: (500, 10) (500,) unique(labels): [223 277] [0 1]\n",
            "val set: (802, 10) (802,)\n",
            "\n",
            "Train set: (500, 10)\n",
            "Validation set: (802, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 4\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.266 s \n",
            "\n",
            "Accuracy rate is 76.267281 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.84      0.84       321\n",
            "           1       0.54      0.55      0.55       113\n",
            "\n",
            "    accuracy                           0.76       434\n",
            "   macro avg       0.69      0.69      0.69       434\n",
            "weighted avg       0.76      0.76      0.76       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[269  52]\n",
            " [ 51  62]]\n",
            "--------------------------------\n",
            "final active learning accuracies [72.58064516129032, 72.58064516129032, 76.036866359447, 76.26728110599078]\n",
            "saved /Users/wenxuanhuang/Documents/Repo/ML-for-COVID-19-dataset/Results/Active-learning-experiment-2.pkl /Users/wenxuanhuang/Documents/Repo/ML-for-COVID-19-dataset ['Decision_tree.ipynb', 'dec_git.png', 'Logit_default_f10.pdf', 'Logistic.ipynb', 'SVC.ipynb', 'RF_f5e50_featureimp.pdf', 'log_al.png', 'dec_git.pdf', '.DS_Store', 'log_git.png', 'svm_git.png', 'Logistic_Scikit.ipynb', 'knn_git.pdf', 'knn_git.png', 'rf_al.png', 'Best classifier_RF_f5e50.pdf', 'KNN.ipynb', 'GBDC.ipynb', 'rf_git.png', 'README.md', 'all_training.csv', 'Results', 'svm_al.png', 'Log_ROC.png', 'Logit_default_f7(p_removal).pdf', 'Active_learning.ipynb', 'Random_forest.ipynb', 'Model_select.ipynb', 'gdbc_git.png', '.git', '.vscode', 'Untitled', 'RF_f5e50_modelselect.pdf', 'Logit_default_f8(std_removal).pdf']\n",
            "\n",
            "---------------------------- FINISHED ---------------------------\n",
            "\n",
            "Count = 3, using model = GDBCModel, selection_function = RandomSelection, k = 50, iteration = 0.\n",
            "\n",
            "initial random chosen samples (50,)\n",
            "initial train set: (50, 10) (50,) unique(labels): [22 28] [0 1]\n",
            "Val set: (1252, 10) (1252,) (50,)\n",
            "\n",
            "Train set: (50, 10)\n",
            "Validation set: (1252, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.618 s \n",
            "\n",
            "Accuracy rate is 69.354839 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.75      0.78       321\n",
            "           1       0.43      0.54      0.48       113\n",
            "\n",
            "    accuracy                           0.69       434\n",
            "   macro avg       0.63      0.64      0.63       434\n",
            "weighted avg       0.72      0.69      0.70       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[240  81]\n",
            " [ 52  61]]\n",
            "--------------------------------\n",
            "val predicted: (1252,) [0 1 1 ... 0 0 1]\n",
            "probabilities: (1252, 2) \n",
            " [0 1 1 ... 0 0 1]\n",
            "uniques chosen: 50 <= should be equal to: 50\n",
            "trainset before adding uncertain samples (50, 10) (50,)\n",
            "trainset after adding uncertain samples (100, 10) (100,)\n",
            "updated train set: (100, 10) (100,) unique(labels): [51 49] [0 1]\n",
            "val set: (1202, 10) (1202,)\n",
            "\n",
            "Train set: (100, 10)\n",
            "Validation set: (1202, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.722 s \n",
            "\n",
            "Accuracy rate is 76.728111 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.87      0.85       321\n",
            "           1       0.56      0.49      0.52       113\n",
            "\n",
            "    accuracy                           0.77       434\n",
            "   macro avg       0.69      0.68      0.68       434\n",
            "weighted avg       0.76      0.77      0.76       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[278  43]\n",
            " [ 58  55]]\n",
            "--------------------------------\n",
            "val predicted: (1202,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1202, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "uniques chosen: 50 <= should be equal to: 50\n",
            "trainset before adding uncertain samples (100, 10) (100,)\n",
            "trainset after adding uncertain samples (150, 10) (150,)\n",
            "updated train set: (150, 10) (150,) unique(labels): [73 77] [0 1]\n",
            "val set: (1152, 10) (1152,)\n",
            "\n",
            "Train set: (150, 10)\n",
            "Validation set: (1152, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 3\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.798 s \n",
            "\n",
            "Accuracy rate is 78.341014 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.87      0.86       321\n",
            "           1       0.59      0.53      0.56       113\n",
            "\n",
            "    accuracy                           0.78       434\n",
            "   macro avg       0.72      0.70      0.71       434\n",
            "weighted avg       0.78      0.78      0.78       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[280  41]\n",
            " [ 53  60]]\n",
            "--------------------------------\n",
            "val predicted: (1152,) [0 1 1 ... 0 0 1]\n",
            "probabilities: (1152, 2) \n",
            " [0 1 1 ... 0 0 1]\n",
            "uniques chosen: 50 <= should be equal to: 50\n",
            "trainset before adding uncertain samples (150, 10) (150,)\n",
            "trainset after adding uncertain samples (200, 10) (200,)\n",
            "updated train set: (200, 10) (200,) unique(labels): [ 91 109] [0 1]\n",
            "val set: (1102, 10) (1102,)\n",
            "\n",
            "Train set: (200, 10)\n",
            "Validation set: (1102, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 4\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.872 s \n",
            "\n",
            "Accuracy rate is 78.571429 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.87      0.86       321\n",
            "           1       0.60      0.54      0.57       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.72      0.71      0.71       434\n",
            "weighted avg       0.78      0.79      0.78       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[280  41]\n",
            " [ 52  61]]\n",
            "--------------------------------\n",
            "val predicted: (1102,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1102, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "uniques chosen: 50 <= should be equal to: 50\n",
            "trainset before adding uncertain samples (200, 10) (200,)\n",
            "trainset after adding uncertain samples (250, 10) (250,)\n",
            "updated train set: (250, 10) (250,) unique(labels): [119 131] [0 1]\n",
            "val set: (1052, 10) (1052,)\n",
            "\n",
            "Train set: (250, 10)\n",
            "Validation set: (1052, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 5\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.913 s \n",
            "\n",
            "Accuracy rate is 78.801843 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86       321\n",
            "           1       0.61      0.52      0.56       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.72      0.70      0.71       434\n",
            "weighted avg       0.78      0.79      0.78       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[283  38]\n",
            " [ 54  59]]\n",
            "--------------------------------\n",
            "val predicted: (1052,) [1 1 0 ... 0 0 0]\n",
            "probabilities: (1052, 2) \n",
            " [1 1 0 ... 0 0 0]\n",
            "uniques chosen: 50 <= should be equal to: 50\n",
            "trainset before adding uncertain samples (250, 10) (250,)\n",
            "trainset after adding uncertain samples (300, 10) (300,)\n",
            "updated train set: (300, 10) (300,) unique(labels): [140 160] [0 1]\n",
            "val set: (1002, 10) (1002,)\n",
            "\n",
            "Train set: (300, 10)\n",
            "Validation set: (1002, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 6\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.987 s \n",
            "\n",
            "Accuracy rate is 79.953917 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.90      0.87       321\n",
            "           1       0.64      0.51      0.57       113\n",
            "\n",
            "    accuracy                           0.80       434\n",
            "   macro avg       0.74      0.71      0.72       434\n",
            "weighted avg       0.79      0.80      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[289  32]\n",
            " [ 55  58]]\n",
            "--------------------------------\n",
            "val predicted: (1002,) [1 1 1 ... 0 0 0]\n",
            "probabilities: (1002, 2) \n",
            " [1 1 1 ... 0 0 0]\n",
            "uniques chosen: 50 <= should be equal to: 50\n",
            "trainset before adding uncertain samples (300, 10) (300,)\n",
            "trainset after adding uncertain samples (350, 10) (350,)\n",
            "updated train set: (350, 10) (350,) unique(labels): [160 190] [0 1]\n",
            "val set: (952, 10) (952,)\n",
            "\n",
            "Train set: (350, 10)\n",
            "Validation set: (952, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 7\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.048 s \n",
            "\n",
            "Accuracy rate is 79.262673 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86       321\n",
            "           1       0.62      0.54      0.58       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.73      0.71      0.72       434\n",
            "weighted avg       0.79      0.79      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[283  38]\n",
            " [ 52  61]]\n",
            "--------------------------------\n",
            "val predicted: (952,) [1 0 0 1 0 0 0 0 0 0 1 1 1 0 1 0 0 0 0 1 0 1 1 1 0 0 0 1 0 0 0 0 0 1 0 0 0\n",
            " 1 0 1 1 1 1 0 1 0 0 1 1 1 0 1 1 0 0 1 0 0 0 1 1 1 1 1 1 0 0 1 0 0 0 0 0 0\n",
            " 1 0 0 0 1 1 1 1 1 1 0 0 1 1 1 0 0 0 0 1 0 1 0 1 0 1 0 1 1 1 1 0 0 0 0 1 0\n",
            " 0 0 0 0 1 1 1 0 1 1 0 1 0 1 0 1 1 1 1 1 1 1 1 0 1 0 1 1 0 0 1 1 1 1 0 0 0\n",
            " 1 0 0 0 0 1 1 1 0 1 1 1 0 1 1 0 0 1 1 0 0 1 1 0 0 0 0 1 0 0 0 0 1 1 0 0 1\n",
            " 0 0 0 1 1 0 1 1 0 1 1 0 1 1 0 1 1 0 1 0 1 0 0 0 0 1 1 0 1 1 1 0 1 1 1 1 0\n",
            " 1 0 1 1 1 0 1 1 1 1 0 1 1 1 0 0 1 0 1 1 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1 0 0\n",
            " 1 1 1 1 1 1 0 0 0 0 0 1 1 1 0 1 0 0 1 0 0 1 0 1 0 0 1 0 0 0 0 0 1 1 1 1 0\n",
            " 1 1 0 0 1 1 1 0 1 0 0 1 0 1 0 0 1 0 1 1 0 1 1 0 0 0 1 0 1 1 0 0 1 1 1 0 1\n",
            " 0 1 1 0 1 1 0 1 1 1 1 0 1 1 0 0 1 0 0 0 1 0 1 1 0 1 1 0 1 1 0 0 0 1 0 1 0\n",
            " 1 1 1 1 0 1 1 1 0 1 0 1 1 0 1 1 1 1 0 1 0 0 1 1 0 0 0 0 1 1 0 1 0 0 1 0 0\n",
            " 1 0 1 0 1 0 0 0 1 0 1 0 0 0 0 1 1 1 1 0 0 1 1 1 1 0 0 0 0 0 1 1 1 1 0 1 0\n",
            " 0 1 1 0 1 0 0 1 0 0 1 0 0 1 1 0 1 1 1 0 1 0 0 1 1 1 0 0 1 1 1 1 1 0 1 1 1\n",
            " 1 1 1 1 0 0 0 1 1 1 0 0 1 0 1 0 1 1 0 1 0 0 1 0 0 0 1 0 0 1 0 1 1 0 0 0 1\n",
            " 1 1 1 1 0 1 1 1 1 1 1 0 0 0 1 0 1 1 1 1 1 0 1 1 1 1 0 1 0 0 0 0 0 0 1 0 1\n",
            " 0 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 0 0 1 0 0 0 1 0 0 0 0 1 1 1 1 1 0 0\n",
            " 1 1 0 0 0 0 0 1 1 0 1 1 0 1 0 1 0 1 1 0 1 1 1 0 1 1 0 1 1 1 1 0 0 1 1 0 1\n",
            " 1 0 1 1 0 0 0 1 1 0 1 1 1 0 1 0 1 1 0 0 1 0 0 1 1 1 0 0 1 0 1 0 0 1 0 0 1\n",
            " 0 0 1 1 0 0 0 0 1 1 1 1 0 0 1 0 1 0 0 1 1 1 1 0 0 1 0 0 0 1 1 1 1 1 1 1 0\n",
            " 0 0 1 1 0 1 1 0 1 1 0 1 0 0 1 0 1 0 0 1 0 0 1 0 1 1 0 0 1 0 0 0 1 0 0 1 1\n",
            " 1 1 0 0 0 1 1 0 1 0 1 0 1 1 1 0 0 0 0 1 0 0 0 0 1 1 1 0 0 1 0 1 1 1 1 0 0\n",
            " 1 1 0 1 0 0 1 1 0 1 1 1 1 0 1 0 1 0 1 0 1 1 1 1 0 0 0 0 0 1 1 0 0 1 0 1 1\n",
            " 0 1 0 1 0 1 0 0 0 1 1 1 0 0 1 1 0 0 0 1 0 1 0 0 1 1 1 0 0 1 1 1 1 1 1 1 0\n",
            " 0 1 1 0 1 1 1 0 1 0 1 1 0 1 1 0 0 1 0 0 1 1 1 1 1 1 0 1 1 0 1 1 0 1 0 0 0\n",
            " 1 1 1 0 1 0 0 0 1 1 0 0 1 1 0 0 1 1 1 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 0 1 0\n",
            " 1 0 1 1 1 0 0 1 1 1 1 1 1 1 1 1 0 0 0 1 0 1 1 1 0 0 0]\n",
            "probabilities: (952, 2) \n",
            " [1 0 0 1 0 0 0 0 0 0 1 1 1 0 1 0 0 0 0 1 0 1 1 1 0 0 0 1 0 0 0 0 0 1 0 0 0\n",
            " 1 0 1 1 1 1 0 1 0 0 1 1 1 0 1 1 0 0 1 0 0 0 1 1 1 1 1 1 0 0 1 0 0 0 0 0 0\n",
            " 1 0 0 0 1 1 1 1 1 1 0 0 1 1 1 0 0 0 0 1 0 1 0 1 0 1 0 1 1 1 1 0 0 0 0 1 0\n",
            " 0 0 0 0 1 1 1 0 1 1 0 1 0 1 0 1 1 1 1 1 1 1 1 0 1 0 1 1 0 0 1 1 1 1 0 0 0\n",
            " 1 0 0 0 0 1 1 1 0 1 1 1 0 1 1 0 0 1 1 0 0 1 1 0 0 0 0 1 0 0 0 0 1 1 0 0 1\n",
            " 0 0 0 1 1 0 1 1 0 1 1 0 1 1 0 1 1 0 1 0 1 0 0 0 0 1 1 0 1 1 1 0 1 1 1 1 0\n",
            " 1 0 1 1 1 0 1 1 1 1 0 1 1 1 0 0 1 0 1 1 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1 0 0\n",
            " 1 1 1 1 1 1 0 0 0 0 0 1 1 1 0 1 0 0 1 0 0 1 0 1 0 0 1 0 0 0 0 0 1 1 1 1 0\n",
            " 1 1 0 0 1 1 1 0 1 0 0 1 0 1 0 0 1 0 1 1 0 1 1 0 0 0 1 0 1 1 0 0 1 1 1 0 1\n",
            " 0 1 1 0 1 1 0 1 1 1 1 0 1 1 0 0 1 0 0 0 1 0 1 1 0 1 1 0 1 1 0 0 0 1 0 1 0\n",
            " 1 1 1 1 0 1 1 1 0 1 0 1 1 0 1 1 1 1 0 1 0 0 1 1 0 0 0 0 1 1 0 1 0 0 1 0 0\n",
            " 1 0 1 0 1 0 0 0 1 0 1 0 0 0 0 1 1 1 1 0 0 1 1 1 1 0 0 0 0 0 1 1 1 1 0 1 0\n",
            " 0 1 1 0 1 0 0 1 0 0 1 0 0 1 1 0 1 1 1 0 1 0 0 1 1 1 0 0 1 1 1 1 1 0 1 1 1\n",
            " 1 1 1 1 0 0 0 1 1 1 0 0 1 0 1 0 1 1 0 1 0 0 1 0 0 0 1 0 0 1 0 1 1 0 0 0 1\n",
            " 1 1 1 1 0 1 1 1 1 1 1 0 0 0 1 0 1 1 1 1 1 0 1 1 1 1 0 1 0 0 0 0 0 0 1 0 1\n",
            " 0 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 0 0 1 0 0 0 1 0 0 0 0 1 1 1 1 1 0 0\n",
            " 1 1 0 0 0 0 0 1 1 0 1 1 0 1 0 1 0 1 1 0 1 1 1 0 1 1 0 1 1 1 1 0 0 1 1 0 1\n",
            " 1 0 1 1 0 0 0 1 1 0 1 1 1 0 1 0 1 1 0 0 1 0 0 1 1 1 0 0 1 0 1 0 0 1 0 0 1\n",
            " 0 0 1 1 0 0 0 0 1 1 1 1 0 0 1 0 1 0 0 1 1 1 1 0 0 1 0 0 0 1 1 1 1 1 1 1 0\n",
            " 0 0 1 1 0 1 1 0 1 1 0 1 0 0 1 0 1 0 0 1 0 0 1 0 1 1 0 0 1 0 0 0 1 0 0 1 1\n",
            " 1 1 0 0 0 1 1 0 1 0 1 0 1 1 1 0 0 0 0 1 0 0 0 0 1 1 1 0 0 1 0 1 1 1 1 0 0\n",
            " 1 1 0 1 0 0 1 1 0 1 1 1 1 0 1 0 1 0 1 0 1 1 1 1 0 0 0 0 0 1 1 0 0 1 0 1 1\n",
            " 0 1 0 1 0 1 0 0 0 1 1 1 0 0 1 1 0 0 0 1 0 1 0 0 1 1 1 0 0 1 1 1 1 1 1 1 0\n",
            " 0 1 1 0 1 1 1 0 1 0 1 1 0 1 1 0 0 1 0 0 1 1 1 1 1 1 0 1 1 0 1 1 0 1 0 0 0\n",
            " 1 1 1 0 1 0 0 0 1 1 0 0 1 1 0 0 1 1 1 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 0 1 0\n",
            " 1 0 1 1 1 0 0 1 1 1 1 1 1 1 1 1 0 0 0 1 0 1 1 1 0 0 0]\n",
            "uniques chosen: 50 <= should be equal to: 50\n",
            "trainset before adding uncertain samples (350, 10) (350,)\n",
            "trainset after adding uncertain samples (400, 10) (400,)\n",
            "updated train set: (400, 10) (400,) unique(labels): [178 222] [0 1]\n",
            "val set: (902, 10) (902,)\n",
            "\n",
            "Train set: (400, 10)\n",
            "Validation set: (902, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 8\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.098 s \n",
            "\n",
            "Accuracy rate is 79.032258 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86       321\n",
            "           1       0.61      0.54      0.57       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.73      0.71      0.72       434\n",
            "weighted avg       0.78      0.79      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[282  39]\n",
            " [ 52  61]]\n",
            "--------------------------------\n",
            "val predicted: (902,) [1 0 0 1 0 0 0 0 0 0 1 1 1 0 1 0 0 0 0 1 0 1 1 1 0 0 0 1 0 0 1 0 1 0 0 0 1\n",
            " 0 0 1 1 1 0 0 1 1 1 1 0 1 1 0 1 0 0 0 1 1 1 1 1 1 0 0 1 0 0 0 0 0 0 1 0 0\n",
            " 1 1 1 1 1 1 0 0 1 1 1 0 0 0 0 1 1 1 0 1 0 1 0 1 0 1 1 0 0 0 1 0 0 0 0 0 1\n",
            " 0 0 0 1 1 0 1 0 1 0 1 1 1 1 1 1 1 1 0 1 0 1 1 0 0 1 1 1 1 0 0 0 1 0 0 0 0\n",
            " 1 1 0 1 1 0 1 1 0 0 1 1 0 0 1 1 0 0 0 1 0 0 0 0 1 1 0 0 1 0 0 0 1 1 0 1 1\n",
            " 0 0 1 0 1 0 1 1 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1 1 1 1 0 1 0 1 1 0 1 1 1 1 0\n",
            " 1 1 1 0 0 1 0 1 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1 0 0 0 1 1 1 1 1 0 0 0 0 1 1\n",
            " 1 0 1 0 0 1 0 0 1 0 1 0 0 1 0 0 0 0 0 1 1 1 0 1 1 0 0 0 1 1 0 1 0 0 1 0 1\n",
            " 1 0 1 0 1 1 0 1 0 0 0 0 1 0 1 1 0 0 1 1 1 0 1 1 1 0 1 1 0 1 1 1 1 0 1 1 0\n",
            " 0 1 0 0 0 1 0 1 1 0 1 1 0 1 0 1 0 1 0 1 0 1 1 1 1 0 1 1 0 1 1 0 0 0 1 1 1\n",
            " 1 0 1 1 1 1 0 0 0 0 1 1 0 1 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 1 1 0 0 1 1 1 1\n",
            " 0 0 1 1 1 1 0 0 0 0 0 1 1 1 1 0 0 0 0 1 1 0 1 0 0 1 0 0 1 0 0 1 1 0 1 0 1\n",
            " 0 1 1 1 1 0 1 0 0 1 1 1 1 1 0 1 1 1 1 1 1 1 0 0 0 1 1 1 0 0 1 0 1 0 1 1 0\n",
            " 0 0 1 0 0 0 1 0 0 1 0 1 1 0 0 0 1 1 1 1 1 0 1 1 1 1 1 1 0 0 1 0 1 1 1 1 1\n",
            " 0 1 1 1 0 1 0 0 0 0 0 0 1 0 1 0 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 0 0\n",
            " 0 1 0 0 0 0 1 1 1 0 0 1 1 0 0 0 0 1 1 1 0 1 1 0 1 0 0 1 1 1 0 1 1 0 1 1 1\n",
            " 1 0 0 1 1 0 1 1 0 1 1 0 0 0 1 0 0 1 1 1 0 0 1 1 0 0 1 0 0 1 1 0 0 1 0 1 0\n",
            " 1 0 0 1 0 0 1 1 0 0 0 0 1 1 0 0 1 0 1 0 0 1 1 1 1 0 0 1 0 1 1 1 1 1 1 1 0\n",
            " 0 0 1 1 0 1 1 0 1 1 1 1 0 1 0 1 0 0 1 0 0 1 0 1 1 0 0 1 0 0 0 1 0 0 1 1 1\n",
            " 1 0 0 0 1 1 0 1 0 1 1 1 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 1 1 1 1 0 0 1 1 0 1\n",
            " 1 0 1 1 0 1 1 1 1 1 0 0 0 1 0 1 1 0 0 0 0 0 1 1 0 0 1 0 1 1 0 1 0 1 0 0 0\n",
            " 0 1 1 1 0 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 1 1 1 1 0 1 1 0 1 1 1 0 1 0\n",
            " 1 0 1 1 1 0 1 0 0 1 1 1 1 1 1 0 1 1 0 1 1 0 1 0 0 0 1 1 1 1 0 0 0 1 1 0 0\n",
            " 1 1 0 0 1 1 1 1 0 0 1 1 0 0 0 1 1 0 1 1 1 0 0 1 0 1 0 1 1 1 0 0 1 1 1 1 1\n",
            " 0 1 0 0 0 0 1 0 1 1 1 0 0 0]\n",
            "probabilities: (902, 2) \n",
            " [1 0 0 1 0 0 0 0 0 0 1 1 1 0 1 0 0 0 0 1 0 1 1 1 0 0 0 1 0 0 1 0 1 0 0 0 1\n",
            " 0 0 1 1 1 0 0 1 1 1 1 0 1 1 0 1 0 0 0 1 1 1 1 1 1 0 0 1 0 0 0 0 0 0 1 0 0\n",
            " 1 1 1 1 1 1 0 0 1 1 1 0 0 0 0 1 1 1 0 1 0 1 0 1 0 1 1 0 0 0 1 0 0 0 0 0 1\n",
            " 0 0 0 1 1 0 1 0 1 0 1 1 1 1 1 1 1 1 0 1 0 1 1 0 0 1 1 1 1 0 0 0 1 0 0 0 0\n",
            " 1 1 0 1 1 0 1 1 0 0 1 1 0 0 1 1 0 0 0 1 0 0 0 0 1 1 0 0 1 0 0 0 1 1 0 1 1\n",
            " 0 0 1 0 1 0 1 1 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1 1 1 1 0 1 0 1 1 0 1 1 1 1 0\n",
            " 1 1 1 0 0 1 0 1 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1 0 0 0 1 1 1 1 1 0 0 0 0 1 1\n",
            " 1 0 1 0 0 1 0 0 1 0 1 0 0 1 0 0 0 0 0 1 1 1 0 1 1 0 0 0 1 1 0 1 0 0 1 0 1\n",
            " 1 0 1 0 1 1 0 1 0 0 0 0 1 0 1 1 0 0 1 1 1 0 1 1 1 0 1 1 0 1 1 1 1 0 1 1 0\n",
            " 0 1 0 0 0 1 0 1 1 0 1 1 0 1 0 1 0 1 0 1 0 1 1 1 1 0 1 1 0 1 1 0 0 0 1 1 1\n",
            " 1 0 1 1 1 1 0 0 0 0 1 1 0 1 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 1 1 0 0 1 1 1 1\n",
            " 0 0 1 1 1 1 0 0 0 0 0 1 1 1 1 0 0 0 0 1 1 0 1 0 0 1 0 0 1 0 0 1 1 0 1 0 1\n",
            " 0 1 1 1 1 0 1 0 0 1 1 1 1 1 0 1 1 1 1 1 1 1 0 0 0 1 1 1 0 0 1 0 1 0 1 1 0\n",
            " 0 0 1 0 0 0 1 0 0 1 0 1 1 0 0 0 1 1 1 1 1 0 1 1 1 1 1 1 0 0 1 0 1 1 1 1 1\n",
            " 0 1 1 1 0 1 0 0 0 0 0 0 1 0 1 0 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 0 0\n",
            " 0 1 0 0 0 0 1 1 1 0 0 1 1 0 0 0 0 1 1 1 0 1 1 0 1 0 0 1 1 1 0 1 1 0 1 1 1\n",
            " 1 0 0 1 1 0 1 1 0 1 1 0 0 0 1 0 0 1 1 1 0 0 1 1 0 0 1 0 0 1 1 0 0 1 0 1 0\n",
            " 1 0 0 1 0 0 1 1 0 0 0 0 1 1 0 0 1 0 1 0 0 1 1 1 1 0 0 1 0 1 1 1 1 1 1 1 0\n",
            " 0 0 1 1 0 1 1 0 1 1 1 1 0 1 0 1 0 0 1 0 0 1 0 1 1 0 0 1 0 0 0 1 0 0 1 1 1\n",
            " 1 0 0 0 1 1 0 1 0 1 1 1 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 1 1 1 1 0 0 1 1 0 1\n",
            " 1 0 1 1 0 1 1 1 1 1 0 0 0 1 0 1 1 0 0 0 0 0 1 1 0 0 1 0 1 1 0 1 0 1 0 0 0\n",
            " 0 1 1 1 0 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 1 1 1 1 0 1 1 0 1 1 1 0 1 0\n",
            " 1 0 1 1 1 0 1 0 0 1 1 1 1 1 1 0 1 1 0 1 1 0 1 0 0 0 1 1 1 1 0 0 0 1 1 0 0\n",
            " 1 1 0 0 1 1 1 1 0 0 1 1 0 0 0 1 1 0 1 1 1 0 0 1 0 1 0 1 1 1 0 0 1 1 1 1 1\n",
            " 0 1 0 0 0 0 1 0 1 1 1 0 0 0]\n",
            "uniques chosen: 50 <= should be equal to: 50\n",
            "trainset before adding uncertain samples (400, 10) (400,)\n",
            "trainset after adding uncertain samples (450, 10) (450,)\n",
            "updated train set: (450, 10) (450,) unique(labels): [197 253] [0 1]\n",
            "val set: (852, 10) (852,)\n",
            "\n",
            "Train set: (450, 10)\n",
            "Validation set: (852, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 9\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.161 s \n",
            "\n",
            "Accuracy rate is 79.032258 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86       321\n",
            "           1       0.61      0.53      0.57       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.73      0.71      0.72       434\n",
            "weighted avg       0.78      0.79      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[283  38]\n",
            " [ 53  60]]\n",
            "--------------------------------\n",
            "val predicted: (852,) [1 1 0 1 0 0 0 0 0 0 1 1 1 0 1 0 0 0 0 1 0 1 1 1 0 0 0 1 0 0 1 0 1 0 0 0 1\n",
            " 0 0 1 1 1 0 0 0 1 1 1 0 1 1 0 1 0 0 0 1 1 1 1 1 1 0 0 1 0 0 0 0 0 0 1 0 1\n",
            " 1 1 1 1 1 0 0 1 1 0 0 0 0 1 1 1 0 1 0 1 0 1 0 1 1 0 0 0 1 0 0 0 0 0 1 0 0\n",
            " 0 1 1 0 1 0 1 0 1 1 1 1 1 1 1 0 1 0 1 1 0 0 1 1 1 0 0 0 0 0 0 1 1 0 1 1 0\n",
            " 0 1 0 0 1 1 0 0 1 0 0 0 1 1 0 0 0 0 1 1 0 0 1 0 0 0 1 1 0 1 1 0 1 1 0 1 0\n",
            " 1 1 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1 1 1 1 0 1 0 1 1 0 1 1 1 0 1 1 1 0 0 1 0\n",
            " 1 0 1 1 1 1 1 0 1 1 0 1 1 1 0 0 0 1 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 1 0 0 1\n",
            " 0 1 0 0 1 0 0 0 0 1 1 1 0 1 1 0 0 1 1 1 0 1 0 1 1 0 0 1 0 1 1 0 1 1 0 0 0\n",
            " 1 0 1 1 0 0 1 1 0 0 1 1 0 1 1 0 1 1 1 1 1 1 0 0 0 0 0 0 1 1 0 1 1 0 1 0 1\n",
            " 0 1 0 1 0 1 1 1 0 1 1 0 1 1 0 0 0 1 1 1 0 1 1 1 0 0 0 0 1 1 0 1 0 0 1 0 0\n",
            " 1 0 1 0 1 0 0 0 0 1 1 0 0 1 1 1 1 0 0 1 1 0 0 0 0 0 1 1 1 1 0 0 0 0 1 1 0\n",
            " 1 0 0 1 0 0 1 0 0 1 1 0 1 0 1 0 1 1 1 1 0 0 0 1 1 1 1 1 0 1 1 1 1 1 1 1 0\n",
            " 0 0 1 1 1 0 0 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 1 0 1 1 0 0 0 1 1 1 1 1 0 1 1\n",
            " 1 1 1 1 0 0 1 0 0 1 1 1 0 1 1 1 0 1 0 0 0 0 1 0 1 1 0 1 0 1 0 1 1 1 1 1 1\n",
            " 1 1 0 0 1 0 0 0 1 0 0 0 0 1 1 1 1 0 1 0 0 0 1 1 1 0 1 1 0 1 0 0 1 1 1 0 1\n",
            " 1 0 1 1 1 0 0 1 1 0 1 1 0 1 0 0 0 1 0 0 1 1 0 0 1 1 0 0 1 0 0 1 1 0 0 1 0\n",
            " 1 0 1 0 1 0 0 1 1 0 0 0 0 1 0 0 1 1 1 0 0 1 1 1 1 0 0 1 0 1 1 1 1 1 1 1 0\n",
            " 0 0 1 1 0 1 1 0 1 1 1 1 0 1 0 1 0 0 1 0 0 1 1 0 1 1 0 0 0 1 0 0 1 1 1 1 0\n",
            " 0 0 1 1 0 1 0 1 1 1 0 0 1 0 1 0 0 0 1 0 0 1 0 1 1 1 1 0 0 1 1 0 1 1 0 1 1\n",
            " 0 1 1 1 1 1 0 0 0 1 1 1 0 0 0 0 0 1 1 0 0 1 0 1 1 0 1 0 1 0 0 0 1 1 0 1 0\n",
            " 0 0 1 0 1 0 0 1 1 1 0 0 1 1 1 1 1 1 1 0 1 0 1 1 0 0 1 0 1 1 1 0 1 0 1 1 1\n",
            " 0 1 1 0 1 1 0 1 1 0 1 0 0 0 1 1 1 1 0 0 0 1 1 0 0 1 0 0 1 1 1 1 0 0 1 1 0\n",
            " 1 0 1 1 0 0 1 1 0 0 1 0 1 0 1 1 1 0 0 1 1 0 1 1 0 1 0 0 0 0 1 0 1 1 1 0 0\n",
            " 0]\n",
            "probabilities: (852, 2) \n",
            " [1 1 0 1 0 0 0 0 0 0 1 1 1 0 1 0 0 0 0 1 0 1 1 1 0 0 0 1 0 0 1 0 1 0 0 0 1\n",
            " 0 0 1 1 1 0 0 0 1 1 1 0 1 1 0 1 0 0 0 1 1 1 1 1 1 0 0 1 0 0 0 0 0 0 1 0 1\n",
            " 1 1 1 1 1 0 0 1 1 0 0 0 0 1 1 1 0 1 0 1 0 1 0 1 1 0 0 0 1 0 0 0 0 0 1 0 0\n",
            " 0 1 1 0 1 0 1 0 1 1 1 1 1 1 1 0 1 0 1 1 0 0 1 1 1 0 0 0 0 0 0 1 1 0 1 1 0\n",
            " 0 1 0 0 1 1 0 0 1 0 0 0 1 1 0 0 0 0 1 1 0 0 1 0 0 0 1 1 0 1 1 0 1 1 0 1 0\n",
            " 1 1 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1 1 1 1 0 1 0 1 1 0 1 1 1 0 1 1 1 0 0 1 0\n",
            " 1 0 1 1 1 1 1 0 1 1 0 1 1 1 0 0 0 1 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 1 0 0 1\n",
            " 0 1 0 0 1 0 0 0 0 1 1 1 0 1 1 0 0 1 1 1 0 1 0 1 1 0 0 1 0 1 1 0 1 1 0 0 0\n",
            " 1 0 1 1 0 0 1 1 0 0 1 1 0 1 1 0 1 1 1 1 1 1 0 0 0 0 0 0 1 1 0 1 1 0 1 0 1\n",
            " 0 1 0 1 0 1 1 1 0 1 1 0 1 1 0 0 0 1 1 1 0 1 1 1 0 0 0 0 1 1 0 1 0 0 1 0 0\n",
            " 1 0 1 0 1 0 0 0 0 1 1 0 0 1 1 1 1 0 0 1 1 0 0 0 0 0 1 1 1 1 0 0 0 0 1 1 0\n",
            " 1 0 0 1 0 0 1 0 0 1 1 0 1 0 1 0 1 1 1 1 0 0 0 1 1 1 1 1 0 1 1 1 1 1 1 1 0\n",
            " 0 0 1 1 1 0 0 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 1 0 1 1 0 0 0 1 1 1 1 1 0 1 1\n",
            " 1 1 1 1 0 0 1 0 0 1 1 1 0 1 1 1 0 1 0 0 0 0 1 0 1 1 0 1 0 1 0 1 1 1 1 1 1\n",
            " 1 1 0 0 1 0 0 0 1 0 0 0 0 1 1 1 1 0 1 0 0 0 1 1 1 0 1 1 0 1 0 0 1 1 1 0 1\n",
            " 1 0 1 1 1 0 0 1 1 0 1 1 0 1 0 0 0 1 0 0 1 1 0 0 1 1 0 0 1 0 0 1 1 0 0 1 0\n",
            " 1 0 1 0 1 0 0 1 1 0 0 0 0 1 0 0 1 1 1 0 0 1 1 1 1 0 0 1 0 1 1 1 1 1 1 1 0\n",
            " 0 0 1 1 0 1 1 0 1 1 1 1 0 1 0 1 0 0 1 0 0 1 1 0 1 1 0 0 0 1 0 0 1 1 1 1 0\n",
            " 0 0 1 1 0 1 0 1 1 1 0 0 1 0 1 0 0 0 1 0 0 1 0 1 1 1 1 0 0 1 1 0 1 1 0 1 1\n",
            " 0 1 1 1 1 1 0 0 0 1 1 1 0 0 0 0 0 1 1 0 0 1 0 1 1 0 1 0 1 0 0 0 1 1 0 1 0\n",
            " 0 0 1 0 1 0 0 1 1 1 0 0 1 1 1 1 1 1 1 0 1 0 1 1 0 0 1 0 1 1 1 0 1 0 1 1 1\n",
            " 0 1 1 0 1 1 0 1 1 0 1 0 0 0 1 1 1 1 0 0 0 1 1 0 0 1 0 0 1 1 1 1 0 0 1 1 0\n",
            " 1 0 1 1 0 0 1 1 0 0 1 0 1 0 1 1 1 0 0 1 1 0 1 1 0 1 0 0 0 0 1 0 1 1 1 0 0\n",
            " 0]\n",
            "uniques chosen: 50 <= should be equal to: 50\n",
            "trainset before adding uncertain samples (450, 10) (450,)\n",
            "trainset after adding uncertain samples (500, 10) (500,)\n",
            "updated train set: (500, 10) (500,) unique(labels): [221 279] [0 1]\n",
            "val set: (802, 10) (802,)\n",
            "\n",
            "Train set: (500, 10)\n",
            "Validation set: (802, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 10\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.219 s \n",
            "\n",
            "Accuracy rate is 78.801843 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86       321\n",
            "           1       0.61      0.51      0.56       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.72      0.70      0.71       434\n",
            "weighted avg       0.78      0.79      0.78       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[284  37]\n",
            " [ 55  58]]\n",
            "--------------------------------\n",
            "final active learning accuracies [69.35483870967742, 76.72811059907833, 78.3410138248848, 78.57142857142857, 78.80184331797236, 79.95391705069125, 79.26267281105991, 79.03225806451613, 79.03225806451613, 78.80184331797236]\n",
            "saved /Users/wenxuanhuang/Documents/Repo/ML-for-COVID-19-dataset/Results/Active-learning-experiment-3.pkl /Users/wenxuanhuang/Documents/Repo/ML-for-COVID-19-dataset ['Decision_tree.ipynb', 'dec_git.png', 'Logit_default_f10.pdf', 'Logistic.ipynb', 'SVC.ipynb', 'RF_f5e50_featureimp.pdf', 'log_al.png', 'dec_git.pdf', '.DS_Store', 'log_git.png', 'svm_git.png', 'Logistic_Scikit.ipynb', 'knn_git.pdf', 'knn_git.png', 'rf_al.png', 'Best classifier_RF_f5e50.pdf', 'KNN.ipynb', 'GBDC.ipynb', 'rf_git.png', 'README.md', 'all_training.csv', 'Results', 'svm_al.png', 'Log_ROC.png', 'Logit_default_f7(p_removal).pdf', 'Active_learning.ipynb', 'Random_forest.ipynb', 'Model_select.ipynb', 'gdbc_git.png', '.git', '.vscode', 'Untitled', 'RF_f5e50_modelselect.pdf', 'Logit_default_f8(std_removal).pdf']\n",
            "\n",
            "---------------------------- FINISHED ---------------------------\n",
            "\n",
            "Count = 4, using model = GDBCModel, selection_function = RandomSelection, k = 25, iteration = 0.\n",
            "\n",
            "initial random chosen samples (25,)\n",
            "initial train set: (25, 10) (25,) unique(labels): [12 13] [0 1]\n",
            "Val set: (1277, 10) (1277,) (25,)\n",
            "\n",
            "Train set: (25, 10)\n",
            "Validation set: (1277, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.587 s \n",
            "\n",
            "Accuracy rate is 72.350230 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.80      0.81       321\n",
            "           1       0.47      0.50      0.48       113\n",
            "\n",
            "    accuracy                           0.72       434\n",
            "   macro avg       0.64      0.65      0.65       434\n",
            "weighted avg       0.73      0.72      0.73       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[258  63]\n",
            " [ 57  56]]\n",
            "--------------------------------\n",
            "val predicted: (1277,) [0 0 1 ... 0 0 0]\n",
            "probabilities: (1277, 2) \n",
            " [0 0 1 ... 0 0 0]\n",
            "uniques chosen: 25 <= should be equal to: 25\n",
            "trainset before adding uncertain samples (25, 10) (25,)\n",
            "trainset after adding uncertain samples (50, 10) (50,)\n",
            "updated train set: (50, 10) (50,) unique(labels): [20 30] [0 1]\n",
            "val set: (1252, 10) (1252,)\n",
            "\n",
            "Train set: (50, 10)\n",
            "Validation set: (1252, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.635 s \n",
            "\n",
            "Accuracy rate is 72.119816 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.80      0.81       321\n",
            "           1       0.47      0.50      0.49       113\n",
            "\n",
            "    accuracy                           0.72       434\n",
            "   macro avg       0.64      0.65      0.65       434\n",
            "weighted avg       0.73      0.72      0.72       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[256  65]\n",
            " [ 56  57]]\n",
            "--------------------------------\n",
            "val predicted: (1252,) [0 0 1 ... 0 0 1]\n",
            "probabilities: (1252, 2) \n",
            " [0 0 1 ... 0 0 1]\n",
            "uniques chosen: 25 <= should be equal to: 25\n",
            "trainset before adding uncertain samples (50, 10) (50,)\n",
            "trainset after adding uncertain samples (75, 10) (75,)\n",
            "updated train set: (75, 10) (75,) unique(labels): [33 42] [0 1]\n",
            "val set: (1227, 10) (1227,)\n",
            "\n",
            "Train set: (75, 10)\n",
            "Validation set: (1227, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 3\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.672 s \n",
            "\n",
            "Accuracy rate is 71.889401 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.81      0.81       321\n",
            "           1       0.46      0.45      0.46       113\n",
            "\n",
            "    accuracy                           0.72       434\n",
            "   macro avg       0.63      0.63      0.63       434\n",
            "weighted avg       0.72      0.72      0.72       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[261  60]\n",
            " [ 62  51]]\n",
            "--------------------------------\n",
            "val predicted: (1227,) [0 0 1 ... 0 0 1]\n",
            "probabilities: (1227, 2) \n",
            " [0 0 1 ... 0 0 1]\n",
            "uniques chosen: 25 <= should be equal to: 25\n",
            "trainset before adding uncertain samples (75, 10) (75,)\n",
            "trainset after adding uncertain samples (100, 10) (100,)\n",
            "updated train set: (100, 10) (100,) unique(labels): [50 50] [0 1]\n",
            "val set: (1202, 10) (1202,)\n",
            "\n",
            "Train set: (100, 10)\n",
            "Validation set: (1202, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 4\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.722 s \n",
            "\n",
            "Accuracy rate is 73.041475 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.83      0.82       321\n",
            "           1       0.48      0.44      0.46       113\n",
            "\n",
            "    accuracy                           0.73       434\n",
            "   macro avg       0.64      0.64      0.64       434\n",
            "weighted avg       0.72      0.73      0.73       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[267  54]\n",
            " [ 63  50]]\n",
            "--------------------------------\n",
            "val predicted: (1202,) [0 0 1 ... 0 0 0]\n",
            "probabilities: (1202, 2) \n",
            " [0 0 1 ... 0 0 0]\n",
            "uniques chosen: 25 <= should be equal to: 25\n",
            "trainset before adding uncertain samples (100, 10) (100,)\n",
            "trainset after adding uncertain samples (125, 10) (125,)\n",
            "updated train set: (125, 10) (125,) unique(labels): [63 62] [0 1]\n",
            "val set: (1177, 10) (1177,)\n",
            "\n",
            "Train set: (125, 10)\n",
            "Validation set: (1177, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 5\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.767 s \n",
            "\n",
            "Accuracy rate is 72.811060 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.83      0.82       321\n",
            "           1       0.48      0.42      0.45       113\n",
            "\n",
            "    accuracy                           0.73       434\n",
            "   macro avg       0.64      0.63      0.63       434\n",
            "weighted avg       0.72      0.73      0.72       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[268  53]\n",
            " [ 65  48]]\n",
            "--------------------------------\n",
            "val predicted: (1177,) [0 0 1 ... 0 0 0]\n",
            "probabilities: (1177, 2) \n",
            " [0 0 1 ... 0 0 0]\n",
            "uniques chosen: 25 <= should be equal to: 25\n",
            "trainset before adding uncertain samples (125, 10) (125,)\n",
            "trainset after adding uncertain samples (150, 10) (150,)\n",
            "updated train set: (150, 10) (150,) unique(labels): [76 74] [0 1]\n",
            "val set: (1152, 10) (1152,)\n",
            "\n",
            "Train set: (150, 10)\n",
            "Validation set: (1152, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 6\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.836 s \n",
            "\n",
            "Accuracy rate is 75.115207 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.88      0.84       321\n",
            "           1       0.53      0.40      0.45       113\n",
            "\n",
            "    accuracy                           0.75       434\n",
            "   macro avg       0.67      0.64      0.65       434\n",
            "weighted avg       0.73      0.75      0.74       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[281  40]\n",
            " [ 68  45]]\n",
            "--------------------------------\n",
            "val predicted: (1152,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1152, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "uniques chosen: 25 <= should be equal to: 25\n",
            "trainset before adding uncertain samples (150, 10) (150,)\n",
            "trainset after adding uncertain samples (175, 10) (175,)\n",
            "updated train set: (175, 10) (175,) unique(labels): [90 85] [0 1]\n",
            "val set: (1127, 10) (1127,)\n",
            "\n",
            "Train set: (175, 10)\n",
            "Validation set: (1127, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 7\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.853 s \n",
            "\n",
            "Accuracy rate is 73.502304 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.82      0.82       321\n",
            "           1       0.49      0.50      0.49       113\n",
            "\n",
            "    accuracy                           0.74       434\n",
            "   macro avg       0.66      0.66      0.66       434\n",
            "weighted avg       0.74      0.74      0.74       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[263  58]\n",
            " [ 57  56]]\n",
            "--------------------------------\n",
            "val predicted: (1127,) [0 1 1 ... 0 1 0]\n",
            "probabilities: (1127, 2) \n",
            " [0 1 1 ... 0 1 0]\n",
            "uniques chosen: 25 <= should be equal to: 25\n",
            "trainset before adding uncertain samples (175, 10) (175,)\n",
            "trainset after adding uncertain samples (200, 10) (200,)\n",
            "updated train set: (200, 10) (200,) unique(labels): [107  93] [0 1]\n",
            "val set: (1102, 10) (1102,)\n",
            "\n",
            "Train set: (200, 10)\n",
            "Validation set: (1102, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 8\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.867 s \n",
            "\n",
            "Accuracy rate is 76.036866 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.86      0.84       321\n",
            "           1       0.55      0.47      0.50       113\n",
            "\n",
            "    accuracy                           0.76       434\n",
            "   macro avg       0.68      0.67      0.67       434\n",
            "weighted avg       0.75      0.76      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[277  44]\n",
            " [ 60  53]]\n",
            "--------------------------------\n",
            "val predicted: (1102,) [0 1 1 ... 0 1 0]\n",
            "probabilities: (1102, 2) \n",
            " [0 1 1 ... 0 1 0]\n",
            "uniques chosen: 25 <= should be equal to: 25\n",
            "trainset before adding uncertain samples (200, 10) (200,)\n",
            "trainset after adding uncertain samples (225, 10) (225,)\n",
            "updated train set: (225, 10) (225,) unique(labels): [119 106] [0 1]\n",
            "val set: (1077, 10) (1077,)\n",
            "\n",
            "Train set: (225, 10)\n",
            "Validation set: (1077, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 9\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.932 s \n",
            "\n",
            "Accuracy rate is 76.267281 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.86      0.84       321\n",
            "           1       0.55      0.48      0.51       113\n",
            "\n",
            "    accuracy                           0.76       434\n",
            "   macro avg       0.69      0.67      0.68       434\n",
            "weighted avg       0.75      0.76      0.76       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[277  44]\n",
            " [ 59  54]]\n",
            "--------------------------------\n",
            "val predicted: (1077,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1077, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "uniques chosen: 25 <= should be equal to: 25\n",
            "trainset before adding uncertain samples (225, 10) (225,)\n",
            "trainset after adding uncertain samples (250, 10) (250,)\n",
            "updated train set: (250, 10) (250,) unique(labels): [130 120] [0 1]\n",
            "val set: (1052, 10) (1052,)\n",
            "\n",
            "Train set: (250, 10)\n",
            "Validation set: (1052, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 10\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.061 s \n",
            "\n",
            "Accuracy rate is 76.497696 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.86      0.84       321\n",
            "           1       0.56      0.49      0.52       113\n",
            "\n",
            "    accuracy                           0.76       434\n",
            "   macro avg       0.69      0.67      0.68       434\n",
            "weighted avg       0.76      0.76      0.76       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[277  44]\n",
            " [ 58  55]]\n",
            "--------------------------------\n",
            "val predicted: (1052,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1052, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "uniques chosen: 25 <= should be equal to: 25\n",
            "trainset before adding uncertain samples (250, 10) (250,)\n",
            "trainset after adding uncertain samples (275, 10) (275,)\n",
            "updated train set: (275, 10) (275,) unique(labels): [141 134] [0 1]\n",
            "val set: (1027, 10) (1027,)\n",
            "\n",
            "Train set: (275, 10)\n",
            "Validation set: (1027, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 11\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.108 s \n",
            "\n",
            "Accuracy rate is 76.728111 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.86      0.84       321\n",
            "           1       0.56      0.51      0.53       113\n",
            "\n",
            "    accuracy                           0.77       434\n",
            "   macro avg       0.70      0.68      0.69       434\n",
            "weighted avg       0.76      0.77      0.76       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[275  46]\n",
            " [ 55  58]]\n",
            "--------------------------------\n",
            "val predicted: (1027,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1027, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "uniques chosen: 25 <= should be equal to: 25\n",
            "trainset before adding uncertain samples (275, 10) (275,)\n",
            "trainset after adding uncertain samples (300, 10) (300,)\n",
            "updated train set: (300, 10) (300,) unique(labels): [154 146] [0 1]\n",
            "val set: (1002, 10) (1002,)\n",
            "\n",
            "Train set: (300, 10)\n",
            "Validation set: (1002, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 12\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.168 s \n",
            "\n",
            "Accuracy rate is 77.188940 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.86      0.85       321\n",
            "           1       0.57      0.52      0.54       113\n",
            "\n",
            "    accuracy                           0.77       434\n",
            "   macro avg       0.70      0.69      0.70       434\n",
            "weighted avg       0.77      0.77      0.77       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[276  45]\n",
            " [ 54  59]]\n",
            "--------------------------------\n",
            "val predicted: (1002,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1002, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "uniques chosen: 25 <= should be equal to: 25\n",
            "trainset before adding uncertain samples (300, 10) (300,)\n",
            "trainset after adding uncertain samples (325, 10) (325,)\n",
            "updated train set: (325, 10) (325,) unique(labels): [165 160] [0 1]\n",
            "val set: (977, 10) (977,)\n",
            "\n",
            "Train set: (325, 10)\n",
            "Validation set: (977, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 13\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.103 s \n",
            "\n",
            "Accuracy rate is 76.728111 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.85      0.84       321\n",
            "           1       0.55      0.54      0.55       113\n",
            "\n",
            "    accuracy                           0.77       434\n",
            "   macro avg       0.70      0.69      0.70       434\n",
            "weighted avg       0.77      0.77      0.77       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[272  49]\n",
            " [ 52  61]]\n",
            "--------------------------------\n",
            "val predicted: (977,) [0 1 1 0 1 0 0 0 1 1 0 1 0 0 0 0 1 1 0 1 0 1 0 0 0 1 1 1 1 1 0 1 0 0 0 1 1\n",
            " 0 0 1 0 0 1 1 0 0 1 1 0 1 1 1 1 0 0 0 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1\n",
            " 0 1 0 1 0 0 1 0 0 1 0 0 0 1 1 0 0 1 1 1 0 0 0 1 1 0 0 0 0 0 1 1 1 0 1 0 1\n",
            " 0 1 1 1 0 0 1 0 1 0 0 1 0 0 0 0 0 1 0 1 0 0 1 1 0 1 1 1 0 0 0 1 1 1 1 1 1\n",
            " 1 0 1 0 1 1 0 1 1 1 1 1 1 0 1 0 1 0 0 0 0 1 1 1 1 1 0 1 1 1 0 1 1 1 0 1 1\n",
            " 0 0 0 1 1 0 0 0 0 1 1 1 0 0 0 0 0 1 1 0 1 0 0 1 0 1 0 1 0 0 1 0 1 1 0 0 0\n",
            " 0 0 1 0 1 0 1 1 0 1 1 1 1 1 0 1 0 1 0 1 0 1 1 1 1 0 1 0 1 1 1 1 0 1 1 0 0\n",
            " 1 1 1 1 0 0 0 1 1 0 1 1 0 1 1 1 1 1 0 0 0 0 0 0 1 0 1 0 1 1 0 0 1 0 0 0 1\n",
            " 0 0 0 0 1 1 1 1 0 0 1 1 1 1 0 0 1 1 0 1 1 0 1 0 0 0 0 1 1 1 1 1 1 0 1 1 0\n",
            " 1 0 1 1 1 0 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 1 0 1 1 0\n",
            " 0 1 1 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 0 1 1 1 1 1 0 1 0 1 1 0 1 0 0 1 0\n",
            " 1 1 1 1 1 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 1 1 1 0 1 1 0 1 0 1 1 0 1 0 1\n",
            " 1 1 0 0 0 1 1 1 0 0 1 1 1 1 0 0 0 0 0 1 1 1 1 0 0 1 0 0 0 0 1 0 0 0 1 1 1\n",
            " 0 1 1 0 0 1 1 0 0 1 0 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 1 1 0 0 0 1 0 1 0 1 1\n",
            " 1 0 1 1 0 0 0 0 1 0 1 1 0 1 1 1 0 0 1 1 1 1 0 1 1 1 1 0 1 1 0 0 0 1 1 1 1\n",
            " 1 1 1 1 0 1 0 0 1 0 0 1 0 0 0 1 1 0 1 0 1 1 1 0 1 1 1 0 0 0 1 1 0 0 1 0 0\n",
            " 1 0 0 1 0 0 1 0 1 0 0 0 1 0 0 0 0 0 1 1 0 1 1 1 1 0 1 0 1 1 0 0 1 1 0 1 1\n",
            " 1 0 0 0 1 1 0 0 0 1 1 1 0 1 0 1 1 1 0 0 1 1 0 1 0 1 1 0 0 0 1 1 1 0 0 1 1\n",
            " 1 1 0 0 0 0 0 1 0 1 0 1 0 0 0 1 1 0 0 1 0 0 0 1 1 0 1 1 1 0 0 1 0 0 0 1 0\n",
            " 1 1 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 1 0 1 1 0 1 1 0 1 0 1 1 1 0 1 0 1 0 0 0\n",
            " 0 0 1 1 1 0 1 0 0 1 0 0 1 0 1 1 1 0 0 0 0 1 1 0 0 1 0 1 0 1 0 0 1 0 0 1 0\n",
            " 0 0 0 0 1 1 1 0 0 1 1 1 1 0 0 1 0 0 0 0 0 0 1 1 0 1 0 0 1 1 1 1 1 1 0 1 0\n",
            " 0 0 1 1 1 1 1 1 1 1 1 1 0 1 0 0 0 0 1 0 0 0 1 1 0 1 1 1 1 1 0 0 0 0 0 1 0\n",
            " 1 0 1 0 0 1 1 0 1 1 1 0 1 0 0 1 1 1 1 1 1 0 1 1 1 0 0 1 1 0 1 1 1 1 1 0 0\n",
            " 1 1 0 1 1 1 0 0 1 1 1 1 1 1 1 1 0 0 1 1 0 0 1 0 1 0 0 1 0 0 1 0 1 0 1 0 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 0 1 1 0 1 0 0 1 0 0 1 1 1 1 1 1 0 1 1 1\n",
            " 1 0 0 1 0 1 0 0 1 0 1 1 0 0 0]\n",
            "probabilities: (977, 2) \n",
            " [0 1 1 0 1 0 0 0 1 1 0 1 0 0 0 0 1 1 0 1 0 1 0 0 0 1 1 1 1 1 0 1 0 0 0 1 1\n",
            " 0 0 1 0 0 1 1 0 0 1 1 0 1 1 1 1 0 0 0 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1\n",
            " 0 1 0 1 0 0 1 0 0 1 0 0 0 1 1 0 0 1 1 1 0 0 0 1 1 0 0 0 0 0 1 1 1 0 1 0 1\n",
            " 0 1 1 1 0 0 1 0 1 0 0 1 0 0 0 0 0 1 0 1 0 0 1 1 0 1 1 1 0 0 0 1 1 1 1 1 1\n",
            " 1 0 1 0 1 1 0 1 1 1 1 1 1 0 1 0 1 0 0 0 0 1 1 1 1 1 0 1 1 1 0 1 1 1 0 1 1\n",
            " 0 0 0 1 1 0 0 0 0 1 1 1 0 0 0 0 0 1 1 0 1 0 0 1 0 1 0 1 0 0 1 0 1 1 0 0 0\n",
            " 0 0 1 0 1 0 1 1 0 1 1 1 1 1 0 1 0 1 0 1 0 1 1 1 1 0 1 0 1 1 1 1 0 1 1 0 0\n",
            " 1 1 1 1 0 0 0 1 1 0 1 1 0 1 1 1 1 1 0 0 0 0 0 0 1 0 1 0 1 1 0 0 1 0 0 0 1\n",
            " 0 0 0 0 1 1 1 1 0 0 1 1 1 1 0 0 1 1 0 1 1 0 1 0 0 0 0 1 1 1 1 1 1 0 1 1 0\n",
            " 1 0 1 1 1 0 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 1 0 1 1 0\n",
            " 0 1 1 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 0 1 1 1 1 1 0 1 0 1 1 0 1 0 0 1 0\n",
            " 1 1 1 1 1 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 1 1 1 0 1 1 0 1 0 1 1 0 1 0 1\n",
            " 1 1 0 0 0 1 1 1 0 0 1 1 1 1 0 0 0 0 0 1 1 1 1 0 0 1 0 0 0 0 1 0 0 0 1 1 1\n",
            " 0 1 1 0 0 1 1 0 0 1 0 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 1 1 0 0 0 1 0 1 0 1 1\n",
            " 1 0 1 1 0 0 0 0 1 0 1 1 0 1 1 1 0 0 1 1 1 1 0 1 1 1 1 0 1 1 0 0 0 1 1 1 1\n",
            " 1 1 1 1 0 1 0 0 1 0 0 1 0 0 0 1 1 0 1 0 1 1 1 0 1 1 1 0 0 0 1 1 0 0 1 0 0\n",
            " 1 0 0 1 0 0 1 0 1 0 0 0 1 0 0 0 0 0 1 1 0 1 1 1 1 0 1 0 1 1 0 0 1 1 0 1 1\n",
            " 1 0 0 0 1 1 0 0 0 1 1 1 0 1 0 1 1 1 0 0 1 1 0 1 0 1 1 0 0 0 1 1 1 0 0 1 1\n",
            " 1 1 0 0 0 0 0 1 0 1 0 1 0 0 0 1 1 0 0 1 0 0 0 1 1 0 1 1 1 0 0 1 0 0 0 1 0\n",
            " 1 1 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 1 0 1 1 0 1 1 0 1 0 1 1 1 0 1 0 1 0 0 0\n",
            " 0 0 1 1 1 0 1 0 0 1 0 0 1 0 1 1 1 0 0 0 0 1 1 0 0 1 0 1 0 1 0 0 1 0 0 1 0\n",
            " 0 0 0 0 1 1 1 0 0 1 1 1 1 0 0 1 0 0 0 0 0 0 1 1 0 1 0 0 1 1 1 1 1 1 0 1 0\n",
            " 0 0 1 1 1 1 1 1 1 1 1 1 0 1 0 0 0 0 1 0 0 0 1 1 0 1 1 1 1 1 0 0 0 0 0 1 0\n",
            " 1 0 1 0 0 1 1 0 1 1 1 0 1 0 0 1 1 1 1 1 1 0 1 1 1 0 0 1 1 0 1 1 1 1 1 0 0\n",
            " 1 1 0 1 1 1 0 0 1 1 1 1 1 1 1 1 0 0 1 1 0 0 1 0 1 0 0 1 0 0 1 0 1 0 1 0 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 0 1 1 0 1 0 0 1 0 0 1 1 1 1 1 1 0 1 1 1\n",
            " 1 0 0 1 0 1 0 0 1 0 1 1 0 0 0]\n",
            "uniques chosen: 25 <= should be equal to: 25\n",
            "trainset before adding uncertain samples (325, 10) (325,)\n",
            "trainset after adding uncertain samples (350, 10) (350,)\n",
            "updated train set: (350, 10) (350,) unique(labels): [175 175] [0 1]\n",
            "val set: (952, 10) (952,)\n",
            "\n",
            "Train set: (350, 10)\n",
            "Validation set: (952, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 14\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.291 s \n",
            "\n",
            "Accuracy rate is 78.110599 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.87      0.85       321\n",
            "           1       0.59      0.54      0.56       113\n",
            "\n",
            "    accuracy                           0.78       434\n",
            "   macro avg       0.71      0.70      0.71       434\n",
            "weighted avg       0.78      0.78      0.78       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[278  43]\n",
            " [ 52  61]]\n",
            "--------------------------------\n",
            "val predicted: (952,) [0 1 1 0 0 0 1 1 0 0 0 0 0 0 1 1 0 1 0 1 0 0 0 1 1 1 1 1 0 1 0 0 0 1 1 0 0\n",
            " 1 0 0 1 1 0 0 0 1 0 1 1 1 1 0 0 0 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 0 1\n",
            " 0 1 0 0 0 0 0 1 0 0 0 1 1 0 0 1 1 1 0 0 0 1 1 1 0 0 0 0 1 1 1 0 1 0 1 0 1\n",
            " 1 1 0 0 1 0 1 0 0 1 0 0 0 0 0 1 0 1 1 0 1 1 0 1 1 1 0 0 0 1 1 1 1 1 1 1 0\n",
            " 1 0 1 1 1 1 1 1 1 1 0 1 0 1 0 0 0 1 1 1 1 1 0 1 1 1 0 1 1 1 0 1 1 0 0 0 1\n",
            " 1 0 0 0 0 1 1 1 0 0 0 0 0 1 1 0 1 0 0 1 0 1 0 1 0 0 1 0 1 1 0 0 0 0 0 1 0\n",
            " 1 0 1 1 0 1 1 1 1 1 0 1 0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 0 1 1 1 0 1 1 1 1 0\n",
            " 0 0 1 1 0 1 1 0 1 1 1 1 1 0 0 0 0 0 0 1 0 1 0 1 1 0 0 1 1 0 0 1 0 0 0 1 1\n",
            " 1 0 0 1 1 1 1 0 0 1 1 0 1 1 0 1 0 0 0 0 1 1 1 1 1 1 0 1 1 0 1 0 1 1 1 0 0\n",
            " 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 1 0 1 1 0 0 1 1 0 1 1 0 0\n",
            " 1 0 1 0 0 0 1 1 0 1 1 0 1 1 1 1 1 0 1 0 1 1 0 1 0 0 0 1 1 1 1 1 0 0 0 0 1\n",
            " 0 0 0 1 0 0 1 0 0 0 0 0 1 1 1 0 1 1 0 1 0 1 1 0 1 0 1 0 1 0 0 0 1 1 1 0 1\n",
            " 1 1 1 1 0 0 0 0 1 1 1 1 0 0 1 0 0 0 0 1 0 0 0 1 1 1 0 1 0 0 1 1 0 0 1 0 1\n",
            " 1 1 1 1 0 1 1 1 1 1 0 0 0 0 1 1 0 0 0 1 0 1 0 1 1 1 0 1 1 0 0 0 1 0 1 1 0\n",
            " 1 1 1 0 0 1 1 1 1 0 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 0 1 0 0 0 0 0 1 0\n",
            " 0 0 1 1 0 1 1 1 1 0 1 1 1 0 0 0 1 1 0 0 1 0 0 1 0 0 1 0 0 1 0 1 1 0 0 1 0\n",
            " 0 0 0 0 1 1 0 1 1 1 1 0 1 0 1 0 0 1 1 0 1 1 1 0 0 1 1 0 0 0 1 1 1 0 1 0 1\n",
            " 1 1 0 1 1 1 0 1 0 1 1 0 1 0 1 1 1 0 0 1 1 1 1 0 0 0 0 1 0 1 0 1 0 0 0 1 0\n",
            " 0 1 0 0 0 1 0 0 1 0 1 0 0 0 0 0 1 0 1 1 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 1 0\n",
            " 1 0 0 1 1 0 1 0 1 1 1 0 0 1 0 0 0 0 0 1 1 0 0 1 0 0 1 0 0 1 1 1 1 1 0 1 0\n",
            " 0 1 0 0 1 0 1 0 1 1 0 0 1 0 0 0 0 0 1 1 1 0 0 1 1 1 1 1 0 1 0 0 0 0 0 0 1\n",
            " 1 0 1 1 0 1 1 1 1 1 1 0 1 0 0 0 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 1 0 0 0 1\n",
            " 1 0 1 1 1 1 1 0 0 0 0 0 1 0 1 0 1 0 0 1 1 0 1 1 1 0 1 0 1 1 0 1 1 1 1 0 1\n",
            " 1 1 0 0 1 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 0 0 1 1 1 1 1 1 1 1 0 0 1 1 0 0 1\n",
            " 0 1 0 0 1 0 0 1 0 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 0 1 1 0 1 0\n",
            " 0 1 0 0 0 1 0 1 1 0 1 1 1 1 0 0 0 1 0 0 1 0 1 1 0 0 0]\n",
            "probabilities: (952, 2) \n",
            " [0 1 1 0 0 0 1 1 0 0 0 0 0 0 1 1 0 1 0 1 0 0 0 1 1 1 1 1 0 1 0 0 0 1 1 0 0\n",
            " 1 0 0 1 1 0 0 0 1 0 1 1 1 1 0 0 0 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 0 1\n",
            " 0 1 0 0 0 0 0 1 0 0 0 1 1 0 0 1 1 1 0 0 0 1 1 1 0 0 0 0 1 1 1 0 1 0 1 0 1\n",
            " 1 1 0 0 1 0 1 0 0 1 0 0 0 0 0 1 0 1 1 0 1 1 0 1 1 1 0 0 0 1 1 1 1 1 1 1 0\n",
            " 1 0 1 1 1 1 1 1 1 1 0 1 0 1 0 0 0 1 1 1 1 1 0 1 1 1 0 1 1 1 0 1 1 0 0 0 1\n",
            " 1 0 0 0 0 1 1 1 0 0 0 0 0 1 1 0 1 0 0 1 0 1 0 1 0 0 1 0 1 1 0 0 0 0 0 1 0\n",
            " 1 0 1 1 0 1 1 1 1 1 0 1 0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 0 1 1 1 0 1 1 1 1 0\n",
            " 0 0 1 1 0 1 1 0 1 1 1 1 1 0 0 0 0 0 0 1 0 1 0 1 1 0 0 1 1 0 0 1 0 0 0 1 1\n",
            " 1 0 0 1 1 1 1 0 0 1 1 0 1 1 0 1 0 0 0 0 1 1 1 1 1 1 0 1 1 0 1 0 1 1 1 0 0\n",
            " 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 1 0 1 1 0 0 1 1 0 1 1 0 0\n",
            " 1 0 1 0 0 0 1 1 0 1 1 0 1 1 1 1 1 0 1 0 1 1 0 1 0 0 0 1 1 1 1 1 0 0 0 0 1\n",
            " 0 0 0 1 0 0 1 0 0 0 0 0 1 1 1 0 1 1 0 1 0 1 1 0 1 0 1 0 1 0 0 0 1 1 1 0 1\n",
            " 1 1 1 1 0 0 0 0 1 1 1 1 0 0 1 0 0 0 0 1 0 0 0 1 1 1 0 1 0 0 1 1 0 0 1 0 1\n",
            " 1 1 1 1 0 1 1 1 1 1 0 0 0 0 1 1 0 0 0 1 0 1 0 1 1 1 0 1 1 0 0 0 1 0 1 1 0\n",
            " 1 1 1 0 0 1 1 1 1 0 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 0 1 0 0 0 0 0 1 0\n",
            " 0 0 1 1 0 1 1 1 1 0 1 1 1 0 0 0 1 1 0 0 1 0 0 1 0 0 1 0 0 1 0 1 1 0 0 1 0\n",
            " 0 0 0 0 1 1 0 1 1 1 1 0 1 0 1 0 0 1 1 0 1 1 1 0 0 1 1 0 0 0 1 1 1 0 1 0 1\n",
            " 1 1 0 1 1 1 0 1 0 1 1 0 1 0 1 1 1 0 0 1 1 1 1 0 0 0 0 1 0 1 0 1 0 0 0 1 0\n",
            " 0 1 0 0 0 1 0 0 1 0 1 0 0 0 0 0 1 0 1 1 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 1 0\n",
            " 1 0 0 1 1 0 1 0 1 1 1 0 0 1 0 0 0 0 0 1 1 0 0 1 0 0 1 0 0 1 1 1 1 1 0 1 0\n",
            " 0 1 0 0 1 0 1 0 1 1 0 0 1 0 0 0 0 0 1 1 1 0 0 1 1 1 1 1 0 1 0 0 0 0 0 0 1\n",
            " 1 0 1 1 0 1 1 1 1 1 1 0 1 0 0 0 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 1 0 0 0 1\n",
            " 1 0 1 1 1 1 1 0 0 0 0 0 1 0 1 0 1 0 0 1 1 0 1 1 1 0 1 0 1 1 0 1 1 1 1 0 1\n",
            " 1 1 0 0 1 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 0 0 1 1 1 1 1 1 1 1 0 0 1 1 0 0 1\n",
            " 0 1 0 0 1 0 0 1 0 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 0 1 1 0 1 0\n",
            " 0 1 0 0 0 1 0 1 1 0 1 1 1 1 0 0 0 1 0 0 1 0 1 1 0 0 0]\n",
            "uniques chosen: 25 <= should be equal to: 25\n",
            "trainset before adding uncertain samples (350, 10) (350,)\n",
            "trainset after adding uncertain samples (375, 10) (375,)\n",
            "updated train set: (375, 10) (375,) unique(labels): [185 190] [0 1]\n",
            "val set: (927, 10) (927,)\n",
            "\n",
            "Train set: (375, 10)\n",
            "Validation set: (927, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 15\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.205 s \n",
            "\n",
            "Accuracy rate is 78.341014 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.87      0.86       321\n",
            "           1       0.59      0.53      0.56       113\n",
            "\n",
            "    accuracy                           0.78       434\n",
            "   macro avg       0.72      0.70      0.71       434\n",
            "weighted avg       0.78      0.78      0.78       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[280  41]\n",
            " [ 53  60]]\n",
            "--------------------------------\n",
            "val predicted: (927,) [0 1 1 0 0 0 1 1 0 0 0 0 0 0 1 1 0 1 0 1 0 0 0 1 1 1 1 1 0 1 0 0 1 1 0 0 1\n",
            " 0 0 1 1 0 0 0 1 0 0 1 1 1 0 0 0 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 0 1\n",
            " 0 0 0 0 0 1 0 0 0 1 0 1 1 1 1 0 0 0 1 1 1 1 0 0 1 1 1 0 1 0 1 0 1 1 0 0 1\n",
            " 0 1 0 0 1 0 0 0 0 0 1 0 1 1 0 1 1 0 1 1 1 0 0 0 1 1 1 1 1 1 1 0 1 0 1 1 1\n",
            " 1 1 1 1 0 1 0 1 0 0 0 1 1 1 1 1 0 1 1 1 0 1 1 1 0 1 1 0 0 0 1 0 0 0 1 1 1\n",
            " 0 0 0 0 1 1 0 1 0 0 1 0 1 0 1 0 0 0 1 1 0 0 0 0 0 1 0 1 0 1 1 0 1 1 1 1 0\n",
            " 1 0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 0 0 1 1 1 1 1 1 1 0 0 0 1 1 0 1 1 0 1 1 1\n",
            " 1 1 0 0 0 0 0 0 1 0 1 0 1 1 0 0 1 1 0 0 1 0 0 0 1 1 1 0 0 1 1 0 1 0 0 1 1\n",
            " 0 1 1 0 1 0 0 0 0 1 1 1 1 1 1 0 1 1 0 1 0 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1\n",
            " 1 1 1 1 1 0 1 1 0 0 1 1 1 0 1 1 0 0 1 1 0 1 1 0 0 1 0 1 0 0 1 1 1 0 1 1 0\n",
            " 1 1 1 1 1 1 0 1 1 0 1 1 0 0 1 1 1 1 1 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 1\n",
            " 1 1 0 1 1 0 1 0 1 1 0 1 0 1 0 1 1 0 0 1 1 0 0 1 1 1 1 1 1 0 0 0 1 1 1 1 0\n",
            " 0 1 0 0 0 0 1 0 0 0 1 1 0 0 0 0 1 1 0 0 1 0 1 1 1 0 0 1 1 1 1 1 0 0 0 0 1\n",
            " 1 0 0 0 1 0 1 0 1 1 1 0 1 1 0 0 0 1 0 1 1 0 1 1 1 0 0 1 1 1 1 0 1 1 1 1 0\n",
            " 1 1 0 0 0 1 1 1 1 1 1 1 1 0 1 0 0 0 0 0 1 0 0 0 1 1 0 1 1 1 1 0 1 1 1 0 0\n",
            " 1 1 0 0 1 1 0 1 0 0 1 0 0 1 0 1 1 0 1 0 0 0 0 0 1 1 0 1 1 1 1 0 1 0 1 0 0\n",
            " 1 1 0 1 1 1 0 0 1 0 0 0 1 1 1 0 1 0 0 1 0 0 1 1 0 1 0 1 1 0 1 0 1 1 1 0 0\n",
            " 1 1 1 1 0 0 0 0 1 0 1 0 1 1 0 0 1 0 1 0 0 1 1 0 0 1 1 1 0 0 0 0 0 1 0 1 1\n",
            " 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 1 0 0 1 1 0 1 0 1 1 1 0 0 1 0 0 0 0 0 1\n",
            " 1 0 0 1 0 0 1 0 0 1 1 1 1 1 0 1 0 0 1 0 0 1 0 1 0 1 1 0 0 1 0 0 0 0 0 1 1\n",
            " 1 0 0 1 1 1 1 1 0 1 1 0 0 0 0 1 1 0 1 0 0 1 1 1 1 1 1 0 1 0 0 1 1 1 1 0 1\n",
            " 1 1 1 0 0 1 0 0 0 1 0 0 0 1 0 1 1 1 1 1 0 0 0 0 0 1 0 1 0 1 0 0 1 1 0 1 1\n",
            " 1 0 1 0 1 1 1 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 0 0 1 1\n",
            " 1 1 1 1 1 1 0 0 1 1 0 0 1 0 1 0 0 1 0 0 1 0 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1\n",
            " 0 0 1 0 1 1 0 1 1 0 1 0 0 1 0 0 0 1 0 1 1 0 1 1 1 1 0 0 1 1 0 0 1 0 1 1 0\n",
            " 0 0]\n",
            "probabilities: (927, 2) \n",
            " [0 1 1 0 0 0 1 1 0 0 0 0 0 0 1 1 0 1 0 1 0 0 0 1 1 1 1 1 0 1 0 0 1 1 0 0 1\n",
            " 0 0 1 1 0 0 0 1 0 0 1 1 1 0 0 0 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 0 1\n",
            " 0 0 0 0 0 1 0 0 0 1 0 1 1 1 1 0 0 0 1 1 1 1 0 0 1 1 1 0 1 0 1 0 1 1 0 0 1\n",
            " 0 1 0 0 1 0 0 0 0 0 1 0 1 1 0 1 1 0 1 1 1 0 0 0 1 1 1 1 1 1 1 0 1 0 1 1 1\n",
            " 1 1 1 1 0 1 0 1 0 0 0 1 1 1 1 1 0 1 1 1 0 1 1 1 0 1 1 0 0 0 1 0 0 0 1 1 1\n",
            " 0 0 0 0 1 1 0 1 0 0 1 0 1 0 1 0 0 0 1 1 0 0 0 0 0 1 0 1 0 1 1 0 1 1 1 1 0\n",
            " 1 0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 0 0 1 1 1 1 1 1 1 0 0 0 1 1 0 1 1 0 1 1 1\n",
            " 1 1 0 0 0 0 0 0 1 0 1 0 1 1 0 0 1 1 0 0 1 0 0 0 1 1 1 0 0 1 1 0 1 0 0 1 1\n",
            " 0 1 1 0 1 0 0 0 0 1 1 1 1 1 1 0 1 1 0 1 0 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1\n",
            " 1 1 1 1 1 0 1 1 0 0 1 1 1 0 1 1 0 0 1 1 0 1 1 0 0 1 0 1 0 0 1 1 1 0 1 1 0\n",
            " 1 1 1 1 1 1 0 1 1 0 1 1 0 0 1 1 1 1 1 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 1\n",
            " 1 1 0 1 1 0 1 0 1 1 0 1 0 1 0 1 1 0 0 1 1 0 0 1 1 1 1 1 1 0 0 0 1 1 1 1 0\n",
            " 0 1 0 0 0 0 1 0 0 0 1 1 0 0 0 0 1 1 0 0 1 0 1 1 1 0 0 1 1 1 1 1 0 0 0 0 1\n",
            " 1 0 0 0 1 0 1 0 1 1 1 0 1 1 0 0 0 1 0 1 1 0 1 1 1 0 0 1 1 1 1 0 1 1 1 1 0\n",
            " 1 1 0 0 0 1 1 1 1 1 1 1 1 0 1 0 0 0 0 0 1 0 0 0 1 1 0 1 1 1 1 0 1 1 1 0 0\n",
            " 1 1 0 0 1 1 0 1 0 0 1 0 0 1 0 1 1 0 1 0 0 0 0 0 1 1 0 1 1 1 1 0 1 0 1 0 0\n",
            " 1 1 0 1 1 1 0 0 1 0 0 0 1 1 1 0 1 0 0 1 0 0 1 1 0 1 0 1 1 0 1 0 1 1 1 0 0\n",
            " 1 1 1 1 0 0 0 0 1 0 1 0 1 1 0 0 1 0 1 0 0 1 1 0 0 1 1 1 0 0 0 0 0 1 0 1 1\n",
            " 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 1 0 0 1 1 0 1 0 1 1 1 0 0 1 0 0 0 0 0 1\n",
            " 1 0 0 1 0 0 1 0 0 1 1 1 1 1 0 1 0 0 1 0 0 1 0 1 0 1 1 0 0 1 0 0 0 0 0 1 1\n",
            " 1 0 0 1 1 1 1 1 0 1 1 0 0 0 0 1 1 0 1 0 0 1 1 1 1 1 1 0 1 0 0 1 1 1 1 0 1\n",
            " 1 1 1 0 0 1 0 0 0 1 0 0 0 1 0 1 1 1 1 1 0 0 0 0 0 1 0 1 0 1 0 0 1 1 0 1 1\n",
            " 1 0 1 0 1 1 1 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 0 0 1 1\n",
            " 1 1 1 1 1 1 0 0 1 1 0 0 1 0 1 0 0 1 0 0 1 0 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1\n",
            " 0 0 1 0 1 1 0 1 1 0 1 0 0 1 0 0 0 1 0 1 1 0 1 1 1 1 0 0 1 1 0 0 1 0 1 1 0\n",
            " 0 0]\n",
            "uniques chosen: 25 <= should be equal to: 25\n",
            "trainset before adding uncertain samples (375, 10) (375,)\n",
            "trainset after adding uncertain samples (400, 10) (400,)\n",
            "updated train set: (400, 10) (400,) unique(labels): [200 200] [0 1]\n",
            "val set: (902, 10) (902,)\n",
            "\n",
            "Train set: (400, 10)\n",
            "Validation set: (902, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 16\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.365 s \n",
            "\n",
            "Accuracy rate is 77.649770 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.86      0.85       321\n",
            "           1       0.58      0.53      0.55       113\n",
            "\n",
            "    accuracy                           0.78       434\n",
            "   macro avg       0.71      0.70      0.70       434\n",
            "weighted avg       0.77      0.78      0.77       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[277  44]\n",
            " [ 53  60]]\n",
            "--------------------------------\n",
            "val predicted: (902,) [0 1 1 0 0 0 1 1 0 1 0 0 0 1 1 1 0 1 1 0 0 0 1 1 1 1 1 0 1 0 0 1 1 0 0 1 0\n",
            " 0 1 1 0 0 0 1 0 1 1 1 1 0 0 0 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 0 1 0 0\n",
            " 0 0 1 0 0 0 1 0 0 1 1 1 0 0 0 1 1 1 0 0 0 1 1 1 0 1 0 1 0 1 1 0 0 1 0 1 0\n",
            " 0 1 0 0 0 0 0 1 0 1 1 0 1 1 0 1 1 1 1 0 0 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1\n",
            " 0 1 0 1 0 0 0 1 0 1 1 1 0 1 1 1 0 1 1 1 0 1 0 0 1 1 0 1 0 1 1 1 0 0 0 0 1\n",
            " 1 0 1 0 0 1 0 1 0 1 0 0 0 1 1 0 0 0 0 0 1 0 1 0 1 1 0 1 1 1 1 1 0 1 0 1 0\n",
            " 1 1 1 0 1 0 1 1 1 1 0 1 1 1 0 1 1 1 1 0 0 0 1 1 0 1 0 1 1 1 1 0 0 0 0 0 1\n",
            " 0 1 0 1 1 0 0 1 1 0 0 1 0 0 0 1 1 1 0 0 1 1 1 1 0 0 1 1 0 1 1 0 1 0 0 0 1\n",
            " 1 1 1 0 1 0 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 0 0 1\n",
            " 1 1 0 1 1 0 0 1 1 0 1 1 0 1 0 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 1 1 0 1\n",
            " 1 1 1 1 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 1 1 1 0 1 1 0 1 0 1 1 0 1 0 1 1\n",
            " 0 0 0 1 1 1 0 1 1 1 1 1 1 0 0 0 1 1 1 1 0 0 1 0 0 0 0 0 0 0 0 1 1 0 1 0 0\n",
            " 1 1 0 0 1 0 1 1 1 0 0 1 1 1 1 1 0 0 0 0 1 1 0 0 0 1 0 1 1 1 1 1 0 1 1 0 0\n",
            " 0 1 0 1 1 0 1 1 1 0 0 1 1 1 1 0 1 1 1 1 0 1 1 0 0 0 1 1 1 1 1 1 1 1 0 1 0\n",
            " 0 0 0 0 1 0 0 0 1 1 0 1 1 1 1 0 1 1 1 0 0 1 1 0 1 1 0 1 0 0 1 0 0 1 0 1 1\n",
            " 0 1 0 0 0 0 0 1 1 0 1 1 1 1 0 1 0 1 0 0 1 1 0 1 1 1 0 0 1 0 0 0 1 1 1 0 1\n",
            " 0 1 1 0 0 1 1 0 1 0 1 1 0 1 0 1 1 0 0 1 1 1 1 0 0 0 0 1 1 0 1 0 0 0 0 1 1\n",
            " 0 1 1 0 0 0 1 0 0 0 0 0 1 0 1 1 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 1 0 1 0 0 1\n",
            " 1 0 1 0 1 1 1 0 0 1 0 0 0 0 0 1 1 1 0 1 0 0 1 0 0 1 1 1 1 1 0 1 0 0 0 1 0\n",
            " 1 0 1 1 0 0 1 0 0 0 0 0 1 1 1 0 0 1 1 1 1 1 0 1 1 0 0 0 0 1 1 0 1 0 0 1 1\n",
            " 1 1 1 1 0 1 0 0 1 1 1 1 0 1 1 1 1 1 0 1 0 0 0 1 0 0 0 1 0 1 1 1 1 1 0 0 0\n",
            " 0 0 1 0 0 1 0 0 1 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 1 1\n",
            " 1 1 0 1 0 0 1 1 1 0 0 1 1 1 1 1 1 1 0 0 1 1 0 0 1 0 1 0 0 1 0 0 1 0 1 0 1\n",
            " 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 0 1 1 0 1 0 0 1 0 0 1 1 0 1 1 0 1 1 1\n",
            " 1 0 0 0 1 0 0 1 0 1 1 0 0 0]\n",
            "probabilities: (902, 2) \n",
            " [0 1 1 0 0 0 1 1 0 1 0 0 0 1 1 1 0 1 1 0 0 0 1 1 1 1 1 0 1 0 0 1 1 0 0 1 0\n",
            " 0 1 1 0 0 0 1 0 1 1 1 1 0 0 0 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 0 1 0 0\n",
            " 0 0 1 0 0 0 1 0 0 1 1 1 0 0 0 1 1 1 0 0 0 1 1 1 0 1 0 1 0 1 1 0 0 1 0 1 0\n",
            " 0 1 0 0 0 0 0 1 0 1 1 0 1 1 0 1 1 1 1 0 0 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1\n",
            " 0 1 0 1 0 0 0 1 0 1 1 1 0 1 1 1 0 1 1 1 0 1 0 0 1 1 0 1 0 1 1 1 0 0 0 0 1\n",
            " 1 0 1 0 0 1 0 1 0 1 0 0 0 1 1 0 0 0 0 0 1 0 1 0 1 1 0 1 1 1 1 1 0 1 0 1 0\n",
            " 1 1 1 0 1 0 1 1 1 1 0 1 1 1 0 1 1 1 1 0 0 0 1 1 0 1 0 1 1 1 1 0 0 0 0 0 1\n",
            " 0 1 0 1 1 0 0 1 1 0 0 1 0 0 0 1 1 1 0 0 1 1 1 1 0 0 1 1 0 1 1 0 1 0 0 0 1\n",
            " 1 1 1 0 1 0 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 0 0 1\n",
            " 1 1 0 1 1 0 0 1 1 0 1 1 0 1 0 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 1 1 0 1\n",
            " 1 1 1 1 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 1 1 1 0 1 1 0 1 0 1 1 0 1 0 1 1\n",
            " 0 0 0 1 1 1 0 1 1 1 1 1 1 0 0 0 1 1 1 1 0 0 1 0 0 0 0 0 0 0 0 1 1 0 1 0 0\n",
            " 1 1 0 0 1 0 1 1 1 0 0 1 1 1 1 1 0 0 0 0 1 1 0 0 0 1 0 1 1 1 1 1 0 1 1 0 0\n",
            " 0 1 0 1 1 0 1 1 1 0 0 1 1 1 1 0 1 1 1 1 0 1 1 0 0 0 1 1 1 1 1 1 1 1 0 1 0\n",
            " 0 0 0 0 1 0 0 0 1 1 0 1 1 1 1 0 1 1 1 0 0 1 1 0 1 1 0 1 0 0 1 0 0 1 0 1 1\n",
            " 0 1 0 0 0 0 0 1 1 0 1 1 1 1 0 1 0 1 0 0 1 1 0 1 1 1 0 0 1 0 0 0 1 1 1 0 1\n",
            " 0 1 1 0 0 1 1 0 1 0 1 1 0 1 0 1 1 0 0 1 1 1 1 0 0 0 0 1 1 0 1 0 0 0 0 1 1\n",
            " 0 1 1 0 0 0 1 0 0 0 0 0 1 0 1 1 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 1 0 1 0 0 1\n",
            " 1 0 1 0 1 1 1 0 0 1 0 0 0 0 0 1 1 1 0 1 0 0 1 0 0 1 1 1 1 1 0 1 0 0 0 1 0\n",
            " 1 0 1 1 0 0 1 0 0 0 0 0 1 1 1 0 0 1 1 1 1 1 0 1 1 0 0 0 0 1 1 0 1 0 0 1 1\n",
            " 1 1 1 1 0 1 0 0 1 1 1 1 0 1 1 1 1 1 0 1 0 0 0 1 0 0 0 1 0 1 1 1 1 1 0 0 0\n",
            " 0 0 1 0 0 1 0 0 1 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 1 1\n",
            " 1 1 0 1 0 0 1 1 1 0 0 1 1 1 1 1 1 1 0 0 1 1 0 0 1 0 1 0 0 1 0 0 1 0 1 0 1\n",
            " 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 0 1 1 0 1 0 0 1 0 0 1 1 0 1 1 0 1 1 1\n",
            " 1 0 0 0 1 0 0 1 0 1 1 0 0 0]\n",
            "uniques chosen: 25 <= should be equal to: 25\n",
            "trainset before adding uncertain samples (400, 10) (400,)\n",
            "trainset after adding uncertain samples (425, 10) (425,)\n",
            "updated train set: (425, 10) (425,) unique(labels): [212 213] [0 1]\n",
            "val set: (877, 10) (877,)\n",
            "\n",
            "Train set: (425, 10)\n",
            "Validation set: (877, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 17\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.223 s \n",
            "\n",
            "Accuracy rate is 79.723502 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.88      0.87       321\n",
            "           1       0.62      0.56      0.59       113\n",
            "\n",
            "    accuracy                           0.80       434\n",
            "   macro avg       0.74      0.72      0.73       434\n",
            "weighted avg       0.79      0.80      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[283  38]\n",
            " [ 50  63]]\n",
            "--------------------------------\n",
            "val predicted: (877,) [0 1 1 0 0 0 1 1 0 0 0 0 0 1 1 0 1 1 0 0 1 1 1 1 0 1 0 0 1 1 0 0 1 0 0 1 0\n",
            " 0 0 1 0 1 1 1 1 0 0 0 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 0 1 0 0 0 0 1 0\n",
            " 0 0 1 0 1 1 1 0 0 0 1 1 1 0 0 1 1 1 0 1 0 1 0 1 1 0 0 1 0 1 0 0 1 0 0 0 0\n",
            " 1 0 1 1 0 1 1 0 1 1 0 0 0 1 0 1 1 1 1 0 0 1 1 1 1 1 1 1 0 1 0 1 0 0 0 1 0\n",
            " 1 1 1 0 1 1 1 0 1 1 1 0 1 0 0 1 1 0 0 0 1 1 1 0 0 0 0 1 1 0 1 0 0 1 0 1 0\n",
            " 1 0 0 0 1 1 0 0 0 0 0 1 0 1 0 1 1 0 1 1 1 1 1 0 1 0 1 0 1 1 1 0 1 0 1 1 1\n",
            " 1 0 1 1 1 1 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 0 0 0 0 0 1 1 0 1 1 0 1 1 0 0\n",
            " 1 0 0 0 1 1 1 0 0 1 1 1 1 0 0 1 1 0 1 1 0 1 0 0 0 1 1 1 1 0 1 0 1 1 1 0 1\n",
            " 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 1\n",
            " 0 1 0 0 0 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 0 0 0 0 1 0 0 0 1\n",
            " 0 0 0 0 0 0 0 1 1 1 0 1 1 0 1 0 1 1 0 1 0 1 1 0 0 0 1 1 0 0 1 1 1 1 1 1 0\n",
            " 0 0 1 1 1 1 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 1 1 0 0 1 0 1 1 1 0 0 1 1 1 1\n",
            " 1 0 0 0 0 1 1 0 0 0 1 0 1 1 1 1 1 0 1 1 0 0 0 1 0 1 1 0 1 1 1 0 0 1 1 1 1\n",
            " 0 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 0 1 0 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
            " 1 1 0 0 1 1 0 1 1 0 1 0 0 1 0 0 1 0 1 1 0 1 0 0 0 0 1 1 0 1 1 1 1 0 1 0 1\n",
            " 0 0 1 1 0 1 1 1 0 0 1 0 0 0 1 1 1 0 1 0 1 1 0 1 1 1 0 1 0 1 1 0 1 0 1 1 0\n",
            " 0 1 1 1 1 0 0 0 0 1 1 0 1 1 0 0 1 0 0 1 1 0 0 0 1 0 0 0 0 1 0 1 1 0 0 0 0\n",
            " 1 1 0 1 1 1 1 0 0 0 0 1 0 1 0 0 1 1 0 1 0 1 1 1 0 0 1 0 0 0 0 0 1 1 0 0 1\n",
            " 0 0 1 0 0 1 1 1 1 1 0 1 0 0 0 1 0 1 0 1 1 0 0 1 0 0 0 0 0 1 1 1 0 0 1 1 1\n",
            " 1 1 0 1 1 0 0 0 0 1 1 0 1 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 0 1 1 1 1 1 0 1\n",
            " 0 0 0 0 0 0 1 0 1 1 1 1 1 0 0 0 0 0 1 0 0 1 0 0 1 1 1 1 0 1 1 1 1 1 1 1 1\n",
            " 0 1 1 1 0 0 1 1 0 1 1 1 1 1 1 0 1 0 0 1 1 1 0 0 1 1 1 1 1 1 1 0 0 1 1 0 1\n",
            " 0 1 0 0 1 0 0 1 0 1 0 1 0 1 1 0 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1 0 1 0 1 0 0\n",
            " 1 0 0 1 1 0 1 1 0 1 1 1 1 0 0 1 1 0 0 1 0 1 1 0 0 0]\n",
            "probabilities: (877, 2) \n",
            " [0 1 1 0 0 0 1 1 0 0 0 0 0 1 1 0 1 1 0 0 1 1 1 1 0 1 0 0 1 1 0 0 1 0 0 1 0\n",
            " 0 0 1 0 1 1 1 1 0 0 0 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 0 1 0 0 0 0 1 0\n",
            " 0 0 1 0 1 1 1 0 0 0 1 1 1 0 0 1 1 1 0 1 0 1 0 1 1 0 0 1 0 1 0 0 1 0 0 0 0\n",
            " 1 0 1 1 0 1 1 0 1 1 0 0 0 1 0 1 1 1 1 0 0 1 1 1 1 1 1 1 0 1 0 1 0 0 0 1 0\n",
            " 1 1 1 0 1 1 1 0 1 1 1 0 1 0 0 1 1 0 0 0 1 1 1 0 0 0 0 1 1 0 1 0 0 1 0 1 0\n",
            " 1 0 0 0 1 1 0 0 0 0 0 1 0 1 0 1 1 0 1 1 1 1 1 0 1 0 1 0 1 1 1 0 1 0 1 1 1\n",
            " 1 0 1 1 1 1 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 0 0 0 0 0 1 1 0 1 1 0 1 1 0 0\n",
            " 1 0 0 0 1 1 1 0 0 1 1 1 1 0 0 1 1 0 1 1 0 1 0 0 0 1 1 1 1 0 1 0 1 1 1 0 1\n",
            " 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 1\n",
            " 0 1 0 0 0 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 0 0 0 0 1 0 0 0 1\n",
            " 0 0 0 0 0 0 0 1 1 1 0 1 1 0 1 0 1 1 0 1 0 1 1 0 0 0 1 1 0 0 1 1 1 1 1 1 0\n",
            " 0 0 1 1 1 1 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 1 1 0 0 1 0 1 1 1 0 0 1 1 1 1\n",
            " 1 0 0 0 0 1 1 0 0 0 1 0 1 1 1 1 1 0 1 1 0 0 0 1 0 1 1 0 1 1 1 0 0 1 1 1 1\n",
            " 0 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 0 1 0 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
            " 1 1 0 0 1 1 0 1 1 0 1 0 0 1 0 0 1 0 1 1 0 1 0 0 0 0 1 1 0 1 1 1 1 0 1 0 1\n",
            " 0 0 1 1 0 1 1 1 0 0 1 0 0 0 1 1 1 0 1 0 1 1 0 1 1 1 0 1 0 1 1 0 1 0 1 1 0\n",
            " 0 1 1 1 1 0 0 0 0 1 1 0 1 1 0 0 1 0 0 1 1 0 0 0 1 0 0 0 0 1 0 1 1 0 0 0 0\n",
            " 1 1 0 1 1 1 1 0 0 0 0 1 0 1 0 0 1 1 0 1 0 1 1 1 0 0 1 0 0 0 0 0 1 1 0 0 1\n",
            " 0 0 1 0 0 1 1 1 1 1 0 1 0 0 0 1 0 1 0 1 1 0 0 1 0 0 0 0 0 1 1 1 0 0 1 1 1\n",
            " 1 1 0 1 1 0 0 0 0 1 1 0 1 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 0 1 1 1 1 1 0 1\n",
            " 0 0 0 0 0 0 1 0 1 1 1 1 1 0 0 0 0 0 1 0 0 1 0 0 1 1 1 1 0 1 1 1 1 1 1 1 1\n",
            " 0 1 1 1 0 0 1 1 0 1 1 1 1 1 1 0 1 0 0 1 1 1 0 0 1 1 1 1 1 1 1 0 0 1 1 0 1\n",
            " 0 1 0 0 1 0 0 1 0 1 0 1 0 1 1 0 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1 0 1 0 1 0 0\n",
            " 1 0 0 1 1 0 1 1 0 1 1 1 1 0 0 1 1 0 0 1 0 1 1 0 0 0]\n",
            "uniques chosen: 25 <= should be equal to: 25\n",
            "trainset before adding uncertain samples (425, 10) (425,)\n",
            "trainset after adding uncertain samples (450, 10) (450,)\n",
            "updated train set: (450, 10) (450,) unique(labels): [224 226] [0 1]\n",
            "val set: (852, 10) (852,)\n",
            "\n",
            "Train set: (450, 10)\n",
            "Validation set: (852, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 18\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.240 s \n",
            "\n",
            "Accuracy rate is 79.953917 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.88      0.87       321\n",
            "           1       0.63      0.57      0.60       113\n",
            "\n",
            "    accuracy                           0.80       434\n",
            "   macro avg       0.74      0.72      0.73       434\n",
            "weighted avg       0.79      0.80      0.80       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[283  38]\n",
            " [ 49  64]]\n",
            "--------------------------------\n",
            "val predicted: (852,) [0 1 1 0 0 0 1 1 0 0 0 1 1 1 0 1 1 0 0 1 1 1 0 1 0 0 1 1 0 0 1 0 0 1 0 0 0\n",
            " 1 0 1 1 1 0 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 0 1 0 0 0 0 1 0 0 0 1 0\n",
            " 1 1 1 0 0 0 1 1 1 0 0 1 1 1 0 1 0 1 0 1 1 0 0 1 0 1 0 0 1 0 0 0 1 0 1 0 0\n",
            " 1 1 0 1 1 1 0 0 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 0 1 0 0 0 1 0 1 1 1 0 1\n",
            " 1 1 0 1 1 1 0 1 0 0 1 1 0 0 0 1 1 1 0 0 0 0 1 1 0 1 0 0 1 0 1 0 1 0 0 0 1\n",
            " 1 0 0 0 0 0 1 0 1 0 1 1 0 1 1 1 1 1 0 1 0 1 0 1 1 1 1 0 1 1 1 0 0 1 1 0 1\n",
            " 1 1 1 0 0 1 1 0 1 0 1 1 1 1 0 0 0 0 0 1 1 0 1 1 0 1 1 0 0 1 0 0 0 1 1 0 0\n",
            " 1 1 1 1 0 1 1 0 1 1 0 1 0 0 0 1 1 1 1 0 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1\n",
            " 0 1 1 1 1 1 1 1 0 1 1 0 1 1 1 0 1 1 0 0 1 1 0 1 1 0 1 0 0 1 1 0 1 1 0 1 1\n",
            " 1 1 1 1 0 1 1 0 0 1 1 1 1 1 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 1 1 1 0 1 1 0\n",
            " 1 0 1 1 0 1 0 1 1 0 0 0 1 1 0 0 1 1 1 1 1 0 0 0 1 1 1 1 0 0 0 0 0 0 1 0 0\n",
            " 0 1 1 0 0 0 0 1 1 0 0 1 0 1 1 1 0 0 1 1 1 1 1 0 0 0 0 1 1 0 0 0 1 0 1 1 1\n",
            " 1 1 0 1 1 0 0 0 1 0 1 1 0 1 1 1 0 0 1 1 1 1 0 1 1 1 1 1 1 0 0 0 1 1 1 1 1\n",
            " 1 1 1 0 1 0 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1 1 1 0 0 1 1 0 1 1 0 1 0 0 1 0\n",
            " 0 1 0 1 1 0 1 0 0 0 0 1 1 0 1 1 1 1 0 1 0 1 0 0 1 1 0 1 1 1 0 0 1 0 0 0 1\n",
            " 1 1 0 1 0 1 1 0 1 1 1 0 1 0 1 1 0 0 0 1 1 0 1 1 1 1 0 0 0 0 1 1 0 1 1 0 0\n",
            " 1 1 0 1 1 0 0 0 1 0 0 0 0 1 0 1 1 0 0 0 0 1 1 0 1 1 1 1 0 0 0 0 0 1 0 0 1\n",
            " 1 0 1 0 1 1 1 0 0 1 0 0 0 0 0 1 1 0 1 0 0 1 0 0 1 1 1 0 0 1 0 0 0 1 0 1 0\n",
            " 1 1 0 0 1 0 0 0 0 0 1 1 1 0 1 1 1 1 1 0 1 1 0 0 0 0 1 1 1 1 1 0 1 1 1 1 1\n",
            " 1 0 1 0 0 1 1 1 1 0 1 1 1 1 1 0 1 0 0 0 0 0 0 1 0 1 1 1 1 1 0 0 0 0 0 1 0\n",
            " 0 0 1 0 1 0 0 1 1 1 1 1 1 1 0 0 1 1 1 0 0 1 1 0 1 1 1 1 1 1 0 1 0 0 1 1 0\n",
            " 1 1 1 1 1 1 1 0 0 1 1 0 1 0 1 0 0 1 0 0 1 0 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1\n",
            " 0 0 1 0 1 1 0 1 1 0 1 0 0 1 0 0 0 1 0 1 1 0 1 1 1 1 0 0 0 0 0 1 0 1 1 0 0\n",
            " 0]\n",
            "probabilities: (852, 2) \n",
            " [0 1 1 0 0 0 1 1 0 0 0 1 1 1 0 1 1 0 0 1 1 1 0 1 0 0 1 1 0 0 1 0 0 1 0 0 0\n",
            " 1 0 1 1 1 0 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 0 1 0 0 0 0 1 0 0 0 1 0\n",
            " 1 1 1 0 0 0 1 1 1 0 0 1 1 1 0 1 0 1 0 1 1 0 0 1 0 1 0 0 1 0 0 0 1 0 1 0 0\n",
            " 1 1 0 1 1 1 0 0 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 0 1 0 0 0 1 0 1 1 1 0 1\n",
            " 1 1 0 1 1 1 0 1 0 0 1 1 0 0 0 1 1 1 0 0 0 0 1 1 0 1 0 0 1 0 1 0 1 0 0 0 1\n",
            " 1 0 0 0 0 0 1 0 1 0 1 1 0 1 1 1 1 1 0 1 0 1 0 1 1 1 1 0 1 1 1 0 0 1 1 0 1\n",
            " 1 1 1 0 0 1 1 0 1 0 1 1 1 1 0 0 0 0 0 1 1 0 1 1 0 1 1 0 0 1 0 0 0 1 1 0 0\n",
            " 1 1 1 1 0 1 1 0 1 1 0 1 0 0 0 1 1 1 1 0 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1\n",
            " 0 1 1 1 1 1 1 1 0 1 1 0 1 1 1 0 1 1 0 0 1 1 0 1 1 0 1 0 0 1 1 0 1 1 0 1 1\n",
            " 1 1 1 1 0 1 1 0 0 1 1 1 1 1 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 1 1 1 0 1 1 0\n",
            " 1 0 1 1 0 1 0 1 1 0 0 0 1 1 0 0 1 1 1 1 1 0 0 0 1 1 1 1 0 0 0 0 0 0 1 0 0\n",
            " 0 1 1 0 0 0 0 1 1 0 0 1 0 1 1 1 0 0 1 1 1 1 1 0 0 0 0 1 1 0 0 0 1 0 1 1 1\n",
            " 1 1 0 1 1 0 0 0 1 0 1 1 0 1 1 1 0 0 1 1 1 1 0 1 1 1 1 1 1 0 0 0 1 1 1 1 1\n",
            " 1 1 1 0 1 0 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1 1 1 0 0 1 1 0 1 1 0 1 0 0 1 0\n",
            " 0 1 0 1 1 0 1 0 0 0 0 1 1 0 1 1 1 1 0 1 0 1 0 0 1 1 0 1 1 1 0 0 1 0 0 0 1\n",
            " 1 1 0 1 0 1 1 0 1 1 1 0 1 0 1 1 0 0 0 1 1 0 1 1 1 1 0 0 0 0 1 1 0 1 1 0 0\n",
            " 1 1 0 1 1 0 0 0 1 0 0 0 0 1 0 1 1 0 0 0 0 1 1 0 1 1 1 1 0 0 0 0 0 1 0 0 1\n",
            " 1 0 1 0 1 1 1 0 0 1 0 0 0 0 0 1 1 0 1 0 0 1 0 0 1 1 1 0 0 1 0 0 0 1 0 1 0\n",
            " 1 1 0 0 1 0 0 0 0 0 1 1 1 0 1 1 1 1 1 0 1 1 0 0 0 0 1 1 1 1 1 0 1 1 1 1 1\n",
            " 1 0 1 0 0 1 1 1 1 0 1 1 1 1 1 0 1 0 0 0 0 0 0 1 0 1 1 1 1 1 0 0 0 0 0 1 0\n",
            " 0 0 1 0 1 0 0 1 1 1 1 1 1 1 0 0 1 1 1 0 0 1 1 0 1 1 1 1 1 1 0 1 0 0 1 1 0\n",
            " 1 1 1 1 1 1 1 0 0 1 1 0 1 0 1 0 0 1 0 0 1 0 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1\n",
            " 0 0 1 0 1 1 0 1 1 0 1 0 0 1 0 0 0 1 0 1 1 0 1 1 1 1 0 0 0 0 0 1 0 1 1 0 0\n",
            " 0]\n",
            "uniques chosen: 25 <= should be equal to: 25\n",
            "trainset before adding uncertain samples (450, 10) (450,)\n",
            "trainset after adding uncertain samples (475, 10) (475,)\n",
            "updated train set: (475, 10) (475,) unique(labels): [234 241] [0 1]\n",
            "val set: (827, 10) (827,)\n",
            "\n",
            "Train set: (475, 10)\n",
            "Validation set: (827, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 19\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.266 s \n",
            "\n",
            "Accuracy rate is 80.184332 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.88      0.87       321\n",
            "           1       0.63      0.57      0.60       113\n",
            "\n",
            "    accuracy                           0.80       434\n",
            "   macro avg       0.74      0.73      0.73       434\n",
            "weighted avg       0.80      0.80      0.80       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[284  37]\n",
            " [ 49  64]]\n",
            "--------------------------------\n",
            "val predicted: (827,) [0 1 1 0 0 0 1 1 0 0 0 1 1 1 0 1 1 0 0 1 1 1 0 1 0 0 1 1 0 0 0 0 0 0 0 0 1\n",
            " 0 1 1 1 0 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 1 1 0 1 0 0 0 1 0 0 1 0 1 1 1 0\n",
            " 0 0 1 1 1 0 0 1 1 1 0 1 0 1 0 1 1 0 0 1 0 1 0 0 1 0 0 0 1 0 1 0 1 1 0 1 1\n",
            " 0 0 0 1 0 1 1 1 1 0 0 1 1 1 1 1 1 1 0 1 0 0 0 0 1 0 1 1 0 1 1 1 0 1 1 1 0\n",
            " 1 0 0 1 1 0 0 0 1 1 1 0 0 0 0 1 1 0 1 0 0 1 0 1 0 1 0 0 0 1 1 0 0 0 0 0 0\n",
            " 1 0 1 1 0 1 1 1 1 1 0 1 0 1 0 1 1 1 0 1 1 1 0 0 1 0 0 1 1 1 1 0 1 1 1 0 1\n",
            " 0 1 1 1 1 0 0 0 0 0 1 1 0 1 1 0 1 1 0 0 1 0 0 0 1 1 0 0 1 1 0 1 0 1 1 0 1\n",
            " 1 0 1 0 0 0 1 1 1 1 0 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0\n",
            " 1 1 0 1 1 1 0 1 1 0 0 1 1 0 1 1 0 1 0 0 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 0 0\n",
            " 1 1 1 1 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 1 1 0 1 1 0 1 0 1 1 0 1 0 1 0\n",
            " 0 0 0 1 1 0 0 1 1 1 1 1 0 0 0 1 1 1 1 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 1 1\n",
            " 0 0 1 0 1 1 1 0 0 1 1 1 1 1 0 0 0 0 1 1 0 0 0 1 0 1 1 1 1 1 0 1 1 0 0 0 1\n",
            " 0 1 1 0 1 1 1 0 0 1 1 1 1 0 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 0 1 0 0 0 0\n",
            " 1 0 0 0 1 1 0 1 1 1 0 1 1 1 0 0 1 1 0 1 0 0 1 0 0 1 0 0 1 0 1 1 0 1 0 0 0\n",
            " 0 1 1 0 1 1 1 1 0 0 0 1 1 0 1 1 1 0 0 1 0 0 0 1 1 1 0 1 0 0 1 0 1 1 1 0 1\n",
            " 0 1 1 1 0 1 1 1 1 1 1 0 0 0 1 1 0 1 1 0 0 1 1 0 0 1 0 0 0 1 0 0 0 0 1 0 1\n",
            " 1 0 0 0 0 1 1 0 1 1 1 0 0 0 0 1 0 0 1 1 0 1 0 1 1 1 0 0 1 0 0 0 0 1 1 0 1\n",
            " 0 0 1 0 0 1 1 1 0 0 1 0 0 0 1 0 1 0 1 1 0 0 1 0 0 0 0 0 1 1 1 0 1 1 1 1 0\n",
            " 1 0 0 0 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 0 0 1 0 1 1 0 1 1 1 1 1 0 0 0 0 0 0\n",
            " 0 0 1 0 1 1 1 1 1 0 0 0 0 0 1 0 0 0 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 0 0 1\n",
            " 1 0 1 1 1 1 1 1 0 1 0 0 1 1 0 1 1 1 1 1 1 0 0 1 1 0 1 0 1 0 0 1 0 0 0 1 0\n",
            " 1 0 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0 1 0 0 1 0 1 0 0 1 0 0 1 1 0 1 1 0 1 1 1\n",
            " 1 0 0 0 0 0 1 0 1 1 0 0 0]\n",
            "probabilities: (827, 2) \n",
            " [0 1 1 0 0 0 1 1 0 0 0 1 1 1 0 1 1 0 0 1 1 1 0 1 0 0 1 1 0 0 0 0 0 0 0 0 1\n",
            " 0 1 1 1 0 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 1 1 0 1 0 0 0 1 0 0 1 0 1 1 1 0\n",
            " 0 0 1 1 1 0 0 1 1 1 0 1 0 1 0 1 1 0 0 1 0 1 0 0 1 0 0 0 1 0 1 0 1 1 0 1 1\n",
            " 0 0 0 1 0 1 1 1 1 0 0 1 1 1 1 1 1 1 0 1 0 0 0 0 1 0 1 1 0 1 1 1 0 1 1 1 0\n",
            " 1 0 0 1 1 0 0 0 1 1 1 0 0 0 0 1 1 0 1 0 0 1 0 1 0 1 0 0 0 1 1 0 0 0 0 0 0\n",
            " 1 0 1 1 0 1 1 1 1 1 0 1 0 1 0 1 1 1 0 1 1 1 0 0 1 0 0 1 1 1 1 0 1 1 1 0 1\n",
            " 0 1 1 1 1 0 0 0 0 0 1 1 0 1 1 0 1 1 0 0 1 0 0 0 1 1 0 0 1 1 0 1 0 1 1 0 1\n",
            " 1 0 1 0 0 0 1 1 1 1 0 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0\n",
            " 1 1 0 1 1 1 0 1 1 0 0 1 1 0 1 1 0 1 0 0 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 0 0\n",
            " 1 1 1 1 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 1 1 0 1 1 0 1 0 1 1 0 1 0 1 0\n",
            " 0 0 0 1 1 0 0 1 1 1 1 1 0 0 0 1 1 1 1 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 1 1\n",
            " 0 0 1 0 1 1 1 0 0 1 1 1 1 1 0 0 0 0 1 1 0 0 0 1 0 1 1 1 1 1 0 1 1 0 0 0 1\n",
            " 0 1 1 0 1 1 1 0 0 1 1 1 1 0 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 0 1 0 0 0 0\n",
            " 1 0 0 0 1 1 0 1 1 1 0 1 1 1 0 0 1 1 0 1 0 0 1 0 0 1 0 0 1 0 1 1 0 1 0 0 0\n",
            " 0 1 1 0 1 1 1 1 0 0 0 1 1 0 1 1 1 0 0 1 0 0 0 1 1 1 0 1 0 0 1 0 1 1 1 0 1\n",
            " 0 1 1 1 0 1 1 1 1 1 1 0 0 0 1 1 0 1 1 0 0 1 1 0 0 1 0 0 0 1 0 0 0 0 1 0 1\n",
            " 1 0 0 0 0 1 1 0 1 1 1 0 0 0 0 1 0 0 1 1 0 1 0 1 1 1 0 0 1 0 0 0 0 1 1 0 1\n",
            " 0 0 1 0 0 1 1 1 0 0 1 0 0 0 1 0 1 0 1 1 0 0 1 0 0 0 0 0 1 1 1 0 1 1 1 1 0\n",
            " 1 0 0 0 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 0 0 1 0 1 1 0 1 1 1 1 1 0 0 0 0 0 0\n",
            " 0 0 1 0 1 1 1 1 1 0 0 0 0 0 1 0 0 0 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 0 0 1\n",
            " 1 0 1 1 1 1 1 1 0 1 0 0 1 1 0 1 1 1 1 1 1 0 0 1 1 0 1 0 1 0 0 1 0 0 0 1 0\n",
            " 1 0 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0 1 0 0 1 0 1 0 0 1 0 0 1 1 0 1 1 0 1 1 1\n",
            " 1 0 0 0 0 0 1 0 1 1 0 0 0]\n",
            "uniques chosen: 25 <= should be equal to: 25\n",
            "trainset before adding uncertain samples (475, 10) (475,)\n",
            "trainset after adding uncertain samples (500, 10) (500,)\n",
            "updated train set: (500, 10) (500,) unique(labels): [245 255] [0 1]\n",
            "val set: (802, 10) (802,)\n",
            "\n",
            "Train set: (500, 10)\n",
            "Validation set: (802, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 20\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.294 s \n",
            "\n",
            "Accuracy rate is 80.875576 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.89      0.87       321\n",
            "           1       0.65      0.58      0.61       113\n",
            "\n",
            "    accuracy                           0.81       434\n",
            "   macro avg       0.75      0.73      0.74       434\n",
            "weighted avg       0.80      0.81      0.80       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[286  35]\n",
            " [ 48  65]]\n",
            "--------------------------------\n",
            "final active learning accuracies [72.35023041474655, 72.11981566820278, 71.88940092165899, 73.04147465437788, 72.81105990783409, 75.11520737327189, 73.50230414746544, 76.036866359447, 76.26728110599078, 76.49769585253456, 76.72811059907833, 77.18894009216591, 76.72811059907833, 78.11059907834101, 78.3410138248848, 77.64976958525345, 79.72350230414746, 79.95391705069125, 80.18433179723502, 80.87557603686636]\n",
            "saved /Users/wenxuanhuang/Documents/Repo/ML-for-COVID-19-dataset/Results/Active-learning-experiment-4.pkl /Users/wenxuanhuang/Documents/Repo/ML-for-COVID-19-dataset ['Decision_tree.ipynb', 'dec_git.png', 'Logit_default_f10.pdf', 'Logistic.ipynb', 'SVC.ipynb', 'RF_f5e50_featureimp.pdf', 'log_al.png', 'dec_git.pdf', '.DS_Store', 'log_git.png', 'svm_git.png', 'Logistic_Scikit.ipynb', 'knn_git.pdf', 'knn_git.png', 'rf_al.png', 'Best classifier_RF_f5e50.pdf', 'KNN.ipynb', 'GBDC.ipynb', 'rf_git.png', 'README.md', 'all_training.csv', 'Results', 'svm_al.png', 'Log_ROC.png', 'Logit_default_f7(p_removal).pdf', 'Active_learning.ipynb', 'Random_forest.ipynb', 'Model_select.ipynb', 'gdbc_git.png', '.git', '.vscode', 'Untitled', 'RF_f5e50_modelselect.pdf', 'Logit_default_f8(std_removal).pdf']\n",
            "\n",
            "---------------------------- FINISHED ---------------------------\n",
            "\n",
            "Count = 5, using model = GDBCModel, selection_function = RandomSelection, k = 10, iteration = 0.\n",
            "\n",
            "initial random chosen samples (10,)\n",
            "initial train set: (10, 10) (10,) unique(labels): [4 6] [0 1]\n",
            "Val set: (1292, 10) (1292,) (10,)\n",
            "\n",
            "Train set: (10, 10)\n",
            "Validation set: (1292, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.568 s \n",
            "\n",
            "Accuracy rate is 63.364055 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.59      0.70       321\n",
            "           1       0.40      0.77      0.52       113\n",
            "\n",
            "    accuracy                           0.63       434\n",
            "   macro avg       0.64      0.68      0.61       434\n",
            "weighted avg       0.75      0.63      0.66       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[188 133]\n",
            " [ 26  87]]\n",
            "--------------------------------\n",
            "val predicted: (1292,) [1 1 1 ... 0 0 0]\n",
            "probabilities: (1292, 2) \n",
            " [1 1 1 ... 0 0 0]\n",
            "uniques chosen: 10 <= should be equal to: 10\n",
            "trainset before adding uncertain samples (10, 10) (10,)\n",
            "trainset after adding uncertain samples (20, 10) (20,)\n",
            "updated train set: (20, 10) (20,) unique(labels): [10 10] [0 1]\n",
            "val set: (1282, 10) (1282,)\n",
            "\n",
            "Train set: (20, 10)\n",
            "Validation set: (1282, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.624 s \n",
            "\n",
            "Accuracy rate is 70.737327 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.72      0.78       321\n",
            "           1       0.46      0.68      0.55       113\n",
            "\n",
            "    accuracy                           0.71       434\n",
            "   macro avg       0.66      0.70      0.67       434\n",
            "weighted avg       0.76      0.71      0.72       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[230  91]\n",
            " [ 36  77]]\n",
            "--------------------------------\n",
            "val predicted: (1282,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1282, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "uniques chosen: 10 <= should be equal to: 10\n",
            "trainset before adding uncertain samples (20, 10) (20,)\n",
            "trainset after adding uncertain samples (30, 10) (30,)\n",
            "updated train set: (30, 10) (30,) unique(labels): [11 19] [0 1]\n",
            "val set: (1272, 10) (1272,)\n",
            "\n",
            "Train set: (30, 10)\n",
            "Validation set: (1272, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 3\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.625 s \n",
            "\n",
            "Accuracy rate is 61.290323 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.60      0.70       321\n",
            "           1       0.36      0.65      0.46       113\n",
            "\n",
            "    accuracy                           0.61       434\n",
            "   macro avg       0.60      0.62      0.58       434\n",
            "weighted avg       0.71      0.61      0.64       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[193 128]\n",
            " [ 40  73]]\n",
            "--------------------------------\n",
            "val predicted: (1272,) [1 1 1 ... 1 0 1]\n",
            "probabilities: (1272, 2) \n",
            " [1 1 1 ... 1 0 1]\n",
            "uniques chosen: 10 <= should be equal to: 10\n",
            "trainset before adding uncertain samples (30, 10) (30,)\n",
            "trainset after adding uncertain samples (40, 10) (40,)\n",
            "updated train set: (40, 10) (40,) unique(labels): [15 25] [0 1]\n",
            "val set: (1262, 10) (1262,)\n",
            "\n",
            "Train set: (40, 10)\n",
            "Validation set: (1262, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 4\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.702 s \n",
            "\n",
            "Accuracy rate is 63.594470 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.63      0.72       321\n",
            "           1       0.38      0.65      0.48       113\n",
            "\n",
            "    accuracy                           0.64       434\n",
            "   macro avg       0.61      0.64      0.60       434\n",
            "weighted avg       0.72      0.64      0.66       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[203 118]\n",
            " [ 40  73]]\n",
            "--------------------------------\n",
            "val predicted: (1262,) [1 1 0 ... 0 0 0]\n",
            "probabilities: (1262, 2) \n",
            " [1 1 0 ... 0 0 0]\n",
            "uniques chosen: 10 <= should be equal to: 10\n",
            "trainset before adding uncertain samples (40, 10) (40,)\n",
            "trainset after adding uncertain samples (50, 10) (50,)\n",
            "updated train set: (50, 10) (50,) unique(labels): [21 29] [0 1]\n",
            "val set: (1252, 10) (1252,)\n",
            "\n",
            "Train set: (50, 10)\n",
            "Validation set: (1252, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 5\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.690 s \n",
            "\n",
            "Accuracy rate is 74.654378 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.82      0.83       321\n",
            "           1       0.51      0.55      0.53       113\n",
            "\n",
            "    accuracy                           0.75       434\n",
            "   macro avg       0.67      0.68      0.68       434\n",
            "weighted avg       0.75      0.75      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[262  59]\n",
            " [ 51  62]]\n",
            "--------------------------------\n",
            "val predicted: (1252,) [0 1 0 ... 0 0 0]\n",
            "probabilities: (1252, 2) \n",
            " [0 1 0 ... 0 0 0]\n",
            "uniques chosen: 10 <= should be equal to: 10\n",
            "trainset before adding uncertain samples (50, 10) (50,)\n",
            "trainset after adding uncertain samples (60, 10) (60,)\n",
            "updated train set: (60, 10) (60,) unique(labels): [26 34] [0 1]\n",
            "val set: (1242, 10) (1242,)\n",
            "\n",
            "Train set: (60, 10)\n",
            "Validation set: (1242, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 6\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.716 s \n",
            "\n",
            "Accuracy rate is 75.806452 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.86      0.84       321\n",
            "           1       0.54      0.47      0.50       113\n",
            "\n",
            "    accuracy                           0.76       434\n",
            "   macro avg       0.68      0.66      0.67       434\n",
            "weighted avg       0.75      0.76      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[276  45]\n",
            " [ 60  53]]\n",
            "--------------------------------\n",
            "val predicted: (1242,) [0 1 0 ... 0 0 0]\n",
            "probabilities: (1242, 2) \n",
            " [0 1 0 ... 0 0 0]\n",
            "uniques chosen: 10 <= should be equal to: 10\n",
            "trainset before adding uncertain samples (60, 10) (60,)\n",
            "trainset after adding uncertain samples (70, 10) (70,)\n",
            "updated train set: (70, 10) (70,) unique(labels): [30 40] [0 1]\n",
            "val set: (1232, 10) (1232,)\n",
            "\n",
            "Train set: (70, 10)\n",
            "Validation set: (1232, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 7\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.728 s \n",
            "\n",
            "Accuracy rate is 76.497696 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.86      0.84       321\n",
            "           1       0.55      0.50      0.52       113\n",
            "\n",
            "    accuracy                           0.76       434\n",
            "   macro avg       0.69      0.68      0.68       434\n",
            "weighted avg       0.76      0.76      0.76       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[276  45]\n",
            " [ 57  56]]\n",
            "--------------------------------\n",
            "val predicted: (1232,) [0 1 0 ... 0 0 0]\n",
            "probabilities: (1232, 2) \n",
            " [0 1 0 ... 0 0 0]\n",
            "uniques chosen: 10 <= should be equal to: 10\n",
            "trainset before adding uncertain samples (70, 10) (70,)\n",
            "trainset after adding uncertain samples (80, 10) (80,)\n",
            "updated train set: (80, 10) (80,) unique(labels): [36 44] [0 1]\n",
            "val set: (1222, 10) (1222,)\n",
            "\n",
            "Train set: (80, 10)\n",
            "Validation set: (1222, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 8\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.733 s \n",
            "\n",
            "Accuracy rate is 76.497696 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.85      0.84       321\n",
            "           1       0.55      0.52      0.54       113\n",
            "\n",
            "    accuracy                           0.76       434\n",
            "   macro avg       0.69      0.69      0.69       434\n",
            "weighted avg       0.76      0.76      0.76       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[273  48]\n",
            " [ 54  59]]\n",
            "--------------------------------\n",
            "val predicted: (1222,) [0 1 0 ... 0 0 0]\n",
            "probabilities: (1222, 2) \n",
            " [0 1 0 ... 0 0 0]\n",
            "uniques chosen: 10 <= should be equal to: 10\n",
            "trainset before adding uncertain samples (80, 10) (80,)\n",
            "trainset after adding uncertain samples (90, 10) (90,)\n",
            "updated train set: (90, 10) (90,) unique(labels): [38 52] [0 1]\n",
            "val set: (1212, 10) (1212,)\n",
            "\n",
            "Train set: (90, 10)\n",
            "Validation set: (1212, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 9\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.757 s \n",
            "\n",
            "Accuracy rate is 77.419355 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.87      0.85       321\n",
            "           1       0.58      0.50      0.54       113\n",
            "\n",
            "    accuracy                           0.77       434\n",
            "   macro avg       0.70      0.69      0.69       434\n",
            "weighted avg       0.77      0.77      0.77       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[279  42]\n",
            " [ 56  57]]\n",
            "--------------------------------\n",
            "val predicted: (1212,) [0 1 0 ... 0 0 0]\n",
            "probabilities: (1212, 2) \n",
            " [0 1 0 ... 0 0 0]\n",
            "uniques chosen: 10 <= should be equal to: 10\n",
            "trainset before adding uncertain samples (90, 10) (90,)\n",
            "trainset after adding uncertain samples (100, 10) (100,)\n",
            "updated train set: (100, 10) (100,) unique(labels): [41 59] [0 1]\n",
            "val set: (1202, 10) (1202,)\n",
            "\n",
            "Train set: (100, 10)\n",
            "Validation set: (1202, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 10\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.763 s \n",
            "\n",
            "Accuracy rate is 76.728111 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.85      0.84       321\n",
            "           1       0.56      0.53      0.54       113\n",
            "\n",
            "    accuracy                           0.77       434\n",
            "   macro avg       0.70      0.69      0.69       434\n",
            "weighted avg       0.76      0.77      0.77       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[273  48]\n",
            " [ 53  60]]\n",
            "--------------------------------\n",
            "val predicted: (1202,) [0 1 0 ... 0 0 0]\n",
            "probabilities: (1202, 2) \n",
            " [0 1 0 ... 0 0 0]\n",
            "uniques chosen: 10 <= should be equal to: 10\n",
            "trainset before adding uncertain samples (100, 10) (100,)\n",
            "trainset after adding uncertain samples (110, 10) (110,)\n",
            "updated train set: (110, 10) (110,) unique(labels): [47 63] [0 1]\n",
            "val set: (1192, 10) (1192,)\n",
            "\n",
            "Train set: (110, 10)\n",
            "Validation set: (1192, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 11\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.781 s \n",
            "\n",
            "Accuracy rate is 78.341014 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.87      0.86       321\n",
            "           1       0.59      0.53      0.56       113\n",
            "\n",
            "    accuracy                           0.78       434\n",
            "   macro avg       0.72      0.70      0.71       434\n",
            "weighted avg       0.78      0.78      0.78       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[280  41]\n",
            " [ 53  60]]\n",
            "--------------------------------\n",
            "val predicted: (1192,) [0 1 0 ... 0 0 0]\n",
            "probabilities: (1192, 2) \n",
            " [0 1 0 ... 0 0 0]\n",
            "uniques chosen: 10 <= should be equal to: 10\n",
            "trainset before adding uncertain samples (110, 10) (110,)\n",
            "trainset after adding uncertain samples (120, 10) (120,)\n",
            "updated train set: (120, 10) (120,) unique(labels): [51 69] [0 1]\n",
            "val set: (1182, 10) (1182,)\n",
            "\n",
            "Train set: (120, 10)\n",
            "Validation set: (1182, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 12\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.779 s \n",
            "\n",
            "Accuracy rate is 78.801843 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86       321\n",
            "           1       0.61      0.53      0.57       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.72      0.70      0.71       434\n",
            "weighted avg       0.78      0.79      0.78       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[282  39]\n",
            " [ 53  60]]\n",
            "--------------------------------\n",
            "val predicted: (1182,) [0 1 0 ... 0 0 0]\n",
            "probabilities: (1182, 2) \n",
            " [0 1 0 ... 0 0 0]\n",
            "uniques chosen: 10 <= should be equal to: 10\n",
            "trainset before adding uncertain samples (120, 10) (120,)\n",
            "trainset after adding uncertain samples (130, 10) (130,)\n",
            "updated train set: (130, 10) (130,) unique(labels): [53 77] [0 1]\n",
            "val set: (1172, 10) (1172,)\n",
            "\n",
            "Train set: (130, 10)\n",
            "Validation set: (1172, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 13\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.803 s \n",
            "\n",
            "Accuracy rate is 77.419355 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.86      0.85       321\n",
            "           1       0.57      0.54      0.55       113\n",
            "\n",
            "    accuracy                           0.77       434\n",
            "   macro avg       0.71      0.70      0.70       434\n",
            "weighted avg       0.77      0.77      0.77       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[275  46]\n",
            " [ 52  61]]\n",
            "--------------------------------\n",
            "val predicted: (1172,) [0 1 0 ... 0 0 0]\n",
            "probabilities: (1172, 2) \n",
            " [0 1 0 ... 0 0 0]\n",
            "uniques chosen: 10 <= should be equal to: 10\n",
            "trainset before adding uncertain samples (130, 10) (130,)\n",
            "trainset after adding uncertain samples (140, 10) (140,)\n",
            "updated train set: (140, 10) (140,) unique(labels): [60 80] [0 1]\n",
            "val set: (1162, 10) (1162,)\n",
            "\n",
            "Train set: (140, 10)\n",
            "Validation set: (1162, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 14\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.816 s \n",
            "\n",
            "Accuracy rate is 79.493088 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.88      0.86       321\n",
            "           1       0.62      0.57      0.59       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.73      0.72      0.73       434\n",
            "weighted avg       0.79      0.79      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[281  40]\n",
            " [ 49  64]]\n",
            "--------------------------------\n",
            "val predicted: (1162,) [0 1 0 ... 0 0 0]\n",
            "probabilities: (1162, 2) \n",
            " [0 1 0 ... 0 0 0]\n",
            "uniques chosen: 10 <= should be equal to: 10\n",
            "trainset before adding uncertain samples (140, 10) (140,)\n",
            "trainset after adding uncertain samples (150, 10) (150,)\n",
            "updated train set: (150, 10) (150,) unique(labels): [66 84] [0 1]\n",
            "val set: (1152, 10) (1152,)\n",
            "\n",
            "Train set: (150, 10)\n",
            "Validation set: (1152, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 15\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.828 s \n",
            "\n",
            "Accuracy rate is 77.649770 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.85      0.85       321\n",
            "           1       0.57      0.56      0.57       113\n",
            "\n",
            "    accuracy                           0.78       434\n",
            "   macro avg       0.71      0.71      0.71       434\n",
            "weighted avg       0.77      0.78      0.78       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[274  47]\n",
            " [ 50  63]]\n",
            "--------------------------------\n",
            "val predicted: (1152,) [0 1 0 ... 0 0 0]\n",
            "probabilities: (1152, 2) \n",
            " [0 1 0 ... 0 0 0]\n",
            "uniques chosen: 10 <= should be equal to: 10\n",
            "trainset before adding uncertain samples (150, 10) (150,)\n",
            "trainset after adding uncertain samples (160, 10) (160,)\n",
            "updated train set: (160, 10) (160,) unique(labels): [71 89] [0 1]\n",
            "val set: (1142, 10) (1142,)\n",
            "\n",
            "Train set: (160, 10)\n",
            "Validation set: (1142, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 16\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.844 s \n",
            "\n",
            "Accuracy rate is 76.958525 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.85      0.84       321\n",
            "           1       0.56      0.55      0.55       113\n",
            "\n",
            "    accuracy                           0.77       434\n",
            "   macro avg       0.70      0.70      0.70       434\n",
            "weighted avg       0.77      0.77      0.77       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[272  49]\n",
            " [ 51  62]]\n",
            "--------------------------------\n",
            "val predicted: (1142,) [0 1 0 ... 0 0 0]\n",
            "probabilities: (1142, 2) \n",
            " [0 1 0 ... 0 0 0]\n",
            "uniques chosen: 10 <= should be equal to: 10\n",
            "trainset before adding uncertain samples (160, 10) (160,)\n",
            "trainset after adding uncertain samples (170, 10) (170,)\n",
            "updated train set: (170, 10) (170,) unique(labels): [76 94] [0 1]\n",
            "val set: (1132, 10) (1132,)\n",
            "\n",
            "Train set: (170, 10)\n",
            "Validation set: (1132, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 17\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.862 s \n",
            "\n",
            "Accuracy rate is 77.188940 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.85      0.85       321\n",
            "           1       0.56      0.56      0.56       113\n",
            "\n",
            "    accuracy                           0.77       434\n",
            "   macro avg       0.70      0.70      0.70       434\n",
            "weighted avg       0.77      0.77      0.77       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[272  49]\n",
            " [ 50  63]]\n",
            "--------------------------------\n",
            "val predicted: (1132,) [0 1 0 ... 0 0 0]\n",
            "probabilities: (1132, 2) \n",
            " [0 1 0 ... 0 0 0]\n",
            "uniques chosen: 10 <= should be equal to: 10\n",
            "trainset before adding uncertain samples (170, 10) (170,)\n",
            "trainset after adding uncertain samples (180, 10) (180,)\n",
            "updated train set: (180, 10) (180,) unique(labels): [ 79 101] [0 1]\n",
            "val set: (1122, 10) (1122,)\n",
            "\n",
            "Train set: (180, 10)\n",
            "Validation set: (1122, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 18\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.884 s \n",
            "\n",
            "Accuracy rate is 76.958525 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.85      0.85       321\n",
            "           1       0.56      0.54      0.55       113\n",
            "\n",
            "    accuracy                           0.77       434\n",
            "   macro avg       0.70      0.70      0.70       434\n",
            "weighted avg       0.77      0.77      0.77       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[273  48]\n",
            " [ 52  61]]\n",
            "--------------------------------\n",
            "val predicted: (1122,) [0 1 0 ... 0 0 0]\n",
            "probabilities: (1122, 2) \n",
            " [0 1 0 ... 0 0 0]\n",
            "uniques chosen: 10 <= should be equal to: 10\n",
            "trainset before adding uncertain samples (180, 10) (180,)\n",
            "trainset after adding uncertain samples (190, 10) (190,)\n",
            "updated train set: (190, 10) (190,) unique(labels): [ 84 106] [0 1]\n",
            "val set: (1112, 10) (1112,)\n",
            "\n",
            "Train set: (190, 10)\n",
            "Validation set: (1112, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 19\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.894 s \n",
            "\n",
            "Accuracy rate is 77.649770 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.85      0.85       321\n",
            "           1       0.57      0.58      0.57       113\n",
            "\n",
            "    accuracy                           0.78       434\n",
            "   macro avg       0.71      0.71      0.71       434\n",
            "weighted avg       0.78      0.78      0.78       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[272  49]\n",
            " [ 48  65]]\n",
            "--------------------------------\n",
            "val predicted: (1112,) [0 1 0 ... 0 0 0]\n",
            "probabilities: (1112, 2) \n",
            " [0 1 0 ... 0 0 0]\n",
            "uniques chosen: 10 <= should be equal to: 10\n",
            "trainset before adding uncertain samples (190, 10) (190,)\n",
            "trainset after adding uncertain samples (200, 10) (200,)\n",
            "updated train set: (200, 10) (200,) unique(labels): [ 88 112] [0 1]\n",
            "val set: (1102, 10) (1102,)\n",
            "\n",
            "Train set: (200, 10)\n",
            "Validation set: (1102, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 20\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.904 s \n",
            "\n",
            "Accuracy rate is 78.110599 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.86      0.85       321\n",
            "           1       0.58      0.56      0.57       113\n",
            "\n",
            "    accuracy                           0.78       434\n",
            "   macro avg       0.71      0.71      0.71       434\n",
            "weighted avg       0.78      0.78      0.78       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[276  45]\n",
            " [ 50  63]]\n",
            "--------------------------------\n",
            "val predicted: (1102,) [0 1 0 ... 0 0 0]\n",
            "probabilities: (1102, 2) \n",
            " [0 1 0 ... 0 0 0]\n",
            "uniques chosen: 10 <= should be equal to: 10\n",
            "trainset before adding uncertain samples (200, 10) (200,)\n",
            "trainset after adding uncertain samples (210, 10) (210,)\n",
            "updated train set: (210, 10) (210,) unique(labels): [ 91 119] [0 1]\n",
            "val set: (1092, 10) (1092,)\n",
            "\n",
            "Train set: (210, 10)\n",
            "Validation set: (1092, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 21\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.917 s \n",
            "\n",
            "Accuracy rate is 78.110599 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.86      0.85       321\n",
            "           1       0.58      0.56      0.57       113\n",
            "\n",
            "    accuracy                           0.78       434\n",
            "   macro avg       0.71      0.71      0.71       434\n",
            "weighted avg       0.78      0.78      0.78       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[276  45]\n",
            " [ 50  63]]\n",
            "--------------------------------\n",
            "val predicted: (1092,) [0 1 0 ... 0 0 0]\n",
            "probabilities: (1092, 2) \n",
            " [0 1 0 ... 0 0 0]\n",
            "uniques chosen: 10 <= should be equal to: 10\n",
            "trainset before adding uncertain samples (210, 10) (210,)\n",
            "trainset after adding uncertain samples (220, 10) (220,)\n",
            "updated train set: (220, 10) (220,) unique(labels): [ 95 125] [0 1]\n",
            "val set: (1082, 10) (1082,)\n",
            "\n",
            "Train set: (220, 10)\n",
            "Validation set: (1082, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 22\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.926 s \n",
            "\n",
            "Accuracy rate is 77.649770 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.85      0.85       321\n",
            "           1       0.57      0.57      0.57       113\n",
            "\n",
            "    accuracy                           0.78       434\n",
            "   macro avg       0.71      0.71      0.71       434\n",
            "weighted avg       0.78      0.78      0.78       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[273  48]\n",
            " [ 49  64]]\n",
            "--------------------------------\n",
            "val predicted: (1082,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1082, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "uniques chosen: 10 <= should be equal to: 10\n",
            "trainset before adding uncertain samples (220, 10) (220,)\n",
            "trainset after adding uncertain samples (230, 10) (230,)\n",
            "updated train set: (230, 10) (230,) unique(labels): [ 98 132] [0 1]\n",
            "val set: (1072, 10) (1072,)\n",
            "\n",
            "Train set: (230, 10)\n",
            "Validation set: (1072, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 23\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.943 s \n",
            "\n",
            "Accuracy rate is 77.649770 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.85      0.85       321\n",
            "           1       0.57      0.57      0.57       113\n",
            "\n",
            "    accuracy                           0.78       434\n",
            "   macro avg       0.71      0.71      0.71       434\n",
            "weighted avg       0.78      0.78      0.78       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[273  48]\n",
            " [ 49  64]]\n",
            "--------------------------------\n",
            "val predicted: (1072,) [0 1 0 ... 0 0 0]\n",
            "probabilities: (1072, 2) \n",
            " [0 1 0 ... 0 0 0]\n",
            "uniques chosen: 10 <= should be equal to: 10\n",
            "trainset before adding uncertain samples (230, 10) (230,)\n",
            "trainset after adding uncertain samples (240, 10) (240,)\n",
            "updated train set: (240, 10) (240,) unique(labels): [103 137] [0 1]\n",
            "val set: (1062, 10) (1062,)\n",
            "\n",
            "Train set: (240, 10)\n",
            "Validation set: (1062, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 24\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.954 s \n",
            "\n",
            "Accuracy rate is 78.341014 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.86      0.85       321\n",
            "           1       0.59      0.56      0.57       113\n",
            "\n",
            "    accuracy                           0.78       434\n",
            "   macro avg       0.72      0.71      0.71       434\n",
            "weighted avg       0.78      0.78      0.78       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[277  44]\n",
            " [ 50  63]]\n",
            "--------------------------------\n",
            "val predicted: (1062,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1062, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "uniques chosen: 10 <= should be equal to: 10\n",
            "trainset before adding uncertain samples (240, 10) (240,)\n",
            "trainset after adding uncertain samples (250, 10) (250,)\n",
            "updated train set: (250, 10) (250,) unique(labels): [108 142] [0 1]\n",
            "val set: (1052, 10) (1052,)\n",
            "\n",
            "Train set: (250, 10)\n",
            "Validation set: (1052, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 25\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.968 s \n",
            "\n",
            "Accuracy rate is 78.571429 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.86      0.86       321\n",
            "           1       0.59      0.57      0.58       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.72      0.71      0.72       434\n",
            "weighted avg       0.78      0.79      0.78       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[277  44]\n",
            " [ 49  64]]\n",
            "--------------------------------\n",
            "val predicted: (1052,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1052, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "uniques chosen: 10 <= should be equal to: 10\n",
            "trainset before adding uncertain samples (250, 10) (250,)\n",
            "trainset after adding uncertain samples (260, 10) (260,)\n",
            "updated train set: (260, 10) (260,) unique(labels): [114 146] [0 1]\n",
            "val set: (1042, 10) (1042,)\n",
            "\n",
            "Train set: (260, 10)\n",
            "Validation set: (1042, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 26\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.031 s \n",
            "\n",
            "Accuracy rate is 77.649770 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.85      0.85       321\n",
            "           1       0.57      0.56      0.57       113\n",
            "\n",
            "    accuracy                           0.78       434\n",
            "   macro avg       0.71      0.71      0.71       434\n",
            "weighted avg       0.77      0.78      0.78       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[274  47]\n",
            " [ 50  63]]\n",
            "--------------------------------\n",
            "val predicted: (1042,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1042, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "uniques chosen: 10 <= should be equal to: 10\n",
            "trainset before adding uncertain samples (260, 10) (260,)\n",
            "trainset after adding uncertain samples (270, 10) (270,)\n",
            "updated train set: (270, 10) (270,) unique(labels): [121 149] [0 1]\n",
            "val set: (1032, 10) (1032,)\n",
            "\n",
            "Train set: (270, 10)\n",
            "Validation set: (1032, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 27\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.009 s \n",
            "\n",
            "Accuracy rate is 77.649770 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.86      0.85       321\n",
            "           1       0.58      0.54      0.56       113\n",
            "\n",
            "    accuracy                           0.78       434\n",
            "   macro avg       0.71      0.70      0.70       434\n",
            "weighted avg       0.77      0.78      0.77       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[276  45]\n",
            " [ 52  61]]\n",
            "--------------------------------\n",
            "val predicted: (1032,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1032, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "uniques chosen: 10 <= should be equal to: 10\n",
            "trainset before adding uncertain samples (270, 10) (270,)\n",
            "trainset after adding uncertain samples (280, 10) (280,)\n",
            "updated train set: (280, 10) (280,) unique(labels): [125 155] [0 1]\n",
            "val set: (1022, 10) (1022,)\n",
            "\n",
            "Train set: (280, 10)\n",
            "Validation set: (1022, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 28\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.021 s \n",
            "\n",
            "Accuracy rate is 77.419355 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.86      0.85       321\n",
            "           1       0.57      0.52      0.55       113\n",
            "\n",
            "    accuracy                           0.77       434\n",
            "   macro avg       0.70      0.69      0.70       434\n",
            "weighted avg       0.77      0.77      0.77       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[277  44]\n",
            " [ 54  59]]\n",
            "--------------------------------\n",
            "val predicted: (1022,) [0 1 0 ... 0 0 0]\n",
            "probabilities: (1022, 2) \n",
            " [0 1 0 ... 0 0 0]\n",
            "uniques chosen: 10 <= should be equal to: 10\n",
            "trainset before adding uncertain samples (280, 10) (280,)\n",
            "trainset after adding uncertain samples (290, 10) (290,)\n",
            "updated train set: (290, 10) (290,) unique(labels): [130 160] [0 1]\n",
            "val set: (1012, 10) (1012,)\n",
            "\n",
            "Train set: (290, 10)\n",
            "Validation set: (1012, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 29\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.042 s \n",
            "\n",
            "Accuracy rate is 77.880184 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.87      0.85       321\n",
            "           1       0.58      0.53      0.56       113\n",
            "\n",
            "    accuracy                           0.78       434\n",
            "   macro avg       0.71      0.70      0.70       434\n",
            "weighted avg       0.77      0.78      0.78       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[278  43]\n",
            " [ 53  60]]\n",
            "--------------------------------\n",
            "val predicted: (1012,) [0 1 0 ... 0 0 0]\n",
            "probabilities: (1012, 2) \n",
            " [0 1 0 ... 0 0 0]\n",
            "uniques chosen: 10 <= should be equal to: 10\n",
            "trainset before adding uncertain samples (290, 10) (290,)\n",
            "trainset after adding uncertain samples (300, 10) (300,)\n",
            "updated train set: (300, 10) (300,) unique(labels): [135 165] [0 1]\n",
            "val set: (1002, 10) (1002,)\n",
            "\n",
            "Train set: (300, 10)\n",
            "Validation set: (1002, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 30\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.046 s \n",
            "\n",
            "Accuracy rate is 77.880184 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.87      0.85       321\n",
            "           1       0.58      0.53      0.56       113\n",
            "\n",
            "    accuracy                           0.78       434\n",
            "   macro avg       0.71      0.70      0.70       434\n",
            "weighted avg       0.77      0.78      0.78       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[278  43]\n",
            " [ 53  60]]\n",
            "--------------------------------\n",
            "val predicted: (1002,) [0 1 0 ... 0 0 0]\n",
            "probabilities: (1002, 2) \n",
            " [0 1 0 ... 0 0 0]\n",
            "uniques chosen: 10 <= should be equal to: 10\n",
            "trainset before adding uncertain samples (300, 10) (300,)\n",
            "trainset after adding uncertain samples (310, 10) (310,)\n",
            "updated train set: (310, 10) (310,) unique(labels): [141 169] [0 1]\n",
            "val set: (992, 10) (992,)\n",
            "\n",
            "Train set: (310, 10)\n",
            "Validation set: (992, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 31\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.060 s \n",
            "\n",
            "Accuracy rate is 77.880184 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.87      0.85       321\n",
            "           1       0.58      0.53      0.56       113\n",
            "\n",
            "    accuracy                           0.78       434\n",
            "   macro avg       0.71      0.70      0.70       434\n",
            "weighted avg       0.77      0.78      0.78       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[278  43]\n",
            " [ 53  60]]\n",
            "--------------------------------\n",
            "val predicted: (992,) [0 1 0 0 0 0 1 1 0 0 1 0 0 0 1 1 1 0 1 1 0 0 0 0 0 0 0 1 0 1 1 0 0 1 0 0 0\n",
            " 1 1 0 1 0 1 0 1 0 0 0 1 0 0 0 1 1 1 0 0 0 1 1 1 0 0 0 1 1 0 1 1 1 1 1 1 0\n",
            " 1 1 0 0 0 1 0 0 0 0 1 0 0 1 1 1 1 0 1 0 0 1 1 1 0 0 0 0 0 1 1 0 0 1 0 0 1\n",
            " 0 1 1 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 1 1 1 0 1 1 1 1 0\n",
            " 0 1 1 0 1 1 0 1 1 1 0 0 1 0 0 0 1 1 0 1 1 1 0 1 1 1 1 0 1 0 1 0 0 1 1 0 1\n",
            " 0 0 0 1 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 1 0 1 0 1 1 0 0 1\n",
            " 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 0 1 0 1 1 1 1 0 1 0 1 0 0 1 1 0 1 1\n",
            " 0 1 1 0 1 1 1 1 1 0 1 1 0 1 1 0 1 0 0 0 0 1 1 1 0 0 0 0 0 1 0 0 1 0 1 0 0\n",
            " 0 0 0 1 0 1 0 1 0 0 1 0 0 0 1 1 0 1 1 1 0 1 1 0 1 0 1 0 1 0 1 0 0 0 0 1 0\n",
            " 1 1 1 0 0 1 0 1 0 1 0 0 1 0 1 0 1 1 0 0 1 1 1 0 1 0 1 0 0 0 1 0 1 1 1 1 1\n",
            " 1 0 0 1 1 0 0 1 1 0 0 1 0 0 1 1 0 1 0 1 0 1 0 0 0 1 1 1 1 0 0 1 0 1 0 0 0\n",
            " 1 1 0 1 1 0 0 1 0 1 1 0 1 0 0 0 0 1 1 0 0 1 0 0 1 0 0 0 1 0 1 0 0 1 0 1 0\n",
            " 1 0 0 1 1 1 1 0 0 1 1 1 1 1 0 1 0 1 0 0 0 0 0 0 0 1 1 0 1 1 1 0 0 1 1 0 0\n",
            " 0 1 0 1 0 0 1 1 0 0 1 0 1 1 0 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 0 1 1 1 1 1 0\n",
            " 0 1 1 1 1 0 0 0 1 0 0 1 1 0 0 1 1 0 1 1 0 1 0 0 0 0 1 1 0 0 1 0 0 1 1 1 1\n",
            " 1 0 1 1 0 1 0 1 1 0 0 0 1 0 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 1 0 0 1 0 1 1 0\n",
            " 1 1 1 1 0 1 1 1 0 1 0 1 0 1 0 0 1 1 1 1 0 1 0 1 0 0 1 0 0 1 0 0 0 1 0 1 1\n",
            " 0 1 1 0 1 1 0 1 1 0 0 0 1 1 0 1 1 1 0 0 0 0 0 0 1 1 1 1 0 1 1 0 1 0 1 1 0\n",
            " 0 1 1 1 1 0 1 0 1 1 1 0 1 1 1 1 0 0 0 1 1 1 1 0 0 1 0 0 1 0 1 0 0 0 1 0 0\n",
            " 0 1 0 1 0 0 0 1 1 1 1 0 0 0 1 0 1 1 1 0 1 1 0 1 0 0 1 1 0 1 1 1 1 1 0 0 0\n",
            " 0 0 1 0 1 1 0 1 0 1 1 1 0 1 0 1 0 1 0 1 0 1 1 0 0 1 1 0 1 0 1 1 1 1 1 0 1\n",
            " 0 0 1 0 0 1 0 1 1 1 0 0 0 1 1 0 1 1 0 1 0 1 0 1 1 0 0 1 0 1 0 1 0 0 0 1 0\n",
            " 1 1 0 0 1 0 0 1 0 1 1 1 1 1 1 0 0 1 0 0 1 0 1 1 1 1 1 0 0 0 0 0 0 1 1 1 0\n",
            " 1 1 0 1 0 0 0 0 0 1 0 1 0 1 1 1 0 0 0 1 1 0 1 0 0 1 0 0 0 0 1 1 1 1 1 1 1\n",
            " 0 0 1 1 1 0 0 1 1 1 1 1 0 1 0 0 0 1 1 1 0 0 1 0 1 1 1 1 1 1 1 1 0 0 1 0 0\n",
            " 1 1 0 1 0 0 1 1 1 0 0 1 0 1 0 1 1 1 1 1 0 1 1 1 1 1 0 1 0 0 1 0 0 1 0 0 1\n",
            " 1 1 1 1 1 1 0 1 0 1 0 0 1 1 1 1 0 1 1 1 0 0 1 1 0 1 1 0 0 0]\n",
            "probabilities: (992, 2) \n",
            " [0 1 0 0 0 0 1 1 0 0 1 0 0 0 1 1 1 0 1 1 0 0 0 0 0 0 0 1 0 1 1 0 0 1 0 0 0\n",
            " 1 1 0 1 0 1 0 1 0 0 0 1 0 0 0 1 1 1 0 0 0 1 1 1 0 0 0 1 1 0 1 1 1 1 1 1 0\n",
            " 1 1 0 0 0 1 0 0 0 0 1 0 0 1 1 1 1 0 1 0 0 1 1 1 0 0 0 0 0 1 1 0 0 1 0 0 1\n",
            " 0 1 1 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 1 1 1 0 1 1 1 1 0\n",
            " 0 1 1 0 1 1 0 1 1 1 0 0 1 0 0 0 1 1 0 1 1 1 0 1 1 1 1 0 1 0 1 0 0 1 1 0 1\n",
            " 0 0 0 1 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 1 0 1 0 1 1 0 0 1\n",
            " 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 0 1 0 1 1 1 1 0 1 0 1 0 0 1 1 0 1 1\n",
            " 0 1 1 0 1 1 1 1 1 0 1 1 0 1 1 0 1 0 0 0 0 1 1 1 0 0 0 0 0 1 0 0 1 0 1 0 0\n",
            " 0 0 0 1 0 1 0 1 0 0 1 0 0 0 1 1 0 1 1 1 0 1 1 0 1 0 1 0 1 0 1 0 0 0 0 1 0\n",
            " 1 1 1 0 0 1 0 1 0 1 0 0 1 0 1 0 1 1 0 0 1 1 1 0 1 0 1 0 0 0 1 0 1 1 1 1 1\n",
            " 1 0 0 1 1 0 0 1 1 0 0 1 0 0 1 1 0 1 0 1 0 1 0 0 0 1 1 1 1 0 0 1 0 1 0 0 0\n",
            " 1 1 0 1 1 0 0 1 0 1 1 0 1 0 0 0 0 1 1 0 0 1 0 0 1 0 0 0 1 0 1 0 0 1 0 1 0\n",
            " 1 0 0 1 1 1 1 0 0 1 1 1 1 1 0 1 0 1 0 0 0 0 0 0 0 1 1 0 1 1 1 0 0 1 1 0 0\n",
            " 0 1 0 1 0 0 1 1 0 0 1 0 1 1 0 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 0 1 1 1 1 1 0\n",
            " 0 1 1 1 1 0 0 0 1 0 0 1 1 0 0 1 1 0 1 1 0 1 0 0 0 0 1 1 0 0 1 0 0 1 1 1 1\n",
            " 1 0 1 1 0 1 0 1 1 0 0 0 1 0 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 1 0 0 1 0 1 1 0\n",
            " 1 1 1 1 0 1 1 1 0 1 0 1 0 1 0 0 1 1 1 1 0 1 0 1 0 0 1 0 0 1 0 0 0 1 0 1 1\n",
            " 0 1 1 0 1 1 0 1 1 0 0 0 1 1 0 1 1 1 0 0 0 0 0 0 1 1 1 1 0 1 1 0 1 0 1 1 0\n",
            " 0 1 1 1 1 0 1 0 1 1 1 0 1 1 1 1 0 0 0 1 1 1 1 0 0 1 0 0 1 0 1 0 0 0 1 0 0\n",
            " 0 1 0 1 0 0 0 1 1 1 1 0 0 0 1 0 1 1 1 0 1 1 0 1 0 0 1 1 0 1 1 1 1 1 0 0 0\n",
            " 0 0 1 0 1 1 0 1 0 1 1 1 0 1 0 1 0 1 0 1 0 1 1 0 0 1 1 0 1 0 1 1 1 1 1 0 1\n",
            " 0 0 1 0 0 1 0 1 1 1 0 0 0 1 1 0 1 1 0 1 0 1 0 1 1 0 0 1 0 1 0 1 0 0 0 1 0\n",
            " 1 1 0 0 1 0 0 1 0 1 1 1 1 1 1 0 0 1 0 0 1 0 1 1 1 1 1 0 0 0 0 0 0 1 1 1 0\n",
            " 1 1 0 1 0 0 0 0 0 1 0 1 0 1 1 1 0 0 0 1 1 0 1 0 0 1 0 0 0 0 1 1 1 1 1 1 1\n",
            " 0 0 1 1 1 0 0 1 1 1 1 1 0 1 0 0 0 1 1 1 0 0 1 0 1 1 1 1 1 1 1 1 0 0 1 0 0\n",
            " 1 1 0 1 0 0 1 1 1 0 0 1 0 1 0 1 1 1 1 1 0 1 1 1 1 1 0 1 0 0 1 0 0 1 0 0 1\n",
            " 1 1 1 1 1 1 0 1 0 1 0 0 1 1 1 1 0 1 1 1 0 0 1 1 0 1 1 0 0 0]\n",
            "uniques chosen: 10 <= should be equal to: 10\n",
            "trainset before adding uncertain samples (310, 10) (310,)\n",
            "trainset after adding uncertain samples (320, 10) (320,)\n",
            "updated train set: (320, 10) (320,) unique(labels): [144 176] [0 1]\n",
            "val set: (982, 10) (982,)\n",
            "\n",
            "Train set: (320, 10)\n",
            "Validation set: (982, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 32\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.069 s \n",
            "\n",
            "Accuracy rate is 78.110599 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.86      0.85       321\n",
            "           1       0.58      0.55      0.57       113\n",
            "\n",
            "    accuracy                           0.78       434\n",
            "   macro avg       0.71      0.71      0.71       434\n",
            "weighted avg       0.78      0.78      0.78       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[277  44]\n",
            " [ 51  62]]\n",
            "--------------------------------\n",
            "val predicted: (982,) [0 1 0 0 0 0 1 1 0 0 1 0 0 0 1 1 1 0 1 1 0 0 0 0 0 0 0 1 0 1 1 0 0 1 1 0 0\n",
            " 1 1 0 1 0 1 0 1 0 0 0 1 0 0 0 1 1 1 0 0 0 1 1 1 0 0 1 1 1 0 1 1 1 1 1 1 0\n",
            " 1 1 0 0 0 1 0 0 0 0 1 0 1 1 1 1 0 1 0 0 1 1 1 0 0 0 0 0 1 1 0 0 1 0 0 1 0\n",
            " 1 1 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 1 1 0 1 1 1 1 0 0\n",
            " 1 1 0 1 1 0 1 0 1 0 0 1 0 0 0 1 1 0 1 1 1 0 1 1 1 1 0 1 0 1 0 1 1 1 0 1 0\n",
            " 0 0 0 0 0 0 1 0 1 1 0 1 0 0 0 0 0 0 1 0 1 0 0 0 1 0 1 0 1 0 1 1 0 0 1 1 0\n",
            " 0 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 0 1 0 1 1 1 1 0 1 0 1 0 0 1 1 0 1 1 0 1\n",
            " 0 1 1 1 1 1 0 1 1 0 1 1 0 1 0 0 0 0 1 1 1 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0\n",
            " 1 0 1 0 1 0 0 1 0 0 0 1 1 0 1 1 1 0 1 0 1 0 1 0 1 0 1 0 0 0 0 1 0 1 1 1 0\n",
            " 0 1 0 1 0 1 0 0 1 0 1 0 1 1 0 0 1 1 1 0 1 0 1 0 0 0 1 0 1 1 1 1 1 1 0 1 1\n",
            " 1 0 0 1 1 0 0 1 0 0 1 1 0 1 0 1 0 1 0 0 0 1 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1\n",
            " 1 0 0 1 0 1 1 0 1 0 0 0 0 1 1 0 0 1 0 0 1 0 0 0 1 0 1 0 1 1 0 1 0 1 1 0 1\n",
            " 1 1 1 0 0 1 1 1 1 1 0 1 0 1 0 0 0 1 0 0 0 1 1 1 1 1 1 0 0 1 1 0 0 0 1 0 1\n",
            " 0 0 1 1 0 0 1 0 1 1 0 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 0 1 1 1 1 1 0 0 1 0 1\n",
            " 1 0 0 0 1 0 0 1 1 0 0 1 1 0 1 1 0 1 0 0 0 0 1 1 0 0 1 0 0 1 1 1 1 1 0 1 1\n",
            " 0 1 1 1 1 0 0 0 1 0 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 1 0 0 1 0 1 1 0 1 1 1 1\n",
            " 0 1 1 1 0 1 0 1 0 1 0 0 1 1 1 0 1 0 1 0 0 1 0 0 1 0 0 0 1 0 1 1 0 1 1 0 1\n",
            " 1 0 1 1 0 0 0 1 1 0 1 1 1 0 0 0 0 0 0 1 1 1 1 0 1 1 0 1 0 1 1 0 0 1 1 1 1\n",
            " 0 1 0 1 1 1 0 1 1 1 0 0 0 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 0 0 1 1 0 1 0 0 0\n",
            " 1 1 1 0 0 0 0 1 0 1 1 1 0 1 1 0 1 0 0 0 1 0 1 1 1 1 1 0 0 0 0 0 1 0 1 1 0\n",
            " 1 0 1 1 1 0 1 0 1 0 1 0 1 0 1 1 0 0 0 1 0 1 0 1 1 1 1 0 1 0 0 1 0 0 1 0 1\n",
            " 1 1 0 0 0 1 1 0 1 1 0 1 0 1 0 1 1 0 0 1 0 1 0 1 0 0 0 1 0 1 1 0 1 1 0 0 1\n",
            " 0 1 1 1 1 1 1 0 0 1 0 0 1 0 1 1 1 1 1 0 0 0 0 0 0 0 1 1 0 1 1 0 1 0 0 0 0\n",
            " 0 1 0 1 0 1 1 1 0 0 0 1 1 0 1 0 0 1 0 0 0 0 1 1 1 1 1 1 1 0 0 1 1 1 0 0 1\n",
            " 1 1 1 0 1 0 0 1 1 1 0 0 1 0 1 1 1 1 1 1 1 1 0 0 1 0 0 1 1 0 1 0 0 1 1 1 0\n",
            " 0 1 0 1 0 1 1 1 1 1 0 1 1 1 1 1 0 1 0 0 1 0 0 1 0 0 1 1 1 1 1 1 1 1 1 0 1\n",
            " 0 0 1 1 1 1 0 1 1 1 0 0 1 1 0 1 1 0 0 0]\n",
            "probabilities: (982, 2) \n",
            " [0 1 0 0 0 0 1 1 0 0 1 0 0 0 1 1 1 0 1 1 0 0 0 0 0 0 0 1 0 1 1 0 0 1 1 0 0\n",
            " 1 1 0 1 0 1 0 1 0 0 0 1 0 0 0 1 1 1 0 0 0 1 1 1 0 0 1 1 1 0 1 1 1 1 1 1 0\n",
            " 1 1 0 0 0 1 0 0 0 0 1 0 1 1 1 1 0 1 0 0 1 1 1 0 0 0 0 0 1 1 0 0 1 0 0 1 0\n",
            " 1 1 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 1 1 0 1 1 1 1 0 0\n",
            " 1 1 0 1 1 0 1 0 1 0 0 1 0 0 0 1 1 0 1 1 1 0 1 1 1 1 0 1 0 1 0 1 1 1 0 1 0\n",
            " 0 0 0 0 0 0 1 0 1 1 0 1 0 0 0 0 0 0 1 0 1 0 0 0 1 0 1 0 1 0 1 1 0 0 1 1 0\n",
            " 0 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 0 1 0 1 1 1 1 0 1 0 1 0 0 1 1 0 1 1 0 1\n",
            " 0 1 1 1 1 1 0 1 1 0 1 1 0 1 0 0 0 0 1 1 1 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0\n",
            " 1 0 1 0 1 0 0 1 0 0 0 1 1 0 1 1 1 0 1 0 1 0 1 0 1 0 1 0 0 0 0 1 0 1 1 1 0\n",
            " 0 1 0 1 0 1 0 0 1 0 1 0 1 1 0 0 1 1 1 0 1 0 1 0 0 0 1 0 1 1 1 1 1 1 0 1 1\n",
            " 1 0 0 1 1 0 0 1 0 0 1 1 0 1 0 1 0 1 0 0 0 1 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1\n",
            " 1 0 0 1 0 1 1 0 1 0 0 0 0 1 1 0 0 1 0 0 1 0 0 0 1 0 1 0 1 1 0 1 0 1 1 0 1\n",
            " 1 1 1 0 0 1 1 1 1 1 0 1 0 1 0 0 0 1 0 0 0 1 1 1 1 1 1 0 0 1 1 0 0 0 1 0 1\n",
            " 0 0 1 1 0 0 1 0 1 1 0 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 0 1 1 1 1 1 0 0 1 0 1\n",
            " 1 0 0 0 1 0 0 1 1 0 0 1 1 0 1 1 0 1 0 0 0 0 1 1 0 0 1 0 0 1 1 1 1 1 0 1 1\n",
            " 0 1 1 1 1 0 0 0 1 0 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 1 0 0 1 0 1 1 0 1 1 1 1\n",
            " 0 1 1 1 0 1 0 1 0 1 0 0 1 1 1 0 1 0 1 0 0 1 0 0 1 0 0 0 1 0 1 1 0 1 1 0 1\n",
            " 1 0 1 1 0 0 0 1 1 0 1 1 1 0 0 0 0 0 0 1 1 1 1 0 1 1 0 1 0 1 1 0 0 1 1 1 1\n",
            " 0 1 0 1 1 1 0 1 1 1 0 0 0 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 0 0 1 1 0 1 0 0 0\n",
            " 1 1 1 0 0 0 0 1 0 1 1 1 0 1 1 0 1 0 0 0 1 0 1 1 1 1 1 0 0 0 0 0 1 0 1 1 0\n",
            " 1 0 1 1 1 0 1 0 1 0 1 0 1 0 1 1 0 0 0 1 0 1 0 1 1 1 1 0 1 0 0 1 0 0 1 0 1\n",
            " 1 1 0 0 0 1 1 0 1 1 0 1 0 1 0 1 1 0 0 1 0 1 0 1 0 0 0 1 0 1 1 0 1 1 0 0 1\n",
            " 0 1 1 1 1 1 1 0 0 1 0 0 1 0 1 1 1 1 1 0 0 0 0 0 0 0 1 1 0 1 1 0 1 0 0 0 0\n",
            " 0 1 0 1 0 1 1 1 0 0 0 1 1 0 1 0 0 1 0 0 0 0 1 1 1 1 1 1 1 0 0 1 1 1 0 0 1\n",
            " 1 1 1 0 1 0 0 1 1 1 0 0 1 0 1 1 1 1 1 1 1 1 0 0 1 0 0 1 1 0 1 0 0 1 1 1 0\n",
            " 0 1 0 1 0 1 1 1 1 1 0 1 1 1 1 1 0 1 0 0 1 0 0 1 0 0 1 1 1 1 1 1 1 1 1 0 1\n",
            " 0 0 1 1 1 1 0 1 1 1 0 0 1 1 0 1 1 0 0 0]\n",
            "uniques chosen: 10 <= should be equal to: 10\n",
            "trainset before adding uncertain samples (320, 10) (320,)\n",
            "trainset after adding uncertain samples (330, 10) (330,)\n",
            "updated train set: (330, 10) (330,) unique(labels): [149 181] [0 1]\n",
            "val set: (972, 10) (972,)\n",
            "\n",
            "Train set: (330, 10)\n",
            "Validation set: (972, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 33\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.082 s \n",
            "\n",
            "Accuracy rate is 77.649770 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.86      0.85       321\n",
            "           1       0.58      0.53      0.55       113\n",
            "\n",
            "    accuracy                           0.78       434\n",
            "   macro avg       0.71      0.70      0.70       434\n",
            "weighted avg       0.77      0.78      0.77       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[277  44]\n",
            " [ 53  60]]\n",
            "--------------------------------\n",
            "val predicted: (972,) [0 1 0 1 0 0 1 1 0 0 1 0 0 0 1 1 1 0 1 1 0 0 0 0 0 0 0 1 0 1 1 0 0 1 1 0 0\n",
            " 1 1 0 1 0 1 0 0 0 0 0 1 1 0 0 1 1 1 0 0 0 1 1 1 0 0 0 1 1 1 1 1 1 1 1 0 1\n",
            " 1 1 0 0 1 0 0 0 1 0 1 1 1 1 0 1 0 0 1 1 1 0 0 0 0 0 1 1 0 0 1 0 0 1 0 1 1\n",
            " 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 1 1 0 1 1 1 1 0 0 1 1 0 1\n",
            " 1 0 1 0 1 0 0 1 0 0 0 1 1 0 1 1 1 0 1 1 1 1 0 1 0 1 0 1 1 1 0 1 0 0 0 1 0\n",
            " 0 0 1 0 1 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 1 0 1 0 1 0 1 1 0 0 1 1 0 0 0 1 1\n",
            " 1 1 1 1 1 1 1 1 1 0 1 0 1 0 1 0 1 1 1 1 0 1 0 1 1 0 1 1 0 1 1 0 1 0 1 1 1\n",
            " 1 1 0 1 1 0 1 1 0 1 0 0 0 0 1 1 1 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 1 0 1 0\n",
            " 1 0 0 1 0 0 0 1 1 0 1 1 1 0 1 0 1 0 1 0 1 0 1 0 0 0 0 1 0 1 1 1 0 1 0 1 0\n",
            " 1 0 0 1 0 1 0 1 1 0 0 1 1 0 0 1 0 1 0 0 0 1 0 1 1 1 1 1 1 0 0 1 1 0 0 1 1\n",
            " 0 0 1 0 0 1 1 0 1 0 1 0 1 0 0 0 0 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 0 0 1 0 1\n",
            " 1 0 1 0 0 0 0 1 1 0 0 1 0 0 1 0 0 0 1 0 0 0 1 1 0 1 0 1 1 0 1 0 1 1 0 0 1\n",
            " 1 1 1 1 0 1 0 1 0 0 0 0 0 0 0 1 1 0 1 1 1 0 0 1 1 0 0 0 1 0 1 0 0 1 1 0 0\n",
            " 1 0 1 1 0 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 0 1 1 0 0 1 0 0\n",
            " 1 1 0 0 1 1 0 1 1 0 1 0 0 0 0 1 1 0 0 1 0 0 1 1 1 1 1 0 1 1 0 1 0 1 1 0 0\n",
            " 0 1 0 1 0 1 1 1 1 1 1 1 0 0 0 1 1 0 1 0 0 1 0 1 1 0 1 1 1 1 0 1 1 1 0 1 0\n",
            " 1 0 1 0 0 1 1 1 0 1 0 1 0 0 1 0 0 1 0 0 0 1 0 1 1 0 1 1 0 1 1 0 1 1 0 0 0\n",
            " 1 1 0 1 1 1 0 0 0 0 0 0 1 1 1 1 0 1 1 0 1 0 1 1 0 0 1 1 1 1 0 0 1 1 1 0 1\n",
            " 1 1 0 0 0 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 0 0 1 1 0 1 0 1 0 1 1 1 1 0 0 0 1\n",
            " 0 1 1 1 0 1 1 0 1 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 1 0 1 1 0 1 0 1 1 1 0 1 0\n",
            " 1 0 1 0 1 0 1 1 0 0 0 1 0 1 0 1 1 1 1 0 1 0 0 1 0 0 1 0 1 1 1 0 0 0 1 1 0\n",
            " 1 1 0 1 0 1 0 1 1 0 0 1 0 1 0 1 0 0 0 1 0 1 1 0 0 1 0 0 1 1 1 1 1 1 1 0 0\n",
            " 1 0 0 1 0 1 1 1 1 1 0 0 0 0 0 0 1 1 1 0 1 1 0 1 0 0 0 0 0 1 0 1 0 1 1 1 0\n",
            " 0 0 1 1 0 1 0 0 1 0 0 0 0 1 1 1 1 1 1 1 0 0 1 1 1 0 0 1 1 1 1 0 1 0 0 1 1\n",
            " 1 0 0 1 0 1 1 1 1 1 1 1 1 1 0 1 0 0 1 1 0 1 0 0 1 1 1 0 0 1 0 1 0 1 1 1 1\n",
            " 1 0 1 1 1 1 1 0 1 0 0 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 0 1 1 1\n",
            " 0 0 1 1 0 1 1 0 0 0]\n",
            "probabilities: (972, 2) \n",
            " [0 1 0 1 0 0 1 1 0 0 1 0 0 0 1 1 1 0 1 1 0 0 0 0 0 0 0 1 0 1 1 0 0 1 1 0 0\n",
            " 1 1 0 1 0 1 0 0 0 0 0 1 1 0 0 1 1 1 0 0 0 1 1 1 0 0 0 1 1 1 1 1 1 1 1 0 1\n",
            " 1 1 0 0 1 0 0 0 1 0 1 1 1 1 0 1 0 0 1 1 1 0 0 0 0 0 1 1 0 0 1 0 0 1 0 1 1\n",
            " 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 1 1 0 1 1 1 1 0 0 1 1 0 1\n",
            " 1 0 1 0 1 0 0 1 0 0 0 1 1 0 1 1 1 0 1 1 1 1 0 1 0 1 0 1 1 1 0 1 0 0 0 1 0\n",
            " 0 0 1 0 1 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 1 0 1 0 1 0 1 1 0 0 1 1 0 0 0 1 1\n",
            " 1 1 1 1 1 1 1 1 1 0 1 0 1 0 1 0 1 1 1 1 0 1 0 1 1 0 1 1 0 1 1 0 1 0 1 1 1\n",
            " 1 1 0 1 1 0 1 1 0 1 0 0 0 0 1 1 1 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 1 0 1 0\n",
            " 1 0 0 1 0 0 0 1 1 0 1 1 1 0 1 0 1 0 1 0 1 0 1 0 0 0 0 1 0 1 1 1 0 1 0 1 0\n",
            " 1 0 0 1 0 1 0 1 1 0 0 1 1 0 0 1 0 1 0 0 0 1 0 1 1 1 1 1 1 0 0 1 1 0 0 1 1\n",
            " 0 0 1 0 0 1 1 0 1 0 1 0 1 0 0 0 0 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 0 0 1 0 1\n",
            " 1 0 1 0 0 0 0 1 1 0 0 1 0 0 1 0 0 0 1 0 0 0 1 1 0 1 0 1 1 0 1 0 1 1 0 0 1\n",
            " 1 1 1 1 0 1 0 1 0 0 0 0 0 0 0 1 1 0 1 1 1 0 0 1 1 0 0 0 1 0 1 0 0 1 1 0 0\n",
            " 1 0 1 1 0 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 0 1 1 0 0 1 0 0\n",
            " 1 1 0 0 1 1 0 1 1 0 1 0 0 0 0 1 1 0 0 1 0 0 1 1 1 1 1 0 1 1 0 1 0 1 1 0 0\n",
            " 0 1 0 1 0 1 1 1 1 1 1 1 0 0 0 1 1 0 1 0 0 1 0 1 1 0 1 1 1 1 0 1 1 1 0 1 0\n",
            " 1 0 1 0 0 1 1 1 0 1 0 1 0 0 1 0 0 1 0 0 0 1 0 1 1 0 1 1 0 1 1 0 1 1 0 0 0\n",
            " 1 1 0 1 1 1 0 0 0 0 0 0 1 1 1 1 0 1 1 0 1 0 1 1 0 0 1 1 1 1 0 0 1 1 1 0 1\n",
            " 1 1 0 0 0 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 0 0 1 1 0 1 0 1 0 1 1 1 1 0 0 0 1\n",
            " 0 1 1 1 0 1 1 0 1 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 1 0 1 1 0 1 0 1 1 1 0 1 0\n",
            " 1 0 1 0 1 0 1 1 0 0 0 1 0 1 0 1 1 1 1 0 1 0 0 1 0 0 1 0 1 1 1 0 0 0 1 1 0\n",
            " 1 1 0 1 0 1 0 1 1 0 0 1 0 1 0 1 0 0 0 1 0 1 1 0 0 1 0 0 1 1 1 1 1 1 1 0 0\n",
            " 1 0 0 1 0 1 1 1 1 1 0 0 0 0 0 0 1 1 1 0 1 1 0 1 0 0 0 0 0 1 0 1 0 1 1 1 0\n",
            " 0 0 1 1 0 1 0 0 1 0 0 0 0 1 1 1 1 1 1 1 0 0 1 1 1 0 0 1 1 1 1 0 1 0 0 1 1\n",
            " 1 0 0 1 0 1 1 1 1 1 1 1 1 1 0 1 0 0 1 1 0 1 0 0 1 1 1 0 0 1 0 1 0 1 1 1 1\n",
            " 1 0 1 1 1 1 1 0 1 0 0 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 0 1 1 1\n",
            " 0 0 1 1 0 1 1 0 0 0]\n",
            "uniques chosen: 10 <= should be equal to: 10\n",
            "trainset before adding uncertain samples (330, 10) (330,)\n",
            "trainset after adding uncertain samples (340, 10) (340,)\n",
            "updated train set: (340, 10) (340,) unique(labels): [151 189] [0 1]\n",
            "val set: (962, 10) (962,)\n",
            "\n",
            "Train set: (340, 10)\n",
            "Validation set: (962, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 34\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.103 s \n",
            "\n",
            "Accuracy rate is 78.341014 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.87      0.86       321\n",
            "           1       0.59      0.54      0.56       113\n",
            "\n",
            "    accuracy                           0.78       434\n",
            "   macro avg       0.72      0.70      0.71       434\n",
            "weighted avg       0.78      0.78      0.78       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[279  42]\n",
            " [ 52  61]]\n",
            "--------------------------------\n",
            "val predicted: (962,) [0 1 0 1 0 0 1 1 0 0 1 0 0 0 1 1 1 0 1 1 0 0 0 0 0 0 0 1 0 1 1 0 0 1 0 0 0\n",
            " 1 1 0 1 0 1 0 0 0 0 0 1 1 0 0 1 1 1 0 0 0 1 1 1 0 0 1 1 1 1 1 1 1 1 1 0 1\n",
            " 1 1 0 0 1 0 0 0 1 0 1 1 1 1 0 1 0 0 1 1 1 0 0 0 0 0 1 1 0 1 1 0 0 1 0 1 1\n",
            " 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 1 1 1 0 1 1 1 1 0 0 1 1 0 1\n",
            " 1 0 1 0 1 0 0 1 0 0 0 1 1 0 1 1 1 0 1 1 1 1 0 1 0 1 0 1 1 1 0 1 0 0 0 1 0\n",
            " 0 0 1 0 1 1 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 1 0 1 1 0 0 0 1 0 0 0 1 1 1\n",
            " 1 1 1 1 1 1 1 1 0 1 0 1 0 1 0 1 1 1 1 0 1 0 1 0 1 1 0 1 1 0 1 0 1 1 1 1 1\n",
            " 0 1 1 0 1 0 1 0 0 0 0 1 1 1 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 1 0 1 0 1 0 0\n",
            " 1 0 0 0 1 1 0 1 1 1 0 1 0 1 0 1 0 1 0 1 0 0 0 0 1 0 1 1 1 0 1 0 0 1 0 0 1\n",
            " 0 1 0 1 1 0 0 1 1 0 0 1 0 1 0 0 0 1 0 1 1 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 0\n",
            " 0 1 1 0 1 0 1 0 1 0 0 0 0 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 0 0 1 0 1 1 0 1 0\n",
            " 0 0 0 1 1 0 0 1 0 0 1 0 0 0 1 1 0 0 1 1 0 1 0 1 1 0 1 0 1 1 0 0 1 1 1 1 1\n",
            " 0 1 0 1 0 0 0 0 0 0 0 1 1 0 1 1 1 0 0 1 1 0 0 0 1 0 1 0 0 1 1 0 0 1 0 1 1\n",
            " 0 0 1 1 1 1 0 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 0 1 1 0 0 1 0 0 1 1 0 0 1\n",
            " 1 0 1 1 0 1 0 0 0 0 1 1 0 0 1 0 0 1 1 1 1 1 0 1 1 0 1 0 1 1 0 0 0 1 0 1 1\n",
            " 1 1 1 1 1 1 1 0 0 1 1 0 1 0 0 1 0 1 1 0 1 1 1 1 0 1 1 1 0 0 1 0 1 0 0 1 1\n",
            " 1 0 1 0 1 0 0 1 0 0 1 0 0 0 1 0 1 1 0 1 1 0 1 1 0 1 1 0 0 0 1 1 0 1 1 1 0\n",
            " 0 0 0 0 0 1 1 1 1 0 1 1 0 1 0 1 1 0 0 1 1 1 1 0 0 1 1 1 0 1 1 1 0 0 0 1 1\n",
            " 1 1 0 1 0 0 1 0 1 0 0 0 1 0 0 1 1 0 1 0 0 0 1 1 1 1 0 0 0 1 0 1 1 1 1 1 1\n",
            " 0 1 0 0 0 0 0 1 1 1 1 0 0 0 0 0 1 0 1 1 0 1 0 1 1 1 0 1 0 1 0 1 0 1 0 1 1\n",
            " 0 0 1 1 0 1 0 1 1 1 1 0 1 0 0 0 0 1 0 1 1 1 0 0 0 1 1 0 1 1 0 1 0 1 0 1 1\n",
            " 0 0 1 0 1 0 1 0 0 0 1 0 1 1 0 1 1 0 0 1 0 1 1 1 1 1 0 0 1 0 0 1 0 1 1 1 1\n",
            " 1 0 0 0 0 0 0 1 1 1 0 1 1 0 1 0 0 0 0 0 1 0 1 0 1 1 1 0 0 0 1 1 0 1 0 0 1\n",
            " 0 0 1 0 1 1 1 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 0 1 1 0 1 1 1 0 0 1 0 1 1 1 1\n",
            " 1 1 1 1 1 0 1 0 0 1 1 0 1 0 0 1 1 1 0 0 1 0 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0\n",
            " 0 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 0 1 1 1 0 0 1 1 0 1 1 0 0 0]\n",
            "probabilities: (962, 2) \n",
            " [0 1 0 1 0 0 1 1 0 0 1 0 0 0 1 1 1 0 1 1 0 0 0 0 0 0 0 1 0 1 1 0 0 1 0 0 0\n",
            " 1 1 0 1 0 1 0 0 0 0 0 1 1 0 0 1 1 1 0 0 0 1 1 1 0 0 1 1 1 1 1 1 1 1 1 0 1\n",
            " 1 1 0 0 1 0 0 0 1 0 1 1 1 1 0 1 0 0 1 1 1 0 0 0 0 0 1 1 0 1 1 0 0 1 0 1 1\n",
            " 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 1 1 1 0 1 1 1 1 0 0 1 1 0 1\n",
            " 1 0 1 0 1 0 0 1 0 0 0 1 1 0 1 1 1 0 1 1 1 1 0 1 0 1 0 1 1 1 0 1 0 0 0 1 0\n",
            " 0 0 1 0 1 1 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 1 0 1 1 0 0 0 1 0 0 0 1 1 1\n",
            " 1 1 1 1 1 1 1 1 0 1 0 1 0 1 0 1 1 1 1 0 1 0 1 0 1 1 0 1 1 0 1 0 1 1 1 1 1\n",
            " 0 1 1 0 1 0 1 0 0 0 0 1 1 1 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 1 0 1 0 1 0 0\n",
            " 1 0 0 0 1 1 0 1 1 1 0 1 0 1 0 1 0 1 0 1 0 0 0 0 1 0 1 1 1 0 1 0 0 1 0 0 1\n",
            " 0 1 0 1 1 0 0 1 1 0 0 1 0 1 0 0 0 1 0 1 1 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 0\n",
            " 0 1 1 0 1 0 1 0 1 0 0 0 0 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 0 0 1 0 1 1 0 1 0\n",
            " 0 0 0 1 1 0 0 1 0 0 1 0 0 0 1 1 0 0 1 1 0 1 0 1 1 0 1 0 1 1 0 0 1 1 1 1 1\n",
            " 0 1 0 1 0 0 0 0 0 0 0 1 1 0 1 1 1 0 0 1 1 0 0 0 1 0 1 0 0 1 1 0 0 1 0 1 1\n",
            " 0 0 1 1 1 1 0 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 0 1 1 0 0 1 0 0 1 1 0 0 1\n",
            " 1 0 1 1 0 1 0 0 0 0 1 1 0 0 1 0 0 1 1 1 1 1 0 1 1 0 1 0 1 1 0 0 0 1 0 1 1\n",
            " 1 1 1 1 1 1 1 0 0 1 1 0 1 0 0 1 0 1 1 0 1 1 1 1 0 1 1 1 0 0 1 0 1 0 0 1 1\n",
            " 1 0 1 0 1 0 0 1 0 0 1 0 0 0 1 0 1 1 0 1 1 0 1 1 0 1 1 0 0 0 1 1 0 1 1 1 0\n",
            " 0 0 0 0 0 1 1 1 1 0 1 1 0 1 0 1 1 0 0 1 1 1 1 0 0 1 1 1 0 1 1 1 0 0 0 1 1\n",
            " 1 1 0 1 0 0 1 0 1 0 0 0 1 0 0 1 1 0 1 0 0 0 1 1 1 1 0 0 0 1 0 1 1 1 1 1 1\n",
            " 0 1 0 0 0 0 0 1 1 1 1 0 0 0 0 0 1 0 1 1 0 1 0 1 1 1 0 1 0 1 0 1 0 1 0 1 1\n",
            " 0 0 1 1 0 1 0 1 1 1 1 0 1 0 0 0 0 1 0 1 1 1 0 0 0 1 1 0 1 1 0 1 0 1 0 1 1\n",
            " 0 0 1 0 1 0 1 0 0 0 1 0 1 1 0 1 1 0 0 1 0 1 1 1 1 1 0 0 1 0 0 1 0 1 1 1 1\n",
            " 1 0 0 0 0 0 0 1 1 1 0 1 1 0 1 0 0 0 0 0 1 0 1 0 1 1 1 0 0 0 1 1 0 1 0 0 1\n",
            " 0 0 1 0 1 1 1 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 0 1 1 0 1 1 1 0 0 1 0 1 1 1 1\n",
            " 1 1 1 1 1 0 1 0 0 1 1 0 1 0 0 1 1 1 0 0 1 0 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0\n",
            " 0 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 0 1 1 1 0 0 1 1 0 1 1 0 0 0]\n",
            "uniques chosen: 10 <= should be equal to: 10\n",
            "trainset before adding uncertain samples (340, 10) (340,)\n",
            "trainset after adding uncertain samples (350, 10) (350,)\n",
            "updated train set: (350, 10) (350,) unique(labels): [156 194] [0 1]\n",
            "val set: (952, 10) (952,)\n",
            "\n",
            "Train set: (350, 10)\n",
            "Validation set: (952, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 35\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.107 s \n",
            "\n",
            "Accuracy rate is 78.801843 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.87      0.86       321\n",
            "           1       0.60      0.56      0.58       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.72      0.71      0.72       434\n",
            "weighted avg       0.78      0.79      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[279  42]\n",
            " [ 50  63]]\n",
            "--------------------------------\n",
            "val predicted: (952,) [0 1 0 1 0 0 1 1 0 0 1 0 0 0 1 1 1 0 1 1 0 0 0 0 0 0 0 1 0 1 1 0 0 1 0 0 0\n",
            " 1 1 0 1 0 1 0 1 0 0 0 1 1 0 0 1 1 1 0 0 0 1 1 1 0 0 0 1 1 1 1 1 1 1 1 0 1\n",
            " 1 0 0 0 0 0 0 1 0 1 1 1 1 0 1 0 0 1 1 1 0 0 0 0 0 1 1 0 1 1 0 0 1 0 1 1 1\n",
            " 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 1 1 0 1 1 1 1 1 0 1 1 0 1 1\n",
            " 0 1 0 1 0 0 1 0 0 0 1 1 0 1 1 1 0 1 1 1 1 0 1 0 1 0 1 1 1 0 1 0 0 0 0 0 0\n",
            " 0 1 0 1 1 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 1 0 1 1 0 0 1 1 0 0 1 1 1 1 1\n",
            " 1 1 1 1 1 1 0 1 0 1 0 1 0 1 1 1 1 0 1 0 1 0 1 1 0 1 1 0 1 0 1 1 1 1 1 0 1\n",
            " 1 0 1 0 1 0 0 0 0 1 1 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 1 0 1 0 1 0 0 0\n",
            " 1 1 0 1 1 1 0 1 0 1 0 1 0 1 0 1 0 0 0 0 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 1 1\n",
            " 0 0 1 1 0 0 1 0 1 0 0 0 1 0 1 1 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 0 0 1 1 0 1\n",
            " 0 1 0 1 0 0 0 0 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 0 0 1 0 1 1 0 1 0 0 0 0 1 1\n",
            " 0 0 1 0 0 1 0 0 0 1 0 1 0 1 1 0 1 0 1 0 0 1 0 1 1 0 0 1 1 1 1 1 0 1 0 1 0\n",
            " 0 0 1 0 0 0 1 1 0 1 1 1 0 0 1 1 0 0 0 1 0 1 0 0 1 1 0 0 1 0 1 1 0 0 1 1 1\n",
            " 1 0 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 0 1 1 0 0 1 0 0 1 1 0 0 1 1 0 1 1 1\n",
            " 1 0 0 0 1 1 0 0 1 0 0 1 1 1 1 1 0 1 1 0 1 0 1 1 0 0 0 1 0 1 0 1 1 1 1 1 1\n",
            " 1 0 0 1 1 1 1 0 0 1 0 0 1 0 1 1 1 1 0 1 1 1 0 1 1 0 1 0 0 1 1 1 0 1 0 1 0\n",
            " 0 0 0 0 1 0 0 0 1 0 1 1 0 1 1 0 1 1 0 1 1 0 0 0 1 1 0 1 1 1 0 0 0 0 0 0 1\n",
            " 1 1 1 0 1 1 0 1 0 1 1 0 0 1 1 1 1 0 0 1 1 1 0 1 1 0 0 0 0 1 1 0 1 0 1 0 0\n",
            " 1 0 1 0 0 0 1 0 0 1 1 0 1 0 1 0 1 1 1 0 0 0 0 1 0 1 1 1 0 1 1 0 1 0 0 0 0\n",
            " 0 1 1 1 1 0 0 0 0 0 1 0 1 1 0 1 0 1 1 1 0 1 0 1 0 1 0 0 1 1 0 0 0 1 0 1 0\n",
            " 1 1 1 1 0 1 0 0 0 0 1 0 1 1 1 0 0 0 1 1 0 1 1 0 1 0 1 1 1 0 0 1 0 1 0 1 0\n",
            " 0 0 1 0 1 1 0 1 1 0 0 1 0 1 1 1 1 1 0 0 1 0 0 1 0 1 1 1 1 1 0 0 0 0 0 0 1\n",
            " 1 0 1 1 0 1 0 0 0 0 0 1 0 1 0 1 1 1 0 0 0 1 1 0 1 0 0 1 0 0 1 0 1 1 1 1 0\n",
            " 1 1 0 0 1 1 1 0 0 1 1 1 1 0 1 1 0 1 1 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 0 0 1\n",
            " 1 0 1 0 0 1 1 1 0 0 1 0 1 0 0 1 1 1 0 1 1 1 1 1 0 1 0 0 1 0 0 1 0 0 1 1 1\n",
            " 1 1 1 1 0 1 0 1 0 0 1 0 1 0 1 1 1 0 0 1 1 0 1 1 0 0 0]\n",
            "probabilities: (952, 2) \n",
            " [0 1 0 1 0 0 1 1 0 0 1 0 0 0 1 1 1 0 1 1 0 0 0 0 0 0 0 1 0 1 1 0 0 1 0 0 0\n",
            " 1 1 0 1 0 1 0 1 0 0 0 1 1 0 0 1 1 1 0 0 0 1 1 1 0 0 0 1 1 1 1 1 1 1 1 0 1\n",
            " 1 0 0 0 0 0 0 1 0 1 1 1 1 0 1 0 0 1 1 1 0 0 0 0 0 1 1 0 1 1 0 0 1 0 1 1 1\n",
            " 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 1 1 0 1 1 1 1 1 0 1 1 0 1 1\n",
            " 0 1 0 1 0 0 1 0 0 0 1 1 0 1 1 1 0 1 1 1 1 0 1 0 1 0 1 1 1 0 1 0 0 0 0 0 0\n",
            " 0 1 0 1 1 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 1 0 1 1 0 0 1 1 0 0 1 1 1 1 1\n",
            " 1 1 1 1 1 1 0 1 0 1 0 1 0 1 1 1 1 0 1 0 1 0 1 1 0 1 1 0 1 0 1 1 1 1 1 0 1\n",
            " 1 0 1 0 1 0 0 0 0 1 1 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 1 0 1 0 1 0 0 0\n",
            " 1 1 0 1 1 1 0 1 0 1 0 1 0 1 0 1 0 0 0 0 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 1 1\n",
            " 0 0 1 1 0 0 1 0 1 0 0 0 1 0 1 1 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 0 0 1 1 0 1\n",
            " 0 1 0 1 0 0 0 0 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 0 0 1 0 1 1 0 1 0 0 0 0 1 1\n",
            " 0 0 1 0 0 1 0 0 0 1 0 1 0 1 1 0 1 0 1 0 0 1 0 1 1 0 0 1 1 1 1 1 0 1 0 1 0\n",
            " 0 0 1 0 0 0 1 1 0 1 1 1 0 0 1 1 0 0 0 1 0 1 0 0 1 1 0 0 1 0 1 1 0 0 1 1 1\n",
            " 1 0 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 0 1 1 0 0 1 0 0 1 1 0 0 1 1 0 1 1 1\n",
            " 1 0 0 0 1 1 0 0 1 0 0 1 1 1 1 1 0 1 1 0 1 0 1 1 0 0 0 1 0 1 0 1 1 1 1 1 1\n",
            " 1 0 0 1 1 1 1 0 0 1 0 0 1 0 1 1 1 1 0 1 1 1 0 1 1 0 1 0 0 1 1 1 0 1 0 1 0\n",
            " 0 0 0 0 1 0 0 0 1 0 1 1 0 1 1 0 1 1 0 1 1 0 0 0 1 1 0 1 1 1 0 0 0 0 0 0 1\n",
            " 1 1 1 0 1 1 0 1 0 1 1 0 0 1 1 1 1 0 0 1 1 1 0 1 1 0 0 0 0 1 1 0 1 0 1 0 0\n",
            " 1 0 1 0 0 0 1 0 0 1 1 0 1 0 1 0 1 1 1 0 0 0 0 1 0 1 1 1 0 1 1 0 1 0 0 0 0\n",
            " 0 1 1 1 1 0 0 0 0 0 1 0 1 1 0 1 0 1 1 1 0 1 0 1 0 1 0 0 1 1 0 0 0 1 0 1 0\n",
            " 1 1 1 1 0 1 0 0 0 0 1 0 1 1 1 0 0 0 1 1 0 1 1 0 1 0 1 1 1 0 0 1 0 1 0 1 0\n",
            " 0 0 1 0 1 1 0 1 1 0 0 1 0 1 1 1 1 1 0 0 1 0 0 1 0 1 1 1 1 1 0 0 0 0 0 0 1\n",
            " 1 0 1 1 0 1 0 0 0 0 0 1 0 1 0 1 1 1 0 0 0 1 1 0 1 0 0 1 0 0 1 0 1 1 1 1 0\n",
            " 1 1 0 0 1 1 1 0 0 1 1 1 1 0 1 1 0 1 1 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 0 0 1\n",
            " 1 0 1 0 0 1 1 1 0 0 1 0 1 0 0 1 1 1 0 1 1 1 1 1 0 1 0 0 1 0 0 1 0 0 1 1 1\n",
            " 1 1 1 1 0 1 0 1 0 0 1 0 1 0 1 1 1 0 0 1 1 0 1 1 0 0 0]\n",
            "uniques chosen: 10 <= should be equal to: 10\n",
            "trainset before adding uncertain samples (350, 10) (350,)\n",
            "trainset after adding uncertain samples (360, 10) (360,)\n",
            "updated train set: (360, 10) (360,) unique(labels): [160 200] [0 1]\n",
            "val set: (942, 10) (942,)\n",
            "\n",
            "Train set: (360, 10)\n",
            "Validation set: (942, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 36\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.122 s \n",
            "\n",
            "Accuracy rate is 79.262673 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.88      0.86       321\n",
            "           1       0.61      0.56      0.58       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.73      0.72      0.72       434\n",
            "weighted avg       0.79      0.79      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[281  40]\n",
            " [ 50  63]]\n",
            "--------------------------------\n",
            "val predicted: (942,) [0 1 0 1 0 0 1 1 0 0 1 0 0 0 1 1 1 0 1 1 1 0 0 0 0 0 0 1 0 1 1 0 0 1 1 0 0\n",
            " 1 1 0 1 0 1 0 0 0 0 0 1 1 0 0 1 1 1 0 0 0 1 1 1 0 0 0 1 1 1 1 1 1 1 1 0 1\n",
            " 1 1 0 0 0 0 0 1 0 1 1 1 1 0 1 0 0 1 1 1 0 0 0 0 0 1 1 0 1 1 0 0 1 0 1 1 1\n",
            " 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 1 1 0 1 1 1 1 1 0 1 1 0 1 1\n",
            " 0 1 1 1 0 0 1 0 0 1 1 1 0 1 1 1 0 1 1 1 1 0 1 0 1 0 1 1 1 0 1 0 0 0 1 0 0\n",
            " 0 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 1 0 1 0 1 1 0 0 0 1 0 0 1 1 1 1 1 1\n",
            " 1 1 1 1 1 0 1 0 1 0 1 0 1 1 1 1 0 1 0 1 0 1 1 0 1 1 0 1 1 1 1 1 1 1 0 1 1\n",
            " 0 1 0 1 0 0 0 0 1 1 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 1 0 1 0 1 0 0 0 1\n",
            " 1 0 1 1 1 0 1 0 1 0 1 0 1 0 1 0 0 0 0 1 0 1 1 1 0 1 0 1 0 0 1 0 1 0 1 1 0\n",
            " 0 1 1 0 0 1 0 1 0 0 1 1 0 1 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 0 0 1 1 0 1 0 1\n",
            " 0 1 0 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 0 0 1 0 1 1 0 1 0 0 0 0 1 1 0 0\n",
            " 1 0 0 1 0 0 0 1 0 1 0 1 1 0 1 0 1 1 0 1 1 1 1 0 0 1 1 1 1 1 0 1 0 1 0 0 0\n",
            " 1 0 0 0 1 1 0 1 1 0 0 1 1 0 0 0 1 0 1 0 0 1 1 0 0 1 0 1 1 0 0 1 1 1 1 0 1\n",
            " 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 0 0 1 0 0 1 1 0 0 1 1 0 1 1 1 1 0 0 0\n",
            " 1 1 0 0 1 0 0 1 1 1 1 1 0 1 1 0 1 1 1 1 0 0 1 0 1 0 1 1 1 1 1 1 1 0 0 1 1\n",
            " 0 1 0 0 1 0 1 1 0 1 1 1 1 0 1 1 1 0 1 1 0 1 0 0 1 1 1 0 1 1 0 0 1 0 0 1 0\n",
            " 0 0 1 0 1 1 0 1 1 0 1 1 0 1 1 0 0 0 1 1 0 1 1 1 0 0 0 0 0 0 1 1 1 1 0 1 1\n",
            " 0 1 0 1 1 0 0 1 1 1 1 0 0 1 1 1 0 1 0 1 0 0 0 1 1 0 1 0 1 0 0 1 0 1 0 0 0\n",
            " 1 0 0 1 1 0 1 0 1 0 1 1 1 1 0 0 0 1 0 1 1 1 0 1 1 0 1 0 0 0 1 1 1 1 0 0 0\n",
            " 0 0 1 0 1 1 0 1 0 1 1 1 0 1 0 1 0 1 0 0 1 1 0 0 0 1 0 1 0 1 1 1 1 0 0 0 0\n",
            " 1 0 1 1 1 0 0 0 1 1 0 1 1 0 1 0 1 1 1 0 0 1 0 1 0 1 0 0 0 1 0 1 1 0 1 1 0\n",
            " 0 1 0 1 1 1 1 1 0 0 1 0 0 1 0 1 1 1 1 1 0 0 0 0 0 0 0 1 0 1 1 0 1 0 0 0 0\n",
            " 0 1 0 1 0 1 1 1 0 0 0 1 1 0 1 0 0 1 0 0 0 0 1 1 1 1 0 1 1 0 0 1 1 1 0 0 1\n",
            " 1 1 1 0 1 1 0 1 1 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 0 0 1 1 0 1 0 0 1 1 1 0 0\n",
            " 1 0 1 0 0 1 1 1 0 1 1 1 1 1 0 1 0 0 1 0 0 0 0 0 1 1 0 1 1 1 1 0 1 0 1 0 0\n",
            " 1 1 1 0 1 1 1 0 0 1 1 0 1 1 0 0 0]\n",
            "probabilities: (942, 2) \n",
            " [0 1 0 1 0 0 1 1 0 0 1 0 0 0 1 1 1 0 1 1 1 0 0 0 0 0 0 1 0 1 1 0 0 1 1 0 0\n",
            " 1 1 0 1 0 1 0 0 0 0 0 1 1 0 0 1 1 1 0 0 0 1 1 1 0 0 0 1 1 1 1 1 1 1 1 0 1\n",
            " 1 1 0 0 0 0 0 1 0 1 1 1 1 0 1 0 0 1 1 1 0 0 0 0 0 1 1 0 1 1 0 0 1 0 1 1 1\n",
            " 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 1 1 0 1 1 1 1 1 0 1 1 0 1 1\n",
            " 0 1 1 1 0 0 1 0 0 1 1 1 0 1 1 1 0 1 1 1 1 0 1 0 1 0 1 1 1 0 1 0 0 0 1 0 0\n",
            " 0 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 1 0 1 0 1 1 0 0 0 1 0 0 1 1 1 1 1 1\n",
            " 1 1 1 1 1 0 1 0 1 0 1 0 1 1 1 1 0 1 0 1 0 1 1 0 1 1 0 1 1 1 1 1 1 1 0 1 1\n",
            " 0 1 0 1 0 0 0 0 1 1 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 1 0 1 0 1 0 0 0 1\n",
            " 1 0 1 1 1 0 1 0 1 0 1 0 1 0 1 0 0 0 0 1 0 1 1 1 0 1 0 1 0 0 1 0 1 0 1 1 0\n",
            " 0 1 1 0 0 1 0 1 0 0 1 1 0 1 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 0 0 1 1 0 1 0 1\n",
            " 0 1 0 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 0 0 1 0 1 1 0 1 0 0 0 0 1 1 0 0\n",
            " 1 0 0 1 0 0 0 1 0 1 0 1 1 0 1 0 1 1 0 1 1 1 1 0 0 1 1 1 1 1 0 1 0 1 0 0 0\n",
            " 1 0 0 0 1 1 0 1 1 0 0 1 1 0 0 0 1 0 1 0 0 1 1 0 0 1 0 1 1 0 0 1 1 1 1 0 1\n",
            " 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 0 0 1 0 0 1 1 0 0 1 1 0 1 1 1 1 0 0 0\n",
            " 1 1 0 0 1 0 0 1 1 1 1 1 0 1 1 0 1 1 1 1 0 0 1 0 1 0 1 1 1 1 1 1 1 0 0 1 1\n",
            " 0 1 0 0 1 0 1 1 0 1 1 1 1 0 1 1 1 0 1 1 0 1 0 0 1 1 1 0 1 1 0 0 1 0 0 1 0\n",
            " 0 0 1 0 1 1 0 1 1 0 1 1 0 1 1 0 0 0 1 1 0 1 1 1 0 0 0 0 0 0 1 1 1 1 0 1 1\n",
            " 0 1 0 1 1 0 0 1 1 1 1 0 0 1 1 1 0 1 0 1 0 0 0 1 1 0 1 0 1 0 0 1 0 1 0 0 0\n",
            " 1 0 0 1 1 0 1 0 1 0 1 1 1 1 0 0 0 1 0 1 1 1 0 1 1 0 1 0 0 0 1 1 1 1 0 0 0\n",
            " 0 0 1 0 1 1 0 1 0 1 1 1 0 1 0 1 0 1 0 0 1 1 0 0 0 1 0 1 0 1 1 1 1 0 0 0 0\n",
            " 1 0 1 1 1 0 0 0 1 1 0 1 1 0 1 0 1 1 1 0 0 1 0 1 0 1 0 0 0 1 0 1 1 0 1 1 0\n",
            " 0 1 0 1 1 1 1 1 0 0 1 0 0 1 0 1 1 1 1 1 0 0 0 0 0 0 0 1 0 1 1 0 1 0 0 0 0\n",
            " 0 1 0 1 0 1 1 1 0 0 0 1 1 0 1 0 0 1 0 0 0 0 1 1 1 1 0 1 1 0 0 1 1 1 0 0 1\n",
            " 1 1 1 0 1 1 0 1 1 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 0 0 1 1 0 1 0 0 1 1 1 0 0\n",
            " 1 0 1 0 0 1 1 1 0 1 1 1 1 1 0 1 0 0 1 0 0 0 0 0 1 1 0 1 1 1 1 0 1 0 1 0 0\n",
            " 1 1 1 0 1 1 1 0 0 1 1 0 1 1 0 0 0]\n",
            "uniques chosen: 10 <= should be equal to: 10\n",
            "trainset before adding uncertain samples (360, 10) (360,)\n",
            "trainset after adding uncertain samples (370, 10) (370,)\n",
            "updated train set: (370, 10) (370,) unique(labels): [164 206] [0 1]\n",
            "val set: (932, 10) (932,)\n",
            "\n",
            "Train set: (370, 10)\n",
            "Validation set: (932, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 37\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.147 s \n",
            "\n",
            "Accuracy rate is 78.571429 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.87      0.86       321\n",
            "           1       0.60      0.55      0.57       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.72      0.71      0.71       434\n",
            "weighted avg       0.78      0.79      0.78       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[279  42]\n",
            " [ 51  62]]\n",
            "--------------------------------\n",
            "val predicted: (932,) [0 1 0 1 0 1 1 0 0 1 0 0 0 1 1 1 0 1 1 1 0 0 0 0 0 0 1 0 1 1 0 0 1 1 0 0 1\n",
            " 1 0 1 0 1 0 0 0 0 0 1 1 0 0 1 1 1 0 0 0 1 1 1 0 0 1 1 1 1 1 1 1 1 0 1 1 1\n",
            " 0 0 0 0 0 1 0 1 1 1 1 0 1 0 0 1 1 1 0 0 0 0 0 1 1 0 1 1 0 1 0 1 1 1 0 0 0\n",
            " 0 1 0 1 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 1 1 0 1 1 1 1 1 0 1 1 0 1 1 0 1 1\n",
            " 1 0 0 1 0 0 1 1 1 0 1 1 1 0 1 1 1 1 0 1 0 1 0 1 1 1 0 1 0 0 0 1 0 0 0 1 0\n",
            " 1 1 0 1 0 0 0 0 0 0 1 0 0 0 1 0 1 0 1 0 1 1 0 0 0 1 0 0 1 1 1 1 1 1 1 1 1\n",
            " 1 1 0 1 0 1 0 1 0 1 1 1 1 0 1 0 1 0 1 1 0 1 1 0 1 1 1 1 1 1 1 0 1 1 0 1 0\n",
            " 1 0 0 0 0 1 1 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 1 0 1 0 1 0 0 0 1 1 0 1\n",
            " 1 1 0 1 0 1 0 1 0 1 0 1 0 0 0 0 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 1 1 0 0 1 1\n",
            " 0 0 1 0 1 0 0 1 1 0 1 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 0 0 1 1 0 1 0 1 0 1 0\n",
            " 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 0 0 1 0 1 1 0 1 0 0 0 0 1 1 0 0 1 0 0\n",
            " 1 0 0 0 1 0 1 0 1 1 0 1 0 1 1 0 1 1 1 1 0 0 1 1 1 1 1 0 1 0 1 0 0 0 1 0 0\n",
            " 0 1 1 0 1 0 0 1 1 0 0 0 1 0 1 0 0 1 1 0 0 1 0 1 1 0 0 1 1 1 1 0 1 1 0 1 1\n",
            " 1 1 1 1 1 1 1 1 0 1 0 1 1 0 0 1 0 0 1 1 0 0 1 1 0 1 1 1 1 0 0 0 1 1 0 0 1\n",
            " 0 0 1 1 1 1 1 0 1 1 0 1 0 1 1 0 0 1 0 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 0 0 1\n",
            " 0 1 1 0 1 1 1 1 0 1 1 1 0 1 1 0 1 0 0 1 1 1 0 1 1 1 1 0 0 1 0 0 0 1 0 1 1\n",
            " 1 1 1 0 1 1 0 1 1 0 0 0 1 1 0 1 1 1 0 0 0 0 0 0 1 1 1 1 0 1 1 0 1 0 1 0 0\n",
            " 1 1 1 1 0 0 1 1 1 0 1 0 0 0 0 0 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 0 0 1 1 0 1\n",
            " 0 1 0 1 1 1 1 0 0 0 1 0 1 1 1 0 1 1 0 1 0 0 0 1 1 1 1 0 0 0 0 0 1 0 0 1 0\n",
            " 1 0 1 1 1 0 1 0 1 0 1 0 0 1 1 0 0 0 1 0 1 0 1 1 1 1 0 0 0 0 1 0 1 1 1 0 0\n",
            " 0 1 1 0 1 1 0 1 0 1 1 1 0 0 1 0 1 0 1 0 0 0 1 0 1 1 1 1 0 0 1 0 1 1 1 1 1\n",
            " 0 0 1 0 0 1 0 1 1 1 1 1 0 0 0 0 0 0 0 1 0 1 1 0 1 0 0 0 0 0 1 0 1 0 1 1 1\n",
            " 0 0 0 1 1 0 1 0 0 1 0 0 0 0 1 1 1 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 0 1 1 0 1\n",
            " 1 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 0 0 1 0 0 0 1 1 1 0 0 1 0 1 0 1 1 1 1 0 1\n",
            " 1 1 1 1 0 1 0 0 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 0 1 1 1 0 0 1\n",
            " 1 0 1 1 0 0 0]\n",
            "probabilities: (932, 2) \n",
            " [0 1 0 1 0 1 1 0 0 1 0 0 0 1 1 1 0 1 1 1 0 0 0 0 0 0 1 0 1 1 0 0 1 1 0 0 1\n",
            " 1 0 1 0 1 0 0 0 0 0 1 1 0 0 1 1 1 0 0 0 1 1 1 0 0 1 1 1 1 1 1 1 1 0 1 1 1\n",
            " 0 0 0 0 0 1 0 1 1 1 1 0 1 0 0 1 1 1 0 0 0 0 0 1 1 0 1 1 0 1 0 1 1 1 0 0 0\n",
            " 0 1 0 1 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 1 1 0 1 1 1 1 1 0 1 1 0 1 1 0 1 1\n",
            " 1 0 0 1 0 0 1 1 1 0 1 1 1 0 1 1 1 1 0 1 0 1 0 1 1 1 0 1 0 0 0 1 0 0 0 1 0\n",
            " 1 1 0 1 0 0 0 0 0 0 1 0 0 0 1 0 1 0 1 0 1 1 0 0 0 1 0 0 1 1 1 1 1 1 1 1 1\n",
            " 1 1 0 1 0 1 0 1 0 1 1 1 1 0 1 0 1 0 1 1 0 1 1 0 1 1 1 1 1 1 1 0 1 1 0 1 0\n",
            " 1 0 0 0 0 1 1 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 1 0 1 0 1 0 0 0 1 1 0 1\n",
            " 1 1 0 1 0 1 0 1 0 1 0 1 0 0 0 0 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 1 1 0 0 1 1\n",
            " 0 0 1 0 1 0 0 1 1 0 1 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 0 0 1 1 0 1 0 1 0 1 0\n",
            " 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 0 0 1 0 1 1 0 1 0 0 0 0 1 1 0 0 1 0 0\n",
            " 1 0 0 0 1 0 1 0 1 1 0 1 0 1 1 0 1 1 1 1 0 0 1 1 1 1 1 0 1 0 1 0 0 0 1 0 0\n",
            " 0 1 1 0 1 0 0 1 1 0 0 0 1 0 1 0 0 1 1 0 0 1 0 1 1 0 0 1 1 1 1 0 1 1 0 1 1\n",
            " 1 1 1 1 1 1 1 1 0 1 0 1 1 0 0 1 0 0 1 1 0 0 1 1 0 1 1 1 1 0 0 0 1 1 0 0 1\n",
            " 0 0 1 1 1 1 1 0 1 1 0 1 0 1 1 0 0 1 0 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 0 0 1\n",
            " 0 1 1 0 1 1 1 1 0 1 1 1 0 1 1 0 1 0 0 1 1 1 0 1 1 1 1 0 0 1 0 0 0 1 0 1 1\n",
            " 1 1 1 0 1 1 0 1 1 0 0 0 1 1 0 1 1 1 0 0 0 0 0 0 1 1 1 1 0 1 1 0 1 0 1 0 0\n",
            " 1 1 1 1 0 0 1 1 1 0 1 0 0 0 0 0 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 0 0 1 1 0 1\n",
            " 0 1 0 1 1 1 1 0 0 0 1 0 1 1 1 0 1 1 0 1 0 0 0 1 1 1 1 0 0 0 0 0 1 0 0 1 0\n",
            " 1 0 1 1 1 0 1 0 1 0 1 0 0 1 1 0 0 0 1 0 1 0 1 1 1 1 0 0 0 0 1 0 1 1 1 0 0\n",
            " 0 1 1 0 1 1 0 1 0 1 1 1 0 0 1 0 1 0 1 0 0 0 1 0 1 1 1 1 0 0 1 0 1 1 1 1 1\n",
            " 0 0 1 0 0 1 0 1 1 1 1 1 0 0 0 0 0 0 0 1 0 1 1 0 1 0 0 0 0 0 1 0 1 0 1 1 1\n",
            " 0 0 0 1 1 0 1 0 0 1 0 0 0 0 1 1 1 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 0 1 1 0 1\n",
            " 1 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 0 0 1 0 0 0 1 1 1 0 0 1 0 1 0 1 1 1 1 0 1\n",
            " 1 1 1 1 0 1 0 0 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 0 1 1 1 0 0 1\n",
            " 1 0 1 1 0 0 0]\n",
            "uniques chosen: 10 <= should be equal to: 10\n",
            "trainset before adding uncertain samples (370, 10) (370,)\n",
            "trainset after adding uncertain samples (380, 10) (380,)\n",
            "updated train set: (380, 10) (380,) unique(labels): [169 211] [0 1]\n",
            "val set: (922, 10) (922,)\n",
            "\n",
            "Train set: (380, 10)\n",
            "Validation set: (922, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 38\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.146 s \n",
            "\n",
            "Accuracy rate is 77.880184 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.86      0.85       321\n",
            "           1       0.58      0.55      0.56       113\n",
            "\n",
            "    accuracy                           0.78       434\n",
            "   macro avg       0.71      0.70      0.71       434\n",
            "weighted avg       0.78      0.78      0.78       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[276  45]\n",
            " [ 51  62]]\n",
            "--------------------------------\n",
            "val predicted: (922,) [0 1 0 1 0 1 1 0 0 1 0 0 1 1 1 0 1 1 1 0 0 0 0 0 0 1 0 1 1 0 0 1 0 0 0 1 1\n",
            " 0 1 0 1 0 0 0 0 0 0 1 0 0 1 1 1 0 0 0 1 1 1 0 0 1 1 1 1 1 1 1 0 1 1 1 0 0\n",
            " 0 0 0 1 0 1 1 1 1 0 1 0 0 1 1 1 0 0 0 0 0 1 1 0 1 1 0 1 0 1 1 1 0 0 0 0 1\n",
            " 0 1 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 1 1 0 1 1 1 1 1 0 1 1 0 1 1 0 1 1 1 0\n",
            " 0 1 0 0 0 1 1 0 1 1 1 0 1 1 1 1 0 1 0 0 1 1 1 0 1 0 0 0 1 0 0 0 1 0 1 0 0\n",
            " 1 0 0 0 0 0 0 1 0 0 0 1 0 1 0 1 0 1 1 0 0 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 0\n",
            " 1 0 1 0 1 0 1 1 1 1 0 1 0 1 0 1 1 0 1 1 0 1 1 1 1 1 1 1 0 1 1 0 1 0 1 0 0\n",
            " 0 0 1 1 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 1 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
            " 0 1 0 1 0 1 0 1 0 0 0 0 1 1 1 1 0 1 0 1 0 0 1 0 1 0 1 1 0 0 1 0 0 1 0 1 1\n",
            " 0 1 0 0 1 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 0 0 1 1 0 0 1 0 1 0 0 0 1 1 1 0 0\n",
            " 1 1 1 0 1 0 1 1 0 1 1 0 0 1 0 1 0 0 1 0 0 0 0 1 1 0 0 1 0 0 1 0 0 0 1 0 1\n",
            " 0 1 1 0 1 0 1 1 1 1 1 0 1 0 0 1 1 1 1 1 0 1 0 1 0 0 0 0 0 0 0 1 1 0 1 0 0\n",
            " 1 1 0 0 0 1 0 1 0 0 1 1 0 0 1 0 1 1 0 0 1 1 1 1 0 1 1 0 1 1 1 0 1 1 1 1 1\n",
            " 0 0 1 0 1 1 0 0 1 0 0 1 1 0 0 1 1 0 1 1 1 0 0 0 0 1 1 0 0 1 0 0 1 1 1 1 1\n",
            " 0 1 1 0 1 1 1 1 0 0 1 0 1 1 1 1 1 1 1 1 1 0 0 1 1 0 1 0 0 1 0 0 1 0 1 1 1\n",
            " 1 0 1 1 1 0 0 1 0 1 0 0 1 1 1 0 1 0 1 0 0 1 0 0 0 1 0 1 1 1 1 1 0 1 1 0 1\n",
            " 1 0 0 0 1 0 1 1 1 0 0 0 0 0 0 1 1 1 1 0 1 1 0 1 0 1 0 0 1 1 1 1 0 0 1 1 1\n",
            " 0 1 0 1 0 0 0 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 0 1 1 0 1 0 1 0 1 1 1 1 0 0 0\n",
            " 1 0 1 1 1 0 1 0 0 1 0 0 1 1 1 1 1 0 0 0 0 0 1 0 0 1 0 1 0 1 1 1 0 1 0 1 0\n",
            " 1 0 0 1 1 0 0 0 1 0 1 0 1 1 1 1 0 0 0 0 1 0 1 1 1 0 0 0 1 1 0 1 1 0 1 0 1\n",
            " 1 1 0 0 1 0 1 0 1 0 0 0 1 0 1 1 1 1 1 0 0 0 1 1 0 1 1 0 0 1 0 0 1 0 1 1 1\n",
            " 1 1 0 0 0 0 0 0 0 1 0 1 1 0 1 0 0 0 0 0 1 0 1 0 1 1 1 0 0 0 1 1 0 1 0 0 1\n",
            " 0 0 1 0 1 1 1 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 0 1 1 0 1 1 1 0 0 1 0 1 1 1 1\n",
            " 1 1 1 1 0 1 0 0 1 0 0 0 1 1 1 0 0 1 0 1 0 0 1 1 1 0 1 1 1 1 1 0 1 1 0 1 0\n",
            " 1 0 0 0 1 1 0 1 1 1 1 1 1 0 1 0 0 1 1 1 0 1 1 1 0 0 1 1 0 1 1 0 0 1]\n",
            "probabilities: (922, 2) \n",
            " [0 1 0 1 0 1 1 0 0 1 0 0 1 1 1 0 1 1 1 0 0 0 0 0 0 1 0 1 1 0 0 1 0 0 0 1 1\n",
            " 0 1 0 1 0 0 0 0 0 0 1 0 0 1 1 1 0 0 0 1 1 1 0 0 1 1 1 1 1 1 1 0 1 1 1 0 0\n",
            " 0 0 0 1 0 1 1 1 1 0 1 0 0 1 1 1 0 0 0 0 0 1 1 0 1 1 0 1 0 1 1 1 0 0 0 0 1\n",
            " 0 1 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 1 1 0 1 1 1 1 1 0 1 1 0 1 1 0 1 1 1 0\n",
            " 0 1 0 0 0 1 1 0 1 1 1 0 1 1 1 1 0 1 0 0 1 1 1 0 1 0 0 0 1 0 0 0 1 0 1 0 0\n",
            " 1 0 0 0 0 0 0 1 0 0 0 1 0 1 0 1 0 1 1 0 0 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 0\n",
            " 1 0 1 0 1 0 1 1 1 1 0 1 0 1 0 1 1 0 1 1 0 1 1 1 1 1 1 1 0 1 1 0 1 0 1 0 0\n",
            " 0 0 1 1 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 1 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1\n",
            " 0 1 0 1 0 1 0 1 0 0 0 0 1 1 1 1 0 1 0 1 0 0 1 0 1 0 1 1 0 0 1 0 0 1 0 1 1\n",
            " 0 1 0 0 1 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 0 0 1 1 0 0 1 0 1 0 0 0 1 1 1 0 0\n",
            " 1 1 1 0 1 0 1 1 0 1 1 0 0 1 0 1 0 0 1 0 0 0 0 1 1 0 0 1 0 0 1 0 0 0 1 0 1\n",
            " 0 1 1 0 1 0 1 1 1 1 1 0 1 0 0 1 1 1 1 1 0 1 0 1 0 0 0 0 0 0 0 1 1 0 1 0 0\n",
            " 1 1 0 0 0 1 0 1 0 0 1 1 0 0 1 0 1 1 0 0 1 1 1 1 0 1 1 0 1 1 1 0 1 1 1 1 1\n",
            " 0 0 1 0 1 1 0 0 1 0 0 1 1 0 0 1 1 0 1 1 1 0 0 0 0 1 1 0 0 1 0 0 1 1 1 1 1\n",
            " 0 1 1 0 1 1 1 1 0 0 1 0 1 1 1 1 1 1 1 1 1 0 0 1 1 0 1 0 0 1 0 0 1 0 1 1 1\n",
            " 1 0 1 1 1 0 0 1 0 1 0 0 1 1 1 0 1 0 1 0 0 1 0 0 0 1 0 1 1 1 1 1 0 1 1 0 1\n",
            " 1 0 0 0 1 0 1 1 1 0 0 0 0 0 0 1 1 1 1 0 1 1 0 1 0 1 0 0 1 1 1 1 0 0 1 1 1\n",
            " 0 1 0 1 0 0 0 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 0 1 1 0 1 0 1 0 1 1 1 1 0 0 0\n",
            " 1 0 1 1 1 0 1 0 0 1 0 0 1 1 1 1 1 0 0 0 0 0 1 0 0 1 0 1 0 1 1 1 0 1 0 1 0\n",
            " 1 0 0 1 1 0 0 0 1 0 1 0 1 1 1 1 0 0 0 0 1 0 1 1 1 0 0 0 1 1 0 1 1 0 1 0 1\n",
            " 1 1 0 0 1 0 1 0 1 0 0 0 1 0 1 1 1 1 1 0 0 0 1 1 0 1 1 0 0 1 0 0 1 0 1 1 1\n",
            " 1 1 0 0 0 0 0 0 0 1 0 1 1 0 1 0 0 0 0 0 1 0 1 0 1 1 1 0 0 0 1 1 0 1 0 0 1\n",
            " 0 0 1 0 1 1 1 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 0 1 1 0 1 1 1 0 0 1 0 1 1 1 1\n",
            " 1 1 1 1 0 1 0 0 1 0 0 0 1 1 1 0 0 1 0 1 0 0 1 1 1 0 1 1 1 1 1 0 1 1 0 1 0\n",
            " 1 0 0 0 1 1 0 1 1 1 1 1 1 0 1 0 0 1 1 1 0 1 1 1 0 0 1 1 0 1 1 0 0 1]\n",
            "uniques chosen: 10 <= should be equal to: 10\n",
            "trainset before adding uncertain samples (380, 10) (380,)\n",
            "trainset after adding uncertain samples (390, 10) (390,)\n",
            "updated train set: (390, 10) (390,) unique(labels): [172 218] [0 1]\n",
            "val set: (912, 10) (912,)\n",
            "\n",
            "Train set: (390, 10)\n",
            "Validation set: (912, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 39\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.159 s \n",
            "\n",
            "Accuracy rate is 77.649770 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.85      0.85       321\n",
            "           1       0.57      0.56      0.57       113\n",
            "\n",
            "    accuracy                           0.78       434\n",
            "   macro avg       0.71      0.71      0.71       434\n",
            "weighted avg       0.77      0.78      0.78       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[274  47]\n",
            " [ 50  63]]\n",
            "--------------------------------\n",
            "val predicted: (912,) [0 1 0 1 0 1 1 0 1 1 0 0 1 1 1 0 1 1 1 0 0 0 0 0 0 1 0 1 1 0 0 1 0 0 0 1 1\n",
            " 0 1 0 1 0 0 0 0 0 0 1 0 0 1 1 1 0 0 0 1 1 0 0 1 1 1 1 1 1 1 0 0 1 1 0 0 0\n",
            " 0 0 1 0 1 1 1 1 0 1 0 0 1 1 1 0 0 0 0 0 1 1 0 1 1 0 1 0 1 1 1 0 0 0 0 1 0\n",
            " 1 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 1 1 0 1 1 1 1 1 0 1 0 1 1 0 1 1 0 0 1 0\n",
            " 0 1 1 1 0 1 1 1 0 1 1 1 1 0 1 0 0 1 1 1 0 1 0 0 0 1 0 0 0 1 0 1 0 0 1 0 0\n",
            " 0 0 0 0 1 0 1 0 1 0 1 0 1 0 1 1 0 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 0\n",
            " 1 0 1 1 1 1 0 1 0 1 1 1 1 0 1 1 0 1 0 1 1 1 1 1 0 1 1 0 1 0 1 0 0 0 0 1 1\n",
            " 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 1 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1 0 1 0 1\n",
            " 0 1 0 1 0 0 0 0 1 1 1 1 0 1 0 1 0 0 1 0 1 0 1 1 0 0 1 0 0 1 0 1 1 0 1 1 0\n",
            " 1 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 0 0 1 1 0 0 1 0 1 0 0 0 1 1 1 0 0 1 0 0 0\n",
            " 0 1 1 0 1 1 0 0 1 0 1 1 0 1 0 0 0 0 1 1 0 0 1 0 0 1 0 0 0 1 0 1 0 1 1 0 1\n",
            " 0 1 1 1 1 1 1 1 0 0 1 1 1 1 1 0 1 0 1 0 0 0 0 0 0 0 1 1 0 1 0 0 1 1 0 0 0\n",
            " 1 0 1 0 0 1 1 0 0 1 0 1 1 0 0 1 1 1 1 0 1 1 0 1 1 1 0 1 1 1 1 1 0 0 1 0 1\n",
            " 1 0 0 1 0 0 1 1 0 0 1 1 0 1 1 1 0 0 0 0 1 1 0 0 1 0 0 1 1 1 1 1 0 1 1 0 1\n",
            " 1 1 1 0 0 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 1 0 0 1 0 1 1 0 1 1 1 1 0 1 1 1 0\n",
            " 0 1 0 1 0 0 1 1 1 0 1 1 1 0 0 1 0 0 0 1 0 1 1 1 1 1 0 1 1 1 1 0 0 0 1 0 1\n",
            " 1 1 0 0 0 0 0 0 1 1 1 1 0 1 1 0 1 0 1 0 0 1 1 1 1 0 0 1 1 1 0 1 0 0 0 0 0\n",
            " 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 0 1 1 0 1 0 0 0 1 1 1 0 0 0 0 1 0 1 1 1 0 1\n",
            " 0 0 1 0 0 0 1 1 1 1 0 0 0 0 0 1 0 0 1 0 1 0 1 1 0 1 0 1 1 0 0 1 1 0 0 1 1\n",
            " 0 1 0 1 1 1 1 0 0 0 0 1 0 1 1 1 0 0 0 1 1 0 1 1 0 1 0 1 1 1 0 0 1 0 1 0 1\n",
            " 0 0 0 1 0 1 1 1 0 0 0 0 1 1 0 1 1 0 0 1 0 0 1 0 1 1 1 1 1 0 0 0 0 0 0 1 1\n",
            " 0 1 1 0 1 0 0 0 0 0 1 0 1 0 1 1 1 0 0 0 1 1 0 1 0 0 1 0 0 0 0 1 1 1 1 0 1\n",
            " 1 0 0 1 1 1 0 0 1 1 1 1 0 1 0 0 1 1 1 0 0 1 0 1 1 1 1 1 0 1 1 0 1 0 0 1 0\n",
            " 0 0 1 1 1 0 0 1 0 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 0 1 0 0 1 0 0 1 1 1 1 1 1\n",
            " 1 1 1 0 1 0 0 1 1 1 0 1 1 1 0 0 1 1 0 1 1 0 0 1]\n",
            "probabilities: (912, 2) \n",
            " [0 1 0 1 0 1 1 0 1 1 0 0 1 1 1 0 1 1 1 0 0 0 0 0 0 1 0 1 1 0 0 1 0 0 0 1 1\n",
            " 0 1 0 1 0 0 0 0 0 0 1 0 0 1 1 1 0 0 0 1 1 0 0 1 1 1 1 1 1 1 0 0 1 1 0 0 0\n",
            " 0 0 1 0 1 1 1 1 0 1 0 0 1 1 1 0 0 0 0 0 1 1 0 1 1 0 1 0 1 1 1 0 0 0 0 1 0\n",
            " 1 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 1 1 0 1 1 1 1 1 0 1 0 1 1 0 1 1 0 0 1 0\n",
            " 0 1 1 1 0 1 1 1 0 1 1 1 1 0 1 0 0 1 1 1 0 1 0 0 0 1 0 0 0 1 0 1 0 0 1 0 0\n",
            " 0 0 0 0 1 0 1 0 1 0 1 0 1 0 1 1 0 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 0\n",
            " 1 0 1 1 1 1 0 1 0 1 1 1 1 0 1 1 0 1 0 1 1 1 1 1 0 1 1 0 1 0 1 0 0 0 0 1 1\n",
            " 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 1 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1 0 1 0 1\n",
            " 0 1 0 1 0 0 0 0 1 1 1 1 0 1 0 1 0 0 1 0 1 0 1 1 0 0 1 0 0 1 0 1 1 0 1 1 0\n",
            " 1 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 0 0 1 1 0 0 1 0 1 0 0 0 1 1 1 0 0 1 0 0 0\n",
            " 0 1 1 0 1 1 0 0 1 0 1 1 0 1 0 0 0 0 1 1 0 0 1 0 0 1 0 0 0 1 0 1 0 1 1 0 1\n",
            " 0 1 1 1 1 1 1 1 0 0 1 1 1 1 1 0 1 0 1 0 0 0 0 0 0 0 1 1 0 1 0 0 1 1 0 0 0\n",
            " 1 0 1 0 0 1 1 0 0 1 0 1 1 0 0 1 1 1 1 0 1 1 0 1 1 1 0 1 1 1 1 1 0 0 1 0 1\n",
            " 1 0 0 1 0 0 1 1 0 0 1 1 0 1 1 1 0 0 0 0 1 1 0 0 1 0 0 1 1 1 1 1 0 1 1 0 1\n",
            " 1 1 1 0 0 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 1 0 0 1 0 1 1 0 1 1 1 1 0 1 1 1 0\n",
            " 0 1 0 1 0 0 1 1 1 0 1 1 1 0 0 1 0 0 0 1 0 1 1 1 1 1 0 1 1 1 1 0 0 0 1 0 1\n",
            " 1 1 0 0 0 0 0 0 1 1 1 1 0 1 1 0 1 0 1 0 0 1 1 1 1 0 0 1 1 1 0 1 0 0 0 0 0\n",
            " 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 0 1 1 0 1 0 0 0 1 1 1 0 0 0 0 1 0 1 1 1 0 1\n",
            " 0 0 1 0 0 0 1 1 1 1 0 0 0 0 0 1 0 0 1 0 1 0 1 1 0 1 0 1 1 0 0 1 1 0 0 1 1\n",
            " 0 1 0 1 1 1 1 0 0 0 0 1 0 1 1 1 0 0 0 1 1 0 1 1 0 1 0 1 1 1 0 0 1 0 1 0 1\n",
            " 0 0 0 1 0 1 1 1 0 0 0 0 1 1 0 1 1 0 0 1 0 0 1 0 1 1 1 1 1 0 0 0 0 0 0 1 1\n",
            " 0 1 1 0 1 0 0 0 0 0 1 0 1 0 1 1 1 0 0 0 1 1 0 1 0 0 1 0 0 0 0 1 1 1 1 0 1\n",
            " 1 0 0 1 1 1 0 0 1 1 1 1 0 1 0 0 1 1 1 0 0 1 0 1 1 1 1 1 0 1 1 0 1 0 0 1 0\n",
            " 0 0 1 1 1 0 0 1 0 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 0 1 0 0 1 0 0 1 1 1 1 1 1\n",
            " 1 1 1 0 1 0 0 1 1 1 0 1 1 1 0 0 1 1 0 1 1 0 0 1]\n",
            "uniques chosen: 10 <= should be equal to: 10\n",
            "trainset before adding uncertain samples (390, 10) (390,)\n",
            "trainset after adding uncertain samples (400, 10) (400,)\n",
            "updated train set: (400, 10) (400,) unique(labels): [180 220] [0 1]\n",
            "val set: (902, 10) (902,)\n",
            "\n",
            "Train set: (400, 10)\n",
            "Validation set: (902, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 40\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.171 s \n",
            "\n",
            "Accuracy rate is 77.649770 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.85      0.85       321\n",
            "           1       0.57      0.58      0.57       113\n",
            "\n",
            "    accuracy                           0.78       434\n",
            "   macro avg       0.71      0.71      0.71       434\n",
            "weighted avg       0.78      0.78      0.78       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[272  49]\n",
            " [ 48  65]]\n",
            "--------------------------------\n",
            "val predicted: (902,) [1 0 1 0 1 1 0 1 1 0 0 1 1 1 0 1 1 1 0 0 0 0 0 0 1 0 1 1 0 0 1 0 0 0 1 1 0\n",
            " 0 1 0 1 0 0 0 1 1 0 0 1 1 1 0 0 0 1 1 0 1 1 1 1 1 1 1 0 1 1 1 0 0 0 0 0 1\n",
            " 0 1 1 1 1 0 1 0 0 1 1 1 0 0 0 0 0 1 1 0 1 1 0 1 0 1 1 1 0 0 0 0 1 0 1 0 0\n",
            " 0 0 0 0 0 0 0 1 1 1 1 0 0 1 1 1 0 1 1 1 1 1 0 1 0 1 1 0 1 1 0 0 1 0 0 1 0\n",
            " 1 0 1 1 1 0 1 1 1 1 0 1 0 0 1 1 1 0 1 0 0 0 1 0 0 0 1 0 1 0 0 1 0 0 0 0 0\n",
            " 0 1 0 0 0 1 0 1 0 1 0 1 1 0 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 0 1 0 1\n",
            " 1 1 1 0 1 0 1 1 1 1 0 1 1 0 1 0 1 1 1 1 1 0 1 0 1 0 1 0 0 0 0 1 1 1 0 0 0\n",
            " 0 0 1 0 0 0 1 0 0 0 0 1 0 1 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1 0 1 0 1 0 1 0 1\n",
            " 0 0 0 0 1 1 1 1 0 1 0 1 0 0 1 0 1 0 1 1 0 0 1 1 0 1 0 1 0 0 1 1 0 1 1 1 1\n",
            " 1 1 1 1 0 0 1 1 0 0 1 0 0 1 1 0 0 1 0 1 0 0 0 1 1 1 0 0 1 0 0 0 0 1 1 0 1\n",
            " 1 0 0 1 0 1 0 0 1 0 0 0 0 1 1 0 0 1 0 0 1 0 0 0 1 0 1 0 1 1 0 0 0 1 0 0 1\n",
            " 1 0 1 0 0 1 1 1 1 1 0 1 0 1 0 0 0 0 0 0 1 1 0 1 0 0 1 1 0 0 0 1 0 1 0 0 1\n",
            " 1 0 0 1 0 1 1 0 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 0 0 1 0 0\n",
            " 1 1 0 0 1 1 0 1 1 1 0 0 0 0 1 1 0 0 1 0 0 1 1 1 1 1 0 1 1 0 1 0 1 1 0 0 1\n",
            " 0 1 0 1 1 1 1 1 1 0 0 1 1 1 1 0 0 1 0 0 1 0 1 1 1 1 0 1 1 1 0 0 1 0 1 0 0\n",
            " 1 1 1 0 1 1 1 0 0 1 0 0 0 1 0 1 1 1 1 1 0 1 1 1 1 0 0 0 1 1 1 1 0 0 0 0 0\n",
            " 0 1 1 1 1 0 1 1 0 1 0 1 0 0 1 1 1 1 0 0 1 1 0 1 0 1 0 0 0 1 1 0 1 0 1 0 0\n",
            " 1 0 1 0 0 0 1 0 1 1 0 1 0 1 0 1 1 1 1 0 0 0 1 0 1 1 1 0 1 0 0 1 0 0 0 1 1\n",
            " 1 1 0 0 0 0 0 1 0 1 0 1 0 1 0 0 1 0 1 1 0 0 1 1 0 0 1 1 0 1 1 1 1 1 0 0 0\n",
            " 0 1 0 1 1 1 0 0 0 1 1 0 1 1 0 1 0 1 1 1 0 0 1 0 1 0 1 0 0 0 1 0 1 1 1 0 0\n",
            " 0 1 1 1 0 1 1 0 0 1 0 0 1 0 1 1 1 1 1 0 0 0 0 0 0 1 1 0 1 1 0 1 0 0 0 0 0\n",
            " 1 0 1 0 1 1 1 0 0 0 1 1 0 1 0 0 1 0 0 1 0 1 1 1 1 0 1 1 0 0 1 1 1 0 0 1 1\n",
            " 1 1 0 1 0 0 1 1 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 0 0 1 0 0 0 1 1 1 0 0 1 0 1\n",
            " 0 1 1 1 1 0 1 1 1 1 1 0 1 1 0 1 0 0 1 0 0 1 1 1 1 1 1 1 0 1 0 1 0 0 1 1 1\n",
            " 0 1 1 1 0 0 1 1 0 1 1 0 0 1]\n",
            "probabilities: (902, 2) \n",
            " [1 0 1 0 1 1 0 1 1 0 0 1 1 1 0 1 1 1 0 0 0 0 0 0 1 0 1 1 0 0 1 0 0 0 1 1 0\n",
            " 0 1 0 1 0 0 0 1 1 0 0 1 1 1 0 0 0 1 1 0 1 1 1 1 1 1 1 0 1 1 1 0 0 0 0 0 1\n",
            " 0 1 1 1 1 0 1 0 0 1 1 1 0 0 0 0 0 1 1 0 1 1 0 1 0 1 1 1 0 0 0 0 1 0 1 0 0\n",
            " 0 0 0 0 0 0 0 1 1 1 1 0 0 1 1 1 0 1 1 1 1 1 0 1 0 1 1 0 1 1 0 0 1 0 0 1 0\n",
            " 1 0 1 1 1 0 1 1 1 1 0 1 0 0 1 1 1 0 1 0 0 0 1 0 0 0 1 0 1 0 0 1 0 0 0 0 0\n",
            " 0 1 0 0 0 1 0 1 0 1 0 1 1 0 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 0 1 0 1\n",
            " 1 1 1 0 1 0 1 1 1 1 0 1 1 0 1 0 1 1 1 1 1 0 1 0 1 0 1 0 0 0 0 1 1 1 0 0 0\n",
            " 0 0 1 0 0 0 1 0 0 0 0 1 0 1 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1 0 1 0 1 0 1 0 1\n",
            " 0 0 0 0 1 1 1 1 0 1 0 1 0 0 1 0 1 0 1 1 0 0 1 1 0 1 0 1 0 0 1 1 0 1 1 1 1\n",
            " 1 1 1 1 0 0 1 1 0 0 1 0 0 1 1 0 0 1 0 1 0 0 0 1 1 1 0 0 1 0 0 0 0 1 1 0 1\n",
            " 1 0 0 1 0 1 0 0 1 0 0 0 0 1 1 0 0 1 0 0 1 0 0 0 1 0 1 0 1 1 0 0 0 1 0 0 1\n",
            " 1 0 1 0 0 1 1 1 1 1 0 1 0 1 0 0 0 0 0 0 1 1 0 1 0 0 1 1 0 0 0 1 0 1 0 0 1\n",
            " 1 0 0 1 0 1 1 0 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 0 0 1 0 0\n",
            " 1 1 0 0 1 1 0 1 1 1 0 0 0 0 1 1 0 0 1 0 0 1 1 1 1 1 0 1 1 0 1 0 1 1 0 0 1\n",
            " 0 1 0 1 1 1 1 1 1 0 0 1 1 1 1 0 0 1 0 0 1 0 1 1 1 1 0 1 1 1 0 0 1 0 1 0 0\n",
            " 1 1 1 0 1 1 1 0 0 1 0 0 0 1 0 1 1 1 1 1 0 1 1 1 1 0 0 0 1 1 1 1 0 0 0 0 0\n",
            " 0 1 1 1 1 0 1 1 0 1 0 1 0 0 1 1 1 1 0 0 1 1 0 1 0 1 0 0 0 1 1 0 1 0 1 0 0\n",
            " 1 0 1 0 0 0 1 0 1 1 0 1 0 1 0 1 1 1 1 0 0 0 1 0 1 1 1 0 1 0 0 1 0 0 0 1 1\n",
            " 1 1 0 0 0 0 0 1 0 1 0 1 0 1 0 0 1 0 1 1 0 0 1 1 0 0 1 1 0 1 1 1 1 1 0 0 0\n",
            " 0 1 0 1 1 1 0 0 0 1 1 0 1 1 0 1 0 1 1 1 0 0 1 0 1 0 1 0 0 0 1 0 1 1 1 0 0\n",
            " 0 1 1 1 0 1 1 0 0 1 0 0 1 0 1 1 1 1 1 0 0 0 0 0 0 1 1 0 1 1 0 1 0 0 0 0 0\n",
            " 1 0 1 0 1 1 1 0 0 0 1 1 0 1 0 0 1 0 0 1 0 1 1 1 1 0 1 1 0 0 1 1 1 0 0 1 1\n",
            " 1 1 0 1 0 0 1 1 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 0 0 1 0 0 0 1 1 1 0 0 1 0 1\n",
            " 0 1 1 1 1 0 1 1 1 1 1 0 1 1 0 1 0 0 1 0 0 1 1 1 1 1 1 1 0 1 0 1 0 0 1 1 1\n",
            " 0 1 1 1 0 0 1 1 0 1 1 0 0 1]\n",
            "uniques chosen: 10 <= should be equal to: 10\n",
            "trainset before adding uncertain samples (400, 10) (400,)\n",
            "trainset after adding uncertain samples (410, 10) (410,)\n",
            "updated train set: (410, 10) (410,) unique(labels): [187 223] [0 1]\n",
            "val set: (892, 10) (892,)\n",
            "\n",
            "Train set: (410, 10)\n",
            "Validation set: (892, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 41\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.183 s \n",
            "\n",
            "Accuracy rate is 78.110599 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.86      0.85       321\n",
            "           1       0.58      0.56      0.57       113\n",
            "\n",
            "    accuracy                           0.78       434\n",
            "   macro avg       0.71      0.71      0.71       434\n",
            "weighted avg       0.78      0.78      0.78       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[276  45]\n",
            " [ 50  63]]\n",
            "--------------------------------\n",
            "val predicted: (892,) [1 0 1 0 1 1 0 0 1 0 0 1 1 1 0 1 1 1 0 0 0 0 0 0 1 0 1 1 0 0 1 0 0 0 1 1 0\n",
            " 0 1 0 1 0 0 0 1 1 0 0 1 1 1 0 0 0 1 1 0 1 1 1 1 1 1 1 0 0 1 1 0 0 0 0 0 1\n",
            " 0 1 1 1 1 0 1 0 0 1 1 1 0 0 0 0 0 1 1 0 1 1 0 1 0 1 1 1 0 0 0 0 1 0 1 0 0\n",
            " 0 0 0 0 0 0 0 1 1 1 1 0 0 0 1 1 0 1 1 1 1 1 0 1 0 1 1 0 1 1 0 0 1 0 0 1 1\n",
            " 1 0 1 1 1 0 1 1 1 1 0 1 0 0 1 1 1 0 1 0 0 0 1 0 0 0 1 0 1 1 0 1 0 0 0 0 0\n",
            " 0 1 0 1 0 1 0 1 0 1 0 1 1 0 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 0 1 0 1\n",
            " 1 1 1 0 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 0 1 0 1 0 1 0 0 0 0 1 1 1 0 0 0\n",
            " 0 0 1 0 0 0 1 0 0 0 0 1 0 1 0 1 0 1 0 0 0 1 1 0 1 1 0 1 0 1 0 1 0 1 0 1 0\n",
            " 0 0 0 1 1 1 1 0 1 0 1 0 0 1 0 1 0 1 1 0 0 1 0 0 1 0 1 1 0 1 1 0 1 1 1 1 1\n",
            " 1 1 1 0 0 1 1 0 0 1 0 0 1 1 0 0 1 0 1 0 0 0 1 1 1 0 0 1 0 0 0 0 1 1 0 1 1\n",
            " 0 0 1 0 1 1 0 1 0 0 0 0 1 1 0 0 1 0 0 1 0 0 0 1 0 1 0 1 1 0 1 0 1 0 0 1 1\n",
            " 1 1 0 0 1 1 1 1 1 0 1 0 1 0 0 1 0 0 0 1 1 0 1 0 0 1 1 0 0 0 1 0 1 0 0 1 1\n",
            " 0 0 1 0 1 1 0 0 1 1 1 1 0 1 1 0 1 1 1 0 1 1 1 1 1 0 0 1 1 1 1 0 0 1 0 0 1\n",
            " 1 0 0 1 1 0 1 1 1 0 0 0 0 1 1 0 0 1 0 0 1 1 1 1 1 0 1 1 0 1 1 1 1 0 0 1 0\n",
            " 1 1 1 1 1 1 1 1 0 0 1 1 1 1 0 0 1 0 1 0 1 1 1 1 0 1 1 1 0 0 1 0 1 0 0 1 1\n",
            " 1 0 1 1 0 0 0 1 0 0 0 1 0 1 1 1 1 1 0 1 1 1 1 0 0 0 1 1 1 1 0 0 0 0 0 0 1\n",
            " 1 1 1 0 1 1 0 1 0 0 0 1 1 1 0 0 1 1 0 1 1 0 0 0 0 1 1 0 1 0 1 0 1 0 1 0 0\n",
            " 0 1 0 1 1 0 1 0 1 0 1 1 1 1 0 0 0 0 1 1 1 0 1 0 0 1 0 1 0 1 1 1 1 0 0 0 0\n",
            " 0 1 0 1 0 1 0 1 0 0 1 0 1 1 0 0 1 1 0 0 0 1 0 1 1 1 1 1 0 0 0 1 0 1 1 1 0\n",
            " 0 0 1 1 0 1 1 0 1 0 1 1 1 0 0 1 0 1 0 1 0 0 0 1 0 1 1 0 0 0 0 1 1 0 1 1 0\n",
            " 0 1 0 0 1 0 1 1 1 1 1 0 0 0 0 0 0 0 1 0 1 1 0 1 0 0 0 0 1 0 1 0 1 1 1 0 0\n",
            " 0 1 1 0 1 0 0 1 0 0 1 0 1 1 1 1 1 1 1 0 0 1 1 1 0 0 1 1 1 1 0 1 0 0 1 1 1\n",
            " 0 0 1 0 1 1 1 1 1 1 1 1 0 1 0 0 1 0 0 0 1 1 1 0 0 1 0 1 0 1 1 1 1 0 1 1 1\n",
            " 1 1 0 1 1 0 1 0 0 1 0 0 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 0 1 0 1 0 0 1 1 0 1\n",
            " 1 0 0 1]\n",
            "probabilities: (892, 2) \n",
            " [1 0 1 0 1 1 0 0 1 0 0 1 1 1 0 1 1 1 0 0 0 0 0 0 1 0 1 1 0 0 1 0 0 0 1 1 0\n",
            " 0 1 0 1 0 0 0 1 1 0 0 1 1 1 0 0 0 1 1 0 1 1 1 1 1 1 1 0 0 1 1 0 0 0 0 0 1\n",
            " 0 1 1 1 1 0 1 0 0 1 1 1 0 0 0 0 0 1 1 0 1 1 0 1 0 1 1 1 0 0 0 0 1 0 1 0 0\n",
            " 0 0 0 0 0 0 0 1 1 1 1 0 0 0 1 1 0 1 1 1 1 1 0 1 0 1 1 0 1 1 0 0 1 0 0 1 1\n",
            " 1 0 1 1 1 0 1 1 1 1 0 1 0 0 1 1 1 0 1 0 0 0 1 0 0 0 1 0 1 1 0 1 0 0 0 0 0\n",
            " 0 1 0 1 0 1 0 1 0 1 0 1 1 0 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 0 1 0 1\n",
            " 1 1 1 0 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 0 1 0 1 0 1 0 0 0 0 1 1 1 0 0 0\n",
            " 0 0 1 0 0 0 1 0 0 0 0 1 0 1 0 1 0 1 0 0 0 1 1 0 1 1 0 1 0 1 0 1 0 1 0 1 0\n",
            " 0 0 0 1 1 1 1 0 1 0 1 0 0 1 0 1 0 1 1 0 0 1 0 0 1 0 1 1 0 1 1 0 1 1 1 1 1\n",
            " 1 1 1 0 0 1 1 0 0 1 0 0 1 1 0 0 1 0 1 0 0 0 1 1 1 0 0 1 0 0 0 0 1 1 0 1 1\n",
            " 0 0 1 0 1 1 0 1 0 0 0 0 1 1 0 0 1 0 0 1 0 0 0 1 0 1 0 1 1 0 1 0 1 0 0 1 1\n",
            " 1 1 0 0 1 1 1 1 1 0 1 0 1 0 0 1 0 0 0 1 1 0 1 0 0 1 1 0 0 0 1 0 1 0 0 1 1\n",
            " 0 0 1 0 1 1 0 0 1 1 1 1 0 1 1 0 1 1 1 0 1 1 1 1 1 0 0 1 1 1 1 0 0 1 0 0 1\n",
            " 1 0 0 1 1 0 1 1 1 0 0 0 0 1 1 0 0 1 0 0 1 1 1 1 1 0 1 1 0 1 1 1 1 0 0 1 0\n",
            " 1 1 1 1 1 1 1 1 0 0 1 1 1 1 0 0 1 0 1 0 1 1 1 1 0 1 1 1 0 0 1 0 1 0 0 1 1\n",
            " 1 0 1 1 0 0 0 1 0 0 0 1 0 1 1 1 1 1 0 1 1 1 1 0 0 0 1 1 1 1 0 0 0 0 0 0 1\n",
            " 1 1 1 0 1 1 0 1 0 0 0 1 1 1 0 0 1 1 0 1 1 0 0 0 0 1 1 0 1 0 1 0 1 0 1 0 0\n",
            " 0 1 0 1 1 0 1 0 1 0 1 1 1 1 0 0 0 0 1 1 1 0 1 0 0 1 0 1 0 1 1 1 1 0 0 0 0\n",
            " 0 1 0 1 0 1 0 1 0 0 1 0 1 1 0 0 1 1 0 0 0 1 0 1 1 1 1 1 0 0 0 1 0 1 1 1 0\n",
            " 0 0 1 1 0 1 1 0 1 0 1 1 1 0 0 1 0 1 0 1 0 0 0 1 0 1 1 0 0 0 0 1 1 0 1 1 0\n",
            " 0 1 0 0 1 0 1 1 1 1 1 0 0 0 0 0 0 0 1 0 1 1 0 1 0 0 0 0 1 0 1 0 1 1 1 0 0\n",
            " 0 1 1 0 1 0 0 1 0 0 1 0 1 1 1 1 1 1 1 0 0 1 1 1 0 0 1 1 1 1 0 1 0 0 1 1 1\n",
            " 0 0 1 0 1 1 1 1 1 1 1 1 0 1 0 0 1 0 0 0 1 1 1 0 0 1 0 1 0 1 1 1 1 0 1 1 1\n",
            " 1 1 0 1 1 0 1 0 0 1 0 0 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 0 1 0 1 0 0 1 1 0 1\n",
            " 1 0 0 1]\n",
            "uniques chosen: 10 <= should be equal to: 10\n",
            "trainset before adding uncertain samples (410, 10) (410,)\n",
            "trainset after adding uncertain samples (420, 10) (420,)\n",
            "updated train set: (420, 10) (420,) unique(labels): [193 227] [0 1]\n",
            "val set: (882, 10) (882,)\n",
            "\n",
            "Train set: (420, 10)\n",
            "Validation set: (882, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 42\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.199 s \n",
            "\n",
            "Accuracy rate is 79.723502 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.87      0.86       321\n",
            "           1       0.62      0.58      0.60       113\n",
            "\n",
            "    accuracy                           0.80       434\n",
            "   macro avg       0.74      0.73      0.73       434\n",
            "weighted avg       0.79      0.80      0.80       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[280  41]\n",
            " [ 47  66]]\n",
            "--------------------------------\n",
            "val predicted: (882,) [1 0 1 0 1 1 0 0 1 0 0 1 1 1 0 1 1 1 0 0 0 0 0 0 1 0 1 1 0 0 1 1 0 0 1 1 0\n",
            " 0 1 0 1 0 0 0 0 1 0 1 1 1 1 0 0 0 1 1 0 1 1 1 1 1 1 1 0 0 1 1 0 0 0 0 1 0\n",
            " 1 1 1 1 0 1 0 0 1 1 0 0 0 0 0 0 1 1 0 0 1 1 1 0 1 1 1 0 0 0 0 1 0 1 0 0 0\n",
            " 0 0 0 0 0 0 1 1 1 1 0 0 0 1 1 0 1 1 1 1 0 0 1 0 1 1 0 1 1 0 0 1 0 0 1 0 1\n",
            " 0 1 1 1 0 1 1 1 1 0 1 0 0 1 1 1 0 1 0 0 0 1 0 0 1 0 1 1 0 1 0 0 0 0 0 0 1\n",
            " 0 0 0 1 0 1 0 1 0 1 1 0 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 0 1 0 1 1 1\n",
            " 1 0 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 0 1 0 1 0 1 0 0 0 0 1 1 1 0 0 0 0 0\n",
            " 1 0 0 1 0 0 0 0 1 0 1 0 1 0 1 0 0 0 1 1 0 1 1 0 1 0 1 1 0 1 0 1 0 0 0 0 1\n",
            " 1 1 1 0 1 0 1 0 0 1 0 1 0 1 1 0 0 1 1 0 1 0 1 0 0 1 1 0 1 1 1 1 1 1 1 0 0\n",
            " 1 1 0 0 1 1 0 1 1 0 0 1 0 1 0 0 0 1 1 1 0 0 1 0 0 0 0 1 1 0 1 1 0 0 1 0 1\n",
            " 1 0 1 0 0 0 0 1 1 0 0 1 0 0 1 0 0 0 1 0 1 0 1 1 0 1 0 1 1 0 1 1 1 1 0 0 1\n",
            " 1 1 1 1 0 1 0 1 0 0 1 0 0 0 1 1 0 1 0 0 1 1 0 0 1 0 1 0 0 1 1 0 0 1 0 1 1\n",
            " 0 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 0 0 1 0 0 1 1 0 0 1 1 0\n",
            " 1 1 1 0 0 0 0 1 1 0 0 1 0 0 1 1 1 1 0 1 1 0 1 1 1 1 0 0 1 0 1 1 1 1 1 1 1\n",
            " 1 0 0 1 1 0 1 0 0 1 1 1 0 1 1 1 1 0 1 1 1 0 0 1 0 1 0 0 1 0 1 0 1 1 0 0 0\n",
            " 1 0 0 0 1 0 1 1 0 1 1 0 1 1 1 1 0 0 0 1 1 1 1 0 0 0 0 0 0 1 1 1 1 0 1 1 0\n",
            " 1 0 0 0 1 1 1 0 0 1 1 0 1 1 0 0 0 0 1 1 0 1 0 1 0 1 0 1 0 0 0 1 0 1 1 0 1\n",
            " 0 1 0 1 1 1 0 0 0 0 0 1 1 1 1 1 0 0 1 0 0 0 1 1 1 1 0 0 0 0 0 1 0 1 0 1 0\n",
            " 1 1 0 1 0 1 1 0 0 1 1 0 0 0 1 0 1 1 1 1 1 0 0 0 1 0 1 1 1 0 0 0 1 1 0 1 1\n",
            " 0 1 0 1 1 1 0 0 1 0 1 0 1 0 0 1 0 1 1 0 0 1 1 1 1 0 1 1 0 0 1 0 0 1 0 1 1\n",
            " 1 1 1 0 0 0 0 0 0 0 1 0 1 1 0 1 0 0 0 0 1 0 1 0 1 1 1 0 0 0 1 1 0 1 0 0 1\n",
            " 0 0 1 0 1 1 1 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 0 1 0 0 1 1 1 0 0 1 0 1 1 1 1\n",
            " 1 1 1 0 1 0 0 1 0 0 0 1 1 1 0 0 1 0 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 0 0\n",
            " 1 0 0 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 0 1 1 1 0 1 1 0 1 1 0 0 1]\n",
            "probabilities: (882, 2) \n",
            " [1 0 1 0 1 1 0 0 1 0 0 1 1 1 0 1 1 1 0 0 0 0 0 0 1 0 1 1 0 0 1 1 0 0 1 1 0\n",
            " 0 1 0 1 0 0 0 0 1 0 1 1 1 1 0 0 0 1 1 0 1 1 1 1 1 1 1 0 0 1 1 0 0 0 0 1 0\n",
            " 1 1 1 1 0 1 0 0 1 1 0 0 0 0 0 0 1 1 0 0 1 1 1 0 1 1 1 0 0 0 0 1 0 1 0 0 0\n",
            " 0 0 0 0 0 0 1 1 1 1 0 0 0 1 1 0 1 1 1 1 0 0 1 0 1 1 0 1 1 0 0 1 0 0 1 0 1\n",
            " 0 1 1 1 0 1 1 1 1 0 1 0 0 1 1 1 0 1 0 0 0 1 0 0 1 0 1 1 0 1 0 0 0 0 0 0 1\n",
            " 0 0 0 1 0 1 0 1 0 1 1 0 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 0 1 0 1 1 1\n",
            " 1 0 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 0 1 0 1 0 1 0 0 0 0 1 1 1 0 0 0 0 0\n",
            " 1 0 0 1 0 0 0 0 1 0 1 0 1 0 1 0 0 0 1 1 0 1 1 0 1 0 1 1 0 1 0 1 0 0 0 0 1\n",
            " 1 1 1 0 1 0 1 0 0 1 0 1 0 1 1 0 0 1 1 0 1 0 1 0 0 1 1 0 1 1 1 1 1 1 1 0 0\n",
            " 1 1 0 0 1 1 0 1 1 0 0 1 0 1 0 0 0 1 1 1 0 0 1 0 0 0 0 1 1 0 1 1 0 0 1 0 1\n",
            " 1 0 1 0 0 0 0 1 1 0 0 1 0 0 1 0 0 0 1 0 1 0 1 1 0 1 0 1 1 0 1 1 1 1 0 0 1\n",
            " 1 1 1 1 0 1 0 1 0 0 1 0 0 0 1 1 0 1 0 0 1 1 0 0 1 0 1 0 0 1 1 0 0 1 0 1 1\n",
            " 0 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 0 0 1 0 0 1 1 0 0 1 1 0\n",
            " 1 1 1 0 0 0 0 1 1 0 0 1 0 0 1 1 1 1 0 1 1 0 1 1 1 1 0 0 1 0 1 1 1 1 1 1 1\n",
            " 1 0 0 1 1 0 1 0 0 1 1 1 0 1 1 1 1 0 1 1 1 0 0 1 0 1 0 0 1 0 1 0 1 1 0 0 0\n",
            " 1 0 0 0 1 0 1 1 0 1 1 0 1 1 1 1 0 0 0 1 1 1 1 0 0 0 0 0 0 1 1 1 1 0 1 1 0\n",
            " 1 0 0 0 1 1 1 0 0 1 1 0 1 1 0 0 0 0 1 1 0 1 0 1 0 1 0 1 0 0 0 1 0 1 1 0 1\n",
            " 0 1 0 1 1 1 0 0 0 0 0 1 1 1 1 1 0 0 1 0 0 0 1 1 1 1 0 0 0 0 0 1 0 1 0 1 0\n",
            " 1 1 0 1 0 1 1 0 0 1 1 0 0 0 1 0 1 1 1 1 1 0 0 0 1 0 1 1 1 0 0 0 1 1 0 1 1\n",
            " 0 1 0 1 1 1 0 0 1 0 1 0 1 0 0 1 0 1 1 0 0 1 1 1 1 0 1 1 0 0 1 0 0 1 0 1 1\n",
            " 1 1 1 0 0 0 0 0 0 0 1 0 1 1 0 1 0 0 0 0 1 0 1 0 1 1 1 0 0 0 1 1 0 1 0 0 1\n",
            " 0 0 1 0 1 1 1 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 0 1 0 0 1 1 1 0 0 1 0 1 1 1 1\n",
            " 1 1 1 0 1 0 0 1 0 0 0 1 1 1 0 0 1 0 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 0 0\n",
            " 1 0 0 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 0 1 1 1 0 1 1 0 1 1 0 0 1]\n",
            "uniques chosen: 10 <= should be equal to: 10\n",
            "trainset before adding uncertain samples (420, 10) (420,)\n",
            "trainset after adding uncertain samples (430, 10) (430,)\n",
            "updated train set: (430, 10) (430,) unique(labels): [195 235] [0 1]\n",
            "val set: (872, 10) (872,)\n",
            "\n",
            "Train set: (430, 10)\n",
            "Validation set: (872, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 43\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.215 s \n",
            "\n",
            "Accuracy rate is 79.723502 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.88      0.87       321\n",
            "           1       0.62      0.57      0.59       113\n",
            "\n",
            "    accuracy                           0.80       434\n",
            "   macro avg       0.74      0.72      0.73       434\n",
            "weighted avg       0.79      0.80      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[282  39]\n",
            " [ 49  64]]\n",
            "--------------------------------\n",
            "val predicted: (872,) [1 0 1 0 1 1 0 0 1 0 0 1 1 1 0 1 1 1 0 0 0 0 0 0 1 0 1 1 0 0 1 1 0 0 1 1 0\n",
            " 0 1 0 1 0 0 0 1 1 0 0 1 1 1 0 0 0 1 1 0 1 1 1 1 1 1 1 0 0 1 1 0 0 0 0 1 0\n",
            " 1 1 1 1 0 1 0 0 1 1 1 0 0 0 0 0 1 1 0 1 1 1 1 0 1 1 1 0 0 0 0 0 1 0 0 0 0\n",
            " 0 0 0 0 0 1 1 1 1 0 0 0 1 1 0 1 1 1 1 1 0 1 0 1 1 0 1 1 0 0 1 0 0 1 1 1 0\n",
            " 1 1 1 0 1 1 1 1 0 1 0 0 1 1 1 0 1 0 0 0 1 0 0 1 0 1 1 0 1 0 0 0 0 0 0 1 0\n",
            " 1 0 1 0 1 0 1 0 1 1 0 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 0 1 0 1 1 1 1\n",
            " 0 1 0 1 1 1 1 0 1 1 0 1 0 1 1 1 1 1 0 1 0 0 1 0 0 0 0 1 1 1 0 0 0 0 0 1 0\n",
            " 0 1 0 0 0 0 1 0 1 0 1 0 1 0 0 0 1 1 0 1 1 0 1 0 1 1 0 1 0 1 0 0 0 0 1 1 1\n",
            " 1 0 1 0 1 0 0 1 0 1 0 1 0 0 1 1 0 1 0 1 1 0 1 1 0 1 1 1 1 1 1 1 0 0 1 1 0\n",
            " 0 1 1 0 1 1 0 0 1 0 1 0 0 0 1 1 1 0 0 1 0 0 0 0 1 1 0 1 1 0 0 1 0 1 1 0 1\n",
            " 0 0 0 0 1 1 0 0 1 0 0 1 0 0 0 1 0 1 0 1 1 0 1 0 1 1 0 1 1 1 1 0 0 1 1 1 1\n",
            " 1 0 1 0 1 0 0 0 0 0 0 1 1 0 1 0 0 1 1 0 0 1 0 1 0 0 1 1 0 0 1 0 1 1 0 0 1\n",
            " 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 0 0 1 1 1 1 0 0 1 0 0 1 1 0 1 1 0 1 1 1 0 0\n",
            " 0 0 1 1 0 0 1 0 0 1 1 1 1 0 1 1 0 1 1 1 1 0 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1\n",
            " 0 1 0 0 1 1 1 0 1 1 1 1 0 1 1 1 0 0 1 0 1 0 0 1 0 1 1 1 0 0 0 1 0 0 0 1 0\n",
            " 1 1 1 1 1 0 1 1 1 1 0 0 0 1 1 1 1 0 0 0 0 0 0 1 1 1 1 0 1 0 1 0 0 0 1 1 1\n",
            " 0 0 1 1 0 1 0 1 0 0 0 1 1 0 1 0 1 0 1 0 1 0 0 0 1 0 1 1 0 1 0 0 0 1 1 1 0\n",
            " 0 0 0 0 1 1 1 0 1 1 0 1 1 0 0 1 1 1 1 0 0 0 0 0 1 0 1 0 1 0 1 1 0 1 0 1 1\n",
            " 0 0 1 1 0 0 0 1 0 1 1 1 1 0 0 0 1 0 1 1 1 0 0 0 1 1 0 1 1 0 1 0 1 1 1 0 0\n",
            " 1 0 1 0 1 0 0 1 0 1 1 0 0 0 0 1 1 0 1 1 0 0 1 0 0 1 0 1 1 1 1 1 0 0 0 0 0\n",
            " 0 1 1 0 1 1 0 1 0 0 0 0 1 0 1 0 1 1 1 0 0 0 1 1 0 1 0 0 1 0 0 0 0 1 1 1 1\n",
            " 0 1 1 0 0 1 1 1 0 0 1 1 1 1 0 1 1 0 1 1 1 0 0 1 0 1 1 1 1 1 0 1 0 1 0 0 1\n",
            " 0 0 0 1 1 1 0 0 1 0 1 0 1 1 1 0 1 1 1 1 1 1 1 0 1 0 0 1 0 0 1 1 1 1 1 1 1\n",
            " 1 1 0 1 0 1 1 1 0 1 1 1 0 1 1 0 1 1 0 0 1]\n",
            "probabilities: (872, 2) \n",
            " [1 0 1 0 1 1 0 0 1 0 0 1 1 1 0 1 1 1 0 0 0 0 0 0 1 0 1 1 0 0 1 1 0 0 1 1 0\n",
            " 0 1 0 1 0 0 0 1 1 0 0 1 1 1 0 0 0 1 1 0 1 1 1 1 1 1 1 0 0 1 1 0 0 0 0 1 0\n",
            " 1 1 1 1 0 1 0 0 1 1 1 0 0 0 0 0 1 1 0 1 1 1 1 0 1 1 1 0 0 0 0 0 1 0 0 0 0\n",
            " 0 0 0 0 0 1 1 1 1 0 0 0 1 1 0 1 1 1 1 1 0 1 0 1 1 0 1 1 0 0 1 0 0 1 1 1 0\n",
            " 1 1 1 0 1 1 1 1 0 1 0 0 1 1 1 0 1 0 0 0 1 0 0 1 0 1 1 0 1 0 0 0 0 0 0 1 0\n",
            " 1 0 1 0 1 0 1 0 1 1 0 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 0 1 0 1 1 1 1\n",
            " 0 1 0 1 1 1 1 0 1 1 0 1 0 1 1 1 1 1 0 1 0 0 1 0 0 0 0 1 1 1 0 0 0 0 0 1 0\n",
            " 0 1 0 0 0 0 1 0 1 0 1 0 1 0 0 0 1 1 0 1 1 0 1 0 1 1 0 1 0 1 0 0 0 0 1 1 1\n",
            " 1 0 1 0 1 0 0 1 0 1 0 1 0 0 1 1 0 1 0 1 1 0 1 1 0 1 1 1 1 1 1 1 0 0 1 1 0\n",
            " 0 1 1 0 1 1 0 0 1 0 1 0 0 0 1 1 1 0 0 1 0 0 0 0 1 1 0 1 1 0 0 1 0 1 1 0 1\n",
            " 0 0 0 0 1 1 0 0 1 0 0 1 0 0 0 1 0 1 0 1 1 0 1 0 1 1 0 1 1 1 1 0 0 1 1 1 1\n",
            " 1 0 1 0 1 0 0 0 0 0 0 1 1 0 1 0 0 1 1 0 0 1 0 1 0 0 1 1 0 0 1 0 1 1 0 0 1\n",
            " 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 0 0 1 1 1 1 0 0 1 0 0 1 1 0 1 1 0 1 1 1 0 0\n",
            " 0 0 1 1 0 0 1 0 0 1 1 1 1 0 1 1 0 1 1 1 1 0 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1\n",
            " 0 1 0 0 1 1 1 0 1 1 1 1 0 1 1 1 0 0 1 0 1 0 0 1 0 1 1 1 0 0 0 1 0 0 0 1 0\n",
            " 1 1 1 1 1 0 1 1 1 1 0 0 0 1 1 1 1 0 0 0 0 0 0 1 1 1 1 0 1 0 1 0 0 0 1 1 1\n",
            " 0 0 1 1 0 1 0 1 0 0 0 1 1 0 1 0 1 0 1 0 1 0 0 0 1 0 1 1 0 1 0 0 0 1 1 1 0\n",
            " 0 0 0 0 1 1 1 0 1 1 0 1 1 0 0 1 1 1 1 0 0 0 0 0 1 0 1 0 1 0 1 1 0 1 0 1 1\n",
            " 0 0 1 1 0 0 0 1 0 1 1 1 1 0 0 0 1 0 1 1 1 0 0 0 1 1 0 1 1 0 1 0 1 1 1 0 0\n",
            " 1 0 1 0 1 0 0 1 0 1 1 0 0 0 0 1 1 0 1 1 0 0 1 0 0 1 0 1 1 1 1 1 0 0 0 0 0\n",
            " 0 1 1 0 1 1 0 1 0 0 0 0 1 0 1 0 1 1 1 0 0 0 1 1 0 1 0 0 1 0 0 0 0 1 1 1 1\n",
            " 0 1 1 0 0 1 1 1 0 0 1 1 1 1 0 1 1 0 1 1 1 0 0 1 0 1 1 1 1 1 0 1 0 1 0 0 1\n",
            " 0 0 0 1 1 1 0 0 1 0 1 0 1 1 1 0 1 1 1 1 1 1 1 0 1 0 0 1 0 0 1 1 1 1 1 1 1\n",
            " 1 1 0 1 0 1 1 1 0 1 1 1 0 1 1 0 1 1 0 0 1]\n",
            "uniques chosen: 10 <= should be equal to: 10\n",
            "trainset before adding uncertain samples (430, 10) (430,)\n",
            "trainset after adding uncertain samples (440, 10) (440,)\n",
            "updated train set: (440, 10) (440,) unique(labels): [198 242] [0 1]\n",
            "val set: (862, 10) (862,)\n",
            "\n",
            "Train set: (440, 10)\n",
            "Validation set: (862, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 44\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.511 s \n",
            "\n",
            "Accuracy rate is 79.493088 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.88      0.86       321\n",
            "           1       0.62      0.56      0.59       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.73      0.72      0.72       434\n",
            "weighted avg       0.79      0.79      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[282  39]\n",
            " [ 50  63]]\n",
            "--------------------------------\n",
            "val predicted: (862,) [1 0 1 0 1 1 0 0 1 0 0 1 1 1 0 1 1 0 0 0 0 0 0 1 0 1 1 0 0 1 1 0 0 1 1 0 0\n",
            " 1 0 1 0 0 0 0 1 0 0 1 1 1 0 0 0 1 1 0 1 1 1 1 1 1 1 0 1 1 1 0 0 0 0 1 1 1\n",
            " 1 1 1 1 0 0 1 1 0 0 0 0 0 0 1 1 0 1 1 0 1 0 1 1 1 0 0 0 0 0 1 0 0 0 0 0 0\n",
            " 0 0 1 1 1 1 1 1 0 0 1 1 0 1 1 1 1 1 0 1 0 1 1 0 1 1 0 0 1 0 0 1 1 1 0 1 1\n",
            " 1 0 1 1 1 1 0 1 0 0 1 1 1 0 1 0 0 0 1 0 0 1 0 1 1 0 1 0 0 0 0 0 0 1 0 0 0\n",
            " 1 0 1 0 1 0 1 1 0 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 0 1 0 1 1 1 1 0 1\n",
            " 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 0 1 0 0 1 0 0 0 0 1 1 1 0 0 0 0 1 0 0 1 0\n",
            " 0 0 0 1 0 1 0 1 0 1 0 0 0 1 1 0 1 1 0 1 0 1 1 0 1 0 1 0 0 0 0 1 1 1 1 0 1\n",
            " 0 1 0 0 1 0 1 0 1 0 0 1 1 0 1 0 1 0 0 1 1 1 1 1 1 1 1 1 0 0 1 1 0 0 1 0 0\n",
            " 1 1 0 0 1 0 1 0 0 0 1 1 1 0 0 1 0 0 0 0 1 1 0 1 1 0 0 1 0 1 1 0 1 0 0 0 0\n",
            " 1 1 0 0 1 0 0 0 0 0 1 0 1 0 1 1 0 1 0 1 1 0 1 1 1 1 0 0 1 1 1 1 1 0 1 0 1\n",
            " 0 0 1 0 0 0 1 1 0 1 0 0 1 1 0 0 1 0 1 0 0 1 1 0 0 1 0 1 1 0 0 1 1 1 1 0 1\n",
            " 1 0 1 1 1 1 1 1 1 1 0 0 1 0 1 1 0 0 1 0 0 1 1 0 1 1 0 1 1 1 0 0 0 0 1 1 0\n",
            " 0 1 0 0 1 1 1 1 0 1 1 0 1 1 1 1 0 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 0 1 0 0 1\n",
            " 1 1 0 1 1 1 1 0 1 1 1 0 0 1 0 1 0 0 1 0 1 1 1 1 0 0 1 0 0 0 1 0 1 1 1 1 1\n",
            " 0 1 1 1 1 0 0 0 1 1 1 1 0 0 0 0 0 0 1 1 1 1 0 1 0 1 0 0 0 1 1 1 0 0 1 1 0\n",
            " 1 0 1 0 0 0 1 1 0 1 0 1 0 1 0 1 0 0 0 1 0 1 1 0 1 0 0 0 1 1 1 1 0 0 0 0 1\n",
            " 1 1 1 1 0 0 1 0 0 0 1 1 1 1 0 0 0 0 0 1 0 1 0 1 0 1 0 0 1 0 1 1 0 0 1 1 0\n",
            " 0 1 1 1 1 1 1 0 0 0 1 1 1 1 1 0 0 0 1 1 0 1 1 0 1 0 1 1 1 0 0 1 0 1 0 1 0\n",
            " 0 1 0 1 0 0 1 0 1 1 0 1 1 0 0 1 0 0 1 0 1 1 1 1 1 0 0 0 0 0 0 1 1 0 1 1 0\n",
            " 1 0 0 0 0 1 0 1 0 1 1 1 0 0 0 1 0 1 0 0 1 0 0 0 0 1 1 1 1 0 1 1 0 0 1 1 1\n",
            " 0 0 1 1 1 1 0 1 0 0 1 1 1 0 0 1 0 1 1 1 1 1 1 1 0 1 0 0 1 0 0 0 1 1 1 0 0\n",
            " 1 0 0 1 1 1 0 1 1 1 1 1 1 1 0 1 0 1 0 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 0 1\n",
            " 1 1 0 1 1 0 1 1 0 0 1]\n",
            "probabilities: (862, 2) \n",
            " [1 0 1 0 1 1 0 0 1 0 0 1 1 1 0 1 1 0 0 0 0 0 0 1 0 1 1 0 0 1 1 0 0 1 1 0 0\n",
            " 1 0 1 0 0 0 0 1 0 0 1 1 1 0 0 0 1 1 0 1 1 1 1 1 1 1 0 1 1 1 0 0 0 0 1 1 1\n",
            " 1 1 1 1 0 0 1 1 0 0 0 0 0 0 1 1 0 1 1 0 1 0 1 1 1 0 0 0 0 0 1 0 0 0 0 0 0\n",
            " 0 0 1 1 1 1 1 1 0 0 1 1 0 1 1 1 1 1 0 1 0 1 1 0 1 1 0 0 1 0 0 1 1 1 0 1 1\n",
            " 1 0 1 1 1 1 0 1 0 0 1 1 1 0 1 0 0 0 1 0 0 1 0 1 1 0 1 0 0 0 0 0 0 1 0 0 0\n",
            " 1 0 1 0 1 0 1 1 0 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 0 1 0 1 1 1 1 0 1\n",
            " 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 0 1 0 0 1 0 0 0 0 1 1 1 0 0 0 0 1 0 0 1 0\n",
            " 0 0 0 1 0 1 0 1 0 1 0 0 0 1 1 0 1 1 0 1 0 1 1 0 1 0 1 0 0 0 0 1 1 1 1 0 1\n",
            " 0 1 0 0 1 0 1 0 1 0 0 1 1 0 1 0 1 0 0 1 1 1 1 1 1 1 1 1 0 0 1 1 0 0 1 0 0\n",
            " 1 1 0 0 1 0 1 0 0 0 1 1 1 0 0 1 0 0 0 0 1 1 0 1 1 0 0 1 0 1 1 0 1 0 0 0 0\n",
            " 1 1 0 0 1 0 0 0 0 0 1 0 1 0 1 1 0 1 0 1 1 0 1 1 1 1 0 0 1 1 1 1 1 0 1 0 1\n",
            " 0 0 1 0 0 0 1 1 0 1 0 0 1 1 0 0 1 0 1 0 0 1 1 0 0 1 0 1 1 0 0 1 1 1 1 0 1\n",
            " 1 0 1 1 1 1 1 1 1 1 0 0 1 0 1 1 0 0 1 0 0 1 1 0 1 1 0 1 1 1 0 0 0 0 1 1 0\n",
            " 0 1 0 0 1 1 1 1 0 1 1 0 1 1 1 1 0 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 0 1 0 0 1\n",
            " 1 1 0 1 1 1 1 0 1 1 1 0 0 1 0 1 0 0 1 0 1 1 1 1 0 0 1 0 0 0 1 0 1 1 1 1 1\n",
            " 0 1 1 1 1 0 0 0 1 1 1 1 0 0 0 0 0 0 1 1 1 1 0 1 0 1 0 0 0 1 1 1 0 0 1 1 0\n",
            " 1 0 1 0 0 0 1 1 0 1 0 1 0 1 0 1 0 0 0 1 0 1 1 0 1 0 0 0 1 1 1 1 0 0 0 0 1\n",
            " 1 1 1 1 0 0 1 0 0 0 1 1 1 1 0 0 0 0 0 1 0 1 0 1 0 1 0 0 1 0 1 1 0 0 1 1 0\n",
            " 0 1 1 1 1 1 1 0 0 0 1 1 1 1 1 0 0 0 1 1 0 1 1 0 1 0 1 1 1 0 0 1 0 1 0 1 0\n",
            " 0 1 0 1 0 0 1 0 1 1 0 1 1 0 0 1 0 0 1 0 1 1 1 1 1 0 0 0 0 0 0 1 1 0 1 1 0\n",
            " 1 0 0 0 0 1 0 1 0 1 1 1 0 0 0 1 0 1 0 0 1 0 0 0 0 1 1 1 1 0 1 1 0 0 1 1 1\n",
            " 0 0 1 1 1 1 0 1 0 0 1 1 1 0 0 1 0 1 1 1 1 1 1 1 0 1 0 0 1 0 0 0 1 1 1 0 0\n",
            " 1 0 0 1 1 1 0 1 1 1 1 1 1 1 0 1 0 1 0 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 0 1\n",
            " 1 1 0 1 1 0 1 1 0 0 1]\n",
            "uniques chosen: 10 <= should be equal to: 10\n",
            "trainset before adding uncertain samples (440, 10) (440,)\n",
            "trainset after adding uncertain samples (450, 10) (450,)\n",
            "updated train set: (450, 10) (450,) unique(labels): [202 248] [0 1]\n",
            "val set: (852, 10) (852,)\n",
            "\n",
            "Train set: (450, 10)\n",
            "Validation set: (852, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 45\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.233 s \n",
            "\n",
            "Accuracy rate is 79.032258 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.87      0.86       321\n",
            "           1       0.61      0.56      0.58       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.73      0.71      0.72       434\n",
            "weighted avg       0.79      0.79      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[280  41]\n",
            " [ 50  63]]\n",
            "--------------------------------\n",
            "val predicted: (852,) [1 0 1 0 1 1 0 1 0 0 1 1 1 0 1 1 0 0 0 0 0 0 1 0 1 1 0 0 1 1 0 0 1 1 0 0 1\n",
            " 0 1 0 0 0 1 1 0 0 1 1 1 0 0 0 1 1 0 1 1 1 1 1 1 1 0 1 1 1 0 0 0 0 1 0 1 1\n",
            " 1 1 1 0 0 1 1 1 0 0 0 0 0 1 1 0 1 1 0 1 0 1 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
            " 0 0 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 0 1 0 1 1 0 1 1 0 0 1 0 0 1 1 1 0 1 1 1\n",
            " 0 1 1 1 1 0 1 0 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 1 0 1\n",
            " 0 1 0 1 1 0 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 0 1 0 1 1 1 1 0 1 0 1 1\n",
            " 1 1 0 1 1 0 1 1 1 1 1 1 1 0 1 0 0 1 0 0 0 0 1 1 1 0 0 0 0 1 0 0 1 0 0 0 0\n",
            " 1 0 1 0 1 0 1 0 0 0 1 1 0 1 1 0 1 0 1 1 0 1 0 1 0 0 0 0 1 1 1 0 0 1 0 1 0\n",
            " 0 1 0 1 0 1 0 1 1 0 1 0 1 0 0 1 1 1 1 1 1 1 1 1 0 0 1 1 0 0 1 1 0 1 1 0 1\n",
            " 0 1 0 0 0 1 1 1 0 0 1 0 0 0 0 1 1 0 1 1 0 1 0 1 1 0 1 0 0 0 0 1 1 0 0 1 0\n",
            " 0 0 0 0 1 0 1 0 1 1 0 1 0 1 1 0 1 1 1 1 0 0 1 1 1 1 0 1 0 1 0 0 1 0 0 0 1\n",
            " 1 0 1 0 0 1 1 0 0 1 0 1 0 0 1 1 0 0 1 0 1 1 0 0 1 1 1 1 0 1 1 0 1 1 1 1 1\n",
            " 1 1 1 0 0 1 0 1 1 0 0 1 0 0 1 1 0 1 1 0 1 1 1 0 0 0 0 1 1 0 0 1 0 0 1 1 1\n",
            " 1 0 1 1 0 1 1 1 1 0 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 0 1 0 0 0 0 1 0 1 1 1 1\n",
            " 0 1 1 1 0 0 1 0 1 0 0 1 0 1 1 1 1 0 0 1 0 0 0 1 0 1 1 1 1 1 0 1 1 1 1 0 0\n",
            " 1 1 1 1 0 0 0 0 0 0 1 1 1 1 0 1 0 1 0 0 0 1 1 1 0 0 1 1 0 1 1 1 0 0 0 1 1\n",
            " 0 1 0 1 0 1 0 1 0 0 0 1 0 1 1 0 1 0 0 0 1 1 1 0 0 0 0 0 1 1 1 1 1 0 0 1 0\n",
            " 0 0 1 1 1 1 0 0 0 0 0 1 0 1 0 1 0 1 1 0 1 0 1 0 0 1 1 0 0 1 1 1 1 1 1 0 0\n",
            " 0 1 0 1 1 1 0 0 0 1 1 0 1 1 0 1 0 1 1 1 0 0 1 0 1 0 1 0 0 1 0 1 0 0 0 0 1\n",
            " 1 0 1 1 0 0 1 0 0 1 0 1 1 1 1 1 0 0 0 0 0 0 1 1 0 1 1 0 1 0 0 0 0 1 0 1 0\n",
            " 1 1 1 0 0 0 1 0 1 0 0 1 0 0 0 0 1 1 1 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 0 1 1\n",
            " 0 1 1 1 0 0 1 0 1 1 1 1 1 1 1 0 1 0 0 1 0 0 0 1 1 1 0 0 1 0 0 1 1 1 0 1 1\n",
            " 1 1 1 1 0 0 1 0 0 0 1 1 1 1 1 0 1 1 1 1 0 1 0 1 1 1 0 1 1 1 0 1 1 0 1 0 0\n",
            " 1]\n",
            "probabilities: (852, 2) \n",
            " [1 0 1 0 1 1 0 1 0 0 1 1 1 0 1 1 0 0 0 0 0 0 1 0 1 1 0 0 1 1 0 0 1 1 0 0 1\n",
            " 0 1 0 0 0 1 1 0 0 1 1 1 0 0 0 1 1 0 1 1 1 1 1 1 1 0 1 1 1 0 0 0 0 1 0 1 1\n",
            " 1 1 1 0 0 1 1 1 0 0 0 0 0 1 1 0 1 1 0 1 0 1 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
            " 0 0 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 0 1 0 1 1 0 1 1 0 0 1 0 0 1 1 1 0 1 1 1\n",
            " 0 1 1 1 1 0 1 0 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 1 0 1\n",
            " 0 1 0 1 1 0 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 0 1 0 1 1 1 1 0 1 0 1 1\n",
            " 1 1 0 1 1 0 1 1 1 1 1 1 1 0 1 0 0 1 0 0 0 0 1 1 1 0 0 0 0 1 0 0 1 0 0 0 0\n",
            " 1 0 1 0 1 0 1 0 0 0 1 1 0 1 1 0 1 0 1 1 0 1 0 1 0 0 0 0 1 1 1 0 0 1 0 1 0\n",
            " 0 1 0 1 0 1 0 1 1 0 1 0 1 0 0 1 1 1 1 1 1 1 1 1 0 0 1 1 0 0 1 1 0 1 1 0 1\n",
            " 0 1 0 0 0 1 1 1 0 0 1 0 0 0 0 1 1 0 1 1 0 1 0 1 1 0 1 0 0 0 0 1 1 0 0 1 0\n",
            " 0 0 0 0 1 0 1 0 1 1 0 1 0 1 1 0 1 1 1 1 0 0 1 1 1 1 0 1 0 1 0 0 1 0 0 0 1\n",
            " 1 0 1 0 0 1 1 0 0 1 0 1 0 0 1 1 0 0 1 0 1 1 0 0 1 1 1 1 0 1 1 0 1 1 1 1 1\n",
            " 1 1 1 0 0 1 0 1 1 0 0 1 0 0 1 1 0 1 1 0 1 1 1 0 0 0 0 1 1 0 0 1 0 0 1 1 1\n",
            " 1 0 1 1 0 1 1 1 1 0 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 0 1 0 0 0 0 1 0 1 1 1 1\n",
            " 0 1 1 1 0 0 1 0 1 0 0 1 0 1 1 1 1 0 0 1 0 0 0 1 0 1 1 1 1 1 0 1 1 1 1 0 0\n",
            " 1 1 1 1 0 0 0 0 0 0 1 1 1 1 0 1 0 1 0 0 0 1 1 1 0 0 1 1 0 1 1 1 0 0 0 1 1\n",
            " 0 1 0 1 0 1 0 1 0 0 0 1 0 1 1 0 1 0 0 0 1 1 1 0 0 0 0 0 1 1 1 1 1 0 0 1 0\n",
            " 0 0 1 1 1 1 0 0 0 0 0 1 0 1 0 1 0 1 1 0 1 0 1 0 0 1 1 0 0 1 1 1 1 1 1 0 0\n",
            " 0 1 0 1 1 1 0 0 0 1 1 0 1 1 0 1 0 1 1 1 0 0 1 0 1 0 1 0 0 1 0 1 0 0 0 0 1\n",
            " 1 0 1 1 0 0 1 0 0 1 0 1 1 1 1 1 0 0 0 0 0 0 1 1 0 1 1 0 1 0 0 0 0 1 0 1 0\n",
            " 1 1 1 0 0 0 1 0 1 0 0 1 0 0 0 0 1 1 1 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 0 1 1\n",
            " 0 1 1 1 0 0 1 0 1 1 1 1 1 1 1 0 1 0 0 1 0 0 0 1 1 1 0 0 1 0 0 1 1 1 0 1 1\n",
            " 1 1 1 1 0 0 1 0 0 0 1 1 1 1 1 0 1 1 1 1 0 1 0 1 1 1 0 1 1 1 0 1 1 0 1 0 0\n",
            " 1]\n",
            "uniques chosen: 10 <= should be equal to: 10\n",
            "trainset before adding uncertain samples (450, 10) (450,)\n",
            "trainset after adding uncertain samples (460, 10) (460,)\n",
            "updated train set: (460, 10) (460,) unique(labels): [206 254] [0 1]\n",
            "val set: (842, 10) (842,)\n",
            "\n",
            "Train set: (460, 10)\n",
            "Validation set: (842, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 46\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.248 s \n",
            "\n",
            "Accuracy rate is 79.723502 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.88      0.87       321\n",
            "           1       0.62      0.56      0.59       113\n",
            "\n",
            "    accuracy                           0.80       434\n",
            "   macro avg       0.74      0.72      0.73       434\n",
            "weighted avg       0.79      0.80      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[283  38]\n",
            " [ 50  63]]\n",
            "--------------------------------\n",
            "val predicted: (842,) [1 0 1 0 1 1 0 0 0 0 1 1 1 0 1 1 0 0 0 0 0 0 1 0 1 1 0 0 1 0 0 1 1 0 0 1 0\n",
            " 1 0 0 0 0 1 0 0 1 1 1 0 0 0 1 1 0 1 1 1 1 1 1 1 0 1 1 0 0 0 0 1 0 1 1 1 1\n",
            " 1 0 0 1 1 1 0 0 0 0 0 1 1 0 1 1 0 1 0 1 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
            " 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 0 1 0 1 1 0 1 1 0 0 1 0 0 1 1 1 0 1 1 1 0 1\n",
            " 1 1 1 0 1 0 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 1 0 1 0 1\n",
            " 0 1 1 0 0 1 0 0 1 1 1 1 1 1 1 1 1 1 0 1 0 1 0 1 0 1 1 1 1 0 1 0 1 1 1 1 0\n",
            " 1 1 0 1 1 1 1 1 1 1 0 1 0 0 1 0 0 0 0 1 1 1 0 0 0 0 1 0 0 1 0 0 0 0 1 0 1\n",
            " 0 1 0 1 0 0 0 1 1 0 1 1 0 1 0 1 1 0 1 0 1 0 0 0 0 1 1 1 0 0 1 0 1 0 0 1 0\n",
            " 1 0 1 0 1 1 0 1 0 1 0 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 0 1 0 0 1 1 0 1 0 1 0\n",
            " 0 0 1 1 1 0 0 1 0 0 0 0 1 1 0 1 1 0 1 0 1 1 0 1 0 0 0 0 1 1 0 0 1 0 0 0 0\n",
            " 0 1 0 1 0 1 1 0 1 0 1 1 0 1 1 1 1 0 0 1 1 1 1 0 1 0 1 0 0 1 0 0 0 1 1 0 1\n",
            " 0 0 1 1 0 0 1 0 1 0 0 1 1 0 1 0 1 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 0 0\n",
            " 1 0 1 1 0 0 1 0 0 1 1 0 1 1 0 1 1 1 0 0 0 0 1 1 0 0 1 0 0 1 1 1 1 0 1 1 0\n",
            " 1 0 1 1 0 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 0 1 0 0 1 0 1 0 1 1 1 1 0 1 1 1 0\n",
            " 1 0 1 0 0 1 0 1 1 1 1 0 0 1 0 0 0 1 0 1 1 0 1 1 0 1 1 1 1 0 0 1 1 1 1 0 0\n",
            " 0 0 0 0 1 1 1 1 0 1 0 1 0 0 0 1 1 1 0 0 1 0 1 0 0 0 0 1 1 0 1 0 1 0 1 0 1\n",
            " 0 0 0 1 0 1 1 0 1 0 0 0 1 1 1 0 0 0 0 0 1 1 1 0 1 0 0 1 0 0 0 1 1 1 1 0 0\n",
            " 0 0 0 1 0 1 0 1 0 1 0 0 1 0 1 0 0 1 1 0 0 1 1 1 1 1 1 0 0 0 1 1 1 1 1 0 0\n",
            " 0 1 1 0 1 1 0 1 0 1 1 0 0 1 0 1 0 1 0 0 1 0 1 0 1 0 0 1 1 0 1 1 0 0 1 0 0\n",
            " 1 0 1 1 1 1 1 1 0 0 0 0 1 1 0 1 1 0 1 0 0 0 0 1 0 1 0 1 1 1 0 0 0 1 0 1 0\n",
            " 0 1 0 0 0 0 1 1 1 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 0 1 1 0 1 1 1 0 0 1 0 1 1\n",
            " 1 1 1 1 1 0 1 0 0 1 0 0 0 1 1 1 0 0 1 0 0 1 1 1 0 1 1 1 1 1 1 1 0 1 0 1 0\n",
            " 1 1 1 1 1 0 1 1 1 1 0 1 0 1 1 1 0 1 1 1 0 1 1 0 1 0 0 1]\n",
            "probabilities: (842, 2) \n",
            " [1 0 1 0 1 1 0 0 0 0 1 1 1 0 1 1 0 0 0 0 0 0 1 0 1 1 0 0 1 0 0 1 1 0 0 1 0\n",
            " 1 0 0 0 0 1 0 0 1 1 1 0 0 0 1 1 0 1 1 1 1 1 1 1 0 1 1 0 0 0 0 1 0 1 1 1 1\n",
            " 1 0 0 1 1 1 0 0 0 0 0 1 1 0 1 1 0 1 0 1 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
            " 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 0 1 0 1 1 0 1 1 0 0 1 0 0 1 1 1 0 1 1 1 0 1\n",
            " 1 1 1 0 1 0 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 1 0 1 0 1\n",
            " 0 1 1 0 0 1 0 0 1 1 1 1 1 1 1 1 1 1 0 1 0 1 0 1 0 1 1 1 1 0 1 0 1 1 1 1 0\n",
            " 1 1 0 1 1 1 1 1 1 1 0 1 0 0 1 0 0 0 0 1 1 1 0 0 0 0 1 0 0 1 0 0 0 0 1 0 1\n",
            " 0 1 0 1 0 0 0 1 1 0 1 1 0 1 0 1 1 0 1 0 1 0 0 0 0 1 1 1 0 0 1 0 1 0 0 1 0\n",
            " 1 0 1 0 1 1 0 1 0 1 0 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 0 1 0 0 1 1 0 1 0 1 0\n",
            " 0 0 1 1 1 0 0 1 0 0 0 0 1 1 0 1 1 0 1 0 1 1 0 1 0 0 0 0 1 1 0 0 1 0 0 0 0\n",
            " 0 1 0 1 0 1 1 0 1 0 1 1 0 1 1 1 1 0 0 1 1 1 1 0 1 0 1 0 0 1 0 0 0 1 1 0 1\n",
            " 0 0 1 1 0 0 1 0 1 0 0 1 1 0 1 0 1 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 0 0\n",
            " 1 0 1 1 0 0 1 0 0 1 1 0 1 1 0 1 1 1 0 0 0 0 1 1 0 0 1 0 0 1 1 1 1 0 1 1 0\n",
            " 1 0 1 1 0 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 0 1 0 0 1 0 1 0 1 1 1 1 0 1 1 1 0\n",
            " 1 0 1 0 0 1 0 1 1 1 1 0 0 1 0 0 0 1 0 1 1 0 1 1 0 1 1 1 1 0 0 1 1 1 1 0 0\n",
            " 0 0 0 0 1 1 1 1 0 1 0 1 0 0 0 1 1 1 0 0 1 0 1 0 0 0 0 1 1 0 1 0 1 0 1 0 1\n",
            " 0 0 0 1 0 1 1 0 1 0 0 0 1 1 1 0 0 0 0 0 1 1 1 0 1 0 0 1 0 0 0 1 1 1 1 0 0\n",
            " 0 0 0 1 0 1 0 1 0 1 0 0 1 0 1 0 0 1 1 0 0 1 1 1 1 1 1 0 0 0 1 1 1 1 1 0 0\n",
            " 0 1 1 0 1 1 0 1 0 1 1 0 0 1 0 1 0 1 0 0 1 0 1 0 1 0 0 1 1 0 1 1 0 0 1 0 0\n",
            " 1 0 1 1 1 1 1 1 0 0 0 0 1 1 0 1 1 0 1 0 0 0 0 1 0 1 0 1 1 1 0 0 0 1 0 1 0\n",
            " 0 1 0 0 0 0 1 1 1 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 0 1 1 0 1 1 1 0 0 1 0 1 1\n",
            " 1 1 1 1 1 0 1 0 0 1 0 0 0 1 1 1 0 0 1 0 0 1 1 1 0 1 1 1 1 1 1 1 0 1 0 1 0\n",
            " 1 1 1 1 1 0 1 1 1 1 0 1 0 1 1 1 0 1 1 1 0 1 1 0 1 0 0 1]\n",
            "uniques chosen: 10 <= should be equal to: 10\n",
            "trainset before adding uncertain samples (460, 10) (460,)\n",
            "trainset after adding uncertain samples (470, 10) (470,)\n",
            "updated train set: (470, 10) (470,) unique(labels): [210 260] [0 1]\n",
            "val set: (832, 10) (832,)\n",
            "\n",
            "Train set: (470, 10)\n",
            "Validation set: (832, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 47\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.259 s \n",
            "\n",
            "Accuracy rate is 78.801843 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.86      0.86       321\n",
            "           1       0.59      0.58      0.59       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.72      0.72      0.72       434\n",
            "weighted avg       0.79      0.79      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[276  45]\n",
            " [ 47  66]]\n",
            "--------------------------------\n",
            "val predicted: (832,) [1 0 1 0 1 1 0 0 0 0 1 1 1 0 1 0 0 0 0 0 0 1 0 1 1 0 0 1 0 0 1 1 0 0 1 0 0\n",
            " 0 0 0 1 1 0 0 1 1 1 0 0 0 1 1 0 1 1 1 1 1 1 1 0 1 1 0 0 0 0 1 0 1 1 1 1 1\n",
            " 0 0 1 1 1 0 0 0 0 0 1 1 0 0 1 0 1 0 1 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1\n",
            " 1 1 1 1 0 1 1 1 0 1 1 1 1 1 0 1 0 1 1 0 1 1 0 0 1 0 0 1 1 1 0 1 1 1 0 1 1\n",
            " 1 1 0 1 0 0 1 1 1 0 0 0 0 1 0 0 1 0 1 1 0 1 0 0 0 0 0 0 1 0 0 1 0 1 0 1 0\n",
            " 1 1 0 0 1 0 0 1 1 1 1 1 1 1 1 1 1 0 1 0 1 0 1 0 1 1 1 1 0 1 0 1 1 1 1 0 1\n",
            " 1 0 1 1 1 1 1 1 1 0 1 0 0 1 0 0 0 0 1 1 1 0 0 0 0 1 0 0 1 0 0 0 0 1 0 1 0\n",
            " 1 0 1 0 0 0 1 0 1 1 0 1 0 1 1 0 1 0 1 0 0 0 0 1 1 1 1 0 1 0 1 0 0 1 0 1 0\n",
            " 1 0 1 1 0 1 0 1 1 0 1 1 1 1 1 1 1 1 1 0 0 1 1 0 0 1 1 0 1 1 0 1 0 1 0 0 0\n",
            " 1 1 1 0 0 1 0 0 0 0 1 1 0 1 1 0 1 0 1 1 0 1 0 0 0 1 1 0 0 1 0 0 0 0 0 1 0\n",
            " 1 0 1 1 0 1 0 1 1 0 1 1 1 1 0 0 1 1 1 1 0 1 0 1 0 0 1 0 0 0 1 1 0 1 0 0 1\n",
            " 1 0 0 1 0 1 0 0 1 1 0 1 0 1 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 0 0 1 0 1\n",
            " 1 0 0 1 0 0 1 1 0 1 1 0 1 1 1 0 0 0 0 1 1 0 0 1 0 0 1 1 1 1 1 1 0 1 1 1 1\n",
            " 0 0 1 0 1 1 1 1 1 1 1 0 0 1 1 0 1 0 0 1 0 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 0\n",
            " 1 0 1 1 1 0 0 0 1 0 0 0 1 0 1 1 0 1 1 0 1 1 1 1 0 0 1 1 1 1 0 0 0 0 0 0 1\n",
            " 1 1 1 0 1 0 1 0 0 0 1 1 1 0 0 1 0 1 0 0 0 0 1 1 0 1 0 1 0 1 0 1 0 0 0 1 0\n",
            " 1 1 0 1 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 1 0 0 1 0 1 0 1 1 1 1 0 0 0 0 0 1 0\n",
            " 1 0 1 0 1 1 0 1 0 1 0 0 1 1 0 0 1 1 1 1 1 1 0 0 0 1 0 1 1 1 0 0 0 1 1 0 1\n",
            " 1 0 1 0 1 1 0 0 1 0 1 0 1 0 0 1 0 1 0 0 1 1 1 1 1 0 0 1 0 0 1 0 1 1 1 1 1\n",
            " 1 0 0 0 0 1 1 0 1 1 0 1 0 0 0 0 1 0 1 0 1 1 1 0 0 0 1 0 1 0 0 1 0 0 0 0 1\n",
            " 1 1 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 0 1 0 0 1 1 1 0 0 1 0 1 1 1 1 1 0 1 0 1\n",
            " 0 0 1 0 0 0 1 1 1 0 0 1 0 0 1 1 1 1 1 1 1 1 1 1 0 1 0 1 0 1 1 1 1 1 1 1 1\n",
            " 1 0 1 0 1 1 1 0 1 0 1 0 1 1 0 1 0 1]\n",
            "probabilities: (832, 2) \n",
            " [1 0 1 0 1 1 0 0 0 0 1 1 1 0 1 0 0 0 0 0 0 1 0 1 1 0 0 1 0 0 1 1 0 0 1 0 0\n",
            " 0 0 0 1 1 0 0 1 1 1 0 0 0 1 1 0 1 1 1 1 1 1 1 0 1 1 0 0 0 0 1 0 1 1 1 1 1\n",
            " 0 0 1 1 1 0 0 0 0 0 1 1 0 0 1 0 1 0 1 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1\n",
            " 1 1 1 1 0 1 1 1 0 1 1 1 1 1 0 1 0 1 1 0 1 1 0 0 1 0 0 1 1 1 0 1 1 1 0 1 1\n",
            " 1 1 0 1 0 0 1 1 1 0 0 0 0 1 0 0 1 0 1 1 0 1 0 0 0 0 0 0 1 0 0 1 0 1 0 1 0\n",
            " 1 1 0 0 1 0 0 1 1 1 1 1 1 1 1 1 1 0 1 0 1 0 1 0 1 1 1 1 0 1 0 1 1 1 1 0 1\n",
            " 1 0 1 1 1 1 1 1 1 0 1 0 0 1 0 0 0 0 1 1 1 0 0 0 0 1 0 0 1 0 0 0 0 1 0 1 0\n",
            " 1 0 1 0 0 0 1 0 1 1 0 1 0 1 1 0 1 0 1 0 0 0 0 1 1 1 1 0 1 0 1 0 0 1 0 1 0\n",
            " 1 0 1 1 0 1 0 1 1 0 1 1 1 1 1 1 1 1 1 0 0 1 1 0 0 1 1 0 1 1 0 1 0 1 0 0 0\n",
            " 1 1 1 0 0 1 0 0 0 0 1 1 0 1 1 0 1 0 1 1 0 1 0 0 0 1 1 0 0 1 0 0 0 0 0 1 0\n",
            " 1 0 1 1 0 1 0 1 1 0 1 1 1 1 0 0 1 1 1 1 0 1 0 1 0 0 1 0 0 0 1 1 0 1 0 0 1\n",
            " 1 0 0 1 0 1 0 0 1 1 0 1 0 1 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 0 0 1 0 1\n",
            " 1 0 0 1 0 0 1 1 0 1 1 0 1 1 1 0 0 0 0 1 1 0 0 1 0 0 1 1 1 1 1 1 0 1 1 1 1\n",
            " 0 0 1 0 1 1 1 1 1 1 1 0 0 1 1 0 1 0 0 1 0 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 0\n",
            " 1 0 1 1 1 0 0 0 1 0 0 0 1 0 1 1 0 1 1 0 1 1 1 1 0 0 1 1 1 1 0 0 0 0 0 0 1\n",
            " 1 1 1 0 1 0 1 0 0 0 1 1 1 0 0 1 0 1 0 0 0 0 1 1 0 1 0 1 0 1 0 1 0 0 0 1 0\n",
            " 1 1 0 1 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 1 0 0 1 0 1 0 1 1 1 1 0 0 0 0 0 1 0\n",
            " 1 0 1 0 1 1 0 1 0 1 0 0 1 1 0 0 1 1 1 1 1 1 0 0 0 1 0 1 1 1 0 0 0 1 1 0 1\n",
            " 1 0 1 0 1 1 0 0 1 0 1 0 1 0 0 1 0 1 0 0 1 1 1 1 1 0 0 1 0 0 1 0 1 1 1 1 1\n",
            " 1 0 0 0 0 1 1 0 1 1 0 1 0 0 0 0 1 0 1 0 1 1 1 0 0 0 1 0 1 0 0 1 0 0 0 0 1\n",
            " 1 1 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 0 1 0 0 1 1 1 0 0 1 0 1 1 1 1 1 0 1 0 1\n",
            " 0 0 1 0 0 0 1 1 1 0 0 1 0 0 1 1 1 1 1 1 1 1 1 1 0 1 0 1 0 1 1 1 1 1 1 1 1\n",
            " 1 0 1 0 1 1 1 0 1 0 1 0 1 1 0 1 0 1]\n",
            "uniques chosen: 10 <= should be equal to: 10\n",
            "trainset before adding uncertain samples (470, 10) (470,)\n",
            "trainset after adding uncertain samples (480, 10) (480,)\n",
            "updated train set: (480, 10) (480,) unique(labels): [213 267] [0 1]\n",
            "val set: (822, 10) (822,)\n",
            "\n",
            "Train set: (480, 10)\n",
            "Validation set: (822, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 48\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.267 s \n",
            "\n",
            "Accuracy rate is 78.571429 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.86      0.86       321\n",
            "           1       0.59      0.57      0.58       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.72      0.71      0.72       434\n",
            "weighted avg       0.78      0.79      0.78       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[277  44]\n",
            " [ 49  64]]\n",
            "--------------------------------\n",
            "val predicted: (822,) [1 0 1 0 1 1 0 0 0 0 1 1 0 1 0 0 0 0 0 0 1 0 1 1 0 0 1 0 0 1 1 0 0 1 1 1 0\n",
            " 0 0 0 1 0 0 1 1 1 0 0 0 1 1 0 1 1 1 1 1 1 1 0 1 0 0 0 0 1 0 1 1 1 1 1 0 0\n",
            " 1 1 1 0 0 0 0 0 1 1 0 1 1 0 1 0 1 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 1\n",
            " 1 0 1 1 1 0 1 1 1 1 0 0 1 0 1 1 0 1 1 0 0 1 0 0 1 1 0 1 1 1 0 1 1 1 1 0 1\n",
            " 0 0 1 1 1 0 0 0 0 0 0 0 1 0 1 1 0 1 0 0 0 0 0 0 1 0 0 1 0 1 0 1 0 1 1 0 1\n",
            " 0 0 1 1 1 1 1 1 1 1 1 1 0 1 0 1 0 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1\n",
            " 1 1 1 0 1 0 0 1 0 0 0 0 1 1 1 0 0 0 0 1 1 0 1 0 0 0 0 0 1 0 1 0 1 0 0 0 1\n",
            " 0 1 1 0 1 0 1 1 0 1 0 1 0 0 0 0 1 1 1 1 0 1 0 1 0 0 1 0 1 0 1 0 1 1 0 1 0\n",
            " 1 1 0 1 1 1 1 1 1 1 1 1 0 0 1 1 0 0 1 1 0 1 1 0 1 0 1 0 0 0 1 1 1 0 0 1 0\n",
            " 0 0 1 1 0 1 1 0 1 0 1 1 0 1 0 0 0 1 1 0 0 1 0 0 0 0 0 1 0 1 0 1 1 0 1 1 1\n",
            " 0 1 1 1 1 0 0 1 1 1 1 0 1 0 1 0 0 1 0 0 0 1 1 0 1 0 0 1 1 0 0 1 0 1 0 0 1\n",
            " 1 0 1 0 1 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 0 0 1 0 1 1 0 0 1 0 0 1 1 0\n",
            " 1 1 0 1 1 1 0 0 0 0 1 1 0 0 1 0 0 1 1 1 1 1 1 0 1 1 1 1 0 0 1 0 1 1 1 1 1\n",
            " 1 1 0 0 1 1 0 1 0 0 1 0 1 0 1 1 1 0 1 1 1 0 1 0 1 0 0 1 0 1 1 1 0 0 0 1 0\n",
            " 0 0 1 0 1 1 0 1 1 0 1 1 1 1 0 0 1 1 1 1 0 0 0 0 0 0 1 1 1 1 0 1 0 1 0 0 0\n",
            " 1 1 1 0 0 1 0 1 0 0 0 0 1 1 0 1 0 1 0 1 0 1 0 0 0 1 0 1 1 0 1 0 0 0 1 1 1\n",
            " 1 0 0 0 0 1 1 1 1 1 0 0 1 0 1 0 1 1 1 1 0 0 0 0 0 1 0 1 0 1 0 1 1 0 1 0 1\n",
            " 0 0 1 1 0 0 1 1 1 1 1 1 0 0 0 1 1 1 1 1 0 0 0 1 1 0 1 1 0 1 0 1 1 0 0 1 0\n",
            " 1 0 1 0 0 1 0 1 0 1 1 1 1 1 1 0 0 1 0 0 1 0 1 1 1 1 1 1 0 0 0 0 1 1 0 1 1\n",
            " 0 1 0 0 0 0 1 0 1 0 1 1 1 0 0 0 1 0 1 0 0 1 0 0 0 0 1 1 1 1 0 1 1 0 0 1 1\n",
            " 1 0 0 1 1 1 1 0 1 1 0 1 1 1 0 0 1 0 1 1 1 1 1 0 1 0 1 0 0 1 0 0 0 1 1 1 0\n",
            " 0 1 0 0 1 1 1 1 1 1 1 1 1 0 0 1 0 1 0 1 1 1 1 1 0 1 1 1 0 1 0 1 1 1 0 1 1\n",
            " 1 0 1 1 0 1 0 0]\n",
            "probabilities: (822, 2) \n",
            " [1 0 1 0 1 1 0 0 0 0 1 1 0 1 0 0 0 0 0 0 1 0 1 1 0 0 1 0 0 1 1 0 0 1 1 1 0\n",
            " 0 0 0 1 0 0 1 1 1 0 0 0 1 1 0 1 1 1 1 1 1 1 0 1 0 0 0 0 1 0 1 1 1 1 1 0 0\n",
            " 1 1 1 0 0 0 0 0 1 1 0 1 1 0 1 0 1 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 1\n",
            " 1 0 1 1 1 0 1 1 1 1 0 0 1 0 1 1 0 1 1 0 0 1 0 0 1 1 0 1 1 1 0 1 1 1 1 0 1\n",
            " 0 0 1 1 1 0 0 0 0 0 0 0 1 0 1 1 0 1 0 0 0 0 0 0 1 0 0 1 0 1 0 1 0 1 1 0 1\n",
            " 0 0 1 1 1 1 1 1 1 1 1 1 0 1 0 1 0 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1\n",
            " 1 1 1 0 1 0 0 1 0 0 0 0 1 1 1 0 0 0 0 1 1 0 1 0 0 0 0 0 1 0 1 0 1 0 0 0 1\n",
            " 0 1 1 0 1 0 1 1 0 1 0 1 0 0 0 0 1 1 1 1 0 1 0 1 0 0 1 0 1 0 1 0 1 1 0 1 0\n",
            " 1 1 0 1 1 1 1 1 1 1 1 1 0 0 1 1 0 0 1 1 0 1 1 0 1 0 1 0 0 0 1 1 1 0 0 1 0\n",
            " 0 0 1 1 0 1 1 0 1 0 1 1 0 1 0 0 0 1 1 0 0 1 0 0 0 0 0 1 0 1 0 1 1 0 1 1 1\n",
            " 0 1 1 1 1 0 0 1 1 1 1 0 1 0 1 0 0 1 0 0 0 1 1 0 1 0 0 1 1 0 0 1 0 1 0 0 1\n",
            " 1 0 1 0 1 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 0 0 1 0 1 1 0 0 1 0 0 1 1 0\n",
            " 1 1 0 1 1 1 0 0 0 0 1 1 0 0 1 0 0 1 1 1 1 1 1 0 1 1 1 1 0 0 1 0 1 1 1 1 1\n",
            " 1 1 0 0 1 1 0 1 0 0 1 0 1 0 1 1 1 0 1 1 1 0 1 0 1 0 0 1 0 1 1 1 0 0 0 1 0\n",
            " 0 0 1 0 1 1 0 1 1 0 1 1 1 1 0 0 1 1 1 1 0 0 0 0 0 0 1 1 1 1 0 1 0 1 0 0 0\n",
            " 1 1 1 0 0 1 0 1 0 0 0 0 1 1 0 1 0 1 0 1 0 1 0 0 0 1 0 1 1 0 1 0 0 0 1 1 1\n",
            " 1 0 0 0 0 1 1 1 1 1 0 0 1 0 1 0 1 1 1 1 0 0 0 0 0 1 0 1 0 1 0 1 1 0 1 0 1\n",
            " 0 0 1 1 0 0 1 1 1 1 1 1 0 0 0 1 1 1 1 1 0 0 0 1 1 0 1 1 0 1 0 1 1 0 0 1 0\n",
            " 1 0 1 0 0 1 0 1 0 1 1 1 1 1 1 0 0 1 0 0 1 0 1 1 1 1 1 1 0 0 0 0 1 1 0 1 1\n",
            " 0 1 0 0 0 0 1 0 1 0 1 1 1 0 0 0 1 0 1 0 0 1 0 0 0 0 1 1 1 1 0 1 1 0 0 1 1\n",
            " 1 0 0 1 1 1 1 0 1 1 0 1 1 1 0 0 1 0 1 1 1 1 1 0 1 0 1 0 0 1 0 0 0 1 1 1 0\n",
            " 0 1 0 0 1 1 1 1 1 1 1 1 1 0 0 1 0 1 0 1 1 1 1 1 0 1 1 1 0 1 0 1 1 1 0 1 1\n",
            " 1 0 1 1 0 1 0 0]\n",
            "uniques chosen: 10 <= should be equal to: 10\n",
            "trainset before adding uncertain samples (480, 10) (480,)\n",
            "trainset after adding uncertain samples (490, 10) (490,)\n",
            "updated train set: (490, 10) (490,) unique(labels): [217 273] [0 1]\n",
            "val set: (812, 10) (812,)\n",
            "\n",
            "Train set: (490, 10)\n",
            "Validation set: (812, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 49\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.287 s \n",
            "\n",
            "Accuracy rate is 79.493088 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.88      0.86       321\n",
            "           1       0.62      0.57      0.59       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.73      0.72      0.73       434\n",
            "weighted avg       0.79      0.79      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[281  40]\n",
            " [ 49  64]]\n",
            "--------------------------------\n",
            "val predicted: (812,) [1 0 1 0 1 1 0 0 0 0 1 1 0 1 0 0 0 0 0 0 1 1 1 1 0 0 1 0 0 1 1 0 0 1 1 0 0\n",
            " 0 0 1 1 0 0 1 1 1 0 0 0 1 1 0 1 1 1 1 1 1 1 0 1 0 0 0 0 1 0 1 1 1 1 1 0 0\n",
            " 1 1 1 0 0 0 0 0 1 1 0 1 1 0 1 0 1 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 1\n",
            " 1 0 1 1 1 0 1 1 1 1 0 0 1 0 1 1 0 1 1 0 0 1 0 0 1 1 0 1 1 1 0 1 1 1 1 0 1\n",
            " 0 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 1 0 1 0 1 0 1 1 0 1\n",
            " 0 0 1 1 1 1 1 1 1 1 1 1 0 1 0 1 0 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1\n",
            " 1 1 1 0 1 0 0 1 0 0 0 0 1 1 1 0 0 0 0 1 1 0 1 0 0 0 0 0 1 0 1 0 1 0 0 0 1\n",
            " 0 1 1 0 1 0 1 1 0 1 0 1 0 0 0 0 0 1 1 1 0 1 0 1 0 0 1 0 1 0 1 0 1 1 0 1 0\n",
            " 1 0 0 1 1 1 1 1 1 1 1 1 0 0 1 1 0 0 1 1 0 1 1 0 1 0 1 0 0 0 1 1 0 0 1 0 0\n",
            " 0 1 1 0 1 1 0 1 0 1 1 0 1 0 0 0 1 1 0 0 1 0 0 0 0 0 1 0 1 0 1 1 0 1 1 0 0\n",
            " 1 1 1 1 0 0 1 1 1 1 0 1 0 1 0 0 1 0 0 1 1 0 1 0 0 1 1 0 0 1 0 1 0 0 1 1 0\n",
            " 1 0 1 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 0 0 1 0 1 1 0 0 1 0 0 1 1 0 1 0\n",
            " 1 1 1 0 0 0 0 1 1 0 1 0 0 1 1 1 1 1 1 0 1 1 1 1 0 0 1 0 1 1 1 1 1 1 1 0 0\n",
            " 1 1 0 1 0 0 1 0 1 0 1 1 1 0 1 1 1 0 1 0 1 0 0 1 0 1 1 1 1 0 0 1 0 0 0 1 1\n",
            " 1 1 1 1 0 1 1 1 1 0 0 1 1 1 1 0 0 0 0 0 0 1 1 1 1 0 1 0 1 0 0 0 1 1 1 0 0\n",
            " 1 0 1 0 0 0 0 1 1 0 1 1 0 1 0 1 0 0 0 0 1 1 0 1 0 0 0 1 1 1 1 0 0 0 0 1 1\n",
            " 1 1 0 0 1 0 0 0 1 1 1 1 0 0 0 0 0 1 0 1 0 1 0 1 1 0 1 0 1 0 0 1 1 0 0 1 1\n",
            " 1 1 1 0 0 0 0 1 0 1 1 1 0 0 0 1 1 0 1 1 0 1 0 1 1 0 0 1 0 1 0 1 0 0 1 0 1\n",
            " 0 1 1 1 1 1 1 0 0 1 0 0 1 0 1 1 1 1 1 1 0 0 0 0 1 1 0 1 1 0 1 0 0 0 0 1 0\n",
            " 1 0 1 1 1 0 0 0 1 0 1 0 0 1 0 0 0 0 0 1 1 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 0\n",
            " 1 1 0 1 1 0 0 1 0 1 1 1 1 1 1 1 0 1 0 0 1 0 1 0 1 1 1 0 0 1 0 0 1 1 1 1 1\n",
            " 1 1 1 1 1 0 1 0 0 0 1 1 1 1 1 0 1 1 1 0 1 0 1 1 1 0 1 1 1 0 1 0 1 0 0]\n",
            "probabilities: (812, 2) \n",
            " [1 0 1 0 1 1 0 0 0 0 1 1 0 1 0 0 0 0 0 0 1 1 1 1 0 0 1 0 0 1 1 0 0 1 1 0 0\n",
            " 0 0 1 1 0 0 1 1 1 0 0 0 1 1 0 1 1 1 1 1 1 1 0 1 0 0 0 0 1 0 1 1 1 1 1 0 0\n",
            " 1 1 1 0 0 0 0 0 1 1 0 1 1 0 1 0 1 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 1\n",
            " 1 0 1 1 1 0 1 1 1 1 0 0 1 0 1 1 0 1 1 0 0 1 0 0 1 1 0 1 1 1 0 1 1 1 1 0 1\n",
            " 0 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 1 0 1 0 1 0 1 1 0 1\n",
            " 0 0 1 1 1 1 1 1 1 1 1 1 0 1 0 1 0 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1\n",
            " 1 1 1 0 1 0 0 1 0 0 0 0 1 1 1 0 0 0 0 1 1 0 1 0 0 0 0 0 1 0 1 0 1 0 0 0 1\n",
            " 0 1 1 0 1 0 1 1 0 1 0 1 0 0 0 0 0 1 1 1 0 1 0 1 0 0 1 0 1 0 1 0 1 1 0 1 0\n",
            " 1 0 0 1 1 1 1 1 1 1 1 1 0 0 1 1 0 0 1 1 0 1 1 0 1 0 1 0 0 0 1 1 0 0 1 0 0\n",
            " 0 1 1 0 1 1 0 1 0 1 1 0 1 0 0 0 1 1 0 0 1 0 0 0 0 0 1 0 1 0 1 1 0 1 1 0 0\n",
            " 1 1 1 1 0 0 1 1 1 1 0 1 0 1 0 0 1 0 0 1 1 0 1 0 0 1 1 0 0 1 0 1 0 0 1 1 0\n",
            " 1 0 1 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 0 0 1 0 1 1 0 0 1 0 0 1 1 0 1 0\n",
            " 1 1 1 0 0 0 0 1 1 0 1 0 0 1 1 1 1 1 1 0 1 1 1 1 0 0 1 0 1 1 1 1 1 1 1 0 0\n",
            " 1 1 0 1 0 0 1 0 1 0 1 1 1 0 1 1 1 0 1 0 1 0 0 1 0 1 1 1 1 0 0 1 0 0 0 1 1\n",
            " 1 1 1 1 0 1 1 1 1 0 0 1 1 1 1 0 0 0 0 0 0 1 1 1 1 0 1 0 1 0 0 0 1 1 1 0 0\n",
            " 1 0 1 0 0 0 0 1 1 0 1 1 0 1 0 1 0 0 0 0 1 1 0 1 0 0 0 1 1 1 1 0 0 0 0 1 1\n",
            " 1 1 0 0 1 0 0 0 1 1 1 1 0 0 0 0 0 1 0 1 0 1 0 1 1 0 1 0 1 0 0 1 1 0 0 1 1\n",
            " 1 1 1 0 0 0 0 1 0 1 1 1 0 0 0 1 1 0 1 1 0 1 0 1 1 0 0 1 0 1 0 1 0 0 1 0 1\n",
            " 0 1 1 1 1 1 1 0 0 1 0 0 1 0 1 1 1 1 1 1 0 0 0 0 1 1 0 1 1 0 1 0 0 0 0 1 0\n",
            " 1 0 1 1 1 0 0 0 1 0 1 0 0 1 0 0 0 0 0 1 1 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 0\n",
            " 1 1 0 1 1 0 0 1 0 1 1 1 1 1 1 1 0 1 0 0 1 0 1 0 1 1 1 0 0 1 0 0 1 1 1 1 1\n",
            " 1 1 1 1 1 0 1 0 0 0 1 1 1 1 1 0 1 1 1 0 1 0 1 1 1 0 1 1 1 0 1 0 1 0 0]\n",
            "uniques chosen: 10 <= should be equal to: 10\n",
            "trainset before adding uncertain samples (490, 10) (490,)\n",
            "trainset after adding uncertain samples (500, 10) (500,)\n",
            "updated train set: (500, 10) (500,) unique(labels): [222 278] [0 1]\n",
            "val set: (802, 10) (802,)\n",
            "\n",
            "Train set: (500, 10)\n",
            "Validation set: (802, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 50\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.293 s \n",
            "\n",
            "Accuracy rate is 79.262673 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.87      0.86       321\n",
            "           1       0.61      0.58      0.59       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.73      0.73      0.73       434\n",
            "weighted avg       0.79      0.79      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[278  43]\n",
            " [ 47  66]]\n",
            "--------------------------------\n",
            "final active learning accuracies [63.36405529953917, 70.73732718894009, 61.29032258064516, 63.594470046082954, 74.65437788018433, 75.80645161290323, 76.49769585253456, 76.49769585253456, 77.41935483870968, 76.72811059907833, 78.3410138248848, 78.80184331797236, 77.41935483870968, 79.49308755760369, 77.64976958525345, 76.95852534562212, 77.18894009216591, 76.95852534562212, 77.64976958525345, 78.11059907834101, 78.11059907834101, 77.64976958525345, 77.64976958525345, 78.3410138248848, 78.57142857142857, 77.64976958525345, 77.64976958525345, 77.41935483870968, 77.88018433179722, 77.88018433179722, 77.88018433179722, 78.11059907834101, 77.64976958525345, 78.3410138248848, 78.80184331797236, 79.26267281105991, 78.57142857142857, 77.88018433179722, 77.64976958525345, 77.64976958525345, 78.11059907834101, 79.72350230414746, 79.72350230414746, 79.49308755760369, 79.03225806451613, 79.72350230414746, 78.80184331797236, 78.57142857142857, 79.49308755760369, 79.26267281105991]\n",
            "saved /Users/wenxuanhuang/Documents/Repo/ML-for-COVID-19-dataset/Results/Active-learning-experiment-5.pkl /Users/wenxuanhuang/Documents/Repo/ML-for-COVID-19-dataset ['Decision_tree.ipynb', 'dec_git.png', 'Logit_default_f10.pdf', 'Logistic.ipynb', 'SVC.ipynb', 'RF_f5e50_featureimp.pdf', 'log_al.png', 'dec_git.pdf', '.DS_Store', 'log_git.png', 'svm_git.png', 'Logistic_Scikit.ipynb', 'knn_git.pdf', 'knn_git.png', 'rf_al.png', 'Best classifier_RF_f5e50.pdf', 'KNN.ipynb', 'GBDC.ipynb', 'rf_git.png', 'README.md', 'all_training.csv', 'Results', 'svm_al.png', 'Log_ROC.png', 'Logit_default_f7(p_removal).pdf', 'Active_learning.ipynb', 'Random_forest.ipynb', 'Model_select.ipynb', 'gdbc_git.png', '.git', '.vscode', 'Untitled', 'RF_f5e50_modelselect.pdf', 'Logit_default_f8(std_removal).pdf']\n",
            "{\n",
            "  \"GDBCModel\": {\n",
            "    \"RandomSelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          63.36405529953917,\n",
            "          70.73732718894009,\n",
            "          61.29032258064516,\n",
            "          63.594470046082954,\n",
            "          74.65437788018433,\n",
            "          75.80645161290323,\n",
            "          76.49769585253456,\n",
            "          76.49769585253456,\n",
            "          77.41935483870968,\n",
            "          76.72811059907833,\n",
            "          78.3410138248848,\n",
            "          78.80184331797236,\n",
            "          77.41935483870968,\n",
            "          79.49308755760369,\n",
            "          77.64976958525345,\n",
            "          76.95852534562212,\n",
            "          77.18894009216591,\n",
            "          76.95852534562212,\n",
            "          77.64976958525345,\n",
            "          78.11059907834101,\n",
            "          78.11059907834101,\n",
            "          77.64976958525345,\n",
            "          77.64976958525345,\n",
            "          78.3410138248848,\n",
            "          78.57142857142857,\n",
            "          77.64976958525345,\n",
            "          77.64976958525345,\n",
            "          77.41935483870968,\n",
            "          77.88018433179722,\n",
            "          77.88018433179722,\n",
            "          77.88018433179722,\n",
            "          78.11059907834101,\n",
            "          77.64976958525345,\n",
            "          78.3410138248848,\n",
            "          78.80184331797236,\n",
            "          79.26267281105991,\n",
            "          78.57142857142857,\n",
            "          77.88018433179722,\n",
            "          77.64976958525345,\n",
            "          77.64976958525345,\n",
            "          78.11059907834101,\n",
            "          79.72350230414746,\n",
            "          79.72350230414746,\n",
            "          79.49308755760369,\n",
            "          79.03225806451613,\n",
            "          79.72350230414746,\n",
            "          78.80184331797236,\n",
            "          78.57142857142857,\n",
            "          79.49308755760369,\n",
            "          79.26267281105991\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          72.58064516129032,\n",
            "          72.58064516129032,\n",
            "          76.036866359447,\n",
            "          76.26728110599078\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          72.35023041474655,\n",
            "          72.11981566820278,\n",
            "          71.88940092165899,\n",
            "          73.04147465437788,\n",
            "          72.81105990783409,\n",
            "          75.11520737327189,\n",
            "          73.50230414746544,\n",
            "          76.036866359447,\n",
            "          76.26728110599078,\n",
            "          76.49769585253456,\n",
            "          76.72811059907833,\n",
            "          77.18894009216591,\n",
            "          76.72811059907833,\n",
            "          78.11059907834101,\n",
            "          78.3410138248848,\n",
            "          77.64976958525345,\n",
            "          79.72350230414746,\n",
            "          79.95391705069125,\n",
            "          80.18433179723502,\n",
            "          80.87557603686636\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          78.3410138248848,\n",
            "          79.95391705069125\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          69.35483870967742,\n",
            "          76.72811059907833,\n",
            "          78.3410138248848,\n",
            "          78.57142857142857,\n",
            "          78.80184331797236,\n",
            "          79.95391705069125,\n",
            "          79.26267281105991,\n",
            "          79.03225806451613,\n",
            "          79.03225806451613,\n",
            "          78.80184331797236\n",
            "        ]\n",
            "      ]\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "---------------------------- FINISHED ---------------------------\n",
            "\n",
            "Count = 6, using model = GDBCModel, selection_function = MarginSamplingSelection, k = 250, iteration = 0.\n",
            "\n",
            "initial random chosen samples (250,)\n",
            "initial train set: (250, 10) (250,) unique(labels): [112 138] [0 1]\n",
            "Val set: (1052, 10) (1052,) (250,)\n",
            "\n",
            "Train set: (250, 10)\n",
            "Validation set: (1052, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.020 s \n",
            "\n",
            "Accuracy rate is 76.267281 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.86      0.84       321\n",
            "           1       0.55      0.50      0.52       113\n",
            "\n",
            "    accuracy                           0.76       434\n",
            "   macro avg       0.69      0.68      0.68       434\n",
            "weighted avg       0.76      0.76      0.76       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[275  46]\n",
            " [ 57  56]]\n",
            "--------------------------------\n",
            "val predicted: (1052,) [1 1 0 ... 0 0 0]\n",
            "probabilities: (1052, 2) \n",
            " [1 1 0 ... 0 0 0]\n",
            "trainset before adding uncertain samples (250, 10) (250,)\n",
            "trainset after adding uncertain samples (500, 10) (500,)\n",
            "updated train set: (500, 10) (500,) unique(labels): [227 273] [0 1]\n",
            "val set: (802, 10) (802,)\n",
            "\n",
            "Train set: (500, 10)\n",
            "Validation set: (802, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.313 s \n",
            "\n",
            "Accuracy rate is 79.262673 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.88      0.86       321\n",
            "           1       0.61      0.56      0.58       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.73      0.72      0.72       434\n",
            "weighted avg       0.79      0.79      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[281  40]\n",
            " [ 50  63]]\n",
            "--------------------------------\n",
            "final active learning accuracies [76.26728110599078, 79.26267281105991]\n",
            "saved /Users/wenxuanhuang/Documents/Repo/ML-for-COVID-19-dataset/Results/Active-learning-experiment-6.pkl /Users/wenxuanhuang/Documents/Repo/ML-for-COVID-19-dataset ['Decision_tree.ipynb', 'dec_git.png', 'Logit_default_f10.pdf', 'Logistic.ipynb', 'SVC.ipynb', 'RF_f5e50_featureimp.pdf', 'log_al.png', 'dec_git.pdf', '.DS_Store', 'log_git.png', 'svm_git.png', 'Logistic_Scikit.ipynb', 'knn_git.pdf', 'knn_git.png', 'rf_al.png', 'Best classifier_RF_f5e50.pdf', 'KNN.ipynb', 'GBDC.ipynb', 'rf_git.png', 'README.md', 'all_training.csv', 'Results', 'svm_al.png', 'Log_ROC.png', 'Logit_default_f7(p_removal).pdf', 'Active_learning.ipynb', 'Random_forest.ipynb', 'Model_select.ipynb', 'gdbc_git.png', '.git', '.vscode', 'Untitled', 'RF_f5e50_modelselect.pdf', 'Logit_default_f8(std_removal).pdf']\n",
            "\n",
            "---------------------------- FINISHED ---------------------------\n",
            "\n",
            "Count = 7, using model = GDBCModel, selection_function = MarginSamplingSelection, k = 125, iteration = 0.\n",
            "\n",
            "initial random chosen samples (125,)\n",
            "initial train set: (125, 10) (125,) unique(labels): [60 65] [0 1]\n",
            "Val set: (1177, 10) (1177,) (125,)\n",
            "\n",
            "Train set: (125, 10)\n",
            "Validation set: (1177, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.844 s \n",
            "\n",
            "Accuracy rate is 76.958525 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.83      0.84       321\n",
            "           1       0.55      0.59      0.57       113\n",
            "\n",
            "    accuracy                           0.77       434\n",
            "   macro avg       0.70      0.71      0.71       434\n",
            "weighted avg       0.78      0.77      0.77       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[267  54]\n",
            " [ 46  67]]\n",
            "--------------------------------\n",
            "val predicted: (1177,) [1 1 1 ... 1 0 0]\n",
            "probabilities: (1177, 2) \n",
            " [1 1 1 ... 1 0 0]\n",
            "trainset before adding uncertain samples (125, 10) (125,)\n",
            "trainset after adding uncertain samples (250, 10) (250,)\n",
            "updated train set: (250, 10) (250,) unique(labels): [112 138] [0 1]\n",
            "val set: (1052, 10) (1052,)\n",
            "\n",
            "Train set: (250, 10)\n",
            "Validation set: (1052, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.002 s \n",
            "\n",
            "Accuracy rate is 78.801843 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.84      0.85       321\n",
            "           1       0.59      0.64      0.61       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.73      0.74      0.73       434\n",
            "weighted avg       0.79      0.79      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[270  51]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "val predicted: (1052,) [1 1 0 ... 1 0 0]\n",
            "probabilities: (1052, 2) \n",
            " [1 1 0 ... 1 0 0]\n",
            "trainset before adding uncertain samples (250, 10) (250,)\n",
            "trainset after adding uncertain samples (375, 10) (375,)\n",
            "updated train set: (375, 10) (375,) unique(labels): [183 192] [0 1]\n",
            "val set: (927, 10) (927,)\n",
            "\n",
            "Train set: (375, 10)\n",
            "Validation set: (927, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 3\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.196 s \n",
            "\n",
            "Accuracy rate is 79.032258 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.86      0.86       321\n",
            "           1       0.60      0.58      0.59       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.73      0.72      0.73       434\n",
            "weighted avg       0.79      0.79      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[277  44]\n",
            " [ 47  66]]\n",
            "--------------------------------\n",
            "val predicted: (927,) [1 1 0 0 1 0 1 1 0 0 1 0 0 1 1 1 0 1 0 0 0 0 0 1 1 1 1 1 1 1 0 0 1 1 0 0 0\n",
            " 1 1 1 0 0 0 0 1 1 1 1 0 0 0 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 0 1 0 1 0 1 1\n",
            " 0 0 0 0 0 0 0 0 0 1 0 1 1 1 0 1 0 0 1 1 1 0 0 0 0 1 0 0 1 0 0 1 1 1 0 0 1\n",
            " 0 0 1 0 0 0 0 1 0 0 1 1 0 1 1 0 0 1 1 0 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0 1 0\n",
            " 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 0 1 1 1 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0\n",
            " 0 1 1 0 1 0 0 0 0 1 1 1 1 0 1 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 0\n",
            " 1 1 1 1 1 1 1 0 1 1 0 1 1 0 0 1 1 0 1 1 1 1 1 1 0 0 1 0 1 1 0 0 0 0 1 1 1\n",
            " 1 1 0 0 0 1 0 1 0 0 1 0 1 0 1 0 1 0 0 1 0 0 0 1 1 1 1 1 1 0 1 1 0 1 0 1 0\n",
            " 1 0 1 0 0 0 1 1 1 1 0 1 0 1 0 0 1 0 1 0 1 1 0 0 1 1 1 1 1 0 1 1 1 1 1 0 1\n",
            " 1 1 1 1 1 1 1 1 1 1 0 0 1 1 0 0 1 1 0 1 1 1 1 0 0 1 0 0 0 1 1 1 1 0 1 0 0\n",
            " 1 1 1 0 1 0 1 1 1 0 1 1 1 0 1 1 1 1 0 0 0 0 0 1 1 0 1 1 0 0 1 0 1 0 0 1 0\n",
            " 0 1 0 1 1 1 1 0 0 1 1 1 1 1 1 0 1 0 1 1 1 0 0 0 0 1 1 1 1 1 1 0 0 0 1 1 1\n",
            " 1 0 1 0 0 1 0 0 0 0 0 1 1 0 0 0 1 1 0 0 0 1 1 1 1 0 0 1 1 1 1 1 0 1 0 0 0\n",
            " 1 0 1 0 0 0 0 1 1 1 0 0 1 1 1 1 0 1 0 0 0 1 0 1 0 0 1 1 0 1 0 1 0 0 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1 1 1 1 0 1 1 1 1 0 0 1 0 1 0 1 1 0 1 0 1 1\n",
            " 1 1 1 1 1 1 0 1 0 0 1 0 1 0 0 1 0 1 0 0 0 1 0 1 1 1 1 1 0 0 1 0 1 1 0 1 1\n",
            " 1 1 0 0 0 1 1 0 1 1 1 1 1 0 0 1 0 1 1 1 1 1 1 0 1 1 1 1 0 0 1 1 1 1 0 1 1\n",
            " 0 0 1 0 1 1 0 0 0 1 0 1 1 1 0 0 1 1 0 1 1 0 0 1 0 0 0 1 0 1 1 1 0 1 0 0 1\n",
            " 1 0 1 0 0 1 0 1 1 1 1 1 0 0 0 0 1 0 1 1 1 0 1 0 1 0 0 1 0 0 0 1 0 0 1 1 0\n",
            " 0 1 1 1 0 1 0 0 1 0 0 1 0 1 1 1 0 0 0 1 1 0 0 1 0 1 0 1 1 0 0 1 0 1 0 0 0\n",
            " 0 1 0 1 0 0 0 1 1 1 1 0 1 0 0 1 0 0 0 0 1 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1\n",
            " 1 1 0 0 1 0 0 1 1 1 0 1 1 1 0 0 1 0 0 0 1 0 1 0 1 0 1 0 1 1 1 0 0 0 1 1 0\n",
            " 1 0 1 1 0 0 0 0 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0\n",
            " 0 1 1 1 1 1 1 1 0 1 1 0 0 1 1 0 0 0 1 0 1 1 0 0 0 1 0 1 0 1 1 1 0 1 0 1 1\n",
            " 1 1 0 1 0 1 0 0 0 1 1 1 0 0 1 0 1 0 1 1 1 0 1 0 1 1 0 0 1 1 0 1 0 1 1 1 1\n",
            " 0 0]\n",
            "probabilities: (927, 2) \n",
            " [1 1 0 0 1 0 1 1 0 0 1 0 0 1 1 1 0 1 0 0 0 0 0 1 1 1 1 1 1 1 0 0 1 1 0 0 0\n",
            " 1 1 1 0 0 0 0 1 1 1 1 0 0 0 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 0 1 0 1 0 1 1\n",
            " 0 0 0 0 0 0 0 0 0 1 0 1 1 1 0 1 0 0 1 1 1 0 0 0 0 1 0 0 1 0 0 1 1 1 0 0 1\n",
            " 0 0 1 0 0 0 0 1 0 0 1 1 0 1 1 0 0 1 1 0 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0 1 0\n",
            " 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 0 1 1 1 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0\n",
            " 0 1 1 0 1 0 0 0 0 1 1 1 1 0 1 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 0\n",
            " 1 1 1 1 1 1 1 0 1 1 0 1 1 0 0 1 1 0 1 1 1 1 1 1 0 0 1 0 1 1 0 0 0 0 1 1 1\n",
            " 1 1 0 0 0 1 0 1 0 0 1 0 1 0 1 0 1 0 0 1 0 0 0 1 1 1 1 1 1 0 1 1 0 1 0 1 0\n",
            " 1 0 1 0 0 0 1 1 1 1 0 1 0 1 0 0 1 0 1 0 1 1 0 0 1 1 1 1 1 0 1 1 1 1 1 0 1\n",
            " 1 1 1 1 1 1 1 1 1 1 0 0 1 1 0 0 1 1 0 1 1 1 1 0 0 1 0 0 0 1 1 1 1 0 1 0 0\n",
            " 1 1 1 0 1 0 1 1 1 0 1 1 1 0 1 1 1 1 0 0 0 0 0 1 1 0 1 1 0 0 1 0 1 0 0 1 0\n",
            " 0 1 0 1 1 1 1 0 0 1 1 1 1 1 1 0 1 0 1 1 1 0 0 0 0 1 1 1 1 1 1 0 0 0 1 1 1\n",
            " 1 0 1 0 0 1 0 0 0 0 0 1 1 0 0 0 1 1 0 0 0 1 1 1 1 0 0 1 1 1 1 1 0 1 0 0 0\n",
            " 1 0 1 0 0 0 0 1 1 1 0 0 1 1 1 1 0 1 0 0 0 1 0 1 0 0 1 1 0 1 0 1 0 0 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1 1 1 1 0 1 1 1 1 0 0 1 0 1 0 1 1 0 1 0 1 1\n",
            " 1 1 1 1 1 1 0 1 0 0 1 0 1 0 0 1 0 1 0 0 0 1 0 1 1 1 1 1 0 0 1 0 1 1 0 1 1\n",
            " 1 1 0 0 0 1 1 0 1 1 1 1 1 0 0 1 0 1 1 1 1 1 1 0 1 1 1 1 0 0 1 1 1 1 0 1 1\n",
            " 0 0 1 0 1 1 0 0 0 1 0 1 1 1 0 0 1 1 0 1 1 0 0 1 0 0 0 1 0 1 1 1 0 1 0 0 1\n",
            " 1 0 1 0 0 1 0 1 1 1 1 1 0 0 0 0 1 0 1 1 1 0 1 0 1 0 0 1 0 0 0 1 0 0 1 1 0\n",
            " 0 1 1 1 0 1 0 0 1 0 0 1 0 1 1 1 0 0 0 1 1 0 0 1 0 1 0 1 1 0 0 1 0 1 0 0 0\n",
            " 0 1 0 1 0 0 0 1 1 1 1 0 1 0 0 1 0 0 0 0 1 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1\n",
            " 1 1 0 0 1 0 0 1 1 1 0 1 1 1 0 0 1 0 0 0 1 0 1 0 1 0 1 0 1 1 1 0 0 0 1 1 0\n",
            " 1 0 1 1 0 0 0 0 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0\n",
            " 0 1 1 1 1 1 1 1 0 1 1 0 0 1 1 0 0 0 1 0 1 1 0 0 0 1 0 1 0 1 1 1 0 1 0 1 1\n",
            " 1 1 0 1 0 1 0 0 0 1 1 1 0 0 1 0 1 0 1 1 1 0 1 0 1 1 0 0 1 1 0 1 0 1 1 1 1\n",
            " 0 0]\n",
            "trainset before adding uncertain samples (375, 10) (375,)\n",
            "trainset after adding uncertain samples (500, 10) (500,)\n",
            "updated train set: (500, 10) (500,) unique(labels): [250 250] [0 1]\n",
            "val set: (802, 10) (802,)\n",
            "\n",
            "Train set: (500, 10)\n",
            "Validation set: (802, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 4\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.369 s \n",
            "\n",
            "Accuracy rate is 81.105991 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.89      0.87       321\n",
            "           1       0.65      0.58      0.62       113\n",
            "\n",
            "    accuracy                           0.81       434\n",
            "   macro avg       0.76      0.74      0.75       434\n",
            "weighted avg       0.81      0.81      0.81       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[286  35]\n",
            " [ 47  66]]\n",
            "--------------------------------\n",
            "final active learning accuracies [76.95852534562212, 78.80184331797236, 79.03225806451613, 81.10599078341014]\n",
            "saved /Users/wenxuanhuang/Documents/Repo/ML-for-COVID-19-dataset/Results/Active-learning-experiment-7.pkl /Users/wenxuanhuang/Documents/Repo/ML-for-COVID-19-dataset ['Decision_tree.ipynb', 'dec_git.png', 'Logit_default_f10.pdf', 'Logistic.ipynb', 'SVC.ipynb', 'RF_f5e50_featureimp.pdf', 'log_al.png', 'dec_git.pdf', '.DS_Store', 'log_git.png', 'svm_git.png', 'Logistic_Scikit.ipynb', 'knn_git.pdf', 'knn_git.png', 'rf_al.png', 'Best classifier_RF_f5e50.pdf', 'KNN.ipynb', 'GBDC.ipynb', 'rf_git.png', 'README.md', 'all_training.csv', 'Results', 'svm_al.png', 'Log_ROC.png', 'Logit_default_f7(p_removal).pdf', 'Active_learning.ipynb', 'Random_forest.ipynb', 'Model_select.ipynb', 'gdbc_git.png', '.git', '.vscode', 'Untitled', 'RF_f5e50_modelselect.pdf', 'Logit_default_f8(std_removal).pdf']\n",
            "\n",
            "---------------------------- FINISHED ---------------------------\n",
            "\n",
            "Count = 8, using model = GDBCModel, selection_function = MarginSamplingSelection, k = 50, iteration = 0.\n",
            "\n",
            "initial random chosen samples (50,)\n",
            "initial train set: (50, 10) (50,) unique(labels): [29 21] [0 1]\n",
            "Val set: (1252, 10) (1252,) (50,)\n",
            "\n",
            "Train set: (50, 10)\n",
            "Validation set: (1252, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.709 s \n",
            "\n",
            "Accuracy rate is 78.110599 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.90      0.86       321\n",
            "           1       0.61      0.45      0.52       113\n",
            "\n",
            "    accuracy                           0.78       434\n",
            "   macro avg       0.71      0.67      0.69       434\n",
            "weighted avg       0.77      0.78      0.77       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[288  33]\n",
            " [ 62  51]]\n",
            "--------------------------------\n",
            "val predicted: (1252,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1252, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "trainset before adding uncertain samples (50, 10) (50,)\n",
            "trainset after adding uncertain samples (100, 10) (100,)\n",
            "updated train set: (100, 10) (100,) unique(labels): [45 55] [0 1]\n",
            "val set: (1202, 10) (1202,)\n",
            "\n",
            "Train set: (100, 10)\n",
            "Validation set: (1202, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.780 s \n",
            "\n",
            "Accuracy rate is 78.110599 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.87      0.85       321\n",
            "           1       0.59      0.54      0.56       113\n",
            "\n",
            "    accuracy                           0.78       434\n",
            "   macro avg       0.71      0.70      0.71       434\n",
            "weighted avg       0.78      0.78      0.78       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[278  43]\n",
            " [ 52  61]]\n",
            "--------------------------------\n",
            "val predicted: (1202,) [0 1 1 ... 0 0 1]\n",
            "probabilities: (1202, 2) \n",
            " [0 1 1 ... 0 0 1]\n",
            "trainset before adding uncertain samples (100, 10) (100,)\n",
            "trainset after adding uncertain samples (150, 10) (150,)\n",
            "updated train set: (150, 10) (150,) unique(labels): [67 83] [0 1]\n",
            "val set: (1152, 10) (1152,)\n",
            "\n",
            "Train set: (150, 10)\n",
            "Validation set: (1152, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 3\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.875 s \n",
            "\n",
            "Accuracy rate is 78.571429 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.86      0.86       321\n",
            "           1       0.59      0.58      0.58       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.72      0.72      0.72       434\n",
            "weighted avg       0.78      0.79      0.78       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[276  45]\n",
            " [ 48  65]]\n",
            "--------------------------------\n",
            "val predicted: (1152,) [0 1 1 ... 0 0 1]\n",
            "probabilities: (1152, 2) \n",
            " [0 1 1 ... 0 0 1]\n",
            "trainset before adding uncertain samples (150, 10) (150,)\n",
            "trainset after adding uncertain samples (200, 10) (200,)\n",
            "updated train set: (200, 10) (200,) unique(labels): [ 88 112] [0 1]\n",
            "val set: (1102, 10) (1102,)\n",
            "\n",
            "Train set: (200, 10)\n",
            "Validation set: (1102, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 4\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.133 s \n",
            "\n",
            "Accuracy rate is 78.571429 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.85      0.85       321\n",
            "           1       0.58      0.61      0.60       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.72      0.73      0.73       434\n",
            "weighted avg       0.79      0.79      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[272  49]\n",
            " [ 44  69]]\n",
            "--------------------------------\n",
            "val predicted: (1102,) [0 1 1 ... 0 0 1]\n",
            "probabilities: (1102, 2) \n",
            " [0 1 1 ... 0 0 1]\n",
            "trainset before adding uncertain samples (200, 10) (200,)\n",
            "trainset after adding uncertain samples (250, 10) (250,)\n",
            "updated train set: (250, 10) (250,) unique(labels): [113 137] [0 1]\n",
            "val set: (1052, 10) (1052,)\n",
            "\n",
            "Train set: (250, 10)\n",
            "Validation set: (1052, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 5\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.003 s \n",
            "\n",
            "Accuracy rate is 80.414747 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.86      0.87       321\n",
            "           1       0.62      0.64      0.63       113\n",
            "\n",
            "    accuracy                           0.80       434\n",
            "   macro avg       0.75      0.75      0.75       434\n",
            "weighted avg       0.81      0.80      0.80       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[277  44]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "val predicted: (1052,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1052, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "trainset before adding uncertain samples (250, 10) (250,)\n",
            "trainset after adding uncertain samples (300, 10) (300,)\n",
            "updated train set: (300, 10) (300,) unique(labels): [144 156] [0 1]\n",
            "val set: (1002, 10) (1002,)\n",
            "\n",
            "Train set: (300, 10)\n",
            "Validation set: (1002, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 6\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.061 s \n",
            "\n",
            "Accuracy rate is 80.184332 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.87      0.87       321\n",
            "           1       0.62      0.60      0.61       113\n",
            "\n",
            "    accuracy                           0.80       434\n",
            "   macro avg       0.74      0.74      0.74       434\n",
            "weighted avg       0.80      0.80      0.80       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[280  41]\n",
            " [ 45  68]]\n",
            "--------------------------------\n",
            "val predicted: (1002,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1002, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "trainset before adding uncertain samples (300, 10) (300,)\n",
            "trainset after adding uncertain samples (350, 10) (350,)\n",
            "updated train set: (350, 10) (350,) unique(labels): [173 177] [0 1]\n",
            "val set: (952, 10) (952,)\n",
            "\n",
            "Train set: (350, 10)\n",
            "Validation set: (952, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 7\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.126 s \n",
            "\n",
            "Accuracy rate is 79.953917 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.87      0.86       321\n",
            "           1       0.62      0.61      0.61       113\n",
            "\n",
            "    accuracy                           0.80       434\n",
            "   macro avg       0.74      0.74      0.74       434\n",
            "weighted avg       0.80      0.80      0.80       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[278  43]\n",
            " [ 44  69]]\n",
            "--------------------------------\n",
            "val predicted: (952,) [0 1 1 0 0 1 0 0 1 1 0 0 0 0 1 1 0 0 0 0 1 1 1 1 0 1 1 0 0 1 1 0 0 0 1 1 0\n",
            " 0 0 1 0 1 1 1 1 0 0 1 1 1 1 1 0 1 1 0 1 1 1 0 0 1 1 1 1 1 0 1 1 0 1 0 1 1\n",
            " 0 0 0 1 0 0 1 1 1 1 0 0 0 1 1 1 0 0 0 0 0 1 1 0 1 0 1 0 1 1 1 0 1 0 0 1 0\n",
            " 0 1 0 0 0 0 1 0 0 1 0 1 1 0 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 1 0 1 0 1 1 0 1\n",
            " 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 0 0 1 0 0 0 0 0 1 1 1 0\n",
            " 1 0 0 0 0 1 1 0 1 1 0 0 0 1 0 1 1 0 1 1 0 1 1 0 0 0 0 0 0 1 1 1 1 1 1 1 1\n",
            " 1 1 1 0 0 1 1 0 1 0 1 1 1 1 0 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 1 1 0 0 1 1\n",
            " 0 1 1 0 0 0 0 1 1 1 1 1 0 0 0 1 0 1 1 0 0 1 0 1 0 1 0 1 0 0 0 0 0 0 0 1 1\n",
            " 1 1 1 1 1 1 1 0 1 1 0 1 0 1 0 0 0 1 1 0 0 1 0 1 1 0 1 1 1 0 0 1 1 1 0 1 0\n",
            " 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 0 0 0 1 0 1 0 1 1 0 1 1 1 0\n",
            " 1 0 1 1 1 1 0 1 1 0 1 0 1 0 1 1 1 1 1 0 1 1 1 1 0 1 1 0 0 0 0 1 1 0 0 1 0\n",
            " 1 0 0 1 0 0 0 0 0 0 1 0 1 1 1 1 0 0 1 0 1 0 1 1 0 0 0 1 0 0 0 1 1 1 1 1 1\n",
            " 1 0 0 0 1 1 0 1 1 0 0 1 0 0 1 0 0 0 0 0 1 1 0 0 1 0 1 1 1 0 1 0 0 1 1 1 1\n",
            " 0 0 1 1 1 1 1 0 1 1 0 0 1 1 0 0 0 1 0 1 1 0 0 1 1 0 1 0 1 0 1 0 0 0 0 0 1\n",
            " 0 1 0 1 0 1 1 0 1 1 0 1 1 0 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0 0 0 1 1 1 1\n",
            " 0 1 1 1 1 0 1 0 0 0 1 0 1 1 0 0 1 1 0 1 1 1 1 1 1 0 1 0 0 1 1 0 1 0 1 0 1\n",
            " 0 0 1 0 1 0 1 1 1 1 1 1 0 0 0 1 1 1 0 1 0 1 1 1 0 1 1 0 1 0 0 1 1 0 1 1 1\n",
            " 1 0 0 1 1 0 0 1 1 1 0 1 1 0 0 1 1 0 0 1 1 1 0 1 1 1 1 0 0 1 1 1 0 1 0 1 1\n",
            " 1 0 0 0 1 0 1 0 0 1 1 0 0 1 0 1 0 0 1 0 1 0 0 1 1 1 0 1 0 0 1 0 1 0 0 1 1\n",
            " 1 1 1 1 0 0 0 1 0 1 1 1 0 1 0 0 1 0 1 1 0 0 0 1 0 1 1 0 1 1 0 0 1 0 0 1 0\n",
            " 1 1 1 0 0 0 1 0 0 1 1 0 1 1 0 1 0 0 1 0 1 1 0 0 0 1 0 0 1 0 1 1 1 1 0 1 0\n",
            " 0 1 0 0 0 0 1 1 0 1 1 1 1 1 1 1 1 0 1 0 1 0 1 1 1 1 1 1 1 0 0 0 0 1 0 0 1\n",
            " 0 1 1 1 0 1 0 1 0 0 0 0 0 1 0 1 0 1 0 1 1 1 0 0 1 0 1 1 1 0 0 1 0 1 1 1 1\n",
            " 0 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1\n",
            " 0 0 1 0 1 1 0 1 0 0 0 1 0 0 1 1 1 0 1 0 1 1 1 1 1 1 0 1 0 1 0 0 1 1 1 0 1\n",
            " 0 0 0 1 1 1 1 1 0 1 0 1 1 0 0 1 1 0 0 1 0 1 1 1 1 0 0]\n",
            "probabilities: (952, 2) \n",
            " [0 1 1 0 0 1 0 0 1 1 0 0 0 0 1 1 0 0 0 0 1 1 1 1 0 1 1 0 0 1 1 0 0 0 1 1 0\n",
            " 0 0 1 0 1 1 1 1 0 0 1 1 1 1 1 0 1 1 0 1 1 1 0 0 1 1 1 1 1 0 1 1 0 1 0 1 1\n",
            " 0 0 0 1 0 0 1 1 1 1 0 0 0 1 1 1 0 0 0 0 0 1 1 0 1 0 1 0 1 1 1 0 1 0 0 1 0\n",
            " 0 1 0 0 0 0 1 0 0 1 0 1 1 0 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 1 0 1 0 1 1 0 1\n",
            " 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 0 0 1 0 0 0 0 0 1 1 1 0\n",
            " 1 0 0 0 0 1 1 0 1 1 0 0 0 1 0 1 1 0 1 1 0 1 1 0 0 0 0 0 0 1 1 1 1 1 1 1 1\n",
            " 1 1 1 0 0 1 1 0 1 0 1 1 1 1 0 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 1 1 0 0 1 1\n",
            " 0 1 1 0 0 0 0 1 1 1 1 1 0 0 0 1 0 1 1 0 0 1 0 1 0 1 0 1 0 0 0 0 0 0 0 1 1\n",
            " 1 1 1 1 1 1 1 0 1 1 0 1 0 1 0 0 0 1 1 0 0 1 0 1 1 0 1 1 1 0 0 1 1 1 0 1 0\n",
            " 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 0 0 0 1 0 1 0 1 1 0 1 1 1 0\n",
            " 1 0 1 1 1 1 0 1 1 0 1 0 1 0 1 1 1 1 1 0 1 1 1 1 0 1 1 0 0 0 0 1 1 0 0 1 0\n",
            " 1 0 0 1 0 0 0 0 0 0 1 0 1 1 1 1 0 0 1 0 1 0 1 1 0 0 0 1 0 0 0 1 1 1 1 1 1\n",
            " 1 0 0 0 1 1 0 1 1 0 0 1 0 0 1 0 0 0 0 0 1 1 0 0 1 0 1 1 1 0 1 0 0 1 1 1 1\n",
            " 0 0 1 1 1 1 1 0 1 1 0 0 1 1 0 0 0 1 0 1 1 0 0 1 1 0 1 0 1 0 1 0 0 0 0 0 1\n",
            " 0 1 0 1 0 1 1 0 1 1 0 1 1 0 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0 0 0 1 1 1 1\n",
            " 0 1 1 1 1 0 1 0 0 0 1 0 1 1 0 0 1 1 0 1 1 1 1 1 1 0 1 0 0 1 1 0 1 0 1 0 1\n",
            " 0 0 1 0 1 0 1 1 1 1 1 1 0 0 0 1 1 1 0 1 0 1 1 1 0 1 1 0 1 0 0 1 1 0 1 1 1\n",
            " 1 0 0 1 1 0 0 1 1 1 0 1 1 0 0 1 1 0 0 1 1 1 0 1 1 1 1 0 0 1 1 1 0 1 0 1 1\n",
            " 1 0 0 0 1 0 1 0 0 1 1 0 0 1 0 1 0 0 1 0 1 0 0 1 1 1 0 1 0 0 1 0 1 0 0 1 1\n",
            " 1 1 1 1 0 0 0 1 0 1 1 1 0 1 0 0 1 0 1 1 0 0 0 1 0 1 1 0 1 1 0 0 1 0 0 1 0\n",
            " 1 1 1 0 0 0 1 0 0 1 1 0 1 1 0 1 0 0 1 0 1 1 0 0 0 1 0 0 1 0 1 1 1 1 0 1 0\n",
            " 0 1 0 0 0 0 1 1 0 1 1 1 1 1 1 1 1 0 1 0 1 0 1 1 1 1 1 1 1 0 0 0 0 1 0 0 1\n",
            " 0 1 1 1 0 1 0 1 0 0 0 0 0 1 0 1 0 1 0 1 1 1 0 0 1 0 1 1 1 0 0 1 0 1 1 1 1\n",
            " 0 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1\n",
            " 0 0 1 0 1 1 0 1 0 0 0 1 0 0 1 1 1 0 1 0 1 1 1 1 1 1 0 1 0 1 0 0 1 1 1 0 1\n",
            " 0 0 0 1 1 1 1 1 0 1 0 1 1 0 0 1 1 0 0 1 0 1 1 1 1 0 0]\n",
            "trainset before adding uncertain samples (350, 10) (350,)\n",
            "trainset after adding uncertain samples (400, 10) (400,)\n",
            "updated train set: (400, 10) (400,) unique(labels): [203 197] [0 1]\n",
            "val set: (902, 10) (902,)\n",
            "\n",
            "Train set: (400, 10)\n",
            "Validation set: (902, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 8\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.189 s \n",
            "\n",
            "Accuracy rate is 79.723502 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.86      0.86       321\n",
            "           1       0.61      0.61      0.61       113\n",
            "\n",
            "    accuracy                           0.80       434\n",
            "   macro avg       0.74      0.74      0.74       434\n",
            "weighted avg       0.80      0.80      0.80       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[277  44]\n",
            " [ 44  69]]\n",
            "--------------------------------\n",
            "val predicted: (902,) [1 1 0 1 0 1 1 0 0 0 0 1 1 0 0 0 0 1 1 1 1 0 1 1 0 1 1 0 0 1 0 0 0 1 0 1 1\n",
            " 1 1 0 0 1 1 1 1 1 0 1 1 0 1 1 0 0 1 1 1 1 0 1 1 1 0 1 1 0 0 0 1 0 0 1 1 1\n",
            " 1 0 0 0 1 1 1 0 0 0 1 1 0 1 0 1 0 1 1 1 0 1 0 0 1 0 0 1 0 0 0 0 1 0 0 1 0\n",
            " 1 1 0 1 1 0 1 0 1 1 1 1 1 1 0 1 1 1 0 0 1 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1 1\n",
            " 1 0 1 0 0 1 1 1 1 1 0 0 1 0 0 0 0 0 1 1 1 0 1 0 0 0 0 1 1 0 1 0 0 0 1 0 1\n",
            " 1 0 1 1 0 1 1 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 0 1 1\n",
            " 1 1 0 1 1 0 1 1 0 1 1 1 1 1 1 1 0 0 1 1 0 1 1 0 0 0 0 1 1 1 1 1 0 0 1 0 1\n",
            " 1 0 0 1 0 1 0 1 0 1 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 1 1 0 1 0 1 0 0 0 1 1\n",
            " 0 1 0 1 1 0 1 1 1 0 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1\n",
            " 0 0 0 1 0 1 0 1 1 0 1 1 1 0 1 0 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 0 1 1 1 1\n",
            " 1 1 0 0 0 0 1 1 0 1 0 1 0 0 1 0 0 0 0 1 0 1 1 1 1 0 1 0 1 0 1 1 0 0 0 1 0\n",
            " 0 0 1 1 1 1 1 1 1 0 0 0 1 1 0 1 1 0 0 1 0 0 1 0 0 0 0 0 1 1 0 0 0 1 1 1 0\n",
            " 1 0 0 1 1 1 1 0 1 1 1 1 1 0 1 1 0 0 1 1 0 0 0 1 0 1 1 0 0 1 1 0 1 0 1 0 1\n",
            " 0 0 0 0 1 0 1 0 1 0 1 1 0 1 1 0 1 1 0 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0 0\n",
            " 0 1 1 1 1 0 1 1 1 1 0 1 0 0 0 1 0 1 1 0 0 1 1 0 1 1 1 1 1 1 0 1 0 0 1 1 0\n",
            " 1 0 1 0 0 0 1 1 0 1 1 1 1 1 1 0 0 0 1 1 1 0 1 0 1 1 1 0 1 1 0 1 0 0 1 1 0\n",
            " 1 1 1 1 0 0 1 1 0 0 1 1 1 0 1 1 0 0 1 1 0 0 1 1 1 1 1 1 1 0 0 1 1 1 1 0 1\n",
            " 1 0 0 1 0 1 0 0 1 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 1 0 0 1 0 1 0 0 1 1 1 1 1\n",
            " 1 0 0 1 0 1 1 1 1 0 0 1 0 1 1 0 0 0 1 0 1 1 0 1 0 1 0 0 1 0 1 1 1 0 0 0 1\n",
            " 0 0 1 1 0 1 1 0 1 0 0 1 0 1 1 0 0 0 1 0 0 1 0 1 1 1 1 0 1 0 0 1 0 0 0 0 1\n",
            " 1 0 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 0 0 0 1 0 0 1 0 1 1 1 0 1 0 1 0 0\n",
            " 0 0 0 1 0 1 0 1 0 1 1 1 0 0 1 0 1 1 1 0 0 1 0 1 1 1 1 0 1 1 1 0 0 1 1 1 1\n",
            " 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 0 1 0 1 1 1 0 0 0 1\n",
            " 0 0 1 1 1 0 1 0 1 1 1 1 1 1 0 1 0 1 0 0 1 1 1 0 1 0 0 0 1 1 1 1 1 0 1 0 1\n",
            " 1 0 0 1 1 0 0 1 0 1 1 1 0 0]\n",
            "probabilities: (902, 2) \n",
            " [1 1 0 1 0 1 1 0 0 0 0 1 1 0 0 0 0 1 1 1 1 0 1 1 0 1 1 0 0 1 0 0 0 1 0 1 1\n",
            " 1 1 0 0 1 1 1 1 1 0 1 1 0 1 1 0 0 1 1 1 1 0 1 1 1 0 1 1 0 0 0 1 0 0 1 1 1\n",
            " 1 0 0 0 1 1 1 0 0 0 1 1 0 1 0 1 0 1 1 1 0 1 0 0 1 0 0 1 0 0 0 0 1 0 0 1 0\n",
            " 1 1 0 1 1 0 1 0 1 1 1 1 1 1 0 1 1 1 0 0 1 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1 1\n",
            " 1 0 1 0 0 1 1 1 1 1 0 0 1 0 0 0 0 0 1 1 1 0 1 0 0 0 0 1 1 0 1 0 0 0 1 0 1\n",
            " 1 0 1 1 0 1 1 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 0 1 1\n",
            " 1 1 0 1 1 0 1 1 0 1 1 1 1 1 1 1 0 0 1 1 0 1 1 0 0 0 0 1 1 1 1 1 0 0 1 0 1\n",
            " 1 0 0 1 0 1 0 1 0 1 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 1 1 0 1 0 1 0 0 0 1 1\n",
            " 0 1 0 1 1 0 1 1 1 0 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1\n",
            " 0 0 0 1 0 1 0 1 1 0 1 1 1 0 1 0 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 0 1 1 1 1\n",
            " 1 1 0 0 0 0 1 1 0 1 0 1 0 0 1 0 0 0 0 1 0 1 1 1 1 0 1 0 1 0 1 1 0 0 0 1 0\n",
            " 0 0 1 1 1 1 1 1 1 0 0 0 1 1 0 1 1 0 0 1 0 0 1 0 0 0 0 0 1 1 0 0 0 1 1 1 0\n",
            " 1 0 0 1 1 1 1 0 1 1 1 1 1 0 1 1 0 0 1 1 0 0 0 1 0 1 1 0 0 1 1 0 1 0 1 0 1\n",
            " 0 0 0 0 1 0 1 0 1 0 1 1 0 1 1 0 1 1 0 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0 0\n",
            " 0 1 1 1 1 0 1 1 1 1 0 1 0 0 0 1 0 1 1 0 0 1 1 0 1 1 1 1 1 1 0 1 0 0 1 1 0\n",
            " 1 0 1 0 0 0 1 1 0 1 1 1 1 1 1 0 0 0 1 1 1 0 1 0 1 1 1 0 1 1 0 1 0 0 1 1 0\n",
            " 1 1 1 1 0 0 1 1 0 0 1 1 1 0 1 1 0 0 1 1 0 0 1 1 1 1 1 1 1 0 0 1 1 1 1 0 1\n",
            " 1 0 0 1 0 1 0 0 1 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 1 0 0 1 0 1 0 0 1 1 1 1 1\n",
            " 1 0 0 1 0 1 1 1 1 0 0 1 0 1 1 0 0 0 1 0 1 1 0 1 0 1 0 0 1 0 1 1 1 0 0 0 1\n",
            " 0 0 1 1 0 1 1 0 1 0 0 1 0 1 1 0 0 0 1 0 0 1 0 1 1 1 1 0 1 0 0 1 0 0 0 0 1\n",
            " 1 0 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 0 0 0 1 0 0 1 0 1 1 1 0 1 0 1 0 0\n",
            " 0 0 0 1 0 1 0 1 0 1 1 1 0 0 1 0 1 1 1 0 0 1 0 1 1 1 1 0 1 1 1 0 0 1 1 1 1\n",
            " 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 0 1 0 1 1 1 0 0 0 1\n",
            " 0 0 1 1 1 0 1 0 1 1 1 1 1 1 0 1 0 1 0 0 1 1 1 0 1 0 0 0 1 1 1 1 1 0 1 0 1\n",
            " 1 0 0 1 1 0 0 1 0 1 1 1 0 0]\n",
            "trainset before adding uncertain samples (400, 10) (400,)\n",
            "trainset after adding uncertain samples (450, 10) (450,)\n",
            "updated train set: (450, 10) (450,) unique(labels): [225 225] [0 1]\n",
            "val set: (852, 10) (852,)\n",
            "\n",
            "Train set: (450, 10)\n",
            "Validation set: (852, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 9\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.244 s \n",
            "\n",
            "Accuracy rate is 79.493088 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.86      0.86       321\n",
            "           1       0.61      0.60      0.60       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.73      0.73      0.73       434\n",
            "weighted avg       0.79      0.79      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[277  44]\n",
            " [ 45  68]]\n",
            "--------------------------------\n",
            "val predicted: (852,) [1 1 0 1 0 1 1 0 0 0 1 1 0 0 0 0 1 1 1 1 0 1 1 0 1 1 0 0 1 0 0 0 1 0 1 1 1\n",
            " 0 0 1 1 1 1 1 0 1 0 1 1 0 0 1 1 1 1 0 1 1 1 0 1 1 0 0 0 1 0 0 1 1 1 1 0 0\n",
            " 0 1 1 1 0 0 0 1 1 0 1 0 1 0 1 1 1 0 1 0 1 0 0 1 0 0 0 1 0 0 1 0 1 0 1 1 0\n",
            " 1 0 1 1 1 1 1 1 0 1 1 1 0 0 1 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 0 1 0 0 1\n",
            " 1 1 1 1 0 0 0 0 0 0 0 1 1 1 0 1 0 0 0 0 1 0 1 0 0 0 1 0 1 1 0 1 1 0 1 1 0\n",
            " 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 0 1 1 1 1 0 1 1 0 1 0\n",
            " 1 1 1 1 1 1 0 0 1 1 0 1 1 0 0 0 1 1 1 1 1 0 0 0 1 1 0 0 1 0 1 0 1 0 1 0 0\n",
            " 0 0 0 0 0 1 1 1 1 1 1 1 1 0 1 1 0 1 0 1 0 0 0 1 0 1 0 1 1 0 1 1 0 0 1 1 1\n",
            " 0 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 0 0 1 0 1 0 1 1 0 1 1 1 0 1 0 1 1 1\n",
            " 1 0 1 1 0 1 1 0 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 1 1 0 1 1 0 0 1 0 0 0 0 1 1\n",
            " 1 1 0 1 0 1 0 1 1 0 0 0 1 0 0 0 1 1 1 1 1 1 0 0 0 1 1 0 1 0 1 0 0 1 0 0 0\n",
            " 0 0 1 1 0 0 0 1 1 1 0 1 0 0 1 1 1 1 0 1 1 1 1 1 1 1 0 0 1 1 0 0 0 1 0 1 1\n",
            " 0 0 1 0 1 0 1 0 1 0 0 0 0 1 0 1 0 1 0 1 1 0 1 0 1 1 0 1 1 0 1 1 1 0 1 1 1\n",
            " 1 1 1 1 0 0 0 0 1 1 1 1 0 1 1 1 1 0 1 0 0 0 0 1 0 0 1 1 0 1 1 1 1 1 0 1 0\n",
            " 0 1 1 0 1 0 1 0 0 1 1 0 1 1 1 1 0 0 0 1 1 1 0 1 1 1 1 0 1 1 0 1 0 0 1 1 0\n",
            " 1 1 1 1 0 0 1 1 0 0 1 1 1 0 1 0 0 1 0 0 1 1 1 1 1 1 1 0 0 1 1 1 1 0 1 1 0\n",
            " 0 1 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 1 0 0 1 0 1 0 0 1 1 1 1 1 1 0 0\n",
            " 1 0 1 1 1 1 0 0 1 0 1 0 0 0 1 0 1 1 0 1 0 1 0 0 1 0 1 1 1 0 0 0 1 0 0 1 1\n",
            " 0 1 1 0 1 0 0 1 0 1 1 0 0 0 1 0 0 1 0 1 1 1 1 0 1 0 0 1 0 0 0 0 1 1 0 1 1\n",
            " 1 1 1 1 0 1 1 0 1 1 1 1 1 0 0 1 0 0 1 0 1 1 1 0 1 0 1 0 0 0 0 0 1 0 1 0 1\n",
            " 0 1 1 1 0 0 1 1 1 1 0 0 1 0 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 0 1 0 1 1 1 0 0 0 1 0 0 1 1 0 1 0 1 1 1 1\n",
            " 1 1 0 1 0 1 0 0 1 1 1 0 0 0 0 1 1 1 1 1 0 1 0 1 1 0 0 1 1 0 0 1 0 1 1 1 0\n",
            " 0]\n",
            "probabilities: (852, 2) \n",
            " [1 1 0 1 0 1 1 0 0 0 1 1 0 0 0 0 1 1 1 1 0 1 1 0 1 1 0 0 1 0 0 0 1 0 1 1 1\n",
            " 0 0 1 1 1 1 1 0 1 0 1 1 0 0 1 1 1 1 0 1 1 1 0 1 1 0 0 0 1 0 0 1 1 1 1 0 0\n",
            " 0 1 1 1 0 0 0 1 1 0 1 0 1 0 1 1 1 0 1 0 1 0 0 1 0 0 0 1 0 0 1 0 1 0 1 1 0\n",
            " 1 0 1 1 1 1 1 1 0 1 1 1 0 0 1 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 0 1 0 0 1\n",
            " 1 1 1 1 0 0 0 0 0 0 0 1 1 1 0 1 0 0 0 0 1 0 1 0 0 0 1 0 1 1 0 1 1 0 1 1 0\n",
            " 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 0 1 1 1 1 0 1 1 0 1 0\n",
            " 1 1 1 1 1 1 0 0 1 1 0 1 1 0 0 0 1 1 1 1 1 0 0 0 1 1 0 0 1 0 1 0 1 0 1 0 0\n",
            " 0 0 0 0 0 1 1 1 1 1 1 1 1 0 1 1 0 1 0 1 0 0 0 1 0 1 0 1 1 0 1 1 0 0 1 1 1\n",
            " 0 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 0 0 1 0 1 0 1 1 0 1 1 1 0 1 0 1 1 1\n",
            " 1 0 1 1 0 1 1 0 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 1 1 0 1 1 0 0 1 0 0 0 0 1 1\n",
            " 1 1 0 1 0 1 0 1 1 0 0 0 1 0 0 0 1 1 1 1 1 1 0 0 0 1 1 0 1 0 1 0 0 1 0 0 0\n",
            " 0 0 1 1 0 0 0 1 1 1 0 1 0 0 1 1 1 1 0 1 1 1 1 1 1 1 0 0 1 1 0 0 0 1 0 1 1\n",
            " 0 0 1 0 1 0 1 0 1 0 0 0 0 1 0 1 0 1 0 1 1 0 1 0 1 1 0 1 1 0 1 1 1 0 1 1 1\n",
            " 1 1 1 1 0 0 0 0 1 1 1 1 0 1 1 1 1 0 1 0 0 0 0 1 0 0 1 1 0 1 1 1 1 1 0 1 0\n",
            " 0 1 1 0 1 0 1 0 0 1 1 0 1 1 1 1 0 0 0 1 1 1 0 1 1 1 1 0 1 1 0 1 0 0 1 1 0\n",
            " 1 1 1 1 0 0 1 1 0 0 1 1 1 0 1 0 0 1 0 0 1 1 1 1 1 1 1 0 0 1 1 1 1 0 1 1 0\n",
            " 0 1 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 1 0 0 1 0 1 0 0 1 1 1 1 1 1 0 0\n",
            " 1 0 1 1 1 1 0 0 1 0 1 0 0 0 1 0 1 1 0 1 0 1 0 0 1 0 1 1 1 0 0 0 1 0 0 1 1\n",
            " 0 1 1 0 1 0 0 1 0 1 1 0 0 0 1 0 0 1 0 1 1 1 1 0 1 0 0 1 0 0 0 0 1 1 0 1 1\n",
            " 1 1 1 1 0 1 1 0 1 1 1 1 1 0 0 1 0 0 1 0 1 1 1 0 1 0 1 0 0 0 0 0 1 0 1 0 1\n",
            " 0 1 1 1 0 0 1 1 1 1 0 0 1 0 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 0 1 0 1 1 1 0 0 0 1 0 0 1 1 0 1 0 1 1 1 1\n",
            " 1 1 0 1 0 1 0 0 1 1 1 0 0 0 0 1 1 1 1 1 0 1 0 1 1 0 0 1 1 0 0 1 0 1 1 1 0\n",
            " 0]\n",
            "trainset before adding uncertain samples (450, 10) (450,)\n",
            "trainset after adding uncertain samples (500, 10) (500,)\n",
            "updated train set: (500, 10) (500,) unique(labels): [251 249] [0 1]\n",
            "val set: (802, 10) (802,)\n",
            "\n",
            "Train set: (500, 10)\n",
            "Validation set: (802, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 10\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.303 s \n",
            "\n",
            "Accuracy rate is 78.801843 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.86      0.86       321\n",
            "           1       0.59      0.59      0.59       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.72      0.72      0.72       434\n",
            "weighted avg       0.79      0.79      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[275  46]\n",
            " [ 46  67]]\n",
            "--------------------------------\n",
            "final active learning accuracies [78.11059907834101, 78.11059907834101, 78.57142857142857, 78.57142857142857, 80.4147465437788, 80.18433179723502, 79.95391705069125, 79.72350230414746, 79.49308755760369, 78.80184331797236]\n",
            "saved /Users/wenxuanhuang/Documents/Repo/ML-for-COVID-19-dataset/Results/Active-learning-experiment-8.pkl /Users/wenxuanhuang/Documents/Repo/ML-for-COVID-19-dataset ['Decision_tree.ipynb', 'dec_git.png', 'Logit_default_f10.pdf', 'Logistic.ipynb', 'SVC.ipynb', 'RF_f5e50_featureimp.pdf', 'log_al.png', 'dec_git.pdf', '.DS_Store', 'log_git.png', 'svm_git.png', 'Logistic_Scikit.ipynb', 'knn_git.pdf', 'knn_git.png', 'rf_al.png', 'Best classifier_RF_f5e50.pdf', 'KNN.ipynb', 'GBDC.ipynb', 'rf_git.png', 'README.md', 'all_training.csv', 'Results', 'svm_al.png', 'Log_ROC.png', 'Logit_default_f7(p_removal).pdf', 'Active_learning.ipynb', 'Random_forest.ipynb', 'Model_select.ipynb', 'gdbc_git.png', '.git', '.vscode', 'Untitled', 'RF_f5e50_modelselect.pdf', 'Logit_default_f8(std_removal).pdf']\n",
            "\n",
            "---------------------------- FINISHED ---------------------------\n",
            "\n",
            "Count = 9, using model = GDBCModel, selection_function = MarginSamplingSelection, k = 25, iteration = 0.\n",
            "\n",
            "initial random chosen samples (25,)\n",
            "initial train set: (25, 10) (25,) unique(labels): [ 9 16] [0 1]\n",
            "Val set: (1277, 10) (1277,) (25,)\n",
            "\n",
            "Train set: (25, 10)\n",
            "Validation set: (1277, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.666 s \n",
            "\n",
            "Accuracy rate is 74.654378 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.79      0.82       321\n",
            "           1       0.51      0.62      0.56       113\n",
            "\n",
            "    accuracy                           0.75       434\n",
            "   macro avg       0.68      0.71      0.69       434\n",
            "weighted avg       0.77      0.75      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[254  67]\n",
            " [ 43  70]]\n",
            "--------------------------------\n",
            "val predicted: (1277,) [1 1 1 ... 0 0 1]\n",
            "probabilities: (1277, 2) \n",
            " [1 1 1 ... 0 0 1]\n",
            "trainset before adding uncertain samples (25, 10) (25,)\n",
            "trainset after adding uncertain samples (50, 10) (50,)\n",
            "updated train set: (50, 10) (50,) unique(labels): [22 28] [0 1]\n",
            "val set: (1252, 10) (1252,)\n",
            "\n",
            "Train set: (50, 10)\n",
            "Validation set: (1252, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.718 s \n",
            "\n",
            "Accuracy rate is 69.815668 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.72      0.78       321\n",
            "           1       0.44      0.63      0.52       113\n",
            "\n",
            "    accuracy                           0.70       434\n",
            "   macro avg       0.65      0.68      0.65       434\n",
            "weighted avg       0.74      0.70      0.71       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[232  89]\n",
            " [ 42  71]]\n",
            "--------------------------------\n",
            "val predicted: (1252,) [1 0 1 ... 0 0 1]\n",
            "probabilities: (1252, 2) \n",
            " [1 0 1 ... 0 0 1]\n",
            "trainset before adding uncertain samples (50, 10) (50,)\n",
            "trainset after adding uncertain samples (75, 10) (75,)\n",
            "updated train set: (75, 10) (75,) unique(labels): [37 38] [0 1]\n",
            "val set: (1227, 10) (1227,)\n",
            "\n",
            "Train set: (75, 10)\n",
            "Validation set: (1227, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 3\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.752 s \n",
            "\n",
            "Accuracy rate is 80.184332 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.87      0.87       321\n",
            "           1       0.62      0.61      0.62       113\n",
            "\n",
            "    accuracy                           0.80       434\n",
            "   macro avg       0.74      0.74      0.74       434\n",
            "weighted avg       0.80      0.80      0.80       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[279  42]\n",
            " [ 44  69]]\n",
            "--------------------------------\n",
            "val predicted: (1227,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1227, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "trainset before adding uncertain samples (75, 10) (75,)\n",
            "trainset after adding uncertain samples (100, 10) (100,)\n",
            "updated train set: (100, 10) (100,) unique(labels): [43 57] [0 1]\n",
            "val set: (1202, 10) (1202,)\n",
            "\n",
            "Train set: (100, 10)\n",
            "Validation set: (1202, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 4\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.825 s \n",
            "\n",
            "Accuracy rate is 72.119816 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.73      0.79       321\n",
            "           1       0.48      0.71      0.57       113\n",
            "\n",
            "    accuracy                           0.72       434\n",
            "   macro avg       0.68      0.72      0.68       434\n",
            "weighted avg       0.77      0.72      0.74       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[233  88]\n",
            " [ 33  80]]\n",
            "--------------------------------\n",
            "val predicted: (1202,) [1 1 0 ... 0 0 0]\n",
            "probabilities: (1202, 2) \n",
            " [1 1 0 ... 0 0 0]\n",
            "trainset before adding uncertain samples (100, 10) (100,)\n",
            "trainset after adding uncertain samples (125, 10) (125,)\n",
            "updated train set: (125, 10) (125,) unique(labels): [57 68] [0 1]\n",
            "val set: (1177, 10) (1177,)\n",
            "\n",
            "Train set: (125, 10)\n",
            "Validation set: (1177, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 5\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.821 s \n",
            "\n",
            "Accuracy rate is 72.811060 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.75      0.80       321\n",
            "           1       0.48      0.67      0.56       113\n",
            "\n",
            "    accuracy                           0.73       434\n",
            "   macro avg       0.68      0.71      0.68       434\n",
            "weighted avg       0.77      0.73      0.74       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[240  81]\n",
            " [ 37  76]]\n",
            "--------------------------------\n",
            "val predicted: (1177,) [1 1 0 ... 0 0 0]\n",
            "probabilities: (1177, 2) \n",
            " [1 1 0 ... 0 0 0]\n",
            "trainset before adding uncertain samples (125, 10) (125,)\n",
            "trainset after adding uncertain samples (150, 10) (150,)\n",
            "updated train set: (150, 10) (150,) unique(labels): [71 79] [0 1]\n",
            "val set: (1152, 10) (1152,)\n",
            "\n",
            "Train set: (150, 10)\n",
            "Validation set: (1152, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 6\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.857 s \n",
            "\n",
            "Accuracy rate is 73.732719 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.78      0.81       321\n",
            "           1       0.50      0.63      0.55       113\n",
            "\n",
            "    accuracy                           0.74       434\n",
            "   macro avg       0.68      0.70      0.68       434\n",
            "weighted avg       0.76      0.74      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[249  72]\n",
            " [ 42  71]]\n",
            "--------------------------------\n",
            "val predicted: (1152,) [1 1 0 ... 0 0 0]\n",
            "probabilities: (1152, 2) \n",
            " [1 1 0 ... 0 0 0]\n",
            "trainset before adding uncertain samples (150, 10) (150,)\n",
            "trainset after adding uncertain samples (175, 10) (175,)\n",
            "updated train set: (175, 10) (175,) unique(labels): [83 92] [0 1]\n",
            "val set: (1127, 10) (1127,)\n",
            "\n",
            "Train set: (175, 10)\n",
            "Validation set: (1127, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 7\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.893 s \n",
            "\n",
            "Accuracy rate is 73.502304 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.78      0.81       321\n",
            "           1       0.49      0.61      0.55       113\n",
            "\n",
            "    accuracy                           0.74       434\n",
            "   macro avg       0.67      0.69      0.68       434\n",
            "weighted avg       0.76      0.74      0.74       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[250  71]\n",
            " [ 44  69]]\n",
            "--------------------------------\n",
            "val predicted: (1127,) [1 1 0 ... 0 0 0]\n",
            "probabilities: (1127, 2) \n",
            " [1 1 0 ... 0 0 0]\n",
            "trainset before adding uncertain samples (175, 10) (175,)\n",
            "trainset after adding uncertain samples (200, 10) (200,)\n",
            "updated train set: (200, 10) (200,) unique(labels): [100 100] [0 1]\n",
            "val set: (1102, 10) (1102,)\n",
            "\n",
            "Train set: (200, 10)\n",
            "Validation set: (1102, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 8\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.922 s \n",
            "\n",
            "Accuracy rate is 78.571429 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.85      0.85       321\n",
            "           1       0.59      0.59      0.59       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.72      0.72      0.72       434\n",
            "weighted avg       0.79      0.79      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[274  47]\n",
            " [ 46  67]]\n",
            "--------------------------------\n",
            "val predicted: (1102,) [1 1 0 ... 0 0 0]\n",
            "probabilities: (1102, 2) \n",
            " [1 1 0 ... 0 0 0]\n",
            "trainset before adding uncertain samples (200, 10) (200,)\n",
            "trainset after adding uncertain samples (225, 10) (225,)\n",
            "updated train set: (225, 10) (225,) unique(labels): [119 106] [0 1]\n",
            "val set: (1077, 10) (1077,)\n",
            "\n",
            "Train set: (225, 10)\n",
            "Validation set: (1077, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 9\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.965 s \n",
            "\n",
            "Accuracy rate is 78.571429 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.86      0.86       321\n",
            "           1       0.59      0.58      0.58       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.72      0.72      0.72       434\n",
            "weighted avg       0.78      0.79      0.78       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[276  45]\n",
            " [ 48  65]]\n",
            "--------------------------------\n",
            "val predicted: (1077,) [1 1 0 ... 0 0 0]\n",
            "probabilities: (1077, 2) \n",
            " [1 1 0 ... 0 0 0]\n",
            "trainset before adding uncertain samples (225, 10) (225,)\n",
            "trainset after adding uncertain samples (250, 10) (250,)\n",
            "updated train set: (250, 10) (250,) unique(labels): [131 119] [0 1]\n",
            "val set: (1052, 10) (1052,)\n",
            "\n",
            "Train set: (250, 10)\n",
            "Validation set: (1052, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 10\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.997 s \n",
            "\n",
            "Accuracy rate is 81.105991 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.87      0.87       321\n",
            "           1       0.64      0.64      0.64       113\n",
            "\n",
            "    accuracy                           0.81       434\n",
            "   macro avg       0.75      0.75      0.75       434\n",
            "weighted avg       0.81      0.81      0.81       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[280  41]\n",
            " [ 41  72]]\n",
            "--------------------------------\n",
            "val predicted: (1052,) [1 1 0 ... 0 0 0]\n",
            "probabilities: (1052, 2) \n",
            " [1 1 0 ... 0 0 0]\n",
            "trainset before adding uncertain samples (250, 10) (250,)\n",
            "trainset after adding uncertain samples (275, 10) (275,)\n",
            "updated train set: (275, 10) (275,) unique(labels): [144 131] [0 1]\n",
            "val set: (1027, 10) (1027,)\n",
            "\n",
            "Train set: (275, 10)\n",
            "Validation set: (1027, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 11\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.027 s \n",
            "\n",
            "Accuracy rate is 80.645161 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.88      0.87       321\n",
            "           1       0.64      0.59      0.61       113\n",
            "\n",
            "    accuracy                           0.81       434\n",
            "   macro avg       0.75      0.74      0.74       434\n",
            "weighted avg       0.80      0.81      0.80       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[283  38]\n",
            " [ 46  67]]\n",
            "--------------------------------\n",
            "val predicted: (1027,) [1 1 0 ... 0 0 0]\n",
            "probabilities: (1027, 2) \n",
            " [1 1 0 ... 0 0 0]\n",
            "trainset before adding uncertain samples (275, 10) (275,)\n",
            "trainset after adding uncertain samples (300, 10) (300,)\n",
            "updated train set: (300, 10) (300,) unique(labels): [155 145] [0 1]\n",
            "val set: (1002, 10) (1002,)\n",
            "\n",
            "Train set: (300, 10)\n",
            "Validation set: (1002, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 12\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.061 s \n",
            "\n",
            "Accuracy rate is 78.801843 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.86      0.86       321\n",
            "           1       0.60      0.58      0.59       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.72      0.72      0.72       434\n",
            "weighted avg       0.79      0.79      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[277  44]\n",
            " [ 48  65]]\n",
            "--------------------------------\n",
            "val predicted: (1002,) [1 1 0 ... 0 0 0]\n",
            "probabilities: (1002, 2) \n",
            " [1 1 0 ... 0 0 0]\n",
            "trainset before adding uncertain samples (300, 10) (300,)\n",
            "trainset after adding uncertain samples (325, 10) (325,)\n",
            "updated train set: (325, 10) (325,) unique(labels): [166 159] [0 1]\n",
            "val set: (977, 10) (977,)\n",
            "\n",
            "Train set: (325, 10)\n",
            "Validation set: (977, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 13\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.094 s \n",
            "\n",
            "Accuracy rate is 79.262673 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.86      0.86       321\n",
            "           1       0.60      0.59      0.60       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.73      0.73      0.73       434\n",
            "weighted avg       0.79      0.79      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[277  44]\n",
            " [ 46  67]]\n",
            "--------------------------------\n",
            "val predicted: (977,) [1 1 0 0 1 0 1 1 0 0 0 0 1 1 1 0 1 0 1 0 0 0 0 1 1 0 1 1 0 1 0 0 0 0 1 1 0\n",
            " 0 0 1 1 0 1 1 1 1 0 0 1 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 1 0 1 0 1 0 1 0 0\n",
            " 0 0 1 0 0 1 1 1 1 1 0 1 0 0 1 1 0 0 0 0 0 0 1 1 0 0 1 0 0 1 1 1 1 0 1 0 1\n",
            " 0 0 1 0 0 0 0 0 1 0 0 1 1 0 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 1 1 0 0 1 1 0\n",
            " 1 1 1 0 0 1 0 0 0 0 1 0 1 1 1 0 1 1 0 1 0 0 1 1 0 1 1 1 0 0 0 1 0 0 0 0 1\n",
            " 1 1 0 1 0 0 0 0 0 1 1 0 1 1 0 0 0 1 0 1 0 1 0 1 1 0 1 0 0 0 0 0 0 1 1 0 1\n",
            " 1 0 1 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 1 0 1 1 0 1 1 1 0 1 1 0 1 0 1 1 1 1\n",
            " 1 1 0 0 1 0 1 1 0 0 0 1 0 1 1 1 0 0 0 0 0 1 0 1 0 1 0 0 1 0 1 0 1 0 1 0 0\n",
            " 0 1 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 0 1 1 0 0 1 1 1 0 0 1 0\n",
            " 1 0 1 0 1 0 1 1 1 1 0 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 0 1 1 0 1 1 0 1 1 0 1 1 0 1 0 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 0 1 0 1 1 0 1\n",
            " 1 1 1 1 1 0 0 0 0 1 1 0 1 1 0 0 1 0 0 1 0 0 1 0 1 1 0 1 1 0 1 1 1 1 1 0 1\n",
            " 0 1 0 1 1 0 0 1 0 0 0 1 1 1 1 1 1 1 0 0 0 1 1 1 0 0 1 0 0 1 0 1 0 0 0 0 1\n",
            " 1 0 0 1 1 1 1 0 1 0 0 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 0 0 0 1 1 0 0 1 0 1 1\n",
            " 0 0 1 1 1 0 1 0 1 0 1 0 0 0 0 0 1 0 1 1 0 1 1 0 1 1 0 1 1 1 1 1 0 1 1 1 0\n",
            " 1 1 1 1 1 1 1 0 0 0 1 0 0 1 1 1 1 0 1 1 1 1 0 0 0 0 1 1 0 0 0 1 0 1 0 1 1\n",
            " 1 0 1 1 1 0 1 0 1 1 1 0 0 1 0 1 0 0 1 0 0 1 1 1 1 1 1 0 0 0 0 1 1 1 0 1 1\n",
            " 1 0 1 1 0 1 0 1 0 0 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 0 0 1 0 0 1 1 1 0\n",
            " 1 0 1 1 1 0 1 1 1 0 1 0 1 0 1 1 0 1 0 1 0 1 1 0 0 1 0 0 0 1 0 1 0 1 0 0 1\n",
            " 1 1 0 1 0 0 1 0 1 0 1 1 1 1 1 0 0 0 0 1 0 1 1 1 0 1 1 1 0 0 1 1 0 0 1 0 0\n",
            " 1 0 1 0 1 0 0 0 1 0 0 1 1 0 1 1 0 0 1 1 0 0 1 0 1 0 1 1 0 1 0 0 1 0 1 1 0\n",
            " 0 0 1 0 0 0 1 0 1 1 1 1 0 1 1 0 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0\n",
            " 1 1 0 1 1 1 1 1 1 1 0 0 1 0 0 1 1 1 0 1 1 1 0 1 0 1 0 0 0 0 1 0 0 1 1 0 1\n",
            " 0 1 1 1 0 0 0 1 0 1 0 1 0 0 1 0 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1\n",
            " 1 1 1 1 1 0 0 1 1 1 1 1 0 1 0 0 1 1 0 1 0 0 1 0 1 1 0 1 0 0 0 0 1 0 1 1 1\n",
            " 0 1 0 1 1 1 1 1 0 1 1 0 1 0 0 0 0 0 1 1 0 1 0 0 0 1 1 0 0 1 1 1 1 0 1 1 1\n",
            " 0 0 1 1 1 0 0 1 1 0 1 1 0 0 0]\n",
            "probabilities: (977, 2) \n",
            " [1 1 0 0 1 0 1 1 0 0 0 0 1 1 1 0 1 0 1 0 0 0 0 1 1 0 1 1 0 1 0 0 0 0 1 1 0\n",
            " 0 0 1 1 0 1 1 1 1 0 0 1 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 1 0 1 0 1 0 1 0 0\n",
            " 0 0 1 0 0 1 1 1 1 1 0 1 0 0 1 1 0 0 0 0 0 0 1 1 0 0 1 0 0 1 1 1 1 0 1 0 1\n",
            " 0 0 1 0 0 0 0 0 1 0 0 1 1 0 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 1 1 0 0 1 1 0\n",
            " 1 1 1 0 0 1 0 0 0 0 1 0 1 1 1 0 1 1 0 1 0 0 1 1 0 1 1 1 0 0 0 1 0 0 0 0 1\n",
            " 1 1 0 1 0 0 0 0 0 1 1 0 1 1 0 0 0 1 0 1 0 1 0 1 1 0 1 0 0 0 0 0 0 1 1 0 1\n",
            " 1 0 1 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 1 0 1 1 0 1 1 1 0 1 1 0 1 0 1 1 1 1\n",
            " 1 1 0 0 1 0 1 1 0 0 0 1 0 1 1 1 0 0 0 0 0 1 0 1 0 1 0 0 1 0 1 0 1 0 1 0 0\n",
            " 0 1 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 0 1 1 0 0 1 1 1 0 0 1 0\n",
            " 1 0 1 0 1 0 1 1 1 1 0 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 0 1 1 0 1 1 0 1 1 0 1 1 0 1 0 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 0 1 0 1 1 0 1\n",
            " 1 1 1 1 1 0 0 0 0 1 1 0 1 1 0 0 1 0 0 1 0 0 1 0 1 1 0 1 1 0 1 1 1 1 1 0 1\n",
            " 0 1 0 1 1 0 0 1 0 0 0 1 1 1 1 1 1 1 0 0 0 1 1 1 0 0 1 0 0 1 0 1 0 0 0 0 1\n",
            " 1 0 0 1 1 1 1 0 1 0 0 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 0 0 0 1 1 0 0 1 0 1 1\n",
            " 0 0 1 1 1 0 1 0 1 0 1 0 0 0 0 0 1 0 1 1 0 1 1 0 1 1 0 1 1 1 1 1 0 1 1 1 0\n",
            " 1 1 1 1 1 1 1 0 0 0 1 0 0 1 1 1 1 0 1 1 1 1 0 0 0 0 1 1 0 0 0 1 0 1 0 1 1\n",
            " 1 0 1 1 1 0 1 0 1 1 1 0 0 1 0 1 0 0 1 0 0 1 1 1 1 1 1 0 0 0 0 1 1 1 0 1 1\n",
            " 1 0 1 1 0 1 0 1 0 0 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 0 0 1 0 0 1 1 1 0\n",
            " 1 0 1 1 1 0 1 1 1 0 1 0 1 0 1 1 0 1 0 1 0 1 1 0 0 1 0 0 0 1 0 1 0 1 0 0 1\n",
            " 1 1 0 1 0 0 1 0 1 0 1 1 1 1 1 0 0 0 0 1 0 1 1 1 0 1 1 1 0 0 1 1 0 0 1 0 0\n",
            " 1 0 1 0 1 0 0 0 1 0 0 1 1 0 1 1 0 0 1 1 0 0 1 0 1 0 1 1 0 1 0 0 1 0 1 1 0\n",
            " 0 0 1 0 0 0 1 0 1 1 1 1 0 1 1 0 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0\n",
            " 1 1 0 1 1 1 1 1 1 1 0 0 1 0 0 1 1 1 0 1 1 1 0 1 0 1 0 0 0 0 1 0 0 1 1 0 1\n",
            " 0 1 1 1 0 0 0 1 0 1 0 1 0 0 1 0 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1\n",
            " 1 1 1 1 1 0 0 1 1 1 1 1 0 1 0 0 1 1 0 1 0 0 1 0 1 1 0 1 0 0 0 0 1 0 1 1 1\n",
            " 0 1 0 1 1 1 1 1 0 1 1 0 1 0 0 0 0 0 1 1 0 1 0 0 0 1 1 0 0 1 1 1 1 0 1 1 1\n",
            " 0 0 1 1 1 0 0 1 1 0 1 1 0 0 0]\n",
            "trainset before adding uncertain samples (325, 10) (325,)\n",
            "trainset after adding uncertain samples (350, 10) (350,)\n",
            "updated train set: (350, 10) (350,) unique(labels): [178 172] [0 1]\n",
            "val set: (952, 10) (952,)\n",
            "\n",
            "Train set: (350, 10)\n",
            "Validation set: (952, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 14\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.158 s \n",
            "\n",
            "Accuracy rate is 80.184332 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.88      0.87       321\n",
            "           1       0.63      0.58      0.60       113\n",
            "\n",
            "    accuracy                           0.80       434\n",
            "   macro avg       0.74      0.73      0.73       434\n",
            "weighted avg       0.80      0.80      0.80       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[283  38]\n",
            " [ 48  65]]\n",
            "--------------------------------\n",
            "val predicted: (952,) [1 1 0 0 1 0 1 1 0 0 0 0 1 1 1 0 1 0 1 0 0 0 0 1 1 0 1 1 0 1 0 0 0 0 1 1 0\n",
            " 0 0 1 0 1 1 1 1 0 0 1 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 1 0 1 0 1 0 1 0 0 0\n",
            " 0 1 0 0 1 1 1 1 1 0 1 0 0 1 1 0 0 0 0 0 1 1 0 0 1 0 0 1 1 1 1 0 1 0 1 0 0\n",
            " 1 0 0 0 0 0 1 0 0 1 0 1 1 0 1 1 1 0 1 1 1 1 1 0 1 0 1 1 0 0 1 1 0 1 1 1 0\n",
            " 0 1 0 0 0 1 0 1 1 1 0 1 1 0 1 0 0 1 1 0 1 1 1 0 0 0 1 0 0 0 0 1 1 1 0 1 0\n",
            " 0 0 0 0 1 1 0 1 1 0 0 0 1 0 1 0 1 0 1 1 0 1 0 0 0 0 0 0 1 1 0 1 1 0 1 1 1\n",
            " 1 1 1 0 0 1 1 0 1 0 1 1 1 1 1 0 1 1 0 1 1 1 0 1 1 0 1 0 1 1 1 1 1 1 0 0 1\n",
            " 0 1 1 0 0 0 0 1 1 0 0 0 0 0 0 1 0 1 0 0 1 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0\n",
            " 1 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 0 1 1 0 0 1 1 1 0 0 1 0 1 0 1 0 1 0 1 1 1\n",
            " 1 0 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 0 1 1 0\n",
            " 1 1 0 1 0 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0 0 0 1 1\n",
            " 0 1 1 0 0 1 0 0 1 0 0 1 0 1 1 0 1 1 0 1 1 1 1 1 0 1 0 1 0 1 1 0 0 1 0 0 0\n",
            " 1 1 1 1 1 1 1 0 0 0 1 1 1 0 0 1 0 0 1 0 0 0 0 0 1 1 0 0 1 1 1 1 0 1 0 0 1\n",
            " 1 1 1 1 0 1 1 1 1 1 0 1 1 0 0 0 1 1 0 0 1 0 1 1 0 0 1 1 1 0 1 0 1 0 1 0 0\n",
            " 0 0 1 0 1 1 0 1 1 0 1 1 0 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0 0 1 0 0 1\n",
            " 1 1 1 0 1 1 1 1 0 0 0 0 1 1 0 0 0 1 0 1 0 1 1 1 0 1 1 1 0 1 0 1 1 1 0 0 1\n",
            " 0 1 0 0 1 0 0 1 1 1 1 1 0 0 0 1 1 1 0 1 1 1 0 1 1 0 1 0 1 0 0 1 1 0 1 1 1\n",
            " 1 1 0 1 1 1 1 1 1 0 1 1 0 0 1 0 0 1 1 1 0 1 0 1 1 1 0 1 1 1 0 1 0 1 0 1 0\n",
            " 1 0 1 0 1 1 0 0 1 0 0 0 1 0 1 0 1 0 0 1 1 1 0 1 0 0 1 0 1 0 1 1 1 1 1 0 0\n",
            " 0 0 1 0 1 1 1 0 1 1 1 0 0 1 1 0 0 0 0 1 0 1 0 1 0 0 0 1 0 0 1 1 0 1 1 0 0\n",
            " 1 1 0 0 1 0 1 0 1 1 0 1 0 0 1 0 1 1 0 0 1 0 0 0 1 0 1 1 1 1 0 1 0 1 0 1 0\n",
            " 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 0 0 1 0 0 1 1 1 0 1 1\n",
            " 1 0 1 0 1 0 0 0 0 1 0 1 1 0 1 0 1 1 1 0 0 0 1 0 1 0 1 0 0 1 0 1 1 1 1 1 0\n",
            " 1 0 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 0 1 0 0 1 1 0 1 0 0 1 0\n",
            " 1 1 0 1 0 0 0 0 1 0 1 1 1 0 1 0 1 1 1 1 1 0 1 1 0 1 0 0 0 0 0 1 1 0 1 0 0\n",
            " 0 1 1 0 0 1 1 1 1 0 1 1 1 0 1 1 1 0 0 1 1 0 1 1 0 0 0]\n",
            "probabilities: (952, 2) \n",
            " [1 1 0 0 1 0 1 1 0 0 0 0 1 1 1 0 1 0 1 0 0 0 0 1 1 0 1 1 0 1 0 0 0 0 1 1 0\n",
            " 0 0 1 0 1 1 1 1 0 0 1 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 1 0 1 0 1 0 1 0 0 0\n",
            " 0 1 0 0 1 1 1 1 1 0 1 0 0 1 1 0 0 0 0 0 1 1 0 0 1 0 0 1 1 1 1 0 1 0 1 0 0\n",
            " 1 0 0 0 0 0 1 0 0 1 0 1 1 0 1 1 1 0 1 1 1 1 1 0 1 0 1 1 0 0 1 1 0 1 1 1 0\n",
            " 0 1 0 0 0 1 0 1 1 1 0 1 1 0 1 0 0 1 1 0 1 1 1 0 0 0 1 0 0 0 0 1 1 1 0 1 0\n",
            " 0 0 0 0 1 1 0 1 1 0 0 0 1 0 1 0 1 0 1 1 0 1 0 0 0 0 0 0 1 1 0 1 1 0 1 1 1\n",
            " 1 1 1 0 0 1 1 0 1 0 1 1 1 1 1 0 1 1 0 1 1 1 0 1 1 0 1 0 1 1 1 1 1 1 0 0 1\n",
            " 0 1 1 0 0 0 0 1 1 0 0 0 0 0 0 1 0 1 0 0 1 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0\n",
            " 1 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 0 1 1 0 0 1 1 1 0 0 1 0 1 0 1 0 1 0 1 1 1\n",
            " 1 0 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 0 1 1 0\n",
            " 1 1 0 1 0 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0 0 0 1 1\n",
            " 0 1 1 0 0 1 0 0 1 0 0 1 0 1 1 0 1 1 0 1 1 1 1 1 0 1 0 1 0 1 1 0 0 1 0 0 0\n",
            " 1 1 1 1 1 1 1 0 0 0 1 1 1 0 0 1 0 0 1 0 0 0 0 0 1 1 0 0 1 1 1 1 0 1 0 0 1\n",
            " 1 1 1 1 0 1 1 1 1 1 0 1 1 0 0 0 1 1 0 0 1 0 1 1 0 0 1 1 1 0 1 0 1 0 1 0 0\n",
            " 0 0 1 0 1 1 0 1 1 0 1 1 0 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0 0 1 0 0 1\n",
            " 1 1 1 0 1 1 1 1 0 0 0 0 1 1 0 0 0 1 0 1 0 1 1 1 0 1 1 1 0 1 0 1 1 1 0 0 1\n",
            " 0 1 0 0 1 0 0 1 1 1 1 1 0 0 0 1 1 1 0 1 1 1 0 1 1 0 1 0 1 0 0 1 1 0 1 1 1\n",
            " 1 1 0 1 1 1 1 1 1 0 1 1 0 0 1 0 0 1 1 1 0 1 0 1 1 1 0 1 1 1 0 1 0 1 0 1 0\n",
            " 1 0 1 0 1 1 0 0 1 0 0 0 1 0 1 0 1 0 0 1 1 1 0 1 0 0 1 0 1 0 1 1 1 1 1 0 0\n",
            " 0 0 1 0 1 1 1 0 1 1 1 0 0 1 1 0 0 0 0 1 0 1 0 1 0 0 0 1 0 0 1 1 0 1 1 0 0\n",
            " 1 1 0 0 1 0 1 0 1 1 0 1 0 0 1 0 1 1 0 0 1 0 0 0 1 0 1 1 1 1 0 1 0 1 0 1 0\n",
            " 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 0 0 1 0 0 1 1 1 0 1 1\n",
            " 1 0 1 0 1 0 0 0 0 1 0 1 1 0 1 0 1 1 1 0 0 0 1 0 1 0 1 0 0 1 0 1 1 1 1 1 0\n",
            " 1 0 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 0 1 0 0 1 1 0 1 0 0 1 0\n",
            " 1 1 0 1 0 0 0 0 1 0 1 1 1 0 1 0 1 1 1 1 1 0 1 1 0 1 0 0 0 0 0 1 1 0 1 0 0\n",
            " 0 1 1 0 0 1 1 1 1 0 1 1 1 0 1 1 1 0 0 1 1 0 1 1 0 0 0]\n",
            "trainset before adding uncertain samples (350, 10) (350,)\n",
            "trainset after adding uncertain samples (375, 10) (375,)\n",
            "updated train set: (375, 10) (375,) unique(labels): [193 182] [0 1]\n",
            "val set: (927, 10) (927,)\n",
            "\n",
            "Train set: (375, 10)\n",
            "Validation set: (927, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 15\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.153 s \n",
            "\n",
            "Accuracy rate is 79.723502 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.88      0.87       321\n",
            "           1       0.62      0.57      0.59       113\n",
            "\n",
            "    accuracy                           0.80       434\n",
            "   macro avg       0.74      0.72      0.73       434\n",
            "weighted avg       0.79      0.80      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[282  39]\n",
            " [ 49  64]]\n",
            "--------------------------------\n",
            "val predicted: (927,) [1 1 0 1 0 1 1 0 0 0 0 1 1 1 0 1 0 1 0 0 0 1 1 0 1 1 1 0 0 0 0 1 1 0 0 0 1\n",
            " 0 1 1 1 1 0 0 1 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 1 0 1 0 1 0 1 0 0 0 0 1 0\n",
            " 0 1 1 1 1 1 0 1 0 1 1 0 0 0 0 0 1 1 0 0 1 0 0 1 1 1 1 0 1 0 1 0 0 1 0 0 0\n",
            " 0 1 0 1 0 1 1 0 1 1 1 1 1 1 1 1 0 1 0 1 1 0 0 1 1 0 1 1 1 0 0 1 0 0 0 1 0\n",
            " 1 1 1 0 1 1 0 1 0 0 1 1 0 1 1 1 0 0 1 0 0 0 0 1 1 1 0 1 0 0 0 0 0 1 1 0 1\n",
            " 0 0 0 1 0 1 1 0 1 1 0 1 0 0 0 0 0 0 1 1 0 1 1 0 1 1 1 1 1 1 0 0 1 1 0 1 0\n",
            " 1 1 1 1 1 0 1 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 1 0 0 1 0 1 1 0 0 0 1 1 0 0 0\n",
            " 0 0 0 1 0 1 0 0 1 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 1 1 1\n",
            " 0 1 0 1 0 1 1 0 0 1 1 0 0 1 0 1 0 1 0 1 0 1 1 1 0 0 1 1 1 1 0 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 0 1 1 0 1 1 0 1 0 1 0 1 1 1 1 0 1 1 0\n",
            " 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0 0 0 1 1 0 1 1 0 0 1 0 0 1 0 0 1 0 1 1\n",
            " 0 1 1 0 1 1 1 1 1 0 1 0 1 0 1 1 0 0 1 0 0 0 1 1 1 1 1 1 1 0 0 0 1 1 1 0 0\n",
            " 1 0 0 1 0 0 0 0 0 1 1 0 0 1 1 1 0 1 0 0 1 1 1 1 1 0 1 1 1 1 1 0 1 1 0 0 0\n",
            " 1 1 0 0 1 0 1 1 0 0 1 1 1 1 0 1 0 1 0 0 0 0 1 0 1 1 0 1 1 0 1 1 0 1 1 1 1\n",
            " 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0 0 1 0 1 1 1 1 0 1 1 1 1 0 0 0 0 1 1 0 0 0 1\n",
            " 0 1 0 1 1 1 0 1 1 1 0 1 0 1 1 1 0 0 1 0 1 0 0 1 0 0 1 1 1 1 1 0 0 1 1 1 0\n",
            " 1 1 1 0 1 1 0 1 0 1 0 0 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 0 0 1 0 0 1 1\n",
            " 1 0 1 0 1 1 1 0 1 1 1 0 1 0 1 0 1 0 1 0 1 0 1 1 0 0 1 0 0 0 1 0 1 0 1 0 0\n",
            " 1 1 1 0 1 0 0 1 0 1 0 1 1 1 1 1 0 0 0 0 1 0 1 1 1 0 1 1 1 0 0 1 1 0 0 0 0\n",
            " 1 0 1 0 1 0 0 0 1 0 0 1 1 0 1 1 0 0 1 1 0 0 1 0 1 0 1 1 0 1 0 0 1 0 1 0 0\n",
            " 1 0 0 1 0 1 1 1 1 0 1 0 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1\n",
            " 1 1 1 1 1 0 0 1 0 0 1 1 1 0 1 1 1 0 1 0 1 0 0 0 0 1 0 1 1 0 1 0 1 1 1 0 0\n",
            " 0 1 0 1 0 1 0 0 1 0 1 1 1 1 1 0 1 0 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 0 1\n",
            " 1 1 1 1 0 1 0 0 1 1 0 1 0 0 1 0 1 1 0 1 0 0 0 0 1 0 1 1 1 0 1 0 1 1 1 1 1\n",
            " 1 1 0 1 0 0 0 0 1 0 1 0 0 0 1 1 0 0 1 1 1 1 0 1 1 1 0 1 1 0 0 1 1 0 1 1 0\n",
            " 0 0]\n",
            "probabilities: (927, 2) \n",
            " [1 1 0 1 0 1 1 0 0 0 0 1 1 1 0 1 0 1 0 0 0 1 1 0 1 1 1 0 0 0 0 1 1 0 0 0 1\n",
            " 0 1 1 1 1 0 0 1 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 1 0 1 0 1 0 1 0 0 0 0 1 0\n",
            " 0 1 1 1 1 1 0 1 0 1 1 0 0 0 0 0 1 1 0 0 1 0 0 1 1 1 1 0 1 0 1 0 0 1 0 0 0\n",
            " 0 1 0 1 0 1 1 0 1 1 1 1 1 1 1 1 0 1 0 1 1 0 0 1 1 0 1 1 1 0 0 1 0 0 0 1 0\n",
            " 1 1 1 0 1 1 0 1 0 0 1 1 0 1 1 1 0 0 1 0 0 0 0 1 1 1 0 1 0 0 0 0 0 1 1 0 1\n",
            " 0 0 0 1 0 1 1 0 1 1 0 1 0 0 0 0 0 0 1 1 0 1 1 0 1 1 1 1 1 1 0 0 1 1 0 1 0\n",
            " 1 1 1 1 1 0 1 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 1 0 0 1 0 1 1 0 0 0 1 1 0 0 0\n",
            " 0 0 0 1 0 1 0 0 1 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 1 1 1\n",
            " 0 1 0 1 0 1 1 0 0 1 1 0 0 1 0 1 0 1 0 1 0 1 1 1 0 0 1 1 1 1 0 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 0 1 1 0 1 1 0 1 0 1 0 1 1 1 1 0 1 1 0\n",
            " 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0 0 0 1 1 0 1 1 0 0 1 0 0 1 0 0 1 0 1 1\n",
            " 0 1 1 0 1 1 1 1 1 0 1 0 1 0 1 1 0 0 1 0 0 0 1 1 1 1 1 1 1 0 0 0 1 1 1 0 0\n",
            " 1 0 0 1 0 0 0 0 0 1 1 0 0 1 1 1 0 1 0 0 1 1 1 1 1 0 1 1 1 1 1 0 1 1 0 0 0\n",
            " 1 1 0 0 1 0 1 1 0 0 1 1 1 1 0 1 0 1 0 0 0 0 1 0 1 1 0 1 1 0 1 1 0 1 1 1 1\n",
            " 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0 0 1 0 1 1 1 1 0 1 1 1 1 0 0 0 0 1 1 0 0 0 1\n",
            " 0 1 0 1 1 1 0 1 1 1 0 1 0 1 1 1 0 0 1 0 1 0 0 1 0 0 1 1 1 1 1 0 0 1 1 1 0\n",
            " 1 1 1 0 1 1 0 1 0 1 0 0 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 0 0 1 0 0 1 1\n",
            " 1 0 1 0 1 1 1 0 1 1 1 0 1 0 1 0 1 0 1 0 1 0 1 1 0 0 1 0 0 0 1 0 1 0 1 0 0\n",
            " 1 1 1 0 1 0 0 1 0 1 0 1 1 1 1 1 0 0 0 0 1 0 1 1 1 0 1 1 1 0 0 1 1 0 0 0 0\n",
            " 1 0 1 0 1 0 0 0 1 0 0 1 1 0 1 1 0 0 1 1 0 0 1 0 1 0 1 1 0 1 0 0 1 0 1 0 0\n",
            " 1 0 0 1 0 1 1 1 1 0 1 0 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1\n",
            " 1 1 1 1 1 0 0 1 0 0 1 1 1 0 1 1 1 0 1 0 1 0 0 0 0 1 0 1 1 0 1 0 1 1 1 0 0\n",
            " 0 1 0 1 0 1 0 0 1 0 1 1 1 1 1 0 1 0 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 0 1\n",
            " 1 1 1 1 0 1 0 0 1 1 0 1 0 0 1 0 1 1 0 1 0 0 0 0 1 0 1 1 1 0 1 0 1 1 1 1 1\n",
            " 1 1 0 1 0 0 0 0 1 0 1 0 0 0 1 1 0 0 1 1 1 1 0 1 1 1 0 1 1 0 0 1 1 0 1 1 0\n",
            " 0 0]\n",
            "trainset before adding uncertain samples (375, 10) (375,)\n",
            "trainset after adding uncertain samples (400, 10) (400,)\n",
            "updated train set: (400, 10) (400,) unique(labels): [204 196] [0 1]\n",
            "val set: (902, 10) (902,)\n",
            "\n",
            "Train set: (400, 10)\n",
            "Validation set: (902, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 16\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.189 s \n",
            "\n",
            "Accuracy rate is 79.262673 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.87      0.86       321\n",
            "           1       0.61      0.58      0.59       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.73      0.72      0.73       434\n",
            "weighted avg       0.79      0.79      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[279  42]\n",
            " [ 48  65]]\n",
            "--------------------------------\n",
            "val predicted: (902,) [1 1 1 0 1 1 0 0 0 0 1 1 1 0 1 0 0 0 1 1 0 1 1 1 0 0 0 0 1 1 0 0 0 1 0 1 1\n",
            " 1 0 0 1 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 1 0 1 0 1 0 1 0 0 0 0 1 0 0 1 1 1\n",
            " 1 1 0 1 0 1 1 0 0 0 0 1 1 0 1 0 0 1 1 1 1 0 1 0 1 0 0 1 0 0 0 0 1 0 1 0 1\n",
            " 1 0 1 1 1 1 1 1 1 1 0 1 0 1 1 0 0 1 1 0 1 1 1 0 1 0 0 0 1 0 1 1 1 0 1 1 0\n",
            " 1 0 0 1 1 0 1 1 1 0 0 0 0 0 0 1 1 1 0 1 0 0 0 0 0 1 1 0 1 0 0 0 1 0 1 1 0\n",
            " 1 1 0 1 0 0 0 0 0 0 1 1 0 1 1 1 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 1 0 1 1 0\n",
            " 1 1 1 0 1 1 0 1 1 1 1 1 1 1 0 0 1 0 1 1 0 0 0 1 1 0 0 0 0 0 1 0 1 0 0 1 0\n",
            " 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 0 1 1 0 0 1 1\n",
            " 0 0 1 0 1 0 1 0 1 0 1 1 1 0 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 0 1 1 0 1 0 1 1 0 1 1 0 1 0 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 0 1\n",
            " 1 1 1 1 1 0 0 0 0 1 1 0 1 1 0 0 1 0 1 0 0 1 0 1 1 0 1 1 0 1 1 1 1 1 0 1 0\n",
            " 1 0 1 1 0 0 1 0 0 0 1 1 1 1 1 1 0 0 0 1 1 1 0 0 1 0 0 1 0 0 0 0 0 1 1 0 0\n",
            " 1 1 1 0 1 0 0 1 1 1 1 1 0 1 1 1 1 1 0 1 1 0 0 0 1 1 0 0 1 0 1 1 0 0 1 1 1\n",
            " 1 0 1 0 1 0 0 0 0 1 0 1 1 0 1 1 0 1 1 0 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 0\n",
            " 0 0 1 0 1 1 1 1 0 1 1 1 0 0 0 0 1 1 0 0 0 1 0 1 0 1 1 1 0 1 1 1 0 1 0 1 1\n",
            " 1 0 0 1 0 1 0 0 1 0 0 1 1 1 1 1 0 0 1 1 1 0 1 1 1 1 1 0 1 0 1 0 0 1 0 1 1\n",
            " 1 1 1 0 1 1 1 1 1 1 0 1 0 0 1 0 0 1 1 1 0 1 0 1 1 1 0 1 1 1 0 1 0 1 0 1 0\n",
            " 1 0 1 0 1 1 0 0 1 0 0 0 1 0 1 0 1 0 0 1 1 1 0 1 0 0 1 0 1 0 1 1 1 1 1 0 0\n",
            " 0 0 1 0 1 1 1 0 1 1 1 0 0 1 1 0 0 0 0 1 0 1 0 1 0 0 0 1 0 0 1 1 0 1 1 0 0\n",
            " 1 1 0 0 1 1 0 1 1 0 1 0 0 1 0 1 0 0 1 0 0 1 0 1 1 1 0 1 0 1 0 1 0 0 1 0 1\n",
            " 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 0 0 1 0 0 1 1 1 0 1 1 1 0 1 0 1\n",
            " 0 0 0 0 1 0 1 1 0 1 0 1 1 1 0 0 0 1 0 1 0 1 0 0 1 0 1 1 1 1 0 1 0 0 1 1 1\n",
            " 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 0 0 1 1 0 1 0 0 1 0 1 1 0 1 0 0 0\n",
            " 0 1 0 1 1 1 0 1 1 1 1 1 1 1 0 1 0 0 0 0 1 0 1 0 0 0 1 1 0 0 1 1 1 1 0 1 1\n",
            " 1 0 1 1 0 0 1 1 0 1 1 0 0 0]\n",
            "probabilities: (902, 2) \n",
            " [1 1 1 0 1 1 0 0 0 0 1 1 1 0 1 0 0 0 1 1 0 1 1 1 0 0 0 0 1 1 0 0 0 1 0 1 1\n",
            " 1 0 0 1 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 1 0 1 0 1 0 1 0 0 0 0 1 0 0 1 1 1\n",
            " 1 1 0 1 0 1 1 0 0 0 0 1 1 0 1 0 0 1 1 1 1 0 1 0 1 0 0 1 0 0 0 0 1 0 1 0 1\n",
            " 1 0 1 1 1 1 1 1 1 1 0 1 0 1 1 0 0 1 1 0 1 1 1 0 1 0 0 0 1 0 1 1 1 0 1 1 0\n",
            " 1 0 0 1 1 0 1 1 1 0 0 0 0 0 0 1 1 1 0 1 0 0 0 0 0 1 1 0 1 0 0 0 1 0 1 1 0\n",
            " 1 1 0 1 0 0 0 0 0 0 1 1 0 1 1 1 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 1 0 1 1 0\n",
            " 1 1 1 0 1 1 0 1 1 1 1 1 1 1 0 0 1 0 1 1 0 0 0 1 1 0 0 0 0 0 1 0 1 0 0 1 0\n",
            " 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 0 1 1 0 0 1 1\n",
            " 0 0 1 0 1 0 1 0 1 0 1 1 1 0 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 0 1 1 0 1 0 1 1 0 1 1 0 1 0 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 0 1\n",
            " 1 1 1 1 1 0 0 0 0 1 1 0 1 1 0 0 1 0 1 0 0 1 0 1 1 0 1 1 0 1 1 1 1 1 0 1 0\n",
            " 1 0 1 1 0 0 1 0 0 0 1 1 1 1 1 1 0 0 0 1 1 1 0 0 1 0 0 1 0 0 0 0 0 1 1 0 0\n",
            " 1 1 1 0 1 0 0 1 1 1 1 1 0 1 1 1 1 1 0 1 1 0 0 0 1 1 0 0 1 0 1 1 0 0 1 1 1\n",
            " 1 0 1 0 1 0 0 0 0 1 0 1 1 0 1 1 0 1 1 0 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 0\n",
            " 0 0 1 0 1 1 1 1 0 1 1 1 0 0 0 0 1 1 0 0 0 1 0 1 0 1 1 1 0 1 1 1 0 1 0 1 1\n",
            " 1 0 0 1 0 1 0 0 1 0 0 1 1 1 1 1 0 0 1 1 1 0 1 1 1 1 1 0 1 0 1 0 0 1 0 1 1\n",
            " 1 1 1 0 1 1 1 1 1 1 0 1 0 0 1 0 0 1 1 1 0 1 0 1 1 1 0 1 1 1 0 1 0 1 0 1 0\n",
            " 1 0 1 0 1 1 0 0 1 0 0 0 1 0 1 0 1 0 0 1 1 1 0 1 0 0 1 0 1 0 1 1 1 1 1 0 0\n",
            " 0 0 1 0 1 1 1 0 1 1 1 0 0 1 1 0 0 0 0 1 0 1 0 1 0 0 0 1 0 0 1 1 0 1 1 0 0\n",
            " 1 1 0 0 1 1 0 1 1 0 1 0 0 1 0 1 0 0 1 0 0 1 0 1 1 1 0 1 0 1 0 1 0 0 1 0 1\n",
            " 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 0 0 1 0 0 1 1 1 0 1 1 1 0 1 0 1\n",
            " 0 0 0 0 1 0 1 1 0 1 0 1 1 1 0 0 0 1 0 1 0 1 0 0 1 0 1 1 1 1 0 1 0 0 1 1 1\n",
            " 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 0 0 1 1 0 1 0 0 1 0 1 1 0 1 0 0 0\n",
            " 0 1 0 1 1 1 0 1 1 1 1 1 1 1 0 1 0 0 0 0 1 0 1 0 0 0 1 1 0 0 1 1 1 1 0 1 1\n",
            " 1 0 1 1 0 0 1 1 0 1 1 0 0 0]\n",
            "trainset before adding uncertain samples (400, 10) (400,)\n",
            "trainset after adding uncertain samples (425, 10) (425,)\n",
            "updated train set: (425, 10) (425,) unique(labels): [216 209] [0 1]\n",
            "val set: (877, 10) (877,)\n",
            "\n",
            "Train set: (425, 10)\n",
            "Validation set: (877, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 17\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.229 s \n",
            "\n",
            "Accuracy rate is 79.953917 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.87      0.87       321\n",
            "           1       0.62      0.59      0.61       113\n",
            "\n",
            "    accuracy                           0.80       434\n",
            "   macro avg       0.74      0.73      0.74       434\n",
            "weighted avg       0.80      0.80      0.80       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[280  41]\n",
            " [ 46  67]]\n",
            "--------------------------------\n",
            "val predicted: (877,) [1 1 1 0 1 1 0 0 0 0 1 1 1 0 1 0 0 0 1 1 0 1 1 1 0 0 0 0 1 0 0 0 1 0 1 1 1\n",
            " 0 0 1 1 1 1 1 0 1 0 1 1 0 1 1 1 1 1 1 0 1 0 1 0 1 0 0 0 0 1 0 0 1 1 1 1 1\n",
            " 0 1 0 1 1 0 0 0 1 1 0 1 0 0 1 1 1 1 0 1 0 1 0 0 1 0 0 0 0 1 0 1 0 1 1 0 1\n",
            " 1 1 1 1 1 1 1 0 1 0 1 1 0 0 1 1 0 1 1 1 0 1 0 0 0 1 0 1 1 1 0 1 1 0 1 0 0\n",
            " 1 1 0 1 1 1 0 0 0 0 0 1 1 1 0 1 0 0 0 0 0 1 1 0 1 0 0 0 1 0 1 1 0 1 1 0 1\n",
            " 0 0 0 0 1 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 0 1 1 1 1 1 0 1 1 0 1 1 1 0 1 1 0\n",
            " 1 1 1 1 1 1 1 0 0 1 0 1 1 0 0 0 1 1 0 0 0 0 0 1 0 1 0 0 1 0 1 0 1 0 1 0 0\n",
            " 0 1 0 0 0 0 0 0 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 0 1 1 0 0 1 1 0 0 1 0 1 0 1\n",
            " 0 1 0 1 1 1 0 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1\n",
            " 0 1 1 0 1 1 0 1 0 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0\n",
            " 0 0 1 1 0 1 1 0 0 1 0 1 0 1 0 1 1 0 1 1 0 1 1 1 1 1 0 1 0 1 0 1 1 0 0 1 0\n",
            " 0 0 1 1 1 1 1 1 0 0 0 1 1 1 0 0 1 0 0 1 0 0 0 0 0 1 1 0 0 1 1 0 1 0 0 1 1\n",
            " 1 1 1 1 1 1 1 1 0 1 1 0 0 0 1 1 0 0 1 0 1 1 0 0 1 1 1 1 0 1 0 1 0 0 0 0 1\n",
            " 0 1 1 0 1 1 0 1 1 0 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 0 0 0 1 0 1 1 1 1 0 1 1\n",
            " 1 0 0 0 0 1 0 0 1 0 1 0 1 1 1 0 1 1 0 1 0 1 1 0 0 1 0 1 0 0 1 0 0 1 1 1 1\n",
            " 1 0 0 1 1 1 0 1 1 1 1 1 0 1 0 1 0 0 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 0 1 0\n",
            " 0 1 1 1 1 0 1 1 1 0 1 1 1 0 1 0 1 0 1 0 1 0 1 0 1 1 0 0 1 0 0 0 1 0 1 0 1\n",
            " 0 0 1 1 1 0 1 0 0 1 0 1 0 1 1 1 1 1 0 0 0 0 1 0 1 1 1 0 1 1 0 0 1 1 0 0 0\n",
            " 0 1 0 1 0 1 0 0 1 0 0 1 1 0 1 1 0 0 1 1 0 0 1 1 0 1 1 0 1 0 0 1 0 1 0 0 1\n",
            " 0 0 1 0 1 1 1 0 1 0 1 0 1 0 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1\n",
            " 0 0 1 0 0 1 1 1 0 1 1 1 0 1 0 1 0 0 0 0 1 0 1 1 0 1 0 1 1 1 0 0 0 1 0 1 0\n",
            " 1 0 0 1 0 1 1 1 1 0 1 0 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 0\n",
            " 0 1 1 0 1 0 0 1 0 1 1 0 1 0 0 0 0 1 0 1 1 1 0 1 1 1 1 1 1 0 1 0 0 0 1 0 0\n",
            " 0 0 1 1 0 0 1 1 1 1 0 1 1 1 0 1 1 0 0 1 1 0 1 1 0 0]\n",
            "probabilities: (877, 2) \n",
            " [1 1 1 0 1 1 0 0 0 0 1 1 1 0 1 0 0 0 1 1 0 1 1 1 0 0 0 0 1 0 0 0 1 0 1 1 1\n",
            " 0 0 1 1 1 1 1 0 1 0 1 1 0 1 1 1 1 1 1 0 1 0 1 0 1 0 0 0 0 1 0 0 1 1 1 1 1\n",
            " 0 1 0 1 1 0 0 0 1 1 0 1 0 0 1 1 1 1 0 1 0 1 0 0 1 0 0 0 0 1 0 1 0 1 1 0 1\n",
            " 1 1 1 1 1 1 1 0 1 0 1 1 0 0 1 1 0 1 1 1 0 1 0 0 0 1 0 1 1 1 0 1 1 0 1 0 0\n",
            " 1 1 0 1 1 1 0 0 0 0 0 1 1 1 0 1 0 0 0 0 0 1 1 0 1 0 0 0 1 0 1 1 0 1 1 0 1\n",
            " 0 0 0 0 1 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 0 1 1 1 1 1 0 1 1 0 1 1 1 0 1 1 0\n",
            " 1 1 1 1 1 1 1 0 0 1 0 1 1 0 0 0 1 1 0 0 0 0 0 1 0 1 0 0 1 0 1 0 1 0 1 0 0\n",
            " 0 1 0 0 0 0 0 0 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 0 1 1 0 0 1 1 0 0 1 0 1 0 1\n",
            " 0 1 0 1 1 1 0 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1\n",
            " 0 1 1 0 1 1 0 1 0 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0\n",
            " 0 0 1 1 0 1 1 0 0 1 0 1 0 1 0 1 1 0 1 1 0 1 1 1 1 1 0 1 0 1 0 1 1 0 0 1 0\n",
            " 0 0 1 1 1 1 1 1 0 0 0 1 1 1 0 0 1 0 0 1 0 0 0 0 0 1 1 0 0 1 1 0 1 0 0 1 1\n",
            " 1 1 1 1 1 1 1 1 0 1 1 0 0 0 1 1 0 0 1 0 1 1 0 0 1 1 1 1 0 1 0 1 0 0 0 0 1\n",
            " 0 1 1 0 1 1 0 1 1 0 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 0 0 0 1 0 1 1 1 1 0 1 1\n",
            " 1 0 0 0 0 1 0 0 1 0 1 0 1 1 1 0 1 1 0 1 0 1 1 0 0 1 0 1 0 0 1 0 0 1 1 1 1\n",
            " 1 0 0 1 1 1 0 1 1 1 1 1 0 1 0 1 0 0 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 0 1 0\n",
            " 0 1 1 1 1 0 1 1 1 0 1 1 1 0 1 0 1 0 1 0 1 0 1 0 1 1 0 0 1 0 0 0 1 0 1 0 1\n",
            " 0 0 1 1 1 0 1 0 0 1 0 1 0 1 1 1 1 1 0 0 0 0 1 0 1 1 1 0 1 1 0 0 1 1 0 0 0\n",
            " 0 1 0 1 0 1 0 0 1 0 0 1 1 0 1 1 0 0 1 1 0 0 1 1 0 1 1 0 1 0 0 1 0 1 0 0 1\n",
            " 0 0 1 0 1 1 1 0 1 0 1 0 1 0 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1\n",
            " 0 0 1 0 0 1 1 1 0 1 1 1 0 1 0 1 0 0 0 0 1 0 1 1 0 1 0 1 1 1 0 0 0 1 0 1 0\n",
            " 1 0 0 1 0 1 1 1 1 0 1 0 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 0\n",
            " 0 1 1 0 1 0 0 1 0 1 1 0 1 0 0 0 0 1 0 1 1 1 0 1 1 1 1 1 1 0 1 0 0 0 1 0 0\n",
            " 0 0 1 1 0 0 1 1 1 1 0 1 1 1 0 1 1 0 0 1 1 0 1 1 0 0]\n",
            "trainset before adding uncertain samples (425, 10) (425,)\n",
            "trainset after adding uncertain samples (450, 10) (450,)\n",
            "updated train set: (450, 10) (450,) unique(labels): [223 227] [0 1]\n",
            "val set: (852, 10) (852,)\n",
            "\n",
            "Train set: (450, 10)\n",
            "Validation set: (852, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 18\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.250 s \n",
            "\n",
            "Accuracy rate is 79.723502 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.87      0.86       321\n",
            "           1       0.61      0.60      0.61       113\n",
            "\n",
            "    accuracy                           0.80       434\n",
            "   macro avg       0.74      0.73      0.74       434\n",
            "weighted avg       0.80      0.80      0.80       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[278  43]\n",
            " [ 45  68]]\n",
            "--------------------------------\n",
            "val predicted: (852,) [1 1 1 0 1 1 0 0 0 0 1 1 1 0 1 0 0 0 1 1 0 1 1 1 0 0 0 0 1 0 0 0 1 0 1 1 1\n",
            " 0 0 1 1 1 1 1 0 1 0 1 1 0 1 1 1 1 1 1 0 1 0 1 0 1 0 0 0 0 1 0 0 1 1 1 1 1\n",
            " 0 1 0 1 1 0 0 0 1 1 0 1 0 0 1 1 1 1 0 1 0 1 0 0 1 0 0 0 1 0 1 0 1 1 0 1 1\n",
            " 1 1 1 1 1 0 1 0 1 1 0 0 1 1 0 1 1 0 1 0 0 0 1 0 1 1 1 0 1 1 0 1 0 0 1 1 0\n",
            " 1 1 1 0 0 0 0 0 1 1 1 0 1 0 0 0 0 0 1 0 1 0 0 0 1 0 1 1 0 1 1 0 1 0 0 0 0\n",
            " 1 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 0 1 1 1 1 1 0 1 1 0 1 1 1 0 1 1 0 1 1 1 1\n",
            " 1 1 0 0 1 0 1 1 0 0 0 1 1 0 0 0 0 0 1 0 1 0 0 1 0 1 0 1 0 1 0 0 0 1 0 0 0\n",
            " 0 0 0 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 0 1 1 0 0 1 1 0 0 1 0 1 0 1 0 1 0 1 1\n",
            " 1 0 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 0 1 1 0 1\n",
            " 1 0 1 0 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 0 0 0 0 1 1 0 1\n",
            " 1 0 0 1 0 1 0 1 0 1 1 1 0 1 1 1 1 1 0 1 0 1 0 1 1 0 0 1 0 0 0 1 1 1 1 1 1\n",
            " 0 0 0 1 1 0 0 1 0 0 1 0 0 0 0 0 1 1 0 0 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 0 1\n",
            " 1 0 0 0 1 1 0 0 1 0 1 1 0 0 1 1 0 1 0 1 0 0 0 0 1 0 1 1 0 1 1 0 1 1 0 1 1\n",
            " 1 1 0 1 1 1 0 1 1 1 1 1 1 0 0 0 1 0 1 1 1 1 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1\n",
            " 1 1 0 1 1 1 0 1 1 0 0 1 0 1 0 0 1 0 0 1 1 1 1 1 0 0 1 1 0 1 1 1 1 1 0 1 0\n",
            " 1 0 0 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 0 1 0 0 1 1 1 1 0 1 1 1 0 1 1 1 0 1\n",
            " 0 1 0 1 0 1 0 1 0 1 1 0 0 1 0 0 0 1 0 1 0 1 0 0 1 1 1 0 1 0 0 1 0 1 0 1 1\n",
            " 1 1 1 0 0 0 1 0 1 1 1 1 0 0 1 1 0 0 0 1 0 1 0 1 0 0 1 0 0 1 1 0 1 1 0 0 1\n",
            " 1 0 0 1 1 0 1 1 0 1 0 0 1 0 1 0 0 1 0 0 1 0 1 1 1 0 1 0 1 0 0 0 0 1 1 1 1\n",
            " 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 0 0 1 0 0 1 1 1 0 1 1 1 0 1 0 1 0 0 0 0 1 0\n",
            " 1 1 0 1 0 1 1 0 0 0 1 0 1 0 1 0 0 1 0 1 1 1 1 0 1 0 0 1 1 1 1 1 0 1 1 1 1\n",
            " 1 1 1 1 1 0 1 1 1 1 0 1 0 0 1 1 0 1 0 0 1 0 1 1 0 1 0 0 0 0 1 0 1 1 1 0 1\n",
            " 1 1 1 1 1 0 1 0 0 0 1 0 0 0 0 1 1 0 0 1 1 1 0 1 1 1 0 1 1 0 0 1 1 0 1 1 0\n",
            " 0]\n",
            "probabilities: (852, 2) \n",
            " [1 1 1 0 1 1 0 0 0 0 1 1 1 0 1 0 0 0 1 1 0 1 1 1 0 0 0 0 1 0 0 0 1 0 1 1 1\n",
            " 0 0 1 1 1 1 1 0 1 0 1 1 0 1 1 1 1 1 1 0 1 0 1 0 1 0 0 0 0 1 0 0 1 1 1 1 1\n",
            " 0 1 0 1 1 0 0 0 1 1 0 1 0 0 1 1 1 1 0 1 0 1 0 0 1 0 0 0 1 0 1 0 1 1 0 1 1\n",
            " 1 1 1 1 1 0 1 0 1 1 0 0 1 1 0 1 1 0 1 0 0 0 1 0 1 1 1 0 1 1 0 1 0 0 1 1 0\n",
            " 1 1 1 0 0 0 0 0 1 1 1 0 1 0 0 0 0 0 1 0 1 0 0 0 1 0 1 1 0 1 1 0 1 0 0 0 0\n",
            " 1 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 0 1 1 1 1 1 0 1 1 0 1 1 1 0 1 1 0 1 1 1 1\n",
            " 1 1 0 0 1 0 1 1 0 0 0 1 1 0 0 0 0 0 1 0 1 0 0 1 0 1 0 1 0 1 0 0 0 1 0 0 0\n",
            " 0 0 0 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 0 1 1 0 0 1 1 0 0 1 0 1 0 1 0 1 0 1 1\n",
            " 1 0 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 0 1 1 0 1\n",
            " 1 0 1 0 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 0 0 0 0 1 1 0 1\n",
            " 1 0 0 1 0 1 0 1 0 1 1 1 0 1 1 1 1 1 0 1 0 1 0 1 1 0 0 1 0 0 0 1 1 1 1 1 1\n",
            " 0 0 0 1 1 0 0 1 0 0 1 0 0 0 0 0 1 1 0 0 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 0 1\n",
            " 1 0 0 0 1 1 0 0 1 0 1 1 0 0 1 1 0 1 0 1 0 0 0 0 1 0 1 1 0 1 1 0 1 1 0 1 1\n",
            " 1 1 0 1 1 1 0 1 1 1 1 1 1 0 0 0 1 0 1 1 1 1 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1\n",
            " 1 1 0 1 1 1 0 1 1 0 0 1 0 1 0 0 1 0 0 1 1 1 1 1 0 0 1 1 0 1 1 1 1 1 0 1 0\n",
            " 1 0 0 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 0 1 0 0 1 1 1 1 0 1 1 1 0 1 1 1 0 1\n",
            " 0 1 0 1 0 1 0 1 0 1 1 0 0 1 0 0 0 1 0 1 0 1 0 0 1 1 1 0 1 0 0 1 0 1 0 1 1\n",
            " 1 1 1 0 0 0 1 0 1 1 1 1 0 0 1 1 0 0 0 1 0 1 0 1 0 0 1 0 0 1 1 0 1 1 0 0 1\n",
            " 1 0 0 1 1 0 1 1 0 1 0 0 1 0 1 0 0 1 0 0 1 0 1 1 1 0 1 0 1 0 0 0 0 1 1 1 1\n",
            " 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 0 0 1 0 0 1 1 1 0 1 1 1 0 1 0 1 0 0 0 0 1 0\n",
            " 1 1 0 1 0 1 1 0 0 0 1 0 1 0 1 0 0 1 0 1 1 1 1 0 1 0 0 1 1 1 1 1 0 1 1 1 1\n",
            " 1 1 1 1 1 0 1 1 1 1 0 1 0 0 1 1 0 1 0 0 1 0 1 1 0 1 0 0 0 0 1 0 1 1 1 0 1\n",
            " 1 1 1 1 1 0 1 0 0 0 1 0 0 0 0 1 1 0 0 1 1 1 0 1 1 1 0 1 1 0 0 1 1 0 1 1 0\n",
            " 0]\n",
            "trainset before adding uncertain samples (450, 10) (450,)\n",
            "trainset after adding uncertain samples (475, 10) (475,)\n",
            "updated train set: (475, 10) (475,) unique(labels): [237 238] [0 1]\n",
            "val set: (827, 10) (827,)\n",
            "\n",
            "Train set: (475, 10)\n",
            "Validation set: (827, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 19\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.281 s \n",
            "\n",
            "Accuracy rate is 79.953917 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.87      0.87       321\n",
            "           1       0.62      0.60      0.61       113\n",
            "\n",
            "    accuracy                           0.80       434\n",
            "   macro avg       0.74      0.74      0.74       434\n",
            "weighted avg       0.80      0.80      0.80       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[279  42]\n",
            " [ 45  68]]\n",
            "--------------------------------\n",
            "val predicted: (827,) [1 1 1 0 1 1 0 0 0 1 1 1 0 1 0 0 0 1 1 0 1 1 1 0 0 0 1 0 0 0 1 0 1 1 1 0 0\n",
            " 1 1 1 1 1 0 1 0 1 1 0 1 1 1 1 1 1 0 1 0 1 0 1 0 0 1 0 0 1 1 1 1 1 0 1 0 1\n",
            " 1 0 0 0 1 1 0 1 0 0 1 1 1 1 0 1 0 1 0 0 1 0 0 0 1 0 1 0 1 0 1 1 1 1 1 1 1\n",
            " 0 1 0 1 1 0 0 1 1 0 1 1 0 1 0 0 1 0 1 1 1 0 1 1 0 1 0 0 1 1 0 1 1 1 0 0 0\n",
            " 0 0 1 1 1 0 1 0 0 0 0 0 1 0 1 0 0 0 1 0 1 1 0 1 1 0 1 0 0 0 0 1 0 1 1 1 1\n",
            " 1 1 1 1 0 0 1 1 1 0 1 1 1 1 1 0 1 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0 1 0 1\n",
            " 1 0 0 0 1 1 0 0 0 0 0 1 0 1 0 0 1 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0 1 1 1 1\n",
            " 1 1 1 0 1 1 1 0 1 0 1 0 1 1 0 0 1 1 0 0 1 0 1 0 1 0 1 1 0 0 1 1 1 1 0 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 0 1 1 0 1 1 0 1 0 1 0 1 1 1 1\n",
            " 0 1 1 0 1 1 1 1 1 1 0 1 1 0 1 1 1 1 0 0 0 0 1 1 0 1 1 0 0 1 0 1 0 1 0 1 1\n",
            " 0 1 1 1 1 1 0 1 0 1 1 0 0 1 0 0 0 1 1 1 1 1 1 0 0 0 1 1 0 1 0 0 1 0 0 0 0\n",
            " 0 1 1 0 0 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 0 1 1 0 0 0 1 1 0 0 1 0 1 1 0 0 1\n",
            " 1 0 1 0 1 0 0 0 0 1 0 1 1 0 1 1 0 1 1 0 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 0 0\n",
            " 0 1 0 1 1 1 1 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 1 1 0 1 1 1 0 1 1 0 0 1 0 1 0\n",
            " 0 1 0 0 1 1 1 1 1 0 0 1 0 1 1 1 1 1 0 1 0 1 0 0 1 0 1 1 1 1 1 0 1 1 1 1 1\n",
            " 1 0 1 0 1 0 0 1 1 1 1 0 1 1 1 0 1 1 1 0 1 0 1 0 1 0 1 1 0 1 0 0 1 0 0 0 1\n",
            " 0 1 1 0 0 1 1 1 1 0 0 1 0 1 0 1 1 1 1 1 0 0 0 1 0 1 1 1 1 0 0 1 1 0 0 0 1\n",
            " 0 1 0 1 0 0 1 0 0 1 1 0 1 1 0 0 1 1 0 0 1 1 0 1 1 0 1 0 0 1 0 1 0 0 1 0 0\n",
            " 1 0 1 1 1 0 1 0 1 0 0 0 0 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 0 0 1 0 0 1 1\n",
            " 1 0 1 1 1 0 1 0 1 0 0 0 0 1 0 1 1 0 1 0 1 1 0 0 0 1 0 1 0 1 0 0 1 0 1 1 1\n",
            " 1 0 1 0 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 0 0 1 1 0 1 0 0 1 0\n",
            " 1 1 1 0 0 0 0 1 0 1 1 1 0 1 1 1 1 1 1 0 1 0 0 1 0 0 0 0 1 1 0 1 1 1 0 1 1\n",
            " 1 0 1 1 0 0 1 1 0 1 1 0 0]\n",
            "probabilities: (827, 2) \n",
            " [1 1 1 0 1 1 0 0 0 1 1 1 0 1 0 0 0 1 1 0 1 1 1 0 0 0 1 0 0 0 1 0 1 1 1 0 0\n",
            " 1 1 1 1 1 0 1 0 1 1 0 1 1 1 1 1 1 0 1 0 1 0 1 0 0 1 0 0 1 1 1 1 1 0 1 0 1\n",
            " 1 0 0 0 1 1 0 1 0 0 1 1 1 1 0 1 0 1 0 0 1 0 0 0 1 0 1 0 1 0 1 1 1 1 1 1 1\n",
            " 0 1 0 1 1 0 0 1 1 0 1 1 0 1 0 0 1 0 1 1 1 0 1 1 0 1 0 0 1 1 0 1 1 1 0 0 0\n",
            " 0 0 1 1 1 0 1 0 0 0 0 0 1 0 1 0 0 0 1 0 1 1 0 1 1 0 1 0 0 0 0 1 0 1 1 1 1\n",
            " 1 1 1 1 0 0 1 1 1 0 1 1 1 1 1 0 1 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0 1 0 1\n",
            " 1 0 0 0 1 1 0 0 0 0 0 1 0 1 0 0 1 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0 1 1 1 1\n",
            " 1 1 1 0 1 1 1 0 1 0 1 0 1 1 0 0 1 1 0 0 1 0 1 0 1 0 1 1 0 0 1 1 1 1 0 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 0 1 1 0 1 1 0 1 0 1 0 1 1 1 1\n",
            " 0 1 1 0 1 1 1 1 1 1 0 1 1 0 1 1 1 1 0 0 0 0 1 1 0 1 1 0 0 1 0 1 0 1 0 1 1\n",
            " 0 1 1 1 1 1 0 1 0 1 1 0 0 1 0 0 0 1 1 1 1 1 1 0 0 0 1 1 0 1 0 0 1 0 0 0 0\n",
            " 0 1 1 0 0 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 0 1 1 0 0 0 1 1 0 0 1 0 1 1 0 0 1\n",
            " 1 0 1 0 1 0 0 0 0 1 0 1 1 0 1 1 0 1 1 0 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 0 0\n",
            " 0 1 0 1 1 1 1 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 1 1 0 1 1 1 0 1 1 0 0 1 0 1 0\n",
            " 0 1 0 0 1 1 1 1 1 0 0 1 0 1 1 1 1 1 0 1 0 1 0 0 1 0 1 1 1 1 1 0 1 1 1 1 1\n",
            " 1 0 1 0 1 0 0 1 1 1 1 0 1 1 1 0 1 1 1 0 1 0 1 0 1 0 1 1 0 1 0 0 1 0 0 0 1\n",
            " 0 1 1 0 0 1 1 1 1 0 0 1 0 1 0 1 1 1 1 1 0 0 0 1 0 1 1 1 1 0 0 1 1 0 0 0 1\n",
            " 0 1 0 1 0 0 1 0 0 1 1 0 1 1 0 0 1 1 0 0 1 1 0 1 1 0 1 0 0 1 0 1 0 0 1 0 0\n",
            " 1 0 1 1 1 0 1 0 1 0 0 0 0 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 0 0 1 0 0 1 1\n",
            " 1 0 1 1 1 0 1 0 1 0 0 0 0 1 0 1 1 0 1 0 1 1 0 0 0 1 0 1 0 1 0 0 1 0 1 1 1\n",
            " 1 0 1 0 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 0 0 1 1 0 1 0 0 1 0\n",
            " 1 1 1 0 0 0 0 1 0 1 1 1 0 1 1 1 1 1 1 0 1 0 0 1 0 0 0 0 1 1 0 1 1 1 0 1 1\n",
            " 1 0 1 1 0 0 1 1 0 1 1 0 0]\n",
            "trainset before adding uncertain samples (475, 10) (475,)\n",
            "trainset after adding uncertain samples (500, 10) (500,)\n",
            "updated train set: (500, 10) (500,) unique(labels): [256 244] [0 1]\n",
            "val set: (802, 10) (802,)\n",
            "\n",
            "Train set: (500, 10)\n",
            "Validation set: (802, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 20\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.308 s \n",
            "\n",
            "Accuracy rate is 79.723502 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.88      0.86       321\n",
            "           1       0.62      0.58      0.60       113\n",
            "\n",
            "    accuracy                           0.80       434\n",
            "   macro avg       0.74      0.73      0.73       434\n",
            "weighted avg       0.79      0.80      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[281  40]\n",
            " [ 48  65]]\n",
            "--------------------------------\n",
            "final active learning accuracies [74.65437788018433, 69.81566820276498, 80.18433179723502, 72.11981566820278, 72.81105990783409, 73.73271889400922, 73.50230414746544, 78.57142857142857, 78.57142857142857, 81.10599078341014, 80.64516129032258, 78.80184331797236, 79.26267281105991, 80.18433179723502, 79.72350230414746, 79.26267281105991, 79.95391705069125, 79.72350230414746, 79.95391705069125, 79.72350230414746]\n",
            "saved /Users/wenxuanhuang/Documents/Repo/ML-for-COVID-19-dataset/Results/Active-learning-experiment-9.pkl /Users/wenxuanhuang/Documents/Repo/ML-for-COVID-19-dataset ['Decision_tree.ipynb', 'dec_git.png', 'Logit_default_f10.pdf', 'Logistic.ipynb', 'SVC.ipynb', 'RF_f5e50_featureimp.pdf', 'log_al.png', 'dec_git.pdf', '.DS_Store', 'log_git.png', 'svm_git.png', 'Logistic_Scikit.ipynb', 'knn_git.pdf', 'knn_git.png', 'rf_al.png', 'Best classifier_RF_f5e50.pdf', 'KNN.ipynb', 'GBDC.ipynb', 'rf_git.png', 'README.md', 'all_training.csv', 'Results', 'svm_al.png', 'Log_ROC.png', 'Logit_default_f7(p_removal).pdf', 'Active_learning.ipynb', 'Random_forest.ipynb', 'Model_select.ipynb', 'gdbc_git.png', '.git', '.vscode', 'Untitled', 'RF_f5e50_modelselect.pdf', 'Logit_default_f8(std_removal).pdf']\n",
            "\n",
            "---------------------------- FINISHED ---------------------------\n",
            "\n",
            "Count = 10, using model = GDBCModel, selection_function = MarginSamplingSelection, k = 10, iteration = 0.\n",
            "\n",
            "initial random chosen samples (10,)\n",
            "initial train set: (10, 10) (10,) unique(labels): [4 6] [0 1]\n",
            "Val set: (1292, 10) (1292,) (10,)\n",
            "\n",
            "Train set: (10, 10)\n",
            "Validation set: (1292, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.557 s \n",
            "\n",
            "Accuracy rate is 49.078341 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.45      0.56       321\n",
            "           1       0.28      0.62      0.39       113\n",
            "\n",
            "    accuracy                           0.49       434\n",
            "   macro avg       0.53      0.53      0.48       434\n",
            "weighted avg       0.64      0.49      0.52       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[143 178]\n",
            " [ 43  70]]\n",
            "--------------------------------\n",
            "val predicted: (1292,) [1 1 1 ... 1 0 0]\n",
            "probabilities: (1292, 2) \n",
            " [1 1 1 ... 1 0 0]\n",
            "trainset before adding uncertain samples (10, 10) (10,)\n",
            "trainset after adding uncertain samples (20, 10) (20,)\n",
            "updated train set: (20, 10) (20,) unique(labels): [ 8 12] [0 1]\n",
            "val set: (1282, 10) (1282,)\n",
            "\n",
            "Train set: (20, 10)\n",
            "Validation set: (1282, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.618 s \n",
            "\n",
            "Accuracy rate is 63.133641 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.61      0.71       321\n",
            "           1       0.39      0.70      0.50       113\n",
            "\n",
            "    accuracy                           0.63       434\n",
            "   macro avg       0.62      0.65      0.60       434\n",
            "weighted avg       0.73      0.63      0.65       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[195 126]\n",
            " [ 34  79]]\n",
            "--------------------------------\n",
            "val predicted: (1282,) [1 1 1 ... 1 0 1]\n",
            "probabilities: (1282, 2) \n",
            " [1 1 1 ... 1 0 1]\n",
            "trainset before adding uncertain samples (20, 10) (20,)\n",
            "trainset after adding uncertain samples (30, 10) (30,)\n",
            "updated train set: (30, 10) (30,) unique(labels): [14 16] [0 1]\n",
            "val set: (1272, 10) (1272,)\n",
            "\n",
            "Train set: (30, 10)\n",
            "Validation set: (1272, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 3\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.707 s \n",
            "\n",
            "Accuracy rate is 72.580645 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.74      0.80       321\n",
            "           1       0.48      0.68      0.56       113\n",
            "\n",
            "    accuracy                           0.73       434\n",
            "   macro avg       0.67      0.71      0.68       434\n",
            "weighted avg       0.77      0.73      0.74       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[238  83]\n",
            " [ 36  77]]\n",
            "--------------------------------\n",
            "val predicted: (1272,) [1 0 1 ... 0 0 0]\n",
            "probabilities: (1272, 2) \n",
            " [1 0 1 ... 0 0 0]\n",
            "trainset before adding uncertain samples (30, 10) (30,)\n",
            "trainset after adding uncertain samples (40, 10) (40,)\n",
            "updated train set: (40, 10) (40,) unique(labels): [21 19] [0 1]\n",
            "val set: (1262, 10) (1262,)\n",
            "\n",
            "Train set: (40, 10)\n",
            "Validation set: (1262, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 4\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.836 s \n",
            "\n",
            "Accuracy rate is 68.894009 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.70      0.77       321\n",
            "           1       0.43      0.65      0.52       113\n",
            "\n",
            "    accuracy                           0.69       434\n",
            "   macro avg       0.64      0.68      0.64       434\n",
            "weighted avg       0.74      0.69      0.70       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[226  95]\n",
            " [ 40  73]]\n",
            "--------------------------------\n",
            "val predicted: (1262,) [1 0 1 ... 1 0 0]\n",
            "probabilities: (1262, 2) \n",
            " [1 0 1 ... 1 0 0]\n",
            "trainset before adding uncertain samples (40, 10) (40,)\n",
            "trainset after adding uncertain samples (50, 10) (50,)\n",
            "updated train set: (50, 10) (50,) unique(labels): [29 21] [0 1]\n",
            "val set: (1252, 10) (1252,)\n",
            "\n",
            "Train set: (50, 10)\n",
            "Validation set: (1252, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 5\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.880 s \n",
            "\n",
            "Accuracy rate is 72.580645 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.79      0.81       321\n",
            "           1       0.48      0.54      0.51       113\n",
            "\n",
            "    accuracy                           0.73       434\n",
            "   macro avg       0.65      0.67      0.66       434\n",
            "weighted avg       0.74      0.73      0.73       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[254  67]\n",
            " [ 52  61]]\n",
            "--------------------------------\n",
            "val predicted: (1252,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1252, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "trainset before adding uncertain samples (50, 10) (50,)\n",
            "trainset after adding uncertain samples (60, 10) (60,)\n",
            "updated train set: (60, 10) (60,) unique(labels): [33 27] [0 1]\n",
            "val set: (1242, 10) (1242,)\n",
            "\n",
            "Train set: (60, 10)\n",
            "Validation set: (1242, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 6\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.861 s \n",
            "\n",
            "Accuracy rate is 76.036866 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.82      0.83       321\n",
            "           1       0.54      0.59      0.56       113\n",
            "\n",
            "    accuracy                           0.76       434\n",
            "   macro avg       0.69      0.71      0.70       434\n",
            "weighted avg       0.77      0.76      0.76       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[263  58]\n",
            " [ 46  67]]\n",
            "--------------------------------\n",
            "val predicted: (1242,) [1 1 1 ... 0 0 0]\n",
            "probabilities: (1242, 2) \n",
            " [1 1 1 ... 0 0 0]\n",
            "trainset before adding uncertain samples (60, 10) (60,)\n",
            "trainset after adding uncertain samples (70, 10) (70,)\n",
            "updated train set: (70, 10) (70,) unique(labels): [36 34] [0 1]\n",
            "val set: (1232, 10) (1232,)\n",
            "\n",
            "Train set: (70, 10)\n",
            "Validation set: (1232, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 7\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.746 s \n",
            "\n",
            "Accuracy rate is 75.345622 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.80      0.83       321\n",
            "           1       0.52      0.63      0.57       113\n",
            "\n",
            "    accuracy                           0.75       434\n",
            "   macro avg       0.69      0.71      0.70       434\n",
            "weighted avg       0.77      0.75      0.76       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[256  65]\n",
            " [ 42  71]]\n",
            "--------------------------------\n",
            "val predicted: (1232,) [1 1 1 ... 0 0 0]\n",
            "probabilities: (1232, 2) \n",
            " [1 1 1 ... 0 0 0]\n",
            "trainset before adding uncertain samples (70, 10) (70,)\n",
            "trainset after adding uncertain samples (80, 10) (80,)\n",
            "updated train set: (80, 10) (80,) unique(labels): [39 41] [0 1]\n",
            "val set: (1222, 10) (1222,)\n",
            "\n",
            "Train set: (80, 10)\n",
            "Validation set: (1222, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 8\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.817 s \n",
            "\n",
            "Accuracy rate is 74.193548 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.77      0.82       321\n",
            "           1       0.50      0.66      0.57       113\n",
            "\n",
            "    accuracy                           0.74       434\n",
            "   macro avg       0.69      0.72      0.69       434\n",
            "weighted avg       0.77      0.74      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[247  74]\n",
            " [ 38  75]]\n",
            "--------------------------------\n",
            "val predicted: (1222,) [1 1 1 ... 0 0 0]\n",
            "probabilities: (1222, 2) \n",
            " [1 1 1 ... 0 0 0]\n",
            "trainset before adding uncertain samples (80, 10) (80,)\n",
            "trainset after adding uncertain samples (90, 10) (90,)\n",
            "updated train set: (90, 10) (90,) unique(labels): [44 46] [0 1]\n",
            "val set: (1212, 10) (1212,)\n",
            "\n",
            "Train set: (90, 10)\n",
            "Validation set: (1212, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 9\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.795 s \n",
            "\n",
            "Accuracy rate is 74.654378 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.79      0.82       321\n",
            "           1       0.51      0.63      0.56       113\n",
            "\n",
            "    accuracy                           0.75       434\n",
            "   macro avg       0.68      0.71      0.69       434\n",
            "weighted avg       0.77      0.75      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[253  68]\n",
            " [ 42  71]]\n",
            "--------------------------------\n",
            "val predicted: (1212,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1212, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "trainset before adding uncertain samples (90, 10) (90,)\n",
            "trainset after adding uncertain samples (100, 10) (100,)\n",
            "updated train set: (100, 10) (100,) unique(labels): [48 52] [0 1]\n",
            "val set: (1202, 10) (1202,)\n",
            "\n",
            "Train set: (100, 10)\n",
            "Validation set: (1202, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 10\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.825 s \n",
            "\n",
            "Accuracy rate is 73.732719 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.77      0.81       321\n",
            "           1       0.50      0.65      0.56       113\n",
            "\n",
            "    accuracy                           0.74       434\n",
            "   macro avg       0.68      0.71      0.69       434\n",
            "weighted avg       0.77      0.74      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[246  75]\n",
            " [ 39  74]]\n",
            "--------------------------------\n",
            "val predicted: (1202,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1202, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "trainset before adding uncertain samples (100, 10) (100,)\n",
            "trainset after adding uncertain samples (110, 10) (110,)\n",
            "updated train set: (110, 10) (110,) unique(labels): [55 55] [0 1]\n",
            "val set: (1192, 10) (1192,)\n",
            "\n",
            "Train set: (110, 10)\n",
            "Validation set: (1192, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 11\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.819 s \n",
            "\n",
            "Accuracy rate is 75.115207 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.79      0.82       321\n",
            "           1       0.52      0.65      0.58       113\n",
            "\n",
            "    accuracy                           0.75       434\n",
            "   macro avg       0.69      0.72      0.70       434\n",
            "weighted avg       0.78      0.75      0.76       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[252  69]\n",
            " [ 39  74]]\n",
            "--------------------------------\n",
            "val predicted: (1192,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1192, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "trainset before adding uncertain samples (110, 10) (110,)\n",
            "trainset after adding uncertain samples (120, 10) (120,)\n",
            "updated train set: (120, 10) (120,) unique(labels): [62 58] [0 1]\n",
            "val set: (1182, 10) (1182,)\n",
            "\n",
            "Train set: (120, 10)\n",
            "Validation set: (1182, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 12\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.832 s \n",
            "\n",
            "Accuracy rate is 70.506912 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.71      0.78       321\n",
            "           1       0.46      0.68      0.55       113\n",
            "\n",
            "    accuracy                           0.71       434\n",
            "   macro avg       0.66      0.70      0.66       434\n",
            "weighted avg       0.76      0.71      0.72       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[229  92]\n",
            " [ 36  77]]\n",
            "--------------------------------\n",
            "val predicted: (1182,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1182, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "trainset before adding uncertain samples (120, 10) (120,)\n",
            "trainset after adding uncertain samples (130, 10) (130,)\n",
            "updated train set: (130, 10) (130,) unique(labels): [71 59] [0 1]\n",
            "val set: (1172, 10) (1172,)\n",
            "\n",
            "Train set: (130, 10)\n",
            "Validation set: (1172, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 13\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.869 s \n",
            "\n",
            "Accuracy rate is 75.576037 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.80      0.83       321\n",
            "           1       0.53      0.62      0.57       113\n",
            "\n",
            "    accuracy                           0.76       434\n",
            "   macro avg       0.69      0.71      0.70       434\n",
            "weighted avg       0.77      0.76      0.76       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[258  63]\n",
            " [ 43  70]]\n",
            "--------------------------------\n",
            "val predicted: (1172,) [1 1 1 ... 0 0 0]\n",
            "probabilities: (1172, 2) \n",
            " [1 1 1 ... 0 0 0]\n",
            "trainset before adding uncertain samples (130, 10) (130,)\n",
            "trainset after adding uncertain samples (140, 10) (140,)\n",
            "updated train set: (140, 10) (140,) unique(labels): [76 64] [0 1]\n",
            "val set: (1162, 10) (1162,)\n",
            "\n",
            "Train set: (140, 10)\n",
            "Validation set: (1162, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 14\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.869 s \n",
            "\n",
            "Accuracy rate is 75.345622 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.80      0.83       321\n",
            "           1       0.52      0.61      0.56       113\n",
            "\n",
            "    accuracy                           0.75       434\n",
            "   macro avg       0.69      0.71      0.70       434\n",
            "weighted avg       0.77      0.75      0.76       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[258  63]\n",
            " [ 44  69]]\n",
            "--------------------------------\n",
            "val predicted: (1162,) [1 1 0 ... 0 0 0]\n",
            "probabilities: (1162, 2) \n",
            " [1 1 0 ... 0 0 0]\n",
            "trainset before adding uncertain samples (140, 10) (140,)\n",
            "trainset after adding uncertain samples (150, 10) (150,)\n",
            "updated train set: (150, 10) (150,) unique(labels): [79 71] [0 1]\n",
            "val set: (1152, 10) (1152,)\n",
            "\n",
            "Train set: (150, 10)\n",
            "Validation set: (1152, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 15\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.886 s \n",
            "\n",
            "Accuracy rate is 75.115207 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.80      0.83       321\n",
            "           1       0.52      0.61      0.56       113\n",
            "\n",
            "    accuracy                           0.75       434\n",
            "   macro avg       0.69      0.71      0.69       434\n",
            "weighted avg       0.77      0.75      0.76       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[257  64]\n",
            " [ 44  69]]\n",
            "--------------------------------\n",
            "val predicted: (1152,) [1 1 0 ... 0 0 0]\n",
            "probabilities: (1152, 2) \n",
            " [1 1 0 ... 0 0 0]\n",
            "trainset before adding uncertain samples (150, 10) (150,)\n",
            "trainset after adding uncertain samples (160, 10) (160,)\n",
            "updated train set: (160, 10) (160,) unique(labels): [85 75] [0 1]\n",
            "val set: (1142, 10) (1142,)\n",
            "\n",
            "Train set: (160, 10)\n",
            "Validation set: (1142, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 16\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.910 s \n",
            "\n",
            "Accuracy rate is 75.806452 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.81      0.83       321\n",
            "           1       0.53      0.62      0.57       113\n",
            "\n",
            "    accuracy                           0.76       434\n",
            "   macro avg       0.69      0.71      0.70       434\n",
            "weighted avg       0.77      0.76      0.76       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[259  62]\n",
            " [ 43  70]]\n",
            "--------------------------------\n",
            "val predicted: (1142,) [1 1 0 ... 0 0 0]\n",
            "probabilities: (1142, 2) \n",
            " [1 1 0 ... 0 0 0]\n",
            "trainset before adding uncertain samples (160, 10) (160,)\n",
            "trainset after adding uncertain samples (170, 10) (170,)\n",
            "updated train set: (170, 10) (170,) unique(labels): [94 76] [0 1]\n",
            "val set: (1132, 10) (1132,)\n",
            "\n",
            "Train set: (170, 10)\n",
            "Validation set: (1132, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 17\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.915 s \n",
            "\n",
            "Accuracy rate is 76.728111 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.83      0.84       321\n",
            "           1       0.55      0.60      0.57       113\n",
            "\n",
            "    accuracy                           0.77       434\n",
            "   macro avg       0.70      0.71      0.71       434\n",
            "weighted avg       0.78      0.77      0.77       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[265  56]\n",
            " [ 45  68]]\n",
            "--------------------------------\n",
            "val predicted: (1132,) [1 1 0 ... 0 0 0]\n",
            "probabilities: (1132, 2) \n",
            " [1 1 0 ... 0 0 0]\n",
            "trainset before adding uncertain samples (170, 10) (170,)\n",
            "trainset after adding uncertain samples (180, 10) (180,)\n",
            "updated train set: (180, 10) (180,) unique(labels): [97 83] [0 1]\n",
            "val set: (1122, 10) (1122,)\n",
            "\n",
            "Train set: (180, 10)\n",
            "Validation set: (1122, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 18\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.931 s \n",
            "\n",
            "Accuracy rate is 76.497696 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.82      0.84       321\n",
            "           1       0.54      0.62      0.58       113\n",
            "\n",
            "    accuracy                           0.76       434\n",
            "   macro avg       0.70      0.72      0.71       434\n",
            "weighted avg       0.78      0.76      0.77       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[262  59]\n",
            " [ 43  70]]\n",
            "--------------------------------\n",
            "val predicted: (1122,) [1 1 0 ... 0 0 0]\n",
            "probabilities: (1122, 2) \n",
            " [1 1 0 ... 0 0 0]\n",
            "trainset before adding uncertain samples (180, 10) (180,)\n",
            "trainset after adding uncertain samples (190, 10) (190,)\n",
            "updated train set: (190, 10) (190,) unique(labels): [102  88] [0 1]\n",
            "val set: (1112, 10) (1112,)\n",
            "\n",
            "Train set: (190, 10)\n",
            "Validation set: (1112, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 19\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.955 s \n",
            "\n",
            "Accuracy rate is 77.419355 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.84      0.85       321\n",
            "           1       0.56      0.59      0.58       113\n",
            "\n",
            "    accuracy                           0.77       434\n",
            "   macro avg       0.71      0.72      0.71       434\n",
            "weighted avg       0.78      0.77      0.78       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[269  52]\n",
            " [ 46  67]]\n",
            "--------------------------------\n",
            "val predicted: (1112,) [1 1 0 ... 0 0 0]\n",
            "probabilities: (1112, 2) \n",
            " [1 1 0 ... 0 0 0]\n",
            "trainset before adding uncertain samples (190, 10) (190,)\n",
            "trainset after adding uncertain samples (200, 10) (200,)\n",
            "updated train set: (200, 10) (200,) unique(labels): [106  94] [0 1]\n",
            "val set: (1102, 10) (1102,)\n",
            "\n",
            "Train set: (200, 10)\n",
            "Validation set: (1102, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 20\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.955 s \n",
            "\n",
            "Accuracy rate is 77.188940 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.84      0.84       321\n",
            "           1       0.56      0.58      0.57       113\n",
            "\n",
            "    accuracy                           0.77       434\n",
            "   macro avg       0.71      0.71      0.71       434\n",
            "weighted avg       0.78      0.77      0.77       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[269  52]\n",
            " [ 47  66]]\n",
            "--------------------------------\n",
            "val predicted: (1102,) [1 1 0 ... 0 0 0]\n",
            "probabilities: (1102, 2) \n",
            " [1 1 0 ... 0 0 0]\n",
            "trainset before adding uncertain samples (200, 10) (200,)\n",
            "trainset after adding uncertain samples (210, 10) (210,)\n",
            "updated train set: (210, 10) (210,) unique(labels): [110 100] [0 1]\n",
            "val set: (1092, 10) (1092,)\n",
            "\n",
            "Train set: (210, 10)\n",
            "Validation set: (1092, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 21\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.961 s \n",
            "\n",
            "Accuracy rate is 77.419355 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.83      0.84       321\n",
            "           1       0.56      0.61      0.58       113\n",
            "\n",
            "    accuracy                           0.77       434\n",
            "   macro avg       0.71      0.72      0.71       434\n",
            "weighted avg       0.78      0.77      0.78       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[267  54]\n",
            " [ 44  69]]\n",
            "--------------------------------\n",
            "val predicted: (1092,) [1 1 0 ... 0 0 0]\n",
            "probabilities: (1092, 2) \n",
            " [1 1 0 ... 0 0 0]\n",
            "trainset before adding uncertain samples (210, 10) (210,)\n",
            "trainset after adding uncertain samples (220, 10) (220,)\n",
            "updated train set: (220, 10) (220,) unique(labels): [115 105] [0 1]\n",
            "val set: (1082, 10) (1082,)\n",
            "\n",
            "Train set: (220, 10)\n",
            "Validation set: (1082, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 22\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.989 s \n",
            "\n",
            "Accuracy rate is 76.958525 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.83      0.84       321\n",
            "           1       0.55      0.59      0.57       113\n",
            "\n",
            "    accuracy                           0.77       434\n",
            "   macro avg       0.70      0.71      0.71       434\n",
            "weighted avg       0.78      0.77      0.77       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[267  54]\n",
            " [ 46  67]]\n",
            "--------------------------------\n",
            "val predicted: (1082,) [1 1 0 ... 0 0 0]\n",
            "probabilities: (1082, 2) \n",
            " [1 1 0 ... 0 0 0]\n",
            "trainset before adding uncertain samples (220, 10) (220,)\n",
            "trainset after adding uncertain samples (230, 10) (230,)\n",
            "updated train set: (230, 10) (230,) unique(labels): [122 108] [0 1]\n",
            "val set: (1072, 10) (1072,)\n",
            "\n",
            "Train set: (230, 10)\n",
            "Validation set: (1072, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 23\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.989 s \n",
            "\n",
            "Accuracy rate is 78.801843 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.86      0.86       321\n",
            "           1       0.59      0.59      0.59       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.72      0.72      0.72       434\n",
            "weighted avg       0.79      0.79      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[275  46]\n",
            " [ 46  67]]\n",
            "--------------------------------\n",
            "val predicted: (1072,) [1 1 0 ... 0 0 0]\n",
            "probabilities: (1072, 2) \n",
            " [1 1 0 ... 0 0 0]\n",
            "trainset before adding uncertain samples (230, 10) (230,)\n",
            "trainset after adding uncertain samples (240, 10) (240,)\n",
            "updated train set: (240, 10) (240,) unique(labels): [129 111] [0 1]\n",
            "val set: (1062, 10) (1062,)\n",
            "\n",
            "Train set: (240, 10)\n",
            "Validation set: (1062, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 24\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.012 s \n",
            "\n",
            "Accuracy rate is 78.341014 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.85      0.85       321\n",
            "           1       0.58      0.58      0.58       113\n",
            "\n",
            "    accuracy                           0.78       434\n",
            "   macro avg       0.72      0.72      0.72       434\n",
            "weighted avg       0.78      0.78      0.78       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[274  47]\n",
            " [ 47  66]]\n",
            "--------------------------------\n",
            "val predicted: (1062,) [1 1 0 ... 0 0 0]\n",
            "probabilities: (1062, 2) \n",
            " [1 1 0 ... 0 0 0]\n",
            "trainset before adding uncertain samples (240, 10) (240,)\n",
            "trainset after adding uncertain samples (250, 10) (250,)\n",
            "updated train set: (250, 10) (250,) unique(labels): [134 116] [0 1]\n",
            "val set: (1052, 10) (1052,)\n",
            "\n",
            "Train set: (250, 10)\n",
            "Validation set: (1052, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 25\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.036 s \n",
            "\n",
            "Accuracy rate is 78.571429 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.86      0.86       321\n",
            "           1       0.59      0.58      0.59       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.72      0.72      0.72       434\n",
            "weighted avg       0.79      0.79      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[275  46]\n",
            " [ 47  66]]\n",
            "--------------------------------\n",
            "val predicted: (1052,) [1 1 0 ... 0 0 0]\n",
            "probabilities: (1052, 2) \n",
            " [1 1 0 ... 0 0 0]\n",
            "trainset before adding uncertain samples (250, 10) (250,)\n",
            "trainset after adding uncertain samples (260, 10) (260,)\n",
            "updated train set: (260, 10) (260,) unique(labels): [140 120] [0 1]\n",
            "val set: (1042, 10) (1042,)\n",
            "\n",
            "Train set: (260, 10)\n",
            "Validation set: (1042, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 26\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.038 s \n",
            "\n",
            "Accuracy rate is 79.723502 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.86      0.86       321\n",
            "           1       0.61      0.61      0.61       113\n",
            "\n",
            "    accuracy                           0.80       434\n",
            "   macro avg       0.74      0.74      0.74       434\n",
            "weighted avg       0.80      0.80      0.80       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[277  44]\n",
            " [ 44  69]]\n",
            "--------------------------------\n",
            "val predicted: (1042,) [1 1 0 ... 0 0 0]\n",
            "probabilities: (1042, 2) \n",
            " [1 1 0 ... 0 0 0]\n",
            "trainset before adding uncertain samples (260, 10) (260,)\n",
            "trainset after adding uncertain samples (270, 10) (270,)\n",
            "updated train set: (270, 10) (270,) unique(labels): [146 124] [0 1]\n",
            "val set: (1032, 10) (1032,)\n",
            "\n",
            "Train set: (270, 10)\n",
            "Validation set: (1032, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 27\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.070 s \n",
            "\n",
            "Accuracy rate is 79.723502 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.88      0.86       321\n",
            "           1       0.62      0.58      0.60       113\n",
            "\n",
            "    accuracy                           0.80       434\n",
            "   macro avg       0.74      0.73      0.73       434\n",
            "weighted avg       0.79      0.80      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[281  40]\n",
            " [ 48  65]]\n",
            "--------------------------------\n",
            "val predicted: (1032,) [1 1 0 ... 0 0 0]\n",
            "probabilities: (1032, 2) \n",
            " [1 1 0 ... 0 0 0]\n",
            "trainset before adding uncertain samples (270, 10) (270,)\n",
            "trainset after adding uncertain samples (280, 10) (280,)\n",
            "updated train set: (280, 10) (280,) unique(labels): [151 129] [0 1]\n",
            "val set: (1022, 10) (1022,)\n",
            "\n",
            "Train set: (280, 10)\n",
            "Validation set: (1022, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 28\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.083 s \n",
            "\n",
            "Accuracy rate is 79.262673 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.87      0.86       321\n",
            "           1       0.61      0.58      0.59       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.73      0.73      0.73       434\n",
            "weighted avg       0.79      0.79      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[278  43]\n",
            " [ 47  66]]\n",
            "--------------------------------\n",
            "val predicted: (1022,) [1 1 0 ... 0 0 0]\n",
            "probabilities: (1022, 2) \n",
            " [1 1 0 ... 0 0 0]\n",
            "trainset before adding uncertain samples (280, 10) (280,)\n",
            "trainset after adding uncertain samples (290, 10) (290,)\n",
            "updated train set: (290, 10) (290,) unique(labels): [156 134] [0 1]\n",
            "val set: (1012, 10) (1012,)\n",
            "\n",
            "Train set: (290, 10)\n",
            "Validation set: (1012, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 29\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.087 s \n",
            "\n",
            "Accuracy rate is 79.493088 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.87      0.86       321\n",
            "           1       0.61      0.58      0.60       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.73      0.73      0.73       434\n",
            "weighted avg       0.79      0.79      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[279  42]\n",
            " [ 47  66]]\n",
            "--------------------------------\n",
            "val predicted: (1012,) [1 1 0 ... 0 0 0]\n",
            "probabilities: (1012, 2) \n",
            " [1 1 0 ... 0 0 0]\n",
            "trainset before adding uncertain samples (290, 10) (290,)\n",
            "trainset after adding uncertain samples (300, 10) (300,)\n",
            "updated train set: (300, 10) (300,) unique(labels): [161 139] [0 1]\n",
            "val set: (1002, 10) (1002,)\n",
            "\n",
            "Train set: (300, 10)\n",
            "Validation set: (1002, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 30\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.104 s \n",
            "\n",
            "Accuracy rate is 79.493088 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.87      0.86       321\n",
            "           1       0.61      0.58      0.59       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.73      0.72      0.73       434\n",
            "weighted avg       0.79      0.79      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[280  41]\n",
            " [ 48  65]]\n",
            "--------------------------------\n",
            "val predicted: (1002,) [1 1 0 ... 0 0 0]\n",
            "probabilities: (1002, 2) \n",
            " [1 1 0 ... 0 0 0]\n",
            "trainset before adding uncertain samples (300, 10) (300,)\n",
            "trainset after adding uncertain samples (310, 10) (310,)\n",
            "updated train set: (310, 10) (310,) unique(labels): [165 145] [0 1]\n",
            "val set: (992, 10) (992,)\n",
            "\n",
            "Train set: (310, 10)\n",
            "Validation set: (992, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 31\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.101 s \n",
            "\n",
            "Accuracy rate is 79.262673 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.87      0.86       321\n",
            "           1       0.61      0.58      0.59       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.73      0.73      0.73       434\n",
            "weighted avg       0.79      0.79      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[278  43]\n",
            " [ 47  66]]\n",
            "--------------------------------\n",
            "val predicted: (992,) [1 1 0 0 1 0 0 1 1 0 0 0 1 1 1 0 0 0 0 1 1 1 0 1 1 1 0 0 1 1 0 0 0 1 1 0 1\n",
            " 1 0 1 1 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 0 1 1 1 0 0 1 1 1 1 1 1 0 1 0 0 1 0\n",
            " 1 1 0 0 1 0 0 0 1 1 1 1 1 0 1 0 0 0 1 1 1 0 0 0 0 1 1 0 1 0 1 0 1 0 1 1 1\n",
            " 0 1 0 0 1 0 0 0 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 0\n",
            " 1 1 1 1 0 1 1 0 0 0 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 1 0 1 1 1 0 0 1 1 0 0 0\n",
            " 0 0 1 1 1 0 1 0 0 0 0 0 1 1 0 1 1 0 0 0 1 1 0 1 0 1 1 0 0 1 1 0 0 0 0 0 1\n",
            " 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 0 1 0 1 1 1 1 0 1 1 0 1 1 1 0 1 1 0 1 1 1 0\n",
            " 1 0 1 1 1 1 1 1 1 0 0 1 0 1 1 0 0 0 1 1 1 1 1 1 0 0 0 1 0 1 0 1 0 1 0 1 0\n",
            " 1 0 1 0 1 0 1 0 0 0 0 0 0 1 1 1 1 1 1 1 0 1 1 1 0 1 1 0 1 0 1 0 0 1 1 1 1\n",
            " 0 0 1 1 0 1 0 0 1 0 0 1 1 1 0 0 1 1 1 1 1 0 1 0 0 1 0 0 1 1 1 1 1 1 1 1 1\n",
            " 1 1 0 0 0 1 1 0 1 0 1 1 1 1 0 0 1 0 1 0 1 1 1 1 0 1 1 0 1 0 1 0 1 1 1 1 0\n",
            " 1 1 0 1 1 1 1 1 0 0 0 0 0 1 1 0 0 1 1 0 0 1 0 0 1 0 0 1 1 0 1 0 1 1 1 1 1\n",
            " 1 1 1 1 0 1 0 1 0 1 1 1 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 0 1 0 0\n",
            " 0 0 1 0 0 0 1 1 0 0 1 1 0 1 1 0 1 0 0 1 1 1 1 0 1 1 1 1 1 1 0 1 1 0 0 1 1\n",
            " 0 0 0 1 0 1 1 1 0 1 1 1 1 0 1 0 1 0 0 0 0 1 0 1 1 0 1 1 0 1 1 0 1 1 0 0 1\n",
            " 1 1 1 0 1 1 1 1 1 1 1 1 1 0 0 0 1 0 1 0 1 1 1 1 1 0 1 1 1 0 1 0 0 0 1 0 1\n",
            " 1 0 0 0 1 1 0 1 1 1 1 0 1 1 0 1 1 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 1 1 1 1\n",
            " 1 0 0 0 0 1 0 1 0 1 1 0 1 1 1 1 1 1 1 0 1 0 0 1 1 0 1 1 1 1 1 0 0 1 0 1 0\n",
            " 1 0 1 1 1 1 0 1 1 0 1 1 1 0 0 1 1 1 0 1 0 1 1 1 1 1 0 0 1 0 1 1 0 1 0 0 1\n",
            " 0 1 0 0 1 1 0 1 0 0 1 0 0 1 0 1 0 0 1 1 1 1 0 0 1 0 1 0 0 1 1 1 1 1 0 0 0\n",
            " 0 1 0 1 1 1 0 1 1 0 0 1 0 1 0 0 1 0 0 0 0 1 0 1 1 1 0 1 1 0 0 1 0 0 1 0 1\n",
            " 1 1 0 0 1 0 0 1 1 0 0 1 0 1 1 1 0 1 0 0 1 0 1 1 0 0 1 0 1 0 1 1 1 1 1 0 1\n",
            " 0 0 1 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 0 0 0 1 1 1 1 0 1\n",
            " 1 0 1 0 1 0 0 0 1 0 0 1 0 1 0 1 0 1 1 0 0 1 1 0 1 0 1 1 0 0 0 1 0 1 1 1 1\n",
            " 0 1 1 1 0 0 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 0 0 1 1 1 1 1 0 1 1 0 0 1\n",
            " 1 0 1 0 0 0 1 0 1 1 0 1 0 0 0 1 0 1 1 0 1 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1\n",
            " 0 0 1 1 0 0 1 1 1 0 1 0 0 1 1 1 0 1 1 1 0 0 1 1 1 1 1 0 0 0]\n",
            "probabilities: (992, 2) \n",
            " [1 1 0 0 1 0 0 1 1 0 0 0 1 1 1 0 0 0 0 1 1 1 0 1 1 1 0 0 1 1 0 0 0 1 1 0 1\n",
            " 1 0 1 1 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 0 1 1 1 0 0 1 1 1 1 1 1 0 1 0 0 1 0\n",
            " 1 1 0 0 1 0 0 0 1 1 1 1 1 0 1 0 0 0 1 1 1 0 0 0 0 1 1 0 1 0 1 0 1 0 1 1 1\n",
            " 0 1 0 0 1 0 0 0 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 0\n",
            " 1 1 1 1 0 1 1 0 0 0 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 1 0 1 1 1 0 0 1 1 0 0 0\n",
            " 0 0 1 1 1 0 1 0 0 0 0 0 1 1 0 1 1 0 0 0 1 1 0 1 0 1 1 0 0 1 1 0 0 0 0 0 1\n",
            " 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 0 1 0 1 1 1 1 0 1 1 0 1 1 1 0 1 1 0 1 1 1 0\n",
            " 1 0 1 1 1 1 1 1 1 0 0 1 0 1 1 0 0 0 1 1 1 1 1 1 0 0 0 1 0 1 0 1 0 1 0 1 0\n",
            " 1 0 1 0 1 0 1 0 0 0 0 0 0 1 1 1 1 1 1 1 0 1 1 1 0 1 1 0 1 0 1 0 0 1 1 1 1\n",
            " 0 0 1 1 0 1 0 0 1 0 0 1 1 1 0 0 1 1 1 1 1 0 1 0 0 1 0 0 1 1 1 1 1 1 1 1 1\n",
            " 1 1 0 0 0 1 1 0 1 0 1 1 1 1 0 0 1 0 1 0 1 1 1 1 0 1 1 0 1 0 1 0 1 1 1 1 0\n",
            " 1 1 0 1 1 1 1 1 0 0 0 0 0 1 1 0 0 1 1 0 0 1 0 0 1 0 0 1 1 0 1 0 1 1 1 1 1\n",
            " 1 1 1 1 0 1 0 1 0 1 1 1 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 0 1 0 0\n",
            " 0 0 1 0 0 0 1 1 0 0 1 1 0 1 1 0 1 0 0 1 1 1 1 0 1 1 1 1 1 1 0 1 1 0 0 1 1\n",
            " 0 0 0 1 0 1 1 1 0 1 1 1 1 0 1 0 1 0 0 0 0 1 0 1 1 0 1 1 0 1 1 0 1 1 0 0 1\n",
            " 1 1 1 0 1 1 1 1 1 1 1 1 1 0 0 0 1 0 1 0 1 1 1 1 1 0 1 1 1 0 1 0 0 0 1 0 1\n",
            " 1 0 0 0 1 1 0 1 1 1 1 0 1 1 0 1 1 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 1 1 1 1\n",
            " 1 0 0 0 0 1 0 1 0 1 1 0 1 1 1 1 1 1 1 0 1 0 0 1 1 0 1 1 1 1 1 0 0 1 0 1 0\n",
            " 1 0 1 1 1 1 0 1 1 0 1 1 1 0 0 1 1 1 0 1 0 1 1 1 1 1 0 0 1 0 1 1 0 1 0 0 1\n",
            " 0 1 0 0 1 1 0 1 0 0 1 0 0 1 0 1 0 0 1 1 1 1 0 0 1 0 1 0 0 1 1 1 1 1 0 0 0\n",
            " 0 1 0 1 1 1 0 1 1 0 0 1 0 1 0 0 1 0 0 0 0 1 0 1 1 1 0 1 1 0 0 1 0 0 1 0 1\n",
            " 1 1 0 0 1 0 0 1 1 0 0 1 0 1 1 1 0 1 0 0 1 0 1 1 0 0 1 0 1 0 1 1 1 1 1 0 1\n",
            " 0 0 1 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 0 0 0 1 1 1 1 0 1\n",
            " 1 0 1 0 1 0 0 0 1 0 0 1 0 1 0 1 0 1 1 0 0 1 1 0 1 0 1 1 0 0 0 1 0 1 1 1 1\n",
            " 0 1 1 1 0 0 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 0 0 1 1 1 1 1 0 1 1 0 0 1\n",
            " 1 0 1 0 0 0 1 0 1 1 0 1 0 0 0 1 0 1 1 0 1 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1\n",
            " 0 0 1 1 0 0 1 1 1 0 1 0 0 1 1 1 0 1 1 1 0 0 1 1 1 1 1 0 0 0]\n",
            "trainset before adding uncertain samples (310, 10) (310,)\n",
            "trainset after adding uncertain samples (320, 10) (320,)\n",
            "updated train set: (320, 10) (320,) unique(labels): [171 149] [0 1]\n",
            "val set: (982, 10) (982,)\n",
            "\n",
            "Train set: (320, 10)\n",
            "Validation set: (982, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 32\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.145 s \n",
            "\n",
            "Accuracy rate is 78.571429 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.85      0.85       321\n",
            "           1       0.59      0.59      0.59       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.72      0.72      0.72       434\n",
            "weighted avg       0.79      0.79      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[274  47]\n",
            " [ 46  67]]\n",
            "--------------------------------\n",
            "val predicted: (982,) [1 1 0 0 1 0 1 1 0 0 0 1 1 1 0 0 0 0 1 1 1 0 1 1 1 0 0 1 1 0 0 0 1 1 0 1 0\n",
            " 1 1 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 0 1 1 1 0 0 1 1 1 1 1 1 0 1 0 0 1 0 1 1\n",
            " 0 0 1 0 0 1 1 1 1 1 0 1 0 0 1 1 1 0 0 0 0 1 1 0 1 0 1 0 1 1 1 1 0 1 0 0 1\n",
            " 0 0 0 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 1 1 1 0\n",
            " 1 1 0 0 0 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 1 0 1 1 1 0 0 1 0 0 0 0 0 1 1 1 0\n",
            " 1 0 0 0 0 0 1 1 0 1 1 0 0 0 1 1 0 1 0 1 1 0 0 1 1 0 0 0 0 0 1 1 1 1 1 1 1\n",
            " 1 1 1 1 0 0 0 1 1 0 1 0 1 1 1 1 0 1 1 0 1 1 1 0 1 1 0 1 1 1 0 1 0 1 1 1 1\n",
            " 1 1 1 0 0 1 0 1 1 0 0 0 1 1 1 1 1 1 0 0 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0\n",
            " 1 0 0 0 0 0 0 1 1 1 1 1 1 1 0 1 1 1 0 1 1 0 1 0 1 0 0 1 1 1 1 0 0 1 1 0 1\n",
            " 0 0 1 0 0 1 1 1 0 0 1 1 1 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1\n",
            " 0 1 0 1 1 1 1 0 0 1 0 1 0 1 1 1 1 0 1 1 0 1 0 1 0 1 1 1 1 0 1 1 0 1 1 1 1\n",
            " 1 0 0 0 0 0 1 1 0 0 1 1 0 0 1 0 0 1 0 0 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 0 1\n",
            " 0 1 1 1 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 0 1 0 0 0 0 1 0 0 0 1 1\n",
            " 0 0 1 1 0 1 1 0 1 0 0 1 1 1 1 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 0 0 1 0 1 1 1\n",
            " 0 1 1 1 1 0 1 0 1 0 0 0 0 1 0 1 1 0 1 1 0 1 1 0 1 1 0 0 1 1 1 1 0 1 1 1 1\n",
            " 1 1 1 1 1 0 0 0 1 0 1 0 1 1 1 1 1 0 1 1 1 0 1 0 0 0 1 0 1 1 0 0 0 1 1 0 1\n",
            " 1 1 1 0 1 1 0 1 1 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 1 1 1 1 1 0 0 0 0 1 0 1\n",
            " 0 1 1 0 1 1 1 1 1 1 1 0 1 0 0 1 1 0 1 1 1 1 1 0 0 1 0 1 0 1 0 1 1 1 1 0 1\n",
            " 1 0 1 1 1 0 0 1 1 1 0 1 0 1 1 1 1 1 0 0 1 0 1 1 0 1 0 0 1 0 1 0 0 1 1 0 1\n",
            " 0 0 1 0 0 1 0 1 0 0 1 1 1 1 0 0 1 0 1 0 0 1 1 1 1 1 0 0 0 0 1 0 1 1 1 0 1\n",
            " 1 0 0 1 0 1 0 0 1 0 0 0 1 0 1 1 1 0 1 1 0 0 1 0 0 1 0 1 1 1 0 0 1 0 0 1 1\n",
            " 0 0 1 0 1 1 1 0 1 0 0 1 0 1 1 0 0 1 0 1 0 1 1 1 1 1 0 1 0 0 1 0 0 0 0 1 1\n",
            " 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 0 0 0 1 1 1 1 0 1 1 0 1 0 1 0 0 0 1 0\n",
            " 0 1 0 1 0 1 0 1 1 0 0 1 1 0 1 0 1 1 0 0 0 1 0 1 1 1 1 0 1 1 1 0 0 1 1 1 1\n",
            " 1 1 1 1 1 0 1 1 1 0 1 1 1 1 0 0 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 0 0 1 0 1 1\n",
            " 0 1 0 0 0 1 0 1 1 0 1 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 0 0 1 1 0 0 1 1 1 0\n",
            " 1 0 0 1 1 1 0 1 1 1 0 0 1 1 1 1 1 0 0 0]\n",
            "probabilities: (982, 2) \n",
            " [1 1 0 0 1 0 1 1 0 0 0 1 1 1 0 0 0 0 1 1 1 0 1 1 1 0 0 1 1 0 0 0 1 1 0 1 0\n",
            " 1 1 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 0 1 1 1 0 0 1 1 1 1 1 1 0 1 0 0 1 0 1 1\n",
            " 0 0 1 0 0 1 1 1 1 1 0 1 0 0 1 1 1 0 0 0 0 1 1 0 1 0 1 0 1 1 1 1 0 1 0 0 1\n",
            " 0 0 0 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 1 1 1 0\n",
            " 1 1 0 0 0 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 1 0 1 1 1 0 0 1 0 0 0 0 0 1 1 1 0\n",
            " 1 0 0 0 0 0 1 1 0 1 1 0 0 0 1 1 0 1 0 1 1 0 0 1 1 0 0 0 0 0 1 1 1 1 1 1 1\n",
            " 1 1 1 1 0 0 0 1 1 0 1 0 1 1 1 1 0 1 1 0 1 1 1 0 1 1 0 1 1 1 0 1 0 1 1 1 1\n",
            " 1 1 1 0 0 1 0 1 1 0 0 0 1 1 1 1 1 1 0 0 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0\n",
            " 1 0 0 0 0 0 0 1 1 1 1 1 1 1 0 1 1 1 0 1 1 0 1 0 1 0 0 1 1 1 1 0 0 1 1 0 1\n",
            " 0 0 1 0 0 1 1 1 0 0 1 1 1 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1\n",
            " 0 1 0 1 1 1 1 0 0 1 0 1 0 1 1 1 1 0 1 1 0 1 0 1 0 1 1 1 1 0 1 1 0 1 1 1 1\n",
            " 1 0 0 0 0 0 1 1 0 0 1 1 0 0 1 0 0 1 0 0 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 0 1\n",
            " 0 1 1 1 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 0 1 0 0 0 0 1 0 0 0 1 1\n",
            " 0 0 1 1 0 1 1 0 1 0 0 1 1 1 1 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 0 0 1 0 1 1 1\n",
            " 0 1 1 1 1 0 1 0 1 0 0 0 0 1 0 1 1 0 1 1 0 1 1 0 1 1 0 0 1 1 1 1 0 1 1 1 1\n",
            " 1 1 1 1 1 0 0 0 1 0 1 0 1 1 1 1 1 0 1 1 1 0 1 0 0 0 1 0 1 1 0 0 0 1 1 0 1\n",
            " 1 1 1 0 1 1 0 1 1 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 1 1 1 1 1 0 0 0 0 1 0 1\n",
            " 0 1 1 0 1 1 1 1 1 1 1 0 1 0 0 1 1 0 1 1 1 1 1 0 0 1 0 1 0 1 0 1 1 1 1 0 1\n",
            " 1 0 1 1 1 0 0 1 1 1 0 1 0 1 1 1 1 1 0 0 1 0 1 1 0 1 0 0 1 0 1 0 0 1 1 0 1\n",
            " 0 0 1 0 0 1 0 1 0 0 1 1 1 1 0 0 1 0 1 0 0 1 1 1 1 1 0 0 0 0 1 0 1 1 1 0 1\n",
            " 1 0 0 1 0 1 0 0 1 0 0 0 1 0 1 1 1 0 1 1 0 0 1 0 0 1 0 1 1 1 0 0 1 0 0 1 1\n",
            " 0 0 1 0 1 1 1 0 1 0 0 1 0 1 1 0 0 1 0 1 0 1 1 1 1 1 0 1 0 0 1 0 0 0 0 1 1\n",
            " 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 0 0 0 1 1 1 1 0 1 1 0 1 0 1 0 0 0 1 0\n",
            " 0 1 0 1 0 1 0 1 1 0 0 1 1 0 1 0 1 1 0 0 0 1 0 1 1 1 1 0 1 1 1 0 0 1 1 1 1\n",
            " 1 1 1 1 1 0 1 1 1 0 1 1 1 1 0 0 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 0 0 1 0 1 1\n",
            " 0 1 0 0 0 1 0 1 1 0 1 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 0 0 1 1 0 0 1 1 1 0\n",
            " 1 0 0 1 1 1 0 1 1 1 0 0 1 1 1 1 1 0 0 0]\n",
            "trainset before adding uncertain samples (320, 10) (320,)\n",
            "trainset after adding uncertain samples (330, 10) (330,)\n",
            "updated train set: (330, 10) (330,) unique(labels): [175 155] [0 1]\n",
            "val set: (972, 10) (972,)\n",
            "\n",
            "Train set: (330, 10)\n",
            "Validation set: (972, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 33\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.139 s \n",
            "\n",
            "Accuracy rate is 79.032258 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.85      0.86       321\n",
            "           1       0.59      0.61      0.60       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.73      0.73      0.73       434\n",
            "weighted avg       0.79      0.79      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[274  47]\n",
            " [ 44  69]]\n",
            "--------------------------------\n",
            "val predicted: (972,) [1 1 0 0 1 0 1 1 0 0 0 1 1 1 0 0 0 0 1 1 1 0 1 1 1 0 0 1 1 0 0 0 1 0 1 0 1\n",
            " 1 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 0 1 1 1 0 0 1 1 1 1 1 1 0 1 0 0 1 0 1 1 0\n",
            " 0 1 0 0 1 1 1 1 1 0 1 0 0 1 1 1 0 0 0 0 1 1 0 1 0 1 0 1 1 1 1 0 1 0 0 1 0\n",
            " 0 0 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 1 1 1 0 1\n",
            " 0 0 0 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 1 0 1 1 1 0 0 0 0 0 0 0 1 1 1 0 1 0 0\n",
            " 0 0 0 1 1 0 1 1 0 0 0 1 1 1 0 1 1 0 0 1 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1\n",
            " 0 0 0 1 1 0 1 0 1 1 1 1 0 1 1 0 1 1 1 0 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 0\n",
            " 0 1 0 1 1 0 0 0 1 1 1 1 1 1 0 0 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 0\n",
            " 0 0 0 1 1 1 1 1 1 1 0 1 1 1 0 1 1 0 1 0 1 0 0 1 1 1 1 0 0 1 1 0 1 0 0 1 0\n",
            " 0 1 1 1 0 0 1 1 1 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 0 1 0 1\n",
            " 1 1 1 0 0 1 0 1 0 1 1 1 1 0 1 1 0 1 0 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 0 0 0\n",
            " 0 0 1 1 0 0 1 1 0 0 1 0 0 1 0 0 1 1 0 1 1 1 1 1 1 1 1 1 0 1 0 1 0 1 1 1 0\n",
            " 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 0 1 0 0 0 0 1 0 0 0 1 1 0 0 1 1 0\n",
            " 1 1 0 1 0 0 1 1 1 1 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 0 0 1 0 1 1 1 0 1 1 1 1\n",
            " 0 1 0 1 0 0 0 0 1 0 1 1 0 1 1 0 1 1 0 1 1 0 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1\n",
            " 0 0 0 1 0 0 1 1 1 1 1 0 1 1 1 0 1 0 0 0 1 0 1 1 0 0 0 1 1 0 1 1 1 1 0 1 1\n",
            " 1 1 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 1 1 1 1 1 0 0 0 0 1 0 1 0 1 1 0 1 1 1\n",
            " 1 1 1 1 0 1 0 0 1 1 0 1 1 1 1 1 0 0 1 0 1 0 1 0 1 1 1 1 0 1 1 0 1 1 1 0 0\n",
            " 1 1 1 0 1 0 1 1 1 1 1 0 0 1 0 1 1 0 1 0 0 1 0 1 0 0 1 1 0 1 0 0 1 0 0 1 1\n",
            " 0 0 1 1 1 1 0 0 1 0 1 0 0 1 1 1 1 1 0 0 0 0 1 0 1 1 1 0 1 1 0 0 1 0 1 0 0\n",
            " 1 0 0 0 1 0 1 1 1 0 1 1 0 0 1 0 0 1 0 1 1 1 0 0 1 0 0 1 1 0 0 1 0 1 1 1 0\n",
            " 1 0 0 1 0 1 1 0 0 1 0 1 0 1 1 1 1 1 0 1 0 0 1 0 0 0 0 1 1 1 1 1 1 1 1 1 0\n",
            " 1 1 1 1 1 1 1 0 1 0 0 0 1 1 1 1 0 1 1 0 1 0 1 0 0 0 1 0 0 1 0 1 0 1 0 1 1\n",
            " 0 0 1 1 0 1 0 1 1 0 0 0 1 0 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 1 1 1 0 1 1 1 0\n",
            " 1 1 1 1 0 0 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 0 0 1 0 1 1 0 1 0 0 0 1 0 1 1 0\n",
            " 1 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 0 0 1 1 0 0 1 1 1 0 1 0 0 1 1 1 0 1 1 1\n",
            " 0 0 1 1 1 1 1 0 0 0]\n",
            "probabilities: (972, 2) \n",
            " [1 1 0 0 1 0 1 1 0 0 0 1 1 1 0 0 0 0 1 1 1 0 1 1 1 0 0 1 1 0 0 0 1 0 1 0 1\n",
            " 1 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 0 1 1 1 0 0 1 1 1 1 1 1 0 1 0 0 1 0 1 1 0\n",
            " 0 1 0 0 1 1 1 1 1 0 1 0 0 1 1 1 0 0 0 0 1 1 0 1 0 1 0 1 1 1 1 0 1 0 0 1 0\n",
            " 0 0 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 1 1 1 0 1\n",
            " 0 0 0 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 1 0 1 1 1 0 0 0 0 0 0 0 1 1 1 0 1 0 0\n",
            " 0 0 0 1 1 0 1 1 0 0 0 1 1 1 0 1 1 0 0 1 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1\n",
            " 0 0 0 1 1 0 1 0 1 1 1 1 0 1 1 0 1 1 1 0 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 0\n",
            " 0 1 0 1 1 0 0 0 1 1 1 1 1 1 0 0 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 0\n",
            " 0 0 0 1 1 1 1 1 1 1 0 1 1 1 0 1 1 0 1 0 1 0 0 1 1 1 1 0 0 1 1 0 1 0 0 1 0\n",
            " 0 1 1 1 0 0 1 1 1 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 0 1 0 1\n",
            " 1 1 1 0 0 1 0 1 0 1 1 1 1 0 1 1 0 1 0 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 0 0 0\n",
            " 0 0 1 1 0 0 1 1 0 0 1 0 0 1 0 0 1 1 0 1 1 1 1 1 1 1 1 1 0 1 0 1 0 1 1 1 0\n",
            " 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 0 1 0 0 0 0 1 0 0 0 1 1 0 0 1 1 0\n",
            " 1 1 0 1 0 0 1 1 1 1 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 0 0 1 0 1 1 1 0 1 1 1 1\n",
            " 0 1 0 1 0 0 0 0 1 0 1 1 0 1 1 0 1 1 0 1 1 0 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1\n",
            " 0 0 0 1 0 0 1 1 1 1 1 0 1 1 1 0 1 0 0 0 1 0 1 1 0 0 0 1 1 0 1 1 1 1 0 1 1\n",
            " 1 1 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 1 1 1 1 1 0 0 0 0 1 0 1 0 1 1 0 1 1 1\n",
            " 1 1 1 1 0 1 0 0 1 1 0 1 1 1 1 1 0 0 1 0 1 0 1 0 1 1 1 1 0 1 1 0 1 1 1 0 0\n",
            " 1 1 1 0 1 0 1 1 1 1 1 0 0 1 0 1 1 0 1 0 0 1 0 1 0 0 1 1 0 1 0 0 1 0 0 1 1\n",
            " 0 0 1 1 1 1 0 0 1 0 1 0 0 1 1 1 1 1 0 0 0 0 1 0 1 1 1 0 1 1 0 0 1 0 1 0 0\n",
            " 1 0 0 0 1 0 1 1 1 0 1 1 0 0 1 0 0 1 0 1 1 1 0 0 1 0 0 1 1 0 0 1 0 1 1 1 0\n",
            " 1 0 0 1 0 1 1 0 0 1 0 1 0 1 1 1 1 1 0 1 0 0 1 0 0 0 0 1 1 1 1 1 1 1 1 1 0\n",
            " 1 1 1 1 1 1 1 0 1 0 0 0 1 1 1 1 0 1 1 0 1 0 1 0 0 0 1 0 0 1 0 1 0 1 0 1 1\n",
            " 0 0 1 1 0 1 0 1 1 0 0 0 1 0 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 1 1 1 0 1 1 1 0\n",
            " 1 1 1 1 0 0 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 0 0 1 0 1 1 0 1 0 0 0 1 0 1 1 0\n",
            " 1 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 0 0 1 1 0 0 1 1 1 0 1 0 0 1 1 1 0 1 1 1\n",
            " 0 0 1 1 1 1 1 0 0 0]\n",
            "trainset before adding uncertain samples (330, 10) (330,)\n",
            "trainset after adding uncertain samples (340, 10) (340,)\n",
            "updated train set: (340, 10) (340,) unique(labels): [181 159] [0 1]\n",
            "val set: (962, 10) (962,)\n",
            "\n",
            "Train set: (340, 10)\n",
            "Validation set: (962, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 34\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.158 s \n",
            "\n",
            "Accuracy rate is 79.493088 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.86      0.86       321\n",
            "           1       0.60      0.62      0.61       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.73      0.74      0.74       434\n",
            "weighted avg       0.80      0.79      0.80       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[275  46]\n",
            " [ 43  70]]\n",
            "--------------------------------\n",
            "val predicted: (962,) [1 1 0 0 1 0 1 1 0 0 0 1 1 1 0 0 0 0 1 1 1 0 1 1 1 0 0 1 1 0 0 0 1 0 1 0 1\n",
            " 1 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 0 1 1 1 0 0 1 1 1 1 1 1 0 1 0 0 1 0 1 1 0\n",
            " 1 0 0 1 1 1 1 1 0 1 0 0 1 1 1 0 0 0 0 1 1 0 1 0 1 0 1 1 1 1 0 1 0 0 1 0 0\n",
            " 0 1 0 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 1 1 1 0 1 0 0\n",
            " 0 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 1 0 1 1 1 0 0 0 0 0 0 0 1 1 1 0 1 0 0 0 0\n",
            " 0 1 1 0 1 1 0 0 0 1 1 1 0 1 1 0 1 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0\n",
            " 1 1 0 1 0 1 1 1 1 0 1 1 0 1 1 1 0 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 0 0 1 0 1\n",
            " 1 0 0 0 1 1 1 1 1 1 0 0 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 0 0 0 0 1\n",
            " 1 1 1 1 1 1 0 1 1 1 0 1 1 0 1 0 1 0 0 1 1 1 1 0 0 1 1 0 1 0 0 1 0 0 1 1 1\n",
            " 0 0 1 1 1 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 0 1 0 1 1 1 1 0\n",
            " 0 1 0 1 0 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 0 0 0 0 0 1 1 0\n",
            " 0 1 1 0 0 1 0 0 1 0 0 1 1 0 1 1 1 1 1 1 1 1 1 0 1 0 1 0 1 1 1 0 0 0 0 0 0\n",
            " 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 0 1 0 0 0 0 1 0 0 0 1 1 0 0 1 1 0 1 1 0 1 0\n",
            " 0 1 1 1 1 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 0 0 1 0 1 1 1 0 1 1 1 1 0 1 0 1 0\n",
            " 0 0 0 1 0 1 1 0 1 1 0 1 1 0 1 1 0 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 0 0 1 0\n",
            " 0 1 1 1 1 1 0 1 1 1 0 1 0 0 0 1 0 1 1 0 0 0 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1\n",
            " 0 0 1 0 0 1 0 0 1 0 0 1 0 1 1 1 1 1 0 0 0 0 1 1 0 1 1 0 1 1 1 1 1 1 1 0 1\n",
            " 0 0 1 1 0 1 1 1 1 1 0 0 1 0 1 0 1 0 1 1 1 1 0 1 1 0 1 1 1 0 0 1 1 1 1 0 1\n",
            " 1 1 1 1 0 0 1 0 1 1 0 1 0 0 1 0 1 0 0 1 1 0 1 0 0 1 0 0 1 1 0 0 1 1 1 1 0\n",
            " 0 1 0 1 0 0 1 1 1 1 1 0 0 0 0 1 0 1 1 1 0 1 1 0 0 1 0 1 0 0 1 0 0 0 1 0 1\n",
            " 1 1 0 1 1 0 0 1 0 0 1 0 1 1 1 0 0 1 0 0 1 1 0 0 1 0 1 1 1 0 1 0 0 1 0 1 1\n",
            " 0 0 0 1 0 1 1 1 1 1 0 1 0 0 1 0 0 0 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0\n",
            " 1 0 0 0 1 1 1 1 0 1 1 0 1 0 1 0 0 0 1 0 0 1 0 1 0 1 0 1 1 0 0 1 1 0 1 0 1\n",
            " 1 0 0 1 0 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 0 0 1 1 1\n",
            " 1 1 0 1 1 0 0 1 1 0 1 0 0 0 1 0 1 1 0 1 0 0 0 1 0 1 1 0 1 0 1 0 1 1 1 1 1\n",
            " 1 1 1 0 0 1 1 1 0 0 1 1 0 0 1 1 1 0 1 0 0 1 1 0 1 1 1 0 0 1 1 1 1 1 0 0 0]\n",
            "probabilities: (962, 2) \n",
            " [1 1 0 0 1 0 1 1 0 0 0 1 1 1 0 0 0 0 1 1 1 0 1 1 1 0 0 1 1 0 0 0 1 0 1 0 1\n",
            " 1 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 0 1 1 1 0 0 1 1 1 1 1 1 0 1 0 0 1 0 1 1 0\n",
            " 1 0 0 1 1 1 1 1 0 1 0 0 1 1 1 0 0 0 0 1 1 0 1 0 1 0 1 1 1 1 0 1 0 0 1 0 0\n",
            " 0 1 0 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 1 1 1 0 1 0 0\n",
            " 0 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 1 0 1 1 1 0 0 0 0 0 0 0 1 1 1 0 1 0 0 0 0\n",
            " 0 1 1 0 1 1 0 0 0 1 1 1 0 1 1 0 1 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0\n",
            " 1 1 0 1 0 1 1 1 1 0 1 1 0 1 1 1 0 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 0 0 1 0 1\n",
            " 1 0 0 0 1 1 1 1 1 1 0 0 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 0 0 0 0 1\n",
            " 1 1 1 1 1 1 0 1 1 1 0 1 1 0 1 0 1 0 0 1 1 1 1 0 0 1 1 0 1 0 0 1 0 0 1 1 1\n",
            " 0 0 1 1 1 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 0 1 0 1 1 1 1 0\n",
            " 0 1 0 1 0 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 0 0 0 0 0 1 1 0\n",
            " 0 1 1 0 0 1 0 0 1 0 0 1 1 0 1 1 1 1 1 1 1 1 1 0 1 0 1 0 1 1 1 0 0 0 0 0 0\n",
            " 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 0 1 0 0 0 0 1 0 0 0 1 1 0 0 1 1 0 1 1 0 1 0\n",
            " 0 1 1 1 1 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 0 0 1 0 1 1 1 0 1 1 1 1 0 1 0 1 0\n",
            " 0 0 0 1 0 1 1 0 1 1 0 1 1 0 1 1 0 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 0 0 1 0\n",
            " 0 1 1 1 1 1 0 1 1 1 0 1 0 0 0 1 0 1 1 0 0 0 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1\n",
            " 0 0 1 0 0 1 0 0 1 0 0 1 0 1 1 1 1 1 0 0 0 0 1 1 0 1 1 0 1 1 1 1 1 1 1 0 1\n",
            " 0 0 1 1 0 1 1 1 1 1 0 0 1 0 1 0 1 0 1 1 1 1 0 1 1 0 1 1 1 0 0 1 1 1 1 0 1\n",
            " 1 1 1 1 0 0 1 0 1 1 0 1 0 0 1 0 1 0 0 1 1 0 1 0 0 1 0 0 1 1 0 0 1 1 1 1 0\n",
            " 0 1 0 1 0 0 1 1 1 1 1 0 0 0 0 1 0 1 1 1 0 1 1 0 0 1 0 1 0 0 1 0 0 0 1 0 1\n",
            " 1 1 0 1 1 0 0 1 0 0 1 0 1 1 1 0 0 1 0 0 1 1 0 0 1 0 1 1 1 0 1 0 0 1 0 1 1\n",
            " 0 0 0 1 0 1 1 1 1 1 0 1 0 0 1 0 0 0 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0\n",
            " 1 0 0 0 1 1 1 1 0 1 1 0 1 0 1 0 0 0 1 0 0 1 0 1 0 1 0 1 1 0 0 1 1 0 1 0 1\n",
            " 1 0 0 1 0 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 0 0 1 1 1\n",
            " 1 1 0 1 1 0 0 1 1 0 1 0 0 0 1 0 1 1 0 1 0 0 0 1 0 1 1 0 1 0 1 0 1 1 1 1 1\n",
            " 1 1 1 0 0 1 1 1 0 0 1 1 0 0 1 1 1 0 1 0 0 1 1 0 1 1 1 0 0 1 1 1 1 1 0 0 0]\n",
            "trainset before adding uncertain samples (340, 10) (340,)\n",
            "trainset after adding uncertain samples (350, 10) (350,)\n",
            "updated train set: (350, 10) (350,) unique(labels): [187 163] [0 1]\n",
            "val set: (952, 10) (952,)\n",
            "\n",
            "Train set: (350, 10)\n",
            "Validation set: (952, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 35\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.159 s \n",
            "\n",
            "Accuracy rate is 79.953917 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.87      0.86       321\n",
            "           1       0.62      0.61      0.61       113\n",
            "\n",
            "    accuracy                           0.80       434\n",
            "   macro avg       0.74      0.74      0.74       434\n",
            "weighted avg       0.80      0.80      0.80       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[278  43]\n",
            " [ 44  69]]\n",
            "--------------------------------\n",
            "val predicted: (952,) [1 1 0 0 1 0 1 1 0 0 0 1 1 1 0 0 0 0 1 1 1 0 1 1 1 0 0 1 1 0 0 0 1 1 0 1 1\n",
            " 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 0 1 1 1 0 0 1 1 1 1 1 1 0 1 0 0 1 0 1 1 0 1\n",
            " 0 0 1 1 1 1 1 0 1 0 0 1 1 1 0 0 0 0 1 1 0 1 0 1 0 1 1 1 1 0 1 0 0 1 0 0 0\n",
            " 1 0 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 1 1 1 0 1 0 0 0 1\n",
            " 1 1 1 1 1 1 1 0 1 0 0 1 1 1 0 1 1 1 0 0 0 0 0 0 0 1 1 1 0 1 0 0 0 0 0 1 1\n",
            " 0 1 1 0 0 0 1 1 1 0 1 1 0 1 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 0\n",
            " 1 0 1 1 1 1 0 1 1 0 1 1 1 0 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 0 0 1 0 1 1 0 0\n",
            " 0 1 1 1 1 1 1 0 0 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 0 0 0 0 1 1 1 1\n",
            " 1 1 1 0 1 1 1 0 1 1 0 1 0 1 0 0 1 1 1 0 0 1 1 0 1 0 0 1 0 0 1 1 1 0 0 1 1\n",
            " 1 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 0 1 0 1 1 1 1 0 0 1 0 1\n",
            " 0 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 0 0 0 0 0 1 1 0 0 1 1 0\n",
            " 0 1 0 0 1 0 0 1 0 1 1 1 1 1 1 1 1 1 0 1 0 1 0 1 1 1 0 0 0 0 0 0 1 1 1 1 1\n",
            " 1 1 0 0 0 1 1 1 1 1 0 1 0 0 0 0 1 0 0 0 1 1 0 0 1 1 0 1 1 0 1 0 0 1 1 1 1\n",
            " 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 0 0 1 0 1 1 1 0 1 1 1 1 0 1 0 1 0 0 0 0 1 0\n",
            " 1 1 0 1 1 0 1 1 0 1 1 0 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 0 0 1 0 0 1 1 1 1\n",
            " 1 0 1 1 1 0 1 0 0 0 1 0 1 1 0 0 0 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 0 1 0 1\n",
            " 0 0 1 0 0 1 0 1 1 1 1 1 0 0 0 0 1 1 0 1 1 0 1 1 1 1 1 1 1 0 1 0 0 1 1 0 1\n",
            " 1 1 1 1 0 0 1 0 1 0 1 0 1 1 1 1 0 1 1 0 1 1 1 0 0 1 1 1 1 0 1 1 1 1 1 0 0\n",
            " 1 0 1 1 0 1 0 0 1 0 1 0 0 1 1 0 1 0 0 1 0 0 1 1 0 0 1 1 1 1 0 0 1 0 1 0 0\n",
            " 1 1 1 1 1 0 0 0 0 1 0 1 1 1 0 1 1 0 0 1 0 1 0 0 0 0 1 0 1 1 1 0 1 1 0 0 1\n",
            " 0 0 1 0 1 1 1 0 0 1 0 0 1 1 0 0 1 0 1 1 1 0 1 0 0 1 0 1 1 0 0 0 1 0 1 1 1\n",
            " 1 1 0 1 0 0 1 0 0 0 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 0\n",
            " 1 1 0 1 0 1 0 0 0 1 0 0 1 0 1 0 1 0 1 1 0 0 1 1 0 1 0 1 1 0 0 1 0 1 1 1 1\n",
            " 0 1 1 1 0 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 0 0 1 1 0\n",
            " 1 0 0 0 1 0 1 1 0 1 0 0 0 1 0 1 1 0 1 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 0 0\n",
            " 1 1 0 0 1 1 1 0 1 0 0 1 1 0 1 1 1 0 0 1 1 1 1 1 0 0 0]\n",
            "probabilities: (952, 2) \n",
            " [1 1 0 0 1 0 1 1 0 0 0 1 1 1 0 0 0 0 1 1 1 0 1 1 1 0 0 1 1 0 0 0 1 1 0 1 1\n",
            " 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 0 1 1 1 0 0 1 1 1 1 1 1 0 1 0 0 1 0 1 1 0 1\n",
            " 0 0 1 1 1 1 1 0 1 0 0 1 1 1 0 0 0 0 1 1 0 1 0 1 0 1 1 1 1 0 1 0 0 1 0 0 0\n",
            " 1 0 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 1 1 1 0 1 0 0 0 1\n",
            " 1 1 1 1 1 1 1 0 1 0 0 1 1 1 0 1 1 1 0 0 0 0 0 0 0 1 1 1 0 1 0 0 0 0 0 1 1\n",
            " 0 1 1 0 0 0 1 1 1 0 1 1 0 1 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 0\n",
            " 1 0 1 1 1 1 0 1 1 0 1 1 1 0 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 0 0 1 0 1 1 0 0\n",
            " 0 1 1 1 1 1 1 0 0 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 0 0 0 0 1 1 1 1\n",
            " 1 1 1 0 1 1 1 0 1 1 0 1 0 1 0 0 1 1 1 0 0 1 1 0 1 0 0 1 0 0 1 1 1 0 0 1 1\n",
            " 1 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 0 1 0 1 1 1 1 0 0 1 0 1\n",
            " 0 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 0 0 0 0 0 1 1 0 0 1 1 0\n",
            " 0 1 0 0 1 0 0 1 0 1 1 1 1 1 1 1 1 1 0 1 0 1 0 1 1 1 0 0 0 0 0 0 1 1 1 1 1\n",
            " 1 1 0 0 0 1 1 1 1 1 0 1 0 0 0 0 1 0 0 0 1 1 0 0 1 1 0 1 1 0 1 0 0 1 1 1 1\n",
            " 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 0 0 1 0 1 1 1 0 1 1 1 1 0 1 0 1 0 0 0 0 1 0\n",
            " 1 1 0 1 1 0 1 1 0 1 1 0 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 0 0 1 0 0 1 1 1 1\n",
            " 1 0 1 1 1 0 1 0 0 0 1 0 1 1 0 0 0 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 0 1 0 1\n",
            " 0 0 1 0 0 1 0 1 1 1 1 1 0 0 0 0 1 1 0 1 1 0 1 1 1 1 1 1 1 0 1 0 0 1 1 0 1\n",
            " 1 1 1 1 0 0 1 0 1 0 1 0 1 1 1 1 0 1 1 0 1 1 1 0 0 1 1 1 1 0 1 1 1 1 1 0 0\n",
            " 1 0 1 1 0 1 0 0 1 0 1 0 0 1 1 0 1 0 0 1 0 0 1 1 0 0 1 1 1 1 0 0 1 0 1 0 0\n",
            " 1 1 1 1 1 0 0 0 0 1 0 1 1 1 0 1 1 0 0 1 0 1 0 0 0 0 1 0 1 1 1 0 1 1 0 0 1\n",
            " 0 0 1 0 1 1 1 0 0 1 0 0 1 1 0 0 1 0 1 1 1 0 1 0 0 1 0 1 1 0 0 0 1 0 1 1 1\n",
            " 1 1 0 1 0 0 1 0 0 0 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 0\n",
            " 1 1 0 1 0 1 0 0 0 1 0 0 1 0 1 0 1 0 1 1 0 0 1 1 0 1 0 1 1 0 0 1 0 1 1 1 1\n",
            " 0 1 1 1 0 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 0 0 1 1 0\n",
            " 1 0 0 0 1 0 1 1 0 1 0 0 0 1 0 1 1 0 1 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 0 0\n",
            " 1 1 0 0 1 1 1 0 1 0 0 1 1 0 1 1 1 0 0 1 1 1 1 1 0 0 0]\n",
            "trainset before adding uncertain samples (350, 10) (350,)\n",
            "trainset after adding uncertain samples (360, 10) (360,)\n",
            "updated train set: (360, 10) (360,) unique(labels): [193 167] [0 1]\n",
            "val set: (942, 10) (942,)\n",
            "\n",
            "Train set: (360, 10)\n",
            "Validation set: (942, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 36\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.182 s \n",
            "\n",
            "Accuracy rate is 79.953917 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.87      0.87       321\n",
            "           1       0.62      0.60      0.61       113\n",
            "\n",
            "    accuracy                           0.80       434\n",
            "   macro avg       0.74      0.74      0.74       434\n",
            "weighted avg       0.80      0.80      0.80       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[279  42]\n",
            " [ 45  68]]\n",
            "--------------------------------\n",
            "val predicted: (942,) [1 1 0 1 0 1 1 0 0 0 1 1 1 0 0 0 0 1 1 1 0 1 1 1 0 0 1 1 0 0 0 1 1 0 1 1 1\n",
            " 1 1 1 1 0 0 1 1 1 1 1 0 1 1 0 1 1 1 0 0 1 1 1 1 1 1 0 1 0 0 1 0 1 1 0 1 0\n",
            " 0 1 1 1 1 1 0 1 0 0 1 1 1 0 0 0 0 1 1 0 1 0 1 0 1 1 1 1 0 1 0 0 1 0 0 0 1\n",
            " 0 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 1 1 1 0 1 0 0 0 1 1 1\n",
            " 1 1 1 1 1 0 1 0 0 1 1 1 0 1 1 1 0 0 0 0 0 0 0 1 1 1 0 1 0 0 0 0 0 1 1 0 1\n",
            " 1 0 0 0 1 1 1 0 1 1 0 1 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 0 1 0\n",
            " 1 1 1 1 0 1 1 0 1 1 1 0 1 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0 1 0 1 1 0 0 0 1 1\n",
            " 1 1 1 1 0 0 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 0 0 0 0 1 1 1 1 1 1 1\n",
            " 0 1 1 1 0 1 1 0 1 0 1 0 0 1 1 1 0 0 1 1 0 1 0 0 1 0 0 1 1 1 0 0 1 1 1 1 1\n",
            " 0 1 0 0 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 0 1 0 1 1 1 1 0 0 1 0 1 0 1 1\n",
            " 1 1 0 1 1 0 1 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 0 0 0 0 0 1 1 0 0 1 1 0 0 1 0\n",
            " 0 1 0 0 1 0 1 1 1 1 1 1 1 1 1 0 1 0 1 0 1 1 1 0 0 0 0 0 0 1 1 1 1 1 1 1 0\n",
            " 0 0 1 1 1 1 1 0 1 0 0 0 0 1 0 0 0 1 1 0 1 0 1 1 0 1 0 0 1 1 1 1 0 1 1 1 1\n",
            " 1 1 0 1 1 0 0 1 1 0 0 0 1 0 1 1 1 0 1 1 1 1 0 1 0 1 0 0 0 0 1 0 1 1 0 1 1\n",
            " 0 1 1 0 1 1 0 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 0 0 1 0 1 1 1 1 1 0 1 1 1 0\n",
            " 1 0 0 0 1 0 1 1 0 0 0 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 0 1 0 1 0 0 1 0 0 1\n",
            " 0 1 1 1 1 1 0 0 0 0 1 1 0 1 1 0 1 1 1 1 1 1 1 0 1 0 0 1 1 0 1 1 1 1 1 0 0\n",
            " 1 0 1 0 0 1 1 1 1 0 1 1 0 1 1 1 0 0 1 1 1 1 0 1 1 1 1 1 0 0 1 0 1 1 0 1 0\n",
            " 0 1 0 1 0 1 1 0 1 0 0 1 0 0 1 1 0 0 1 1 1 1 0 0 1 0 1 0 0 1 1 1 1 1 0 0 0\n",
            " 0 1 0 1 1 1 0 1 1 0 0 1 0 1 0 0 0 0 1 0 1 1 1 0 1 1 0 0 1 0 0 1 0 1 1 1 0\n",
            " 0 1 0 0 1 1 0 0 1 0 1 1 1 0 1 0 0 1 0 1 1 0 0 0 1 0 1 1 1 1 1 0 1 0 0 1 0\n",
            " 0 0 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 0 1 1 0 1 0 1 0 0\n",
            " 0 1 0 0 1 0 1 0 1 0 1 1 0 0 1 1 0 1 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1 0 0 1 1\n",
            " 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 0 0 1 0 1 1\n",
            " 0 1 0 0 0 1 0 1 1 0 1 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 0 0 1 1 0 0 1 1 1 0\n",
            " 1 0 1 1 0 1 1 0 0 1 1 1 1 1 0 0 0]\n",
            "probabilities: (942, 2) \n",
            " [1 1 0 1 0 1 1 0 0 0 1 1 1 0 0 0 0 1 1 1 0 1 1 1 0 0 1 1 0 0 0 1 1 0 1 1 1\n",
            " 1 1 1 1 0 0 1 1 1 1 1 0 1 1 0 1 1 1 0 0 1 1 1 1 1 1 0 1 0 0 1 0 1 1 0 1 0\n",
            " 0 1 1 1 1 1 0 1 0 0 1 1 1 0 0 0 0 1 1 0 1 0 1 0 1 1 1 1 0 1 0 0 1 0 0 0 1\n",
            " 0 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 1 1 1 0 1 0 0 0 1 1 1\n",
            " 1 1 1 1 1 0 1 0 0 1 1 1 0 1 1 1 0 0 0 0 0 0 0 1 1 1 0 1 0 0 0 0 0 1 1 0 1\n",
            " 1 0 0 0 1 1 1 0 1 1 0 1 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 0 1 0\n",
            " 1 1 1 1 0 1 1 0 1 1 1 0 1 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0 1 0 1 1 0 0 0 1 1\n",
            " 1 1 1 1 0 0 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 0 0 0 0 1 1 1 1 1 1 1\n",
            " 0 1 1 1 0 1 1 0 1 0 1 0 0 1 1 1 0 0 1 1 0 1 0 0 1 0 0 1 1 1 0 0 1 1 1 1 1\n",
            " 0 1 0 0 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 0 1 0 1 1 1 1 0 0 1 0 1 0 1 1\n",
            " 1 1 0 1 1 0 1 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 0 0 0 0 0 1 1 0 0 1 1 0 0 1 0\n",
            " 0 1 0 0 1 0 1 1 1 1 1 1 1 1 1 0 1 0 1 0 1 1 1 0 0 0 0 0 0 1 1 1 1 1 1 1 0\n",
            " 0 0 1 1 1 1 1 0 1 0 0 0 0 1 0 0 0 1 1 0 1 0 1 1 0 1 0 0 1 1 1 1 0 1 1 1 1\n",
            " 1 1 0 1 1 0 0 1 1 0 0 0 1 0 1 1 1 0 1 1 1 1 0 1 0 1 0 0 0 0 1 0 1 1 0 1 1\n",
            " 0 1 1 0 1 1 0 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 0 0 1 0 1 1 1 1 1 0 1 1 1 0\n",
            " 1 0 0 0 1 0 1 1 0 0 0 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 0 1 0 1 0 0 1 0 0 1\n",
            " 0 1 1 1 1 1 0 0 0 0 1 1 0 1 1 0 1 1 1 1 1 1 1 0 1 0 0 1 1 0 1 1 1 1 1 0 0\n",
            " 1 0 1 0 0 1 1 1 1 0 1 1 0 1 1 1 0 0 1 1 1 1 0 1 1 1 1 1 0 0 1 0 1 1 0 1 0\n",
            " 0 1 0 1 0 1 1 0 1 0 0 1 0 0 1 1 0 0 1 1 1 1 0 0 1 0 1 0 0 1 1 1 1 1 0 0 0\n",
            " 0 1 0 1 1 1 0 1 1 0 0 1 0 1 0 0 0 0 1 0 1 1 1 0 1 1 0 0 1 0 0 1 0 1 1 1 0\n",
            " 0 1 0 0 1 1 0 0 1 0 1 1 1 0 1 0 0 1 0 1 1 0 0 0 1 0 1 1 1 1 1 0 1 0 0 1 0\n",
            " 0 0 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 0 1 1 0 1 0 1 0 0\n",
            " 0 1 0 0 1 0 1 0 1 0 1 1 0 0 1 1 0 1 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1 0 0 1 1\n",
            " 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 0 0 1 0 1 1\n",
            " 0 1 0 0 0 1 0 1 1 0 1 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 0 0 1 1 0 0 1 1 1 0\n",
            " 1 0 1 1 0 1 1 0 0 1 1 1 1 1 0 0 0]\n",
            "trainset before adding uncertain samples (360, 10) (360,)\n",
            "trainset after adding uncertain samples (370, 10) (370,)\n",
            "updated train set: (370, 10) (370,) unique(labels): [200 170] [0 1]\n",
            "val set: (932, 10) (932,)\n",
            "\n",
            "Train set: (370, 10)\n",
            "Validation set: (932, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 37\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.188 s \n",
            "\n",
            "Accuracy rate is 80.184332 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.87      0.87       321\n",
            "           1       0.62      0.61      0.62       113\n",
            "\n",
            "    accuracy                           0.80       434\n",
            "   macro avg       0.74      0.74      0.74       434\n",
            "weighted avg       0.80      0.80      0.80       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[279  42]\n",
            " [ 44  69]]\n",
            "--------------------------------\n",
            "val predicted: (932,) [1 1 0 1 0 1 1 0 0 0 1 1 1 0 0 0 0 1 1 1 0 1 1 1 0 0 1 1 0 0 0 1 1 0 1 1 1\n",
            " 1 1 1 1 0 0 1 1 1 1 1 0 1 1 0 1 1 1 0 0 1 1 1 1 1 1 0 1 0 0 1 0 1 1 0 1 0\n",
            " 0 1 1 1 1 1 0 1 0 0 1 1 1 0 0 0 0 1 1 0 1 0 1 0 1 1 1 1 0 1 0 0 1 0 0 0 1\n",
            " 0 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 1 1 1 0 1 0 0 0 1 1 1\n",
            " 1 1 1 1 1 0 1 0 0 1 1 1 0 1 1 1 0 0 0 0 0 0 0 1 1 1 0 1 0 0 0 0 0 1 1 0 1\n",
            " 1 0 0 0 1 1 1 0 1 1 0 1 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 0 1 0\n",
            " 1 1 1 1 0 1 1 0 1 1 1 0 1 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0 1 0 1 1 0 0 0 1 1\n",
            " 1 1 1 1 0 0 0 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 0 0 0 1 1 1 1 1 1 1 0 1\n",
            " 1 1 0 1 1 0 1 0 1 0 0 1 1 1 0 0 1 1 0 1 0 0 1 0 0 1 1 1 0 0 1 1 1 1 1 0 1\n",
            " 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 0 1 0 1 1 1 1 0 0 1 0 1 0 1 1 1 1 0\n",
            " 1 1 0 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 0 0 0 0 0 1 1 0 0 1 1 0 0 1 0 0 1 0 0\n",
            " 1 0 1 1 1 1 1 1 1 1 1 0 1 0 1 0 1 1 1 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 1 1\n",
            " 1 1 1 0 1 0 0 0 0 1 0 0 0 1 1 0 1 0 1 1 0 1 0 0 1 1 1 1 0 1 1 1 1 1 1 0 1\n",
            " 1 0 0 1 1 0 0 0 1 0 1 1 1 0 1 1 1 1 0 1 0 1 0 0 0 0 1 0 1 1 0 1 1 0 1 1 0\n",
            " 1 1 0 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 0 0 1 0 1 1 1 1 1 0 1 1 1 0 1 0 0 0\n",
            " 1 0 1 1 0 0 0 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 0 1 0 1 0 0 1 0 0 1 0 1 1 1\n",
            " 1 0 0 0 1 1 0 1 1 0 1 1 1 1 1 1 1 0 1 0 0 1 1 0 1 1 1 1 1 0 0 1 0 1 0 0 1\n",
            " 1 1 1 0 1 1 0 1 1 1 0 0 1 1 1 1 0 1 1 1 1 1 0 0 1 0 1 1 0 0 0 1 0 1 0 1 1\n",
            " 0 1 0 0 1 0 0 1 1 0 0 1 1 1 1 0 0 1 0 1 0 0 1 1 1 1 1 0 0 0 0 1 0 1 1 1 0\n",
            " 1 1 0 0 1 0 1 0 0 0 0 1 0 1 1 1 0 1 1 0 0 1 0 0 1 0 1 1 1 0 0 1 0 0 1 1 0\n",
            " 0 1 0 1 1 1 0 1 0 0 1 0 1 1 0 0 0 1 0 1 1 1 1 1 0 1 0 0 1 0 0 0 0 1 1 1 1\n",
            " 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 0 1 1 0 1 0 1 0 0 0 1 0 0 1 0 1\n",
            " 0 1 0 1 1 0 0 1 1 0 1 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 1 1 0 1\n",
            " 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 0 0 1 0 1 1 0 1 0 0 0 1 0 1 1\n",
            " 0 1 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 0 0 1 1 0 0 1 1 1 0 1 0 1 1 0 1 0 0 1\n",
            " 1 1 1 1 0 0 0]\n",
            "probabilities: (932, 2) \n",
            " [1 1 0 1 0 1 1 0 0 0 1 1 1 0 0 0 0 1 1 1 0 1 1 1 0 0 1 1 0 0 0 1 1 0 1 1 1\n",
            " 1 1 1 1 0 0 1 1 1 1 1 0 1 1 0 1 1 1 0 0 1 1 1 1 1 1 0 1 0 0 1 0 1 1 0 1 0\n",
            " 0 1 1 1 1 1 0 1 0 0 1 1 1 0 0 0 0 1 1 0 1 0 1 0 1 1 1 1 0 1 0 0 1 0 0 0 1\n",
            " 0 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 1 1 1 0 1 0 0 0 1 1 1\n",
            " 1 1 1 1 1 0 1 0 0 1 1 1 0 1 1 1 0 0 0 0 0 0 0 1 1 1 0 1 0 0 0 0 0 1 1 0 1\n",
            " 1 0 0 0 1 1 1 0 1 1 0 1 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 0 1 0\n",
            " 1 1 1 1 0 1 1 0 1 1 1 0 1 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0 1 0 1 1 0 0 0 1 1\n",
            " 1 1 1 1 0 0 0 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 0 0 0 1 1 1 1 1 1 1 0 1\n",
            " 1 1 0 1 1 0 1 0 1 0 0 1 1 1 0 0 1 1 0 1 0 0 1 0 0 1 1 1 0 0 1 1 1 1 1 0 1\n",
            " 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 0 1 0 1 1 1 1 0 0 1 0 1 0 1 1 1 1 0\n",
            " 1 1 0 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 0 0 0 0 0 1 1 0 0 1 1 0 0 1 0 0 1 0 0\n",
            " 1 0 1 1 1 1 1 1 1 1 1 0 1 0 1 0 1 1 1 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 1 1\n",
            " 1 1 1 0 1 0 0 0 0 1 0 0 0 1 1 0 1 0 1 1 0 1 0 0 1 1 1 1 0 1 1 1 1 1 1 0 1\n",
            " 1 0 0 1 1 0 0 0 1 0 1 1 1 0 1 1 1 1 0 1 0 1 0 0 0 0 1 0 1 1 0 1 1 0 1 1 0\n",
            " 1 1 0 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 0 0 1 0 1 1 1 1 1 0 1 1 1 0 1 0 0 0\n",
            " 1 0 1 1 0 0 0 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 0 1 0 1 0 0 1 0 0 1 0 1 1 1\n",
            " 1 0 0 0 1 1 0 1 1 0 1 1 1 1 1 1 1 0 1 0 0 1 1 0 1 1 1 1 1 0 0 1 0 1 0 0 1\n",
            " 1 1 1 0 1 1 0 1 1 1 0 0 1 1 1 1 0 1 1 1 1 1 0 0 1 0 1 1 0 0 0 1 0 1 0 1 1\n",
            " 0 1 0 0 1 0 0 1 1 0 0 1 1 1 1 0 0 1 0 1 0 0 1 1 1 1 1 0 0 0 0 1 0 1 1 1 0\n",
            " 1 1 0 0 1 0 1 0 0 0 0 1 0 1 1 1 0 1 1 0 0 1 0 0 1 0 1 1 1 0 0 1 0 0 1 1 0\n",
            " 0 1 0 1 1 1 0 1 0 0 1 0 1 1 0 0 0 1 0 1 1 1 1 1 0 1 0 0 1 0 0 0 0 1 1 1 1\n",
            " 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 0 1 1 0 1 0 1 0 0 0 1 0 0 1 0 1\n",
            " 0 1 0 1 1 0 0 1 1 0 1 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 1 1 0 1\n",
            " 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 0 0 1 0 1 1 0 1 0 0 0 1 0 1 1\n",
            " 0 1 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 0 0 1 1 0 0 1 1 1 0 1 0 1 1 0 1 0 0 1\n",
            " 1 1 1 1 0 0 0]\n",
            "trainset before adding uncertain samples (370, 10) (370,)\n",
            "trainset after adding uncertain samples (380, 10) (380,)\n",
            "updated train set: (380, 10) (380,) unique(labels): [204 176] [0 1]\n",
            "val set: (922, 10) (922,)\n",
            "\n",
            "Train set: (380, 10)\n",
            "Validation set: (922, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 38\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.208 s \n",
            "\n",
            "Accuracy rate is 79.953917 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.86      0.86       321\n",
            "           1       0.61      0.62      0.62       113\n",
            "\n",
            "    accuracy                           0.80       434\n",
            "   macro avg       0.74      0.74      0.74       434\n",
            "weighted avg       0.80      0.80      0.80       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[277  44]\n",
            " [ 43  70]]\n",
            "--------------------------------\n",
            "val predicted: (922,) [1 1 0 1 0 1 1 0 0 0 1 1 1 0 0 0 0 1 1 1 0 1 1 1 0 0 1 1 0 0 0 1 1 0 1 1 1\n",
            " 1 1 1 0 0 1 1 1 1 1 0 1 0 1 1 1 0 0 1 1 1 1 1 1 0 1 0 0 1 0 1 1 0 1 0 0 1\n",
            " 1 1 1 1 0 1 0 0 1 1 1 0 0 0 0 1 1 0 1 0 1 0 1 1 1 1 0 1 0 0 1 0 0 0 1 0 1\n",
            " 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 1 1 1 0 1 0 0 0 1 1 1 1 1\n",
            " 1 1 1 0 1 0 0 1 1 1 0 1 1 1 0 0 0 0 0 0 0 1 1 1 0 1 0 0 0 0 0 1 1 0 1 1 0\n",
            " 0 0 1 1 1 0 1 1 0 1 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 0 1 0 1 1\n",
            " 1 1 0 1 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 0 0 0 1 1 1 1 1\n",
            " 1 0 0 0 1 0 1 0 1 0 1 0 1 0 0 1 0 1 0 0 0 0 0 1 1 1 1 1 1 1 0 1 1 1 0 1 1\n",
            " 0 1 0 1 0 0 1 1 0 0 1 1 0 1 0 0 1 0 0 1 1 1 0 0 1 1 1 1 1 0 1 0 0 1 1 1 1\n",
            " 1 1 1 1 1 1 1 0 0 0 1 1 0 1 0 1 1 1 1 0 0 1 0 1 0 1 1 1 1 0 1 1 0 1 1 1 1\n",
            " 1 1 0 1 1 0 1 1 1 1 1 0 0 0 0 0 1 1 0 0 1 1 0 0 1 0 0 1 0 0 1 0 1 1 1 1 1\n",
            " 1 1 1 1 0 1 0 1 0 1 1 1 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 0 1 0 0\n",
            " 0 0 1 0 0 0 1 1 0 1 0 1 1 0 1 0 0 1 1 1 1 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 0\n",
            " 0 1 0 1 1 1 0 1 1 1 1 0 1 0 1 0 0 0 0 1 0 1 1 0 1 1 0 1 1 0 1 1 0 0 1 1 1\n",
            " 1 0 1 1 1 1 1 1 1 1 1 0 0 0 1 0 1 1 1 1 1 0 1 1 1 0 1 0 0 0 1 0 1 1 0 0 0\n",
            " 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 0 1 0 1 0 0 1 0 0 1 0 1 1 1 1 0 0 0 1 1 0\n",
            " 1 1 0 1 1 1 1 1 1 1 0 1 0 0 1 1 0 1 1 1 1 1 0 0 1 0 1 0 0 1 1 1 1 0 1 1 0\n",
            " 1 1 1 0 0 1 1 1 1 0 1 1 1 1 1 0 0 1 0 1 1 0 0 0 1 0 1 0 1 1 0 1 0 0 1 0 0\n",
            " 1 1 0 0 1 1 1 1 0 0 1 0 1 0 0 1 1 1 1 1 0 0 0 1 0 1 1 1 0 1 1 0 0 1 0 1 0\n",
            " 0 0 0 1 0 1 1 1 0 1 1 0 0 1 0 0 1 0 1 1 1 0 0 1 0 0 1 1 0 0 1 1 1 1 0 1 0\n",
            " 0 1 0 1 1 0 0 0 1 0 1 1 1 1 1 0 1 0 0 1 0 0 0 0 1 1 1 1 1 1 1 1 1 0 1 1 1\n",
            " 1 1 1 1 0 1 0 0 1 1 1 1 0 1 1 0 1 0 1 0 0 0 1 0 0 1 0 1 0 1 0 1 1 0 0 1 1\n",
            " 0 1 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1\n",
            " 1 1 1 0 1 1 0 0 1 1 0 1 0 0 0 1 0 1 1 0 1 0 0 0 1 0 1 1 0 1 0 1 0 1 1 1 1\n",
            " 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 1 1 0 1 0 1 1 0 1 0 0 1 1 1 1 1 0 0 0]\n",
            "probabilities: (922, 2) \n",
            " [1 1 0 1 0 1 1 0 0 0 1 1 1 0 0 0 0 1 1 1 0 1 1 1 0 0 1 1 0 0 0 1 1 0 1 1 1\n",
            " 1 1 1 0 0 1 1 1 1 1 0 1 0 1 1 1 0 0 1 1 1 1 1 1 0 1 0 0 1 0 1 1 0 1 0 0 1\n",
            " 1 1 1 1 0 1 0 0 1 1 1 0 0 0 0 1 1 0 1 0 1 0 1 1 1 1 0 1 0 0 1 0 0 0 1 0 1\n",
            " 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 1 1 1 0 1 0 0 0 1 1 1 1 1\n",
            " 1 1 1 0 1 0 0 1 1 1 0 1 1 1 0 0 0 0 0 0 0 1 1 1 0 1 0 0 0 0 0 1 1 0 1 1 0\n",
            " 0 0 1 1 1 0 1 1 0 1 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 0 1 0 1 1\n",
            " 1 1 0 1 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 0 0 0 1 1 1 1 1\n",
            " 1 0 0 0 1 0 1 0 1 0 1 0 1 0 0 1 0 1 0 0 0 0 0 1 1 1 1 1 1 1 0 1 1 1 0 1 1\n",
            " 0 1 0 1 0 0 1 1 0 0 1 1 0 1 0 0 1 0 0 1 1 1 0 0 1 1 1 1 1 0 1 0 0 1 1 1 1\n",
            " 1 1 1 1 1 1 1 0 0 0 1 1 0 1 0 1 1 1 1 0 0 1 0 1 0 1 1 1 1 0 1 1 0 1 1 1 1\n",
            " 1 1 0 1 1 0 1 1 1 1 1 0 0 0 0 0 1 1 0 0 1 1 0 0 1 0 0 1 0 0 1 0 1 1 1 1 1\n",
            " 1 1 1 1 0 1 0 1 0 1 1 1 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 0 1 0 0\n",
            " 0 0 1 0 0 0 1 1 0 1 0 1 1 0 1 0 0 1 1 1 1 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 0\n",
            " 0 1 0 1 1 1 0 1 1 1 1 0 1 0 1 0 0 0 0 1 0 1 1 0 1 1 0 1 1 0 1 1 0 0 1 1 1\n",
            " 1 0 1 1 1 1 1 1 1 1 1 0 0 0 1 0 1 1 1 1 1 0 1 1 1 0 1 0 0 0 1 0 1 1 0 0 0\n",
            " 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 0 1 0 1 0 0 1 0 0 1 0 1 1 1 1 0 0 0 1 1 0\n",
            " 1 1 0 1 1 1 1 1 1 1 0 1 0 0 1 1 0 1 1 1 1 1 0 0 1 0 1 0 0 1 1 1 1 0 1 1 0\n",
            " 1 1 1 0 0 1 1 1 1 0 1 1 1 1 1 0 0 1 0 1 1 0 0 0 1 0 1 0 1 1 0 1 0 0 1 0 0\n",
            " 1 1 0 0 1 1 1 1 0 0 1 0 1 0 0 1 1 1 1 1 0 0 0 1 0 1 1 1 0 1 1 0 0 1 0 1 0\n",
            " 0 0 0 1 0 1 1 1 0 1 1 0 0 1 0 0 1 0 1 1 1 0 0 1 0 0 1 1 0 0 1 1 1 1 0 1 0\n",
            " 0 1 0 1 1 0 0 0 1 0 1 1 1 1 1 0 1 0 0 1 0 0 0 0 1 1 1 1 1 1 1 1 1 0 1 1 1\n",
            " 1 1 1 1 0 1 0 0 1 1 1 1 0 1 1 0 1 0 1 0 0 0 1 0 0 1 0 1 0 1 0 1 1 0 0 1 1\n",
            " 0 1 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1\n",
            " 1 1 1 0 1 1 0 0 1 1 0 1 0 0 0 1 0 1 1 0 1 0 0 0 1 0 1 1 0 1 0 1 0 1 1 1 1\n",
            " 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 1 1 0 1 0 1 1 0 1 0 0 1 1 1 1 1 0 0 0]\n",
            "trainset before adding uncertain samples (380, 10) (380,)\n",
            "trainset after adding uncertain samples (390, 10) (390,)\n",
            "updated train set: (390, 10) (390,) unique(labels): [210 180] [0 1]\n",
            "val set: (912, 10) (912,)\n",
            "\n",
            "Train set: (390, 10)\n",
            "Validation set: (912, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 39\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.216 s \n",
            "\n",
            "Accuracy rate is 80.645161 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.87      0.87       321\n",
            "           1       0.63      0.62      0.62       113\n",
            "\n",
            "    accuracy                           0.81       434\n",
            "   macro avg       0.75      0.75      0.75       434\n",
            "weighted avg       0.81      0.81      0.81       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[280  41]\n",
            " [ 43  70]]\n",
            "--------------------------------\n",
            "val predicted: (912,) [1 1 0 1 0 1 1 0 0 0 1 1 1 0 0 0 0 1 1 1 0 1 1 1 0 0 1 1 0 0 0 1 1 0 1 1 1\n",
            " 1 1 1 0 0 1 1 1 1 1 0 1 0 1 1 1 0 0 1 1 1 1 1 1 0 1 0 0 1 0 1 1 0 1 0 0 1\n",
            " 1 1 1 1 0 1 0 0 1 1 1 0 0 0 0 1 1 0 1 0 1 0 1 1 1 1 0 1 0 0 1 0 0 0 1 0 1\n",
            " 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 1 1 1 0 1 0 0 0 1 1 1 1 1\n",
            " 1 1 1 0 1 0 0 1 1 1 0 1 1 1 0 0 0 0 0 0 0 1 1 1 0 1 0 0 0 0 0 1 1 0 1 0 0\n",
            " 0 1 1 1 0 1 1 0 1 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 0 1 0 1 1 1\n",
            " 1 0 1 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 0 0 0 1 1 1 1 1 1\n",
            " 0 0 0 1 1 0 1 0 1 0 1 0 0 1 0 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 0\n",
            " 1 0 1 1 0 0 1 1 0 1 0 0 1 0 0 1 1 1 0 0 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1\n",
            " 1 1 1 0 0 0 1 1 0 1 0 1 1 1 1 0 0 1 0 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1\n",
            " 1 0 1 1 1 1 1 0 0 0 0 0 1 1 0 0 1 1 0 0 1 0 0 1 0 0 1 0 1 1 1 1 1 1 1 1 1\n",
            " 1 0 1 0 1 1 1 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 0 1 0 0 0 0 1 0 0\n",
            " 0 1 1 0 0 1 1 0 1 0 0 1 1 1 1 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 0 0 1 0 1 1 1\n",
            " 0 1 1 1 1 0 1 0 1 0 0 0 0 1 0 1 1 0 1 1 0 1 1 0 1 1 0 0 1 1 1 1 0 1 1 1 1\n",
            " 1 1 1 1 1 0 0 0 1 0 1 1 1 1 1 0 1 1 1 0 1 0 0 0 1 0 1 1 0 0 0 1 1 0 1 1 1\n",
            " 1 0 1 1 1 1 1 0 1 0 0 1 0 1 0 0 1 0 0 1 0 1 1 1 1 0 0 0 1 1 0 1 1 0 1 1 1\n",
            " 1 1 1 1 0 1 0 0 1 1 0 1 1 1 1 1 0 0 1 1 0 0 1 1 1 1 0 1 1 0 1 1 1 0 0 1 1\n",
            " 1 1 0 1 1 1 1 1 0 0 1 0 1 1 0 0 0 1 0 1 0 1 1 0 1 0 0 1 0 0 1 1 0 0 1 1 1\n",
            " 1 0 0 1 0 1 0 0 1 1 1 1 1 0 0 0 1 0 1 1 1 0 1 1 0 0 1 0 1 0 0 0 0 1 0 1 1\n",
            " 1 0 1 1 0 0 1 0 0 1 0 1 1 1 0 0 1 0 0 1 1 0 0 1 1 1 1 0 1 0 0 1 0 1 1 0 0\n",
            " 0 1 0 1 1 1 1 1 0 1 0 0 1 0 0 0 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 0\n",
            " 0 1 1 1 1 0 1 1 0 1 0 1 0 0 0 1 0 0 1 0 1 0 1 0 1 1 0 0 1 1 1 0 1 1 0 0 1\n",
            " 0 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 0 1\n",
            " 1 0 1 0 0 0 1 0 1 1 0 1 0 0 0 1 0 1 1 0 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 0 0\n",
            " 1 1 0 0 1 1 1 0 1 0 1 1 0 1 0 0 1 1 1 1 1 0 0 0]\n",
            "probabilities: (912, 2) \n",
            " [1 1 0 1 0 1 1 0 0 0 1 1 1 0 0 0 0 1 1 1 0 1 1 1 0 0 1 1 0 0 0 1 1 0 1 1 1\n",
            " 1 1 1 0 0 1 1 1 1 1 0 1 0 1 1 1 0 0 1 1 1 1 1 1 0 1 0 0 1 0 1 1 0 1 0 0 1\n",
            " 1 1 1 1 0 1 0 0 1 1 1 0 0 0 0 1 1 0 1 0 1 0 1 1 1 1 0 1 0 0 1 0 0 0 1 0 1\n",
            " 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 1 1 1 0 1 0 0 0 1 1 1 1 1\n",
            " 1 1 1 0 1 0 0 1 1 1 0 1 1 1 0 0 0 0 0 0 0 1 1 1 0 1 0 0 0 0 0 1 1 0 1 0 0\n",
            " 0 1 1 1 0 1 1 0 1 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 0 1 0 1 1 1\n",
            " 1 0 1 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 0 0 0 1 1 1 1 1 1\n",
            " 0 0 0 1 1 0 1 0 1 0 1 0 0 1 0 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 0\n",
            " 1 0 1 1 0 0 1 1 0 1 0 0 1 0 0 1 1 1 0 0 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1\n",
            " 1 1 1 0 0 0 1 1 0 1 0 1 1 1 1 0 0 1 0 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1\n",
            " 1 0 1 1 1 1 1 0 0 0 0 0 1 1 0 0 1 1 0 0 1 0 0 1 0 0 1 0 1 1 1 1 1 1 1 1 1\n",
            " 1 0 1 0 1 1 1 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 0 1 0 0 0 0 1 0 0\n",
            " 0 1 1 0 0 1 1 0 1 0 0 1 1 1 1 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 0 0 1 0 1 1 1\n",
            " 0 1 1 1 1 0 1 0 1 0 0 0 0 1 0 1 1 0 1 1 0 1 1 0 1 1 0 0 1 1 1 1 0 1 1 1 1\n",
            " 1 1 1 1 1 0 0 0 1 0 1 1 1 1 1 0 1 1 1 0 1 0 0 0 1 0 1 1 0 0 0 1 1 0 1 1 1\n",
            " 1 0 1 1 1 1 1 0 1 0 0 1 0 1 0 0 1 0 0 1 0 1 1 1 1 0 0 0 1 1 0 1 1 0 1 1 1\n",
            " 1 1 1 1 0 1 0 0 1 1 0 1 1 1 1 1 0 0 1 1 0 0 1 1 1 1 0 1 1 0 1 1 1 0 0 1 1\n",
            " 1 1 0 1 1 1 1 1 0 0 1 0 1 1 0 0 0 1 0 1 0 1 1 0 1 0 0 1 0 0 1 1 0 0 1 1 1\n",
            " 1 0 0 1 0 1 0 0 1 1 1 1 1 0 0 0 1 0 1 1 1 0 1 1 0 0 1 0 1 0 0 0 0 1 0 1 1\n",
            " 1 0 1 1 0 0 1 0 0 1 0 1 1 1 0 0 1 0 0 1 1 0 0 1 1 1 1 0 1 0 0 1 0 1 1 0 0\n",
            " 0 1 0 1 1 1 1 1 0 1 0 0 1 0 0 0 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 0\n",
            " 0 1 1 1 1 0 1 1 0 1 0 1 0 0 0 1 0 0 1 0 1 0 1 0 1 1 0 0 1 1 1 0 1 1 0 0 1\n",
            " 0 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 0 1\n",
            " 1 0 1 0 0 0 1 0 1 1 0 1 0 0 0 1 0 1 1 0 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 0 0\n",
            " 1 1 0 0 1 1 1 0 1 0 1 1 0 1 0 0 1 1 1 1 1 0 0 0]\n",
            "trainset before adding uncertain samples (390, 10) (390,)\n",
            "trainset after adding uncertain samples (400, 10) (400,)\n",
            "updated train set: (400, 10) (400,) unique(labels): [213 187] [0 1]\n",
            "val set: (902, 10) (902,)\n",
            "\n",
            "Train set: (400, 10)\n",
            "Validation set: (902, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 40\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.236 s \n",
            "\n",
            "Accuracy rate is 79.493088 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.87      0.86       321\n",
            "           1       0.61      0.59      0.60       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.73      0.73      0.73       434\n",
            "weighted avg       0.79      0.79      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[278  43]\n",
            " [ 46  67]]\n",
            "--------------------------------\n",
            "val predicted: (902,) [1 1 0 1 0 1 1 0 0 0 1 1 1 0 0 0 0 1 1 1 0 1 1 1 0 0 1 1 0 0 0 1 1 0 1 1 1\n",
            " 1 1 1 0 0 1 1 1 1 1 0 1 0 1 1 0 0 1 1 1 1 1 0 1 0 0 1 0 1 1 0 1 0 0 1 1 1\n",
            " 1 1 0 1 0 0 1 1 1 0 0 0 0 1 1 0 1 0 1 0 1 1 1 1 0 1 0 0 1 0 0 0 1 0 1 1 0\n",
            " 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 1 1 1 0 1 0 0 0 1 1 1 1 1 1 1\n",
            " 0 1 0 0 1 1 0 1 1 1 0 0 0 0 0 0 0 1 1 1 0 1 0 0 0 0 0 1 1 0 1 0 0 0 1 1 1\n",
            " 0 1 1 0 1 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 0 1 0 1 1 1 1 0 1 1\n",
            " 0 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 0 0 0 1 1 1 1 1 1 0 0 0 1 1\n",
            " 0 1 0 1 0 1 0 0 1 0 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 0 1 0 1 1 0\n",
            " 0 1 1 0 1 0 0 1 0 0 1 1 1 0 0 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0\n",
            " 0 1 1 0 1 0 1 1 1 1 0 0 1 0 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 0 1 1 1\n",
            " 1 1 0 0 0 0 0 1 1 0 0 1 1 0 0 1 0 0 1 0 0 1 0 1 1 1 1 1 1 1 1 1 1 0 1 0 1\n",
            " 1 1 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 1 1 1 1 0 1 0 0 0 0 1 0 0 0 1 1 0 0 1\n",
            " 1 0 1 0 0 1 1 1 1 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 0 0 1 0 1 1 1 0 1 1 1 0 1\n",
            " 0 1 0 0 0 0 1 0 1 1 0 1 1 0 1 1 0 1 1 0 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 0\n",
            " 0 1 0 1 1 1 1 1 0 1 1 1 0 1 0 0 0 1 0 1 1 0 0 0 1 1 0 1 1 1 1 0 1 1 1 1 1\n",
            " 0 1 0 0 1 0 1 0 0 1 0 0 1 0 1 1 1 1 0 0 0 1 1 0 1 1 0 1 1 1 1 1 1 1 0 1 0\n",
            " 0 1 1 0 1 1 1 1 1 0 0 1 1 0 0 1 1 1 1 0 1 1 0 1 1 1 0 0 1 1 1 1 0 1 1 1 1\n",
            " 1 0 0 1 0 1 1 0 0 0 1 0 1 0 1 1 1 0 0 1 0 0 1 1 0 0 1 1 1 1 0 0 1 0 1 0 0\n",
            " 1 1 1 1 1 0 0 0 1 0 1 1 1 0 1 1 0 0 1 0 1 0 0 0 0 1 0 1 1 1 0 1 1 0 0 1 0\n",
            " 0 1 0 1 1 1 0 0 1 0 0 1 1 0 0 1 1 1 1 0 1 0 0 1 0 1 1 0 0 0 1 0 1 1 1 1 1\n",
            " 0 1 0 0 1 0 0 0 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 0 1 1\n",
            " 0 1 0 1 0 0 0 1 0 0 1 0 1 0 1 0 1 1 0 0 1 1 1 0 1 1 0 0 1 0 1 1 1 1 0 1 1\n",
            " 1 0 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 0 1 1 0 1 0 0 0 1 0\n",
            " 1 1 1 0 0 0 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 1 1 0 1 0\n",
            " 1 1 0 1 0 0 1 1 1 1 1 0 0 0]\n",
            "probabilities: (902, 2) \n",
            " [1 1 0 1 0 1 1 0 0 0 1 1 1 0 0 0 0 1 1 1 0 1 1 1 0 0 1 1 0 0 0 1 1 0 1 1 1\n",
            " 1 1 1 0 0 1 1 1 1 1 0 1 0 1 1 0 0 1 1 1 1 1 0 1 0 0 1 0 1 1 0 1 0 0 1 1 1\n",
            " 1 1 0 1 0 0 1 1 1 0 0 0 0 1 1 0 1 0 1 0 1 1 1 1 0 1 0 0 1 0 0 0 1 0 1 1 0\n",
            " 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 1 1 1 0 1 0 0 0 1 1 1 1 1 1 1\n",
            " 0 1 0 0 1 1 0 1 1 1 0 0 0 0 0 0 0 1 1 1 0 1 0 0 0 0 0 1 1 0 1 0 0 0 1 1 1\n",
            " 0 1 1 0 1 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 0 1 0 1 1 1 1 0 1 1\n",
            " 0 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 0 0 0 1 1 1 1 1 1 0 0 0 1 1\n",
            " 0 1 0 1 0 1 0 0 1 0 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 0 1 0 1 1 0\n",
            " 0 1 1 0 1 0 0 1 0 0 1 1 1 0 0 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0\n",
            " 0 1 1 0 1 0 1 1 1 1 0 0 1 0 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 0 1 1 1\n",
            " 1 1 0 0 0 0 0 1 1 0 0 1 1 0 0 1 0 0 1 0 0 1 0 1 1 1 1 1 1 1 1 1 1 0 1 0 1\n",
            " 1 1 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 1 1 1 1 0 1 0 0 0 0 1 0 0 0 1 1 0 0 1\n",
            " 1 0 1 0 0 1 1 1 1 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 0 0 1 0 1 1 1 0 1 1 1 0 1\n",
            " 0 1 0 0 0 0 1 0 1 1 0 1 1 0 1 1 0 1 1 0 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 0\n",
            " 0 1 0 1 1 1 1 1 0 1 1 1 0 1 0 0 0 1 0 1 1 0 0 0 1 1 0 1 1 1 1 0 1 1 1 1 1\n",
            " 0 1 0 0 1 0 1 0 0 1 0 0 1 0 1 1 1 1 0 0 0 1 1 0 1 1 0 1 1 1 1 1 1 1 0 1 0\n",
            " 0 1 1 0 1 1 1 1 1 0 0 1 1 0 0 1 1 1 1 0 1 1 0 1 1 1 0 0 1 1 1 1 0 1 1 1 1\n",
            " 1 0 0 1 0 1 1 0 0 0 1 0 1 0 1 1 1 0 0 1 0 0 1 1 0 0 1 1 1 1 0 0 1 0 1 0 0\n",
            " 1 1 1 1 1 0 0 0 1 0 1 1 1 0 1 1 0 0 1 0 1 0 0 0 0 1 0 1 1 1 0 1 1 0 0 1 0\n",
            " 0 1 0 1 1 1 0 0 1 0 0 1 1 0 0 1 1 1 1 0 1 0 0 1 0 1 1 0 0 0 1 0 1 1 1 1 1\n",
            " 0 1 0 0 1 0 0 0 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 0 1 1\n",
            " 0 1 0 1 0 0 0 1 0 0 1 0 1 0 1 0 1 1 0 0 1 1 1 0 1 1 0 0 1 0 1 1 1 1 0 1 1\n",
            " 1 0 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 0 1 1 0 1 0 0 0 1 0\n",
            " 1 1 1 0 0 0 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 1 1 0 1 0\n",
            " 1 1 0 1 0 0 1 1 1 1 1 0 0 0]\n",
            "trainset before adding uncertain samples (400, 10) (400,)\n",
            "trainset after adding uncertain samples (410, 10) (410,)\n",
            "updated train set: (410, 10) (410,) unique(labels): [217 193] [0 1]\n",
            "val set: (892, 10) (892,)\n",
            "\n",
            "Train set: (410, 10)\n",
            "Validation set: (892, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 41\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.246 s \n",
            "\n",
            "Accuracy rate is 78.571429 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.86      0.86       321\n",
            "           1       0.59      0.58      0.58       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.72      0.72      0.72       434\n",
            "weighted avg       0.78      0.79      0.78       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[276  45]\n",
            " [ 48  65]]\n",
            "--------------------------------\n",
            "val predicted: (892,) [1 1 0 1 0 1 1 0 0 0 1 1 1 0 0 0 0 1 1 1 0 1 1 1 0 0 1 1 0 0 0 1 1 0 1 1 1\n",
            " 1 1 1 0 0 1 1 1 1 1 0 1 0 1 1 0 0 1 1 1 1 1 0 1 0 0 1 0 1 1 0 1 0 0 1 1 1\n",
            " 1 1 0 1 0 0 1 1 1 0 0 0 0 1 1 0 1 0 1 0 1 1 1 1 0 1 0 0 1 0 0 0 1 0 1 1 0\n",
            " 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 1 1 1 0 1 0 0 0 1 1 1 1 1 1 1\n",
            " 0 1 0 0 1 1 0 1 1 1 0 0 0 0 0 0 0 1 1 1 0 1 0 0 0 0 0 1 1 0 1 0 0 0 1 1 1\n",
            " 0 1 1 0 1 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 0 1 0 1 1 1 1 0 1 1\n",
            " 0 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 0 0 0 1 1 1 1 1 0 0 0 1 1 0\n",
            " 1 0 1 0 1 0 0 1 0 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 0 1 0 1 1 0 0\n",
            " 1 1 0 1 0 0 1 0 0 1 1 0 0 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1\n",
            " 0 1 0 1 1 1 1 0 0 1 0 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 0\n",
            " 0 0 0 0 1 1 0 1 1 0 0 1 0 0 1 0 0 1 0 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 0 0\n",
            " 0 0 0 0 1 1 1 1 1 1 1 0 0 0 1 1 1 1 0 1 0 0 0 0 1 0 0 0 1 1 0 0 1 1 0 1 0\n",
            " 0 1 1 1 1 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 0 0 1 0 1 1 1 0 1 1 1 0 1 0 1 0 0\n",
            " 0 0 1 0 1 1 0 1 1 0 1 1 0 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 0 0 0 1 0 1 1 1\n",
            " 1 0 1 1 1 0 1 0 0 0 1 0 1 1 0 0 0 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 0 1 0 1\n",
            " 0 0 1 0 0 1 0 1 1 1 1 0 0 0 1 1 0 1 1 0 1 1 1 1 1 1 1 0 1 0 0 1 1 0 1 1 1\n",
            " 1 1 0 0 1 1 0 0 1 1 1 1 0 1 0 1 1 1 0 0 1 1 1 1 0 1 1 1 1 1 0 0 1 0 1 1 0\n",
            " 0 0 1 0 1 0 1 1 1 0 0 1 0 0 1 1 0 0 1 1 1 1 0 0 1 0 1 0 0 1 1 1 1 1 0 0 0\n",
            " 1 0 1 1 1 1 1 0 0 1 0 1 0 0 0 0 1 0 1 1 1 0 1 1 0 0 1 0 0 1 1 1 1 0 0 1 0\n",
            " 0 1 1 0 0 1 1 1 1 0 1 0 0 1 0 1 1 0 0 0 1 0 1 1 1 1 1 0 1 0 0 1 0 0 0 0 1\n",
            " 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 0 1 1 0 1 0 1 0 0 0 1 0 0\n",
            " 1 0 1 0 1 0 1 1 0 0 1 1 1 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 1 1\n",
            " 0 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 0 1 1 0 1 0 0 0 1 0 1 1 1 0 0 0 1 0 1 1\n",
            " 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 1 1 0 1 0 1 1 0 1 0 0 1 1 1 1\n",
            " 1 0 0 0]\n",
            "probabilities: (892, 2) \n",
            " [1 1 0 1 0 1 1 0 0 0 1 1 1 0 0 0 0 1 1 1 0 1 1 1 0 0 1 1 0 0 0 1 1 0 1 1 1\n",
            " 1 1 1 0 0 1 1 1 1 1 0 1 0 1 1 0 0 1 1 1 1 1 0 1 0 0 1 0 1 1 0 1 0 0 1 1 1\n",
            " 1 1 0 1 0 0 1 1 1 0 0 0 0 1 1 0 1 0 1 0 1 1 1 1 0 1 0 0 1 0 0 0 1 0 1 1 0\n",
            " 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 1 1 1 0 1 0 0 0 1 1 1 1 1 1 1\n",
            " 0 1 0 0 1 1 0 1 1 1 0 0 0 0 0 0 0 1 1 1 0 1 0 0 0 0 0 1 1 0 1 0 0 0 1 1 1\n",
            " 0 1 1 0 1 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 0 1 0 1 1 1 1 0 1 1\n",
            " 0 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 0 0 0 1 1 1 1 1 0 0 0 1 1 0\n",
            " 1 0 1 0 1 0 0 1 0 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 0 1 0 1 1 0 0\n",
            " 1 1 0 1 0 0 1 0 0 1 1 0 0 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1\n",
            " 0 1 0 1 1 1 1 0 0 1 0 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 0\n",
            " 0 0 0 0 1 1 0 1 1 0 0 1 0 0 1 0 0 1 0 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 0 0\n",
            " 0 0 0 0 1 1 1 1 1 1 1 0 0 0 1 1 1 1 0 1 0 0 0 0 1 0 0 0 1 1 0 0 1 1 0 1 0\n",
            " 0 1 1 1 1 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 0 0 1 0 1 1 1 0 1 1 1 0 1 0 1 0 0\n",
            " 0 0 1 0 1 1 0 1 1 0 1 1 0 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 0 0 0 1 0 1 1 1\n",
            " 1 0 1 1 1 0 1 0 0 0 1 0 1 1 0 0 0 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 0 1 0 1\n",
            " 0 0 1 0 0 1 0 1 1 1 1 0 0 0 1 1 0 1 1 0 1 1 1 1 1 1 1 0 1 0 0 1 1 0 1 1 1\n",
            " 1 1 0 0 1 1 0 0 1 1 1 1 0 1 0 1 1 1 0 0 1 1 1 1 0 1 1 1 1 1 0 0 1 0 1 1 0\n",
            " 0 0 1 0 1 0 1 1 1 0 0 1 0 0 1 1 0 0 1 1 1 1 0 0 1 0 1 0 0 1 1 1 1 1 0 0 0\n",
            " 1 0 1 1 1 1 1 0 0 1 0 1 0 0 0 0 1 0 1 1 1 0 1 1 0 0 1 0 0 1 1 1 1 0 0 1 0\n",
            " 0 1 1 0 0 1 1 1 1 0 1 0 0 1 0 1 1 0 0 0 1 0 1 1 1 1 1 0 1 0 0 1 0 0 0 0 1\n",
            " 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 0 1 1 0 1 0 1 0 0 0 1 0 0\n",
            " 1 0 1 0 1 0 1 1 0 0 1 1 1 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 1 1\n",
            " 0 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 0 1 1 0 1 0 0 0 1 0 1 1 1 0 0 0 1 0 1 1\n",
            " 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 1 1 0 1 0 1 1 0 1 0 0 1 1 1 1\n",
            " 1 0 0 0]\n",
            "trainset before adding uncertain samples (410, 10) (410,)\n",
            "trainset after adding uncertain samples (420, 10) (420,)\n",
            "updated train set: (420, 10) (420,) unique(labels): [223 197] [0 1]\n",
            "val set: (882, 10) (882,)\n",
            "\n",
            "Train set: (420, 10)\n",
            "Validation set: (882, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 42\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.257 s \n",
            "\n",
            "Accuracy rate is 78.801843 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.86      0.86       321\n",
            "           1       0.59      0.59      0.59       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.72      0.72      0.72       434\n",
            "weighted avg       0.79      0.79      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[275  46]\n",
            " [ 46  67]]\n",
            "--------------------------------\n",
            "val predicted: (882,) [1 1 0 1 0 1 1 0 0 0 1 1 1 0 0 0 0 1 1 1 0 1 1 1 0 0 1 1 0 0 0 1 1 0 1 1 1\n",
            " 1 1 0 0 1 1 1 1 1 0 1 0 1 1 0 0 1 1 1 1 1 0 1 0 0 1 0 1 1 0 1 0 0 1 1 1 1\n",
            " 1 0 1 0 0 1 1 1 0 0 0 0 1 1 0 1 0 1 0 1 1 1 1 0 1 0 0 1 0 0 0 1 0 1 1 0 1\n",
            " 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 0 1\n",
            " 0 0 1 1 0 1 1 1 0 0 0 0 0 0 1 1 1 0 1 0 0 0 0 0 1 1 0 1 0 0 0 1 1 1 0 1 1\n",
            " 0 1 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 0 1 0 1 1 1 1 0 1 1 0 1 1\n",
            " 1 0 1 1 0 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 0 0 0 1 1 1 1 1 0 0 0 1 1 0 1 0 1\n",
            " 0 1 0 0 1 0 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 0 1 0 1 1 0 0 1 1 0\n",
            " 1 0 0 1 0 0 1 1 0 0 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 0 1 0\n",
            " 1 1 1 1 0 0 1 0 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 0 0 0 0\n",
            " 0 1 1 0 1 1 0 1 0 0 1 0 0 1 0 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 0 0 0 0 0 0\n",
            " 1 1 1 1 1 1 0 0 0 1 1 1 1 0 1 0 0 0 0 1 0 0 0 1 1 0 0 1 1 0 1 0 0 1 1 1 1\n",
            " 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 0 0 1 0 1 1 0 1 1 1 0 1 0 1 0 0 0 0 1 0 1 1\n",
            " 0 1 1 0 1 1 0 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 0 0 0 1 0 1 1 1 1 0 1 1 1 0\n",
            " 1 0 0 0 1 0 1 1 0 0 0 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 0 1 0 1 0 0 1 0 0 1\n",
            " 0 1 1 1 1 0 0 0 1 1 0 1 1 0 1 1 1 1 1 1 1 0 1 0 0 1 1 0 1 1 1 1 1 0 0 1 1\n",
            " 0 0 1 1 1 1 0 1 0 1 1 1 0 0 1 1 1 1 0 1 1 1 1 1 0 0 1 0 1 1 0 0 0 1 0 1 0\n",
            " 1 1 1 0 0 1 0 1 1 0 0 1 1 1 1 0 0 1 0 1 0 0 1 1 1 1 1 0 0 0 1 0 1 1 1 1 1\n",
            " 0 0 1 0 1 0 0 0 0 1 0 1 1 1 0 1 0 0 1 0 0 1 1 1 1 0 0 1 0 0 1 1 0 0 1 1 1\n",
            " 1 0 1 0 0 1 0 1 1 0 0 0 1 0 1 1 1 1 1 0 1 0 0 1 0 0 0 0 1 1 1 1 1 1 1 1 1\n",
            " 0 1 1 1 1 1 1 1 0 0 0 1 1 1 1 0 1 1 0 1 0 1 0 0 0 1 0 0 1 0 1 0 1 0 1 1 0\n",
            " 0 1 1 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1\n",
            " 1 1 1 1 0 1 1 0 1 1 0 1 0 0 0 1 0 1 1 1 0 0 0 1 0 1 1 0 1 0 1 1 1 1 1 1 1\n",
            " 1 0 0 1 1 0 0 1 1 0 0 1 1 1 0 1 0 1 1 0 1 0 0 1 1 1 1 1 0 0 0]\n",
            "probabilities: (882, 2) \n",
            " [1 1 0 1 0 1 1 0 0 0 1 1 1 0 0 0 0 1 1 1 0 1 1 1 0 0 1 1 0 0 0 1 1 0 1 1 1\n",
            " 1 1 0 0 1 1 1 1 1 0 1 0 1 1 0 0 1 1 1 1 1 0 1 0 0 1 0 1 1 0 1 0 0 1 1 1 1\n",
            " 1 0 1 0 0 1 1 1 0 0 0 0 1 1 0 1 0 1 0 1 1 1 1 0 1 0 0 1 0 0 0 1 0 1 1 0 1\n",
            " 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 0 1\n",
            " 0 0 1 1 0 1 1 1 0 0 0 0 0 0 1 1 1 0 1 0 0 0 0 0 1 1 0 1 0 0 0 1 1 1 0 1 1\n",
            " 0 1 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 0 1 0 1 1 1 1 0 1 1 0 1 1\n",
            " 1 0 1 1 0 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 0 0 0 1 1 1 1 1 0 0 0 1 1 0 1 0 1\n",
            " 0 1 0 0 1 0 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 0 1 0 1 1 0 0 1 1 0\n",
            " 1 0 0 1 0 0 1 1 0 0 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 0 1 0\n",
            " 1 1 1 1 0 0 1 0 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 0 0 0 0\n",
            " 0 1 1 0 1 1 0 1 0 0 1 0 0 1 0 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 0 0 0 0 0 0\n",
            " 1 1 1 1 1 1 0 0 0 1 1 1 1 0 1 0 0 0 0 1 0 0 0 1 1 0 0 1 1 0 1 0 0 1 1 1 1\n",
            " 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 0 0 1 0 1 1 0 1 1 1 0 1 0 1 0 0 0 0 1 0 1 1\n",
            " 0 1 1 0 1 1 0 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 0 0 0 1 0 1 1 1 1 0 1 1 1 0\n",
            " 1 0 0 0 1 0 1 1 0 0 0 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 0 1 0 1 0 0 1 0 0 1\n",
            " 0 1 1 1 1 0 0 0 1 1 0 1 1 0 1 1 1 1 1 1 1 0 1 0 0 1 1 0 1 1 1 1 1 0 0 1 1\n",
            " 0 0 1 1 1 1 0 1 0 1 1 1 0 0 1 1 1 1 0 1 1 1 1 1 0 0 1 0 1 1 0 0 0 1 0 1 0\n",
            " 1 1 1 0 0 1 0 1 1 0 0 1 1 1 1 0 0 1 0 1 0 0 1 1 1 1 1 0 0 0 1 0 1 1 1 1 1\n",
            " 0 0 1 0 1 0 0 0 0 1 0 1 1 1 0 1 0 0 1 0 0 1 1 1 1 0 0 1 0 0 1 1 0 0 1 1 1\n",
            " 1 0 1 0 0 1 0 1 1 0 0 0 1 0 1 1 1 1 1 0 1 0 0 1 0 0 0 0 1 1 1 1 1 1 1 1 1\n",
            " 0 1 1 1 1 1 1 1 0 0 0 1 1 1 1 0 1 1 0 1 0 1 0 0 0 1 0 0 1 0 1 0 1 0 1 1 0\n",
            " 0 1 1 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1\n",
            " 1 1 1 1 0 1 1 0 1 1 0 1 0 0 0 1 0 1 1 1 0 0 0 1 0 1 1 0 1 0 1 1 1 1 1 1 1\n",
            " 1 0 0 1 1 0 0 1 1 0 0 1 1 1 0 1 0 1 1 0 1 0 0 1 1 1 1 1 0 0 0]\n",
            "trainset before adding uncertain samples (420, 10) (420,)\n",
            "trainset after adding uncertain samples (430, 10) (430,)\n",
            "updated train set: (430, 10) (430,) unique(labels): [226 204] [0 1]\n",
            "val set: (872, 10) (872,)\n",
            "\n",
            "Train set: (430, 10)\n",
            "Validation set: (872, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 43\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.278 s \n",
            "\n",
            "Accuracy rate is 78.571429 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.85      0.85       321\n",
            "           1       0.59      0.59      0.59       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.72      0.72      0.72       434\n",
            "weighted avg       0.79      0.79      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[274  47]\n",
            " [ 46  67]]\n",
            "--------------------------------\n",
            "val predicted: (872,) [1 1 0 1 0 1 1 0 0 0 1 1 1 0 0 0 0 1 1 1 0 1 1 1 0 0 1 1 0 0 0 1 1 0 1 1 1\n",
            " 1 1 0 0 1 1 1 1 0 1 0 1 1 0 0 1 1 1 1 1 0 1 0 0 1 0 1 1 1 0 0 1 1 1 1 1 0\n",
            " 1 0 0 1 1 1 0 0 0 0 1 1 0 1 0 1 0 1 1 1 1 0 1 0 0 1 0 0 0 1 0 1 1 0 1 1 0\n",
            " 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 1 1 1 1 0 0 1 1 1 1 1 1 1 0 1 0 0 1\n",
            " 1 0 1 1 1 0 0 0 0 0 0 1 1 1 0 1 0 0 0 0 0 1 1 0 1 0 0 0 1 1 1 0 1 1 0 1 1\n",
            " 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 0 1 0 1 1 1 1 0 1 1 0 1 1 1 0 1 1\n",
            " 0 1 1 1 1 1 1 1 1 0 0 1 0 1 1 0 0 0 1 1 1 1 1 0 0 0 1 1 0 0 1 0 1 0 0 1 0\n",
            " 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 0 1 0 1 1 0 0 1 1 0 1 0 0 1 0 0\n",
            " 1 1 0 0 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 0 1 0 1 1 1 1 0 0\n",
            " 1 0 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 0 0 0 0 0 1 1 0 1 1\n",
            " 0 1 0 0 1 0 0 1 0 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 0 0 0 0 0 0 1 1 1 1 1 1\n",
            " 0 0 0 1 1 1 1 0 1 0 0 0 0 0 0 0 1 1 0 0 1 1 0 1 0 0 1 1 1 1 0 1 1 1 1 1 1\n",
            " 0 1 1 0 0 1 1 0 0 0 1 0 1 1 0 1 1 1 0 1 0 1 0 0 0 0 1 0 1 1 0 1 1 0 1 1 0\n",
            " 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 0 0 0 1 0 1 1 1 1 0 1 1 1 0 1 0 0 0 1 0 1\n",
            " 1 0 0 0 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 0 1 0 1 0 0 1 0 0 1 0 1 1 1 1 0 0\n",
            " 0 1 1 0 1 1 0 1 1 1 1 1 1 1 0 1 0 0 1 1 0 1 1 1 1 1 0 0 1 1 0 0 1 1 1 1 0\n",
            " 1 0 1 1 1 0 0 1 1 1 1 0 1 1 1 1 1 0 0 1 0 1 1 0 0 0 1 0 1 0 1 1 1 0 0 1 0\n",
            " 1 1 0 0 1 1 1 1 0 0 1 0 1 0 0 1 1 1 1 1 0 0 0 1 0 1 1 1 1 1 0 0 1 0 1 0 0\n",
            " 0 0 1 0 1 1 0 0 0 1 0 0 1 1 1 1 0 0 1 0 0 1 1 0 0 1 1 1 1 0 1 0 0 1 0 1 1\n",
            " 0 0 0 1 0 1 1 1 1 1 0 1 0 0 1 0 0 0 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0\n",
            " 0 0 1 1 1 1 0 1 1 0 1 0 1 0 0 0 1 0 0 1 0 1 0 1 0 1 1 0 0 1 1 0 1 1 0 0 1\n",
            " 0 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 0 1 1\n",
            " 0 1 0 0 0 1 0 1 1 1 0 0 0 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 0 0 1 1 0\n",
            " 0 1 1 1 0 1 0 1 1 0 1 0 0 1 1 1 1 1 0 0 0]\n",
            "probabilities: (872, 2) \n",
            " [1 1 0 1 0 1 1 0 0 0 1 1 1 0 0 0 0 1 1 1 0 1 1 1 0 0 1 1 0 0 0 1 1 0 1 1 1\n",
            " 1 1 0 0 1 1 1 1 0 1 0 1 1 0 0 1 1 1 1 1 0 1 0 0 1 0 1 1 1 0 0 1 1 1 1 1 0\n",
            " 1 0 0 1 1 1 0 0 0 0 1 1 0 1 0 1 0 1 1 1 1 0 1 0 0 1 0 0 0 1 0 1 1 0 1 1 0\n",
            " 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 1 1 1 1 0 0 1 1 1 1 1 1 1 0 1 0 0 1\n",
            " 1 0 1 1 1 0 0 0 0 0 0 1 1 1 0 1 0 0 0 0 0 1 1 0 1 0 0 0 1 1 1 0 1 1 0 1 1\n",
            " 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 0 1 0 1 1 1 1 0 1 1 0 1 1 1 0 1 1\n",
            " 0 1 1 1 1 1 1 1 1 0 0 1 0 1 1 0 0 0 1 1 1 1 1 0 0 0 1 1 0 0 1 0 1 0 0 1 0\n",
            " 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 0 1 0 1 1 0 0 1 1 0 1 0 0 1 0 0\n",
            " 1 1 0 0 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 0 1 0 1 1 1 1 0 0\n",
            " 1 0 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 0 0 0 0 0 1 1 0 1 1\n",
            " 0 1 0 0 1 0 0 1 0 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 0 0 0 0 0 0 1 1 1 1 1 1\n",
            " 0 0 0 1 1 1 1 0 1 0 0 0 0 0 0 0 1 1 0 0 1 1 0 1 0 0 1 1 1 1 0 1 1 1 1 1 1\n",
            " 0 1 1 0 0 1 1 0 0 0 1 0 1 1 0 1 1 1 0 1 0 1 0 0 0 0 1 0 1 1 0 1 1 0 1 1 0\n",
            " 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 0 0 0 1 0 1 1 1 1 0 1 1 1 0 1 0 0 0 1 0 1\n",
            " 1 0 0 0 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 0 1 0 1 0 0 1 0 0 1 0 1 1 1 1 0 0\n",
            " 0 1 1 0 1 1 0 1 1 1 1 1 1 1 0 1 0 0 1 1 0 1 1 1 1 1 0 0 1 1 0 0 1 1 1 1 0\n",
            " 1 0 1 1 1 0 0 1 1 1 1 0 1 1 1 1 1 0 0 1 0 1 1 0 0 0 1 0 1 0 1 1 1 0 0 1 0\n",
            " 1 1 0 0 1 1 1 1 0 0 1 0 1 0 0 1 1 1 1 1 0 0 0 1 0 1 1 1 1 1 0 0 1 0 1 0 0\n",
            " 0 0 1 0 1 1 0 0 0 1 0 0 1 1 1 1 0 0 1 0 0 1 1 0 0 1 1 1 1 0 1 0 0 1 0 1 1\n",
            " 0 0 0 1 0 1 1 1 1 1 0 1 0 0 1 0 0 0 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0\n",
            " 0 0 1 1 1 1 0 1 1 0 1 0 1 0 0 0 1 0 0 1 0 1 0 1 0 1 1 0 0 1 1 0 1 1 0 0 1\n",
            " 0 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 0 1 1\n",
            " 0 1 0 0 0 1 0 1 1 1 0 0 0 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 0 0 1 1 0\n",
            " 0 1 1 1 0 1 0 1 1 0 1 0 0 1 1 1 1 1 0 0 0]\n",
            "trainset before adding uncertain samples (430, 10) (430,)\n",
            "trainset after adding uncertain samples (440, 10) (440,)\n",
            "updated train set: (440, 10) (440,) unique(labels): [230 210] [0 1]\n",
            "val set: (862, 10) (862,)\n",
            "\n",
            "Train set: (440, 10)\n",
            "Validation set: (862, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 44\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.280 s \n",
            "\n",
            "Accuracy rate is 79.032258 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.86      0.86       321\n",
            "           1       0.60      0.58      0.59       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.73      0.72      0.73       434\n",
            "weighted avg       0.79      0.79      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[277  44]\n",
            " [ 47  66]]\n",
            "--------------------------------\n",
            "val predicted: (862,) [1 1 0 1 0 1 1 0 0 0 1 1 1 0 0 0 0 1 1 1 0 1 1 1 0 0 1 1 0 0 0 1 1 0 1 1 1\n",
            " 1 1 0 0 1 1 1 1 0 1 0 1 1 0 0 1 1 1 1 1 0 1 0 0 1 0 1 1 1 0 0 1 1 1 1 1 0\n",
            " 1 0 0 1 1 1 0 0 0 1 1 0 1 0 1 0 1 1 1 1 0 1 0 0 1 0 0 0 1 0 1 1 0 1 0 1 1\n",
            " 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 1 1 1 1 0 0 1 1 1 1 1 1 1 0 1 0 0 1 1 0\n",
            " 1 1 1 0 0 0 0 0 0 1 1 1 0 1 0 0 0 0 0 1 1 0 1 0 0 0 1 1 1 0 1 1 0 1 1 0 0\n",
            " 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 0 1 1 0 1 1 1 0 1 1 0 1 1\n",
            " 1 1 1 1 1 1 0 0 1 0 1 1 0 0 0 1 1 1 1 0 0 0 1 1 0 0 1 0 1 0 0 1 0 1 0 0 0\n",
            " 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 0 1 0 1 1 0 0 1 1 0 1 0 0 1 0 0 1 1 0 0\n",
            " 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 0 1 0 1 1 1 1 0 0 1 0 1 0\n",
            " 1 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 0 0 0 0 0 1 1 0 1 1 0 1 0 0\n",
            " 1 0 0 1 0 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 0 0 0 0 0 1 1 1 1 1 1 0 0 0 1 1\n",
            " 1 1 0 1 0 0 0 0 0 0 0 1 1 0 0 1 0 1 0 0 1 1 1 0 1 1 1 1 1 1 0 1 1 0 0 1 1\n",
            " 0 0 0 1 0 1 1 0 1 1 1 0 1 0 1 0 0 0 0 1 0 1 1 0 1 1 0 1 1 0 1 1 0 1 1 1 0\n",
            " 1 1 1 1 1 1 1 1 1 0 0 0 1 0 1 1 1 1 0 1 1 1 0 1 0 0 0 1 0 1 1 0 0 0 1 1 0\n",
            " 1 1 1 1 0 1 1 1 1 0 1 0 0 1 0 1 0 0 1 0 0 1 0 1 1 1 1 0 0 0 1 1 0 1 1 0 1\n",
            " 1 1 1 1 1 1 0 1 0 0 1 1 0 1 1 1 1 1 0 0 1 1 0 0 1 1 1 1 0 1 0 1 1 1 0 0 1\n",
            " 1 1 1 0 1 1 1 1 1 0 0 1 0 1 1 0 0 0 1 0 1 0 1 1 0 0 1 0 1 1 0 0 1 1 1 1 0\n",
            " 0 1 0 1 0 0 1 1 1 1 1 0 0 0 1 0 1 1 1 1 1 0 0 1 0 1 0 0 0 0 1 0 1 1 0 0 0\n",
            " 1 0 0 1 1 1 1 0 0 1 0 0 1 1 0 0 1 1 1 1 0 1 0 0 1 0 1 1 0 0 0 1 0 1 1 1 1\n",
            " 1 0 1 0 0 1 0 0 0 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 0 0 1 1 1 1 0 1 1\n",
            " 0 1 0 1 0 0 0 1 0 0 1 0 1 0 1 0 1 1 0 0 1 1 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1\n",
            " 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 0 1 1 0 1 0 0 0 1 0 1 1 1\n",
            " 0 0 0 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 1 1 0 1 0 1 1 0\n",
            " 1 0 0 1 1 1 1 1 0 0 0]\n",
            "probabilities: (862, 2) \n",
            " [1 1 0 1 0 1 1 0 0 0 1 1 1 0 0 0 0 1 1 1 0 1 1 1 0 0 1 1 0 0 0 1 1 0 1 1 1\n",
            " 1 1 0 0 1 1 1 1 0 1 0 1 1 0 0 1 1 1 1 1 0 1 0 0 1 0 1 1 1 0 0 1 1 1 1 1 0\n",
            " 1 0 0 1 1 1 0 0 0 1 1 0 1 0 1 0 1 1 1 1 0 1 0 0 1 0 0 0 1 0 1 1 0 1 0 1 1\n",
            " 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 1 1 1 1 0 0 1 1 1 1 1 1 1 0 1 0 0 1 1 0\n",
            " 1 1 1 0 0 0 0 0 0 1 1 1 0 1 0 0 0 0 0 1 1 0 1 0 0 0 1 1 1 0 1 1 0 1 1 0 0\n",
            " 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 0 1 1 0 1 1 1 0 1 1 0 1 1\n",
            " 1 1 1 1 1 1 0 0 1 0 1 1 0 0 0 1 1 1 1 0 0 0 1 1 0 0 1 0 1 0 0 1 0 1 0 0 0\n",
            " 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 0 1 0 1 1 0 0 1 1 0 1 0 0 1 0 0 1 1 0 0\n",
            " 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 0 1 0 1 1 1 1 0 0 1 0 1 0\n",
            " 1 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 0 0 0 0 0 1 1 0 1 1 0 1 0 0\n",
            " 1 0 0 1 0 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 0 0 0 0 0 1 1 1 1 1 1 0 0 0 1 1\n",
            " 1 1 0 1 0 0 0 0 0 0 0 1 1 0 0 1 0 1 0 0 1 1 1 0 1 1 1 1 1 1 0 1 1 0 0 1 1\n",
            " 0 0 0 1 0 1 1 0 1 1 1 0 1 0 1 0 0 0 0 1 0 1 1 0 1 1 0 1 1 0 1 1 0 1 1 1 0\n",
            " 1 1 1 1 1 1 1 1 1 0 0 0 1 0 1 1 1 1 0 1 1 1 0 1 0 0 0 1 0 1 1 0 0 0 1 1 0\n",
            " 1 1 1 1 0 1 1 1 1 0 1 0 0 1 0 1 0 0 1 0 0 1 0 1 1 1 1 0 0 0 1 1 0 1 1 0 1\n",
            " 1 1 1 1 1 1 0 1 0 0 1 1 0 1 1 1 1 1 0 0 1 1 0 0 1 1 1 1 0 1 0 1 1 1 0 0 1\n",
            " 1 1 1 0 1 1 1 1 1 0 0 1 0 1 1 0 0 0 1 0 1 0 1 1 0 0 1 0 1 1 0 0 1 1 1 1 0\n",
            " 0 1 0 1 0 0 1 1 1 1 1 0 0 0 1 0 1 1 1 1 1 0 0 1 0 1 0 0 0 0 1 0 1 1 0 0 0\n",
            " 1 0 0 1 1 1 1 0 0 1 0 0 1 1 0 0 1 1 1 1 0 1 0 0 1 0 1 1 0 0 0 1 0 1 1 1 1\n",
            " 1 0 1 0 0 1 0 0 0 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 0 0 1 1 1 1 0 1 1\n",
            " 0 1 0 1 0 0 0 1 0 0 1 0 1 0 1 0 1 1 0 0 1 1 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1\n",
            " 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 0 1 1 0 1 0 0 0 1 0 1 1 1\n",
            " 0 0 0 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 1 1 0 1 0 1 1 0\n",
            " 1 0 0 1 1 1 1 1 0 0 0]\n",
            "trainset before adding uncertain samples (440, 10) (440,)\n",
            "trainset after adding uncertain samples (450, 10) (450,)\n",
            "updated train set: (450, 10) (450,) unique(labels): [232 218] [0 1]\n",
            "val set: (852, 10) (852,)\n",
            "\n",
            "Train set: (450, 10)\n",
            "Validation set: (852, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 45\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.294 s \n",
            "\n",
            "Accuracy rate is 79.262673 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.86      0.86       321\n",
            "           1       0.60      0.61      0.61       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.73      0.73      0.73       434\n",
            "weighted avg       0.79      0.79      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[275  46]\n",
            " [ 44  69]]\n",
            "--------------------------------\n",
            "val predicted: (852,) [1 1 0 1 0 1 1 0 0 0 1 1 1 0 0 0 0 1 1 1 0 1 1 1 0 0 1 1 0 0 0 1 1 0 1 1 1\n",
            " 1 1 0 0 1 1 1 1 0 1 0 1 1 0 0 1 1 1 1 1 0 1 0 0 1 0 1 1 1 0 0 1 1 1 1 1 0\n",
            " 1 0 0 1 1 1 0 0 0 1 1 0 1 0 1 0 1 1 1 1 0 1 0 0 1 0 0 0 1 0 1 1 0 1 0 1 1\n",
            " 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 1 1 1 1 0 0 1 1 1 1 1 1 1 0 1 0 0 1 1 0\n",
            " 1 1 1 0 0 0 0 0 0 1 1 1 0 1 0 0 0 0 0 1 1 0 1 0 0 0 1 1 1 0 1 1 0 1 1 0 0\n",
            " 0 0 1 1 1 1 1 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 0 1 1 0 1 1 1 0 1 1 0 1 1 1\n",
            " 1 1 1 1 1 0 0 1 0 1 1 0 0 0 1 1 1 1 0 0 0 1 1 0 0 1 0 1 0 0 1 0 1 0 0 0 0\n",
            " 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 0 1 0 1 1 0 0 1 1 0 1 0 0 1 0 0 1 1 0 0 1\n",
            " 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 0 1 0 1 1 1 1 0 0 1 0 1 0 1\n",
            " 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 0 0 0 0 0 1 1 0 1 1 0 1 0 0 1\n",
            " 0 1 0 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 0 0 0 0 0 1 1 1 1 1 1 0 0 0 1 1 1 1\n",
            " 0 1 0 0 0 0 0 0 0 1 1 0 0 1 0 1 0 0 1 1 1 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 0\n",
            " 0 1 0 1 1 0 1 1 1 0 1 0 1 0 0 0 0 1 0 1 1 0 1 1 0 1 1 0 1 1 0 1 1 1 0 1 1\n",
            " 1 1 1 1 1 1 1 0 0 0 1 0 1 1 1 1 0 1 1 1 0 1 0 0 0 0 1 1 0 0 0 1 1 0 1 1 1\n",
            " 0 1 1 1 1 1 0 0 1 0 1 0 0 1 0 0 1 0 1 1 1 1 0 0 1 1 0 1 1 0 1 1 1 1 1 1 1\n",
            " 0 1 0 0 1 1 0 1 1 1 1 1 0 0 1 1 0 0 1 1 1 1 0 1 0 1 1 1 0 0 1 1 1 1 0 1 1\n",
            " 1 1 1 0 0 1 0 1 1 0 0 0 1 0 1 0 1 1 0 0 1 0 1 1 0 0 1 1 1 1 0 0 1 0 1 0 0\n",
            " 1 1 1 1 1 0 0 0 1 0 1 1 1 1 0 0 1 0 1 0 0 0 0 1 0 1 1 0 0 0 1 0 0 1 1 1 1\n",
            " 0 1 0 0 1 1 0 0 1 1 1 1 0 1 0 0 1 0 1 1 0 0 0 1 0 1 1 1 1 0 1 0 0 1 0 0 0\n",
            " 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 0 0 1 1 1 0 1 1 0 1 0 1 0 0 0 1 0 0\n",
            " 1 0 1 0 1 0 1 1 0 0 1 1 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 1 0 1\n",
            " 1 1 1 1 1 1 0 1 1 1 1 0 1 1 0 1 1 0 1 0 0 0 1 0 1 1 1 0 0 0 1 0 1 1 0 1 0\n",
            " 1 1 1 1 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 1 1 0 1 0 1 1 0 1 0 0 1 1 1 1 1 0 0\n",
            " 0]\n",
            "probabilities: (852, 2) \n",
            " [1 1 0 1 0 1 1 0 0 0 1 1 1 0 0 0 0 1 1 1 0 1 1 1 0 0 1 1 0 0 0 1 1 0 1 1 1\n",
            " 1 1 0 0 1 1 1 1 0 1 0 1 1 0 0 1 1 1 1 1 0 1 0 0 1 0 1 1 1 0 0 1 1 1 1 1 0\n",
            " 1 0 0 1 1 1 0 0 0 1 1 0 1 0 1 0 1 1 1 1 0 1 0 0 1 0 0 0 1 0 1 1 0 1 0 1 1\n",
            " 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 1 1 1 1 0 0 1 1 1 1 1 1 1 0 1 0 0 1 1 0\n",
            " 1 1 1 0 0 0 0 0 0 1 1 1 0 1 0 0 0 0 0 1 1 0 1 0 0 0 1 1 1 0 1 1 0 1 1 0 0\n",
            " 0 0 1 1 1 1 1 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 0 1 1 0 1 1 1 0 1 1 0 1 1 1\n",
            " 1 1 1 1 1 0 0 1 0 1 1 0 0 0 1 1 1 1 0 0 0 1 1 0 0 1 0 1 0 0 1 0 1 0 0 0 0\n",
            " 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 0 1 0 1 1 0 0 1 1 0 1 0 0 1 0 0 1 1 0 0 1\n",
            " 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 0 1 0 1 1 1 1 0 0 1 0 1 0 1\n",
            " 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 0 0 0 0 0 1 1 0 1 1 0 1 0 0 1\n",
            " 0 1 0 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 0 0 0 0 0 1 1 1 1 1 1 0 0 0 1 1 1 1\n",
            " 0 1 0 0 0 0 0 0 0 1 1 0 0 1 0 1 0 0 1 1 1 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 0\n",
            " 0 1 0 1 1 0 1 1 1 0 1 0 1 0 0 0 0 1 0 1 1 0 1 1 0 1 1 0 1 1 0 1 1 1 0 1 1\n",
            " 1 1 1 1 1 1 1 0 0 0 1 0 1 1 1 1 0 1 1 1 0 1 0 0 0 0 1 1 0 0 0 1 1 0 1 1 1\n",
            " 0 1 1 1 1 1 0 0 1 0 1 0 0 1 0 0 1 0 1 1 1 1 0 0 1 1 0 1 1 0 1 1 1 1 1 1 1\n",
            " 0 1 0 0 1 1 0 1 1 1 1 1 0 0 1 1 0 0 1 1 1 1 0 1 0 1 1 1 0 0 1 1 1 1 0 1 1\n",
            " 1 1 1 0 0 1 0 1 1 0 0 0 1 0 1 0 1 1 0 0 1 0 1 1 0 0 1 1 1 1 0 0 1 0 1 0 0\n",
            " 1 1 1 1 1 0 0 0 1 0 1 1 1 1 0 0 1 0 1 0 0 0 0 1 0 1 1 0 0 0 1 0 0 1 1 1 1\n",
            " 0 1 0 0 1 1 0 0 1 1 1 1 0 1 0 0 1 0 1 1 0 0 0 1 0 1 1 1 1 0 1 0 0 1 0 0 0\n",
            " 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 0 0 1 1 1 0 1 1 0 1 0 1 0 0 0 1 0 0\n",
            " 1 0 1 0 1 0 1 1 0 0 1 1 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 1 0 1\n",
            " 1 1 1 1 1 1 0 1 1 1 1 0 1 1 0 1 1 0 1 0 0 0 1 0 1 1 1 0 0 0 1 0 1 1 0 1 0\n",
            " 1 1 1 1 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 1 1 0 1 0 1 1 0 1 0 0 1 1 1 1 1 0 0\n",
            " 0]\n",
            "trainset before adding uncertain samples (450, 10) (450,)\n",
            "trainset after adding uncertain samples (460, 10) (460,)\n",
            "updated train set: (460, 10) (460,) unique(labels): [237 223] [0 1]\n",
            "val set: (842, 10) (842,)\n",
            "\n",
            "Train set: (460, 10)\n",
            "Validation set: (842, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 46\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.311 s \n",
            "\n",
            "Accuracy rate is 78.571429 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.85      0.85       321\n",
            "           1       0.59      0.59      0.59       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.72      0.72      0.72       434\n",
            "weighted avg       0.79      0.79      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[274  47]\n",
            " [ 46  67]]\n",
            "--------------------------------\n",
            "val predicted: (842,) [1 1 0 1 0 1 1 0 0 0 1 1 1 0 0 0 0 1 1 1 0 1 1 1 0 0 1 1 0 0 0 1 1 0 1 1 1\n",
            " 1 1 0 0 1 1 1 1 0 1 0 1 1 0 0 1 1 1 1 1 0 1 0 0 1 0 1 1 1 0 0 1 1 1 1 1 0\n",
            " 1 0 0 1 1 1 0 0 1 1 0 1 0 1 0 1 1 1 1 0 1 0 0 1 0 0 0 1 0 1 1 0 1 0 1 1 1\n",
            " 1 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 1 1 1 1 0 0 1 1 1 1 1 1 1 0 1 0 0 1 1 0 1\n",
            " 1 1 0 0 0 0 0 0 1 1 1 0 1 0 0 0 0 0 1 1 0 1 0 0 0 1 1 1 0 1 1 0 1 1 0 0 0\n",
            " 0 1 1 1 1 1 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 0 1 1 0 1 1 1 0 1 1 0 1 1 1 1\n",
            " 1 1 1 1 0 0 1 0 1 1 0 0 0 1 1 1 1 0 0 0 1 1 0 0 1 0 1 0 0 1 0 1 0 0 0 0 0\n",
            " 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 0 1 0 1 1 0 0 1 1 0 1 0 0 1 0 0 1 1 0 0 1 1\n",
            " 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 0 1 0 1 1 1 1 0 0 1 0 1 0 1 1\n",
            " 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 0 0 0 0 0 1 1 0 1 1 0 1 0 0 1 0\n",
            " 1 0 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 0 0 0 0 0 1 1 1 1 1 1 0 0 0 1 1 1 0 1\n",
            " 0 0 0 0 0 0 0 1 1 0 0 1 0 1 0 0 1 1 1 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 0 1 0\n",
            " 1 1 0 1 1 1 0 1 0 1 0 0 0 1 0 1 1 0 1 1 0 1 1 0 1 1 0 1 1 1 0 1 1 1 1 1 1\n",
            " 1 1 0 0 0 1 0 1 1 1 1 0 1 1 1 1 0 0 0 0 1 1 0 0 0 1 1 0 1 1 1 0 1 1 1 1 1\n",
            " 0 0 1 0 1 0 0 1 0 0 1 0 1 1 1 1 0 0 1 1 0 1 1 0 1 1 1 1 1 1 1 0 1 0 0 1 1\n",
            " 0 1 1 1 1 1 0 0 1 1 0 0 1 1 1 1 0 1 0 1 1 0 0 1 1 1 1 0 1 1 1 1 1 0 0 1 0\n",
            " 1 1 0 0 0 1 1 0 1 1 0 0 1 0 1 1 0 0 1 1 1 1 0 0 1 0 1 0 0 1 1 1 1 1 0 0 0\n",
            " 1 1 1 1 1 0 0 1 0 1 0 0 0 0 1 0 1 1 0 0 0 1 0 0 1 1 1 1 0 1 0 0 1 1 0 0 1\n",
            " 1 1 1 0 1 0 0 1 0 1 1 0 0 0 1 0 1 1 1 1 0 1 0 0 1 0 0 0 0 1 1 1 1 1 1 1 1\n",
            " 1 0 1 1 1 1 1 1 1 0 0 0 1 1 1 0 1 1 0 1 0 1 0 0 0 1 0 0 1 0 1 0 1 0 1 1 0\n",
            " 0 1 1 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1\n",
            " 1 1 0 1 1 0 1 1 0 1 0 0 0 1 0 1 1 1 0 0 0 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 0\n",
            " 0 1 1 0 0 1 1 0 1 1 1 0 1 0 1 1 0 1 0 0 1 1 1 1 1 0 0 0]\n",
            "probabilities: (842, 2) \n",
            " [1 1 0 1 0 1 1 0 0 0 1 1 1 0 0 0 0 1 1 1 0 1 1 1 0 0 1 1 0 0 0 1 1 0 1 1 1\n",
            " 1 1 0 0 1 1 1 1 0 1 0 1 1 0 0 1 1 1 1 1 0 1 0 0 1 0 1 1 1 0 0 1 1 1 1 1 0\n",
            " 1 0 0 1 1 1 0 0 1 1 0 1 0 1 0 1 1 1 1 0 1 0 0 1 0 0 0 1 0 1 1 0 1 0 1 1 1\n",
            " 1 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 1 1 1 1 0 0 1 1 1 1 1 1 1 0 1 0 0 1 1 0 1\n",
            " 1 1 0 0 0 0 0 0 1 1 1 0 1 0 0 0 0 0 1 1 0 1 0 0 0 1 1 1 0 1 1 0 1 1 0 0 0\n",
            " 0 1 1 1 1 1 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 0 1 1 0 1 1 1 0 1 1 0 1 1 1 1\n",
            " 1 1 1 1 0 0 1 0 1 1 0 0 0 1 1 1 1 0 0 0 1 1 0 0 1 0 1 0 0 1 0 1 0 0 0 0 0\n",
            " 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 0 1 0 1 1 0 0 1 1 0 1 0 0 1 0 0 1 1 0 0 1 1\n",
            " 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 0 1 0 1 1 1 1 0 0 1 0 1 0 1 1\n",
            " 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 0 0 0 0 0 1 1 0 1 1 0 1 0 0 1 0\n",
            " 1 0 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 0 0 0 0 0 1 1 1 1 1 1 0 0 0 1 1 1 0 1\n",
            " 0 0 0 0 0 0 0 1 1 0 0 1 0 1 0 0 1 1 1 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 0 1 0\n",
            " 1 1 0 1 1 1 0 1 0 1 0 0 0 1 0 1 1 0 1 1 0 1 1 0 1 1 0 1 1 1 0 1 1 1 1 1 1\n",
            " 1 1 0 0 0 1 0 1 1 1 1 0 1 1 1 1 0 0 0 0 1 1 0 0 0 1 1 0 1 1 1 0 1 1 1 1 1\n",
            " 0 0 1 0 1 0 0 1 0 0 1 0 1 1 1 1 0 0 1 1 0 1 1 0 1 1 1 1 1 1 1 0 1 0 0 1 1\n",
            " 0 1 1 1 1 1 0 0 1 1 0 0 1 1 1 1 0 1 0 1 1 0 0 1 1 1 1 0 1 1 1 1 1 0 0 1 0\n",
            " 1 1 0 0 0 1 1 0 1 1 0 0 1 0 1 1 0 0 1 1 1 1 0 0 1 0 1 0 0 1 1 1 1 1 0 0 0\n",
            " 1 1 1 1 1 0 0 1 0 1 0 0 0 0 1 0 1 1 0 0 0 1 0 0 1 1 1 1 0 1 0 0 1 1 0 0 1\n",
            " 1 1 1 0 1 0 0 1 0 1 1 0 0 0 1 0 1 1 1 1 0 1 0 0 1 0 0 0 0 1 1 1 1 1 1 1 1\n",
            " 1 0 1 1 1 1 1 1 1 0 0 0 1 1 1 0 1 1 0 1 0 1 0 0 0 1 0 0 1 0 1 0 1 0 1 1 0\n",
            " 0 1 1 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1\n",
            " 1 1 0 1 1 0 1 1 0 1 0 0 0 1 0 1 1 1 0 0 0 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 0\n",
            " 0 1 1 0 0 1 1 0 1 1 1 0 1 0 1 1 0 1 0 0 1 1 1 1 1 0 0 0]\n",
            "trainset before adding uncertain samples (460, 10) (460,)\n",
            "trainset after adding uncertain samples (470, 10) (470,)\n",
            "updated train set: (470, 10) (470,) unique(labels): [245 225] [0 1]\n",
            "val set: (832, 10) (832,)\n",
            "\n",
            "Train set: (470, 10)\n",
            "Validation set: (832, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 47\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.315 s \n",
            "\n",
            "Accuracy rate is 79.262673 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.86      0.86       321\n",
            "           1       0.60      0.61      0.61       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.73      0.73      0.73       434\n",
            "weighted avg       0.79      0.79      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[275  46]\n",
            " [ 44  69]]\n",
            "--------------------------------\n",
            "val predicted: (832,) [1 1 0 1 0 1 1 0 0 0 1 1 1 0 0 0 1 1 1 0 1 1 1 0 0 1 1 0 0 1 1 0 1 1 1 1 1\n",
            " 0 0 1 1 1 1 0 1 0 1 1 0 0 1 1 1 1 1 0 1 0 0 1 0 1 1 1 0 0 1 1 1 1 1 0 1 0\n",
            " 0 1 1 1 0 0 1 1 0 1 0 1 0 1 1 1 1 0 1 0 0 1 0 0 0 1 0 1 1 0 1 0 1 1 1 1 1\n",
            " 1 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 0 0 1 1 1 1 1 1 1 0 1 0 0 1 1 0 1 1 1 0\n",
            " 0 0 0 0 0 1 1 1 0 1 0 0 0 0 0 1 1 0 1 0 0 0 1 1 1 0 1 1 0 1 1 0 0 0 0 1 1\n",
            " 1 1 1 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 0 1 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 1\n",
            " 1 0 0 1 0 1 1 0 0 0 1 1 1 1 0 0 0 1 1 0 0 1 0 1 0 0 1 0 1 0 0 0 0 0 1 1 1\n",
            " 1 1 1 1 1 1 1 0 1 1 0 1 0 1 0 1 1 0 0 1 1 0 1 0 1 0 0 1 1 0 0 1 1 1 1 1 0\n",
            " 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 0 1 0 1 1 1 1 0 0 1 0 1 0 1 1 1 1 0 1\n",
            " 1 0 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 0 0 0 0 1 1 0 1 1 0 1 0 0 1 0 1 0 1 1 1\n",
            " 1 1 1 1 1 1 1 0 1 0 1 1 1 0 0 0 0 0 1 1 1 1 1 1 0 0 0 1 1 1 0 1 0 0 0 0 0\n",
            " 0 0 1 1 0 1 0 1 0 0 1 1 1 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 0 1 0 1 1 0 1 1 1\n",
            " 0 1 0 1 0 0 0 1 1 1 0 1 1 0 1 1 0 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 0 0 0 1 0\n",
            " 1 1 1 1 0 1 1 1 1 0 0 0 0 1 1 0 0 1 1 0 1 1 1 0 1 1 1 1 1 0 0 1 0 1 0 0 1\n",
            " 0 0 1 0 1 1 1 1 0 0 1 1 0 1 1 0 1 1 1 1 1 1 1 0 1 0 0 1 1 0 1 1 1 1 1 0 0\n",
            " 1 1 0 0 1 1 1 1 0 1 0 1 1 0 0 1 1 1 1 0 1 1 1 1 1 0 0 1 0 1 1 0 0 0 1 1 0\n",
            " 1 1 0 0 1 0 1 1 0 0 1 1 1 1 0 0 1 0 1 0 0 1 1 1 1 1 0 0 0 1 1 1 1 1 0 0 1\n",
            " 0 1 0 0 0 0 1 0 1 1 0 0 0 1 0 0 1 1 1 1 0 1 0 0 1 1 0 0 1 1 1 1 0 1 0 0 1\n",
            " 0 1 1 0 0 0 1 0 1 1 1 1 0 1 0 0 1 0 0 0 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1\n",
            " 1 0 0 0 1 1 1 0 1 1 0 1 0 1 0 0 0 1 1 0 1 0 1 0 1 1 0 0 1 1 0 1 1 0 0 1 0\n",
            " 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 0 1 1 0 1\n",
            " 0 0 0 1 0 1 1 1 0 0 0 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 0 0 1 1 0 1 1\n",
            " 1 0 1 0 1 1 0 1 0 0 1 1 1 1 1 0 0 0]\n",
            "probabilities: (832, 2) \n",
            " [1 1 0 1 0 1 1 0 0 0 1 1 1 0 0 0 1 1 1 0 1 1 1 0 0 1 1 0 0 1 1 0 1 1 1 1 1\n",
            " 0 0 1 1 1 1 0 1 0 1 1 0 0 1 1 1 1 1 0 1 0 0 1 0 1 1 1 0 0 1 1 1 1 1 0 1 0\n",
            " 0 1 1 1 0 0 1 1 0 1 0 1 0 1 1 1 1 0 1 0 0 1 0 0 0 1 0 1 1 0 1 0 1 1 1 1 1\n",
            " 1 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 0 0 1 1 1 1 1 1 1 0 1 0 0 1 1 0 1 1 1 0\n",
            " 0 0 0 0 0 1 1 1 0 1 0 0 0 0 0 1 1 0 1 0 0 0 1 1 1 0 1 1 0 1 1 0 0 0 0 1 1\n",
            " 1 1 1 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 0 1 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 1\n",
            " 1 0 0 1 0 1 1 0 0 0 1 1 1 1 0 0 0 1 1 0 0 1 0 1 0 0 1 0 1 0 0 0 0 0 1 1 1\n",
            " 1 1 1 1 1 1 1 0 1 1 0 1 0 1 0 1 1 0 0 1 1 0 1 0 1 0 0 1 1 0 0 1 1 1 1 1 0\n",
            " 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 0 1 0 1 1 1 1 0 0 1 0 1 0 1 1 1 1 0 1\n",
            " 1 0 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 0 0 0 0 1 1 0 1 1 0 1 0 0 1 0 1 0 1 1 1\n",
            " 1 1 1 1 1 1 1 0 1 0 1 1 1 0 0 0 0 0 1 1 1 1 1 1 0 0 0 1 1 1 0 1 0 0 0 0 0\n",
            " 0 0 1 1 0 1 0 1 0 0 1 1 1 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 0 1 0 1 1 0 1 1 1\n",
            " 0 1 0 1 0 0 0 1 1 1 0 1 1 0 1 1 0 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 0 0 0 1 0\n",
            " 1 1 1 1 0 1 1 1 1 0 0 0 0 1 1 0 0 1 1 0 1 1 1 0 1 1 1 1 1 0 0 1 0 1 0 0 1\n",
            " 0 0 1 0 1 1 1 1 0 0 1 1 0 1 1 0 1 1 1 1 1 1 1 0 1 0 0 1 1 0 1 1 1 1 1 0 0\n",
            " 1 1 0 0 1 1 1 1 0 1 0 1 1 0 0 1 1 1 1 0 1 1 1 1 1 0 0 1 0 1 1 0 0 0 1 1 0\n",
            " 1 1 0 0 1 0 1 1 0 0 1 1 1 1 0 0 1 0 1 0 0 1 1 1 1 1 0 0 0 1 1 1 1 1 0 0 1\n",
            " 0 1 0 0 0 0 1 0 1 1 0 0 0 1 0 0 1 1 1 1 0 1 0 0 1 1 0 0 1 1 1 1 0 1 0 0 1\n",
            " 0 1 1 0 0 0 1 0 1 1 1 1 0 1 0 0 1 0 0 0 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1\n",
            " 1 0 0 0 1 1 1 0 1 1 0 1 0 1 0 0 0 1 1 0 1 0 1 0 1 1 0 0 1 1 0 1 1 0 0 1 0\n",
            " 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 0 1 1 0 1\n",
            " 0 0 0 1 0 1 1 1 0 0 0 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 0 0 1 1 0 1 1\n",
            " 1 0 1 0 1 1 0 1 0 0 1 1 1 1 1 0 0 0]\n",
            "trainset before adding uncertain samples (470, 10) (470,)\n",
            "trainset after adding uncertain samples (480, 10) (480,)\n",
            "updated train set: (480, 10) (480,) unique(labels): [254 226] [0 1]\n",
            "val set: (822, 10) (822,)\n",
            "\n",
            "Train set: (480, 10)\n",
            "Validation set: (822, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 48\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.327 s \n",
            "\n",
            "Accuracy rate is 78.801843 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.86      0.86       321\n",
            "           1       0.59      0.59      0.59       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.72      0.72      0.72       434\n",
            "weighted avg       0.79      0.79      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[275  46]\n",
            " [ 46  67]]\n",
            "--------------------------------\n",
            "val predicted: (822,) [1 1 0 1 0 1 1 0 0 0 1 1 1 0 0 0 1 1 1 0 1 1 1 0 0 1 1 0 0 1 1 0 1 1 1 1 1\n",
            " 0 0 1 1 1 1 0 1 0 1 1 0 0 1 1 1 1 1 0 1 0 1 0 1 1 1 0 0 1 1 1 1 1 0 1 0 0\n",
            " 1 1 1 0 0 1 1 0 1 0 1 0 1 1 1 1 0 1 0 0 1 0 0 0 1 0 1 1 0 1 0 1 1 1 1 1 1\n",
            " 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 0 1 0 0 1 1 0 1 1 1 0 0 0 0\n",
            " 0 0 1 1 1 0 1 0 0 0 0 0 1 1 0 1 0 0 0 1 1 1 0 1 1 0 1 1 0 0 0 0 1 1 1 1 1\n",
            " 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 0 1 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 0 0 1\n",
            " 0 1 1 0 0 0 1 1 1 1 0 0 0 1 1 0 0 1 0 1 0 0 1 0 1 0 0 0 0 0 1 1 1 1 1 1 1\n",
            " 1 1 1 0 1 1 0 1 0 1 0 1 1 0 0 1 1 0 1 0 1 0 0 1 1 0 0 1 1 1 1 1 0 1 0 1 1\n",
            " 1 1 1 1 1 1 1 1 1 0 0 0 1 1 0 1 0 1 1 1 1 0 0 1 0 1 0 1 1 1 1 0 1 1 0 1 1\n",
            " 1 1 1 1 0 1 1 0 1 1 1 1 1 0 0 0 1 1 0 1 1 0 1 0 0 1 0 1 0 1 1 1 1 1 1 1 1\n",
            " 1 1 0 1 0 1 1 1 0 0 0 0 0 1 1 1 1 1 1 0 0 0 1 1 1 0 1 0 0 0 0 0 0 1 1 0 1\n",
            " 0 1 0 0 1 1 1 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 0 1 0 1 1 0 1 1 1 0 1 0 1 0 0\n",
            " 0 1 1 1 0 1 1 1 1 0 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 0 0 0 1 0 1 1 1 1 0 1 1\n",
            " 1 1 0 0 0 0 1 1 0 0 1 1 0 1 1 1 0 1 1 1 1 1 0 0 1 0 1 0 0 1 0 0 1 0 1 1 1\n",
            " 1 0 0 1 1 0 1 1 0 1 1 1 1 1 1 1 0 1 0 0 1 1 0 1 1 1 1 1 0 0 1 1 0 0 1 1 1\n",
            " 1 0 1 0 1 1 0 0 1 1 1 1 0 1 1 1 1 1 0 0 1 0 1 1 0 0 0 1 1 0 1 1 0 0 1 0 1\n",
            " 1 0 0 1 1 1 1 0 0 1 0 1 0 0 1 1 1 1 1 0 0 0 1 1 1 1 1 0 0 1 0 1 0 0 0 0 1\n",
            " 0 1 1 0 0 0 1 0 0 1 1 1 1 0 1 0 0 1 1 0 0 1 1 1 1 0 1 0 0 1 0 1 1 0 0 0 1\n",
            " 0 1 1 1 1 0 1 0 0 1 0 0 0 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 0 0 1 1 1\n",
            " 0 1 1 0 1 0 1 0 0 1 1 0 1 0 1 0 1 1 0 0 1 1 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1\n",
            " 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 0 1 1 0 1 0 0 0 1 0 1 1 1\n",
            " 0 0 0 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 0 0 1 1 0 1 1 1 0 1 0 1 1 0 1\n",
            " 0 0 1 1 1 1 0 0]\n",
            "probabilities: (822, 2) \n",
            " [1 1 0 1 0 1 1 0 0 0 1 1 1 0 0 0 1 1 1 0 1 1 1 0 0 1 1 0 0 1 1 0 1 1 1 1 1\n",
            " 0 0 1 1 1 1 0 1 0 1 1 0 0 1 1 1 1 1 0 1 0 1 0 1 1 1 0 0 1 1 1 1 1 0 1 0 0\n",
            " 1 1 1 0 0 1 1 0 1 0 1 0 1 1 1 1 0 1 0 0 1 0 0 0 1 0 1 1 0 1 0 1 1 1 1 1 1\n",
            " 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 0 1 0 0 1 1 0 1 1 1 0 0 0 0\n",
            " 0 0 1 1 1 0 1 0 0 0 0 0 1 1 0 1 0 0 0 1 1 1 0 1 1 0 1 1 0 0 0 0 1 1 1 1 1\n",
            " 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 0 1 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 0 0 1\n",
            " 0 1 1 0 0 0 1 1 1 1 0 0 0 1 1 0 0 1 0 1 0 0 1 0 1 0 0 0 0 0 1 1 1 1 1 1 1\n",
            " 1 1 1 0 1 1 0 1 0 1 0 1 1 0 0 1 1 0 1 0 1 0 0 1 1 0 0 1 1 1 1 1 0 1 0 1 1\n",
            " 1 1 1 1 1 1 1 1 1 0 0 0 1 1 0 1 0 1 1 1 1 0 0 1 0 1 0 1 1 1 1 0 1 1 0 1 1\n",
            " 1 1 1 1 0 1 1 0 1 1 1 1 1 0 0 0 1 1 0 1 1 0 1 0 0 1 0 1 0 1 1 1 1 1 1 1 1\n",
            " 1 1 0 1 0 1 1 1 0 0 0 0 0 1 1 1 1 1 1 0 0 0 1 1 1 0 1 0 0 0 0 0 0 1 1 0 1\n",
            " 0 1 0 0 1 1 1 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 0 1 0 1 1 0 1 1 1 0 1 0 1 0 0\n",
            " 0 1 1 1 0 1 1 1 1 0 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 0 0 0 1 0 1 1 1 1 0 1 1\n",
            " 1 1 0 0 0 0 1 1 0 0 1 1 0 1 1 1 0 1 1 1 1 1 0 0 1 0 1 0 0 1 0 0 1 0 1 1 1\n",
            " 1 0 0 1 1 0 1 1 0 1 1 1 1 1 1 1 0 1 0 0 1 1 0 1 1 1 1 1 0 0 1 1 0 0 1 1 1\n",
            " 1 0 1 0 1 1 0 0 1 1 1 1 0 1 1 1 1 1 0 0 1 0 1 1 0 0 0 1 1 0 1 1 0 0 1 0 1\n",
            " 1 0 0 1 1 1 1 0 0 1 0 1 0 0 1 1 1 1 1 0 0 0 1 1 1 1 1 0 0 1 0 1 0 0 0 0 1\n",
            " 0 1 1 0 0 0 1 0 0 1 1 1 1 0 1 0 0 1 1 0 0 1 1 1 1 0 1 0 0 1 0 1 1 0 0 0 1\n",
            " 0 1 1 1 1 0 1 0 0 1 0 0 0 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 0 0 1 1 1\n",
            " 0 1 1 0 1 0 1 0 0 1 1 0 1 0 1 0 1 1 0 0 1 1 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1\n",
            " 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 0 1 1 0 1 0 0 0 1 0 1 1 1\n",
            " 0 0 0 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 0 0 1 1 0 1 1 1 0 1 0 1 1 0 1\n",
            " 0 0 1 1 1 1 0 0]\n",
            "trainset before adding uncertain samples (480, 10) (480,)\n",
            "trainset after adding uncertain samples (490, 10) (490,)\n",
            "updated train set: (490, 10) (490,) unique(labels): [260 230] [0 1]\n",
            "val set: (812, 10) (812,)\n",
            "\n",
            "Train set: (490, 10)\n",
            "Validation set: (812, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 49\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.415 s \n",
            "\n",
            "Accuracy rate is 79.262673 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.86      0.86       321\n",
            "           1       0.60      0.60      0.60       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.73      0.73      0.73       434\n",
            "weighted avg       0.79      0.79      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[276  45]\n",
            " [ 45  68]]\n",
            "--------------------------------\n",
            "val predicted: (812,) [1 1 0 1 0 1 1 0 0 1 1 1 0 0 0 1 1 1 0 1 1 1 0 0 1 1 0 0 1 1 0 1 1 1 1 1 0\n",
            " 0 1 1 1 1 0 1 0 1 1 0 0 1 1 1 1 1 0 1 0 1 0 1 1 1 0 0 1 1 1 1 1 0 1 0 0 1\n",
            " 1 1 0 0 1 1 0 1 0 1 0 1 1 1 1 0 0 0 1 0 0 0 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1\n",
            " 1 1 0 1 1 0 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 0 1 0 0 1 1 0 1 1 1 0 0 0 0 0 0\n",
            " 1 1 1 0 1 0 0 0 0 0 1 1 0 1 0 0 0 1 1 1 0 1 1 0 1 1 0 0 0 0 1 1 1 1 1 1 1\n",
            " 1 1 0 0 1 1 0 1 0 1 1 1 1 0 1 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 0 0 1 0 1\n",
            " 1 0 0 0 1 1 1 1 0 0 0 1 1 0 0 1 0 1 0 0 1 0 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1\n",
            " 1 0 1 1 0 1 0 1 0 1 1 0 0 1 0 1 0 1 0 0 1 1 0 0 1 1 1 1 1 0 1 0 1 1 1 1 1\n",
            " 1 1 1 1 1 0 0 0 1 1 0 1 0 1 1 1 1 0 0 1 0 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1\n",
            " 0 1 1 0 1 1 1 1 1 0 0 0 1 1 0 1 1 0 1 0 0 1 0 1 0 1 1 1 1 1 1 1 1 1 1 0 1\n",
            " 0 1 1 1 0 0 0 0 0 1 1 1 1 1 1 0 0 0 1 1 1 0 1 0 0 0 0 0 0 1 1 0 1 0 1 0 0\n",
            " 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 0 0 1 0 1 1 0 1 1 0 1 0 1 0 0 0 1 1 1 0 1\n",
            " 1 1 1 0 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 0 0 0 1 0 1 1 1 1 0 1 1 1 1 0 0 0 0\n",
            " 1 0 0 1 1 0 1 1 1 0 1 1 1 1 1 0 0 1 0 1 0 1 0 0 1 0 1 1 1 1 0 0 1 1 0 1 1\n",
            " 0 1 1 1 1 1 1 1 0 1 0 0 1 1 0 1 1 1 1 1 0 1 1 0 0 1 1 1 1 0 1 0 1 1 0 0 1\n",
            " 1 1 1 0 1 1 1 1 1 0 0 1 0 1 1 0 0 0 1 1 0 1 1 0 0 1 0 1 1 0 0 1 1 1 1 0 0\n",
            " 1 0 1 0 0 1 1 1 1 1 0 0 1 1 1 1 1 0 0 1 0 1 0 0 0 0 1 0 1 1 0 0 0 1 0 0 1\n",
            " 1 1 1 0 1 0 0 1 1 0 0 1 1 1 1 0 1 0 0 1 0 1 1 0 0 0 1 0 1 1 1 1 0 1 0 0 1\n",
            " 0 0 0 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 0 0 1 1 1 0 1 1 0 1 0 1 0 0 1\n",
            " 1 0 1 0 1 0 1 1 0 0 1 1 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 1 0 1\n",
            " 1 1 1 1 1 1 0 1 1 1 1 0 1 1 0 1 1 0 1 0 0 0 1 0 1 1 1 0 0 0 1 0 1 1 0 1 0\n",
            " 1 1 1 1 1 1 1 1 0 0 1 1 0 0 1 1 0 1 1 1 0 1 0 1 1 0 1 0 0 1 1 1 1 0 0]\n",
            "probabilities: (812, 2) \n",
            " [1 1 0 1 0 1 1 0 0 1 1 1 0 0 0 1 1 1 0 1 1 1 0 0 1 1 0 0 1 1 0 1 1 1 1 1 0\n",
            " 0 1 1 1 1 0 1 0 1 1 0 0 1 1 1 1 1 0 1 0 1 0 1 1 1 0 0 1 1 1 1 1 0 1 0 0 1\n",
            " 1 1 0 0 1 1 0 1 0 1 0 1 1 1 1 0 0 0 1 0 0 0 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1\n",
            " 1 1 0 1 1 0 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 0 1 0 0 1 1 0 1 1 1 0 0 0 0 0 0\n",
            " 1 1 1 0 1 0 0 0 0 0 1 1 0 1 0 0 0 1 1 1 0 1 1 0 1 1 0 0 0 0 1 1 1 1 1 1 1\n",
            " 1 1 0 0 1 1 0 1 0 1 1 1 1 0 1 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 0 0 1 0 1\n",
            " 1 0 0 0 1 1 1 1 0 0 0 1 1 0 0 1 0 1 0 0 1 0 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1\n",
            " 1 0 1 1 0 1 0 1 0 1 1 0 0 1 0 1 0 1 0 0 1 1 0 0 1 1 1 1 1 0 1 0 1 1 1 1 1\n",
            " 1 1 1 1 1 0 0 0 1 1 0 1 0 1 1 1 1 0 0 1 0 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1\n",
            " 0 1 1 0 1 1 1 1 1 0 0 0 1 1 0 1 1 0 1 0 0 1 0 1 0 1 1 1 1 1 1 1 1 1 1 0 1\n",
            " 0 1 1 1 0 0 0 0 0 1 1 1 1 1 1 0 0 0 1 1 1 0 1 0 0 0 0 0 0 1 1 0 1 0 1 0 0\n",
            " 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 0 0 1 0 1 1 0 1 1 0 1 0 1 0 0 0 1 1 1 0 1\n",
            " 1 1 1 0 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 0 0 0 1 0 1 1 1 1 0 1 1 1 1 0 0 0 0\n",
            " 1 0 0 1 1 0 1 1 1 0 1 1 1 1 1 0 0 1 0 1 0 1 0 0 1 0 1 1 1 1 0 0 1 1 0 1 1\n",
            " 0 1 1 1 1 1 1 1 0 1 0 0 1 1 0 1 1 1 1 1 0 1 1 0 0 1 1 1 1 0 1 0 1 1 0 0 1\n",
            " 1 1 1 0 1 1 1 1 1 0 0 1 0 1 1 0 0 0 1 1 0 1 1 0 0 1 0 1 1 0 0 1 1 1 1 0 0\n",
            " 1 0 1 0 0 1 1 1 1 1 0 0 1 1 1 1 1 0 0 1 0 1 0 0 0 0 1 0 1 1 0 0 0 1 0 0 1\n",
            " 1 1 1 0 1 0 0 1 1 0 0 1 1 1 1 0 1 0 0 1 0 1 1 0 0 0 1 0 1 1 1 1 0 1 0 0 1\n",
            " 0 0 0 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 0 0 1 1 1 0 1 1 0 1 0 1 0 0 1\n",
            " 1 0 1 0 1 0 1 1 0 0 1 1 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 1 0 1\n",
            " 1 1 1 1 1 1 0 1 1 1 1 0 1 1 0 1 1 0 1 0 0 0 1 0 1 1 1 0 0 0 1 0 1 1 0 1 0\n",
            " 1 1 1 1 1 1 1 1 0 0 1 1 0 0 1 1 0 1 1 1 0 1 0 1 1 0 1 0 0 1 1 1 1 0 0]\n",
            "trainset before adding uncertain samples (490, 10) (490,)\n",
            "trainset after adding uncertain samples (500, 10) (500,)\n",
            "updated train set: (500, 10) (500,) unique(labels): [266 234] [0 1]\n",
            "val set: (802, 10) (802,)\n",
            "\n",
            "Train set: (500, 10)\n",
            "Validation set: (802, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 50\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.391 s \n",
            "\n",
            "Accuracy rate is 79.493088 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.87      0.86       321\n",
            "           1       0.61      0.58      0.60       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.73      0.73      0.73       434\n",
            "weighted avg       0.79      0.79      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[279  42]\n",
            " [ 47  66]]\n",
            "--------------------------------\n",
            "final active learning accuracies [49.07834101382488, 63.133640552995395, 72.58064516129032, 68.89400921658986, 72.58064516129032, 76.036866359447, 75.34562211981567, 74.19354838709677, 74.65437788018433, 73.73271889400922, 75.11520737327189, 70.50691244239631, 75.57603686635944, 75.34562211981567, 75.11520737327189, 75.80645161290323, 76.72811059907833, 76.49769585253456, 77.41935483870968, 77.18894009216591, 77.41935483870968, 76.95852534562212, 78.80184331797236, 78.3410138248848, 78.57142857142857, 79.72350230414746, 79.72350230414746, 79.26267281105991, 79.49308755760369, 79.49308755760369, 79.26267281105991, 78.57142857142857, 79.03225806451613, 79.49308755760369, 79.95391705069125, 79.95391705069125, 80.18433179723502, 79.95391705069125, 80.64516129032258, 79.49308755760369, 78.57142857142857, 78.80184331797236, 78.57142857142857, 79.03225806451613, 79.26267281105991, 78.57142857142857, 79.26267281105991, 78.80184331797236, 79.26267281105991, 79.49308755760369]\n",
            "saved /Users/wenxuanhuang/Documents/Repo/ML-for-COVID-19-dataset/Results/Active-learning-experiment-10.pkl /Users/wenxuanhuang/Documents/Repo/ML-for-COVID-19-dataset ['Decision_tree.ipynb', 'dec_git.png', 'Logit_default_f10.pdf', 'Logistic.ipynb', 'SVC.ipynb', 'RF_f5e50_featureimp.pdf', 'log_al.png', 'dec_git.pdf', '.DS_Store', 'log_git.png', 'svm_git.png', 'Logistic_Scikit.ipynb', 'knn_git.pdf', 'knn_git.png', 'rf_al.png', 'Best classifier_RF_f5e50.pdf', 'KNN.ipynb', 'GBDC.ipynb', 'rf_git.png', 'README.md', 'all_training.csv', 'Results', 'svm_al.png', 'Log_ROC.png', 'Logit_default_f7(p_removal).pdf', 'Active_learning.ipynb', 'Random_forest.ipynb', 'Model_select.ipynb', 'gdbc_git.png', '.git', '.vscode', 'Untitled', 'RF_f5e50_modelselect.pdf', 'Logit_default_f8(std_removal).pdf']\n",
            "{\n",
            "  \"GDBCModel\": {\n",
            "    \"MarginSamplingSelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          49.07834101382488,\n",
            "          63.133640552995395,\n",
            "          72.58064516129032,\n",
            "          68.89400921658986,\n",
            "          72.58064516129032,\n",
            "          76.036866359447,\n",
            "          75.34562211981567,\n",
            "          74.19354838709677,\n",
            "          74.65437788018433,\n",
            "          73.73271889400922,\n",
            "          75.11520737327189,\n",
            "          70.50691244239631,\n",
            "          75.57603686635944,\n",
            "          75.34562211981567,\n",
            "          75.11520737327189,\n",
            "          75.80645161290323,\n",
            "          76.72811059907833,\n",
            "          76.49769585253456,\n",
            "          77.41935483870968,\n",
            "          77.18894009216591,\n",
            "          77.41935483870968,\n",
            "          76.95852534562212,\n",
            "          78.80184331797236,\n",
            "          78.3410138248848,\n",
            "          78.57142857142857,\n",
            "          79.72350230414746,\n",
            "          79.72350230414746,\n",
            "          79.26267281105991,\n",
            "          79.49308755760369,\n",
            "          79.49308755760369,\n",
            "          79.26267281105991,\n",
            "          78.57142857142857,\n",
            "          79.03225806451613,\n",
            "          79.49308755760369,\n",
            "          79.95391705069125,\n",
            "          79.95391705069125,\n",
            "          80.18433179723502,\n",
            "          79.95391705069125,\n",
            "          80.64516129032258,\n",
            "          79.49308755760369,\n",
            "          78.57142857142857,\n",
            "          78.80184331797236,\n",
            "          78.57142857142857,\n",
            "          79.03225806451613,\n",
            "          79.26267281105991,\n",
            "          78.57142857142857,\n",
            "          79.26267281105991,\n",
            "          78.80184331797236,\n",
            "          79.26267281105991,\n",
            "          79.49308755760369\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          76.95852534562212,\n",
            "          78.80184331797236,\n",
            "          79.03225806451613,\n",
            "          81.10599078341014\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          74.65437788018433,\n",
            "          69.81566820276498,\n",
            "          80.18433179723502,\n",
            "          72.11981566820278,\n",
            "          72.81105990783409,\n",
            "          73.73271889400922,\n",
            "          73.50230414746544,\n",
            "          78.57142857142857,\n",
            "          78.57142857142857,\n",
            "          81.10599078341014,\n",
            "          80.64516129032258,\n",
            "          78.80184331797236,\n",
            "          79.26267281105991,\n",
            "          80.18433179723502,\n",
            "          79.72350230414746,\n",
            "          79.26267281105991,\n",
            "          79.95391705069125,\n",
            "          79.72350230414746,\n",
            "          79.95391705069125,\n",
            "          79.72350230414746\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          76.26728110599078,\n",
            "          79.26267281105991\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          78.11059907834101,\n",
            "          78.11059907834101,\n",
            "          78.57142857142857,\n",
            "          78.57142857142857,\n",
            "          80.4147465437788,\n",
            "          80.18433179723502,\n",
            "          79.95391705069125,\n",
            "          79.72350230414746,\n",
            "          79.49308755760369,\n",
            "          78.80184331797236\n",
            "        ]\n",
            "      ]\n",
            "    },\n",
            "    \"RandomSelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          63.36405529953917,\n",
            "          70.73732718894009,\n",
            "          61.29032258064516,\n",
            "          63.594470046082954,\n",
            "          74.65437788018433,\n",
            "          75.80645161290323,\n",
            "          76.49769585253456,\n",
            "          76.49769585253456,\n",
            "          77.41935483870968,\n",
            "          76.72811059907833,\n",
            "          78.3410138248848,\n",
            "          78.80184331797236,\n",
            "          77.41935483870968,\n",
            "          79.49308755760369,\n",
            "          77.64976958525345,\n",
            "          76.95852534562212,\n",
            "          77.18894009216591,\n",
            "          76.95852534562212,\n",
            "          77.64976958525345,\n",
            "          78.11059907834101,\n",
            "          78.11059907834101,\n",
            "          77.64976958525345,\n",
            "          77.64976958525345,\n",
            "          78.3410138248848,\n",
            "          78.57142857142857,\n",
            "          77.64976958525345,\n",
            "          77.64976958525345,\n",
            "          77.41935483870968,\n",
            "          77.88018433179722,\n",
            "          77.88018433179722,\n",
            "          77.88018433179722,\n",
            "          78.11059907834101,\n",
            "          77.64976958525345,\n",
            "          78.3410138248848,\n",
            "          78.80184331797236,\n",
            "          79.26267281105991,\n",
            "          78.57142857142857,\n",
            "          77.88018433179722,\n",
            "          77.64976958525345,\n",
            "          77.64976958525345,\n",
            "          78.11059907834101,\n",
            "          79.72350230414746,\n",
            "          79.72350230414746,\n",
            "          79.49308755760369,\n",
            "          79.03225806451613,\n",
            "          79.72350230414746,\n",
            "          78.80184331797236,\n",
            "          78.57142857142857,\n",
            "          79.49308755760369,\n",
            "          79.26267281105991\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          72.58064516129032,\n",
            "          72.58064516129032,\n",
            "          76.036866359447,\n",
            "          76.26728110599078\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          72.35023041474655,\n",
            "          72.11981566820278,\n",
            "          71.88940092165899,\n",
            "          73.04147465437788,\n",
            "          72.81105990783409,\n",
            "          75.11520737327189,\n",
            "          73.50230414746544,\n",
            "          76.036866359447,\n",
            "          76.26728110599078,\n",
            "          76.49769585253456,\n",
            "          76.72811059907833,\n",
            "          77.18894009216591,\n",
            "          76.72811059907833,\n",
            "          78.11059907834101,\n",
            "          78.3410138248848,\n",
            "          77.64976958525345,\n",
            "          79.72350230414746,\n",
            "          79.95391705069125,\n",
            "          80.18433179723502,\n",
            "          80.87557603686636\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          78.3410138248848,\n",
            "          79.95391705069125\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          69.35483870967742,\n",
            "          76.72811059907833,\n",
            "          78.3410138248848,\n",
            "          78.57142857142857,\n",
            "          78.80184331797236,\n",
            "          79.95391705069125,\n",
            "          79.26267281105991,\n",
            "          79.03225806451613,\n",
            "          79.03225806451613,\n",
            "          78.80184331797236\n",
            "        ]\n",
            "      ]\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "---------------------------- FINISHED ---------------------------\n",
            "\n",
            "Count = 11, using model = GDBCModel, selection_function = EntropySelection, k = 250, iteration = 0.\n",
            "\n",
            "initial random chosen samples (250,)\n",
            "initial train set: (250, 10) (250,) unique(labels): [103 147] [0 1]\n",
            "Val set: (1052, 10) (1052,) (250,)\n",
            "\n",
            "Train set: (250, 10)\n",
            "Validation set: (1052, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.022 s \n",
            "\n",
            "Accuracy rate is 78.571429 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.83      0.85       321\n",
            "           1       0.58      0.65      0.61       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.72      0.74      0.73       434\n",
            "weighted avg       0.79      0.79      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[268  53]\n",
            " [ 40  73]]\n",
            "--------------------------------\n",
            "val predicted: (1052,) [0 1 1 ... 1 0 0]\n",
            "probabilities: (1052, 2) \n",
            " [0 1 1 ... 1 0 0]\n",
            "trainset before adding uncertain samples (250, 10) (250,)\n",
            "trainset after adding uncertain samples (500, 10) (500,)\n",
            "updated train set: (500, 10) (500,) unique(labels): [241 259] [0 1]\n",
            "val set: (802, 10) (802,)\n",
            "\n",
            "Train set: (500, 10)\n",
            "Validation set: (802, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.379 s \n",
            "\n",
            "Accuracy rate is 80.414747 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.88      0.87       321\n",
            "           1       0.63      0.59      0.61       113\n",
            "\n",
            "    accuracy                           0.80       434\n",
            "   macro avg       0.75      0.74      0.74       434\n",
            "weighted avg       0.80      0.80      0.80       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[282  39]\n",
            " [ 46  67]]\n",
            "--------------------------------\n",
            "final active learning accuracies [78.57142857142857, 80.4147465437788]\n",
            "saved /Users/wenxuanhuang/Documents/Repo/ML-for-COVID-19-dataset/Results/Active-learning-experiment-11.pkl /Users/wenxuanhuang/Documents/Repo/ML-for-COVID-19-dataset ['Decision_tree.ipynb', 'dec_git.png', 'Logit_default_f10.pdf', 'Logistic.ipynb', 'SVC.ipynb', 'RF_f5e50_featureimp.pdf', 'log_al.png', 'dec_git.pdf', '.DS_Store', 'log_git.png', 'svm_git.png', 'Logistic_Scikit.ipynb', 'knn_git.pdf', 'knn_git.png', 'rf_al.png', 'Best classifier_RF_f5e50.pdf', 'KNN.ipynb', 'GBDC.ipynb', 'rf_git.png', 'README.md', 'all_training.csv', 'Results', 'svm_al.png', 'Log_ROC.png', 'Logit_default_f7(p_removal).pdf', 'Active_learning.ipynb', 'Random_forest.ipynb', 'Model_select.ipynb', 'gdbc_git.png', '.git', '.vscode', 'Untitled', 'RF_f5e50_modelselect.pdf', 'Logit_default_f8(std_removal).pdf']\n",
            "\n",
            "---------------------------- FINISHED ---------------------------\n",
            "\n",
            "Count = 12, using model = GDBCModel, selection_function = EntropySelection, k = 125, iteration = 0.\n",
            "\n",
            "initial random chosen samples (125,)\n",
            "initial train set: (125, 10) (125,) unique(labels): [67 58] [0 1]\n",
            "Val set: (1177, 10) (1177,) (125,)\n",
            "\n",
            "Train set: (125, 10)\n",
            "Validation set: (1177, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.875 s \n",
            "\n",
            "Accuracy rate is 77.419355 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.85      0.85       321\n",
            "           1       0.57      0.56      0.56       113\n",
            "\n",
            "    accuracy                           0.77       434\n",
            "   macro avg       0.71      0.70      0.71       434\n",
            "weighted avg       0.77      0.77      0.77       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[273  48]\n",
            " [ 50  63]]\n",
            "--------------------------------\n",
            "val predicted: (1177,) [1 1 1 ... 0 0 1]\n",
            "probabilities: (1177, 2) \n",
            " [1 1 1 ... 0 0 1]\n",
            "trainset before adding uncertain samples (125, 10) (125,)\n",
            "trainset after adding uncertain samples (250, 10) (250,)\n",
            "updated train set: (250, 10) (250,) unique(labels): [121 129] [0 1]\n",
            "val set: (1052, 10) (1052,)\n",
            "\n",
            "Train set: (250, 10)\n",
            "Validation set: (1052, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.061 s \n",
            "\n",
            "Accuracy rate is 79.032258 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86       321\n",
            "           1       0.61      0.53      0.57       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.73      0.71      0.72       434\n",
            "weighted avg       0.78      0.79      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[283  38]\n",
            " [ 53  60]]\n",
            "--------------------------------\n",
            "val predicted: (1052,) [1 1 0 ... 1 0 0]\n",
            "probabilities: (1052, 2) \n",
            " [1 1 0 ... 1 0 0]\n",
            "trainset before adding uncertain samples (250, 10) (250,)\n",
            "trainset after adding uncertain samples (375, 10) (375,)\n",
            "updated train set: (375, 10) (375,) unique(labels): [185 190] [0 1]\n",
            "val set: (927, 10) (927,)\n",
            "\n",
            "Train set: (375, 10)\n",
            "Validation set: (927, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 3\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.256 s \n",
            "\n",
            "Accuracy rate is 80.645161 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.89      0.87       321\n",
            "           1       0.64      0.58      0.61       113\n",
            "\n",
            "    accuracy                           0.81       434\n",
            "   macro avg       0.75      0.73      0.74       434\n",
            "weighted avg       0.80      0.81      0.80       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[285  36]\n",
            " [ 48  65]]\n",
            "--------------------------------\n",
            "val predicted: (927,) [1 1 0 1 0 0 1 1 0 0 0 1 1 1 0 1 0 1 0 0 0 1 1 1 1 0 1 1 1 0 0 0 1 1 0 0 0\n",
            " 1 0 1 0 0 0 1 1 1 1 1 1 0 0 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 1 1 0 1 0 1\n",
            " 0 0 0 0 0 1 1 0 1 1 1 0 1 0 0 1 1 1 0 0 0 0 1 0 1 0 1 0 1 0 0 1 0 0 0 0 1\n",
            " 0 0 0 0 0 0 0 1 1 0 1 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 0 0\n",
            " 1 0 0 1 0 1 1 0 1 1 1 0 0 0 1 1 1 0 1 1 1 0 0 0 0 0 0 1 1 1 0 1 0 0 0 0 0\n",
            " 0 1 1 1 1 0 0 0 1 0 1 0 1 1 0 0 1 0 0 0 0 0 1 0 1 1 1 1 1 1 1 1 1 0 0 1 1\n",
            " 1 0 1 1 1 1 1 0 1 1 0 1 1 0 1 0 0 1 1 0 1 1 1 1 1 1 0 1 1 1 0 0 0 0 1 1 1\n",
            " 1 0 0 0 0 0 1 1 0 0 0 1 0 1 0 1 0 1 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 0 1 0 1\n",
            " 0 1 0 0 0 0 0 1 1 1 1 0 0 1 0 0 0 1 0 0 1 0 1 1 0 0 1 1 1 1 0 1 1 1 1 0 1\n",
            " 1 1 1 1 1 1 1 0 1 0 0 1 1 1 0 0 0 1 1 0 1 1 0 1 0 1 1 0 0 1 0 1 0 1 1 1 0\n",
            " 1 0 1 1 1 0 1 1 0 1 1 0 1 1 0 1 1 1 1 1 0 0 0 0 1 1 1 0 0 1 0 1 0 0 1 0 0\n",
            " 1 0 1 1 1 1 0 1 0 1 1 1 1 0 1 0 1 0 1 1 0 0 0 0 1 1 1 1 0 0 0 1 1 0 1 0 0\n",
            " 1 0 0 0 0 0 0 1 1 0 0 1 0 1 1 1 0 1 0 0 1 1 1 1 0 0 1 1 1 1 1 1 0 1 1 0 0\n",
            " 1 0 1 1 0 0 1 1 0 1 0 1 0 0 0 0 0 0 1 0 1 0 1 0 1 1 1 1 1 0 0 1 1 1 1 1 1\n",
            " 0 1 1 1 1 1 0 0 1 0 1 1 1 0 1 1 1 0 1 0 0 0 1 0 1 0 0 0 1 0 1 1 1 0 1 1 0\n",
            " 0 1 0 1 0 1 0 0 1 0 1 1 0 0 1 0 0 1 0 1 1 1 1 0 0 0 1 0 1 1 1 0 1 1 1 0 1\n",
            " 1 0 1 1 0 1 0 0 1 1 0 1 1 1 1 1 0 0 1 1 0 0 1 1 1 1 0 1 1 0 1 1 0 0 1 1 1\n",
            " 0 1 0 1 1 0 1 1 0 0 0 0 1 1 0 0 0 1 0 1 0 1 1 0 1 0 0 1 0 0 0 0 1 0 1 1 1\n",
            " 0 1 0 0 0 1 0 0 1 0 0 1 1 1 1 0 0 0 0 1 0 1 1 1 1 1 1 0 0 1 0 1 0 0 0 0 0\n",
            " 1 1 1 1 1 0 0 1 0 0 1 0 1 1 1 0 0 1 0 1 1 0 0 1 1 0 1 1 0 1 0 0 1 0 1 1 0\n",
            " 0 0 1 0 0 0 1 0 1 1 1 0 1 0 1 0 0 0 0 1 0 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 0\n",
            " 1 0 0 0 1 0 0 1 1 0 1 1 1 0 1 0 1 0 0 0 0 0 0 1 0 1 1 0 1 1 1 0 0 0 1 1 0\n",
            " 1 1 0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0\n",
            " 1 1 1 1 0 1 1 0 1 1 0 1 1 0 0 0 1 0 1 1 0 1 0 0 0 1 0 1 1 1 0 1 1 1 1 1 1\n",
            " 0 0 1 0 0 0 0 1 1 0 1 0 0 0 1 1 0 1 1 1 0 1 0 0 1 1 0 1 1 0 0 1 1 0 1 1 1\n",
            " 0 0]\n",
            "probabilities: (927, 2) \n",
            " [1 1 0 1 0 0 1 1 0 0 0 1 1 1 0 1 0 1 0 0 0 1 1 1 1 0 1 1 1 0 0 0 1 1 0 0 0\n",
            " 1 0 1 0 0 0 1 1 1 1 1 1 0 0 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 1 1 0 1 0 1\n",
            " 0 0 0 0 0 1 1 0 1 1 1 0 1 0 0 1 1 1 0 0 0 0 1 0 1 0 1 0 1 0 0 1 0 0 0 0 1\n",
            " 0 0 0 0 0 0 0 1 1 0 1 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 0 0\n",
            " 1 0 0 1 0 1 1 0 1 1 1 0 0 0 1 1 1 0 1 1 1 0 0 0 0 0 0 1 1 1 0 1 0 0 0 0 0\n",
            " 0 1 1 1 1 0 0 0 1 0 1 0 1 1 0 0 1 0 0 0 0 0 1 0 1 1 1 1 1 1 1 1 1 0 0 1 1\n",
            " 1 0 1 1 1 1 1 0 1 1 0 1 1 0 1 0 0 1 1 0 1 1 1 1 1 1 0 1 1 1 0 0 0 0 1 1 1\n",
            " 1 0 0 0 0 0 1 1 0 0 0 1 0 1 0 1 0 1 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 0 1 0 1\n",
            " 0 1 0 0 0 0 0 1 1 1 1 0 0 1 0 0 0 1 0 0 1 0 1 1 0 0 1 1 1 1 0 1 1 1 1 0 1\n",
            " 1 1 1 1 1 1 1 0 1 0 0 1 1 1 0 0 0 1 1 0 1 1 0 1 0 1 1 0 0 1 0 1 0 1 1 1 0\n",
            " 1 0 1 1 1 0 1 1 0 1 1 0 1 1 0 1 1 1 1 1 0 0 0 0 1 1 1 0 0 1 0 1 0 0 1 0 0\n",
            " 1 0 1 1 1 1 0 1 0 1 1 1 1 0 1 0 1 0 1 1 0 0 0 0 1 1 1 1 0 0 0 1 1 0 1 0 0\n",
            " 1 0 0 0 0 0 0 1 1 0 0 1 0 1 1 1 0 1 0 0 1 1 1 1 0 0 1 1 1 1 1 1 0 1 1 0 0\n",
            " 1 0 1 1 0 0 1 1 0 1 0 1 0 0 0 0 0 0 1 0 1 0 1 0 1 1 1 1 1 0 0 1 1 1 1 1 1\n",
            " 0 1 1 1 1 1 0 0 1 0 1 1 1 0 1 1 1 0 1 0 0 0 1 0 1 0 0 0 1 0 1 1 1 0 1 1 0\n",
            " 0 1 0 1 0 1 0 0 1 0 1 1 0 0 1 0 0 1 0 1 1 1 1 0 0 0 1 0 1 1 1 0 1 1 1 0 1\n",
            " 1 0 1 1 0 1 0 0 1 1 0 1 1 1 1 1 0 0 1 1 0 0 1 1 1 1 0 1 1 0 1 1 0 0 1 1 1\n",
            " 0 1 0 1 1 0 1 1 0 0 0 0 1 1 0 0 0 1 0 1 0 1 1 0 1 0 0 1 0 0 0 0 1 0 1 1 1\n",
            " 0 1 0 0 0 1 0 0 1 0 0 1 1 1 1 0 0 0 0 1 0 1 1 1 1 1 1 0 0 1 0 1 0 0 0 0 0\n",
            " 1 1 1 1 1 0 0 1 0 0 1 0 1 1 1 0 0 1 0 1 1 0 0 1 1 0 1 1 0 1 0 0 1 0 1 1 0\n",
            " 0 0 1 0 0 0 1 0 1 1 1 0 1 0 1 0 0 0 0 1 0 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 0\n",
            " 1 0 0 0 1 0 0 1 1 0 1 1 1 0 1 0 1 0 0 0 0 0 0 1 0 1 1 0 1 1 1 0 0 0 1 1 0\n",
            " 1 1 0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0\n",
            " 1 1 1 1 0 1 1 0 1 1 0 1 1 0 0 0 1 0 1 1 0 1 0 0 0 1 0 1 1 1 0 1 1 1 1 1 1\n",
            " 0 0 1 0 0 0 0 1 1 0 1 0 0 0 1 1 0 1 1 1 0 1 0 0 1 1 0 1 1 0 0 1 1 0 1 1 1\n",
            " 0 0]\n",
            "trainset before adding uncertain samples (375, 10) (375,)\n",
            "trainset after adding uncertain samples (500, 10) (500,)\n",
            "updated train set: (500, 10) (500,) unique(labels): [249 251] [0 1]\n",
            "val set: (802, 10) (802,)\n",
            "\n",
            "Train set: (500, 10)\n",
            "Validation set: (802, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 4\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.365 s \n",
            "\n",
            "Accuracy rate is 80.184332 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.88      0.87       321\n",
            "           1       0.63      0.57      0.60       113\n",
            "\n",
            "    accuracy                           0.80       434\n",
            "   macro avg       0.74      0.73      0.73       434\n",
            "weighted avg       0.80      0.80      0.80       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[284  37]\n",
            " [ 49  64]]\n",
            "--------------------------------\n",
            "final active learning accuracies [77.41935483870968, 79.03225806451613, 80.64516129032258, 80.18433179723502]\n",
            "saved /Users/wenxuanhuang/Documents/Repo/ML-for-COVID-19-dataset/Results/Active-learning-experiment-12.pkl /Users/wenxuanhuang/Documents/Repo/ML-for-COVID-19-dataset ['Decision_tree.ipynb', 'dec_git.png', 'Logit_default_f10.pdf', 'Logistic.ipynb', 'SVC.ipynb', 'RF_f5e50_featureimp.pdf', 'log_al.png', 'dec_git.pdf', '.DS_Store', 'log_git.png', 'svm_git.png', 'Logistic_Scikit.ipynb', 'knn_git.pdf', 'knn_git.png', 'rf_al.png', 'Best classifier_RF_f5e50.pdf', 'KNN.ipynb', 'GBDC.ipynb', 'rf_git.png', 'README.md', 'all_training.csv', 'Results', 'svm_al.png', 'Log_ROC.png', 'Logit_default_f7(p_removal).pdf', 'Active_learning.ipynb', 'Random_forest.ipynb', 'Model_select.ipynb', 'gdbc_git.png', '.git', '.vscode', 'Untitled', 'RF_f5e50_modelselect.pdf', 'Logit_default_f8(std_removal).pdf']\n",
            "\n",
            "---------------------------- FINISHED ---------------------------\n",
            "\n",
            "Count = 13, using model = GDBCModel, selection_function = EntropySelection, k = 50, iteration = 0.\n",
            "\n",
            "initial random chosen samples (50,)\n",
            "initial train set: (50, 10) (50,) unique(labels): [26 24] [0 1]\n",
            "Val set: (1252, 10) (1252,) (50,)\n",
            "\n",
            "Train set: (50, 10)\n",
            "Validation set: (1252, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.724 s \n",
            "\n",
            "Accuracy rate is 75.345622 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.83      0.83       321\n",
            "           1       0.53      0.52      0.52       113\n",
            "\n",
            "    accuracy                           0.75       434\n",
            "   macro avg       0.68      0.68      0.68       434\n",
            "weighted avg       0.75      0.75      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[268  53]\n",
            " [ 54  59]]\n",
            "--------------------------------\n",
            "val predicted: (1252,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1252, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "trainset before adding uncertain samples (50, 10) (50,)\n",
            "trainset after adding uncertain samples (100, 10) (100,)\n",
            "updated train set: (100, 10) (100,) unique(labels): [52 48] [0 1]\n",
            "val set: (1202, 10) (1202,)\n",
            "\n",
            "Train set: (100, 10)\n",
            "Validation set: (1202, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.825 s \n",
            "\n",
            "Accuracy rate is 80.645161 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.92      0.88       321\n",
            "           1       0.67      0.50      0.57       113\n",
            "\n",
            "    accuracy                           0.81       434\n",
            "   macro avg       0.76      0.71      0.72       434\n",
            "weighted avg       0.80      0.81      0.80       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[294  27]\n",
            " [ 57  56]]\n",
            "--------------------------------\n",
            "val predicted: (1202,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1202, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "trainset before adding uncertain samples (100, 10) (100,)\n",
            "trainset after adding uncertain samples (150, 10) (150,)\n",
            "updated train set: (150, 10) (150,) unique(labels): [71 79] [0 1]\n",
            "val set: (1152, 10) (1152,)\n",
            "\n",
            "Train set: (150, 10)\n",
            "Validation set: (1152, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 3\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.922 s \n",
            "\n",
            "Accuracy rate is 79.953917 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.87      0.86       321\n",
            "           1       0.62      0.61      0.61       113\n",
            "\n",
            "    accuracy                           0.80       434\n",
            "   macro avg       0.74      0.74      0.74       434\n",
            "weighted avg       0.80      0.80      0.80       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[278  43]\n",
            " [ 44  69]]\n",
            "--------------------------------\n",
            "val predicted: (1152,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1152, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "trainset before adding uncertain samples (150, 10) (150,)\n",
            "trainset after adding uncertain samples (200, 10) (200,)\n",
            "updated train set: (200, 10) (200,) unique(labels): [ 99 101] [0 1]\n",
            "val set: (1102, 10) (1102,)\n",
            "\n",
            "Train set: (200, 10)\n",
            "Validation set: (1102, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 4\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.997 s \n",
            "\n",
            "Accuracy rate is 79.032258 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.86      0.86       321\n",
            "           1       0.60      0.59      0.60       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.73      0.73      0.73       434\n",
            "weighted avg       0.79      0.79      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[276  45]\n",
            " [ 46  67]]\n",
            "--------------------------------\n",
            "val predicted: (1102,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1102, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "trainset before adding uncertain samples (200, 10) (200,)\n",
            "trainset after adding uncertain samples (250, 10) (250,)\n",
            "updated train set: (250, 10) (250,) unique(labels): [127 123] [0 1]\n",
            "val set: (1052, 10) (1052,)\n",
            "\n",
            "Train set: (250, 10)\n",
            "Validation set: (1052, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 5\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.044 s \n",
            "\n",
            "Accuracy rate is 80.645161 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.88      0.87       321\n",
            "           1       0.64      0.59      0.61       113\n",
            "\n",
            "    accuracy                           0.81       434\n",
            "   macro avg       0.75      0.74      0.74       434\n",
            "weighted avg       0.80      0.81      0.80       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[283  38]\n",
            " [ 46  67]]\n",
            "--------------------------------\n",
            "val predicted: (1052,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1052, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "trainset before adding uncertain samples (250, 10) (250,)\n",
            "trainset after adding uncertain samples (300, 10) (300,)\n",
            "updated train set: (300, 10) (300,) unique(labels): [146 154] [0 1]\n",
            "val set: (1002, 10) (1002,)\n",
            "\n",
            "Train set: (300, 10)\n",
            "Validation set: (1002, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 6\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.117 s \n",
            "\n",
            "Accuracy rate is 80.184332 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.88      0.87       321\n",
            "           1       0.63      0.59      0.61       113\n",
            "\n",
            "    accuracy                           0.80       434\n",
            "   macro avg       0.74      0.73      0.74       434\n",
            "weighted avg       0.80      0.80      0.80       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[281  40]\n",
            " [ 46  67]]\n",
            "--------------------------------\n",
            "val predicted: (1002,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1002, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "trainset before adding uncertain samples (300, 10) (300,)\n",
            "trainset after adding uncertain samples (350, 10) (350,)\n",
            "updated train set: (350, 10) (350,) unique(labels): [175 175] [0 1]\n",
            "val set: (952, 10) (952,)\n",
            "\n",
            "Train set: (350, 10)\n",
            "Validation set: (952, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 7\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.173 s \n",
            "\n",
            "Accuracy rate is 79.953917 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.87      0.87       321\n",
            "           1       0.62      0.60      0.61       113\n",
            "\n",
            "    accuracy                           0.80       434\n",
            "   macro avg       0.74      0.74      0.74       434\n",
            "weighted avg       0.80      0.80      0.80       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[279  42]\n",
            " [ 45  68]]\n",
            "--------------------------------\n",
            "val predicted: (952,) [0 1 1 0 0 1 0 1 1 0 0 0 1 1 1 1 0 0 1 0 0 0 0 0 1 1 1 1 0 1 1 0 1 0 1 1 0\n",
            " 0 0 1 1 0 0 0 1 1 0 1 1 1 0 0 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 0 1 1 0 0 1\n",
            " 1 0 0 0 0 1 0 0 1 1 1 1 1 0 1 0 0 1 1 1 0 0 0 0 0 1 0 1 0 1 0 0 1 0 1 1 1\n",
            " 1 0 1 0 1 0 0 0 1 0 0 1 1 0 1 1 0 1 1 1 1 0 1 1 1 1 1 1 0 1 0 1 1 0 0 1 1\n",
            " 0 1 1 1 1 0 0 1 0 0 0 1 0 1 1 1 0 1 1 1 1 1 0 1 0 0 1 1 1 1 1 0 0 1 0 0 0\n",
            " 1 1 0 0 1 0 0 0 0 0 1 1 0 1 1 0 0 0 1 0 1 1 0 1 1 0 1 0 1 0 0 0 0 0 1 1 0\n",
            " 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 0\n",
            " 0 1 1 0 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 0 1 0 1 0 0 0 1 0 1 0 1 0 1 0 0 1 0\n",
            " 0 0 0 0 1 1 1 1 1 1 0 1 1 1 0 1 1 0 1 0 1 0 0 1 1 1 0 0 1 1 0 1 0 0 1 0 1\n",
            " 0 1 1 0 0 1 1 1 1 0 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 0 1 1\n",
            " 1 0 0 1 1 0 0 1 0 1 0 0 1 1 1 1 0 1 1 0 1 1 1 1 0 1 0 1 1 0 1 1 0 1 1 1 1\n",
            " 1 0 0 0 0 1 1 0 1 1 0 0 1 0 0 1 0 1 0 0 1 1 1 1 0 1 1 1 1 0 0 1 0 1 1 0 0\n",
            " 0 0 1 1 1 0 1 1 0 0 0 1 1 0 1 0 0 1 0 1 0 0 1 1 0 0 0 1 1 0 1 0 1 1 1 0 0\n",
            " 1 1 1 1 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 0 1 0 1 1 0 0 1 1 1 1 0 1 0 1 0 0 0\n",
            " 1 0 1 0 1 0 1 1 0 1 0 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 0 0 1 0 1 1 1\n",
            " 1 0 1 1 1 1 1 0 0 0 0 1 0 1 0 0 1 0 1 0 1 1 1 0 1 1 1 0 1 1 1 0 0 1 0 1 0\n",
            " 0 1 0 0 1 0 1 1 1 1 1 0 0 0 1 1 1 1 0 1 1 1 1 1 0 1 1 0 1 0 0 1 1 0 1 1 1\n",
            " 1 0 0 1 0 0 1 1 1 1 0 1 1 0 1 0 0 1 1 1 1 0 1 0 1 1 0 1 1 1 0 1 0 1 0 1 1\n",
            " 0 1 0 0 1 0 1 0 1 1 0 0 1 0 0 1 0 1 0 1 0 1 0 0 1 1 1 1 0 0 1 0 1 0 0 1 1\n",
            " 1 1 1 0 0 0 0 1 0 1 1 1 0 1 1 0 0 1 0 1 0 0 0 1 0 0 1 1 0 0 1 0 0 1 1 1 0\n",
            " 0 0 1 1 0 0 1 1 0 1 1 0 0 1 0 1 1 0 0 0 1 1 0 0 1 0 1 1 1 1 0 1 0 0 1 0 0\n",
            " 0 0 0 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 0 0 1 0 0 1 0 0 1 0 1 1 1 0 1\n",
            " 0 1 0 0 0 0 1 1 0 1 0 1 0 1 1 1 0 0 0 1 1 1 1 1 0 0 1 0 1 1 1 1 1 0 1 1 1\n",
            " 0 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 0 0 1 1 0 1 0 0 1\n",
            " 0 1 1 0 1 0 0 0 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 0 1 0 0 0 0 1 1 1 0 0 1 0 0\n",
            " 1 1 0 1 0 1 1 0 1 0 1 1 1 0 1 1 0 0 1 1 0 1 1 1 1 0 0]\n",
            "probabilities: (952, 2) \n",
            " [0 1 1 0 0 1 0 1 1 0 0 0 1 1 1 1 0 0 1 0 0 0 0 0 1 1 1 1 0 1 1 0 1 0 1 1 0\n",
            " 0 0 1 1 0 0 0 1 1 0 1 1 1 0 0 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 0 1 1 0 0 1\n",
            " 1 0 0 0 0 1 0 0 1 1 1 1 1 0 1 0 0 1 1 1 0 0 0 0 0 1 0 1 0 1 0 0 1 0 1 1 1\n",
            " 1 0 1 0 1 0 0 0 1 0 0 1 1 0 1 1 0 1 1 1 1 0 1 1 1 1 1 1 0 1 0 1 1 0 0 1 1\n",
            " 0 1 1 1 1 0 0 1 0 0 0 1 0 1 1 1 0 1 1 1 1 1 0 1 0 0 1 1 1 1 1 0 0 1 0 0 0\n",
            " 1 1 0 0 1 0 0 0 0 0 1 1 0 1 1 0 0 0 1 0 1 1 0 1 1 0 1 0 1 0 0 0 0 0 1 1 0\n",
            " 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 0\n",
            " 0 1 1 0 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 0 1 0 1 0 0 0 1 0 1 0 1 0 1 0 0 1 0\n",
            " 0 0 0 0 1 1 1 1 1 1 0 1 1 1 0 1 1 0 1 0 1 0 0 1 1 1 0 0 1 1 0 1 0 0 1 0 1\n",
            " 0 1 1 0 0 1 1 1 1 0 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 0 1 1\n",
            " 1 0 0 1 1 0 0 1 0 1 0 0 1 1 1 1 0 1 1 0 1 1 1 1 0 1 0 1 1 0 1 1 0 1 1 1 1\n",
            " 1 0 0 0 0 1 1 0 1 1 0 0 1 0 0 1 0 1 0 0 1 1 1 1 0 1 1 1 1 0 0 1 0 1 1 0 0\n",
            " 0 0 1 1 1 0 1 1 0 0 0 1 1 0 1 0 0 1 0 1 0 0 1 1 0 0 0 1 1 0 1 0 1 1 1 0 0\n",
            " 1 1 1 1 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 0 1 0 1 1 0 0 1 1 1 1 0 1 0 1 0 0 0\n",
            " 1 0 1 0 1 0 1 1 0 1 0 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 0 0 1 0 1 1 1\n",
            " 1 0 1 1 1 1 1 0 0 0 0 1 0 1 0 0 1 0 1 0 1 1 1 0 1 1 1 0 1 1 1 0 0 1 0 1 0\n",
            " 0 1 0 0 1 0 1 1 1 1 1 0 0 0 1 1 1 1 0 1 1 1 1 1 0 1 1 0 1 0 0 1 1 0 1 1 1\n",
            " 1 0 0 1 0 0 1 1 1 1 0 1 1 0 1 0 0 1 1 1 1 0 1 0 1 1 0 1 1 1 0 1 0 1 0 1 1\n",
            " 0 1 0 0 1 0 1 0 1 1 0 0 1 0 0 1 0 1 0 1 0 1 0 0 1 1 1 1 0 0 1 0 1 0 0 1 1\n",
            " 1 1 1 0 0 0 0 1 0 1 1 1 0 1 1 0 0 1 0 1 0 0 0 1 0 0 1 1 0 0 1 0 0 1 1 1 0\n",
            " 0 0 1 1 0 0 1 1 0 1 1 0 0 1 0 1 1 0 0 0 1 1 0 0 1 0 1 1 1 1 0 1 0 0 1 0 0\n",
            " 0 0 0 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 0 0 1 0 0 1 0 0 1 0 1 1 1 0 1\n",
            " 0 1 0 0 0 0 1 1 0 1 0 1 0 1 1 1 0 0 0 1 1 1 1 1 0 0 1 0 1 1 1 1 1 0 1 1 1\n",
            " 0 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 0 0 1 1 0 1 0 0 1\n",
            " 0 1 1 0 1 0 0 0 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 0 1 0 0 0 0 1 1 1 0 0 1 0 0\n",
            " 1 1 0 1 0 1 1 0 1 0 1 1 1 0 1 1 0 0 1 1 0 1 1 1 1 0 0]\n",
            "trainset before adding uncertain samples (350, 10) (350,)\n",
            "trainset after adding uncertain samples (400, 10) (400,)\n",
            "updated train set: (400, 10) (400,) unique(labels): [217 183] [0 1]\n",
            "val set: (902, 10) (902,)\n",
            "\n",
            "Train set: (400, 10)\n",
            "Validation set: (902, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 8\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.220 s \n",
            "\n",
            "Accuracy rate is 79.493088 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.87      0.86       321\n",
            "           1       0.61      0.59      0.60       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.73      0.73      0.73       434\n",
            "weighted avg       0.79      0.79      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[278  43]\n",
            " [ 46  67]]\n",
            "--------------------------------\n",
            "val predicted: (902,) [0 1 1 0 0 1 0 1 1 0 0 0 1 1 1 1 0 0 1 0 0 0 0 1 1 1 1 0 1 1 0 1 1 1 0 0 0\n",
            " 1 1 0 0 0 1 1 0 1 1 1 0 0 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 0 1 1 0 0 1 1 0\n",
            " 0 0 0 1 0 1 1 1 1 1 0 1 0 1 1 1 0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 0 1 0 1 0\n",
            " 0 1 0 0 1 1 0 1 1 0 1 1 1 1 0 1 1 1 1 1 1 0 1 0 1 1 0 0 1 1 0 1 1 1 1 0 0\n",
            " 1 0 0 1 0 1 1 1 0 1 1 1 1 1 0 1 0 1 1 1 1 1 0 0 1 0 0 0 1 1 0 0 1 0 0 0 0\n",
            " 0 1 1 0 1 1 0 0 1 0 1 1 0 1 1 0 1 1 0 0 0 0 0 1 1 0 1 1 1 1 1 1 1 0 0 1 1\n",
            " 1 1 1 1 1 1 0 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 0 1 1 0 1 1 0 0 0 1 1 1\n",
            " 1 0 0 1 0 1 1 0 0 0 1 0 1 0 1 0 1 0 0 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 0 1 1\n",
            " 0 1 0 1 0 0 1 1 1 0 0 1 1 0 1 0 1 0 1 0 1 1 0 0 1 1 1 1 0 1 1 0 0 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 0 1 1 1 0 1 1 1 0 1 0 0 1 1 1 1 0 1 1 0 1\n",
            " 1 1 1 0 1 0 1 1 0 1 1 0 1 1 1 1 1 0 0 0 0 1 1 0 1 1 0 1 0 0 1 0 1 0 0 1 1\n",
            " 1 1 0 1 1 1 1 0 1 0 1 1 0 0 0 0 1 1 1 1 1 0 0 0 1 1 0 1 0 0 1 0 1 0 0 1 1\n",
            " 0 0 1 1 0 1 1 1 1 0 0 1 1 1 1 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 1 1 1 1 1\n",
            " 1 0 1 0 1 0 0 0 1 0 1 0 1 0 1 1 0 1 0 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1\n",
            " 0 0 0 1 0 1 1 1 1 1 1 1 1 1 0 0 0 0 1 0 1 0 0 1 0 1 0 1 1 1 0 1 1 1 0 1 1\n",
            " 1 0 0 1 0 1 0 0 1 0 0 1 0 1 1 1 1 1 0 0 0 1 1 1 1 0 1 1 1 1 1 0 1 1 0 1 0\n",
            " 0 1 1 0 1 1 1 1 0 0 1 0 1 1 1 1 0 1 1 0 1 0 0 1 1 1 1 0 1 0 1 1 0 1 1 1 0\n",
            " 1 1 0 1 1 0 1 1 0 1 0 1 1 0 0 1 0 0 1 1 0 1 0 1 0 0 1 1 1 1 0 0 1 0 1 0 0\n",
            " 1 1 1 1 1 0 0 0 0 1 0 1 1 1 1 1 0 0 1 1 0 0 1 0 0 1 1 0 0 1 0 0 1 1 1 0 0\n",
            " 1 1 0 0 1 1 0 1 1 0 0 1 0 1 1 0 0 0 1 0 0 1 0 1 1 1 1 0 1 0 0 1 0 0 0 0 0\n",
            " 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 0 1 0 0 1 0 0 1 0 1 1 1 0 1 0 1 0 0 0\n",
            " 0 1 1 0 1 0 1 0 1 1 1 0 0 0 1 1 1 1 1 0 1 0 1 1 1 1 1 0 1 1 1 0 1 1 1 1 0\n",
            " 1 1 0 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 0 1 0 1 0 1 1 1 0 0 0 1 0 1\n",
            " 1 1 1 0 1 1 1 1 1 0 1 0 1 0 0 0 0 1 1 1 0 0 1 0 0 1 1 0 1 0 1 1 0 1 0 1 1\n",
            " 0 1 1 0 0 1 1 0 1 1 1 1 0 0]\n",
            "probabilities: (902, 2) \n",
            " [0 1 1 0 0 1 0 1 1 0 0 0 1 1 1 1 0 0 1 0 0 0 0 1 1 1 1 0 1 1 0 1 1 1 0 0 0\n",
            " 1 1 0 0 0 1 1 0 1 1 1 0 0 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 0 1 1 0 0 1 1 0\n",
            " 0 0 0 1 0 1 1 1 1 1 0 1 0 1 1 1 0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 0 1 0 1 0\n",
            " 0 1 0 0 1 1 0 1 1 0 1 1 1 1 0 1 1 1 1 1 1 0 1 0 1 1 0 0 1 1 0 1 1 1 1 0 0\n",
            " 1 0 0 1 0 1 1 1 0 1 1 1 1 1 0 1 0 1 1 1 1 1 0 0 1 0 0 0 1 1 0 0 1 0 0 0 0\n",
            " 0 1 1 0 1 1 0 0 1 0 1 1 0 1 1 0 1 1 0 0 0 0 0 1 1 0 1 1 1 1 1 1 1 0 0 1 1\n",
            " 1 1 1 1 1 1 0 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 0 1 1 0 1 1 0 0 0 1 1 1\n",
            " 1 0 0 1 0 1 1 0 0 0 1 0 1 0 1 0 1 0 0 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 0 1 1\n",
            " 0 1 0 1 0 0 1 1 1 0 0 1 1 0 1 0 1 0 1 0 1 1 0 0 1 1 1 1 0 1 1 0 0 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 0 1 1 1 0 1 1 1 0 1 0 0 1 1 1 1 0 1 1 0 1\n",
            " 1 1 1 0 1 0 1 1 0 1 1 0 1 1 1 1 1 0 0 0 0 1 1 0 1 1 0 1 0 0 1 0 1 0 0 1 1\n",
            " 1 1 0 1 1 1 1 0 1 0 1 1 0 0 0 0 1 1 1 1 1 0 0 0 1 1 0 1 0 0 1 0 1 0 0 1 1\n",
            " 0 0 1 1 0 1 1 1 1 0 0 1 1 1 1 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 1 1 1 1 1\n",
            " 1 0 1 0 1 0 0 0 1 0 1 0 1 0 1 1 0 1 0 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1\n",
            " 0 0 0 1 0 1 1 1 1 1 1 1 1 1 0 0 0 0 1 0 1 0 0 1 0 1 0 1 1 1 0 1 1 1 0 1 1\n",
            " 1 0 0 1 0 1 0 0 1 0 0 1 0 1 1 1 1 1 0 0 0 1 1 1 1 0 1 1 1 1 1 0 1 1 0 1 0\n",
            " 0 1 1 0 1 1 1 1 0 0 1 0 1 1 1 1 0 1 1 0 1 0 0 1 1 1 1 0 1 0 1 1 0 1 1 1 0\n",
            " 1 1 0 1 1 0 1 1 0 1 0 1 1 0 0 1 0 0 1 1 0 1 0 1 0 0 1 1 1 1 0 0 1 0 1 0 0\n",
            " 1 1 1 1 1 0 0 0 0 1 0 1 1 1 1 1 0 0 1 1 0 0 1 0 0 1 1 0 0 1 0 0 1 1 1 0 0\n",
            " 1 1 0 0 1 1 0 1 1 0 0 1 0 1 1 0 0 0 1 0 0 1 0 1 1 1 1 0 1 0 0 1 0 0 0 0 0\n",
            " 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 0 1 0 0 1 0 0 1 0 1 1 1 0 1 0 1 0 0 0\n",
            " 0 1 1 0 1 0 1 0 1 1 1 0 0 0 1 1 1 1 1 0 1 0 1 1 1 1 1 0 1 1 1 0 1 1 1 1 0\n",
            " 1 1 0 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 0 1 0 1 0 1 1 1 0 0 0 1 0 1\n",
            " 1 1 1 0 1 1 1 1 1 0 1 0 1 0 0 0 0 1 1 1 0 0 1 0 0 1 1 0 1 0 1 1 0 1 0 1 1\n",
            " 0 1 1 0 0 1 1 0 1 1 1 1 0 0]\n",
            "trainset before adding uncertain samples (400, 10) (400,)\n",
            "trainset after adding uncertain samples (450, 10) (450,)\n",
            "updated train set: (450, 10) (450,) unique(labels): [242 208] [0 1]\n",
            "val set: (852, 10) (852,)\n",
            "\n",
            "Train set: (450, 10)\n",
            "Validation set: (852, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 9\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.286 s \n",
            "\n",
            "Accuracy rate is 79.723502 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.87      0.86       321\n",
            "           1       0.62      0.58      0.60       113\n",
            "\n",
            "    accuracy                           0.80       434\n",
            "   macro avg       0.74      0.73      0.73       434\n",
            "weighted avg       0.79      0.80      0.80       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[280  41]\n",
            " [ 47  66]]\n",
            "--------------------------------\n",
            "val predicted: (852,) [0 1 1 1 0 1 1 0 0 0 1 1 1 1 0 0 0 0 0 1 1 1 1 0 1 1 1 1 1 0 0 1 1 0 0 0 1\n",
            " 1 0 1 1 1 0 0 1 1 1 0 1 1 1 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 0 0 0 1 0 1 1 1\n",
            " 1 1 0 1 0 1 1 1 0 0 0 0 1 1 0 1 0 1 0 1 1 1 1 0 1 0 1 0 0 1 0 0 1 1 0 1 1\n",
            " 0 1 1 1 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 1 1 1 0 0 1 0 0 1 0 1 1 1 1 1 1 1\n",
            " 0 1 0 1 1 1 1 1 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 1 1 0 1 0 0 1 0 1 1 0 1 1 0\n",
            " 1 1 0 0 0 0 1 1 0 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 0 1 1 1\n",
            " 1 1 1 1 1 1 1 0 0 1 1 0 1 1 0 0 0 1 1 1 1 0 0 0 1 1 0 0 0 1 0 1 0 1 0 1 0\n",
            " 0 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 0 1 1 0 1 0 1 0 0 1 1 1 0 0 1 1 0 1 0 1 0\n",
            " 1 0 1 1 0 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 0 1 1\n",
            " 0 1 1 1 0 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 0 0 0 0 1 1\n",
            " 0 1 1 0 1 0 0 1 0 1 0 0 1 1 1 1 0 1 1 1 0 1 0 1 1 0 0 0 0 1 1 1 1 1 0 0 0\n",
            " 1 1 0 1 0 1 0 1 0 0 1 0 0 1 1 0 1 1 1 0 0 1 1 1 1 0 1 1 1 1 1 1 0 1 1 0 0\n",
            " 1 1 0 1 0 1 1 1 1 1 0 1 1 0 0 0 1 1 0 1 0 1 1 0 1 0 1 1 0 1 1 1 1 1 0 1 1\n",
            " 1 1 1 1 1 1 1 0 0 0 1 0 1 1 1 1 1 1 1 1 1 0 0 0 0 1 0 1 0 1 0 1 1 1 0 1 1\n",
            " 1 0 1 1 1 0 0 1 0 1 0 0 1 0 0 1 0 1 1 1 1 1 0 0 1 1 1 1 0 1 1 1 1 1 0 1 1\n",
            " 0 1 0 0 1 1 0 1 1 1 1 0 0 1 0 1 1 1 1 0 1 0 1 0 0 1 1 1 1 1 0 1 1 0 1 1 1\n",
            " 0 1 1 0 1 1 1 1 0 1 0 1 1 0 0 1 0 0 1 1 0 1 0 1 0 0 1 1 1 1 0 0 1 0 1 0 0\n",
            " 1 1 1 1 1 0 0 0 0 1 0 1 1 1 1 0 0 1 1 0 0 1 0 1 1 0 0 1 0 0 1 1 1 0 0 1 1\n",
            " 0 0 1 1 1 1 0 0 1 0 1 0 0 0 1 0 0 1 0 1 1 1 1 0 1 0 0 1 0 0 0 0 0 1 1 1 1\n",
            " 1 1 1 0 1 1 0 1 1 1 1 1 1 1 0 0 0 1 0 0 1 0 1 1 1 0 1 0 1 0 0 0 0 1 1 0 1\n",
            " 0 1 0 1 1 1 0 0 0 1 1 1 0 1 0 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 0 1 1 0 1 1 1\n",
            " 1 1 1 1 0 1 1 1 1 1 0 1 1 0 1 0 1 0 1 1 1 0 0 0 0 1 1 1 1 0 1 1 1 1 1 0 1\n",
            " 0 1 0 0 0 1 1 1 0 0 1 0 0 1 1 0 1 1 1 0 1 0 1 1 0 1 1 0 0 1 1 0 1 1 1 1 0\n",
            " 0]\n",
            "probabilities: (852, 2) \n",
            " [0 1 1 1 0 1 1 0 0 0 1 1 1 1 0 0 0 0 0 1 1 1 1 0 1 1 1 1 1 0 0 1 1 0 0 0 1\n",
            " 1 0 1 1 1 0 0 1 1 1 0 1 1 1 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 0 0 0 1 0 1 1 1\n",
            " 1 1 0 1 0 1 1 1 0 0 0 0 1 1 0 1 0 1 0 1 1 1 1 0 1 0 1 0 0 1 0 0 1 1 0 1 1\n",
            " 0 1 1 1 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 1 1 1 0 0 1 0 0 1 0 1 1 1 1 1 1 1\n",
            " 0 1 0 1 1 1 1 1 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 1 1 0 1 0 0 1 0 1 1 0 1 1 0\n",
            " 1 1 0 0 0 0 1 1 0 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 0 1 1 1\n",
            " 1 1 1 1 1 1 1 0 0 1 1 0 1 1 0 0 0 1 1 1 1 0 0 0 1 1 0 0 0 1 0 1 0 1 0 1 0\n",
            " 0 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 0 1 1 0 1 0 1 0 0 1 1 1 0 0 1 1 0 1 0 1 0\n",
            " 1 0 1 1 0 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 0 1 1\n",
            " 0 1 1 1 0 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 0 0 0 0 1 1\n",
            " 0 1 1 0 1 0 0 1 0 1 0 0 1 1 1 1 0 1 1 1 0 1 0 1 1 0 0 0 0 1 1 1 1 1 0 0 0\n",
            " 1 1 0 1 0 1 0 1 0 0 1 0 0 1 1 0 1 1 1 0 0 1 1 1 1 0 1 1 1 1 1 1 0 1 1 0 0\n",
            " 1 1 0 1 0 1 1 1 1 1 0 1 1 0 0 0 1 1 0 1 0 1 1 0 1 0 1 1 0 1 1 1 1 1 0 1 1\n",
            " 1 1 1 1 1 1 1 0 0 0 1 0 1 1 1 1 1 1 1 1 1 0 0 0 0 1 0 1 0 1 0 1 1 1 0 1 1\n",
            " 1 0 1 1 1 0 0 1 0 1 0 0 1 0 0 1 0 1 1 1 1 1 0 0 1 1 1 1 0 1 1 1 1 1 0 1 1\n",
            " 0 1 0 0 1 1 0 1 1 1 1 0 0 1 0 1 1 1 1 0 1 0 1 0 0 1 1 1 1 1 0 1 1 0 1 1 1\n",
            " 0 1 1 0 1 1 1 1 0 1 0 1 1 0 0 1 0 0 1 1 0 1 0 1 0 0 1 1 1 1 0 0 1 0 1 0 0\n",
            " 1 1 1 1 1 0 0 0 0 1 0 1 1 1 1 0 0 1 1 0 0 1 0 1 1 0 0 1 0 0 1 1 1 0 0 1 1\n",
            " 0 0 1 1 1 1 0 0 1 0 1 0 0 0 1 0 0 1 0 1 1 1 1 0 1 0 0 1 0 0 0 0 0 1 1 1 1\n",
            " 1 1 1 0 1 1 0 1 1 1 1 1 1 1 0 0 0 1 0 0 1 0 1 1 1 0 1 0 1 0 0 0 0 1 1 0 1\n",
            " 0 1 0 1 1 1 0 0 0 1 1 1 0 1 0 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 0 1 1 0 1 1 1\n",
            " 1 1 1 1 0 1 1 1 1 1 0 1 1 0 1 0 1 0 1 1 1 0 0 0 0 1 1 1 1 0 1 1 1 1 1 0 1\n",
            " 0 1 0 0 0 1 1 1 0 0 1 0 0 1 1 0 1 1 1 0 1 0 1 1 0 1 1 0 0 1 1 0 1 1 1 1 0\n",
            " 0]\n",
            "trainset before adding uncertain samples (450, 10) (450,)\n",
            "trainset after adding uncertain samples (500, 10) (500,)\n",
            "updated train set: (500, 10) (500,) unique(labels): [270 230] [0 1]\n",
            "val set: (802, 10) (802,)\n",
            "\n",
            "Train set: (500, 10)\n",
            "Validation set: (802, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 10\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.336 s \n",
            "\n",
            "Accuracy rate is 79.493088 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.87      0.86       321\n",
            "           1       0.61      0.58      0.59       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.73      0.72      0.73       434\n",
            "weighted avg       0.79      0.79      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[280  41]\n",
            " [ 48  65]]\n",
            "--------------------------------\n",
            "final active learning accuracies [75.34562211981567, 80.64516129032258, 79.95391705069125, 79.03225806451613, 80.64516129032258, 80.18433179723502, 79.95391705069125, 79.49308755760369, 79.72350230414746, 79.49308755760369]\n",
            "saved /Users/wenxuanhuang/Documents/Repo/ML-for-COVID-19-dataset/Results/Active-learning-experiment-13.pkl /Users/wenxuanhuang/Documents/Repo/ML-for-COVID-19-dataset ['Decision_tree.ipynb', 'dec_git.png', 'Logit_default_f10.pdf', 'Logistic.ipynb', 'SVC.ipynb', 'RF_f5e50_featureimp.pdf', 'log_al.png', 'dec_git.pdf', '.DS_Store', 'log_git.png', 'svm_git.png', 'Logistic_Scikit.ipynb', 'knn_git.pdf', 'knn_git.png', 'rf_al.png', 'Best classifier_RF_f5e50.pdf', 'KNN.ipynb', 'GBDC.ipynb', 'rf_git.png', 'README.md', 'all_training.csv', 'Results', 'svm_al.png', 'Log_ROC.png', 'Logit_default_f7(p_removal).pdf', 'Active_learning.ipynb', 'Random_forest.ipynb', 'Model_select.ipynb', 'gdbc_git.png', '.git', '.vscode', 'Untitled', 'RF_f5e50_modelselect.pdf', 'Logit_default_f8(std_removal).pdf']\n",
            "\n",
            "---------------------------- FINISHED ---------------------------\n",
            "\n",
            "Count = 14, using model = GDBCModel, selection_function = EntropySelection, k = 25, iteration = 0.\n",
            "\n",
            "initial random chosen samples (25,)\n",
            "initial train set: (25, 10) (25,) unique(labels): [12 13] [0 1]\n",
            "Val set: (1277, 10) (1277,) (25,)\n",
            "\n",
            "Train set: (25, 10)\n",
            "Validation set: (1277, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.758 s \n",
            "\n",
            "Accuracy rate is 70.046083 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.72      0.78       321\n",
            "           1       0.45      0.65      0.53       113\n",
            "\n",
            "    accuracy                           0.70       434\n",
            "   macro avg       0.65      0.69      0.66       434\n",
            "weighted avg       0.75      0.70      0.72       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[230  91]\n",
            " [ 39  74]]\n",
            "--------------------------------\n",
            "val predicted: (1277,) [1 1 1 ... 0 0 0]\n",
            "probabilities: (1277, 2) \n",
            " [1 1 1 ... 0 0 0]\n",
            "trainset before adding uncertain samples (25, 10) (25,)\n",
            "trainset after adding uncertain samples (50, 10) (50,)\n",
            "updated train set: (50, 10) (50,) unique(labels): [23 27] [0 1]\n",
            "val set: (1252, 10) (1252,)\n",
            "\n",
            "Train set: (50, 10)\n",
            "Validation set: (1252, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.730 s \n",
            "\n",
            "Accuracy rate is 76.497696 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.83      0.84       321\n",
            "           1       0.55      0.58      0.56       113\n",
            "\n",
            "    accuracy                           0.76       434\n",
            "   macro avg       0.70      0.70      0.70       434\n",
            "weighted avg       0.77      0.76      0.77       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[267  54]\n",
            " [ 48  65]]\n",
            "--------------------------------\n",
            "val predicted: (1252,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1252, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "trainset before adding uncertain samples (50, 10) (50,)\n",
            "trainset after adding uncertain samples (75, 10) (75,)\n",
            "updated train set: (75, 10) (75,) unique(labels): [34 41] [0 1]\n",
            "val set: (1227, 10) (1227,)\n",
            "\n",
            "Train set: (75, 10)\n",
            "Validation set: (1227, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 3\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.786 s \n",
            "\n",
            "Accuracy rate is 79.032258 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.85      0.86       321\n",
            "           1       0.59      0.61      0.60       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.73      0.73      0.73       434\n",
            "weighted avg       0.79      0.79      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[274  47]\n",
            " [ 44  69]]\n",
            "--------------------------------\n",
            "val predicted: (1227,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1227, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "trainset before adding uncertain samples (75, 10) (75,)\n",
            "trainset after adding uncertain samples (100, 10) (100,)\n",
            "updated train set: (100, 10) (100,) unique(labels): [48 52] [0 1]\n",
            "val set: (1202, 10) (1202,)\n",
            "\n",
            "Train set: (100, 10)\n",
            "Validation set: (1202, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 4\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.810 s \n",
            "\n",
            "Accuracy rate is 78.571429 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.84      0.85       321\n",
            "           1       0.58      0.62      0.60       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.72      0.73      0.73       434\n",
            "weighted avg       0.79      0.79      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[271  50]\n",
            " [ 43  70]]\n",
            "--------------------------------\n",
            "val predicted: (1202,) [0 1 1 ... 0 1 0]\n",
            "probabilities: (1202, 2) \n",
            " [0 1 1 ... 0 1 0]\n",
            "trainset before adding uncertain samples (100, 10) (100,)\n",
            "trainset after adding uncertain samples (125, 10) (125,)\n",
            "updated train set: (125, 10) (125,) unique(labels): [60 65] [0 1]\n",
            "val set: (1177, 10) (1177,)\n",
            "\n",
            "Train set: (125, 10)\n",
            "Validation set: (1177, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 5\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.947 s \n",
            "\n",
            "Accuracy rate is 77.649770 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.86      0.85       321\n",
            "           1       0.58      0.54      0.56       113\n",
            "\n",
            "    accuracy                           0.78       434\n",
            "   macro avg       0.71      0.70      0.70       434\n",
            "weighted avg       0.77      0.78      0.77       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[276  45]\n",
            " [ 52  61]]\n",
            "--------------------------------\n",
            "val predicted: (1177,) [0 1 1 ... 0 1 0]\n",
            "probabilities: (1177, 2) \n",
            " [0 1 1 ... 0 1 0]\n",
            "trainset before adding uncertain samples (125, 10) (125,)\n",
            "trainset after adding uncertain samples (150, 10) (150,)\n",
            "updated train set: (150, 10) (150,) unique(labels): [71 79] [0 1]\n",
            "val set: (1152, 10) (1152,)\n",
            "\n",
            "Train set: (150, 10)\n",
            "Validation set: (1152, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 6\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.180 s \n",
            "\n",
            "Accuracy rate is 78.801843 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.85      0.86       321\n",
            "           1       0.59      0.60      0.60       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.73      0.73      0.73       434\n",
            "weighted avg       0.79      0.79      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[274  47]\n",
            " [ 45  68]]\n",
            "--------------------------------\n",
            "val predicted: (1152,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1152, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "trainset before adding uncertain samples (150, 10) (150,)\n",
            "trainset after adding uncertain samples (175, 10) (175,)\n",
            "updated train set: (175, 10) (175,) unique(labels): [84 91] [0 1]\n",
            "val set: (1127, 10) (1127,)\n",
            "\n",
            "Train set: (175, 10)\n",
            "Validation set: (1127, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 7\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.942 s \n",
            "\n",
            "Accuracy rate is 78.801843 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.87      0.86       321\n",
            "           1       0.60      0.57      0.58       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.72      0.72      0.72       434\n",
            "weighted avg       0.78      0.79      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[278  43]\n",
            " [ 49  64]]\n",
            "--------------------------------\n",
            "val predicted: (1127,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1127, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "trainset before adding uncertain samples (175, 10) (175,)\n",
            "trainset after adding uncertain samples (200, 10) (200,)\n",
            "updated train set: (200, 10) (200,) unique(labels): [ 97 103] [0 1]\n",
            "val set: (1102, 10) (1102,)\n",
            "\n",
            "Train set: (200, 10)\n",
            "Validation set: (1102, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 8\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.951 s \n",
            "\n",
            "Accuracy rate is 77.419355 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.85      0.85       321\n",
            "           1       0.57      0.55      0.56       113\n",
            "\n",
            "    accuracy                           0.77       434\n",
            "   macro avg       0.71      0.70      0.70       434\n",
            "weighted avg       0.77      0.77      0.77       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[274  47]\n",
            " [ 51  62]]\n",
            "--------------------------------\n",
            "val predicted: (1102,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1102, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "trainset before adding uncertain samples (200, 10) (200,)\n",
            "trainset after adding uncertain samples (225, 10) (225,)\n",
            "updated train set: (225, 10) (225,) unique(labels): [109 116] [0 1]\n",
            "val set: (1077, 10) (1077,)\n",
            "\n",
            "Train set: (225, 10)\n",
            "Validation set: (1077, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 9\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.990 s \n",
            "\n",
            "Accuracy rate is 77.880184 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.87      0.85       321\n",
            "           1       0.58      0.53      0.56       113\n",
            "\n",
            "    accuracy                           0.78       434\n",
            "   macro avg       0.71      0.70      0.70       434\n",
            "weighted avg       0.77      0.78      0.78       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[278  43]\n",
            " [ 53  60]]\n",
            "--------------------------------\n",
            "val predicted: (1077,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1077, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "trainset before adding uncertain samples (225, 10) (225,)\n",
            "trainset after adding uncertain samples (250, 10) (250,)\n",
            "updated train set: (250, 10) (250,) unique(labels): [122 128] [0 1]\n",
            "val set: (1052, 10) (1052,)\n",
            "\n",
            "Train set: (250, 10)\n",
            "Validation set: (1052, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 10\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.076 s \n",
            "\n",
            "Accuracy rate is 77.649770 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.85      0.85       321\n",
            "           1       0.57      0.56      0.57       113\n",
            "\n",
            "    accuracy                           0.78       434\n",
            "   macro avg       0.71      0.71      0.71       434\n",
            "weighted avg       0.77      0.78      0.78       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[274  47]\n",
            " [ 50  63]]\n",
            "--------------------------------\n",
            "val predicted: (1052,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1052, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "trainset before adding uncertain samples (250, 10) (250,)\n",
            "trainset after adding uncertain samples (275, 10) (275,)\n",
            "updated train set: (275, 10) (275,) unique(labels): [135 140] [0 1]\n",
            "val set: (1027, 10) (1027,)\n",
            "\n",
            "Train set: (275, 10)\n",
            "Validation set: (1027, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 11\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.110 s \n",
            "\n",
            "Accuracy rate is 79.032258 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.87      0.86       321\n",
            "           1       0.60      0.57      0.58       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.73      0.72      0.72       434\n",
            "weighted avg       0.79      0.79      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[279  42]\n",
            " [ 49  64]]\n",
            "--------------------------------\n",
            "val predicted: (1027,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1027, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "trainset before adding uncertain samples (275, 10) (275,)\n",
            "trainset after adding uncertain samples (300, 10) (300,)\n",
            "updated train set: (300, 10) (300,) unique(labels): [149 151] [0 1]\n",
            "val set: (1002, 10) (1002,)\n",
            "\n",
            "Train set: (300, 10)\n",
            "Validation set: (1002, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 12\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.216 s \n",
            "\n",
            "Accuracy rate is 77.880184 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.86      0.85       321\n",
            "           1       0.58      0.54      0.56       113\n",
            "\n",
            "    accuracy                           0.78       434\n",
            "   macro avg       0.71      0.70      0.71       434\n",
            "weighted avg       0.77      0.78      0.78       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[277  44]\n",
            " [ 52  61]]\n",
            "--------------------------------\n",
            "val predicted: (1002,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1002, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "trainset before adding uncertain samples (300, 10) (300,)\n",
            "trainset after adding uncertain samples (325, 10) (325,)\n",
            "updated train set: (325, 10) (325,) unique(labels): [159 166] [0 1]\n",
            "val set: (977, 10) (977,)\n",
            "\n",
            "Train set: (325, 10)\n",
            "Validation set: (977, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 13\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.258 s \n",
            "\n",
            "Accuracy rate is 78.801843 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.87      0.86       321\n",
            "           1       0.60      0.57      0.58       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.72      0.72      0.72       434\n",
            "weighted avg       0.78      0.79      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[278  43]\n",
            " [ 49  64]]\n",
            "--------------------------------\n",
            "val predicted: (977,) [0 1 1 0 1 0 1 1 0 0 1 1 1 1 0 1 0 0 0 0 1 1 1 1 0 1 1 1 0 0 0 1 1 0 0 1 1\n",
            " 0 0 0 1 0 1 1 1 0 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 0 1 1 0 1 0 1 1 0 0 0 0 1\n",
            " 0 0 0 1 1 0 1 1 1 0 1 1 0 0 0 0 0 1 0 1 0 0 1 0 1 0 1 1 1 0 0 1 0 1 0 0 1\n",
            " 0 0 0 1 0 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 0 1 0 1 1 0 0 1 1 0 1 1 1 1 0 0 1\n",
            " 0 0 0 1 1 1 1 1 0 1 1 1 1 1 0 0 1 1 1 0 1 1 0 1 0 0 0 1 0 0 0 0 1 1 1 0 0\n",
            " 0 0 0 0 1 1 0 1 1 0 0 0 0 1 0 1 1 0 1 1 0 0 0 0 1 0 1 1 1 1 1 1 1 0 0 1 1\n",
            " 0 1 1 1 1 1 0 1 0 1 1 1 0 1 1 0 1 1 1 0 1 1 1 1 1 1 0 1 0 0 1 0 1 1 0 0 0\n",
            " 0 1 1 1 1 0 0 0 1 1 0 1 0 0 0 0 1 0 1 0 1 0 0 0 0 1 0 0 0 0 0 1 1 1 0 0 1\n",
            " 1 1 0 1 1 1 0 1 0 1 0 1 0 1 0 0 1 1 1 1 0 0 1 1 1 0 1 0 1 0 0 1 0 1 1 0 0\n",
            " 1 1 1 1 0 1 0 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 0 0 0 1 1 0\n",
            " 1 1 0 1 1 1 1 1 0 1 0 1 1 1 0 1 1 0 1 1 1 0 1 1 0 1 1 0 1 1 0 1 1 1 0 1 1\n",
            " 0 0 0 1 1 0 0 1 1 0 1 0 1 0 1 0 1 1 1 0 1 1 1 1 1 0 1 0 1 0 1 1 0 0 0 1 0\n",
            " 0 0 1 1 1 1 1 1 1 0 0 0 1 1 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 1 1 0 1 1 1 0\n",
            " 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 0 0 1 0 0 1 0 0 1 1 0 0 1 1 1 0 1 0\n",
            " 1 0 0 0 1 0 1 0 1 0 1 1 0 1 1 0 1 1 0 0 1 1 1 0 1 1 1 0 1 1 1 1 1 1 0 0 0\n",
            " 1 0 1 1 1 0 1 1 1 1 0 1 0 0 0 1 0 0 0 1 0 1 0 1 1 1 1 0 1 1 1 0 1 0 0 1 0\n",
            " 1 0 0 1 0 1 0 0 1 0 0 1 0 1 1 1 1 0 1 1 0 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 0\n",
            " 0 1 0 1 1 1 1 1 0 0 1 1 0 1 1 1 1 0 1 1 0 1 1 0 0 1 1 1 1 1 1 0 1 1 1 0 0\n",
            " 0 1 0 1 0 1 0 0 1 1 0 0 1 0 0 1 0 0 1 1 1 0 0 1 0 0 1 0 0 1 1 1 0 0 0 1 0\n",
            " 1 0 1 1 1 0 0 0 0 0 1 0 0 1 1 1 0 1 1 0 0 1 0 1 0 0 0 0 0 1 0 0 1 1 0 1 0\n",
            " 0 0 1 0 0 1 0 1 1 1 0 0 0 1 1 0 0 1 1 0 1 1 1 0 0 1 0 0 1 0 0 0 1 0 0 1 0\n",
            " 1 1 1 1 0 1 0 0 0 0 0 0 0 1 0 1 1 1 1 1 1 1 1 1 1 0 0 1 1 0 1 1 1 1 1 1 1\n",
            " 0 1 0 0 1 1 0 0 1 1 0 1 1 1 0 1 0 1 0 0 0 0 1 0 1 0 1 0 1 0 1 1 1 0 0 0 1\n",
            " 0 1 1 0 0 0 1 0 1 1 0 1 1 1 0 1 1 1 0 0 1 1 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1\n",
            " 1 0 1 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 0 0 1 0 1 1 1 0 0 0 0 1 0 0 1 1 1 0\n",
            " 1 0 1 1 1 1 1 0 1 1 0 1 0 0 0 0 1 1 0 0 0 0 0 1 1 0 1 0 1 1 0 1 0 1 1 1 1\n",
            " 0 0 1 1 1 0 0 1 1 0 1 1 0 0 0]\n",
            "probabilities: (977, 2) \n",
            " [0 1 1 0 1 0 1 1 0 0 1 1 1 1 0 1 0 0 0 0 1 1 1 1 0 1 1 1 0 0 0 1 1 0 0 1 1\n",
            " 0 0 0 1 0 1 1 1 0 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 0 1 1 0 1 0 1 1 0 0 0 0 1\n",
            " 0 0 0 1 1 0 1 1 1 0 1 1 0 0 0 0 0 1 0 1 0 0 1 0 1 0 1 1 1 0 0 1 0 1 0 0 1\n",
            " 0 0 0 1 0 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 0 1 0 1 1 0 0 1 1 0 1 1 1 1 0 0 1\n",
            " 0 0 0 1 1 1 1 1 0 1 1 1 1 1 0 0 1 1 1 0 1 1 0 1 0 0 0 1 0 0 0 0 1 1 1 0 0\n",
            " 0 0 0 0 1 1 0 1 1 0 0 0 0 1 0 1 1 0 1 1 0 0 0 0 1 0 1 1 1 1 1 1 1 0 0 1 1\n",
            " 0 1 1 1 1 1 0 1 0 1 1 1 0 1 1 0 1 1 1 0 1 1 1 1 1 1 0 1 0 0 1 0 1 1 0 0 0\n",
            " 0 1 1 1 1 0 0 0 1 1 0 1 0 0 0 0 1 0 1 0 1 0 0 0 0 1 0 0 0 0 0 1 1 1 0 0 1\n",
            " 1 1 0 1 1 1 0 1 0 1 0 1 0 1 0 0 1 1 1 1 0 0 1 1 1 0 1 0 1 0 0 1 0 1 1 0 0\n",
            " 1 1 1 1 0 1 0 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 0 0 0 1 1 0\n",
            " 1 1 0 1 1 1 1 1 0 1 0 1 1 1 0 1 1 0 1 1 1 0 1 1 0 1 1 0 1 1 0 1 1 1 0 1 1\n",
            " 0 0 0 1 1 0 0 1 1 0 1 0 1 0 1 0 1 1 1 0 1 1 1 1 1 0 1 0 1 0 1 1 0 0 0 1 0\n",
            " 0 0 1 1 1 1 1 1 1 0 0 0 1 1 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 1 1 0 1 1 1 0\n",
            " 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 0 0 1 0 0 1 0 0 1 1 0 0 1 1 1 0 1 0\n",
            " 1 0 0 0 1 0 1 0 1 0 1 1 0 1 1 0 1 1 0 0 1 1 1 0 1 1 1 0 1 1 1 1 1 1 0 0 0\n",
            " 1 0 1 1 1 0 1 1 1 1 0 1 0 0 0 1 0 0 0 1 0 1 0 1 1 1 1 0 1 1 1 0 1 0 0 1 0\n",
            " 1 0 0 1 0 1 0 0 1 0 0 1 0 1 1 1 1 0 1 1 0 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 0\n",
            " 0 1 0 1 1 1 1 1 0 0 1 1 0 1 1 1 1 0 1 1 0 1 1 0 0 1 1 1 1 1 1 0 1 1 1 0 0\n",
            " 0 1 0 1 0 1 0 0 1 1 0 0 1 0 0 1 0 0 1 1 1 0 0 1 0 0 1 0 0 1 1 1 0 0 0 1 0\n",
            " 1 0 1 1 1 0 0 0 0 0 1 0 0 1 1 1 0 1 1 0 0 1 0 1 0 0 0 0 0 1 0 0 1 1 0 1 0\n",
            " 0 0 1 0 0 1 0 1 1 1 0 0 0 1 1 0 0 1 1 0 1 1 1 0 0 1 0 0 1 0 0 0 1 0 0 1 0\n",
            " 1 1 1 1 0 1 0 0 0 0 0 0 0 1 0 1 1 1 1 1 1 1 1 1 1 0 0 1 1 0 1 1 1 1 1 1 1\n",
            " 0 1 0 0 1 1 0 0 1 1 0 1 1 1 0 1 0 1 0 0 0 0 1 0 1 0 1 0 1 0 1 1 1 0 0 0 1\n",
            " 0 1 1 0 0 0 1 0 1 1 0 1 1 1 0 1 1 1 0 0 1 1 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1\n",
            " 1 0 1 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 0 0 1 0 1 1 1 0 0 0 0 1 0 0 1 1 1 0\n",
            " 1 0 1 1 1 1 1 0 1 1 0 1 0 0 0 0 1 1 0 0 0 0 0 1 1 0 1 0 1 1 0 1 0 1 1 1 1\n",
            " 0 0 1 1 1 0 0 1 1 0 1 1 0 0 0]\n",
            "trainset before adding uncertain samples (325, 10) (325,)\n",
            "trainset after adding uncertain samples (350, 10) (350,)\n",
            "updated train set: (350, 10) (350,) unique(labels): [173 177] [0 1]\n",
            "val set: (952, 10) (952,)\n",
            "\n",
            "Train set: (350, 10)\n",
            "Validation set: (952, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 14\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.290 s \n",
            "\n",
            "Accuracy rate is 78.801843 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.87      0.86       321\n",
            "           1       0.60      0.57      0.58       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.72      0.72      0.72       434\n",
            "weighted avg       0.78      0.79      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[278  43]\n",
            " [ 49  64]]\n",
            "--------------------------------\n",
            "val predicted: (952,) [0 1 1 0 1 0 1 1 0 0 1 1 1 1 0 1 0 0 0 1 1 1 1 0 1 1 1 0 0 0 1 1 0 0 1 1 0\n",
            " 0 0 1 0 1 1 1 0 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 0 1 1 0 1 0 1 1 0 0 0 0 1 0\n",
            " 0 0 1 1 0 1 1 1 0 1 1 0 0 0 0 0 1 1 0 1 0 1 0 1 1 0 0 1 0 1 0 0 1 0 0 0 1\n",
            " 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1 0 1 0 1 1 0 0 1 1 0 1 1 1 1 0 0 1 0 0 0 1 1\n",
            " 1 1 1 0 1 1 1 1 0 0 1 1 0 1 1 0 1 0 0 1 0 0 0 0 1 1 1 0 0 0 0 0 0 1 1 0 1\n",
            " 1 0 0 0 0 1 0 1 1 0 1 1 0 0 0 0 1 0 1 1 1 1 1 1 1 0 0 1 1 0 1 1 1 1 1 0 1\n",
            " 0 1 1 1 0 1 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0 1 0 1 1 0 0 0 0 1 1 1 1 0 0 0 1\n",
            " 1 0 1 0 0 0 0 1 0 1 0 1 0 0 0 0 1 0 0 0 0 0 1 1 1 0 0 1 1 1 0 1 1 1 0 1 0\n",
            " 1 0 1 0 1 0 0 1 1 1 1 0 0 1 1 0 1 0 1 0 0 1 0 1 1 0 0 1 1 1 1 0 1 0 1 1 0\n",
            " 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 0 0 0 1 1 0 1 1 0 1 1 1 1 1 0 1\n",
            " 0 1 1 1 0 1 1 0 1 1 1 1 1 0 1 1 0 1 1 0 1 1 1 0 1 1 0 0 0 1 1 0 0 1 1 0 1\n",
            " 1 0 1 0 1 1 1 0 1 1 1 1 1 0 1 0 1 0 1 1 0 0 0 1 0 0 0 1 1 1 1 1 1 1 0 0 0\n",
            " 1 1 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 1 1 0 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1\n",
            " 1 1 0 0 1 1 0 0 1 0 0 1 0 0 1 1 0 0 1 1 1 0 1 0 1 0 0 0 1 0 1 0 1 0 1 1 0\n",
            " 1 1 0 1 1 0 0 1 1 1 0 1 1 1 0 1 1 1 1 1 1 0 0 0 1 0 1 1 1 0 1 1 1 1 0 1 0\n",
            " 0 0 1 0 0 0 1 0 1 0 1 1 1 1 0 1 1 1 1 0 0 1 0 1 0 0 1 0 1 0 0 1 0 0 1 0 1\n",
            " 1 1 1 0 1 1 0 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 0 1 1 1 1 1 0 0 1 1 0 1\n",
            " 1 1 0 1 1 0 1 1 0 0 1 1 1 1 1 1 0 1 1 1 0 0 0 1 0 1 0 1 0 0 1 1 0 0 1 0 0\n",
            " 1 0 0 1 1 1 0 0 1 0 0 1 0 0 1 1 1 0 0 0 1 0 1 0 1 1 1 0 0 0 0 0 1 0 0 1 1\n",
            " 1 0 1 1 0 0 1 0 1 0 0 0 0 1 0 0 1 1 0 1 0 0 0 1 0 0 1 0 1 1 1 0 0 0 1 1 0\n",
            " 0 1 1 0 1 1 1 0 0 1 0 0 1 0 0 0 1 0 0 1 0 1 1 1 1 0 1 0 0 0 0 0 0 1 0 1 1\n",
            " 1 1 1 1 1 1 1 0 0 1 1 0 1 1 1 1 1 1 1 0 1 0 0 1 0 0 1 1 0 1 1 1 0 1 0 1 0\n",
            " 0 0 1 0 1 0 1 0 1 0 1 1 1 0 0 0 1 0 1 1 0 0 0 1 0 1 1 0 1 1 1 0 1 1 1 0 0\n",
            " 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 0 0 1 0\n",
            " 1 1 1 0 0 0 0 1 0 0 1 1 0 1 0 1 1 1 1 1 0 1 0 1 0 0 0 0 1 1 0 0 0 0 0 1 1\n",
            " 0 1 0 1 1 0 1 0 1 1 1 1 0 0 1 1 1 0 0 1 1 0 1 1 0 0 0]\n",
            "probabilities: (952, 2) \n",
            " [0 1 1 0 1 0 1 1 0 0 1 1 1 1 0 1 0 0 0 1 1 1 1 0 1 1 1 0 0 0 1 1 0 0 1 1 0\n",
            " 0 0 1 0 1 1 1 0 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 0 1 1 0 1 0 1 1 0 0 0 0 1 0\n",
            " 0 0 1 1 0 1 1 1 0 1 1 0 0 0 0 0 1 1 0 1 0 1 0 1 1 0 0 1 0 1 0 0 1 0 0 0 1\n",
            " 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1 0 1 0 1 1 0 0 1 1 0 1 1 1 1 0 0 1 0 0 0 1 1\n",
            " 1 1 1 0 1 1 1 1 0 0 1 1 0 1 1 0 1 0 0 1 0 0 0 0 1 1 1 0 0 0 0 0 0 1 1 0 1\n",
            " 1 0 0 0 0 1 0 1 1 0 1 1 0 0 0 0 1 0 1 1 1 1 1 1 1 0 0 1 1 0 1 1 1 1 1 0 1\n",
            " 0 1 1 1 0 1 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0 1 0 1 1 0 0 0 0 1 1 1 1 0 0 0 1\n",
            " 1 0 1 0 0 0 0 1 0 1 0 1 0 0 0 0 1 0 0 0 0 0 1 1 1 0 0 1 1 1 0 1 1 1 0 1 0\n",
            " 1 0 1 0 1 0 0 1 1 1 1 0 0 1 1 0 1 0 1 0 0 1 0 1 1 0 0 1 1 1 1 0 1 0 1 1 0\n",
            " 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 0 0 0 1 1 0 1 1 0 1 1 1 1 1 0 1\n",
            " 0 1 1 1 0 1 1 0 1 1 1 1 1 0 1 1 0 1 1 0 1 1 1 0 1 1 0 0 0 1 1 0 0 1 1 0 1\n",
            " 1 0 1 0 1 1 1 0 1 1 1 1 1 0 1 0 1 0 1 1 0 0 0 1 0 0 0 1 1 1 1 1 1 1 0 0 0\n",
            " 1 1 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 1 1 0 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1\n",
            " 1 1 0 0 1 1 0 0 1 0 0 1 0 0 1 1 0 0 1 1 1 0 1 0 1 0 0 0 1 0 1 0 1 0 1 1 0\n",
            " 1 1 0 1 1 0 0 1 1 1 0 1 1 1 0 1 1 1 1 1 1 0 0 0 1 0 1 1 1 0 1 1 1 1 0 1 0\n",
            " 0 0 1 0 0 0 1 0 1 0 1 1 1 1 0 1 1 1 1 0 0 1 0 1 0 0 1 0 1 0 0 1 0 0 1 0 1\n",
            " 1 1 1 0 1 1 0 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 0 1 1 1 1 1 0 0 1 1 0 1\n",
            " 1 1 0 1 1 0 1 1 0 0 1 1 1 1 1 1 0 1 1 1 0 0 0 1 0 1 0 1 0 0 1 1 0 0 1 0 0\n",
            " 1 0 0 1 1 1 0 0 1 0 0 1 0 0 1 1 1 0 0 0 1 0 1 0 1 1 1 0 0 0 0 0 1 0 0 1 1\n",
            " 1 0 1 1 0 0 1 0 1 0 0 0 0 1 0 0 1 1 0 1 0 0 0 1 0 0 1 0 1 1 1 0 0 0 1 1 0\n",
            " 0 1 1 0 1 1 1 0 0 1 0 0 1 0 0 0 1 0 0 1 0 1 1 1 1 0 1 0 0 0 0 0 0 1 0 1 1\n",
            " 1 1 1 1 1 1 1 0 0 1 1 0 1 1 1 1 1 1 1 0 1 0 0 1 0 0 1 1 0 1 1 1 0 1 0 1 0\n",
            " 0 0 1 0 1 0 1 0 1 0 1 1 1 0 0 0 1 0 1 1 0 0 0 1 0 1 1 0 1 1 1 0 1 1 1 0 0\n",
            " 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 0 0 1 0\n",
            " 1 1 1 0 0 0 0 1 0 0 1 1 0 1 0 1 1 1 1 1 0 1 0 1 0 0 0 0 1 1 0 0 0 0 0 1 1\n",
            " 0 1 0 1 1 0 1 0 1 1 1 1 0 0 1 1 1 0 0 1 1 0 1 1 0 0 0]\n",
            "trainset before adding uncertain samples (350, 10) (350,)\n",
            "trainset after adding uncertain samples (375, 10) (375,)\n",
            "updated train set: (375, 10) (375,) unique(labels): [184 191] [0 1]\n",
            "val set: (927, 10) (927,)\n",
            "\n",
            "Train set: (375, 10)\n",
            "Validation set: (927, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 15\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.206 s \n",
            "\n",
            "Accuracy rate is 79.262673 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.87      0.86       321\n",
            "           1       0.61      0.58      0.59       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.73      0.73      0.73       434\n",
            "weighted avg       0.79      0.79      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[278  43]\n",
            " [ 47  66]]\n",
            "--------------------------------\n",
            "val predicted: (927,) [0 1 1 0 1 0 1 1 0 0 1 1 1 1 0 1 0 0 0 1 1 1 1 0 1 1 1 0 0 0 1 1 0 0 1 1 0\n",
            " 0 0 1 0 1 1 1 0 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 0 1 1 1 0 1 1 0 0 0 0 1 0 0\n",
            " 0 1 1 0 1 1 1 0 1 1 0 0 0 0 1 1 0 1 0 1 0 1 1 0 0 1 0 1 0 0 1 0 0 0 1 0 1\n",
            " 1 0 1 0 1 1 1 1 1 1 1 0 1 1 1 0 0 1 1 0 1 1 1 1 0 0 1 0 0 0 1 1 1 1 1 0 1\n",
            " 1 1 1 0 0 1 1 1 1 1 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 1 1 0 1 1 0 0 0 0 1 0 1\n",
            " 1 0 1 1 0 0 0 0 1 0 1 1 1 1 1 1 1 0 0 1 1 0 1 1 1 1 1 0 1 0 1 1 1 0 1 1 0\n",
            " 1 1 1 1 1 1 1 1 0 0 1 0 1 1 0 0 0 0 1 1 1 1 0 0 0 1 1 0 1 0 0 0 0 1 0 1 0\n",
            " 1 0 0 0 0 1 0 0 0 0 0 1 1 1 0 1 1 1 0 1 1 1 0 1 1 0 1 0 1 0 0 1 1 1 0 0 1\n",
            " 1 0 1 0 1 0 0 1 0 1 1 0 0 1 1 1 1 0 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 0 1 1 1 1 0 0 0 1 1 0 1 1 0 1 1 1 1 1 0 1 0 1 1 1 0 1 1 0 1 1 1 1 1 0 1 1\n",
            " 0 1 1 0 1 1 1 1 1 0 0 0 1 1 0 0 1 1 0 1 1 0 1 0 1 1 1 0 1 1 1 1 0 1 0 1 0\n",
            " 1 1 0 0 0 1 0 0 0 1 1 1 1 1 1 1 0 0 0 1 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 1\n",
            " 1 0 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 0 0 1 0 0 1 0 1 1 0 0 1 1\n",
            " 1 0 1 0 1 0 0 0 1 0 1 0 1 0 1 1 0 1 1 0 1 1 0 0 1 1 1 0 1 1 1 0 1 1 1 1 1\n",
            " 1 0 0 0 1 0 1 1 1 0 1 1 1 1 0 1 0 0 0 1 0 0 1 0 1 0 1 1 1 1 0 1 1 1 1 0 0\n",
            " 1 0 1 0 0 1 0 1 0 0 1 0 0 1 0 1 1 1 1 0 1 1 0 0 1 1 1 1 0 1 1 1 1 1 0 1 1\n",
            " 1 0 0 1 0 1 1 1 1 1 0 0 1 1 0 1 1 1 0 1 1 0 1 1 0 0 1 1 1 1 1 1 0 1 1 1 0\n",
            " 0 0 1 0 1 0 1 0 0 1 1 0 0 1 0 0 1 0 0 1 1 1 0 0 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
            " 0 1 0 1 1 1 0 0 0 0 1 0 0 1 1 1 0 1 1 0 0 1 0 1 0 0 0 0 1 0 0 1 1 0 1 0 0\n",
            " 0 1 0 0 1 0 1 1 1 0 0 0 1 1 0 0 1 1 0 1 1 1 0 0 1 0 0 1 0 0 0 1 0 0 1 0 1\n",
            " 1 1 0 1 0 0 0 0 0 0 1 0 1 1 1 1 1 1 1 1 1 0 0 1 1 0 1 1 1 1 1 1 1 1 0 0 1\n",
            " 0 0 1 1 0 1 1 1 0 1 0 1 0 0 0 1 0 1 0 1 0 1 0 1 1 1 0 0 0 1 0 1 1 0 0 1 0\n",
            " 1 1 0 1 1 1 0 1 1 1 0 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1\n",
            " 1 0 0 1 1 0 1 0 0 0 1 0 1 1 1 0 0 0 0 1 0 0 1 1 0 1 0 1 1 1 1 1 0 1 0 1 0\n",
            " 0 0 0 1 1 0 0 0 0 0 1 1 0 1 0 1 1 0 1 0 1 1 1 1 0 0 1 1 1 0 0 1 1 0 1 1 0\n",
            " 0 0]\n",
            "probabilities: (927, 2) \n",
            " [0 1 1 0 1 0 1 1 0 0 1 1 1 1 0 1 0 0 0 1 1 1 1 0 1 1 1 0 0 0 1 1 0 0 1 1 0\n",
            " 0 0 1 0 1 1 1 0 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 0 1 1 1 0 1 1 0 0 0 0 1 0 0\n",
            " 0 1 1 0 1 1 1 0 1 1 0 0 0 0 1 1 0 1 0 1 0 1 1 0 0 1 0 1 0 0 1 0 0 0 1 0 1\n",
            " 1 0 1 0 1 1 1 1 1 1 1 0 1 1 1 0 0 1 1 0 1 1 1 1 0 0 1 0 0 0 1 1 1 1 1 0 1\n",
            " 1 1 1 0 0 1 1 1 1 1 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 1 1 0 1 1 0 0 0 0 1 0 1\n",
            " 1 0 1 1 0 0 0 0 1 0 1 1 1 1 1 1 1 0 0 1 1 0 1 1 1 1 1 0 1 0 1 1 1 0 1 1 0\n",
            " 1 1 1 1 1 1 1 1 0 0 1 0 1 1 0 0 0 0 1 1 1 1 0 0 0 1 1 0 1 0 0 0 0 1 0 1 0\n",
            " 1 0 0 0 0 1 0 0 0 0 0 1 1 1 0 1 1 1 0 1 1 1 0 1 1 0 1 0 1 0 0 1 1 1 0 0 1\n",
            " 1 0 1 0 1 0 0 1 0 1 1 0 0 1 1 1 1 0 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 0 1 1 1 1 0 0 0 1 1 0 1 1 0 1 1 1 1 1 0 1 0 1 1 1 0 1 1 0 1 1 1 1 1 0 1 1\n",
            " 0 1 1 0 1 1 1 1 1 0 0 0 1 1 0 0 1 1 0 1 1 0 1 0 1 1 1 0 1 1 1 1 0 1 0 1 0\n",
            " 1 1 0 0 0 1 0 0 0 1 1 1 1 1 1 1 0 0 0 1 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 1\n",
            " 1 0 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 0 0 1 0 0 1 0 1 1 0 0 1 1\n",
            " 1 0 1 0 1 0 0 0 1 0 1 0 1 0 1 1 0 1 1 0 1 1 0 0 1 1 1 0 1 1 1 0 1 1 1 1 1\n",
            " 1 0 0 0 1 0 1 1 1 0 1 1 1 1 0 1 0 0 0 1 0 0 1 0 1 0 1 1 1 1 0 1 1 1 1 0 0\n",
            " 1 0 1 0 0 1 0 1 0 0 1 0 0 1 0 1 1 1 1 0 1 1 0 0 1 1 1 1 0 1 1 1 1 1 0 1 1\n",
            " 1 0 0 1 0 1 1 1 1 1 0 0 1 1 0 1 1 1 0 1 1 0 1 1 0 0 1 1 1 1 1 1 0 1 1 1 0\n",
            " 0 0 1 0 1 0 1 0 0 1 1 0 0 1 0 0 1 0 0 1 1 1 0 0 1 0 0 1 0 0 1 1 1 0 0 0 1\n",
            " 0 1 0 1 1 1 0 0 0 0 1 0 0 1 1 1 0 1 1 0 0 1 0 1 0 0 0 0 1 0 0 1 1 0 1 0 0\n",
            " 0 1 0 0 1 0 1 1 1 0 0 0 1 1 0 0 1 1 0 1 1 1 0 0 1 0 0 1 0 0 0 1 0 0 1 0 1\n",
            " 1 1 0 1 0 0 0 0 0 0 1 0 1 1 1 1 1 1 1 1 1 0 0 1 1 0 1 1 1 1 1 1 1 1 0 0 1\n",
            " 0 0 1 1 0 1 1 1 0 1 0 1 0 0 0 1 0 1 0 1 0 1 0 1 1 1 0 0 0 1 0 1 1 0 0 1 0\n",
            " 1 1 0 1 1 1 0 1 1 1 0 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1\n",
            " 1 0 0 1 1 0 1 0 0 0 1 0 1 1 1 0 0 0 0 1 0 0 1 1 0 1 0 1 1 1 1 1 0 1 0 1 0\n",
            " 0 0 0 1 1 0 0 0 0 0 1 1 0 1 0 1 1 0 1 0 1 1 1 1 0 0 1 1 1 0 0 1 1 0 1 1 0\n",
            " 0 0]\n",
            "trainset before adding uncertain samples (375, 10) (375,)\n",
            "trainset after adding uncertain samples (400, 10) (400,)\n",
            "updated train set: (400, 10) (400,) unique(labels): [200 200] [0 1]\n",
            "val set: (902, 10) (902,)\n",
            "\n",
            "Train set: (400, 10)\n",
            "Validation set: (902, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 16\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.230 s \n",
            "\n",
            "Accuracy rate is 79.723502 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.87      0.86       321\n",
            "           1       0.62      0.58      0.60       113\n",
            "\n",
            "    accuracy                           0.80       434\n",
            "   macro avg       0.74      0.73      0.73       434\n",
            "weighted avg       0.79      0.80      0.80       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[280  41]\n",
            " [ 47  66]]\n",
            "--------------------------------\n",
            "val predicted: (902,) [0 1 1 0 1 0 1 1 0 0 1 1 1 1 0 1 0 0 0 1 1 1 1 0 1 1 1 0 0 0 1 1 0 0 1 1 0\n",
            " 0 0 1 0 1 1 1 0 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 0 1 1 1 0 1 1 0 0 0 0 1 0 0\n",
            " 1 1 0 1 1 1 0 1 1 0 0 0 0 1 1 0 1 0 1 0 1 1 0 0 1 0 1 0 0 1 0 0 0 1 0 1 1\n",
            " 0 1 0 1 1 1 1 1 1 1 0 1 1 1 0 0 1 1 0 1 1 1 1 0 0 1 0 0 0 1 1 1 1 1 0 1 1\n",
            " 1 1 0 0 1 1 1 1 1 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 1 0 1 1 0 0 0 0 1 0 1 1 0\n",
            " 1 1 0 0 0 0 1 0 1 1 1 1 1 1 1 0 0 1 1 0 1 1 1 1 1 0 1 0 1 1 1 0 1 1 0 1 1\n",
            " 1 1 1 1 1 1 0 0 1 0 1 1 0 0 0 0 1 1 1 1 0 0 0 1 1 0 1 0 0 0 1 0 1 0 1 0 0\n",
            " 0 0 1 0 0 0 0 0 1 1 1 0 1 1 1 0 1 1 1 0 1 1 0 1 0 1 0 0 1 1 1 0 0 1 1 0 1\n",
            " 0 1 0 0 1 0 1 1 0 0 1 1 1 1 0 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 0 0 0 1 1 0 1 1 0 1 1 1 1 1 0 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 1 0 1 1 0 1\n",
            " 1 1 1 1 0 0 0 1 1 0 1 1 0 1 1 0 1 0 1 1 1 0 1 1 1 1 0 1 0 1 0 1 1 0 0 0 1\n",
            " 0 0 0 1 1 1 1 1 1 1 0 0 0 1 1 1 0 0 1 0 0 0 0 0 0 0 0 1 1 1 0 1 1 0 1 0 0\n",
            " 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 0 0 1 0 0 1 0 1 1 0 0 1 1 1 0 1 0 1 0 0 1 0\n",
            " 1 0 1 0 1 1 0 1 1 0 1 1 0 0 1 1 1 0 1 1 1 0 1 1 1 1 1 1 0 0 0 1 0 1 1 1 0\n",
            " 1 1 1 1 0 1 0 0 0 1 0 0 1 0 1 0 1 1 1 1 0 1 1 1 1 0 0 1 0 1 0 1 0 1 0 0 1\n",
            " 0 0 1 0 1 1 1 1 1 0 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 0 1 1 1 1 1 0 0 1\n",
            " 1 0 1 1 1 0 1 1 0 1 1 0 0 1 1 1 1 1 1 0 1 1 1 0 0 0 1 0 1 0 1 0 0 1 1 0 0\n",
            " 1 0 0 1 0 0 1 1 1 0 0 1 0 0 1 0 0 1 1 1 0 0 0 1 0 1 0 1 1 1 0 0 0 0 1 0 0\n",
            " 1 1 1 1 1 0 0 1 0 1 0 0 0 0 1 0 0 1 1 0 1 0 0 1 0 0 1 0 1 1 1 0 0 0 1 1 0\n",
            " 0 1 1 0 1 1 1 0 0 1 0 1 0 0 0 1 0 0 1 0 1 1 1 0 1 0 0 0 0 0 0 0 1 1 1 1 1\n",
            " 1 1 1 1 0 0 1 1 0 1 1 1 1 1 1 1 1 0 0 1 0 0 1 1 0 1 1 1 0 1 0 1 0 0 0 1 1\n",
            " 0 1 0 1 0 1 1 0 0 0 1 0 1 1 0 0 1 0 1 1 0 1 1 1 0 1 1 1 0 0 1 1 1 1 1 0 1\n",
            " 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 0 0 1 0 1 1 1 0 0 0 0\n",
            " 1 0 1 0 1 0 1 1 1 1 1 0 1 0 1 0 0 0 0 1 1 0 0 0 1 1 0 1 0 1 1 0 1 0 1 1 1\n",
            " 0 0 1 1 1 0 0 1 1 0 1 1 0 0]\n",
            "probabilities: (902, 2) \n",
            " [0 1 1 0 1 0 1 1 0 0 1 1 1 1 0 1 0 0 0 1 1 1 1 0 1 1 1 0 0 0 1 1 0 0 1 1 0\n",
            " 0 0 1 0 1 1 1 0 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 0 1 1 1 0 1 1 0 0 0 0 1 0 0\n",
            " 1 1 0 1 1 1 0 1 1 0 0 0 0 1 1 0 1 0 1 0 1 1 0 0 1 0 1 0 0 1 0 0 0 1 0 1 1\n",
            " 0 1 0 1 1 1 1 1 1 1 0 1 1 1 0 0 1 1 0 1 1 1 1 0 0 1 0 0 0 1 1 1 1 1 0 1 1\n",
            " 1 1 0 0 1 1 1 1 1 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 1 0 1 1 0 0 0 0 1 0 1 1 0\n",
            " 1 1 0 0 0 0 1 0 1 1 1 1 1 1 1 0 0 1 1 0 1 1 1 1 1 0 1 0 1 1 1 0 1 1 0 1 1\n",
            " 1 1 1 1 1 1 0 0 1 0 1 1 0 0 0 0 1 1 1 1 0 0 0 1 1 0 1 0 0 0 1 0 1 0 1 0 0\n",
            " 0 0 1 0 0 0 0 0 1 1 1 0 1 1 1 0 1 1 1 0 1 1 0 1 0 1 0 0 1 1 1 0 0 1 1 0 1\n",
            " 0 1 0 0 1 0 1 1 0 0 1 1 1 1 0 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 0 0 0 1 1 0 1 1 0 1 1 1 1 1 0 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 1 0 1 1 0 1\n",
            " 1 1 1 1 0 0 0 1 1 0 1 1 0 1 1 0 1 0 1 1 1 0 1 1 1 1 0 1 0 1 0 1 1 0 0 0 1\n",
            " 0 0 0 1 1 1 1 1 1 1 0 0 0 1 1 1 0 0 1 0 0 0 0 0 0 0 0 1 1 1 0 1 1 0 1 0 0\n",
            " 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 0 0 1 0 0 1 0 1 1 0 0 1 1 1 0 1 0 1 0 0 1 0\n",
            " 1 0 1 0 1 1 0 1 1 0 1 1 0 0 1 1 1 0 1 1 1 0 1 1 1 1 1 1 0 0 0 1 0 1 1 1 0\n",
            " 1 1 1 1 0 1 0 0 0 1 0 0 1 0 1 0 1 1 1 1 0 1 1 1 1 0 0 1 0 1 0 1 0 1 0 0 1\n",
            " 0 0 1 0 1 1 1 1 1 0 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 0 1 1 1 1 1 0 0 1\n",
            " 1 0 1 1 1 0 1 1 0 1 1 0 0 1 1 1 1 1 1 0 1 1 1 0 0 0 1 0 1 0 1 0 0 1 1 0 0\n",
            " 1 0 0 1 0 0 1 1 1 0 0 1 0 0 1 0 0 1 1 1 0 0 0 1 0 1 0 1 1 1 0 0 0 0 1 0 0\n",
            " 1 1 1 1 1 0 0 1 0 1 0 0 0 0 1 0 0 1 1 0 1 0 0 1 0 0 1 0 1 1 1 0 0 0 1 1 0\n",
            " 0 1 1 0 1 1 1 0 0 1 0 1 0 0 0 1 0 0 1 0 1 1 1 0 1 0 0 0 0 0 0 0 1 1 1 1 1\n",
            " 1 1 1 1 0 0 1 1 0 1 1 1 1 1 1 1 1 0 0 1 0 0 1 1 0 1 1 1 0 1 0 1 0 0 0 1 1\n",
            " 0 1 0 1 0 1 1 0 0 0 1 0 1 1 0 0 1 0 1 1 0 1 1 1 0 1 1 1 0 0 1 1 1 1 1 0 1\n",
            " 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 0 0 1 0 1 1 1 0 0 0 0\n",
            " 1 0 1 0 1 0 1 1 1 1 1 0 1 0 1 0 0 0 0 1 1 0 0 0 1 1 0 1 0 1 1 0 1 0 1 1 1\n",
            " 0 0 1 1 1 0 0 1 1 0 1 1 0 0]\n",
            "trainset before adding uncertain samples (400, 10) (400,)\n",
            "trainset after adding uncertain samples (425, 10) (425,)\n",
            "updated train set: (425, 10) (425,) unique(labels): [213 212] [0 1]\n",
            "val set: (877, 10) (877,)\n",
            "\n",
            "Train set: (425, 10)\n",
            "Validation set: (877, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 17\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.254 s \n",
            "\n",
            "Accuracy rate is 79.032258 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.86      0.86       321\n",
            "           1       0.60      0.59      0.60       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.73      0.73      0.73       434\n",
            "weighted avg       0.79      0.79      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[276  45]\n",
            " [ 46  67]]\n",
            "--------------------------------\n",
            "val predicted: (877,) [0 1 1 0 1 0 1 1 0 0 1 1 1 1 0 1 0 0 1 1 1 0 1 1 1 0 0 1 1 0 0 1 1 0 0 0 1\n",
            " 0 1 1 1 0 1 1 1 1 0 1 1 1 0 0 1 1 1 1 0 1 1 1 0 1 1 0 0 0 1 0 0 1 1 0 1 1\n",
            " 1 0 1 1 0 0 0 0 1 1 0 1 0 1 0 1 1 0 0 1 0 1 0 0 1 0 0 0 1 0 1 1 0 1 0 1 1\n",
            " 1 1 1 1 1 0 1 1 1 0 0 1 1 0 1 1 1 1 0 0 1 0 0 0 1 1 1 1 1 0 1 1 1 1 0 0 1\n",
            " 1 1 1 1 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 1 0 1 1 0 0 0 0 1 0 1 1 0 1 1 0 0 0\n",
            " 0 1 0 1 1 1 1 1 1 1 0 0 1 1 0 1 1 1 1 1 0 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 1\n",
            " 1 0 0 1 0 1 1 0 0 0 1 1 1 1 0 0 0 1 1 1 0 0 0 1 0 1 0 1 0 0 0 0 1 0 0 0 0\n",
            " 0 1 1 1 0 1 1 1 1 1 1 0 1 1 0 1 0 1 0 0 1 1 1 0 0 1 1 0 1 0 1 0 0 1 0 1 1\n",
            " 0 0 1 1 1 1 0 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 0 1\n",
            " 1 0 1 1 1 1 1 0 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 0 0 0 1\n",
            " 1 0 1 1 0 1 1 0 1 0 1 1 0 1 1 1 1 0 1 0 1 0 1 1 0 0 0 1 0 0 0 1 1 1 1 1 1\n",
            " 0 0 0 1 1 1 0 0 1 0 0 0 0 0 0 0 0 1 1 1 0 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1\n",
            " 1 0 1 1 0 0 1 0 0 1 0 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 1 0 1 1 0 1 1 0 1 1 0\n",
            " 0 1 1 1 0 1 1 1 0 1 1 1 1 1 1 0 0 0 1 0 1 1 1 0 1 1 1 1 0 1 0 0 0 1 0 0 1\n",
            " 1 0 1 1 1 0 1 1 1 0 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 1 1 1 1 1 0 0 1 1 1 1 0\n",
            " 1 1 1 1 1 0 1 1 1 0 0 1 0 1 1 1 1 1 0 0 1 1 0 1 1 1 0 1 1 0 1 1 0 0 1 1 1\n",
            " 1 1 1 0 1 1 1 0 0 0 1 0 1 0 1 0 0 1 1 0 0 1 0 0 1 0 0 1 1 1 0 1 0 0 1 0 0\n",
            " 1 1 1 0 0 1 0 1 1 1 1 0 0 0 0 1 0 1 1 1 1 1 0 0 1 0 1 0 0 0 0 1 0 0 1 1 0\n",
            " 1 0 0 1 0 0 1 0 1 1 1 0 0 0 1 1 0 0 1 1 0 1 1 1 0 0 1 0 1 0 0 0 1 0 0 1 0\n",
            " 1 1 1 0 1 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 0 0 1 1 0 1 1 1 1 1 1 1 0 0 1 0\n",
            " 0 1 1 0 1 1 1 0 1 0 1 0 0 0 1 1 0 1 0 1 0 1 1 0 0 0 1 0 1 1 0 0 1 0 1 1 1\n",
            " 1 1 0 1 1 1 0 0 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1\n",
            " 0 1 0 0 0 1 0 1 1 1 0 0 0 0 1 0 1 0 1 0 1 1 1 1 1 0 1 0 1 0 0 0 0 1 0 0 0\n",
            " 1 1 0 1 0 1 1 0 1 0 1 1 1 0 1 1 1 0 0 1 1 0 1 1 0 0]\n",
            "probabilities: (877, 2) \n",
            " [0 1 1 0 1 0 1 1 0 0 1 1 1 1 0 1 0 0 1 1 1 0 1 1 1 0 0 1 1 0 0 1 1 0 0 0 1\n",
            " 0 1 1 1 0 1 1 1 1 0 1 1 1 0 0 1 1 1 1 0 1 1 1 0 1 1 0 0 0 1 0 0 1 1 0 1 1\n",
            " 1 0 1 1 0 0 0 0 1 1 0 1 0 1 0 1 1 0 0 1 0 1 0 0 1 0 0 0 1 0 1 1 0 1 0 1 1\n",
            " 1 1 1 1 1 0 1 1 1 0 0 1 1 0 1 1 1 1 0 0 1 0 0 0 1 1 1 1 1 0 1 1 1 1 0 0 1\n",
            " 1 1 1 1 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 1 0 1 1 0 0 0 0 1 0 1 1 0 1 1 0 0 0\n",
            " 0 1 0 1 1 1 1 1 1 1 0 0 1 1 0 1 1 1 1 1 0 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 1\n",
            " 1 0 0 1 0 1 1 0 0 0 1 1 1 1 0 0 0 1 1 1 0 0 0 1 0 1 0 1 0 0 0 0 1 0 0 0 0\n",
            " 0 1 1 1 0 1 1 1 1 1 1 0 1 1 0 1 0 1 0 0 1 1 1 0 0 1 1 0 1 0 1 0 0 1 0 1 1\n",
            " 0 0 1 1 1 1 0 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 0 1\n",
            " 1 0 1 1 1 1 1 0 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 0 0 0 1\n",
            " 1 0 1 1 0 1 1 0 1 0 1 1 0 1 1 1 1 0 1 0 1 0 1 1 0 0 0 1 0 0 0 1 1 1 1 1 1\n",
            " 0 0 0 1 1 1 0 0 1 0 0 0 0 0 0 0 0 1 1 1 0 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1\n",
            " 1 0 1 1 0 0 1 0 0 1 0 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 1 0 1 1 0 1 1 0 1 1 0\n",
            " 0 1 1 1 0 1 1 1 0 1 1 1 1 1 1 0 0 0 1 0 1 1 1 0 1 1 1 1 0 1 0 0 0 1 0 0 1\n",
            " 1 0 1 1 1 0 1 1 1 0 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 1 1 1 1 1 0 0 1 1 1 1 0\n",
            " 1 1 1 1 1 0 1 1 1 0 0 1 0 1 1 1 1 1 0 0 1 1 0 1 1 1 0 1 1 0 1 1 0 0 1 1 1\n",
            " 1 1 1 0 1 1 1 0 0 0 1 0 1 0 1 0 0 1 1 0 0 1 0 0 1 0 0 1 1 1 0 1 0 0 1 0 0\n",
            " 1 1 1 0 0 1 0 1 1 1 1 0 0 0 0 1 0 1 1 1 1 1 0 0 1 0 1 0 0 0 0 1 0 0 1 1 0\n",
            " 1 0 0 1 0 0 1 0 1 1 1 0 0 0 1 1 0 0 1 1 0 1 1 1 0 0 1 0 1 0 0 0 1 0 0 1 0\n",
            " 1 1 1 0 1 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 0 0 1 1 0 1 1 1 1 1 1 1 0 0 1 0\n",
            " 0 1 1 0 1 1 1 0 1 0 1 0 0 0 1 1 0 1 0 1 0 1 1 0 0 0 1 0 1 1 0 0 1 0 1 1 1\n",
            " 1 1 0 1 1 1 0 0 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1\n",
            " 0 1 0 0 0 1 0 1 1 1 0 0 0 0 1 0 1 0 1 0 1 1 1 1 1 0 1 0 1 0 0 0 0 1 0 0 0\n",
            " 1 1 0 1 0 1 1 0 1 0 1 1 1 0 1 1 1 0 0 1 1 0 1 1 0 0]\n",
            "trainset before adding uncertain samples (425, 10) (425,)\n",
            "trainset after adding uncertain samples (450, 10) (450,)\n",
            "updated train set: (450, 10) (450,) unique(labels): [230 220] [0 1]\n",
            "val set: (852, 10) (852,)\n",
            "\n",
            "Train set: (450, 10)\n",
            "Validation set: (852, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 18\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.304 s \n",
            "\n",
            "Accuracy rate is 79.723502 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.87      0.86       321\n",
            "           1       0.62      0.58      0.60       113\n",
            "\n",
            "    accuracy                           0.80       434\n",
            "   macro avg       0.74      0.73      0.73       434\n",
            "weighted avg       0.79      0.80      0.80       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[280  41]\n",
            " [ 47  66]]\n",
            "--------------------------------\n",
            "val predicted: (852,) [1 1 0 1 0 1 1 0 0 1 1 1 1 0 1 0 0 1 1 1 0 1 1 1 0 0 1 1 0 0 1 1 0 0 0 1 1\n",
            " 1 1 0 1 1 1 1 0 1 1 1 0 0 1 1 1 1 0 1 1 0 1 1 0 0 1 0 0 1 1 0 1 1 1 0 1 1\n",
            " 0 0 0 0 1 1 0 1 0 1 0 1 1 0 0 1 0 1 0 0 1 0 0 0 1 0 1 1 0 1 0 1 1 1 1 1 1\n",
            " 1 0 1 1 1 0 0 1 1 0 1 1 1 0 0 1 0 0 0 1 1 1 1 0 1 1 1 1 0 0 1 1 1 1 1 0 0\n",
            " 0 0 0 0 1 1 1 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 1 1 0 1 1 0 0 0 0 1 0 1 1 1 1\n",
            " 1 1 1 0 0 1 1 0 1 1 1 1 1 0 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 1 0 0 1 0 1 1 0\n",
            " 0 0 1 1 1 1 0 0 0 1 1 0 0 0 1 0 1 0 1 0 0 0 0 1 0 0 0 0 0 1 1 1 0 1 1 1 1\n",
            " 1 1 0 1 1 0 1 0 1 0 0 1 1 1 0 0 1 1 0 1 0 1 0 0 1 0 1 1 0 0 1 1 1 1 0 0 1\n",
            " 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 0 1 0 1 1 1 1 1 0 1 0 1\n",
            " 1 1 0 1 1 0 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 0 0 0 1 1 0 1 1 0 1 1 0 1 0 1\n",
            " 1 0 1 1 1 1 0 1 0 1 0 1 1 0 0 0 0 0 0 1 1 1 1 1 1 0 0 0 1 1 1 0 0 1 0 0 0\n",
            " 0 0 0 0 0 1 1 1 0 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 0 1 0 1 1\n",
            " 1 1 0 1 0 1 0 0 1 0 1 0 1 0 1 1 0 1 1 0 1 1 0 0 1 1 1 0 1 1 1 0 1 1 1 1 1\n",
            " 1 0 0 0 1 0 1 1 1 0 1 1 1 1 0 1 0 0 0 1 0 0 1 1 0 1 1 1 0 1 1 1 0 1 0 1 0\n",
            " 1 0 1 0 0 1 0 1 0 1 1 1 1 1 0 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 0 1 1 1\n",
            " 1 1 0 1 1 1 1 1 0 1 1 0 1 1 0 0 1 1 1 1 1 1 0 1 1 1 0 0 0 1 0 1 0 1 0 0 1\n",
            " 1 0 0 1 0 0 1 0 0 1 1 1 0 1 0 1 0 0 1 1 1 0 0 1 0 1 1 1 1 0 0 0 1 0 1 1 1\n",
            " 1 1 0 0 1 0 1 0 0 0 0 1 0 0 1 1 0 1 0 0 1 0 0 1 0 1 1 1 0 0 0 1 1 0 0 1 1\n",
            " 0 1 1 1 0 0 1 0 1 0 0 0 1 0 0 1 0 1 1 1 0 1 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1\n",
            " 1 0 0 1 1 0 1 1 1 1 1 1 1 0 0 1 0 0 1 1 0 1 1 1 0 1 0 1 0 0 0 1 1 1 0 1 0\n",
            " 1 1 0 0 0 1 0 1 0 0 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 0 1 0 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 0 0 1 0 1 1 1 0 0 0 0 1 0 1 0 1 0 1 1 1\n",
            " 1 1 1 0 1 0 0 0 0 1 0 0 0 1 1 0 1 0 1 1 0 1 0 1 1 1 0 1 1 0 0 1 1 0 1 1 0\n",
            " 0]\n",
            "probabilities: (852, 2) \n",
            " [1 1 0 1 0 1 1 0 0 1 1 1 1 0 1 0 0 1 1 1 0 1 1 1 0 0 1 1 0 0 1 1 0 0 0 1 1\n",
            " 1 1 0 1 1 1 1 0 1 1 1 0 0 1 1 1 1 0 1 1 0 1 1 0 0 1 0 0 1 1 0 1 1 1 0 1 1\n",
            " 0 0 0 0 1 1 0 1 0 1 0 1 1 0 0 1 0 1 0 0 1 0 0 0 1 0 1 1 0 1 0 1 1 1 1 1 1\n",
            " 1 0 1 1 1 0 0 1 1 0 1 1 1 0 0 1 0 0 0 1 1 1 1 0 1 1 1 1 0 0 1 1 1 1 1 0 0\n",
            " 0 0 0 0 1 1 1 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 1 1 0 1 1 0 0 0 0 1 0 1 1 1 1\n",
            " 1 1 1 0 0 1 1 0 1 1 1 1 1 0 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 1 0 0 1 0 1 1 0\n",
            " 0 0 1 1 1 1 0 0 0 1 1 0 0 0 1 0 1 0 1 0 0 0 0 1 0 0 0 0 0 1 1 1 0 1 1 1 1\n",
            " 1 1 0 1 1 0 1 0 1 0 0 1 1 1 0 0 1 1 0 1 0 1 0 0 1 0 1 1 0 0 1 1 1 1 0 0 1\n",
            " 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 0 1 0 1 1 1 1 1 0 1 0 1\n",
            " 1 1 0 1 1 0 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 0 0 0 1 1 0 1 1 0 1 1 0 1 0 1\n",
            " 1 0 1 1 1 1 0 1 0 1 0 1 1 0 0 0 0 0 0 1 1 1 1 1 1 0 0 0 1 1 1 0 0 1 0 0 0\n",
            " 0 0 0 0 0 1 1 1 0 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 0 1 0 1 1\n",
            " 1 1 0 1 0 1 0 0 1 0 1 0 1 0 1 1 0 1 1 0 1 1 0 0 1 1 1 0 1 1 1 0 1 1 1 1 1\n",
            " 1 0 0 0 1 0 1 1 1 0 1 1 1 1 0 1 0 0 0 1 0 0 1 1 0 1 1 1 0 1 1 1 0 1 0 1 0\n",
            " 1 0 1 0 0 1 0 1 0 1 1 1 1 1 0 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 0 1 1 1\n",
            " 1 1 0 1 1 1 1 1 0 1 1 0 1 1 0 0 1 1 1 1 1 1 0 1 1 1 0 0 0 1 0 1 0 1 0 0 1\n",
            " 1 0 0 1 0 0 1 0 0 1 1 1 0 1 0 1 0 0 1 1 1 0 0 1 0 1 1 1 1 0 0 0 1 0 1 1 1\n",
            " 1 1 0 0 1 0 1 0 0 0 0 1 0 0 1 1 0 1 0 0 1 0 0 1 0 1 1 1 0 0 0 1 1 0 0 1 1\n",
            " 0 1 1 1 0 0 1 0 1 0 0 0 1 0 0 1 0 1 1 1 0 1 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1\n",
            " 1 0 0 1 1 0 1 1 1 1 1 1 1 0 0 1 0 0 1 1 0 1 1 1 0 1 0 1 0 0 0 1 1 1 0 1 0\n",
            " 1 1 0 0 0 1 0 1 0 0 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 0 1 0 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 0 0 1 0 1 1 1 0 0 0 0 1 0 1 0 1 0 1 1 1\n",
            " 1 1 1 0 1 0 0 0 0 1 0 0 0 1 1 0 1 0 1 1 0 1 0 1 1 1 0 1 1 0 0 1 1 0 1 1 0\n",
            " 0]\n",
            "trainset before adding uncertain samples (450, 10) (450,)\n",
            "trainset after adding uncertain samples (475, 10) (475,)\n",
            "updated train set: (475, 10) (475,) unique(labels): [242 233] [0 1]\n",
            "val set: (827, 10) (827,)\n",
            "\n",
            "Train set: (475, 10)\n",
            "Validation set: (827, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 19\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.339 s \n",
            "\n",
            "Accuracy rate is 80.414747 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.88      0.87       321\n",
            "           1       0.64      0.58      0.60       113\n",
            "\n",
            "    accuracy                           0.80       434\n",
            "   macro avg       0.75      0.73      0.74       434\n",
            "weighted avg       0.80      0.80      0.80       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[284  37]\n",
            " [ 48  65]]\n",
            "--------------------------------\n",
            "val predicted: (827,) [1 1 0 1 0 1 1 0 0 1 1 1 0 1 0 0 1 1 1 0 1 1 1 0 0 1 1 0 0 1 1 0 0 0 1 1 1\n",
            " 1 0 1 1 1 1 0 1 1 1 0 0 1 1 1 1 0 1 1 0 1 1 0 0 1 0 0 1 1 0 1 1 1 0 1 1 0\n",
            " 0 0 1 1 0 1 0 1 0 1 1 0 0 1 0 0 0 1 0 0 0 1 0 1 1 0 1 0 1 1 1 1 1 0 1 1 1\n",
            " 0 0 1 1 0 1 1 1 0 0 1 0 0 0 1 1 1 0 1 1 1 0 0 1 1 1 1 1 0 0 0 0 0 0 1 1 1\n",
            " 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 1 1 0 1 0 0 0 0 0 1 1 1 1 1 1 1 0 0 1 1 0 1\n",
            " 1 1 1 1 0 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 1 0 0 1 0 1 1 0 0 0 1 1 1 1 0 0 0\n",
            " 1 1 0 0 0 1 0 1 0 1 0 0 0 0 1 0 0 0 0 0 1 1 1 0 1 1 1 1 1 0 1 1 0 1 0 1 0\n",
            " 0 1 1 0 0 1 1 0 1 0 1 0 0 1 0 1 0 0 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 0 0 0 1 1 0 1 0 1 1 1 1 1 0 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 1 0\n",
            " 1 1 0 1 1 1 1 1 0 0 0 1 1 0 1 1 0 1 0 1 0 1 1 0 1 1 1 1 0 1 0 1 0 1 1 0 0\n",
            " 0 0 0 0 1 1 1 1 1 1 0 0 0 1 1 1 0 0 1 0 0 0 0 0 0 0 1 1 1 0 1 1 0 1 0 0 1\n",
            " 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 0 1 0 1 1 1 1 0 1 0 1 0 0 1 0 1 0 1 0 1 1\n",
            " 0 1 1 0 1 1 0 0 1 1 0 1 1 1 0 1 1 1 1 1 1 0 0 0 1 0 1 1 1 0 1 1 1 1 0 1 0\n",
            " 0 0 1 0 0 1 1 0 1 1 1 0 1 1 1 0 1 0 1 0 1 0 1 0 0 1 0 1 0 1 1 1 1 1 0 0 1\n",
            " 1 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 0 1 1 1 1 1 0 1 1 1 1 1 0 1 1 0 1 0 0 1 1\n",
            " 1 1 1 1 0 1 1 1 0 0 1 0 1 0 1 0 0 1 1 0 0 1 0 0 1 0 0 1 1 0 1 0 1 0 0 1 1\n",
            " 1 0 0 1 0 1 1 1 1 0 0 0 1 0 1 1 1 1 1 0 0 1 0 1 0 0 0 0 1 0 1 0 1 0 0 1 0\n",
            " 0 1 0 1 1 1 0 0 0 1 1 0 0 1 1 0 1 1 1 0 0 1 0 1 0 0 0 1 0 0 1 0 1 1 1 0 1\n",
            " 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 0 0 1 1 0 1 1 1 1 1 1 0 0 1 0 0 1 1 0 1 1\n",
            " 1 0 1 0 1 0 0 0 1 1 1 0 1 0 1 1 0 0 0 1 0 1 0 0 1 0 1 1 1 1 1 0 1 1 1 0 0\n",
            " 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 0 0 1 0 1 1\n",
            " 1 0 0 0 0 1 0 1 0 1 0 1 1 1 1 1 1 0 1 0 0 0 1 0 0 0 1 1 0 1 0 1 1 0 1 0 1\n",
            " 1 1 0 1 0 0 1 1 0 1 1 0 0]\n",
            "probabilities: (827, 2) \n",
            " [1 1 0 1 0 1 1 0 0 1 1 1 0 1 0 0 1 1 1 0 1 1 1 0 0 1 1 0 0 1 1 0 0 0 1 1 1\n",
            " 1 0 1 1 1 1 0 1 1 1 0 0 1 1 1 1 0 1 1 0 1 1 0 0 1 0 0 1 1 0 1 1 1 0 1 1 0\n",
            " 0 0 1 1 0 1 0 1 0 1 1 0 0 1 0 0 0 1 0 0 0 1 0 1 1 0 1 0 1 1 1 1 1 0 1 1 1\n",
            " 0 0 1 1 0 1 1 1 0 0 1 0 0 0 1 1 1 0 1 1 1 0 0 1 1 1 1 1 0 0 0 0 0 0 1 1 1\n",
            " 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 1 1 0 1 0 0 0 0 0 1 1 1 1 1 1 1 0 0 1 1 0 1\n",
            " 1 1 1 1 0 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 1 0 0 1 0 1 1 0 0 0 1 1 1 1 0 0 0\n",
            " 1 1 0 0 0 1 0 1 0 1 0 0 0 0 1 0 0 0 0 0 1 1 1 0 1 1 1 1 1 0 1 1 0 1 0 1 0\n",
            " 0 1 1 0 0 1 1 0 1 0 1 0 0 1 0 1 0 0 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 0 0 0 1 1 0 1 0 1 1 1 1 1 0 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 1 0\n",
            " 1 1 0 1 1 1 1 1 0 0 0 1 1 0 1 1 0 1 0 1 0 1 1 0 1 1 1 1 0 1 0 1 0 1 1 0 0\n",
            " 0 0 0 0 1 1 1 1 1 1 0 0 0 1 1 1 0 0 1 0 0 0 0 0 0 0 1 1 1 0 1 1 0 1 0 0 1\n",
            " 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 0 1 0 1 1 1 1 0 1 0 1 0 0 1 0 1 0 1 0 1 1\n",
            " 0 1 1 0 1 1 0 0 1 1 0 1 1 1 0 1 1 1 1 1 1 0 0 0 1 0 1 1 1 0 1 1 1 1 0 1 0\n",
            " 0 0 1 0 0 1 1 0 1 1 1 0 1 1 1 0 1 0 1 0 1 0 1 0 0 1 0 1 0 1 1 1 1 1 0 0 1\n",
            " 1 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 0 1 1 1 1 1 0 1 1 1 1 1 0 1 1 0 1 0 0 1 1\n",
            " 1 1 1 1 0 1 1 1 0 0 1 0 1 0 1 0 0 1 1 0 0 1 0 0 1 0 0 1 1 0 1 0 1 0 0 1 1\n",
            " 1 0 0 1 0 1 1 1 1 0 0 0 1 0 1 1 1 1 1 0 0 1 0 1 0 0 0 0 1 0 1 0 1 0 0 1 0\n",
            " 0 1 0 1 1 1 0 0 0 1 1 0 0 1 1 0 1 1 1 0 0 1 0 1 0 0 0 1 0 0 1 0 1 1 1 0 1\n",
            " 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 0 0 1 1 0 1 1 1 1 1 1 0 0 1 0 0 1 1 0 1 1\n",
            " 1 0 1 0 1 0 0 0 1 1 1 0 1 0 1 1 0 0 0 1 0 1 0 0 1 0 1 1 1 1 1 0 1 1 1 0 0\n",
            " 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 0 0 1 0 1 1\n",
            " 1 0 0 0 0 1 0 1 0 1 0 1 1 1 1 1 1 0 1 0 0 0 1 0 0 0 1 1 0 1 0 1 1 0 1 0 1\n",
            " 1 1 0 1 0 0 1 1 0 1 1 0 0]\n",
            "trainset before adding uncertain samples (475, 10) (475,)\n",
            "trainset after adding uncertain samples (500, 10) (500,)\n",
            "updated train set: (500, 10) (500,) unique(labels): [252 248] [0 1]\n",
            "val set: (802, 10) (802,)\n",
            "\n",
            "Train set: (500, 10)\n",
            "Validation set: (802, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 20\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.359 s \n",
            "\n",
            "Accuracy rate is 80.875576 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.89      0.87       321\n",
            "           1       0.65      0.58      0.61       113\n",
            "\n",
            "    accuracy                           0.81       434\n",
            "   macro avg       0.75      0.73      0.74       434\n",
            "weighted avg       0.80      0.81      0.80       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[286  35]\n",
            " [ 48  65]]\n",
            "--------------------------------\n",
            "final active learning accuracies [70.04608294930875, 76.49769585253456, 79.03225806451613, 78.57142857142857, 77.64976958525345, 78.80184331797236, 78.80184331797236, 77.41935483870968, 77.88018433179722, 77.64976958525345, 79.03225806451613, 77.88018433179722, 78.80184331797236, 78.80184331797236, 79.26267281105991, 79.72350230414746, 79.03225806451613, 79.72350230414746, 80.4147465437788, 80.87557603686636]\n",
            "saved /Users/wenxuanhuang/Documents/Repo/ML-for-COVID-19-dataset/Results/Active-learning-experiment-14.pkl /Users/wenxuanhuang/Documents/Repo/ML-for-COVID-19-dataset ['Decision_tree.ipynb', 'dec_git.png', 'Logit_default_f10.pdf', 'Logistic.ipynb', 'SVC.ipynb', 'RF_f5e50_featureimp.pdf', 'log_al.png', 'dec_git.pdf', '.DS_Store', 'log_git.png', 'svm_git.png', 'Logistic_Scikit.ipynb', 'knn_git.pdf', 'knn_git.png', 'rf_al.png', 'Best classifier_RF_f5e50.pdf', 'KNN.ipynb', 'GBDC.ipynb', 'rf_git.png', 'README.md', 'all_training.csv', 'Results', 'svm_al.png', 'Log_ROC.png', 'Logit_default_f7(p_removal).pdf', 'Active_learning.ipynb', 'Random_forest.ipynb', 'Model_select.ipynb', 'gdbc_git.png', '.git', '.vscode', 'Untitled', 'RF_f5e50_modelselect.pdf', 'Logit_default_f8(std_removal).pdf']\n",
            "\n",
            "---------------------------- FINISHED ---------------------------\n",
            "\n",
            "Count = 15, using model = GDBCModel, selection_function = EntropySelection, k = 10, iteration = 0.\n",
            "\n",
            "initial random chosen samples (10,)\n",
            "initial train set: (10, 10) (10,) unique(labels): [4 6] [0 1]\n",
            "Val set: (1292, 10) (1292,) (10,)\n",
            "\n",
            "Train set: (10, 10)\n",
            "Validation set: (1292, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.590 s \n",
            "\n",
            "Accuracy rate is 65.207373 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.64      0.73       321\n",
            "           1       0.40      0.70      0.51       113\n",
            "\n",
            "    accuracy                           0.65       434\n",
            "   macro avg       0.63      0.67      0.62       434\n",
            "weighted avg       0.74      0.65      0.67       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[204 117]\n",
            " [ 34  79]]\n",
            "--------------------------------\n",
            "val predicted: (1292,) [0 1 1 ... 1 0 0]\n",
            "probabilities: (1292, 2) \n",
            " [0 1 1 ... 1 0 0]\n",
            "trainset before adding uncertain samples (10, 10) (10,)\n",
            "trainset after adding uncertain samples (20, 10) (20,)\n",
            "updated train set: (20, 10) (20,) unique(labels): [12  8] [0 1]\n",
            "val set: (1282, 10) (1282,)\n",
            "\n",
            "Train set: (20, 10)\n",
            "Validation set: (1282, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.639 s \n",
            "\n",
            "Accuracy rate is 76.958525 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.94      0.86       321\n",
            "           1       0.63      0.27      0.38       113\n",
            "\n",
            "    accuracy                           0.77       434\n",
            "   macro avg       0.71      0.61      0.62       434\n",
            "weighted avg       0.75      0.77      0.73       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[303  18]\n",
            " [ 82  31]]\n",
            "--------------------------------\n",
            "val predicted: (1282,) [0 0 1 ... 0 0 0]\n",
            "probabilities: (1282, 2) \n",
            " [0 0 1 ... 0 0 0]\n",
            "trainset before adding uncertain samples (20, 10) (20,)\n",
            "trainset after adding uncertain samples (30, 10) (30,)\n",
            "updated train set: (30, 10) (30,) unique(labels): [15 15] [0 1]\n",
            "val set: (1272, 10) (1272,)\n",
            "\n",
            "Train set: (30, 10)\n",
            "Validation set: (1272, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 3\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.670 s \n",
            "\n",
            "Accuracy rate is 75.115207 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.87      0.84       321\n",
            "           1       0.53      0.41      0.46       113\n",
            "\n",
            "    accuracy                           0.75       434\n",
            "   macro avg       0.67      0.64      0.65       434\n",
            "weighted avg       0.73      0.75      0.74       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[280  41]\n",
            " [ 67  46]]\n",
            "--------------------------------\n",
            "val predicted: (1272,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1272, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "trainset before adding uncertain samples (30, 10) (30,)\n",
            "trainset after adding uncertain samples (40, 10) (40,)\n",
            "updated train set: (40, 10) (40,) unique(labels): [20 20] [0 1]\n",
            "val set: (1262, 10) (1262,)\n",
            "\n",
            "Train set: (40, 10)\n",
            "Validation set: (1262, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 4\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.686 s \n",
            "\n",
            "Accuracy rate is 70.046083 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.77      0.79       321\n",
            "           1       0.43      0.50      0.46       113\n",
            "\n",
            "    accuracy                           0.70       434\n",
            "   macro avg       0.62      0.63      0.63       434\n",
            "weighted avg       0.71      0.70      0.71       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[248  73]\n",
            " [ 57  56]]\n",
            "--------------------------------\n",
            "val predicted: (1262,) [0 1 0 ... 0 0 0]\n",
            "probabilities: (1262, 2) \n",
            " [0 1 0 ... 0 0 0]\n",
            "trainset before adding uncertain samples (40, 10) (40,)\n",
            "trainset after adding uncertain samples (50, 10) (50,)\n",
            "updated train set: (50, 10) (50,) unique(labels): [25 25] [0 1]\n",
            "val set: (1252, 10) (1252,)\n",
            "\n",
            "Train set: (50, 10)\n",
            "Validation set: (1252, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 5\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.698 s \n",
            "\n",
            "Accuracy rate is 72.350230 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.80      0.81       321\n",
            "           1       0.47      0.50      0.49       113\n",
            "\n",
            "    accuracy                           0.72       434\n",
            "   macro avg       0.65      0.65      0.65       434\n",
            "weighted avg       0.73      0.72      0.73       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[257  64]\n",
            " [ 56  57]]\n",
            "--------------------------------\n",
            "val predicted: (1252,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1252, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "trainset before adding uncertain samples (50, 10) (50,)\n",
            "trainset after adding uncertain samples (60, 10) (60,)\n",
            "updated train set: (60, 10) (60,) unique(labels): [30 30] [0 1]\n",
            "val set: (1242, 10) (1242,)\n",
            "\n",
            "Train set: (60, 10)\n",
            "Validation set: (1242, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 6\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.723 s \n",
            "\n",
            "Accuracy rate is 71.428571 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.79      0.80       321\n",
            "           1       0.46      0.51      0.48       113\n",
            "\n",
            "    accuracy                           0.71       434\n",
            "   macro avg       0.64      0.65      0.64       434\n",
            "weighted avg       0.73      0.71      0.72       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[252  69]\n",
            " [ 55  58]]\n",
            "--------------------------------\n",
            "val predicted: (1242,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1242, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "trainset before adding uncertain samples (60, 10) (60,)\n",
            "trainset after adding uncertain samples (70, 10) (70,)\n",
            "updated train set: (70, 10) (70,) unique(labels): [37 33] [0 1]\n",
            "val set: (1232, 10) (1232,)\n",
            "\n",
            "Train set: (70, 10)\n",
            "Validation set: (1232, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 7\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.771 s \n",
            "\n",
            "Accuracy rate is 77.419355 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.89      0.85       321\n",
            "           1       0.59      0.44      0.51       113\n",
            "\n",
            "    accuracy                           0.77       434\n",
            "   macro avg       0.70      0.67      0.68       434\n",
            "weighted avg       0.76      0.77      0.76       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[286  35]\n",
            " [ 63  50]]\n",
            "--------------------------------\n",
            "val predicted: (1232,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1232, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "trainset before adding uncertain samples (70, 10) (70,)\n",
            "trainset after adding uncertain samples (80, 10) (80,)\n",
            "updated train set: (80, 10) (80,) unique(labels): [40 40] [0 1]\n",
            "val set: (1222, 10) (1222,)\n",
            "\n",
            "Train set: (80, 10)\n",
            "Validation set: (1222, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 8\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.787 s \n",
            "\n",
            "Accuracy rate is 76.267281 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.88      0.85       321\n",
            "           1       0.56      0.44      0.49       113\n",
            "\n",
            "    accuracy                           0.76       434\n",
            "   macro avg       0.69      0.66      0.67       434\n",
            "weighted avg       0.75      0.76      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[281  40]\n",
            " [ 63  50]]\n",
            "--------------------------------\n",
            "val predicted: (1222,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1222, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "trainset before adding uncertain samples (80, 10) (80,)\n",
            "trainset after adding uncertain samples (90, 10) (90,)\n",
            "updated train set: (90, 10) (90,) unique(labels): [44 46] [0 1]\n",
            "val set: (1212, 10) (1212,)\n",
            "\n",
            "Train set: (90, 10)\n",
            "Validation set: (1212, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 9\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.797 s \n",
            "\n",
            "Accuracy rate is 77.419355 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.87      0.85       321\n",
            "           1       0.57      0.51      0.54       113\n",
            "\n",
            "    accuracy                           0.77       434\n",
            "   macro avg       0.70      0.69      0.70       434\n",
            "weighted avg       0.77      0.77      0.77       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[278  43]\n",
            " [ 55  58]]\n",
            "--------------------------------\n",
            "val predicted: (1212,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1212, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "trainset before adding uncertain samples (90, 10) (90,)\n",
            "trainset after adding uncertain samples (100, 10) (100,)\n",
            "updated train set: (100, 10) (100,) unique(labels): [48 52] [0 1]\n",
            "val set: (1202, 10) (1202,)\n",
            "\n",
            "Train set: (100, 10)\n",
            "Validation set: (1202, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 10\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.809 s \n",
            "\n",
            "Accuracy rate is 77.880184 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.87      0.85       321\n",
            "           1       0.59      0.51      0.55       113\n",
            "\n",
            "    accuracy                           0.78       434\n",
            "   macro avg       0.71      0.69      0.70       434\n",
            "weighted avg       0.77      0.78      0.77       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[280  41]\n",
            " [ 55  58]]\n",
            "--------------------------------\n",
            "val predicted: (1202,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1202, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "trainset before adding uncertain samples (100, 10) (100,)\n",
            "trainset after adding uncertain samples (110, 10) (110,)\n",
            "updated train set: (110, 10) (110,) unique(labels): [53 57] [0 1]\n",
            "val set: (1192, 10) (1192,)\n",
            "\n",
            "Train set: (110, 10)\n",
            "Validation set: (1192, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 11\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.831 s \n",
            "\n",
            "Accuracy rate is 78.571429 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.89      0.86       321\n",
            "           1       0.61      0.49      0.54       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.72      0.69      0.70       434\n",
            "weighted avg       0.77      0.79      0.78       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[286  35]\n",
            " [ 58  55]]\n",
            "--------------------------------\n",
            "val predicted: (1192,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1192, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "trainset before adding uncertain samples (110, 10) (110,)\n",
            "trainset after adding uncertain samples (120, 10) (120,)\n",
            "updated train set: (120, 10) (120,) unique(labels): [54 66] [0 1]\n",
            "val set: (1182, 10) (1182,)\n",
            "\n",
            "Train set: (120, 10)\n",
            "Validation set: (1182, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 12\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.839 s \n",
            "\n",
            "Accuracy rate is 73.963134 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.80      0.82       321\n",
            "           1       0.50      0.57      0.53       113\n",
            "\n",
            "    accuracy                           0.74       434\n",
            "   macro avg       0.67      0.68      0.68       434\n",
            "weighted avg       0.75      0.74      0.74       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[257  64]\n",
            " [ 49  64]]\n",
            "--------------------------------\n",
            "val predicted: (1182,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1182, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "trainset before adding uncertain samples (120, 10) (120,)\n",
            "trainset after adding uncertain samples (130, 10) (130,)\n",
            "updated train set: (130, 10) (130,) unique(labels): [60 70] [0 1]\n",
            "val set: (1172, 10) (1172,)\n",
            "\n",
            "Train set: (130, 10)\n",
            "Validation set: (1172, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 13\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.865 s \n",
            "\n",
            "Accuracy rate is 79.493088 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.88      0.86       321\n",
            "           1       0.62      0.54      0.58       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.73      0.71      0.72       434\n",
            "weighted avg       0.79      0.79      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[284  37]\n",
            " [ 52  61]]\n",
            "--------------------------------\n",
            "val predicted: (1172,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1172, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "trainset before adding uncertain samples (130, 10) (130,)\n",
            "trainset after adding uncertain samples (140, 10) (140,)\n",
            "updated train set: (140, 10) (140,) unique(labels): [65 75] [0 1]\n",
            "val set: (1162, 10) (1162,)\n",
            "\n",
            "Train set: (140, 10)\n",
            "Validation set: (1162, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 14\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.875 s \n",
            "\n",
            "Accuracy rate is 79.032258 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.87      0.86       321\n",
            "           1       0.60      0.57      0.58       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.73      0.72      0.72       434\n",
            "weighted avg       0.79      0.79      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[279  42]\n",
            " [ 49  64]]\n",
            "--------------------------------\n",
            "val predicted: (1162,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1162, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "trainset before adding uncertain samples (140, 10) (140,)\n",
            "trainset after adding uncertain samples (150, 10) (150,)\n",
            "updated train set: (150, 10) (150,) unique(labels): [68 82] [0 1]\n",
            "val set: (1152, 10) (1152,)\n",
            "\n",
            "Train set: (150, 10)\n",
            "Validation set: (1152, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 15\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.894 s \n",
            "\n",
            "Accuracy rate is 79.493088 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.87      0.86       321\n",
            "           1       0.61      0.59      0.60       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.73      0.73      0.73       434\n",
            "weighted avg       0.79      0.79      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[278  43]\n",
            " [ 46  67]]\n",
            "--------------------------------\n",
            "val predicted: (1152,) [0 1 1 ... 1 0 0]\n",
            "probabilities: (1152, 2) \n",
            " [0 1 1 ... 1 0 0]\n",
            "trainset before adding uncertain samples (150, 10) (150,)\n",
            "trainset after adding uncertain samples (160, 10) (160,)\n",
            "updated train set: (160, 10) (160,) unique(labels): [73 87] [0 1]\n",
            "val set: (1142, 10) (1142,)\n",
            "\n",
            "Train set: (160, 10)\n",
            "Validation set: (1142, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 16\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.926 s \n",
            "\n",
            "Accuracy rate is 79.262673 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.86      0.86       321\n",
            "           1       0.60      0.59      0.60       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.73      0.73      0.73       434\n",
            "weighted avg       0.79      0.79      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[277  44]\n",
            " [ 46  67]]\n",
            "--------------------------------\n",
            "val predicted: (1142,) [0 1 1 ... 1 0 0]\n",
            "probabilities: (1142, 2) \n",
            " [0 1 1 ... 1 0 0]\n",
            "trainset before adding uncertain samples (160, 10) (160,)\n",
            "trainset after adding uncertain samples (170, 10) (170,)\n",
            "updated train set: (170, 10) (170,) unique(labels): [77 93] [0 1]\n",
            "val set: (1132, 10) (1132,)\n",
            "\n",
            "Train set: (170, 10)\n",
            "Validation set: (1132, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 17\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.913 s \n",
            "\n",
            "Accuracy rate is 78.341014 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.85      0.85       321\n",
            "           1       0.58      0.58      0.58       113\n",
            "\n",
            "    accuracy                           0.78       434\n",
            "   macro avg       0.72      0.72      0.72       434\n",
            "weighted avg       0.78      0.78      0.78       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[274  47]\n",
            " [ 47  66]]\n",
            "--------------------------------\n",
            "val predicted: (1132,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1132, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "trainset before adding uncertain samples (170, 10) (170,)\n",
            "trainset after adding uncertain samples (180, 10) (180,)\n",
            "updated train set: (180, 10) (180,) unique(labels): [82 98] [0 1]\n",
            "val set: (1122, 10) (1122,)\n",
            "\n",
            "Train set: (180, 10)\n",
            "Validation set: (1122, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 18\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.928 s \n",
            "\n",
            "Accuracy rate is 78.571429 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.86      0.86       321\n",
            "           1       0.59      0.58      0.58       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.72      0.72      0.72       434\n",
            "weighted avg       0.78      0.79      0.78       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[276  45]\n",
            " [ 48  65]]\n",
            "--------------------------------\n",
            "val predicted: (1122,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1122, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "trainset before adding uncertain samples (180, 10) (180,)\n",
            "trainset after adding uncertain samples (190, 10) (190,)\n",
            "updated train set: (190, 10) (190,) unique(labels): [ 89 101] [0 1]\n",
            "val set: (1112, 10) (1112,)\n",
            "\n",
            "Train set: (190, 10)\n",
            "Validation set: (1112, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 19\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.943 s \n",
            "\n",
            "Accuracy rate is 79.032258 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.87      0.86       321\n",
            "           1       0.60      0.58      0.59       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.73      0.72      0.72       434\n",
            "weighted avg       0.79      0.79      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[278  43]\n",
            " [ 48  65]]\n",
            "--------------------------------\n",
            "val predicted: (1112,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1112, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "trainset before adding uncertain samples (190, 10) (190,)\n",
            "trainset after adding uncertain samples (200, 10) (200,)\n",
            "updated train set: (200, 10) (200,) unique(labels): [ 96 104] [0 1]\n",
            "val set: (1102, 10) (1102,)\n",
            "\n",
            "Train set: (200, 10)\n",
            "Validation set: (1102, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 20\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.995 s \n",
            "\n",
            "Accuracy rate is 80.184332 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.88      0.87       321\n",
            "           1       0.63      0.58      0.61       113\n",
            "\n",
            "    accuracy                           0.80       434\n",
            "   macro avg       0.74      0.73      0.74       434\n",
            "weighted avg       0.80      0.80      0.80       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[282  39]\n",
            " [ 47  66]]\n",
            "--------------------------------\n",
            "val predicted: (1102,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1102, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "trainset before adding uncertain samples (200, 10) (200,)\n",
            "trainset after adding uncertain samples (210, 10) (210,)\n",
            "updated train set: (210, 10) (210,) unique(labels): [ 99 111] [0 1]\n",
            "val set: (1092, 10) (1092,)\n",
            "\n",
            "Train set: (210, 10)\n",
            "Validation set: (1092, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 21\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.985 s \n",
            "\n",
            "Accuracy rate is 79.953917 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.88      0.87       321\n",
            "           1       0.62      0.58      0.60       113\n",
            "\n",
            "    accuracy                           0.80       434\n",
            "   macro avg       0.74      0.73      0.73       434\n",
            "weighted avg       0.80      0.80      0.80       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[281  40]\n",
            " [ 47  66]]\n",
            "--------------------------------\n",
            "val predicted: (1092,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1092, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "trainset before adding uncertain samples (210, 10) (210,)\n",
            "trainset after adding uncertain samples (220, 10) (220,)\n",
            "updated train set: (220, 10) (220,) unique(labels): [102 118] [0 1]\n",
            "val set: (1082, 10) (1082,)\n",
            "\n",
            "Train set: (220, 10)\n",
            "Validation set: (1082, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 22\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.985 s \n",
            "\n",
            "Accuracy rate is 80.184332 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.88      0.87       321\n",
            "           1       0.63      0.59      0.61       113\n",
            "\n",
            "    accuracy                           0.80       434\n",
            "   macro avg       0.74      0.73      0.74       434\n",
            "weighted avg       0.80      0.80      0.80       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[281  40]\n",
            " [ 46  67]]\n",
            "--------------------------------\n",
            "val predicted: (1082,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1082, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "trainset before adding uncertain samples (220, 10) (220,)\n",
            "trainset after adding uncertain samples (230, 10) (230,)\n",
            "updated train set: (230, 10) (230,) unique(labels): [106 124] [0 1]\n",
            "val set: (1072, 10) (1072,)\n",
            "\n",
            "Train set: (230, 10)\n",
            "Validation set: (1072, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 23\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.995 s \n",
            "\n",
            "Accuracy rate is 78.801843 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.86      0.86       321\n",
            "           1       0.60      0.58      0.59       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.72      0.72      0.72       434\n",
            "weighted avg       0.79      0.79      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[277  44]\n",
            " [ 48  65]]\n",
            "--------------------------------\n",
            "val predicted: (1072,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1072, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "trainset before adding uncertain samples (230, 10) (230,)\n",
            "trainset after adding uncertain samples (240, 10) (240,)\n",
            "updated train set: (240, 10) (240,) unique(labels): [111 129] [0 1]\n",
            "val set: (1062, 10) (1062,)\n",
            "\n",
            "Train set: (240, 10)\n",
            "Validation set: (1062, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 24\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.022 s \n",
            "\n",
            "Accuracy rate is 79.493088 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.87      0.86       321\n",
            "           1       0.61      0.58      0.60       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.73      0.73      0.73       434\n",
            "weighted avg       0.79      0.79      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[279  42]\n",
            " [ 47  66]]\n",
            "--------------------------------\n",
            "val predicted: (1062,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1062, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "trainset before adding uncertain samples (240, 10) (240,)\n",
            "trainset after adding uncertain samples (250, 10) (250,)\n",
            "updated train set: (250, 10) (250,) unique(labels): [118 132] [0 1]\n",
            "val set: (1052, 10) (1052,)\n",
            "\n",
            "Train set: (250, 10)\n",
            "Validation set: (1052, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 25\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.022 s \n",
            "\n",
            "Accuracy rate is 79.723502 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.88      0.86       321\n",
            "           1       0.62      0.58      0.60       113\n",
            "\n",
            "    accuracy                           0.80       434\n",
            "   macro avg       0.74      0.73      0.73       434\n",
            "weighted avg       0.79      0.80      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[281  40]\n",
            " [ 48  65]]\n",
            "--------------------------------\n",
            "val predicted: (1052,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1052, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "trainset before adding uncertain samples (250, 10) (250,)\n",
            "trainset after adding uncertain samples (260, 10) (260,)\n",
            "updated train set: (260, 10) (260,) unique(labels): [122 138] [0 1]\n",
            "val set: (1042, 10) (1042,)\n",
            "\n",
            "Train set: (260, 10)\n",
            "Validation set: (1042, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 26\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.042 s \n",
            "\n",
            "Accuracy rate is 80.184332 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.88      0.87       321\n",
            "           1       0.63      0.58      0.61       113\n",
            "\n",
            "    accuracy                           0.80       434\n",
            "   macro avg       0.74      0.73      0.74       434\n",
            "weighted avg       0.80      0.80      0.80       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[282  39]\n",
            " [ 47  66]]\n",
            "--------------------------------\n",
            "val predicted: (1042,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1042, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "trainset before adding uncertain samples (260, 10) (260,)\n",
            "trainset after adding uncertain samples (270, 10) (270,)\n",
            "updated train set: (270, 10) (270,) unique(labels): [126 144] [0 1]\n",
            "val set: (1032, 10) (1032,)\n",
            "\n",
            "Train set: (270, 10)\n",
            "Validation set: (1032, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 27\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.055 s \n",
            "\n",
            "Accuracy rate is 79.953917 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.88      0.87       321\n",
            "           1       0.62      0.58      0.60       113\n",
            "\n",
            "    accuracy                           0.80       434\n",
            "   macro avg       0.74      0.73      0.73       434\n",
            "weighted avg       0.79      0.80      0.80       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[282  39]\n",
            " [ 48  65]]\n",
            "--------------------------------\n",
            "val predicted: (1032,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1032, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "trainset before adding uncertain samples (270, 10) (270,)\n",
            "trainset after adding uncertain samples (280, 10) (280,)\n",
            "updated train set: (280, 10) (280,) unique(labels): [130 150] [0 1]\n",
            "val set: (1022, 10) (1022,)\n",
            "\n",
            "Train set: (280, 10)\n",
            "Validation set: (1022, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 28\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.072 s \n",
            "\n",
            "Accuracy rate is 81.566820 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.89      0.88       321\n",
            "           1       0.66      0.60      0.63       113\n",
            "\n",
            "    accuracy                           0.82       434\n",
            "   macro avg       0.76      0.75      0.75       434\n",
            "weighted avg       0.81      0.82      0.81       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[286  35]\n",
            " [ 45  68]]\n",
            "--------------------------------\n",
            "val predicted: (1022,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1022, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "trainset before adding uncertain samples (280, 10) (280,)\n",
            "trainset after adding uncertain samples (290, 10) (290,)\n",
            "updated train set: (290, 10) (290,) unique(labels): [133 157] [0 1]\n",
            "val set: (1012, 10) (1012,)\n",
            "\n",
            "Train set: (290, 10)\n",
            "Validation set: (1012, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 29\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.071 s \n",
            "\n",
            "Accuracy rate is 81.797235 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.89      0.88       321\n",
            "           1       0.66      0.62      0.64       113\n",
            "\n",
            "    accuracy                           0.82       434\n",
            "   macro avg       0.76      0.75      0.76       434\n",
            "weighted avg       0.81      0.82      0.82       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[285  36]\n",
            " [ 43  70]]\n",
            "--------------------------------\n",
            "val predicted: (1012,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1012, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "trainset before adding uncertain samples (290, 10) (290,)\n",
            "trainset after adding uncertain samples (300, 10) (300,)\n",
            "updated train set: (300, 10) (300,) unique(labels): [139 161] [0 1]\n",
            "val set: (1002, 10) (1002,)\n",
            "\n",
            "Train set: (300, 10)\n",
            "Validation set: (1002, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 30\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.091 s \n",
            "\n",
            "Accuracy rate is 81.566820 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.89      0.88       321\n",
            "           1       0.66      0.60      0.63       113\n",
            "\n",
            "    accuracy                           0.82       434\n",
            "   macro avg       0.76      0.75      0.75       434\n",
            "weighted avg       0.81      0.82      0.81       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[286  35]\n",
            " [ 45  68]]\n",
            "--------------------------------\n",
            "val predicted: (1002,) [0 1 1 ... 1 0 0]\n",
            "probabilities: (1002, 2) \n",
            " [0 1 1 ... 1 0 0]\n",
            "trainset before adding uncertain samples (300, 10) (300,)\n",
            "trainset after adding uncertain samples (310, 10) (310,)\n",
            "updated train set: (310, 10) (310,) unique(labels): [147 163] [0 1]\n",
            "val set: (992, 10) (992,)\n",
            "\n",
            "Train set: (310, 10)\n",
            "Validation set: (992, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 31\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.122 s \n",
            "\n",
            "Accuracy rate is 81.336406 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.88      0.88       321\n",
            "           1       0.65      0.61      0.63       113\n",
            "\n",
            "    accuracy                           0.81       434\n",
            "   macro avg       0.76      0.75      0.75       434\n",
            "weighted avg       0.81      0.81      0.81       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[284  37]\n",
            " [ 44  69]]\n",
            "--------------------------------\n",
            "val predicted: (992,) [0 1 1 0 1 0 1 1 0 0 0 1 1 1 0 1 0 0 0 1 1 1 0 1 1 0 1 0 0 1 1 0 0 1 0 0 1\n",
            " 0 0 0 1 1 1 1 1 0 0 0 1 1 1 1 1 0 1 1 0 1 1 0 0 1 1 1 1 0 1 1 0 0 1 0 0 1\n",
            " 1 0 0 0 0 1 0 0 1 1 1 1 1 0 0 0 1 1 0 0 0 1 1 0 0 1 0 0 1 0 1 1 1 0 0 1 0\n",
            " 1 0 0 1 0 0 0 0 0 1 0 0 1 1 0 1 0 0 1 1 1 1 0 1 1 1 1 1 1 0 1 1 0 1 0 1 1\n",
            " 0 1 1 1 0 0 0 1 0 0 0 1 1 1 1 0 1 1 1 1 0 0 0 1 1 1 0 1 1 0 1 0 0 0 0 0 0\n",
            " 1 0 0 1 1 1 0 0 1 0 0 0 0 0 1 1 0 1 1 0 0 0 1 0 1 0 0 1 1 0 1 1 0 0 0 0 0\n",
            " 0 1 1 0 1 1 1 1 1 1 1 1 0 0 1 1 0 1 1 1 0 1 1 0 1 0 1 1 0 1 0 1 1 1 1 1 1\n",
            " 1 1 0 1 1 0 1 1 0 0 0 0 1 1 1 1 1 0 0 0 0 1 1 0 1 0 1 0 1 0 0 1 0 0 1 0 0\n",
            " 0 0 0 0 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 0 1 0 1 0 0 0 1 1 0 0 1 1 0 1 0\n",
            " 0 1 0 0 1 0 1 1 0 0 1 1 1 1 0 1 0 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1\n",
            " 1 1 0 0 1 0 1 0 1 1 0 1 1 0 0 1 0 1 0 1 1 1 0 1 1 0 1 1 1 1 0 0 1 0 1 1 0\n",
            " 1 1 0 1 1 1 1 1 1 0 0 0 0 0 1 1 0 0 1 0 0 1 0 0 0 1 0 1 0 0 1 0 0 1 0 1 1\n",
            " 0 1 0 1 1 1 1 0 1 0 1 0 1 1 1 0 0 1 0 0 0 1 1 1 1 1 0 0 0 1 1 1 0 1 0 1 0\n",
            " 0 1 0 0 0 0 0 1 1 0 0 1 0 1 1 1 0 0 1 1 1 1 1 0 1 1 1 1 1 0 0 1 1 0 0 1 1\n",
            " 0 0 0 1 0 0 1 1 0 0 1 0 1 0 1 0 1 0 0 0 0 1 0 1 0 1 0 1 1 0 1 1 0 1 0 1 1\n",
            " 1 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0 0 1 0 1 1 1 1 1 0 1 1 0 0 0 0 0 1 0 0 1 0\n",
            " 0 1 0 1 1 0 1 1 1 0 0 1 1 1 0 1 0 1 0 0 0 1 0 0 1 0 1 1 0 1 1 0 0 0 0 1 1\n",
            " 1 0 1 1 0 1 1 1 0 1 0 1 1 0 0 0 1 1 0 1 1 1 1 0 0 1 1 0 0 1 1 1 1 0 1 0 0\n",
            " 1 0 0 1 1 1 1 1 0 1 1 1 0 1 0 1 0 1 0 0 1 0 1 1 0 0 0 1 0 0 1 0 1 0 0 0 0\n",
            " 1 0 1 1 0 0 1 0 0 1 1 1 0 1 0 0 1 0 1 0 0 1 1 1 1 1 1 0 0 1 0 0 1 1 1 0 1\n",
            " 1 1 0 0 1 0 1 0 0 1 0 0 0 0 0 1 1 0 1 0 0 1 0 0 1 0 1 1 1 0 0 0 1 1 0 0 1\n",
            " 0 1 0 1 1 0 1 0 0 1 1 0 1 1 0 0 0 1 0 0 1 0 1 1 1 1 0 1 0 0 1 0 0 0 0 0 1\n",
            " 1 1 1 1 1 1 1 1 1 0 0 1 0 0 0 1 1 1 1 1 0 0 0 0 0 1 0 1 1 1 0 1 1 1 0 0 1\n",
            " 0 0 0 0 0 0 1 0 1 0 1 0 1 1 1 0 0 1 0 1 0 1 1 0 0 1 0 1 1 1 1 1 0 0 1 1 0\n",
            " 0 1 1 1 1 0 1 1 0 1 1 0 1 1 1 0 1 1 1 1 0 0 1 1 1 1 1 0 0 1 1 0 0 1 1 0 1\n",
            " 1 0 0 1 1 1 0 1 0 0 0 1 0 1 0 1 1 0 1 0 1 1 1 1 1 0 0 0 0 0 0 1 1 1 0 1 0\n",
            " 1 0 0 1 0 0 1 0 1 1 1 1 1 0 0 1 1 1 0 0 1 0 0 1 0 1 1 1 0 0]\n",
            "probabilities: (992, 2) \n",
            " [0 1 1 0 1 0 1 1 0 0 0 1 1 1 0 1 0 0 0 1 1 1 0 1 1 0 1 0 0 1 1 0 0 1 0 0 1\n",
            " 0 0 0 1 1 1 1 1 0 0 0 1 1 1 1 1 0 1 1 0 1 1 0 0 1 1 1 1 0 1 1 0 0 1 0 0 1\n",
            " 1 0 0 0 0 1 0 0 1 1 1 1 1 0 0 0 1 1 0 0 0 1 1 0 0 1 0 0 1 0 1 1 1 0 0 1 0\n",
            " 1 0 0 1 0 0 0 0 0 1 0 0 1 1 0 1 0 0 1 1 1 1 0 1 1 1 1 1 1 0 1 1 0 1 0 1 1\n",
            " 0 1 1 1 0 0 0 1 0 0 0 1 1 1 1 0 1 1 1 1 0 0 0 1 1 1 0 1 1 0 1 0 0 0 0 0 0\n",
            " 1 0 0 1 1 1 0 0 1 0 0 0 0 0 1 1 0 1 1 0 0 0 1 0 1 0 0 1 1 0 1 1 0 0 0 0 0\n",
            " 0 1 1 0 1 1 1 1 1 1 1 1 0 0 1 1 0 1 1 1 0 1 1 0 1 0 1 1 0 1 0 1 1 1 1 1 1\n",
            " 1 1 0 1 1 0 1 1 0 0 0 0 1 1 1 1 1 0 0 0 0 1 1 0 1 0 1 0 1 0 0 1 0 0 1 0 0\n",
            " 0 0 0 0 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 0 1 0 1 0 0 0 1 1 0 0 1 1 0 1 0\n",
            " 0 1 0 0 1 0 1 1 0 0 1 1 1 1 0 1 0 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1\n",
            " 1 1 0 0 1 0 1 0 1 1 0 1 1 0 0 1 0 1 0 1 1 1 0 1 1 0 1 1 1 1 0 0 1 0 1 1 0\n",
            " 1 1 0 1 1 1 1 1 1 0 0 0 0 0 1 1 0 0 1 0 0 1 0 0 0 1 0 1 0 0 1 0 0 1 0 1 1\n",
            " 0 1 0 1 1 1 1 0 1 0 1 0 1 1 1 0 0 1 0 0 0 1 1 1 1 1 0 0 0 1 1 1 0 1 0 1 0\n",
            " 0 1 0 0 0 0 0 1 1 0 0 1 0 1 1 1 0 0 1 1 1 1 1 0 1 1 1 1 1 0 0 1 1 0 0 1 1\n",
            " 0 0 0 1 0 0 1 1 0 0 1 0 1 0 1 0 1 0 0 0 0 1 0 1 0 1 0 1 1 0 1 1 0 1 0 1 1\n",
            " 1 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0 0 1 0 1 1 1 1 1 0 1 1 0 0 0 0 0 1 0 0 1 0\n",
            " 0 1 0 1 1 0 1 1 1 0 0 1 1 1 0 1 0 1 0 0 0 1 0 0 1 0 1 1 0 1 1 0 0 0 0 1 1\n",
            " 1 0 1 1 0 1 1 1 0 1 0 1 1 0 0 0 1 1 0 1 1 1 1 0 0 1 1 0 0 1 1 1 1 0 1 0 0\n",
            " 1 0 0 1 1 1 1 1 0 1 1 1 0 1 0 1 0 1 0 0 1 0 1 1 0 0 0 1 0 0 1 0 1 0 0 0 0\n",
            " 1 0 1 1 0 0 1 0 0 1 1 1 0 1 0 0 1 0 1 0 0 1 1 1 1 1 1 0 0 1 0 0 1 1 1 0 1\n",
            " 1 1 0 0 1 0 1 0 0 1 0 0 0 0 0 1 1 0 1 0 0 1 0 0 1 0 1 1 1 0 0 0 1 1 0 0 1\n",
            " 0 1 0 1 1 0 1 0 0 1 1 0 1 1 0 0 0 1 0 0 1 0 1 1 1 1 0 1 0 0 1 0 0 0 0 0 1\n",
            " 1 1 1 1 1 1 1 1 1 0 0 1 0 0 0 1 1 1 1 1 0 0 0 0 0 1 0 1 1 1 0 1 1 1 0 0 1\n",
            " 0 0 0 0 0 0 1 0 1 0 1 0 1 1 1 0 0 1 0 1 0 1 1 0 0 1 0 1 1 1 1 1 0 0 1 1 0\n",
            " 0 1 1 1 1 0 1 1 0 1 1 0 1 1 1 0 1 1 1 1 0 0 1 1 1 1 1 0 0 1 1 0 0 1 1 0 1\n",
            " 1 0 0 1 1 1 0 1 0 0 0 1 0 1 0 1 1 0 1 0 1 1 1 1 1 0 0 0 0 0 0 1 1 1 0 1 0\n",
            " 1 0 0 1 0 0 1 0 1 1 1 1 1 0 0 1 1 1 0 0 1 0 0 1 0 1 1 1 0 0]\n",
            "trainset before adding uncertain samples (310, 10) (310,)\n",
            "trainset after adding uncertain samples (320, 10) (320,)\n",
            "updated train set: (320, 10) (320,) unique(labels): [153 167] [0 1]\n",
            "val set: (982, 10) (982,)\n",
            "\n",
            "Train set: (320, 10)\n",
            "Validation set: (982, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 32\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.131 s \n",
            "\n",
            "Accuracy rate is 80.645161 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.88      0.87       321\n",
            "           1       0.64      0.59      0.61       113\n",
            "\n",
            "    accuracy                           0.81       434\n",
            "   macro avg       0.75      0.74      0.74       434\n",
            "weighted avg       0.80      0.81      0.80       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[283  38]\n",
            " [ 46  67]]\n",
            "--------------------------------\n",
            "val predicted: (982,) [0 1 1 0 1 0 1 1 0 0 0 1 1 1 0 1 0 0 0 1 1 1 0 1 1 0 1 0 0 1 1 0 0 1 0 0 1\n",
            " 0 0 0 1 1 1 1 1 0 0 0 1 1 1 1 1 0 1 1 0 1 1 0 0 1 1 1 1 0 1 1 0 0 1 0 0 1\n",
            " 1 0 0 0 0 1 0 0 1 1 1 1 1 0 0 0 1 1 0 0 0 1 1 0 0 1 0 0 1 0 1 1 1 0 0 1 0\n",
            " 1 0 0 1 0 0 0 0 0 1 0 0 1 1 0 1 0 0 1 1 1 0 1 1 1 1 1 1 0 1 1 0 1 0 1 1 0\n",
            " 1 1 1 0 0 0 1 0 0 0 1 1 1 0 1 1 1 1 0 0 0 1 1 1 0 1 1 0 1 0 0 0 0 0 0 1 0\n",
            " 0 1 1 1 0 0 1 0 0 0 0 0 1 1 0 1 1 0 0 0 1 0 1 0 0 1 1 0 1 1 0 0 0 0 0 0 1\n",
            " 1 0 1 1 1 1 1 1 1 1 0 0 1 1 0 1 1 1 0 1 1 0 1 0 1 1 0 1 0 1 1 1 1 1 1 1 0\n",
            " 1 1 0 1 1 0 0 0 0 1 1 1 1 1 0 0 0 0 1 1 0 0 0 1 0 1 0 0 1 0 0 1 0 0 0 0 0\n",
            " 0 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 0 1 0 1 0 0 0 1 1 0 0 1 1 0 1 0 0 1 0\n",
            " 0 1 0 1 1 0 0 1 1 1 1 0 1 0 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 0\n",
            " 0 1 0 1 0 1 1 0 1 1 0 0 1 0 1 0 1 1 1 0 1 1 0 1 1 1 1 0 0 1 0 1 1 0 1 1 0\n",
            " 1 1 1 1 1 1 0 0 0 0 0 1 1 0 0 1 0 0 1 0 0 0 1 0 1 0 0 1 0 0 1 0 1 1 0 1 0\n",
            " 1 1 1 1 0 1 0 1 0 1 1 1 0 0 1 0 0 0 1 1 1 1 1 0 0 0 1 1 1 0 1 0 1 0 0 1 0\n",
            " 0 0 0 0 1 1 0 0 1 0 1 1 1 0 0 1 1 1 1 1 0 1 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1\n",
            " 0 0 1 1 0 0 1 0 1 0 1 0 1 0 0 0 0 1 0 1 0 1 0 1 1 0 1 1 0 1 0 1 1 1 1 0 1\n",
            " 1 1 0 1 1 1 1 1 1 1 0 0 0 1 0 1 1 1 1 1 0 1 1 0 0 0 0 0 1 0 0 1 0 0 1 0 1\n",
            " 1 0 1 1 1 0 0 1 1 1 0 1 0 0 0 0 1 0 0 1 0 1 1 0 1 1 0 0 0 0 1 1 1 0 1 1 0\n",
            " 1 1 1 0 1 0 1 1 0 0 0 1 1 0 1 1 1 1 0 0 1 1 0 0 1 1 1 1 0 1 0 0 1 0 0 1 1\n",
            " 1 1 1 0 1 1 1 0 1 0 1 0 1 0 0 1 0 1 0 0 0 1 0 0 1 0 1 0 0 0 0 1 0 1 1 0 0\n",
            " 1 0 0 1 1 1 0 1 0 0 1 0 1 0 0 1 1 1 1 1 0 0 1 0 0 1 1 1 0 1 1 1 0 0 1 0 1\n",
            " 0 0 1 0 0 0 0 0 1 0 1 0 0 1 0 0 1 0 1 1 1 0 0 0 1 1 0 0 1 0 1 0 1 1 0 1 0\n",
            " 0 1 1 0 1 1 0 0 0 1 0 0 1 0 1 1 1 1 0 1 0 0 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1\n",
            " 1 0 0 1 0 0 0 1 1 1 1 0 0 0 0 0 1 0 1 1 1 0 1 1 1 0 0 1 0 0 0 0 0 0 1 0 1\n",
            " 0 1 0 1 1 1 0 0 1 0 1 0 1 1 0 0 1 0 1 1 1 1 1 0 0 1 1 0 0 1 1 1 1 0 1 1 0\n",
            " 1 1 0 1 1 1 0 1 1 1 1 0 0 1 1 1 1 1 0 0 1 1 0 0 1 1 0 1 1 0 0 1 1 1 0 1 0\n",
            " 0 0 1 0 1 0 1 1 0 1 0 1 1 1 1 1 0 0 0 0 0 1 1 1 0 0 0 1 0 0 1 0 0 1 0 1 1\n",
            " 1 1 1 0 0 1 1 1 0 0 1 0 0 1 0 1 1 1 0 0]\n",
            "probabilities: (982, 2) \n",
            " [0 1 1 0 1 0 1 1 0 0 0 1 1 1 0 1 0 0 0 1 1 1 0 1 1 0 1 0 0 1 1 0 0 1 0 0 1\n",
            " 0 0 0 1 1 1 1 1 0 0 0 1 1 1 1 1 0 1 1 0 1 1 0 0 1 1 1 1 0 1 1 0 0 1 0 0 1\n",
            " 1 0 0 0 0 1 0 0 1 1 1 1 1 0 0 0 1 1 0 0 0 1 1 0 0 1 0 0 1 0 1 1 1 0 0 1 0\n",
            " 1 0 0 1 0 0 0 0 0 1 0 0 1 1 0 1 0 0 1 1 1 0 1 1 1 1 1 1 0 1 1 0 1 0 1 1 0\n",
            " 1 1 1 0 0 0 1 0 0 0 1 1 1 0 1 1 1 1 0 0 0 1 1 1 0 1 1 0 1 0 0 0 0 0 0 1 0\n",
            " 0 1 1 1 0 0 1 0 0 0 0 0 1 1 0 1 1 0 0 0 1 0 1 0 0 1 1 0 1 1 0 0 0 0 0 0 1\n",
            " 1 0 1 1 1 1 1 1 1 1 0 0 1 1 0 1 1 1 0 1 1 0 1 0 1 1 0 1 0 1 1 1 1 1 1 1 0\n",
            " 1 1 0 1 1 0 0 0 0 1 1 1 1 1 0 0 0 0 1 1 0 0 0 1 0 1 0 0 1 0 0 1 0 0 0 0 0\n",
            " 0 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 0 1 0 1 0 0 0 1 1 0 0 1 1 0 1 0 0 1 0\n",
            " 0 1 0 1 1 0 0 1 1 1 1 0 1 0 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 0\n",
            " 0 1 0 1 0 1 1 0 1 1 0 0 1 0 1 0 1 1 1 0 1 1 0 1 1 1 1 0 0 1 0 1 1 0 1 1 0\n",
            " 1 1 1 1 1 1 0 0 0 0 0 1 1 0 0 1 0 0 1 0 0 0 1 0 1 0 0 1 0 0 1 0 1 1 0 1 0\n",
            " 1 1 1 1 0 1 0 1 0 1 1 1 0 0 1 0 0 0 1 1 1 1 1 0 0 0 1 1 1 0 1 0 1 0 0 1 0\n",
            " 0 0 0 0 1 1 0 0 1 0 1 1 1 0 0 1 1 1 1 1 0 1 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1\n",
            " 0 0 1 1 0 0 1 0 1 0 1 0 1 0 0 0 0 1 0 1 0 1 0 1 1 0 1 1 0 1 0 1 1 1 1 0 1\n",
            " 1 1 0 1 1 1 1 1 1 1 0 0 0 1 0 1 1 1 1 1 0 1 1 0 0 0 0 0 1 0 0 1 0 0 1 0 1\n",
            " 1 0 1 1 1 0 0 1 1 1 0 1 0 0 0 0 1 0 0 1 0 1 1 0 1 1 0 0 0 0 1 1 1 0 1 1 0\n",
            " 1 1 1 0 1 0 1 1 0 0 0 1 1 0 1 1 1 1 0 0 1 1 0 0 1 1 1 1 0 1 0 0 1 0 0 1 1\n",
            " 1 1 1 0 1 1 1 0 1 0 1 0 1 0 0 1 0 1 0 0 0 1 0 0 1 0 1 0 0 0 0 1 0 1 1 0 0\n",
            " 1 0 0 1 1 1 0 1 0 0 1 0 1 0 0 1 1 1 1 1 0 0 1 0 0 1 1 1 0 1 1 1 0 0 1 0 1\n",
            " 0 0 1 0 0 0 0 0 1 0 1 0 0 1 0 0 1 0 1 1 1 0 0 0 1 1 0 0 1 0 1 0 1 1 0 1 0\n",
            " 0 1 1 0 1 1 0 0 0 1 0 0 1 0 1 1 1 1 0 1 0 0 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1\n",
            " 1 0 0 1 0 0 0 1 1 1 1 0 0 0 0 0 1 0 1 1 1 0 1 1 1 0 0 1 0 0 0 0 0 0 1 0 1\n",
            " 0 1 0 1 1 1 0 0 1 0 1 0 1 1 0 0 1 0 1 1 1 1 1 0 0 1 1 0 0 1 1 1 1 0 1 1 0\n",
            " 1 1 0 1 1 1 0 1 1 1 1 0 0 1 1 1 1 1 0 0 1 1 0 0 1 1 0 1 1 0 0 1 1 1 0 1 0\n",
            " 0 0 1 0 1 0 1 1 0 1 0 1 1 1 1 1 0 0 0 0 0 1 1 1 0 0 0 1 0 0 1 0 0 1 0 1 1\n",
            " 1 1 1 0 0 1 1 1 0 0 1 0 0 1 0 1 1 1 0 0]\n",
            "trainset before adding uncertain samples (320, 10) (320,)\n",
            "trainset after adding uncertain samples (330, 10) (330,)\n",
            "updated train set: (330, 10) (330,) unique(labels): [158 172] [0 1]\n",
            "val set: (972, 10) (972,)\n",
            "\n",
            "Train set: (330, 10)\n",
            "Validation set: (972, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 33\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.133 s \n",
            "\n",
            "Accuracy rate is 80.414747 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.88      0.87       321\n",
            "           1       0.63      0.58      0.61       113\n",
            "\n",
            "    accuracy                           0.80       434\n",
            "   macro avg       0.75      0.73      0.74       434\n",
            "weighted avg       0.80      0.80      0.80       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[283  38]\n",
            " [ 47  66]]\n",
            "--------------------------------\n",
            "val predicted: (972,) [0 1 1 0 1 0 1 1 0 0 0 1 1 1 0 1 0 0 0 1 1 1 0 1 1 0 1 0 0 1 1 0 0 1 0 0 1\n",
            " 0 0 0 1 1 1 1 1 0 0 0 1 1 1 1 1 0 1 1 0 1 1 0 0 1 1 1 1 0 1 1 0 0 1 0 0 1\n",
            " 1 0 0 0 0 1 0 0 1 1 1 1 1 0 0 0 1 1 0 0 0 1 1 0 0 1 0 0 1 0 1 1 1 0 0 1 0\n",
            " 1 0 0 1 0 0 0 0 0 1 0 0 1 1 0 1 0 0 1 1 1 0 1 1 1 1 1 1 0 1 1 0 1 0 1 1 0\n",
            " 1 1 1 0 0 0 1 0 0 0 1 1 1 0 1 1 1 1 0 0 0 1 1 1 0 1 1 0 1 0 0 0 0 0 0 1 0\n",
            " 0 1 1 1 0 0 1 0 0 0 0 0 1 1 0 1 1 0 0 0 1 0 1 0 0 1 1 0 1 1 0 0 0 0 0 0 1\n",
            " 1 0 1 1 1 1 1 1 1 1 0 0 1 1 0 1 1 1 0 1 1 0 1 0 1 1 0 1 0 1 1 1 1 1 1 1 0\n",
            " 1 1 0 1 1 0 0 0 0 1 1 1 1 1 0 0 0 0 1 1 0 0 1 0 1 0 0 1 0 0 1 0 0 0 0 0 0\n",
            " 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 0 1 0 1 0 0 0 1 1 0 0 1 1 0 1 0 0 1 0 0\n",
            " 1 0 1 1 0 0 1 1 1 1 0 1 0 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 0 0\n",
            " 1 0 1 0 1 1 0 1 1 0 0 1 0 1 0 1 1 1 0 1 1 0 1 1 1 1 0 1 0 1 1 0 1 1 0 1 1\n",
            " 1 1 1 1 0 0 0 0 0 1 1 0 1 0 0 1 0 0 1 0 1 0 0 1 0 0 1 1 1 0 1 0 1 1 1 1 0\n",
            " 1 0 1 0 1 1 1 0 0 1 0 0 0 1 1 1 1 1 0 0 0 1 1 1 0 1 0 1 0 0 1 0 0 0 0 0 1\n",
            " 1 0 0 1 0 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 0 0 1 1 0 0\n",
            " 1 0 1 0 1 0 1 0 0 0 0 1 0 1 0 1 0 1 1 0 1 1 0 1 0 1 1 1 1 0 1 1 1 0 1 1 1\n",
            " 1 1 1 1 0 0 0 1 0 1 1 1 1 1 0 1 1 0 0 0 0 0 1 0 0 1 0 0 1 0 1 1 0 1 1 1 0\n",
            " 0 1 1 1 0 1 0 0 0 0 1 0 0 1 0 1 1 0 1 1 0 0 0 0 1 1 1 0 1 1 0 1 1 1 0 1 0\n",
            " 1 1 0 0 0 1 1 0 1 1 1 1 0 0 1 1 0 0 1 1 1 1 0 1 0 0 1 0 0 1 1 1 1 1 0 1 1\n",
            " 1 0 1 0 1 0 1 0 0 1 0 1 0 0 1 0 0 1 0 1 0 0 0 0 1 0 1 1 0 1 0 0 1 1 1 0 1\n",
            " 0 0 1 0 1 0 0 1 1 1 1 1 0 0 1 0 0 1 1 1 0 1 1 1 0 0 1 0 1 0 0 1 0 0 0 0 0\n",
            " 1 0 1 0 0 1 0 0 1 0 1 1 1 0 0 0 1 1 0 0 1 0 1 0 1 1 0 1 0 0 1 1 0 1 1 0 0\n",
            " 0 1 0 0 1 0 1 1 1 1 0 1 0 0 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0 0 1\n",
            " 1 1 1 0 0 0 0 1 0 1 1 1 0 1 1 1 0 0 1 0 0 0 0 0 0 1 0 1 0 1 0 1 1 1 0 0 1\n",
            " 0 1 0 1 1 0 0 1 0 1 1 1 1 1 0 0 1 1 0 0 1 1 1 1 0 1 1 0 1 1 0 1 1 1 0 1 1\n",
            " 1 1 0 0 1 1 1 1 1 0 0 1 1 0 0 1 1 0 1 1 0 0 1 1 1 0 1 0 0 0 1 0 1 0 1 1 0\n",
            " 1 0 1 1 1 1 1 0 0 0 0 0 1 1 1 0 0 1 0 0 1 0 0 1 0 1 1 1 1 1 0 0 1 1 1 0 0\n",
            " 1 0 0 1 0 1 1 1 0 0]\n",
            "probabilities: (972, 2) \n",
            " [0 1 1 0 1 0 1 1 0 0 0 1 1 1 0 1 0 0 0 1 1 1 0 1 1 0 1 0 0 1 1 0 0 1 0 0 1\n",
            " 0 0 0 1 1 1 1 1 0 0 0 1 1 1 1 1 0 1 1 0 1 1 0 0 1 1 1 1 0 1 1 0 0 1 0 0 1\n",
            " 1 0 0 0 0 1 0 0 1 1 1 1 1 0 0 0 1 1 0 0 0 1 1 0 0 1 0 0 1 0 1 1 1 0 0 1 0\n",
            " 1 0 0 1 0 0 0 0 0 1 0 0 1 1 0 1 0 0 1 1 1 0 1 1 1 1 1 1 0 1 1 0 1 0 1 1 0\n",
            " 1 1 1 0 0 0 1 0 0 0 1 1 1 0 1 1 1 1 0 0 0 1 1 1 0 1 1 0 1 0 0 0 0 0 0 1 0\n",
            " 0 1 1 1 0 0 1 0 0 0 0 0 1 1 0 1 1 0 0 0 1 0 1 0 0 1 1 0 1 1 0 0 0 0 0 0 1\n",
            " 1 0 1 1 1 1 1 1 1 1 0 0 1 1 0 1 1 1 0 1 1 0 1 0 1 1 0 1 0 1 1 1 1 1 1 1 0\n",
            " 1 1 0 1 1 0 0 0 0 1 1 1 1 1 0 0 0 0 1 1 0 0 1 0 1 0 0 1 0 0 1 0 0 0 0 0 0\n",
            " 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 0 1 0 1 0 0 0 1 1 0 0 1 1 0 1 0 0 1 0 0\n",
            " 1 0 1 1 0 0 1 1 1 1 0 1 0 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 0 0\n",
            " 1 0 1 0 1 1 0 1 1 0 0 1 0 1 0 1 1 1 0 1 1 0 1 1 1 1 0 1 0 1 1 0 1 1 0 1 1\n",
            " 1 1 1 1 0 0 0 0 0 1 1 0 1 0 0 1 0 0 1 0 1 0 0 1 0 0 1 1 1 0 1 0 1 1 1 1 0\n",
            " 1 0 1 0 1 1 1 0 0 1 0 0 0 1 1 1 1 1 0 0 0 1 1 1 0 1 0 1 0 0 1 0 0 0 0 0 1\n",
            " 1 0 0 1 0 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 0 0 1 1 0 0\n",
            " 1 0 1 0 1 0 1 0 0 0 0 1 0 1 0 1 0 1 1 0 1 1 0 1 0 1 1 1 1 0 1 1 1 0 1 1 1\n",
            " 1 1 1 1 0 0 0 1 0 1 1 1 1 1 0 1 1 0 0 0 0 0 1 0 0 1 0 0 1 0 1 1 0 1 1 1 0\n",
            " 0 1 1 1 0 1 0 0 0 0 1 0 0 1 0 1 1 0 1 1 0 0 0 0 1 1 1 0 1 1 0 1 1 1 0 1 0\n",
            " 1 1 0 0 0 1 1 0 1 1 1 1 0 0 1 1 0 0 1 1 1 1 0 1 0 0 1 0 0 1 1 1 1 1 0 1 1\n",
            " 1 0 1 0 1 0 1 0 0 1 0 1 0 0 1 0 0 1 0 1 0 0 0 0 1 0 1 1 0 1 0 0 1 1 1 0 1\n",
            " 0 0 1 0 1 0 0 1 1 1 1 1 0 0 1 0 0 1 1 1 0 1 1 1 0 0 1 0 1 0 0 1 0 0 0 0 0\n",
            " 1 0 1 0 0 1 0 0 1 0 1 1 1 0 0 0 1 1 0 0 1 0 1 0 1 1 0 1 0 0 1 1 0 1 1 0 0\n",
            " 0 1 0 0 1 0 1 1 1 1 0 1 0 0 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0 0 1\n",
            " 1 1 1 0 0 0 0 1 0 1 1 1 0 1 1 1 0 0 1 0 0 0 0 0 0 1 0 1 0 1 0 1 1 1 0 0 1\n",
            " 0 1 0 1 1 0 0 1 0 1 1 1 1 1 0 0 1 1 0 0 1 1 1 1 0 1 1 0 1 1 0 1 1 1 0 1 1\n",
            " 1 1 0 0 1 1 1 1 1 0 0 1 1 0 0 1 1 0 1 1 0 0 1 1 1 0 1 0 0 0 1 0 1 0 1 1 0\n",
            " 1 0 1 1 1 1 1 0 0 0 0 0 1 1 1 0 0 1 0 0 1 0 0 1 0 1 1 1 1 1 0 0 1 1 1 0 0\n",
            " 1 0 0 1 0 1 1 1 0 0]\n",
            "trainset before adding uncertain samples (330, 10) (330,)\n",
            "trainset after adding uncertain samples (340, 10) (340,)\n",
            "updated train set: (340, 10) (340,) unique(labels): [164 176] [0 1]\n",
            "val set: (962, 10) (962,)\n",
            "\n",
            "Train set: (340, 10)\n",
            "Validation set: (962, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 34\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.162 s \n",
            "\n",
            "Accuracy rate is 81.105991 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.89      0.87       321\n",
            "           1       0.65      0.58      0.62       113\n",
            "\n",
            "    accuracy                           0.81       434\n",
            "   macro avg       0.76      0.74      0.75       434\n",
            "weighted avg       0.81      0.81      0.81       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[286  35]\n",
            " [ 47  66]]\n",
            "--------------------------------\n",
            "val predicted: (962,) [0 1 1 0 1 0 1 1 0 0 0 1 1 1 0 1 0 0 0 1 1 1 0 1 1 0 1 0 0 1 1 0 0 1 0 0 1\n",
            " 0 0 0 1 1 1 1 1 0 0 0 1 1 1 1 1 0 1 1 0 1 1 0 0 1 1 1 1 0 1 1 0 0 1 0 0 1\n",
            " 1 0 0 0 0 1 0 0 1 1 1 1 0 0 0 1 1 0 0 0 1 1 0 0 1 0 0 1 0 1 1 1 0 0 1 0 1\n",
            " 0 0 1 0 0 0 0 0 1 0 0 1 1 0 1 0 1 1 1 0 1 1 1 1 1 1 0 1 1 0 1 0 1 1 0 1 1\n",
            " 1 0 0 1 0 0 0 1 1 1 0 1 1 1 1 0 0 0 1 1 1 0 1 1 0 1 0 0 0 0 0 0 1 0 0 1 1\n",
            " 1 0 0 1 0 0 0 0 0 1 1 0 1 1 0 0 0 1 0 1 0 0 1 1 0 1 1 0 0 0 0 0 0 1 1 0 1\n",
            " 1 1 1 1 1 1 1 0 0 1 1 0 1 1 1 0 1 1 0 1 0 1 1 0 1 0 1 1 1 1 1 1 1 0 1 1 0\n",
            " 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 0 0 1 0 1 0 0 1 0 0 1 0 0 0 0 0 0 1 1 1 1\n",
            " 1 1 1 1 0 1 1 1 0 1 0 1 0 1 0 1 0 0 0 1 1 0 0 1 1 0 1 0 0 1 0 0 1 0 1 1 0\n",
            " 0 1 1 1 1 0 1 0 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 0 0 1 0 1 0 1\n",
            " 1 0 1 1 0 0 1 0 1 0 1 1 1 0 1 1 0 1 1 1 1 0 1 0 1 1 0 1 1 0 1 1 1 1 1 1 0\n",
            " 0 0 0 0 1 1 0 1 0 0 1 0 0 1 0 0 0 1 0 0 1 1 1 0 1 0 1 1 1 1 0 1 0 1 0 1 1\n",
            " 1 0 0 1 0 0 0 1 1 1 1 1 0 0 0 1 1 1 0 1 0 1 0 0 1 0 0 0 0 0 1 1 0 0 1 0 1\n",
            " 1 1 0 0 1 1 1 1 1 1 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 0 0 1 1 0 0 1 0 1 0 1 0\n",
            " 1 0 0 0 0 1 0 1 0 1 0 1 1 0 1 1 0 1 0 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0\n",
            " 0 1 0 1 1 1 1 1 1 1 0 0 0 0 0 1 0 0 1 0 0 1 0 1 1 0 1 1 0 0 1 1 0 1 0 0 0\n",
            " 0 1 0 0 1 0 1 1 0 1 1 0 0 0 0 1 1 1 0 1 1 0 1 1 1 0 1 0 1 1 0 0 0 1 1 0 1\n",
            " 1 1 1 0 0 1 1 0 0 1 1 1 1 0 1 0 0 1 0 0 1 1 1 1 1 0 1 1 1 0 1 0 1 0 1 0 0\n",
            " 1 0 1 0 0 1 0 0 1 0 1 0 0 0 1 0 1 1 0 1 0 0 1 1 1 0 1 0 0 1 0 1 0 0 1 1 1\n",
            " 1 1 0 0 1 0 0 1 1 1 0 1 1 1 0 0 1 0 1 0 0 1 0 0 0 0 0 1 0 1 0 0 1 0 0 1 0\n",
            " 1 1 1 0 0 0 1 1 0 0 1 0 1 0 1 1 0 1 0 0 1 1 0 1 1 0 0 0 1 0 0 1 0 1 1 1 1\n",
            " 0 1 0 0 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0 0 1 1 1 1 0 0 0 0 1 0 1\n",
            " 1 1 0 1 1 1 0 0 1 0 0 0 0 0 0 1 0 1 0 1 0 1 1 1 0 0 1 0 1 0 1 1 0 0 1 0 1\n",
            " 1 1 1 1 0 0 1 1 0 0 1 1 1 1 0 1 1 0 1 1 0 1 1 1 0 1 1 1 1 0 0 1 1 1 1 1 0\n",
            " 0 1 1 0 0 1 1 0 1 1 0 0 1 1 1 0 1 0 0 0 1 0 1 0 1 1 0 1 0 1 1 1 1 1 0 0 0\n",
            " 0 0 1 1 1 0 0 1 0 0 1 0 0 1 0 1 1 1 1 1 0 0 1 1 1 0 0 1 0 0 1 0 1 1 1 0 0]\n",
            "probabilities: (962, 2) \n",
            " [0 1 1 0 1 0 1 1 0 0 0 1 1 1 0 1 0 0 0 1 1 1 0 1 1 0 1 0 0 1 1 0 0 1 0 0 1\n",
            " 0 0 0 1 1 1 1 1 0 0 0 1 1 1 1 1 0 1 1 0 1 1 0 0 1 1 1 1 0 1 1 0 0 1 0 0 1\n",
            " 1 0 0 0 0 1 0 0 1 1 1 1 0 0 0 1 1 0 0 0 1 1 0 0 1 0 0 1 0 1 1 1 0 0 1 0 1\n",
            " 0 0 1 0 0 0 0 0 1 0 0 1 1 0 1 0 1 1 1 0 1 1 1 1 1 1 0 1 1 0 1 0 1 1 0 1 1\n",
            " 1 0 0 1 0 0 0 1 1 1 0 1 1 1 1 0 0 0 1 1 1 0 1 1 0 1 0 0 0 0 0 0 1 0 0 1 1\n",
            " 1 0 0 1 0 0 0 0 0 1 1 0 1 1 0 0 0 1 0 1 0 0 1 1 0 1 1 0 0 0 0 0 0 1 1 0 1\n",
            " 1 1 1 1 1 1 1 0 0 1 1 0 1 1 1 0 1 1 0 1 0 1 1 0 1 0 1 1 1 1 1 1 1 0 1 1 0\n",
            " 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 0 0 1 0 1 0 0 1 0 0 1 0 0 0 0 0 0 1 1 1 1\n",
            " 1 1 1 1 0 1 1 1 0 1 0 1 0 1 0 1 0 0 0 1 1 0 0 1 1 0 1 0 0 1 0 0 1 0 1 1 0\n",
            " 0 1 1 1 1 0 1 0 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 0 0 1 0 1 0 1\n",
            " 1 0 1 1 0 0 1 0 1 0 1 1 1 0 1 1 0 1 1 1 1 0 1 0 1 1 0 1 1 0 1 1 1 1 1 1 0\n",
            " 0 0 0 0 1 1 0 1 0 0 1 0 0 1 0 0 0 1 0 0 1 1 1 0 1 0 1 1 1 1 0 1 0 1 0 1 1\n",
            " 1 0 0 1 0 0 0 1 1 1 1 1 0 0 0 1 1 1 0 1 0 1 0 0 1 0 0 0 0 0 1 1 0 0 1 0 1\n",
            " 1 1 0 0 1 1 1 1 1 1 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 0 0 1 1 0 0 1 0 1 0 1 0\n",
            " 1 0 0 0 0 1 0 1 0 1 0 1 1 0 1 1 0 1 0 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0\n",
            " 0 1 0 1 1 1 1 1 1 1 0 0 0 0 0 1 0 0 1 0 0 1 0 1 1 0 1 1 0 0 1 1 0 1 0 0 0\n",
            " 0 1 0 0 1 0 1 1 0 1 1 0 0 0 0 1 1 1 0 1 1 0 1 1 1 0 1 0 1 1 0 0 0 1 1 0 1\n",
            " 1 1 1 0 0 1 1 0 0 1 1 1 1 0 1 0 0 1 0 0 1 1 1 1 1 0 1 1 1 0 1 0 1 0 1 0 0\n",
            " 1 0 1 0 0 1 0 0 1 0 1 0 0 0 1 0 1 1 0 1 0 0 1 1 1 0 1 0 0 1 0 1 0 0 1 1 1\n",
            " 1 1 0 0 1 0 0 1 1 1 0 1 1 1 0 0 1 0 1 0 0 1 0 0 0 0 0 1 0 1 0 0 1 0 0 1 0\n",
            " 1 1 1 0 0 0 1 1 0 0 1 0 1 0 1 1 0 1 0 0 1 1 0 1 1 0 0 0 1 0 0 1 0 1 1 1 1\n",
            " 0 1 0 0 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0 0 1 1 1 1 0 0 0 0 1 0 1\n",
            " 1 1 0 1 1 1 0 0 1 0 0 0 0 0 0 1 0 1 0 1 0 1 1 1 0 0 1 0 1 0 1 1 0 0 1 0 1\n",
            " 1 1 1 1 0 0 1 1 0 0 1 1 1 1 0 1 1 0 1 1 0 1 1 1 0 1 1 1 1 0 0 1 1 1 1 1 0\n",
            " 0 1 1 0 0 1 1 0 1 1 0 0 1 1 1 0 1 0 0 0 1 0 1 0 1 1 0 1 0 1 1 1 1 1 0 0 0\n",
            " 0 0 1 1 1 0 0 1 0 0 1 0 0 1 0 1 1 1 1 1 0 0 1 1 1 0 0 1 0 0 1 0 1 1 1 0 0]\n",
            "trainset before adding uncertain samples (340, 10) (340,)\n",
            "trainset after adding uncertain samples (350, 10) (350,)\n",
            "updated train set: (350, 10) (350,) unique(labels): [167 183] [0 1]\n",
            "val set: (952, 10) (952,)\n",
            "\n",
            "Train set: (350, 10)\n",
            "Validation set: (952, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 35\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.183 s \n",
            "\n",
            "Accuracy rate is 79.493088 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.87      0.86       321\n",
            "           1       0.61      0.58      0.59       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.73      0.72      0.73       434\n",
            "weighted avg       0.79      0.79      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[280  41]\n",
            " [ 48  65]]\n",
            "--------------------------------\n",
            "val predicted: (952,) [0 1 1 0 1 0 1 1 0 0 0 1 1 1 0 1 0 0 0 1 1 1 0 1 1 0 1 0 0 1 1 0 0 1 0 0 1\n",
            " 0 0 0 1 1 1 1 1 0 0 0 1 1 1 1 1 0 1 1 0 1 1 0 0 1 1 1 1 0 1 1 0 0 1 0 0 1\n",
            " 1 0 0 0 0 1 0 0 1 1 1 1 0 0 0 1 1 0 0 0 1 1 0 0 1 0 0 1 0 1 1 1 0 0 1 0 1\n",
            " 0 0 1 0 0 0 0 0 1 0 0 1 1 0 1 0 1 1 1 0 1 1 1 1 1 1 0 1 1 0 1 0 1 1 0 1 1\n",
            " 1 0 0 1 0 0 0 1 1 1 0 1 1 1 1 0 0 0 1 1 1 0 1 1 0 1 0 0 0 0 0 0 1 0 0 1 1\n",
            " 1 0 0 1 0 0 0 0 0 1 1 0 1 1 0 0 0 1 0 1 0 0 1 1 0 1 1 0 0 0 0 0 0 1 1 0 1\n",
            " 1 1 1 1 1 1 1 0 0 1 1 0 1 1 1 0 1 1 0 1 0 1 1 0 1 0 1 1 1 1 1 1 1 0 1 1 0\n",
            " 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 0 0 1 0 1 0 0 1 0 0 1 0 0 0 0 0 0 1 1 1 1\n",
            " 1 1 1 1 0 1 1 1 0 1 0 1 0 1 0 1 0 0 1 1 0 0 1 0 1 0 0 1 0 0 1 0 1 1 0 0 1\n",
            " 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 0 0 1 0 1 0 1 1 0 1\n",
            " 1 0 0 1 0 1 0 1 1 1 0 1 1 0 1 1 1 1 0 1 0 1 1 0 1 1 0 1 1 1 1 1 1 0 0 0 0\n",
            " 0 1 1 0 1 0 0 1 0 0 1 0 0 0 1 0 0 1 1 1 0 1 0 1 1 1 1 0 1 0 1 0 1 1 1 0 0\n",
            " 1 0 0 0 1 1 1 1 1 0 0 0 1 1 0 1 0 1 0 0 1 0 0 0 0 0 1 1 0 0 1 0 1 1 1 0 0\n",
            " 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 0 0 1 0 0 1 1 0 0 1 0 1 0 1 0 1 0 0 0 0\n",
            " 1 0 1 0 1 0 1 1 0 1 1 0 1 0 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0 0 1 0 1 1\n",
            " 1 1 1 1 1 0 0 0 0 0 1 0 0 1 0 1 0 1 1 0 1 1 0 0 1 1 0 1 0 0 0 0 1 0 0 1 0\n",
            " 1 1 0 1 1 0 0 0 0 1 1 1 0 1 1 0 1 1 1 0 1 0 1 1 0 0 0 1 1 0 1 1 1 1 0 0 1\n",
            " 1 0 0 1 1 1 1 0 1 0 0 1 0 0 1 1 1 1 1 0 1 1 1 0 1 0 1 0 1 0 0 1 0 1 0 0 1\n",
            " 0 0 1 0 1 0 0 0 1 0 1 1 0 1 0 0 1 1 1 0 1 0 0 1 0 1 0 0 1 1 1 1 1 0 0 1 0\n",
            " 0 1 1 1 0 1 1 1 0 0 1 0 1 0 0 1 0 0 0 0 0 1 0 1 0 0 1 0 0 1 0 1 1 1 0 0 0\n",
            " 1 1 0 0 1 0 1 0 1 1 0 1 0 0 1 1 0 1 1 0 0 0 1 0 0 1 0 1 1 1 1 0 1 0 0 1 0\n",
            " 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0 1 1 1 1 0 0 0 0 1 0 1 1 1 0 1 1 1 0\n",
            " 0 1 0 0 0 0 0 0 1 0 1 0 1 0 1 1 1 0 0 1 0 1 0 1 1 0 0 1 0 1 1 1 1 1 0 0 1\n",
            " 1 0 0 1 1 1 1 0 1 1 0 1 1 0 1 1 1 0 1 1 1 1 0 0 1 1 1 1 1 0 1 1 0 0 1 1 0\n",
            " 1 1 0 0 1 1 1 0 1 0 0 0 1 0 1 0 1 1 0 1 0 1 1 1 1 1 0 0 0 0 0 1 1 1 0 0 1\n",
            " 0 0 1 0 0 1 0 1 1 1 1 1 0 0 1 1 0 0 1 0 0 1 0 1 1 1 0]\n",
            "probabilities: (952, 2) \n",
            " [0 1 1 0 1 0 1 1 0 0 0 1 1 1 0 1 0 0 0 1 1 1 0 1 1 0 1 0 0 1 1 0 0 1 0 0 1\n",
            " 0 0 0 1 1 1 1 1 0 0 0 1 1 1 1 1 0 1 1 0 1 1 0 0 1 1 1 1 0 1 1 0 0 1 0 0 1\n",
            " 1 0 0 0 0 1 0 0 1 1 1 1 0 0 0 1 1 0 0 0 1 1 0 0 1 0 0 1 0 1 1 1 0 0 1 0 1\n",
            " 0 0 1 0 0 0 0 0 1 0 0 1 1 0 1 0 1 1 1 0 1 1 1 1 1 1 0 1 1 0 1 0 1 1 0 1 1\n",
            " 1 0 0 1 0 0 0 1 1 1 0 1 1 1 1 0 0 0 1 1 1 0 1 1 0 1 0 0 0 0 0 0 1 0 0 1 1\n",
            " 1 0 0 1 0 0 0 0 0 1 1 0 1 1 0 0 0 1 0 1 0 0 1 1 0 1 1 0 0 0 0 0 0 1 1 0 1\n",
            " 1 1 1 1 1 1 1 0 0 1 1 0 1 1 1 0 1 1 0 1 0 1 1 0 1 0 1 1 1 1 1 1 1 0 1 1 0\n",
            " 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 0 0 1 0 1 0 0 1 0 0 1 0 0 0 0 0 0 1 1 1 1\n",
            " 1 1 1 1 0 1 1 1 0 1 0 1 0 1 0 1 0 0 1 1 0 0 1 0 1 0 0 1 0 0 1 0 1 1 0 0 1\n",
            " 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 0 0 1 0 1 0 1 1 0 1\n",
            " 1 0 0 1 0 1 0 1 1 1 0 1 1 0 1 1 1 1 0 1 0 1 1 0 1 1 0 1 1 1 1 1 1 0 0 0 0\n",
            " 0 1 1 0 1 0 0 1 0 0 1 0 0 0 1 0 0 1 1 1 0 1 0 1 1 1 1 0 1 0 1 0 1 1 1 0 0\n",
            " 1 0 0 0 1 1 1 1 1 0 0 0 1 1 0 1 0 1 0 0 1 0 0 0 0 0 1 1 0 0 1 0 1 1 1 0 0\n",
            " 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 0 0 1 0 0 1 1 0 0 1 0 1 0 1 0 1 0 0 0 0\n",
            " 1 0 1 0 1 0 1 1 0 1 1 0 1 0 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0 0 1 0 1 1\n",
            " 1 1 1 1 1 0 0 0 0 0 1 0 0 1 0 1 0 1 1 0 1 1 0 0 1 1 0 1 0 0 0 0 1 0 0 1 0\n",
            " 1 1 0 1 1 0 0 0 0 1 1 1 0 1 1 0 1 1 1 0 1 0 1 1 0 0 0 1 1 0 1 1 1 1 0 0 1\n",
            " 1 0 0 1 1 1 1 0 1 0 0 1 0 0 1 1 1 1 1 0 1 1 1 0 1 0 1 0 1 0 0 1 0 1 0 0 1\n",
            " 0 0 1 0 1 0 0 0 1 0 1 1 0 1 0 0 1 1 1 0 1 0 0 1 0 1 0 0 1 1 1 1 1 0 0 1 0\n",
            " 0 1 1 1 0 1 1 1 0 0 1 0 1 0 0 1 0 0 0 0 0 1 0 1 0 0 1 0 0 1 0 1 1 1 0 0 0\n",
            " 1 1 0 0 1 0 1 0 1 1 0 1 0 0 1 1 0 1 1 0 0 0 1 0 0 1 0 1 1 1 1 0 1 0 0 1 0\n",
            " 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0 1 1 1 1 0 0 0 0 1 0 1 1 1 0 1 1 1 0\n",
            " 0 1 0 0 0 0 0 0 1 0 1 0 1 0 1 1 1 0 0 1 0 1 0 1 1 0 0 1 0 1 1 1 1 1 0 0 1\n",
            " 1 0 0 1 1 1 1 0 1 1 0 1 1 0 1 1 1 0 1 1 1 1 0 0 1 1 1 1 1 0 1 1 0 0 1 1 0\n",
            " 1 1 0 0 1 1 1 0 1 0 0 0 1 0 1 0 1 1 0 1 0 1 1 1 1 1 0 0 0 0 0 1 1 1 0 0 1\n",
            " 0 0 1 0 0 1 0 1 1 1 1 1 0 0 1 1 0 0 1 0 0 1 0 1 1 1 0]\n",
            "trainset before adding uncertain samples (350, 10) (350,)\n",
            "trainset after adding uncertain samples (360, 10) (360,)\n",
            "updated train set: (360, 10) (360,) unique(labels): [170 190] [0 1]\n",
            "val set: (942, 10) (942,)\n",
            "\n",
            "Train set: (360, 10)\n",
            "Validation set: (942, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 36\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.186 s \n",
            "\n",
            "Accuracy rate is 80.645161 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.88      0.87       321\n",
            "           1       0.64      0.60      0.62       113\n",
            "\n",
            "    accuracy                           0.81       434\n",
            "   macro avg       0.75      0.74      0.74       434\n",
            "weighted avg       0.80      0.81      0.80       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[282  39]\n",
            " [ 45  68]]\n",
            "--------------------------------\n",
            "val predicted: (942,) [1 1 0 1 0 1 1 0 0 0 1 1 1 0 1 0 0 0 1 1 1 0 1 1 0 1 0 0 1 1 0 0 1 0 0 1 0\n",
            " 0 0 1 1 1 1 1 0 0 0 1 1 1 1 1 0 1 1 0 1 1 0 0 1 1 1 1 0 1 1 0 0 1 0 0 1 1\n",
            " 0 0 0 0 1 0 0 1 1 1 1 0 0 0 1 1 0 0 0 1 1 0 0 1 0 0 1 0 1 1 1 0 0 1 0 1 0\n",
            " 0 1 0 0 0 0 0 1 0 0 1 1 0 1 0 1 1 1 0 1 1 1 1 1 1 0 1 1 0 1 0 1 1 0 1 1 1\n",
            " 0 0 1 0 0 0 1 1 1 0 1 1 1 1 0 0 0 1 1 0 1 1 0 1 0 0 0 0 0 0 1 0 0 1 1 1 0\n",
            " 0 1 0 0 0 0 0 1 1 0 1 1 0 0 0 1 0 1 0 0 1 1 0 1 1 0 0 0 0 0 0 1 0 1 1 1 1\n",
            " 1 1 1 1 0 0 1 1 0 1 1 1 0 1 1 0 1 0 1 1 0 1 0 1 1 1 1 1 1 1 0 1 1 0 1 1 0\n",
            " 0 0 0 1 1 1 1 0 0 0 0 1 1 0 0 1 0 1 0 0 1 0 0 1 0 0 0 0 0 0 1 1 1 1 1 1 1\n",
            " 1 0 1 1 1 0 1 0 1 0 1 0 1 0 0 1 1 0 0 1 0 1 0 0 1 0 0 1 0 1 1 0 0 1 1 1 1\n",
            " 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 0 0 1 0 1 0 1 1 0 1 1 0 0\n",
            " 1 0 1 0 1 1 1 0 1 1 0 1 1 1 1 0 1 0 1 1 0 1 1 0 1 1 1 1 1 1 0 0 0 0 0 1 1\n",
            " 0 1 0 0 1 0 0 1 0 0 0 1 0 0 1 1 1 0 1 1 1 1 1 0 1 0 1 0 1 1 1 0 0 1 0 0 0\n",
            " 1 1 1 1 1 0 0 0 1 1 0 1 0 1 0 0 1 0 0 0 0 0 1 1 0 0 1 0 1 1 1 0 0 1 1 1 1\n",
            " 1 1 1 1 1 1 0 1 1 0 0 1 1 0 0 1 0 1 1 0 0 1 0 1 0 1 0 1 0 0 0 0 1 0 1 0 1\n",
            " 0 1 1 0 1 1 0 1 0 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0 0 1 0 1 1 1 1 1 1 1\n",
            " 0 0 0 0 0 1 0 0 1 0 1 0 1 1 0 1 1 0 0 1 1 0 1 0 0 0 0 1 0 1 0 1 1 1 1 0 0\n",
            " 0 0 1 1 1 0 1 1 0 1 1 1 0 1 0 1 1 0 0 0 1 1 0 1 1 1 1 0 0 1 1 0 0 1 1 1 1\n",
            " 0 1 0 0 1 0 0 1 1 1 1 1 0 1 1 1 0 1 0 1 0 1 0 0 1 0 1 0 0 1 0 0 1 0 1 0 0\n",
            " 0 1 0 1 1 0 1 0 0 1 1 1 0 1 0 0 1 0 1 0 0 1 1 1 1 1 0 0 1 0 1 1 1 0 1 1 1\n",
            " 0 0 1 0 1 0 0 1 0 0 0 0 0 1 0 1 0 0 1 0 0 1 0 1 1 1 0 0 0 1 1 0 0 1 0 1 0\n",
            " 1 1 0 1 0 0 1 1 0 1 1 0 0 0 1 0 0 1 0 1 1 1 1 0 1 0 0 1 0 0 0 0 0 1 1 1 1\n",
            " 1 1 1 1 1 1 0 0 1 0 1 1 1 1 0 0 0 0 1 0 1 1 1 0 1 1 1 0 0 1 0 0 0 0 0 0 1\n",
            " 0 1 0 1 0 1 1 1 0 0 1 0 1 0 1 1 0 0 1 0 1 1 1 1 1 0 0 1 1 0 0 1 1 1 1 0 1\n",
            " 1 0 1 1 0 1 1 1 0 1 1 1 1 0 0 1 1 1 1 1 0 1 1 0 0 1 1 0 1 1 0 0 1 1 1 0 1\n",
            " 0 0 0 1 0 1 0 1 1 0 1 0 1 1 1 1 1 0 0 0 0 0 1 1 1 0 0 1 0 0 1 0 0 1 0 1 1\n",
            " 1 1 1 0 0 1 1 0 1 0 0 1 0 1 1 1 0]\n",
            "probabilities: (942, 2) \n",
            " [1 1 0 1 0 1 1 0 0 0 1 1 1 0 1 0 0 0 1 1 1 0 1 1 0 1 0 0 1 1 0 0 1 0 0 1 0\n",
            " 0 0 1 1 1 1 1 0 0 0 1 1 1 1 1 0 1 1 0 1 1 0 0 1 1 1 1 0 1 1 0 0 1 0 0 1 1\n",
            " 0 0 0 0 1 0 0 1 1 1 1 0 0 0 1 1 0 0 0 1 1 0 0 1 0 0 1 0 1 1 1 0 0 1 0 1 0\n",
            " 0 1 0 0 0 0 0 1 0 0 1 1 0 1 0 1 1 1 0 1 1 1 1 1 1 0 1 1 0 1 0 1 1 0 1 1 1\n",
            " 0 0 1 0 0 0 1 1 1 0 1 1 1 1 0 0 0 1 1 0 1 1 0 1 0 0 0 0 0 0 1 0 0 1 1 1 0\n",
            " 0 1 0 0 0 0 0 1 1 0 1 1 0 0 0 1 0 1 0 0 1 1 0 1 1 0 0 0 0 0 0 1 0 1 1 1 1\n",
            " 1 1 1 1 0 0 1 1 0 1 1 1 0 1 1 0 1 0 1 1 0 1 0 1 1 1 1 1 1 1 0 1 1 0 1 1 0\n",
            " 0 0 0 1 1 1 1 0 0 0 0 1 1 0 0 1 0 1 0 0 1 0 0 1 0 0 0 0 0 0 1 1 1 1 1 1 1\n",
            " 1 0 1 1 1 0 1 0 1 0 1 0 1 0 0 1 1 0 0 1 0 1 0 0 1 0 0 1 0 1 1 0 0 1 1 1 1\n",
            " 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 0 0 1 0 1 0 1 1 0 1 1 0 0\n",
            " 1 0 1 0 1 1 1 0 1 1 0 1 1 1 1 0 1 0 1 1 0 1 1 0 1 1 1 1 1 1 0 0 0 0 0 1 1\n",
            " 0 1 0 0 1 0 0 1 0 0 0 1 0 0 1 1 1 0 1 1 1 1 1 0 1 0 1 0 1 1 1 0 0 1 0 0 0\n",
            " 1 1 1 1 1 0 0 0 1 1 0 1 0 1 0 0 1 0 0 0 0 0 1 1 0 0 1 0 1 1 1 0 0 1 1 1 1\n",
            " 1 1 1 1 1 1 0 1 1 0 0 1 1 0 0 1 0 1 1 0 0 1 0 1 0 1 0 1 0 0 0 0 1 0 1 0 1\n",
            " 0 1 1 0 1 1 0 1 0 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0 0 1 0 1 1 1 1 1 1 1\n",
            " 0 0 0 0 0 1 0 0 1 0 1 0 1 1 0 1 1 0 0 1 1 0 1 0 0 0 0 1 0 1 0 1 1 1 1 0 0\n",
            " 0 0 1 1 1 0 1 1 0 1 1 1 0 1 0 1 1 0 0 0 1 1 0 1 1 1 1 0 0 1 1 0 0 1 1 1 1\n",
            " 0 1 0 0 1 0 0 1 1 1 1 1 0 1 1 1 0 1 0 1 0 1 0 0 1 0 1 0 0 1 0 0 1 0 1 0 0\n",
            " 0 1 0 1 1 0 1 0 0 1 1 1 0 1 0 0 1 0 1 0 0 1 1 1 1 1 0 0 1 0 1 1 1 0 1 1 1\n",
            " 0 0 1 0 1 0 0 1 0 0 0 0 0 1 0 1 0 0 1 0 0 1 0 1 1 1 0 0 0 1 1 0 0 1 0 1 0\n",
            " 1 1 0 1 0 0 1 1 0 1 1 0 0 0 1 0 0 1 0 1 1 1 1 0 1 0 0 1 0 0 0 0 0 1 1 1 1\n",
            " 1 1 1 1 1 1 0 0 1 0 1 1 1 1 0 0 0 0 1 0 1 1 1 0 1 1 1 0 0 1 0 0 0 0 0 0 1\n",
            " 0 1 0 1 0 1 1 1 0 0 1 0 1 0 1 1 0 0 1 0 1 1 1 1 1 0 0 1 1 0 0 1 1 1 1 0 1\n",
            " 1 0 1 1 0 1 1 1 0 1 1 1 1 0 0 1 1 1 1 1 0 1 1 0 0 1 1 0 1 1 0 0 1 1 1 0 1\n",
            " 0 0 0 1 0 1 0 1 1 0 1 0 1 1 1 1 1 0 0 0 0 0 1 1 1 0 0 1 0 0 1 0 0 1 0 1 1\n",
            " 1 1 1 0 0 1 1 0 1 0 0 1 0 1 1 1 0]\n",
            "trainset before adding uncertain samples (360, 10) (360,)\n",
            "trainset after adding uncertain samples (370, 10) (370,)\n",
            "updated train set: (370, 10) (370,) unique(labels): [175 195] [0 1]\n",
            "val set: (932, 10) (932,)\n",
            "\n",
            "Train set: (370, 10)\n",
            "Validation set: (932, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 37\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.189 s \n",
            "\n",
            "Accuracy rate is 80.875576 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.88      0.87       321\n",
            "           1       0.64      0.60      0.62       113\n",
            "\n",
            "    accuracy                           0.81       434\n",
            "   macro avg       0.75      0.74      0.75       434\n",
            "weighted avg       0.81      0.81      0.81       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[283  38]\n",
            " [ 45  68]]\n",
            "--------------------------------\n",
            "val predicted: (932,) [1 1 0 1 0 1 1 0 0 0 1 1 1 0 1 0 0 0 1 1 1 0 1 1 0 1 0 0 1 1 0 0 1 0 0 1 0\n",
            " 0 0 1 1 1 1 1 0 0 0 1 1 1 1 1 0 1 0 1 1 0 0 1 1 1 1 0 1 1 0 0 1 0 0 1 1 0\n",
            " 0 0 0 1 0 0 1 1 1 1 0 0 0 1 1 0 0 0 1 1 0 1 0 0 1 0 1 1 1 0 0 1 0 1 0 0 1\n",
            " 0 0 0 0 0 1 0 0 1 1 0 1 0 1 1 1 0 1 1 1 1 1 1 0 1 1 0 1 0 1 1 0 1 1 1 0 0\n",
            " 1 0 0 0 1 1 1 0 1 1 1 1 0 0 0 1 1 0 1 1 0 1 0 0 0 0 0 0 1 0 0 1 1 1 0 0 1\n",
            " 0 0 0 0 0 1 1 0 1 1 0 0 0 1 0 1 0 0 1 1 0 1 1 0 0 0 0 0 0 1 0 1 1 1 1 1 1\n",
            " 1 1 0 0 1 1 0 1 1 1 0 1 1 0 1 0 1 1 0 1 0 1 1 1 1 1 1 1 0 1 1 0 1 1 0 0 0\n",
            " 1 1 1 1 0 0 0 0 1 1 0 0 1 0 1 0 0 1 0 0 1 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 1\n",
            " 1 1 0 1 0 1 0 1 0 1 0 0 1 1 0 0 1 0 1 0 0 1 0 0 1 0 1 1 0 0 1 1 1 1 0 1 0\n",
            " 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 0 0 1 0 1 0 1 1 0 1 1 0 0 1 0 1\n",
            " 0 1 1 1 0 1 1 0 1 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 1 0 0 0 0 0 1 1 0 1 0 0\n",
            " 1 0 0 1 0 0 1 0 0 1 1 1 0 1 1 1 1 1 0 1 0 1 0 1 1 1 0 0 0 0 0 1 1 1 1 1 0\n",
            " 0 0 1 1 0 1 0 1 0 0 1 0 0 0 0 0 1 1 0 0 1 0 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1\n",
            " 0 1 1 0 0 1 1 0 0 1 0 1 1 0 0 1 1 0 1 0 1 0 0 0 0 1 0 1 0 1 0 1 1 0 1 1 0\n",
            " 1 0 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0 0 1 0 1 1 1 1 1 1 1 0 0 0 0 0 1 0\n",
            " 0 1 0 1 0 1 1 0 1 1 0 1 1 0 1 0 0 0 0 1 0 1 0 1 1 1 1 0 0 0 0 1 1 1 0 1 1\n",
            " 0 1 1 1 0 1 0 1 1 0 0 0 1 1 0 1 1 1 1 0 0 1 1 0 0 1 1 1 1 0 1 0 0 1 0 0 1\n",
            " 1 1 1 1 0 1 1 1 0 1 0 1 0 1 0 0 1 0 1 0 0 1 0 0 1 0 1 0 0 0 1 0 1 1 0 1 0\n",
            " 0 1 1 1 0 1 0 0 1 0 1 0 0 1 1 1 1 1 0 0 1 0 1 1 1 0 1 1 1 0 0 1 0 1 0 0 1\n",
            " 0 0 0 0 0 1 0 1 0 0 1 0 0 1 0 1 1 1 0 0 0 1 1 0 0 1 0 1 0 1 1 0 1 0 0 1 1\n",
            " 0 1 1 0 0 0 1 0 0 1 0 1 1 1 1 0 1 0 0 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 0\n",
            " 1 0 1 1 1 1 0 0 0 0 1 0 1 1 1 0 1 1 1 0 0 1 0 0 0 0 0 0 1 0 1 0 1 0 1 1 1\n",
            " 0 0 1 0 1 0 1 1 0 0 1 0 1 1 1 1 1 0 0 1 1 0 0 1 1 1 1 0 1 1 0 1 1 0 1 1 1\n",
            " 0 1 1 1 1 0 0 1 1 1 1 1 0 1 1 0 0 1 1 0 1 1 0 0 1 1 1 0 1 0 0 0 1 0 1 0 1\n",
            " 1 0 1 0 1 1 1 1 1 0 0 0 0 1 1 1 0 0 1 0 0 1 0 0 1 0 1 1 1 1 1 0 0 1 1 0 0\n",
            " 0 1 0 1 1 1 0]\n",
            "probabilities: (932, 2) \n",
            " [1 1 0 1 0 1 1 0 0 0 1 1 1 0 1 0 0 0 1 1 1 0 1 1 0 1 0 0 1 1 0 0 1 0 0 1 0\n",
            " 0 0 1 1 1 1 1 0 0 0 1 1 1 1 1 0 1 0 1 1 0 0 1 1 1 1 0 1 1 0 0 1 0 0 1 1 0\n",
            " 0 0 0 1 0 0 1 1 1 1 0 0 0 1 1 0 0 0 1 1 0 1 0 0 1 0 1 1 1 0 0 1 0 1 0 0 1\n",
            " 0 0 0 0 0 1 0 0 1 1 0 1 0 1 1 1 0 1 1 1 1 1 1 0 1 1 0 1 0 1 1 0 1 1 1 0 0\n",
            " 1 0 0 0 1 1 1 0 1 1 1 1 0 0 0 1 1 0 1 1 0 1 0 0 0 0 0 0 1 0 0 1 1 1 0 0 1\n",
            " 0 0 0 0 0 1 1 0 1 1 0 0 0 1 0 1 0 0 1 1 0 1 1 0 0 0 0 0 0 1 0 1 1 1 1 1 1\n",
            " 1 1 0 0 1 1 0 1 1 1 0 1 1 0 1 0 1 1 0 1 0 1 1 1 1 1 1 1 0 1 1 0 1 1 0 0 0\n",
            " 1 1 1 1 0 0 0 0 1 1 0 0 1 0 1 0 0 1 0 0 1 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 1\n",
            " 1 1 0 1 0 1 0 1 0 1 0 0 1 1 0 0 1 0 1 0 0 1 0 0 1 0 1 1 0 0 1 1 1 1 0 1 0\n",
            " 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 0 0 1 0 1 0 1 1 0 1 1 0 0 1 0 1\n",
            " 0 1 1 1 0 1 1 0 1 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 1 0 0 0 0 0 1 1 0 1 0 0\n",
            " 1 0 0 1 0 0 1 0 0 1 1 1 0 1 1 1 1 1 0 1 0 1 0 1 1 1 0 0 0 0 0 1 1 1 1 1 0\n",
            " 0 0 1 1 0 1 0 1 0 0 1 0 0 0 0 0 1 1 0 0 1 0 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1\n",
            " 0 1 1 0 0 1 1 0 0 1 0 1 1 0 0 1 1 0 1 0 1 0 0 0 0 1 0 1 0 1 0 1 1 0 1 1 0\n",
            " 1 0 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0 0 1 0 1 1 1 1 1 1 1 0 0 0 0 0 1 0\n",
            " 0 1 0 1 0 1 1 0 1 1 0 1 1 0 1 0 0 0 0 1 0 1 0 1 1 1 1 0 0 0 0 1 1 1 0 1 1\n",
            " 0 1 1 1 0 1 0 1 1 0 0 0 1 1 0 1 1 1 1 0 0 1 1 0 0 1 1 1 1 0 1 0 0 1 0 0 1\n",
            " 1 1 1 1 0 1 1 1 0 1 0 1 0 1 0 0 1 0 1 0 0 1 0 0 1 0 1 0 0 0 1 0 1 1 0 1 0\n",
            " 0 1 1 1 0 1 0 0 1 0 1 0 0 1 1 1 1 1 0 0 1 0 1 1 1 0 1 1 1 0 0 1 0 1 0 0 1\n",
            " 0 0 0 0 0 1 0 1 0 0 1 0 0 1 0 1 1 1 0 0 0 1 1 0 0 1 0 1 0 1 1 0 1 0 0 1 1\n",
            " 0 1 1 0 0 0 1 0 0 1 0 1 1 1 1 0 1 0 0 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 0\n",
            " 1 0 1 1 1 1 0 0 0 0 1 0 1 1 1 0 1 1 1 0 0 1 0 0 0 0 0 0 1 0 1 0 1 0 1 1 1\n",
            " 0 0 1 0 1 0 1 1 0 0 1 0 1 1 1 1 1 0 0 1 1 0 0 1 1 1 1 0 1 1 0 1 1 0 1 1 1\n",
            " 0 1 1 1 1 0 0 1 1 1 1 1 0 1 1 0 0 1 1 0 1 1 0 0 1 1 1 0 1 0 0 0 1 0 1 0 1\n",
            " 1 0 1 0 1 1 1 1 1 0 0 0 0 1 1 1 0 0 1 0 0 1 0 0 1 0 1 1 1 1 1 0 0 1 1 0 0\n",
            " 0 1 0 1 1 1 0]\n",
            "trainset before adding uncertain samples (370, 10) (370,)\n",
            "trainset after adding uncertain samples (380, 10) (380,)\n",
            "updated train set: (380, 10) (380,) unique(labels): [182 198] [0 1]\n",
            "val set: (922, 10) (922,)\n",
            "\n",
            "Train set: (380, 10)\n",
            "Validation set: (922, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 38\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.220 s \n",
            "\n",
            "Accuracy rate is 80.875576 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.88      0.87       321\n",
            "           1       0.64      0.60      0.62       113\n",
            "\n",
            "    accuracy                           0.81       434\n",
            "   macro avg       0.75      0.74      0.75       434\n",
            "weighted avg       0.81      0.81      0.81       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[283  38]\n",
            " [ 45  68]]\n",
            "--------------------------------\n",
            "val predicted: (922,) [1 1 0 1 0 1 1 0 0 0 1 1 1 0 1 0 0 0 1 1 1 0 1 1 0 1 0 0 1 1 0 0 1 0 1 0 0\n",
            " 0 1 1 1 1 1 0 0 1 1 1 1 1 0 1 0 1 1 0 0 1 1 1 1 0 1 1 0 0 1 0 1 1 0 0 0 0\n",
            " 1 0 0 1 1 1 1 0 0 0 1 1 0 0 0 1 1 0 1 0 0 1 0 1 1 1 0 0 1 0 1 0 0 1 0 0 0\n",
            " 0 1 0 0 1 1 0 1 0 1 1 1 0 1 1 1 1 1 1 0 1 1 0 1 0 1 1 0 1 1 1 0 0 1 0 0 0\n",
            " 1 1 1 0 1 1 1 1 0 0 0 1 1 0 1 1 0 1 0 0 0 0 0 0 1 0 0 1 1 1 0 0 1 0 0 0 0\n",
            " 0 1 1 0 1 1 0 0 0 1 0 1 0 0 1 1 0 1 1 0 0 0 0 0 0 1 0 1 1 1 1 1 1 1 1 0 0\n",
            " 1 1 0 1 1 1 0 1 1 0 1 0 1 1 0 1 0 1 1 1 1 1 1 1 0 1 1 0 1 1 0 0 0 1 1 1 1\n",
            " 0 0 0 0 1 1 0 0 1 0 1 0 0 1 0 0 1 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 1 1 1 0 1\n",
            " 0 1 0 1 0 1 0 0 1 1 0 0 1 0 1 0 0 1 0 0 1 0 1 1 0 0 1 1 1 1 0 1 0 0 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 1 0 1 0 1 1 0 1 1 0 0 1 0 1 0 1 1 1 0\n",
            " 1 1 0 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 1 0 0 0 0 0 1 1 0 1 0 0 1 0 0 1 0 0\n",
            " 1 0 0 1 1 1 0 1 1 1 1 1 0 1 0 1 0 1 1 1 0 0 0 0 0 1 1 1 1 1 0 0 0 1 1 0 1\n",
            " 0 1 0 0 1 0 0 0 0 0 1 1 0 0 1 0 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1\n",
            " 1 0 0 1 0 1 1 0 0 1 1 0 1 0 1 0 0 0 0 1 0 1 0 1 0 1 1 0 1 1 0 1 0 1 1 1 1\n",
            " 0 1 1 1 0 1 1 1 1 1 1 1 0 0 1 0 1 1 1 1 1 1 1 0 0 0 0 0 1 0 0 1 0 1 0 1 1\n",
            " 0 1 1 0 1 1 0 1 0 0 0 1 0 1 0 1 1 1 1 0 0 0 0 1 1 1 0 1 1 0 1 1 1 0 1 0 1\n",
            " 1 0 0 0 1 1 0 1 1 1 1 0 0 1 1 0 0 1 1 1 1 0 1 0 0 1 0 0 1 1 1 1 1 0 1 1 1\n",
            " 0 1 0 1 0 1 0 0 1 0 1 0 0 1 0 0 1 0 1 0 0 0 1 0 1 1 0 1 0 0 1 1 1 0 1 0 0\n",
            " 1 0 1 0 0 1 1 1 1 1 0 0 1 0 1 1 1 0 1 1 1 0 0 1 0 1 0 0 1 0 0 0 0 0 1 0 1\n",
            " 0 0 1 0 0 1 0 1 1 1 0 0 0 1 1 0 0 1 0 1 0 1 1 0 1 0 0 1 1 0 1 1 0 0 0 1 0\n",
            " 0 1 0 1 1 1 1 0 1 0 0 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1 1 0 0\n",
            " 0 1 0 1 1 1 0 1 1 1 0 0 1 0 0 0 0 0 0 1 0 1 0 1 0 1 1 1 0 0 1 0 1 0 1 1 0\n",
            " 0 1 0 1 1 1 1 1 0 0 1 1 0 0 1 1 1 1 0 1 1 0 1 1 0 1 1 1 0 1 1 1 1 0 0 1 1\n",
            " 1 1 1 0 1 1 0 0 1 1 0 1 1 0 0 1 1 1 0 1 0 0 0 1 0 1 0 1 1 1 0 1 1 1 1 1 0\n",
            " 0 0 0 1 1 1 0 0 1 0 0 1 0 0 1 0 1 1 1 1 1 0 0 1 1 0 0 0 1 0 1 1 1 0]\n",
            "probabilities: (922, 2) \n",
            " [1 1 0 1 0 1 1 0 0 0 1 1 1 0 1 0 0 0 1 1 1 0 1 1 0 1 0 0 1 1 0 0 1 0 1 0 0\n",
            " 0 1 1 1 1 1 0 0 1 1 1 1 1 0 1 0 1 1 0 0 1 1 1 1 0 1 1 0 0 1 0 1 1 0 0 0 0\n",
            " 1 0 0 1 1 1 1 0 0 0 1 1 0 0 0 1 1 0 1 0 0 1 0 1 1 1 0 0 1 0 1 0 0 1 0 0 0\n",
            " 0 1 0 0 1 1 0 1 0 1 1 1 0 1 1 1 1 1 1 0 1 1 0 1 0 1 1 0 1 1 1 0 0 1 0 0 0\n",
            " 1 1 1 0 1 1 1 1 0 0 0 1 1 0 1 1 0 1 0 0 0 0 0 0 1 0 0 1 1 1 0 0 1 0 0 0 0\n",
            " 0 1 1 0 1 1 0 0 0 1 0 1 0 0 1 1 0 1 1 0 0 0 0 0 0 1 0 1 1 1 1 1 1 1 1 0 0\n",
            " 1 1 0 1 1 1 0 1 1 0 1 0 1 1 0 1 0 1 1 1 1 1 1 1 0 1 1 0 1 1 0 0 0 1 1 1 1\n",
            " 0 0 0 0 1 1 0 0 1 0 1 0 0 1 0 0 1 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 1 1 1 0 1\n",
            " 0 1 0 1 0 1 0 0 1 1 0 0 1 0 1 0 0 1 0 0 1 0 1 1 0 0 1 1 1 1 0 1 0 0 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 1 0 1 0 1 1 0 1 1 0 0 1 0 1 0 1 1 1 0\n",
            " 1 1 0 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 1 0 0 0 0 0 1 1 0 1 0 0 1 0 0 1 0 0\n",
            " 1 0 0 1 1 1 0 1 1 1 1 1 0 1 0 1 0 1 1 1 0 0 0 0 0 1 1 1 1 1 0 0 0 1 1 0 1\n",
            " 0 1 0 0 1 0 0 0 0 0 1 1 0 0 1 0 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1\n",
            " 1 0 0 1 0 1 1 0 0 1 1 0 1 0 1 0 0 0 0 1 0 1 0 1 0 1 1 0 1 1 0 1 0 1 1 1 1\n",
            " 0 1 1 1 0 1 1 1 1 1 1 1 0 0 1 0 1 1 1 1 1 1 1 0 0 0 0 0 1 0 0 1 0 1 0 1 1\n",
            " 0 1 1 0 1 1 0 1 0 0 0 1 0 1 0 1 1 1 1 0 0 0 0 1 1 1 0 1 1 0 1 1 1 0 1 0 1\n",
            " 1 0 0 0 1 1 0 1 1 1 1 0 0 1 1 0 0 1 1 1 1 0 1 0 0 1 0 0 1 1 1 1 1 0 1 1 1\n",
            " 0 1 0 1 0 1 0 0 1 0 1 0 0 1 0 0 1 0 1 0 0 0 1 0 1 1 0 1 0 0 1 1 1 0 1 0 0\n",
            " 1 0 1 0 0 1 1 1 1 1 0 0 1 0 1 1 1 0 1 1 1 0 0 1 0 1 0 0 1 0 0 0 0 0 1 0 1\n",
            " 0 0 1 0 0 1 0 1 1 1 0 0 0 1 1 0 0 1 0 1 0 1 1 0 1 0 0 1 1 0 1 1 0 0 0 1 0\n",
            " 0 1 0 1 1 1 1 0 1 0 0 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1 1 0 0\n",
            " 0 1 0 1 1 1 0 1 1 1 0 0 1 0 0 0 0 0 0 1 0 1 0 1 0 1 1 1 0 0 1 0 1 0 1 1 0\n",
            " 0 1 0 1 1 1 1 1 0 0 1 1 0 0 1 1 1 1 0 1 1 0 1 1 0 1 1 1 0 1 1 1 1 0 0 1 1\n",
            " 1 1 1 0 1 1 0 0 1 1 0 1 1 0 0 1 1 1 0 1 0 0 0 1 0 1 0 1 1 1 0 1 1 1 1 1 0\n",
            " 0 0 0 1 1 1 0 0 1 0 0 1 0 0 1 0 1 1 1 1 1 0 0 1 1 0 0 0 1 0 1 1 1 0]\n",
            "trainset before adding uncertain samples (380, 10) (380,)\n",
            "trainset after adding uncertain samples (390, 10) (390,)\n",
            "updated train set: (390, 10) (390,) unique(labels): [185 205] [0 1]\n",
            "val set: (912, 10) (912,)\n",
            "\n",
            "Train set: (390, 10)\n",
            "Validation set: (912, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 39\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.234 s \n",
            "\n",
            "Accuracy rate is 79.493088 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.87      0.86       321\n",
            "           1       0.61      0.59      0.60       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.73      0.73      0.73       434\n",
            "weighted avg       0.79      0.79      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[278  43]\n",
            " [ 46  67]]\n",
            "--------------------------------\n",
            "val predicted: (912,) [1 1 0 1 0 1 1 0 0 0 1 1 1 0 1 0 0 0 1 1 1 0 1 1 0 1 0 0 1 1 0 0 1 1 0 0 0\n",
            " 1 1 1 1 1 0 0 1 1 1 1 1 0 1 0 1 1 0 0 1 1 1 1 0 1 1 0 0 1 0 1 1 0 0 0 0 1\n",
            " 0 0 1 1 1 1 0 0 0 1 1 0 0 0 1 1 0 1 0 0 1 0 1 1 1 0 0 1 0 1 0 0 1 0 0 0 0\n",
            " 1 0 0 1 1 0 1 0 1 1 1 0 1 1 1 1 1 1 0 1 1 0 1 0 1 1 0 1 1 1 0 0 1 0 0 0 1\n",
            " 1 1 0 1 1 1 1 0 0 0 1 1 0 1 1 0 1 0 0 0 0 0 0 1 0 0 1 1 1 0 0 1 0 0 0 0 0\n",
            " 1 1 0 1 1 0 0 0 1 0 1 0 0 1 1 0 1 1 0 0 0 0 0 0 1 0 1 1 1 1 1 1 1 1 0 0 1\n",
            " 1 0 1 1 1 0 1 1 0 1 0 1 1 0 1 0 1 1 1 1 1 1 0 1 1 0 1 1 0 0 0 1 1 1 1 0 0\n",
            " 0 0 1 1 0 0 1 0 1 0 0 1 0 0 1 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1\n",
            " 1 0 1 0 0 1 1 0 0 1 0 1 0 0 1 0 0 1 0 1 1 0 0 1 1 1 1 0 1 0 0 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 1 0 1 0 1 1 0 1 1 0 0 1 0 1 0 1 1 1 0 1 1 0\n",
            " 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 1 0 0 0 0 0 1 1 0 1 0 0 1 0 0 1 0 0 1 0 0\n",
            " 1 1 1 0 1 1 1 1 1 0 1 0 1 0 1 1 1 0 0 0 0 0 1 1 1 1 1 0 0 0 1 1 0 1 0 1 0\n",
            " 0 1 0 0 0 0 0 1 1 0 0 0 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 0 0 1\n",
            " 0 1 1 0 0 1 1 0 1 0 1 0 0 0 0 1 0 1 0 1 0 1 1 0 1 1 0 1 0 1 1 1 1 0 1 1 1\n",
            " 0 1 1 1 1 1 1 1 0 0 1 0 1 1 1 1 1 1 1 0 0 0 0 0 1 0 0 1 0 1 0 1 1 0 1 1 0\n",
            " 1 1 0 1 0 0 0 1 0 1 0 1 1 1 1 0 0 0 1 1 1 0 1 1 0 1 1 1 0 1 0 1 1 0 0 0 1\n",
            " 1 0 1 1 1 1 0 1 1 0 0 1 1 1 1 0 1 0 0 1 0 0 1 1 1 1 1 0 1 1 1 0 1 0 1 0 1\n",
            " 0 0 1 0 1 0 0 1 0 0 1 0 1 0 0 0 1 0 1 1 0 1 0 0 1 1 1 0 1 0 0 1 0 1 0 0 1\n",
            " 1 1 1 1 0 0 1 0 1 1 1 0 1 1 1 0 0 1 0 1 0 0 1 0 0 0 0 0 1 0 1 0 0 1 0 0 1\n",
            " 0 1 1 1 0 0 0 1 1 0 0 1 0 1 0 1 1 0 1 0 0 1 1 0 1 1 0 0 0 1 0 0 1 0 1 1 1\n",
            " 1 0 1 0 0 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1 1 0 0 0 1 0 1 1 1 0\n",
            " 1 1 1 0 0 1 0 0 0 0 0 0 1 0 1 0 1 0 1 1 1 0 0 1 0 1 0 1 1 0 0 1 0 1 1 1 1\n",
            " 1 0 0 1 1 0 0 1 1 1 1 0 1 1 0 1 1 0 1 1 1 0 1 1 1 1 0 0 1 1 1 1 1 0 1 1 0\n",
            " 0 1 1 0 1 1 0 0 1 1 1 0 1 0 0 0 1 0 1 0 1 1 1 0 1 1 1 1 1 0 0 0 1 1 0 0 1\n",
            " 0 0 1 0 0 1 0 1 1 1 1 1 0 1 1 0 0 0 1 0 1 1 1 0]\n",
            "probabilities: (912, 2) \n",
            " [1 1 0 1 0 1 1 0 0 0 1 1 1 0 1 0 0 0 1 1 1 0 1 1 0 1 0 0 1 1 0 0 1 1 0 0 0\n",
            " 1 1 1 1 1 0 0 1 1 1 1 1 0 1 0 1 1 0 0 1 1 1 1 0 1 1 0 0 1 0 1 1 0 0 0 0 1\n",
            " 0 0 1 1 1 1 0 0 0 1 1 0 0 0 1 1 0 1 0 0 1 0 1 1 1 0 0 1 0 1 0 0 1 0 0 0 0\n",
            " 1 0 0 1 1 0 1 0 1 1 1 0 1 1 1 1 1 1 0 1 1 0 1 0 1 1 0 1 1 1 0 0 1 0 0 0 1\n",
            " 1 1 0 1 1 1 1 0 0 0 1 1 0 1 1 0 1 0 0 0 0 0 0 1 0 0 1 1 1 0 0 1 0 0 0 0 0\n",
            " 1 1 0 1 1 0 0 0 1 0 1 0 0 1 1 0 1 1 0 0 0 0 0 0 1 0 1 1 1 1 1 1 1 1 0 0 1\n",
            " 1 0 1 1 1 0 1 1 0 1 0 1 1 0 1 0 1 1 1 1 1 1 0 1 1 0 1 1 0 0 0 1 1 1 1 0 0\n",
            " 0 0 1 1 0 0 1 0 1 0 0 1 0 0 1 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1\n",
            " 1 0 1 0 0 1 1 0 0 1 0 1 0 0 1 0 0 1 0 1 1 0 0 1 1 1 1 0 1 0 0 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 1 0 1 0 1 1 0 1 1 0 0 1 0 1 0 1 1 1 0 1 1 0\n",
            " 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 1 0 0 0 0 0 1 1 0 1 0 0 1 0 0 1 0 0 1 0 0\n",
            " 1 1 1 0 1 1 1 1 1 0 1 0 1 0 1 1 1 0 0 0 0 0 1 1 1 1 1 0 0 0 1 1 0 1 0 1 0\n",
            " 0 1 0 0 0 0 0 1 1 0 0 0 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 0 0 1\n",
            " 0 1 1 0 0 1 1 0 1 0 1 0 0 0 0 1 0 1 0 1 0 1 1 0 1 1 0 1 0 1 1 1 1 0 1 1 1\n",
            " 0 1 1 1 1 1 1 1 0 0 1 0 1 1 1 1 1 1 1 0 0 0 0 0 1 0 0 1 0 1 0 1 1 0 1 1 0\n",
            " 1 1 0 1 0 0 0 1 0 1 0 1 1 1 1 0 0 0 1 1 1 0 1 1 0 1 1 1 0 1 0 1 1 0 0 0 1\n",
            " 1 0 1 1 1 1 0 1 1 0 0 1 1 1 1 0 1 0 0 1 0 0 1 1 1 1 1 0 1 1 1 0 1 0 1 0 1\n",
            " 0 0 1 0 1 0 0 1 0 0 1 0 1 0 0 0 1 0 1 1 0 1 0 0 1 1 1 0 1 0 0 1 0 1 0 0 1\n",
            " 1 1 1 1 0 0 1 0 1 1 1 0 1 1 1 0 0 1 0 1 0 0 1 0 0 0 0 0 1 0 1 0 0 1 0 0 1\n",
            " 0 1 1 1 0 0 0 1 1 0 0 1 0 1 0 1 1 0 1 0 0 1 1 0 1 1 0 0 0 1 0 0 1 0 1 1 1\n",
            " 1 0 1 0 0 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1 1 0 0 0 1 0 1 1 1 0\n",
            " 1 1 1 0 0 1 0 0 0 0 0 0 1 0 1 0 1 0 1 1 1 0 0 1 0 1 0 1 1 0 0 1 0 1 1 1 1\n",
            " 1 0 0 1 1 0 0 1 1 1 1 0 1 1 0 1 1 0 1 1 1 0 1 1 1 1 0 0 1 1 1 1 1 0 1 1 0\n",
            " 0 1 1 0 1 1 0 0 1 1 1 0 1 0 0 0 1 0 1 0 1 1 1 0 1 1 1 1 1 0 0 0 1 1 0 0 1\n",
            " 0 0 1 0 0 1 0 1 1 1 1 1 0 1 1 0 0 0 1 0 1 1 1 0]\n",
            "trainset before adding uncertain samples (390, 10) (390,)\n",
            "trainset after adding uncertain samples (400, 10) (400,)\n",
            "updated train set: (400, 10) (400,) unique(labels): [192 208] [0 1]\n",
            "val set: (902, 10) (902,)\n",
            "\n",
            "Train set: (400, 10)\n",
            "Validation set: (902, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 40\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.227 s \n",
            "\n",
            "Accuracy rate is 80.184332 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.87      0.87       321\n",
            "           1       0.62      0.60      0.61       113\n",
            "\n",
            "    accuracy                           0.80       434\n",
            "   macro avg       0.74      0.74      0.74       434\n",
            "weighted avg       0.80      0.80      0.80       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[280  41]\n",
            " [ 45  68]]\n",
            "--------------------------------\n",
            "val predicted: (902,) [1 1 0 1 0 1 1 0 0 0 1 1 1 0 1 0 0 0 1 1 1 0 1 1 0 1 0 0 1 1 0 0 1 1 0 0 0\n",
            " 1 1 1 1 1 0 0 1 1 1 1 1 0 1 0 1 1 0 0 1 1 1 1 0 1 1 0 0 1 0 1 1 0 0 0 1 0\n",
            " 0 1 1 1 1 0 0 0 1 1 0 0 0 1 1 0 1 0 0 1 0 1 1 1 0 0 1 0 1 0 0 1 0 0 0 0 1\n",
            " 0 0 1 1 0 1 0 1 1 1 0 1 1 1 1 1 1 0 1 1 0 1 0 1 1 0 1 1 1 0 0 1 0 0 0 1 1\n",
            " 1 0 1 1 1 1 0 0 0 1 1 0 1 1 0 1 0 0 0 0 0 0 1 0 0 1 1 1 0 0 1 0 0 0 0 0 1\n",
            " 1 0 1 0 0 0 1 0 1 0 0 1 1 0 1 1 0 0 0 0 0 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 0\n",
            " 1 1 1 0 1 1 0 1 0 1 1 0 1 0 1 1 1 1 1 1 0 1 1 0 1 1 0 0 0 1 1 1 1 0 0 0 0\n",
            " 1 1 0 0 1 0 1 0 0 1 0 0 1 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 1 0\n",
            " 1 0 0 1 1 0 0 1 0 1 0 0 1 0 0 1 0 1 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 0 1 1 1 1 0 0 1 0 1 0 1 1 0 1 1 0 0 1 0 1 0 1 1 1 0 1 1 0 1 1 1\n",
            " 1 0 1 1 0 1 1 0 1 1 1 1 1 1 0 0 0 0 0 1 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 1 1\n",
            " 0 1 1 1 1 1 0 1 0 1 0 1 1 1 0 0 0 0 0 1 1 1 1 1 0 0 0 1 1 0 1 0 1 0 0 1 0\n",
            " 0 0 0 0 1 1 0 0 0 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 0 0 1 0 1 1\n",
            " 0 0 1 1 0 1 0 1 0 0 0 0 1 0 1 0 1 0 1 1 0 1 1 0 1 0 1 1 1 1 0 1 1 1 0 1 1\n",
            " 1 1 1 1 1 0 0 1 0 1 1 1 1 1 1 1 0 0 0 0 0 1 0 0 1 0 1 0 1 0 1 1 0 1 1 0 1\n",
            " 0 0 0 1 0 1 0 1 1 1 1 0 0 1 1 1 0 1 1 0 1 1 1 0 1 0 1 1 0 0 0 1 1 0 1 1 1\n",
            " 1 0 1 1 0 0 1 1 1 1 0 1 0 0 1 0 0 1 1 1 1 1 0 1 1 1 0 1 0 1 0 1 0 0 1 0 1\n",
            " 0 0 1 0 1 0 1 0 0 0 1 0 1 1 0 1 0 0 1 1 1 0 1 0 0 1 0 1 0 0 1 1 1 1 1 0 0\n",
            " 1 0 1 1 1 1 1 1 0 0 1 0 1 0 0 1 0 0 0 0 0 1 0 1 0 0 1 0 0 1 0 1 1 0 0 0 1\n",
            " 1 0 0 1 1 0 1 1 0 1 0 0 1 1 0 1 1 0 0 0 1 0 0 1 0 1 1 1 1 0 1 0 0 1 0 0 0\n",
            " 0 0 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1 1 0 0 0 1 0 1 1 1 0 1 1 1 0 0 1 0 0 0\n",
            " 0 0 0 1 0 1 0 1 0 1 1 1 0 0 1 0 1 0 1 1 0 0 1 0 1 1 1 1 1 0 0 1 1 0 0 1 1\n",
            " 1 1 0 1 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 0 0 1 1 0 1 1 0 0 1 1\n",
            " 1 0 1 0 0 0 1 0 1 0 1 1 1 0 1 1 1 1 1 0 0 0 1 1 0 0 1 0 0 1 0 0 1 0 1 1 1\n",
            " 1 1 0 1 1 0 0 0 1 0 1 1 1 0]\n",
            "probabilities: (902, 2) \n",
            " [1 1 0 1 0 1 1 0 0 0 1 1 1 0 1 0 0 0 1 1 1 0 1 1 0 1 0 0 1 1 0 0 1 1 0 0 0\n",
            " 1 1 1 1 1 0 0 1 1 1 1 1 0 1 0 1 1 0 0 1 1 1 1 0 1 1 0 0 1 0 1 1 0 0 0 1 0\n",
            " 0 1 1 1 1 0 0 0 1 1 0 0 0 1 1 0 1 0 0 1 0 1 1 1 0 0 1 0 1 0 0 1 0 0 0 0 1\n",
            " 0 0 1 1 0 1 0 1 1 1 0 1 1 1 1 1 1 0 1 1 0 1 0 1 1 0 1 1 1 0 0 1 0 0 0 1 1\n",
            " 1 0 1 1 1 1 0 0 0 1 1 0 1 1 0 1 0 0 0 0 0 0 1 0 0 1 1 1 0 0 1 0 0 0 0 0 1\n",
            " 1 0 1 0 0 0 1 0 1 0 0 1 1 0 1 1 0 0 0 0 0 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 0\n",
            " 1 1 1 0 1 1 0 1 0 1 1 0 1 0 1 1 1 1 1 1 0 1 1 0 1 1 0 0 0 1 1 1 1 0 0 0 0\n",
            " 1 1 0 0 1 0 1 0 0 1 0 0 1 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 1 0\n",
            " 1 0 0 1 1 0 0 1 0 1 0 0 1 0 0 1 0 1 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 0 1 1 1 1 0 0 1 0 1 0 1 1 0 1 1 0 0 1 0 1 0 1 1 1 0 1 1 0 1 1 1\n",
            " 1 0 1 1 0 1 1 0 1 1 1 1 1 1 0 0 0 0 0 1 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 1 1\n",
            " 0 1 1 1 1 1 0 1 0 1 0 1 1 1 0 0 0 0 0 1 1 1 1 1 0 0 0 1 1 0 1 0 1 0 0 1 0\n",
            " 0 0 0 0 1 1 0 0 0 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 0 0 1 0 1 1\n",
            " 0 0 1 1 0 1 0 1 0 0 0 0 1 0 1 0 1 0 1 1 0 1 1 0 1 0 1 1 1 1 0 1 1 1 0 1 1\n",
            " 1 1 1 1 1 0 0 1 0 1 1 1 1 1 1 1 0 0 0 0 0 1 0 0 1 0 1 0 1 0 1 1 0 1 1 0 1\n",
            " 0 0 0 1 0 1 0 1 1 1 1 0 0 1 1 1 0 1 1 0 1 1 1 0 1 0 1 1 0 0 0 1 1 0 1 1 1\n",
            " 1 0 1 1 0 0 1 1 1 1 0 1 0 0 1 0 0 1 1 1 1 1 0 1 1 1 0 1 0 1 0 1 0 0 1 0 1\n",
            " 0 0 1 0 1 0 1 0 0 0 1 0 1 1 0 1 0 0 1 1 1 0 1 0 0 1 0 1 0 0 1 1 1 1 1 0 0\n",
            " 1 0 1 1 1 1 1 1 0 0 1 0 1 0 0 1 0 0 0 0 0 1 0 1 0 0 1 0 0 1 0 1 1 0 0 0 1\n",
            " 1 0 0 1 1 0 1 1 0 1 0 0 1 1 0 1 1 0 0 0 1 0 0 1 0 1 1 1 1 0 1 0 0 1 0 0 0\n",
            " 0 0 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1 1 0 0 0 1 0 1 1 1 0 1 1 1 0 0 1 0 0 0\n",
            " 0 0 0 1 0 1 0 1 0 1 1 1 0 0 1 0 1 0 1 1 0 0 1 0 1 1 1 1 1 0 0 1 1 0 0 1 1\n",
            " 1 1 0 1 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 0 0 1 1 0 1 1 0 0 1 1\n",
            " 1 0 1 0 0 0 1 0 1 0 1 1 1 0 1 1 1 1 1 0 0 0 1 1 0 0 1 0 0 1 0 0 1 0 1 1 1\n",
            " 1 1 0 1 1 0 0 0 1 0 1 1 1 0]\n",
            "trainset before adding uncertain samples (400, 10) (400,)\n",
            "trainset after adding uncertain samples (410, 10) (410,)\n",
            "updated train set: (410, 10) (410,) unique(labels): [195 215] [0 1]\n",
            "val set: (892, 10) (892,)\n",
            "\n",
            "Train set: (410, 10)\n",
            "Validation set: (892, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 41\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.243 s \n",
            "\n",
            "Accuracy rate is 79.723502 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.87      0.86       321\n",
            "           1       0.61      0.59      0.60       113\n",
            "\n",
            "    accuracy                           0.80       434\n",
            "   macro avg       0.74      0.73      0.73       434\n",
            "weighted avg       0.79      0.80      0.80       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[279  42]\n",
            " [ 46  67]]\n",
            "--------------------------------\n",
            "val predicted: (892,) [1 1 0 1 0 1 1 0 0 1 1 1 0 1 0 0 0 1 1 1 0 1 1 0 1 0 0 1 1 0 0 1 1 0 0 0 1\n",
            " 1 1 1 1 0 0 1 1 1 1 1 0 1 0 1 0 0 1 1 1 1 0 1 1 0 0 1 0 1 1 0 0 0 1 0 0 1\n",
            " 1 1 1 0 0 0 1 1 0 0 0 1 1 0 1 0 0 1 0 1 1 1 0 0 1 0 1 0 0 1 0 0 0 0 1 0 0\n",
            " 1 1 0 1 0 1 1 0 1 1 1 1 1 1 0 1 1 0 1 0 1 1 0 1 1 1 0 0 1 0 0 0 1 1 1 0 1\n",
            " 1 1 1 0 0 0 1 1 0 1 1 0 1 0 0 0 0 0 0 1 0 0 1 1 1 0 0 1 0 0 0 0 0 1 1 0 1\n",
            " 0 0 0 1 0 1 0 0 1 1 0 1 1 0 0 0 0 0 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 0 1 1 1\n",
            " 0 1 1 0 1 0 1 1 0 1 0 1 1 1 1 1 1 0 1 1 0 1 1 0 0 0 1 1 1 1 0 0 0 0 1 1 0\n",
            " 0 1 0 1 0 0 1 0 0 1 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 1 0 1 0 0\n",
            " 1 1 0 0 1 0 1 0 0 1 0 0 1 0 1 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 0 1 1 1 1 0 0 1 0 1 0 1 1 0 1 1 0 0 1 0 1 0 1 1 1 0 1 1 0 1 1 1 1 0 1\n",
            " 1 0 1 1 0 1 1 1 1 1 1 0 0 0 0 0 1 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 1 1 0 1 1\n",
            " 1 1 1 0 1 0 1 0 1 1 1 0 0 0 0 0 1 1 1 1 1 0 0 0 1 1 0 1 0 1 0 0 1 0 0 0 0\n",
            " 0 1 1 0 0 0 1 1 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 0 0 1 0 1 1 0 0 1 1\n",
            " 0 1 0 1 0 0 0 0 1 0 1 0 1 0 1 1 0 1 1 0 1 0 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1\n",
            " 1 0 0 1 0 1 1 1 1 1 1 1 0 0 0 0 0 1 0 0 1 0 1 0 1 0 1 1 0 1 1 0 1 0 0 0 1\n",
            " 0 1 0 1 1 1 1 0 0 1 1 1 0 1 1 0 1 1 1 1 0 1 1 0 0 0 1 1 0 1 1 1 1 0 1 1 0\n",
            " 0 1 1 1 1 0 1 0 0 1 0 0 1 1 1 1 1 0 1 1 1 0 1 0 1 0 1 0 0 1 0 1 0 0 1 1 0\n",
            " 1 0 0 0 1 0 1 0 1 0 0 1 1 1 0 1 0 0 1 0 1 0 0 1 1 1 1 1 0 0 1 0 1 1 1 1 1\n",
            " 1 0 0 1 0 1 0 0 1 0 0 0 0 0 1 0 1 0 0 1 0 0 1 0 1 1 0 0 0 1 1 0 0 1 1 0 1\n",
            " 1 0 1 0 0 1 1 0 1 1 0 0 0 1 0 0 1 0 1 1 1 1 0 1 0 0 1 0 0 0 0 0 1 1 1 1 1\n",
            " 1 1 1 1 0 1 0 1 1 1 1 0 0 1 0 1 1 1 0 1 1 1 0 0 1 0 0 0 0 0 0 1 0 1 0 1 0\n",
            " 1 1 1 0 0 1 0 1 0 1 1 0 0 1 0 1 1 1 1 1 0 0 1 1 0 0 1 1 1 1 0 1 1 0 1 1 0\n",
            " 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 0 0 1 1 0 1 1 0 0 1 1 1 0 1 0 0 0 1 0 1\n",
            " 0 1 1 1 0 1 1 1 1 1 0 0 0 1 1 0 0 1 0 0 1 0 0 1 0 1 1 1 1 0 1 1 0 0 0 1 0\n",
            " 1 1 1 0]\n",
            "probabilities: (892, 2) \n",
            " [1 1 0 1 0 1 1 0 0 1 1 1 0 1 0 0 0 1 1 1 0 1 1 0 1 0 0 1 1 0 0 1 1 0 0 0 1\n",
            " 1 1 1 1 0 0 1 1 1 1 1 0 1 0 1 0 0 1 1 1 1 0 1 1 0 0 1 0 1 1 0 0 0 1 0 0 1\n",
            " 1 1 1 0 0 0 1 1 0 0 0 1 1 0 1 0 0 1 0 1 1 1 0 0 1 0 1 0 0 1 0 0 0 0 1 0 0\n",
            " 1 1 0 1 0 1 1 0 1 1 1 1 1 1 0 1 1 0 1 0 1 1 0 1 1 1 0 0 1 0 0 0 1 1 1 0 1\n",
            " 1 1 1 0 0 0 1 1 0 1 1 0 1 0 0 0 0 0 0 1 0 0 1 1 1 0 0 1 0 0 0 0 0 1 1 0 1\n",
            " 0 0 0 1 0 1 0 0 1 1 0 1 1 0 0 0 0 0 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 0 1 1 1\n",
            " 0 1 1 0 1 0 1 1 0 1 0 1 1 1 1 1 1 0 1 1 0 1 1 0 0 0 1 1 1 1 0 0 0 0 1 1 0\n",
            " 0 1 0 1 0 0 1 0 0 1 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 1 0 1 0 0\n",
            " 1 1 0 0 1 0 1 0 0 1 0 0 1 0 1 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 0 1 1 1 1 0 0 1 0 1 0 1 1 0 1 1 0 0 1 0 1 0 1 1 1 0 1 1 0 1 1 1 1 0 1\n",
            " 1 0 1 1 0 1 1 1 1 1 1 0 0 0 0 0 1 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 1 1 0 1 1\n",
            " 1 1 1 0 1 0 1 0 1 1 1 0 0 0 0 0 1 1 1 1 1 0 0 0 1 1 0 1 0 1 0 0 1 0 0 0 0\n",
            " 0 1 1 0 0 0 1 1 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 0 0 1 0 1 1 0 0 1 1\n",
            " 0 1 0 1 0 0 0 0 1 0 1 0 1 0 1 1 0 1 1 0 1 0 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1\n",
            " 1 0 0 1 0 1 1 1 1 1 1 1 0 0 0 0 0 1 0 0 1 0 1 0 1 0 1 1 0 1 1 0 1 0 0 0 1\n",
            " 0 1 0 1 1 1 1 0 0 1 1 1 0 1 1 0 1 1 1 1 0 1 1 0 0 0 1 1 0 1 1 1 1 0 1 1 0\n",
            " 0 1 1 1 1 0 1 0 0 1 0 0 1 1 1 1 1 0 1 1 1 0 1 0 1 0 1 0 0 1 0 1 0 0 1 1 0\n",
            " 1 0 0 0 1 0 1 0 1 0 0 1 1 1 0 1 0 0 1 0 1 0 0 1 1 1 1 1 0 0 1 0 1 1 1 1 1\n",
            " 1 0 0 1 0 1 0 0 1 0 0 0 0 0 1 0 1 0 0 1 0 0 1 0 1 1 0 0 0 1 1 0 0 1 1 0 1\n",
            " 1 0 1 0 0 1 1 0 1 1 0 0 0 1 0 0 1 0 1 1 1 1 0 1 0 0 1 0 0 0 0 0 1 1 1 1 1\n",
            " 1 1 1 1 0 1 0 1 1 1 1 0 0 1 0 1 1 1 0 1 1 1 0 0 1 0 0 0 0 0 0 1 0 1 0 1 0\n",
            " 1 1 1 0 0 1 0 1 0 1 1 0 0 1 0 1 1 1 1 1 0 0 1 1 0 0 1 1 1 1 0 1 1 0 1 1 0\n",
            " 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 0 0 1 1 0 1 1 0 0 1 1 1 0 1 0 0 0 1 0 1\n",
            " 0 1 1 1 0 1 1 1 1 1 0 0 0 1 1 0 0 1 0 0 1 0 0 1 0 1 1 1 1 0 1 1 0 0 0 1 0\n",
            " 1 1 1 0]\n",
            "trainset before adding uncertain samples (410, 10) (410,)\n",
            "trainset after adding uncertain samples (420, 10) (420,)\n",
            "updated train set: (420, 10) (420,) unique(labels): [200 220] [0 1]\n",
            "val set: (882, 10) (882,)\n",
            "\n",
            "Train set: (420, 10)\n",
            "Validation set: (882, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 42\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.272 s \n",
            "\n",
            "Accuracy rate is 79.953917 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.87      0.87       321\n",
            "           1       0.62      0.60      0.61       113\n",
            "\n",
            "    accuracy                           0.80       434\n",
            "   macro avg       0.74      0.74      0.74       434\n",
            "weighted avg       0.80      0.80      0.80       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[279  42]\n",
            " [ 45  68]]\n",
            "--------------------------------\n",
            "val predicted: (882,) [1 1 0 1 0 1 1 0 0 1 1 1 0 1 0 0 1 1 1 0 1 1 1 0 0 1 1 0 0 1 1 0 0 0 1 1 1\n",
            " 1 1 0 0 1 1 1 1 1 0 1 0 1 0 0 1 1 1 1 0 1 1 0 0 1 0 1 1 0 0 0 1 0 0 1 1 1\n",
            " 1 0 0 0 1 1 0 0 0 1 1 0 1 0 0 1 0 1 1 1 0 0 1 0 1 0 0 1 0 0 0 0 1 0 0 1 1\n",
            " 0 1 0 1 1 0 1 1 1 1 1 1 0 1 1 0 1 0 1 1 0 1 1 1 0 0 1 0 0 0 1 1 1 0 1 1 1\n",
            " 1 0 0 0 1 1 0 1 1 0 1 0 0 0 0 0 0 1 0 0 1 1 1 0 1 0 0 0 0 0 1 1 0 1 0 0 0\n",
            " 1 0 1 0 0 1 1 0 1 1 0 0 0 0 0 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 0 1 1 1 0 1 1\n",
            " 0 1 0 1 1 0 1 0 1 1 1 1 1 1 0 1 1 0 1 1 0 0 1 1 1 1 0 0 0 0 1 1 0 0 1 0 1\n",
            " 0 0 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 1 0 1 0 0 1 1 0 0 1\n",
            " 0 1 0 0 1 0 0 1 0 1 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1\n",
            " 1 1 0 0 1 0 1 0 1 1 0 1 1 0 0 1 0 1 0 1 1 1 0 1 1 0 1 1 1 1 0 1 1 0 1 1 0\n",
            " 1 1 1 1 1 1 0 0 0 0 0 1 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 1 1 0 1 1 1 1 1 0 1\n",
            " 0 1 0 1 1 1 0 0 0 0 0 1 1 1 1 1 0 0 0 1 1 1 0 1 0 0 1 0 0 0 0 0 1 1 0 0 0\n",
            " 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 0 0 1 0 1 1 0 0 1 1 0 1 0 1 0 0 0\n",
            " 0 1 0 1 0 1 0 1 1 0 1 1 0 1 0 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0 1 0 1 1\n",
            " 1 1 1 1 0 0 0 0 0 1 0 0 1 0 1 0 1 0 1 1 0 1 1 0 1 0 0 0 1 0 1 0 1 1 1 1 0\n",
            " 0 1 1 1 0 1 1 0 1 1 1 1 0 1 1 0 0 0 1 1 0 1 1 1 1 0 1 1 0 0 1 1 1 1 0 1 0\n",
            " 0 1 0 0 1 1 1 1 1 0 1 1 1 0 1 0 1 0 1 0 0 1 0 1 0 0 1 1 0 1 0 0 0 1 0 1 0\n",
            " 1 0 0 1 1 1 0 1 0 0 1 0 1 0 0 1 1 1 1 1 0 0 1 0 1 1 1 1 1 1 0 0 1 0 1 0 0\n",
            " 1 0 0 0 0 0 1 0 1 0 0 1 0 0 1 1 1 0 0 0 1 1 0 0 1 1 0 1 1 0 1 0 0 1 1 0 1\n",
            " 1 0 0 0 1 0 0 1 1 1 1 1 0 1 0 0 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1\n",
            " 1 0 0 1 0 1 1 1 0 1 1 1 0 0 1 0 0 0 0 0 0 1 0 1 0 1 0 1 1 1 0 0 1 0 1 0 1\n",
            " 1 0 0 1 0 1 1 1 1 1 0 0 1 1 0 0 1 1 1 1 0 1 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1\n",
            " 1 1 1 1 0 1 1 0 0 1 1 0 1 1 0 0 1 1 1 0 1 0 0 0 1 0 1 0 1 1 1 0 1 1 1 1 1\n",
            " 0 0 0 1 1 0 0 1 0 0 1 0 0 1 0 1 1 1 1 0 1 1 0 0 0 1 0 1 1 1 0]\n",
            "probabilities: (882, 2) \n",
            " [1 1 0 1 0 1 1 0 0 1 1 1 0 1 0 0 1 1 1 0 1 1 1 0 0 1 1 0 0 1 1 0 0 0 1 1 1\n",
            " 1 1 0 0 1 1 1 1 1 0 1 0 1 0 0 1 1 1 1 0 1 1 0 0 1 0 1 1 0 0 0 1 0 0 1 1 1\n",
            " 1 0 0 0 1 1 0 0 0 1 1 0 1 0 0 1 0 1 1 1 0 0 1 0 1 0 0 1 0 0 0 0 1 0 0 1 1\n",
            " 0 1 0 1 1 0 1 1 1 1 1 1 0 1 1 0 1 0 1 1 0 1 1 1 0 0 1 0 0 0 1 1 1 0 1 1 1\n",
            " 1 0 0 0 1 1 0 1 1 0 1 0 0 0 0 0 0 1 0 0 1 1 1 0 1 0 0 0 0 0 1 1 0 1 0 0 0\n",
            " 1 0 1 0 0 1 1 0 1 1 0 0 0 0 0 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 0 1 1 1 0 1 1\n",
            " 0 1 0 1 1 0 1 0 1 1 1 1 1 1 0 1 1 0 1 1 0 0 1 1 1 1 0 0 0 0 1 1 0 0 1 0 1\n",
            " 0 0 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 1 0 1 0 0 1 1 0 0 1\n",
            " 0 1 0 0 1 0 0 1 0 1 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1\n",
            " 1 1 0 0 1 0 1 0 1 1 0 1 1 0 0 1 0 1 0 1 1 1 0 1 1 0 1 1 1 1 0 1 1 0 1 1 0\n",
            " 1 1 1 1 1 1 0 0 0 0 0 1 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 1 1 0 1 1 1 1 1 0 1\n",
            " 0 1 0 1 1 1 0 0 0 0 0 1 1 1 1 1 0 0 0 1 1 1 0 1 0 0 1 0 0 0 0 0 1 1 0 0 0\n",
            " 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 0 0 1 0 1 1 0 0 1 1 0 1 0 1 0 0 0\n",
            " 0 1 0 1 0 1 0 1 1 0 1 1 0 1 0 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0 1 0 1 1\n",
            " 1 1 1 1 0 0 0 0 0 1 0 0 1 0 1 0 1 0 1 1 0 1 1 0 1 0 0 0 1 0 1 0 1 1 1 1 0\n",
            " 0 1 1 1 0 1 1 0 1 1 1 1 0 1 1 0 0 0 1 1 0 1 1 1 1 0 1 1 0 0 1 1 1 1 0 1 0\n",
            " 0 1 0 0 1 1 1 1 1 0 1 1 1 0 1 0 1 0 1 0 0 1 0 1 0 0 1 1 0 1 0 0 0 1 0 1 0\n",
            " 1 0 0 1 1 1 0 1 0 0 1 0 1 0 0 1 1 1 1 1 0 0 1 0 1 1 1 1 1 1 0 0 1 0 1 0 0\n",
            " 1 0 0 0 0 0 1 0 1 0 0 1 0 0 1 1 1 0 0 0 1 1 0 0 1 1 0 1 1 0 1 0 0 1 1 0 1\n",
            " 1 0 0 0 1 0 0 1 1 1 1 1 0 1 0 0 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1\n",
            " 1 0 0 1 0 1 1 1 0 1 1 1 0 0 1 0 0 0 0 0 0 1 0 1 0 1 0 1 1 1 0 0 1 0 1 0 1\n",
            " 1 0 0 1 0 1 1 1 1 1 0 0 1 1 0 0 1 1 1 1 0 1 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1\n",
            " 1 1 1 1 0 1 1 0 0 1 1 0 1 1 0 0 1 1 1 0 1 0 0 0 1 0 1 0 1 1 1 0 1 1 1 1 1\n",
            " 0 0 0 1 1 0 0 1 0 0 1 0 0 1 0 1 1 1 1 0 1 1 0 0 0 1 0 1 1 1 0]\n",
            "trainset before adding uncertain samples (420, 10) (420,)\n",
            "trainset after adding uncertain samples (430, 10) (430,)\n",
            "updated train set: (430, 10) (430,) unique(labels): [206 224] [0 1]\n",
            "val set: (872, 10) (872,)\n",
            "\n",
            "Train set: (430, 10)\n",
            "Validation set: (872, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 43\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.268 s \n",
            "\n",
            "Accuracy rate is 78.801843 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.86      0.86       321\n",
            "           1       0.59      0.59      0.59       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.72      0.72      0.72       434\n",
            "weighted avg       0.79      0.79      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[275  46]\n",
            " [ 46  67]]\n",
            "--------------------------------\n",
            "val predicted: (872,) [1 1 0 1 0 1 1 0 0 1 1 1 0 1 0 0 1 1 1 0 1 1 1 0 0 1 1 0 0 1 1 0 0 0 1 1 1\n",
            " 1 1 0 0 1 1 1 1 1 0 1 0 1 0 0 1 1 1 1 0 1 1 0 0 1 0 1 1 0 0 0 1 0 0 1 1 1\n",
            " 1 0 0 0 1 1 0 0 0 1 1 0 1 0 0 1 0 1 1 1 0 0 1 0 1 0 0 1 0 0 0 0 1 0 1 1 0\n",
            " 1 0 1 1 0 1 1 1 1 1 1 0 1 1 0 1 0 1 1 0 1 1 1 0 0 1 0 0 0 1 1 1 0 1 1 1 1\n",
            " 0 0 0 1 1 0 1 1 0 1 0 0 0 0 0 0 0 0 1 1 1 0 1 0 0 0 0 0 1 1 0 1 0 0 0 1 0\n",
            " 1 0 0 1 1 0 1 1 0 0 0 0 0 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 0 1 1 1 0 1 1 0 1\n",
            " 0 1 1 0 1 0 1 1 1 1 1 1 0 1 1 0 1 1 0 0 1 1 1 1 0 0 0 0 1 1 0 0 1 0 1 0 0\n",
            " 1 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 1 0 1 0 0 1 1 0 0 1 0 1 0\n",
            " 0 1 0 0 1 0 1 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0\n",
            " 1 0 1 0 1 1 0 1 1 0 0 1 0 1 0 1 1 1 0 1 1 0 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1\n",
            " 1 1 0 0 0 0 0 1 1 0 1 0 1 0 0 1 0 0 1 0 0 1 1 1 0 1 1 1 1 1 1 0 1 0 1 1 1\n",
            " 0 0 0 0 0 1 1 1 1 1 0 0 0 1 1 1 0 1 0 0 1 0 0 0 0 0 1 1 0 0 0 1 1 0 0 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 0 0 1 1 0 0 1 0 1 1 0 0 1 1 0 1 0 1 0 0 0 0 1 0 1 0 1\n",
            " 0 1 1 0 1 1 0 1 0 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0 1 0 1 1 1 1 1 1 0 0\n",
            " 0 0 0 1 0 0 1 0 1 0 1 0 1 1 0 1 1 0 1 0 0 0 1 0 1 0 1 1 1 1 0 0 1 1 1 0 1\n",
            " 1 0 1 1 1 1 0 1 1 0 0 0 1 1 0 1 1 1 1 0 1 1 0 0 1 1 1 1 0 1 0 0 1 0 0 1 1\n",
            " 1 1 1 0 1 1 1 0 1 0 1 0 1 0 0 1 0 1 0 0 1 1 0 1 0 0 0 1 0 1 0 1 0 0 1 1 1\n",
            " 0 1 0 0 1 0 1 0 1 1 1 1 1 0 0 1 0 1 1 1 1 1 0 0 1 0 1 0 0 1 0 0 0 0 1 0 1\n",
            " 0 0 1 0 0 1 1 1 0 0 0 1 1 0 0 1 1 0 1 1 0 1 0 0 1 0 1 1 0 0 0 1 0 0 1 1 1\n",
            " 1 1 0 1 0 0 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 0 0 1 0 1 1 1 0 1\n",
            " 1 1 0 0 1 0 0 0 0 0 0 1 0 1 0 1 0 1 1 1 0 0 1 0 1 0 1 1 0 0 1 0 1 1 1 1 1\n",
            " 0 0 1 1 0 0 1 1 1 1 0 1 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 0 0 1\n",
            " 1 0 1 1 0 0 1 1 1 0 1 0 0 0 1 0 1 0 1 1 1 0 1 1 1 1 1 0 0 0 1 1 0 0 1 0 0\n",
            " 1 0 0 1 0 1 1 1 1 0 1 1 0 0 0 1 0 1 1 1 0]\n",
            "probabilities: (872, 2) \n",
            " [1 1 0 1 0 1 1 0 0 1 1 1 0 1 0 0 1 1 1 0 1 1 1 0 0 1 1 0 0 1 1 0 0 0 1 1 1\n",
            " 1 1 0 0 1 1 1 1 1 0 1 0 1 0 0 1 1 1 1 0 1 1 0 0 1 0 1 1 0 0 0 1 0 0 1 1 1\n",
            " 1 0 0 0 1 1 0 0 0 1 1 0 1 0 0 1 0 1 1 1 0 0 1 0 1 0 0 1 0 0 0 0 1 0 1 1 0\n",
            " 1 0 1 1 0 1 1 1 1 1 1 0 1 1 0 1 0 1 1 0 1 1 1 0 0 1 0 0 0 1 1 1 0 1 1 1 1\n",
            " 0 0 0 1 1 0 1 1 0 1 0 0 0 0 0 0 0 0 1 1 1 0 1 0 0 0 0 0 1 1 0 1 0 0 0 1 0\n",
            " 1 0 0 1 1 0 1 1 0 0 0 0 0 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 0 1 1 1 0 1 1 0 1\n",
            " 0 1 1 0 1 0 1 1 1 1 1 1 0 1 1 0 1 1 0 0 1 1 1 1 0 0 0 0 1 1 0 0 1 0 1 0 0\n",
            " 1 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 1 0 1 0 0 1 1 0 0 1 0 1 0\n",
            " 0 1 0 0 1 0 1 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0\n",
            " 1 0 1 0 1 1 0 1 1 0 0 1 0 1 0 1 1 1 0 1 1 0 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1\n",
            " 1 1 0 0 0 0 0 1 1 0 1 0 1 0 0 1 0 0 1 0 0 1 1 1 0 1 1 1 1 1 1 0 1 0 1 1 1\n",
            " 0 0 0 0 0 1 1 1 1 1 0 0 0 1 1 1 0 1 0 0 1 0 0 0 0 0 1 1 0 0 0 1 1 0 0 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 0 0 1 1 0 0 1 0 1 1 0 0 1 1 0 1 0 1 0 0 0 0 1 0 1 0 1\n",
            " 0 1 1 0 1 1 0 1 0 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0 1 0 1 1 1 1 1 1 0 0\n",
            " 0 0 0 1 0 0 1 0 1 0 1 0 1 1 0 1 1 0 1 0 0 0 1 0 1 0 1 1 1 1 0 0 1 1 1 0 1\n",
            " 1 0 1 1 1 1 0 1 1 0 0 0 1 1 0 1 1 1 1 0 1 1 0 0 1 1 1 1 0 1 0 0 1 0 0 1 1\n",
            " 1 1 1 0 1 1 1 0 1 0 1 0 1 0 0 1 0 1 0 0 1 1 0 1 0 0 0 1 0 1 0 1 0 0 1 1 1\n",
            " 0 1 0 0 1 0 1 0 1 1 1 1 1 0 0 1 0 1 1 1 1 1 0 0 1 0 1 0 0 1 0 0 0 0 1 0 1\n",
            " 0 0 1 0 0 1 1 1 0 0 0 1 1 0 0 1 1 0 1 1 0 1 0 0 1 0 1 1 0 0 0 1 0 0 1 1 1\n",
            " 1 1 0 1 0 0 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 0 0 1 0 1 1 1 0 1\n",
            " 1 1 0 0 1 0 0 0 0 0 0 1 0 1 0 1 0 1 1 1 0 0 1 0 1 0 1 1 0 0 1 0 1 1 1 1 1\n",
            " 0 0 1 1 0 0 1 1 1 1 0 1 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 0 0 1\n",
            " 1 0 1 1 0 0 1 1 1 0 1 0 0 0 1 0 1 0 1 1 1 0 1 1 1 1 1 0 0 0 1 1 0 0 1 0 0\n",
            " 1 0 0 1 0 1 1 1 1 0 1 1 0 0 0 1 0 1 1 1 0]\n",
            "trainset before adding uncertain samples (430, 10) (430,)\n",
            "trainset after adding uncertain samples (440, 10) (440,)\n",
            "updated train set: (440, 10) (440,) unique(labels): [212 228] [0 1]\n",
            "val set: (862, 10) (862,)\n",
            "\n",
            "Train set: (440, 10)\n",
            "Validation set: (862, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 44\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.278 s \n",
            "\n",
            "Accuracy rate is 79.723502 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.86      0.86       321\n",
            "           1       0.61      0.61      0.61       113\n",
            "\n",
            "    accuracy                           0.80       434\n",
            "   macro avg       0.74      0.74      0.74       434\n",
            "weighted avg       0.80      0.80      0.80       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[277  44]\n",
            " [ 44  69]]\n",
            "--------------------------------\n",
            "val predicted: (862,) [1 1 0 1 0 1 1 0 0 1 1 1 0 1 0 0 1 1 1 0 1 1 1 0 0 1 1 0 0 1 0 0 0 1 1 1 1\n",
            " 1 0 0 1 1 1 1 1 0 1 0 1 0 0 1 1 1 1 0 1 1 0 0 1 0 1 1 0 0 0 1 0 0 1 1 1 1\n",
            " 0 0 0 1 1 0 0 0 1 1 0 1 0 0 1 0 1 1 1 0 0 1 0 1 0 0 1 0 0 0 0 1 0 1 1 0 1\n",
            " 0 1 1 0 1 1 1 1 1 1 0 1 1 0 1 0 1 1 0 1 1 1 0 0 1 0 0 0 1 1 1 0 1 1 1 1 0\n",
            " 0 0 1 1 0 1 1 0 1 0 0 0 0 0 0 0 1 1 1 0 1 0 0 0 0 0 1 1 0 1 0 0 0 1 0 1 0\n",
            " 1 1 0 1 1 0 0 0 0 0 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 0 1 1 1 0 1 1 0 1 0 1 1\n",
            " 0 1 0 1 1 1 1 1 1 0 1 1 0 1 1 0 0 1 1 1 1 0 0 0 0 1 1 0 0 1 0 1 0 0 1 0 0\n",
            " 0 0 0 0 0 1 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 1 0 1 0 0 1 1 0 0 1 0 1 0 0 1 0\n",
            " 0 1 0 1 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 1 0 1\n",
            " 0 1 1 0 1 1 0 0 1 0 1 0 1 1 1 0 1 1 0 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 0 0\n",
            " 0 0 0 1 1 0 1 0 1 0 0 1 0 0 1 0 0 1 1 0 1 1 1 1 1 1 0 1 0 1 1 1 0 0 0 0 0\n",
            " 1 1 1 1 1 0 0 0 1 1 1 0 1 0 0 1 0 0 0 0 0 1 1 0 0 1 1 0 0 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 0 0 1 1 0 0 1 0 1 1 0 0 1 1 0 1 0 1 0 0 0 0 1 0 1 0 1 0 1 1 0 1 1\n",
            " 0 1 0 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0 1 0 1 1 1 1 1 0 0 0 0 0 1 0 0 1\n",
            " 0 1 0 1 0 1 1 0 1 1 0 1 0 0 0 1 0 1 0 1 1 1 1 0 0 1 1 1 0 1 1 0 1 1 1 1 0\n",
            " 1 1 0 0 0 1 1 0 1 1 1 1 0 1 1 0 0 1 1 1 1 0 1 0 0 1 0 0 1 1 1 1 1 0 1 1 1\n",
            " 0 1 0 1 0 1 0 0 1 0 1 0 0 1 1 0 1 0 0 0 1 0 1 0 1 0 0 1 1 1 0 1 0 0 1 0 1\n",
            " 0 1 1 1 1 1 0 0 1 0 1 1 1 1 1 0 0 1 0 1 0 1 0 0 0 0 1 0 1 0 0 1 0 0 1 1 1\n",
            " 0 0 0 1 1 0 0 1 1 0 1 1 0 1 0 0 1 0 1 1 0 0 0 1 0 0 1 1 1 1 1 0 1 0 0 1 0\n",
            " 0 0 0 0 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 0 0 1 0 1 1 1 0 1 1 1 0 0 1 0 0 0\n",
            " 0 0 0 1 0 1 0 1 0 1 1 1 0 0 1 1 0 1 1 0 0 1 0 1 1 1 1 1 0 0 1 1 0 0 1 1 1\n",
            " 1 0 1 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 0 0 1 1 0 1 1 0 0 1 1 1\n",
            " 1 0 0 0 1 0 1 0 1 1 1 0 1 1 1 1 1 0 0 0 1 1 0 0 1 0 0 1 0 0 1 0 1 1 1 1 0\n",
            " 1 1 0 0 0 1 0 1 1 1 0]\n",
            "probabilities: (862, 2) \n",
            " [1 1 0 1 0 1 1 0 0 1 1 1 0 1 0 0 1 1 1 0 1 1 1 0 0 1 1 0 0 1 0 0 0 1 1 1 1\n",
            " 1 0 0 1 1 1 1 1 0 1 0 1 0 0 1 1 1 1 0 1 1 0 0 1 0 1 1 0 0 0 1 0 0 1 1 1 1\n",
            " 0 0 0 1 1 0 0 0 1 1 0 1 0 0 1 0 1 1 1 0 0 1 0 1 0 0 1 0 0 0 0 1 0 1 1 0 1\n",
            " 0 1 1 0 1 1 1 1 1 1 0 1 1 0 1 0 1 1 0 1 1 1 0 0 1 0 0 0 1 1 1 0 1 1 1 1 0\n",
            " 0 0 1 1 0 1 1 0 1 0 0 0 0 0 0 0 1 1 1 0 1 0 0 0 0 0 1 1 0 1 0 0 0 1 0 1 0\n",
            " 1 1 0 1 1 0 0 0 0 0 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 0 1 1 1 0 1 1 0 1 0 1 1\n",
            " 0 1 0 1 1 1 1 1 1 0 1 1 0 1 1 0 0 1 1 1 1 0 0 0 0 1 1 0 0 1 0 1 0 0 1 0 0\n",
            " 0 0 0 0 0 1 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 1 0 1 0 0 1 1 0 0 1 0 1 0 0 1 0\n",
            " 0 1 0 1 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 1 0 1\n",
            " 0 1 1 0 1 1 0 0 1 0 1 0 1 1 1 0 1 1 0 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 0 0\n",
            " 0 0 0 1 1 0 1 0 1 0 0 1 0 0 1 0 0 1 1 0 1 1 1 1 1 1 0 1 0 1 1 1 0 0 0 0 0\n",
            " 1 1 1 1 1 0 0 0 1 1 1 0 1 0 0 1 0 0 0 0 0 1 1 0 0 1 1 0 0 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 0 0 1 1 0 0 1 0 1 1 0 0 1 1 0 1 0 1 0 0 0 0 1 0 1 0 1 0 1 1 0 1 1\n",
            " 0 1 0 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0 1 0 1 1 1 1 1 0 0 0 0 0 1 0 0 1\n",
            " 0 1 0 1 0 1 1 0 1 1 0 1 0 0 0 1 0 1 0 1 1 1 1 0 0 1 1 1 0 1 1 0 1 1 1 1 0\n",
            " 1 1 0 0 0 1 1 0 1 1 1 1 0 1 1 0 0 1 1 1 1 0 1 0 0 1 0 0 1 1 1 1 1 0 1 1 1\n",
            " 0 1 0 1 0 1 0 0 1 0 1 0 0 1 1 0 1 0 0 0 1 0 1 0 1 0 0 1 1 1 0 1 0 0 1 0 1\n",
            " 0 1 1 1 1 1 0 0 1 0 1 1 1 1 1 0 0 1 0 1 0 1 0 0 0 0 1 0 1 0 0 1 0 0 1 1 1\n",
            " 0 0 0 1 1 0 0 1 1 0 1 1 0 1 0 0 1 0 1 1 0 0 0 1 0 0 1 1 1 1 1 0 1 0 0 1 0\n",
            " 0 0 0 0 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 0 0 1 0 1 1 1 0 1 1 1 0 0 1 0 0 0\n",
            " 0 0 0 1 0 1 0 1 0 1 1 1 0 0 1 1 0 1 1 0 0 1 0 1 1 1 1 1 0 0 1 1 0 0 1 1 1\n",
            " 1 0 1 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 0 0 1 1 0 1 1 0 0 1 1 1\n",
            " 1 0 0 0 1 0 1 0 1 1 1 0 1 1 1 1 1 0 0 0 1 1 0 0 1 0 0 1 0 0 1 0 1 1 1 1 0\n",
            " 1 1 0 0 0 1 0 1 1 1 0]\n",
            "trainset before adding uncertain samples (440, 10) (440,)\n",
            "trainset after adding uncertain samples (450, 10) (450,)\n",
            "updated train set: (450, 10) (450,) unique(labels): [218 232] [0 1]\n",
            "val set: (852, 10) (852,)\n",
            "\n",
            "Train set: (450, 10)\n",
            "Validation set: (852, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 45\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.291 s \n",
            "\n",
            "Accuracy rate is 79.493088 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.86      0.86       321\n",
            "           1       0.61      0.61      0.61       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.73      0.74      0.73       434\n",
            "weighted avg       0.80      0.79      0.80       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[276  45]\n",
            " [ 44  69]]\n",
            "--------------------------------\n",
            "val predicted: (852,) [1 1 0 1 0 1 1 0 1 1 1 0 1 0 0 1 1 1 0 1 1 1 0 0 1 1 0 0 1 0 0 0 1 1 1 1 1\n",
            " 0 0 1 1 1 1 1 0 1 0 1 0 0 1 1 1 1 0 1 1 0 0 1 0 1 1 0 0 0 1 0 0 1 1 1 1 0\n",
            " 0 0 1 1 0 0 0 1 1 0 1 0 0 1 0 1 1 1 0 0 1 0 1 0 0 1 0 0 0 0 1 0 1 1 0 1 0\n",
            " 1 1 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 1 1 0 0 1 0 0 0 1 1 1 0 1 1 1 1 0 0 0\n",
            " 1 1 0 1 1 0 1 0 0 0 0 0 0 0 1 1 1 0 1 0 0 0 0 0 1 1 0 1 0 0 0 1 0 1 0 1 1\n",
            " 0 1 1 0 0 0 0 0 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 0 1 1 1 0 1 1 0 1 0 1 1 0 1\n",
            " 0 1 1 1 1 1 1 0 1 1 0 1 1 0 0 1 1 1 1 0 0 0 0 1 1 0 0 1 0 1 0 0 1 0 0 0 0\n",
            " 0 0 0 1 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 1 0 1 0 0 1 1 0 0 1 0 1 0 1 0 0 1 0\n",
            " 1 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 1 0 1 0 1 1\n",
            " 0 1 1 0 0 1 0 1 0 1 1 1 0 1 1 0 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 0 0 0 0 0\n",
            " 1 1 0 1 0 1 0 0 1 0 0 1 0 0 1 1 0 1 1 1 1 1 1 0 1 0 1 1 1 0 0 0 0 0 1 1 1\n",
            " 1 1 0 0 0 1 1 1 0 1 0 1 0 0 0 0 0 1 1 0 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0\n",
            " 0 1 1 0 0 1 0 1 1 0 0 1 1 0 1 0 1 0 0 0 1 1 0 1 0 1 1 0 1 1 0 1 0 1 1 1 1\n",
            " 0 1 1 1 0 1 1 1 1 1 1 1 0 0 1 0 1 1 1 1 1 0 0 0 0 0 1 0 0 1 0 1 0 1 0 1 1\n",
            " 0 1 1 0 1 0 0 0 1 0 1 0 1 1 1 1 0 0 1 1 1 0 1 1 0 1 1 1 1 0 1 1 0 0 0 1 1\n",
            " 0 1 1 1 1 0 1 1 0 0 1 1 1 1 0 1 0 0 1 0 0 1 1 1 1 1 0 1 1 1 0 1 1 0 1 0 0\n",
            " 1 0 1 0 0 1 1 0 1 0 0 0 1 0 1 0 1 0 0 1 1 1 0 1 0 0 1 0 1 0 1 1 1 1 1 0 0\n",
            " 1 0 1 1 1 1 0 0 1 0 1 0 1 0 0 0 0 1 0 1 0 0 1 0 0 1 1 1 0 0 0 1 1 0 0 1 1\n",
            " 0 1 1 0 1 0 0 1 0 1 1 0 0 0 1 0 0 1 1 1 1 1 0 1 0 0 1 0 0 0 0 0 1 1 1 1 1\n",
            " 1 1 1 1 0 1 0 1 1 1 1 0 0 1 0 1 1 1 0 1 1 1 0 0 1 0 0 0 0 0 0 1 0 1 0 1 0\n",
            " 1 1 1 0 0 1 1 0 1 1 0 0 1 0 1 1 1 1 1 0 0 1 1 0 0 1 1 1 1 0 1 1 0 1 1 0 1\n",
            " 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 0 0 1 1 0 1 1 0 0 1 1 1 1 0 0 0 1 0 1 0 1\n",
            " 1 1 0 1 1 1 1 1 0 0 0 1 1 0 0 1 0 0 1 0 0 1 0 1 1 1 0 1 1 0 0 0 1 0 1 1 1\n",
            " 0]\n",
            "probabilities: (852, 2) \n",
            " [1 1 0 1 0 1 1 0 1 1 1 0 1 0 0 1 1 1 0 1 1 1 0 0 1 1 0 0 1 0 0 0 1 1 1 1 1\n",
            " 0 0 1 1 1 1 1 0 1 0 1 0 0 1 1 1 1 0 1 1 0 0 1 0 1 1 0 0 0 1 0 0 1 1 1 1 0\n",
            " 0 0 1 1 0 0 0 1 1 0 1 0 0 1 0 1 1 1 0 0 1 0 1 0 0 1 0 0 0 0 1 0 1 1 0 1 0\n",
            " 1 1 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 1 1 0 0 1 0 0 0 1 1 1 0 1 1 1 1 0 0 0\n",
            " 1 1 0 1 1 0 1 0 0 0 0 0 0 0 1 1 1 0 1 0 0 0 0 0 1 1 0 1 0 0 0 1 0 1 0 1 1\n",
            " 0 1 1 0 0 0 0 0 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 0 1 1 1 0 1 1 0 1 0 1 1 0 1\n",
            " 0 1 1 1 1 1 1 0 1 1 0 1 1 0 0 1 1 1 1 0 0 0 0 1 1 0 0 1 0 1 0 0 1 0 0 0 0\n",
            " 0 0 0 1 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 1 0 1 0 0 1 1 0 0 1 0 1 0 1 0 0 1 0\n",
            " 1 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 1 0 1 0 1 1\n",
            " 0 1 1 0 0 1 0 1 0 1 1 1 0 1 1 0 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 0 0 0 0 0\n",
            " 1 1 0 1 0 1 0 0 1 0 0 1 0 0 1 1 0 1 1 1 1 1 1 0 1 0 1 1 1 0 0 0 0 0 1 1 1\n",
            " 1 1 0 0 0 1 1 1 0 1 0 1 0 0 0 0 0 1 1 0 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0\n",
            " 0 1 1 0 0 1 0 1 1 0 0 1 1 0 1 0 1 0 0 0 1 1 0 1 0 1 1 0 1 1 0 1 0 1 1 1 1\n",
            " 0 1 1 1 0 1 1 1 1 1 1 1 0 0 1 0 1 1 1 1 1 0 0 0 0 0 1 0 0 1 0 1 0 1 0 1 1\n",
            " 0 1 1 0 1 0 0 0 1 0 1 0 1 1 1 1 0 0 1 1 1 0 1 1 0 1 1 1 1 0 1 1 0 0 0 1 1\n",
            " 0 1 1 1 1 0 1 1 0 0 1 1 1 1 0 1 0 0 1 0 0 1 1 1 1 1 0 1 1 1 0 1 1 0 1 0 0\n",
            " 1 0 1 0 0 1 1 0 1 0 0 0 1 0 1 0 1 0 0 1 1 1 0 1 0 0 1 0 1 0 1 1 1 1 1 0 0\n",
            " 1 0 1 1 1 1 0 0 1 0 1 0 1 0 0 0 0 1 0 1 0 0 1 0 0 1 1 1 0 0 0 1 1 0 0 1 1\n",
            " 0 1 1 0 1 0 0 1 0 1 1 0 0 0 1 0 0 1 1 1 1 1 0 1 0 0 1 0 0 0 0 0 1 1 1 1 1\n",
            " 1 1 1 1 0 1 0 1 1 1 1 0 0 1 0 1 1 1 0 1 1 1 0 0 1 0 0 0 0 0 0 1 0 1 0 1 0\n",
            " 1 1 1 0 0 1 1 0 1 1 0 0 1 0 1 1 1 1 1 0 0 1 1 0 0 1 1 1 1 0 1 1 0 1 1 0 1\n",
            " 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 0 0 1 1 0 1 1 0 0 1 1 1 1 0 0 0 1 0 1 0 1\n",
            " 1 1 0 1 1 1 1 1 0 0 0 1 1 0 0 1 0 0 1 0 0 1 0 1 1 1 0 1 1 0 0 0 1 0 1 1 1\n",
            " 0]\n",
            "trainset before adding uncertain samples (450, 10) (450,)\n",
            "trainset after adding uncertain samples (460, 10) (460,)\n",
            "updated train set: (460, 10) (460,) unique(labels): [225 235] [0 1]\n",
            "val set: (842, 10) (842,)\n",
            "\n",
            "Train set: (460, 10)\n",
            "Validation set: (842, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 46\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.461 s \n",
            "\n",
            "Accuracy rate is 80.414747 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.88      0.87       321\n",
            "           1       0.63      0.59      0.61       113\n",
            "\n",
            "    accuracy                           0.80       434\n",
            "   macro avg       0.75      0.74      0.74       434\n",
            "weighted avg       0.80      0.80      0.80       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[282  39]\n",
            " [ 46  67]]\n",
            "--------------------------------\n",
            "val predicted: (842,) [1 1 0 1 0 1 1 0 1 1 1 0 1 0 0 1 1 1 0 1 1 1 0 0 1 1 0 0 1 0 0 0 1 1 1 1 1\n",
            " 0 0 1 1 1 1 1 0 1 0 1 0 0 1 1 1 1 0 1 1 0 0 1 0 1 1 0 0 1 0 0 1 1 1 1 0 0\n",
            " 0 1 1 0 0 0 1 1 0 1 0 0 1 0 1 1 1 0 0 1 0 1 0 0 1 0 0 0 0 1 0 1 1 0 0 1 1\n",
            " 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 1 1 0 0 1 0 0 0 1 1 1 0 1 1 1 1 0 0 0 1 1\n",
            " 0 1 1 0 1 0 0 0 0 0 0 0 1 1 1 0 1 0 0 0 0 0 1 1 0 1 0 0 0 1 0 1 0 1 1 0 1\n",
            " 1 0 0 0 0 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 0 1 1 1 0 1 1 0 1 0 1 1 0 1 0 1 1\n",
            " 1 1 1 1 0 1 1 0 1 1 0 0 1 1 1 1 0 0 0 0 1 1 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0\n",
            " 1 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 1 0 1 0 0 1 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0\n",
            " 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 1 0 1 0 1 1 0 1 1 0\n",
            " 0 1 0 1 0 1 1 1 0 1 1 0 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 0 0 0 0 0 1 1 0 1\n",
            " 0 1 0 0 1 0 1 0 0 1 1 0 1 1 1 1 1 1 0 1 0 1 1 1 0 0 0 0 1 1 1 1 1 0 0 0 1\n",
            " 1 1 0 1 0 1 0 0 0 0 0 1 1 0 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 0 0 1\n",
            " 0 1 1 0 0 1 1 0 1 0 1 0 0 0 1 1 0 1 0 1 1 0 1 1 0 1 0 1 1 1 1 0 1 1 1 0 1\n",
            " 1 1 1 1 1 1 0 0 1 0 1 1 1 1 1 0 0 0 0 0 1 0 0 1 0 1 0 1 0 1 1 0 1 1 0 1 0\n",
            " 0 0 1 0 1 0 1 1 1 1 0 0 1 1 1 0 1 1 0 1 1 1 1 0 1 1 0 0 0 1 1 0 1 1 1 1 0\n",
            " 1 1 0 0 1 1 1 1 0 1 0 0 1 0 0 1 1 1 1 1 0 1 1 1 0 1 1 0 1 0 0 1 0 1 0 0 1\n",
            " 1 0 1 0 0 0 1 0 1 0 1 0 0 1 1 1 1 0 0 1 0 1 0 1 1 1 1 1 0 0 1 0 1 1 1 1 0\n",
            " 0 1 0 1 0 0 0 0 0 1 0 1 0 0 1 0 0 1 1 1 0 0 0 1 1 0 0 1 1 0 1 1 0 1 0 0 1\n",
            " 0 1 1 0 0 0 1 0 0 1 1 1 1 1 0 1 0 0 1 0 0 0 0 0 1 1 1 1 1 1 1 1 0 1 0 1 1\n",
            " 1 1 0 0 1 0 1 1 1 0 1 1 1 0 0 1 0 0 0 0 0 0 1 0 1 0 1 0 1 1 1 0 0 1 1 0 1\n",
            " 1 0 0 1 0 1 1 1 1 1 0 1 1 0 0 1 1 1 1 0 1 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1\n",
            " 1 1 1 0 1 1 0 0 1 1 0 1 1 0 0 1 1 1 1 0 0 0 1 0 1 0 1 1 1 0 1 1 1 1 1 0 0\n",
            " 0 1 1 0 0 1 0 0 1 0 0 1 0 1 1 1 0 1 1 0 0 0 1 0 1 1 1 0]\n",
            "probabilities: (842, 2) \n",
            " [1 1 0 1 0 1 1 0 1 1 1 0 1 0 0 1 1 1 0 1 1 1 0 0 1 1 0 0 1 0 0 0 1 1 1 1 1\n",
            " 0 0 1 1 1 1 1 0 1 0 1 0 0 1 1 1 1 0 1 1 0 0 1 0 1 1 0 0 1 0 0 1 1 1 1 0 0\n",
            " 0 1 1 0 0 0 1 1 0 1 0 0 1 0 1 1 1 0 0 1 0 1 0 0 1 0 0 0 0 1 0 1 1 0 0 1 1\n",
            " 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 1 1 0 0 1 0 0 0 1 1 1 0 1 1 1 1 0 0 0 1 1\n",
            " 0 1 1 0 1 0 0 0 0 0 0 0 1 1 1 0 1 0 0 0 0 0 1 1 0 1 0 0 0 1 0 1 0 1 1 0 1\n",
            " 1 0 0 0 0 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 0 1 1 1 0 1 1 0 1 0 1 1 0 1 0 1 1\n",
            " 1 1 1 1 0 1 1 0 1 1 0 0 1 1 1 1 0 0 0 0 1 1 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0\n",
            " 1 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 1 0 1 0 0 1 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0\n",
            " 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 1 0 1 0 1 1 0 1 1 0\n",
            " 0 1 0 1 0 1 1 1 0 1 1 0 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 0 0 0 0 0 1 1 0 1\n",
            " 0 1 0 0 1 0 1 0 0 1 1 0 1 1 1 1 1 1 0 1 0 1 1 1 0 0 0 0 1 1 1 1 1 0 0 0 1\n",
            " 1 1 0 1 0 1 0 0 0 0 0 1 1 0 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 0 0 1\n",
            " 0 1 1 0 0 1 1 0 1 0 1 0 0 0 1 1 0 1 0 1 1 0 1 1 0 1 0 1 1 1 1 0 1 1 1 0 1\n",
            " 1 1 1 1 1 1 0 0 1 0 1 1 1 1 1 0 0 0 0 0 1 0 0 1 0 1 0 1 0 1 1 0 1 1 0 1 0\n",
            " 0 0 1 0 1 0 1 1 1 1 0 0 1 1 1 0 1 1 0 1 1 1 1 0 1 1 0 0 0 1 1 0 1 1 1 1 0\n",
            " 1 1 0 0 1 1 1 1 0 1 0 0 1 0 0 1 1 1 1 1 0 1 1 1 0 1 1 0 1 0 0 1 0 1 0 0 1\n",
            " 1 0 1 0 0 0 1 0 1 0 1 0 0 1 1 1 1 0 0 1 0 1 0 1 1 1 1 1 0 0 1 0 1 1 1 1 0\n",
            " 0 1 0 1 0 0 0 0 0 1 0 1 0 0 1 0 0 1 1 1 0 0 0 1 1 0 0 1 1 0 1 1 0 1 0 0 1\n",
            " 0 1 1 0 0 0 1 0 0 1 1 1 1 1 0 1 0 0 1 0 0 0 0 0 1 1 1 1 1 1 1 1 0 1 0 1 1\n",
            " 1 1 0 0 1 0 1 1 1 0 1 1 1 0 0 1 0 0 0 0 0 0 1 0 1 0 1 0 1 1 1 0 0 1 1 0 1\n",
            " 1 0 0 1 0 1 1 1 1 1 0 1 1 0 0 1 1 1 1 0 1 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1\n",
            " 1 1 1 0 1 1 0 0 1 1 0 1 1 0 0 1 1 1 1 0 0 0 1 0 1 0 1 1 1 0 1 1 1 1 1 0 0\n",
            " 0 1 1 0 0 1 0 0 1 0 0 1 0 1 1 1 0 1 1 0 0 0 1 0 1 1 1 0]\n",
            "trainset before adding uncertain samples (460, 10) (460,)\n",
            "trainset after adding uncertain samples (470, 10) (470,)\n",
            "updated train set: (470, 10) (470,) unique(labels): [230 240] [0 1]\n",
            "val set: (832, 10) (832,)\n",
            "\n",
            "Train set: (470, 10)\n",
            "Validation set: (832, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 47\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.512 s \n",
            "\n",
            "Accuracy rate is 79.493088 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.88      0.86       321\n",
            "           1       0.62      0.57      0.59       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.73      0.72      0.73       434\n",
            "weighted avg       0.79      0.79      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[281  40]\n",
            " [ 49  64]]\n",
            "--------------------------------\n",
            "val predicted: (832,) [1 1 0 0 1 1 0 1 1 1 0 1 0 0 1 1 1 0 1 1 1 0 0 1 1 0 0 1 0 0 0 1 1 1 1 1 0\n",
            " 0 1 1 1 1 1 0 1 0 1 0 0 1 1 1 1 0 1 1 0 0 1 0 1 1 0 0 1 0 0 1 1 1 1 0 0 0\n",
            " 1 1 0 0 0 1 1 0 1 0 0 1 0 1 1 1 0 0 1 0 1 0 0 1 0 0 0 0 1 0 1 1 0 0 1 1 0\n",
            " 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 1 1 0 0 1 0 0 0 1 1 1 0 1 1 1 1 0 0 0 1 1 0\n",
            " 1 1 1 0 0 0 0 0 0 0 1 1 1 0 1 0 0 0 0 0 1 1 0 1 0 0 0 1 0 1 0 1 1 0 1 1 0\n",
            " 0 0 0 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 0 1 1 1 0 1 1 0 1 0 1 1 0 1 0 1 1 1 1\n",
            " 1 1 0 1 1 0 1 1 0 0 1 1 1 1 0 0 0 0 1 1 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 1 1\n",
            " 1 1 1 1 1 0 1 1 0 1 0 1 1 0 1 0 0 1 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 1\n",
            " 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 0 1 1 0 1 1 0 0 1 0 1 0 1\n",
            " 1 1 0 1 1 0 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 0 0 0 0 0 1 1 0 1 0 1 0 0 1 0\n",
            " 1 0 0 1 1 0 1 1 1 1 1 1 0 1 0 1 1 1 0 0 0 0 1 1 1 1 1 0 0 0 1 1 1 0 1 0 1\n",
            " 0 0 0 0 0 1 1 0 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 0 0 1 0 1 1 0 0 1\n",
            " 1 0 1 0 1 0 0 0 1 1 0 1 0 1 1 0 1 1 0 1 0 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1\n",
            " 0 0 1 0 1 1 1 1 0 0 0 0 0 1 0 0 1 0 1 0 1 0 1 1 0 1 1 0 1 0 0 0 1 0 1 0 1\n",
            " 1 1 1 0 0 1 1 1 0 1 1 0 1 1 1 1 0 1 1 0 0 0 1 0 1 1 1 1 0 1 1 0 0 1 1 1 1\n",
            " 0 1 0 0 1 0 0 1 1 1 1 1 0 1 1 1 0 1 1 0 1 0 0 1 0 1 0 0 1 1 0 1 0 0 0 1 0\n",
            " 1 0 1 0 0 1 1 1 1 0 0 1 0 1 0 1 1 1 1 1 0 0 1 0 1 1 1 1 0 0 1 0 1 0 0 0 0\n",
            " 0 1 0 1 0 0 1 0 0 1 1 1 0 0 0 1 1 0 0 1 1 0 1 1 0 1 0 0 1 0 1 1 0 0 0 1 0\n",
            " 0 1 1 1 1 1 0 1 0 0 1 0 0 0 0 0 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 0 0 1 0 1 1\n",
            " 1 0 1 1 1 0 0 1 0 0 0 0 0 0 1 0 1 0 1 0 1 1 1 0 0 1 1 0 1 1 0 0 1 0 1 1 1\n",
            " 1 0 1 1 0 0 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 0 0 1 1\n",
            " 0 1 1 0 0 1 1 1 1 0 0 0 1 0 1 0 1 1 1 0 1 1 1 1 1 0 0 0 1 1 0 0 1 0 0 1 0\n",
            " 0 1 0 1 1 1 0 1 1 0 0 0 1 0 1 1 1 0]\n",
            "probabilities: (832, 2) \n",
            " [1 1 0 0 1 1 0 1 1 1 0 1 0 0 1 1 1 0 1 1 1 0 0 1 1 0 0 1 0 0 0 1 1 1 1 1 0\n",
            " 0 1 1 1 1 1 0 1 0 1 0 0 1 1 1 1 0 1 1 0 0 1 0 1 1 0 0 1 0 0 1 1 1 1 0 0 0\n",
            " 1 1 0 0 0 1 1 0 1 0 0 1 0 1 1 1 0 0 1 0 1 0 0 1 0 0 0 0 1 0 1 1 0 0 1 1 0\n",
            " 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 1 1 0 0 1 0 0 0 1 1 1 0 1 1 1 1 0 0 0 1 1 0\n",
            " 1 1 1 0 0 0 0 0 0 0 1 1 1 0 1 0 0 0 0 0 1 1 0 1 0 0 0 1 0 1 0 1 1 0 1 1 0\n",
            " 0 0 0 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 0 1 1 1 0 1 1 0 1 0 1 1 0 1 0 1 1 1 1\n",
            " 1 1 0 1 1 0 1 1 0 0 1 1 1 1 0 0 0 0 1 1 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 1 1\n",
            " 1 1 1 1 1 0 1 1 0 1 0 1 1 0 1 0 0 1 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 1\n",
            " 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 0 1 1 0 1 1 0 0 1 0 1 0 1\n",
            " 1 1 0 1 1 0 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 0 0 0 0 0 1 1 0 1 0 1 0 0 1 0\n",
            " 1 0 0 1 1 0 1 1 1 1 1 1 0 1 0 1 1 1 0 0 0 0 1 1 1 1 1 0 0 0 1 1 1 0 1 0 1\n",
            " 0 0 0 0 0 1 1 0 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 0 0 1 0 1 1 0 0 1\n",
            " 1 0 1 0 1 0 0 0 1 1 0 1 0 1 1 0 1 1 0 1 0 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1\n",
            " 0 0 1 0 1 1 1 1 0 0 0 0 0 1 0 0 1 0 1 0 1 0 1 1 0 1 1 0 1 0 0 0 1 0 1 0 1\n",
            " 1 1 1 0 0 1 1 1 0 1 1 0 1 1 1 1 0 1 1 0 0 0 1 0 1 1 1 1 0 1 1 0 0 1 1 1 1\n",
            " 0 1 0 0 1 0 0 1 1 1 1 1 0 1 1 1 0 1 1 0 1 0 0 1 0 1 0 0 1 1 0 1 0 0 0 1 0\n",
            " 1 0 1 0 0 1 1 1 1 0 0 1 0 1 0 1 1 1 1 1 0 0 1 0 1 1 1 1 0 0 1 0 1 0 0 0 0\n",
            " 0 1 0 1 0 0 1 0 0 1 1 1 0 0 0 1 1 0 0 1 1 0 1 1 0 1 0 0 1 0 1 1 0 0 0 1 0\n",
            " 0 1 1 1 1 1 0 1 0 0 1 0 0 0 0 0 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 0 0 1 0 1 1\n",
            " 1 0 1 1 1 0 0 1 0 0 0 0 0 0 1 0 1 0 1 0 1 1 1 0 0 1 1 0 1 1 0 0 1 0 1 1 1\n",
            " 1 0 1 1 0 0 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 0 0 1 1\n",
            " 0 1 1 0 0 1 1 1 1 0 0 0 1 0 1 0 1 1 1 0 1 1 1 1 1 0 0 0 1 1 0 0 1 0 0 1 0\n",
            " 0 1 0 1 1 1 0 1 1 0 0 0 1 0 1 1 1 0]\n",
            "trainset before adding uncertain samples (470, 10) (470,)\n",
            "trainset after adding uncertain samples (480, 10) (480,)\n",
            "updated train set: (480, 10) (480,) unique(labels): [233 247] [0 1]\n",
            "val set: (822, 10) (822,)\n",
            "\n",
            "Train set: (480, 10)\n",
            "Validation set: (822, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 48\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.450 s \n",
            "\n",
            "Accuracy rate is 80.414747 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.88      0.87       321\n",
            "           1       0.63      0.60      0.62       113\n",
            "\n",
            "    accuracy                           0.80       434\n",
            "   macro avg       0.75      0.74      0.74       434\n",
            "weighted avg       0.80      0.80      0.80       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[281  40]\n",
            " [ 45  68]]\n",
            "--------------------------------\n",
            "val predicted: (822,) [1 1 0 0 1 1 0 1 1 1 0 1 0 0 1 1 1 0 1 1 1 0 0 1 1 0 0 1 0 0 0 1 1 1 1 1 0\n",
            " 0 1 1 1 1 1 0 1 0 1 0 0 1 1 1 1 0 1 0 0 1 0 1 1 0 0 1 0 0 1 1 1 1 0 0 0 1\n",
            " 1 0 0 0 1 1 0 1 0 1 0 1 1 1 0 0 1 0 1 0 0 1 0 0 0 0 1 0 1 1 0 0 1 1 0 1 1\n",
            " 1 1 1 1 0 1 1 0 0 1 1 0 1 1 1 0 0 1 0 0 0 1 1 1 0 1 1 1 1 0 0 0 1 1 0 1 1\n",
            " 1 0 0 0 0 0 0 0 1 1 1 0 1 0 0 0 0 0 1 1 0 1 0 0 0 1 0 1 0 1 1 0 1 1 0 0 0\n",
            " 0 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 0 1 1 1 0 1 1 0 1 0 1 1 0 1 0 1 1 1 1 1 0\n",
            " 1 1 0 1 1 0 0 1 1 1 1 0 0 0 0 1 1 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 1 1 1 1 1\n",
            " 1 1 0 1 1 0 1 0 1 1 0 1 0 0 1 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 1 0 1 0\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0 1 1 0 1 1 0 0 1 0 1 0 1 1 1 0 1\n",
            " 1 0 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 0 0 0 0 0 1 1 0 1 0 1 0 0 1 0 1 0 0 1\n",
            " 1 0 1 1 1 1 1 0 1 0 1 1 1 0 0 0 0 1 1 1 1 1 0 0 0 1 1 1 0 1 0 1 0 0 0 0 0\n",
            " 1 1 0 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0 1 0 1 1 0 0 1 1 0 1 0 1 0\n",
            " 0 0 1 1 0 1 0 1 1 0 1 1 0 1 0 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 0 0 1 0 1 1 1\n",
            " 1 0 0 0 0 0 1 0 0 1 0 1 0 1 0 1 1 0 1 1 0 1 0 0 0 1 0 1 0 1 1 1 1 0 0 1 1\n",
            " 0 1 1 0 1 1 1 1 0 1 1 0 0 0 1 0 1 1 1 1 0 1 1 0 0 1 1 1 1 0 1 0 0 1 0 0 1\n",
            " 1 1 1 1 0 1 1 1 0 1 1 0 1 0 0 1 0 1 0 0 1 1 0 1 0 0 0 1 0 1 0 1 0 0 1 1 1\n",
            " 1 0 0 1 0 1 1 1 1 1 1 0 0 1 0 1 1 1 1 0 0 1 0 1 0 0 0 0 0 1 0 1 0 0 1 0 0\n",
            " 1 1 1 0 0 0 1 1 0 0 1 1 0 1 1 0 1 0 0 1 0 1 1 0 0 0 1 0 0 1 1 1 1 1 0 1 0\n",
            " 0 1 0 0 0 0 0 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 0 0 1 0 1 1 1 0 1 1 1 0 0 1 0\n",
            " 0 0 0 0 0 1 0 1 0 1 0 1 1 1 0 0 1 1 0 1 1 0 0 1 0 1 1 1 1 0 1 1 0 0 1 1 1\n",
            " 1 0 1 1 0 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 0 0 1 1 0 1 1 0 0 1 1 1 1 0\n",
            " 0 0 1 0 1 0 1 1 1 0 1 1 1 1 1 0 0 0 1 1 0 0 1 0 0 1 0 0 1 0 1 1 1 0 1 1 0\n",
            " 0 0 1 0 1 1 1 0]\n",
            "probabilities: (822, 2) \n",
            " [1 1 0 0 1 1 0 1 1 1 0 1 0 0 1 1 1 0 1 1 1 0 0 1 1 0 0 1 0 0 0 1 1 1 1 1 0\n",
            " 0 1 1 1 1 1 0 1 0 1 0 0 1 1 1 1 0 1 0 0 1 0 1 1 0 0 1 0 0 1 1 1 1 0 0 0 1\n",
            " 1 0 0 0 1 1 0 1 0 1 0 1 1 1 0 0 1 0 1 0 0 1 0 0 0 0 1 0 1 1 0 0 1 1 0 1 1\n",
            " 1 1 1 1 0 1 1 0 0 1 1 0 1 1 1 0 0 1 0 0 0 1 1 1 0 1 1 1 1 0 0 0 1 1 0 1 1\n",
            " 1 0 0 0 0 0 0 0 1 1 1 0 1 0 0 0 0 0 1 1 0 1 0 0 0 1 0 1 0 1 1 0 1 1 0 0 0\n",
            " 0 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 0 1 1 1 0 1 1 0 1 0 1 1 0 1 0 1 1 1 1 1 0\n",
            " 1 1 0 1 1 0 0 1 1 1 1 0 0 0 0 1 1 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 1 1 1 1 1\n",
            " 1 1 0 1 1 0 1 0 1 1 0 1 0 0 1 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 1 0 1 0\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0 1 1 0 1 1 0 0 1 0 1 0 1 1 1 0 1\n",
            " 1 0 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 0 0 0 0 0 1 1 0 1 0 1 0 0 1 0 1 0 0 1\n",
            " 1 0 1 1 1 1 1 0 1 0 1 1 1 0 0 0 0 1 1 1 1 1 0 0 0 1 1 1 0 1 0 1 0 0 0 0 0\n",
            " 1 1 0 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0 1 0 1 1 0 0 1 1 0 1 0 1 0\n",
            " 0 0 1 1 0 1 0 1 1 0 1 1 0 1 0 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 0 0 1 0 1 1 1\n",
            " 1 0 0 0 0 0 1 0 0 1 0 1 0 1 0 1 1 0 1 1 0 1 0 0 0 1 0 1 0 1 1 1 1 0 0 1 1\n",
            " 0 1 1 0 1 1 1 1 0 1 1 0 0 0 1 0 1 1 1 1 0 1 1 0 0 1 1 1 1 0 1 0 0 1 0 0 1\n",
            " 1 1 1 1 0 1 1 1 0 1 1 0 1 0 0 1 0 1 0 0 1 1 0 1 0 0 0 1 0 1 0 1 0 0 1 1 1\n",
            " 1 0 0 1 0 1 1 1 1 1 1 0 0 1 0 1 1 1 1 0 0 1 0 1 0 0 0 0 0 1 0 1 0 0 1 0 0\n",
            " 1 1 1 0 0 0 1 1 0 0 1 1 0 1 1 0 1 0 0 1 0 1 1 0 0 0 1 0 0 1 1 1 1 1 0 1 0\n",
            " 0 1 0 0 0 0 0 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 0 0 1 0 1 1 1 0 1 1 1 0 0 1 0\n",
            " 0 0 0 0 0 1 0 1 0 1 0 1 1 1 0 0 1 1 0 1 1 0 0 1 0 1 1 1 1 0 1 1 0 0 1 1 1\n",
            " 1 0 1 1 0 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 0 0 1 1 0 1 1 0 0 1 1 1 1 0\n",
            " 0 0 1 0 1 0 1 1 1 0 1 1 1 1 1 0 0 0 1 1 0 0 1 0 0 1 0 0 1 0 1 1 1 0 1 1 0\n",
            " 0 0 1 0 1 1 1 0]\n",
            "trainset before adding uncertain samples (480, 10) (480,)\n",
            "trainset after adding uncertain samples (490, 10) (490,)\n",
            "updated train set: (490, 10) (490,) unique(labels): [238 252] [0 1]\n",
            "val set: (812, 10) (812,)\n",
            "\n",
            "Train set: (490, 10)\n",
            "Validation set: (812, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 49\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.282 s \n",
            "\n",
            "Accuracy rate is 79.723502 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.86      0.86       321\n",
            "           1       0.61      0.61      0.61       113\n",
            "\n",
            "    accuracy                           0.80       434\n",
            "   macro avg       0.74      0.74      0.74       434\n",
            "weighted avg       0.80      0.80      0.80       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[277  44]\n",
            " [ 44  69]]\n",
            "--------------------------------\n",
            "val predicted: (812,) [1 1 0 0 1 1 0 1 1 1 0 1 0 0 1 1 1 0 1 1 1 0 0 1 1 0 0 1 0 0 0 1 1 1 1 1 0\n",
            " 0 1 1 1 1 1 0 1 0 1 0 0 1 1 1 1 0 1 0 0 1 0 1 1 0 0 1 0 0 1 1 1 1 0 0 0 1\n",
            " 1 0 0 0 1 1 0 1 0 1 0 1 1 1 0 0 1 0 1 0 0 1 0 0 0 0 1 0 1 1 0 0 1 1 0 1 1\n",
            " 1 1 1 1 0 1 1 0 0 1 1 0 1 1 1 0 0 1 0 0 0 1 1 1 0 1 1 1 1 0 0 0 1 1 0 1 1\n",
            " 1 0 0 0 0 0 0 0 1 1 1 0 1 0 0 0 0 0 1 1 0 1 0 0 1 0 1 0 1 1 0 1 1 0 0 0 0\n",
            " 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 0 1 1 1 0 1 1 0 1 0 1 1 0 1 0 1 1 1 1 1 0 1\n",
            " 1 0 1 1 0 0 1 1 1 1 0 0 0 1 1 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 1 1 1 1 1 1 1\n",
            " 0 1 1 0 1 0 1 1 0 1 0 0 1 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 1 0 1 0 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0 1 1 0 1 1 1 0 1 0 1 1 1 0 1 1 0 1 1\n",
            " 1 1 0 1 1 0 1 1 0 1 1 1 1 1 0 0 0 0 0 1 1 0 1 0 1 0 0 1 0 1 0 0 1 1 0 1 1\n",
            " 1 1 1 0 1 0 1 1 1 0 0 0 0 1 1 1 1 1 0 0 0 1 1 1 0 1 0 1 0 0 0 0 0 1 1 0 1\n",
            " 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0 1 0 1 1 0 0 1 1 0 1 0 1 0 0 0 1 1\n",
            " 0 1 0 1 1 0 1 1 0 1 0 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 0 0 1 0 1 1 1 1 0 0 0\n",
            " 0 0 1 0 0 1 0 1 0 1 0 1 1 0 1 1 0 1 0 0 0 1 0 1 0 1 1 1 1 0 0 1 1 0 1 0 1\n",
            " 1 1 1 0 1 1 0 0 0 1 0 1 1 1 1 0 1 1 0 0 1 1 1 1 0 1 0 0 1 0 0 1 1 1 1 1 0\n",
            " 1 1 1 0 1 1 0 1 0 1 0 1 1 1 0 1 0 0 0 1 0 1 0 1 0 0 1 1 1 1 0 0 1 0 1 1 1\n",
            " 1 1 1 0 0 1 0 1 1 1 1 0 0 1 0 1 0 0 0 0 0 1 0 1 0 0 1 0 0 1 1 1 0 0 1 1 0\n",
            " 0 1 1 0 1 1 0 1 0 0 1 0 1 1 0 0 0 1 0 0 1 1 1 1 1 0 1 0 0 1 0 0 0 0 0 1 1\n",
            " 1 1 1 1 1 0 1 0 1 1 1 1 0 0 1 0 1 1 1 0 1 1 1 0 0 1 0 0 0 0 0 0 1 0 1 0 1\n",
            " 0 1 1 1 0 0 1 1 0 1 1 0 0 1 0 1 1 1 1 0 1 1 0 0 1 1 1 1 0 1 1 0 1 1 0 1 1\n",
            " 1 1 1 1 1 0 1 1 1 1 0 1 1 0 0 1 1 0 1 1 0 0 1 1 1 1 0 0 0 1 0 1 0 1 1 1 0\n",
            " 1 1 1 1 1 0 0 0 1 1 0 0 1 0 0 1 0 0 1 0 1 1 1 0 1 1 0 0 0 1 0 1 1 1 0]\n",
            "probabilities: (812, 2) \n",
            " [1 1 0 0 1 1 0 1 1 1 0 1 0 0 1 1 1 0 1 1 1 0 0 1 1 0 0 1 0 0 0 1 1 1 1 1 0\n",
            " 0 1 1 1 1 1 0 1 0 1 0 0 1 1 1 1 0 1 0 0 1 0 1 1 0 0 1 0 0 1 1 1 1 0 0 0 1\n",
            " 1 0 0 0 1 1 0 1 0 1 0 1 1 1 0 0 1 0 1 0 0 1 0 0 0 0 1 0 1 1 0 0 1 1 0 1 1\n",
            " 1 1 1 1 0 1 1 0 0 1 1 0 1 1 1 0 0 1 0 0 0 1 1 1 0 1 1 1 1 0 0 0 1 1 0 1 1\n",
            " 1 0 0 0 0 0 0 0 1 1 1 0 1 0 0 0 0 0 1 1 0 1 0 0 1 0 1 0 1 1 0 1 1 0 0 0 0\n",
            " 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 0 1 1 1 0 1 1 0 1 0 1 1 0 1 0 1 1 1 1 1 0 1\n",
            " 1 0 1 1 0 0 1 1 1 1 0 0 0 1 1 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 1 1 1 1 1 1 1\n",
            " 0 1 1 0 1 0 1 1 0 1 0 0 1 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 1 0 1 0 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0 1 1 0 1 1 1 0 1 0 1 1 1 0 1 1 0 1 1\n",
            " 1 1 0 1 1 0 1 1 0 1 1 1 1 1 0 0 0 0 0 1 1 0 1 0 1 0 0 1 0 1 0 0 1 1 0 1 1\n",
            " 1 1 1 0 1 0 1 1 1 0 0 0 0 1 1 1 1 1 0 0 0 1 1 1 0 1 0 1 0 0 0 0 0 1 1 0 1\n",
            " 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0 1 0 1 1 0 0 1 1 0 1 0 1 0 0 0 1 1\n",
            " 0 1 0 1 1 0 1 1 0 1 0 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 0 0 1 0 1 1 1 1 0 0 0\n",
            " 0 0 1 0 0 1 0 1 0 1 0 1 1 0 1 1 0 1 0 0 0 1 0 1 0 1 1 1 1 0 0 1 1 0 1 0 1\n",
            " 1 1 1 0 1 1 0 0 0 1 0 1 1 1 1 0 1 1 0 0 1 1 1 1 0 1 0 0 1 0 0 1 1 1 1 1 0\n",
            " 1 1 1 0 1 1 0 1 0 1 0 1 1 1 0 1 0 0 0 1 0 1 0 1 0 0 1 1 1 1 0 0 1 0 1 1 1\n",
            " 1 1 1 0 0 1 0 1 1 1 1 0 0 1 0 1 0 0 0 0 0 1 0 1 0 0 1 0 0 1 1 1 0 0 1 1 0\n",
            " 0 1 1 0 1 1 0 1 0 0 1 0 1 1 0 0 0 1 0 0 1 1 1 1 1 0 1 0 0 1 0 0 0 0 0 1 1\n",
            " 1 1 1 1 1 0 1 0 1 1 1 1 0 0 1 0 1 1 1 0 1 1 1 0 0 1 0 0 0 0 0 0 1 0 1 0 1\n",
            " 0 1 1 1 0 0 1 1 0 1 1 0 0 1 0 1 1 1 1 0 1 1 0 0 1 1 1 1 0 1 1 0 1 1 0 1 1\n",
            " 1 1 1 1 1 0 1 1 1 1 0 1 1 0 0 1 1 0 1 1 0 0 1 1 1 1 0 0 0 1 0 1 0 1 1 1 0\n",
            " 1 1 1 1 1 0 0 0 1 1 0 0 1 0 0 1 0 0 1 0 1 1 1 0 1 1 0 0 0 1 0 1 1 1 0]\n",
            "trainset before adding uncertain samples (490, 10) (490,)\n",
            "trainset after adding uncertain samples (500, 10) (500,)\n",
            "updated train set: (500, 10) (500,) unique(labels): [248 252] [0 1]\n",
            "val set: (802, 10) (802,)\n",
            "\n",
            "Train set: (500, 10)\n",
            "Validation set: (802, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 50\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.271 s \n",
            "\n",
            "Accuracy rate is 79.953917 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.87      0.87       321\n",
            "           1       0.62      0.60      0.61       113\n",
            "\n",
            "    accuracy                           0.80       434\n",
            "   macro avg       0.74      0.74      0.74       434\n",
            "weighted avg       0.80      0.80      0.80       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[279  42]\n",
            " [ 45  68]]\n",
            "--------------------------------\n",
            "final active learning accuracies [65.2073732718894, 76.95852534562212, 75.11520737327189, 70.04608294930875, 72.35023041474655, 71.42857142857143, 77.41935483870968, 76.26728110599078, 77.41935483870968, 77.88018433179722, 78.57142857142857, 73.963133640553, 79.49308755760369, 79.03225806451613, 79.49308755760369, 79.26267281105991, 78.3410138248848, 78.57142857142857, 79.03225806451613, 80.18433179723502, 79.95391705069125, 80.18433179723502, 78.80184331797236, 79.49308755760369, 79.72350230414746, 80.18433179723502, 79.95391705069125, 81.5668202764977, 81.79723502304147, 81.5668202764977, 81.33640552995391, 80.64516129032258, 80.4147465437788, 81.10599078341014, 79.49308755760369, 80.64516129032258, 80.87557603686636, 80.87557603686636, 79.49308755760369, 80.18433179723502, 79.72350230414746, 79.95391705069125, 78.80184331797236, 79.72350230414746, 79.49308755760369, 80.4147465437788, 79.49308755760369, 80.4147465437788, 79.72350230414746, 79.95391705069125]\n",
            "saved /Users/wenxuanhuang/Documents/Repo/ML-for-COVID-19-dataset/Results/Active-learning-experiment-15.pkl /Users/wenxuanhuang/Documents/Repo/ML-for-COVID-19-dataset ['Decision_tree.ipynb', 'dec_git.png', 'Logit_default_f10.pdf', 'Logistic.ipynb', 'SVC.ipynb', 'RF_f5e50_featureimp.pdf', 'log_al.png', 'dec_git.pdf', '.DS_Store', 'log_git.png', 'svm_git.png', 'Logistic_Scikit.ipynb', 'knn_git.pdf', 'knn_git.png', 'rf_al.png', 'Best classifier_RF_f5e50.pdf', 'KNN.ipynb', 'GBDC.ipynb', 'rf_git.png', 'README.md', 'all_training.csv', 'Results', 'svm_al.png', 'Log_ROC.png', 'Logit_default_f7(p_removal).pdf', 'Active_learning.ipynb', 'Random_forest.ipynb', 'Model_select.ipynb', 'gdbc_git.png', '.git', '.vscode', 'Untitled', 'RF_f5e50_modelselect.pdf', 'Logit_default_f8(std_removal).pdf']\n",
            "{\n",
            "  \"GDBCModel\": {\n",
            "    \"EntropySelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          65.2073732718894,\n",
            "          76.95852534562212,\n",
            "          75.11520737327189,\n",
            "          70.04608294930875,\n",
            "          72.35023041474655,\n",
            "          71.42857142857143,\n",
            "          77.41935483870968,\n",
            "          76.26728110599078,\n",
            "          77.41935483870968,\n",
            "          77.88018433179722,\n",
            "          78.57142857142857,\n",
            "          73.963133640553,\n",
            "          79.49308755760369,\n",
            "          79.03225806451613,\n",
            "          79.49308755760369,\n",
            "          79.26267281105991,\n",
            "          78.3410138248848,\n",
            "          78.57142857142857,\n",
            "          79.03225806451613,\n",
            "          80.18433179723502,\n",
            "          79.95391705069125,\n",
            "          80.18433179723502,\n",
            "          78.80184331797236,\n",
            "          79.49308755760369,\n",
            "          79.72350230414746,\n",
            "          80.18433179723502,\n",
            "          79.95391705069125,\n",
            "          81.5668202764977,\n",
            "          81.79723502304147,\n",
            "          81.5668202764977,\n",
            "          81.33640552995391,\n",
            "          80.64516129032258,\n",
            "          80.4147465437788,\n",
            "          81.10599078341014,\n",
            "          79.49308755760369,\n",
            "          80.64516129032258,\n",
            "          80.87557603686636,\n",
            "          80.87557603686636,\n",
            "          79.49308755760369,\n",
            "          80.18433179723502,\n",
            "          79.72350230414746,\n",
            "          79.95391705069125,\n",
            "          78.80184331797236,\n",
            "          79.72350230414746,\n",
            "          79.49308755760369,\n",
            "          80.4147465437788,\n",
            "          79.49308755760369,\n",
            "          80.4147465437788,\n",
            "          79.72350230414746,\n",
            "          79.95391705069125\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          77.41935483870968,\n",
            "          79.03225806451613,\n",
            "          80.64516129032258,\n",
            "          80.18433179723502\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          70.04608294930875,\n",
            "          76.49769585253456,\n",
            "          79.03225806451613,\n",
            "          78.57142857142857,\n",
            "          77.64976958525345,\n",
            "          78.80184331797236,\n",
            "          78.80184331797236,\n",
            "          77.41935483870968,\n",
            "          77.88018433179722,\n",
            "          77.64976958525345,\n",
            "          79.03225806451613,\n",
            "          77.88018433179722,\n",
            "          78.80184331797236,\n",
            "          78.80184331797236,\n",
            "          79.26267281105991,\n",
            "          79.72350230414746,\n",
            "          79.03225806451613,\n",
            "          79.72350230414746,\n",
            "          80.4147465437788,\n",
            "          80.87557603686636\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          78.57142857142857,\n",
            "          80.4147465437788\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          75.34562211981567,\n",
            "          80.64516129032258,\n",
            "          79.95391705069125,\n",
            "          79.03225806451613,\n",
            "          80.64516129032258,\n",
            "          80.18433179723502,\n",
            "          79.95391705069125,\n",
            "          79.49308755760369,\n",
            "          79.72350230414746,\n",
            "          79.49308755760369\n",
            "        ]\n",
            "      ]\n",
            "    },\n",
            "    \"MarginSamplingSelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          49.07834101382488,\n",
            "          63.133640552995395,\n",
            "          72.58064516129032,\n",
            "          68.89400921658986,\n",
            "          72.58064516129032,\n",
            "          76.036866359447,\n",
            "          75.34562211981567,\n",
            "          74.19354838709677,\n",
            "          74.65437788018433,\n",
            "          73.73271889400922,\n",
            "          75.11520737327189,\n",
            "          70.50691244239631,\n",
            "          75.57603686635944,\n",
            "          75.34562211981567,\n",
            "          75.11520737327189,\n",
            "          75.80645161290323,\n",
            "          76.72811059907833,\n",
            "          76.49769585253456,\n",
            "          77.41935483870968,\n",
            "          77.18894009216591,\n",
            "          77.41935483870968,\n",
            "          76.95852534562212,\n",
            "          78.80184331797236,\n",
            "          78.3410138248848,\n",
            "          78.57142857142857,\n",
            "          79.72350230414746,\n",
            "          79.72350230414746,\n",
            "          79.26267281105991,\n",
            "          79.49308755760369,\n",
            "          79.49308755760369,\n",
            "          79.26267281105991,\n",
            "          78.57142857142857,\n",
            "          79.03225806451613,\n",
            "          79.49308755760369,\n",
            "          79.95391705069125,\n",
            "          79.95391705069125,\n",
            "          80.18433179723502,\n",
            "          79.95391705069125,\n",
            "          80.64516129032258,\n",
            "          79.49308755760369,\n",
            "          78.57142857142857,\n",
            "          78.80184331797236,\n",
            "          78.57142857142857,\n",
            "          79.03225806451613,\n",
            "          79.26267281105991,\n",
            "          78.57142857142857,\n",
            "          79.26267281105991,\n",
            "          78.80184331797236,\n",
            "          79.26267281105991,\n",
            "          79.49308755760369\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          76.95852534562212,\n",
            "          78.80184331797236,\n",
            "          79.03225806451613,\n",
            "          81.10599078341014\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          74.65437788018433,\n",
            "          69.81566820276498,\n",
            "          80.18433179723502,\n",
            "          72.11981566820278,\n",
            "          72.81105990783409,\n",
            "          73.73271889400922,\n",
            "          73.50230414746544,\n",
            "          78.57142857142857,\n",
            "          78.57142857142857,\n",
            "          81.10599078341014,\n",
            "          80.64516129032258,\n",
            "          78.80184331797236,\n",
            "          79.26267281105991,\n",
            "          80.18433179723502,\n",
            "          79.72350230414746,\n",
            "          79.26267281105991,\n",
            "          79.95391705069125,\n",
            "          79.72350230414746,\n",
            "          79.95391705069125,\n",
            "          79.72350230414746\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          76.26728110599078,\n",
            "          79.26267281105991\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          78.11059907834101,\n",
            "          78.11059907834101,\n",
            "          78.57142857142857,\n",
            "          78.57142857142857,\n",
            "          80.4147465437788,\n",
            "          80.18433179723502,\n",
            "          79.95391705069125,\n",
            "          79.72350230414746,\n",
            "          79.49308755760369,\n",
            "          78.80184331797236\n",
            "        ]\n",
            "      ]\n",
            "    },\n",
            "    \"RandomSelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          63.36405529953917,\n",
            "          70.73732718894009,\n",
            "          61.29032258064516,\n",
            "          63.594470046082954,\n",
            "          74.65437788018433,\n",
            "          75.80645161290323,\n",
            "          76.49769585253456,\n",
            "          76.49769585253456,\n",
            "          77.41935483870968,\n",
            "          76.72811059907833,\n",
            "          78.3410138248848,\n",
            "          78.80184331797236,\n",
            "          77.41935483870968,\n",
            "          79.49308755760369,\n",
            "          77.64976958525345,\n",
            "          76.95852534562212,\n",
            "          77.18894009216591,\n",
            "          76.95852534562212,\n",
            "          77.64976958525345,\n",
            "          78.11059907834101,\n",
            "          78.11059907834101,\n",
            "          77.64976958525345,\n",
            "          77.64976958525345,\n",
            "          78.3410138248848,\n",
            "          78.57142857142857,\n",
            "          77.64976958525345,\n",
            "          77.64976958525345,\n",
            "          77.41935483870968,\n",
            "          77.88018433179722,\n",
            "          77.88018433179722,\n",
            "          77.88018433179722,\n",
            "          78.11059907834101,\n",
            "          77.64976958525345,\n",
            "          78.3410138248848,\n",
            "          78.80184331797236,\n",
            "          79.26267281105991,\n",
            "          78.57142857142857,\n",
            "          77.88018433179722,\n",
            "          77.64976958525345,\n",
            "          77.64976958525345,\n",
            "          78.11059907834101,\n",
            "          79.72350230414746,\n",
            "          79.72350230414746,\n",
            "          79.49308755760369,\n",
            "          79.03225806451613,\n",
            "          79.72350230414746,\n",
            "          78.80184331797236,\n",
            "          78.57142857142857,\n",
            "          79.49308755760369,\n",
            "          79.26267281105991\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          72.58064516129032,\n",
            "          72.58064516129032,\n",
            "          76.036866359447,\n",
            "          76.26728110599078\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          72.35023041474655,\n",
            "          72.11981566820278,\n",
            "          71.88940092165899,\n",
            "          73.04147465437788,\n",
            "          72.81105990783409,\n",
            "          75.11520737327189,\n",
            "          73.50230414746544,\n",
            "          76.036866359447,\n",
            "          76.26728110599078,\n",
            "          76.49769585253456,\n",
            "          76.72811059907833,\n",
            "          77.18894009216591,\n",
            "          76.72811059907833,\n",
            "          78.11059907834101,\n",
            "          78.3410138248848,\n",
            "          77.64976958525345,\n",
            "          79.72350230414746,\n",
            "          79.95391705069125,\n",
            "          80.18433179723502,\n",
            "          80.87557603686636\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          78.3410138248848,\n",
            "          79.95391705069125\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          69.35483870967742,\n",
            "          76.72811059907833,\n",
            "          78.3410138248848,\n",
            "          78.57142857142857,\n",
            "          78.80184331797236,\n",
            "          79.95391705069125,\n",
            "          79.26267281105991,\n",
            "          79.03225806451613,\n",
            "          79.03225806451613,\n",
            "          78.80184331797236\n",
            "        ]\n",
            "      ]\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "---------------------------- FINISHED ---------------------------\n",
            "\n",
            "Count = 16, using model = GDBCModel, selection_function = MinStdSelection, k = 250, iteration = 0.\n",
            "\n",
            "initial random chosen samples (250,)\n",
            "initial train set: (250, 10) (250,) unique(labels): [115 135] [0 1]\n",
            "Val set: (1052, 10) (1052,) (250,)\n",
            "\n",
            "Train set: (250, 10)\n",
            "Validation set: (1052, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.970 s \n",
            "\n",
            "Accuracy rate is 75.115207 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.82      0.83       321\n",
            "           1       0.52      0.57      0.54       113\n",
            "\n",
            "    accuracy                           0.75       434\n",
            "   macro avg       0.68      0.69      0.69       434\n",
            "weighted avg       0.76      0.75      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[262  59]\n",
            " [ 49  64]]\n",
            "--------------------------------\n",
            "val predicted: (1052,) [0 1 1 ... 0 0 1]\n",
            "probabilities: (1052, 2) \n",
            " [0 1 1 ... 0 0 1]\n",
            "std (1052,) [43.50746948 43.45885129 46.43432336 ... 22.63493086 28.01365456\n",
            " 19.66863342]\n",
            "selection [ 832  747  133  976  606  956  992  651  981  944 1025  371  405  731\n",
            "  918   24   53  175  279 1033  275  615  710 1003  864  202  821  860\n",
            "  627  280  920 1022 1048  661  770  722   50  545  313  957  296  631\n",
            "  272   94 1020  650 1045  935   21  748   91  469  205  134   59  638\n",
            "  213  282  719  320  603  954   26  749  114  893  927  765   99  307\n",
            "  111  691  537  692  450  637  696  785  442  477  376  106  783  276\n",
            "  185  553  249  232  777  751  554 1008  171  417  464  203  504  259\n",
            "  231  750  475 1037   60  435  931  178  967  555  344  929  626  768\n",
            "  732  644  382 1001  759  115  753  640  436  454  739 1031  995   48\n",
            "  742  332  234  196  561  762  874  888  539  423  655  908   22  715\n",
            "  861  996  758  136 1018  788  366  617   95   81  666  979  393  270\n",
            "  181 1023  879  789  826  295  695  492  391  569  321  834  194  120\n",
            " 1051  824  191  212   92  894  348  659  611  534   51  636  341  889\n",
            "  938  771  873  619   47  899  623  605  726  806 1015  415  761  188\n",
            "  240  825  948 1017  705  663 1049  912  558  797  428  165  767 1027\n",
            "  987  179   23 1011  510  403  502  836  984  845  690 1014    7  150\n",
            "  448  728  807  862  471  314  522   45   10  671  878  334  802   93\n",
            "  808  680   75 1041  459  467  317  798   88  727   78  374] (250,) [ 0.57410497  0.86956626  0.89081832  1.05853861  1.32384435  1.39612613\n",
            "  1.48872601  1.97534493  2.1235819   2.2093066   2.43700209  2.51881229\n",
            "  2.58143953  2.59503903  2.75012386  2.98687952  2.99560718  3.0051752\n",
            "  3.20134389  3.4562775   3.7825325   3.86640964  3.87049751  3.96987303\n",
            "  4.43330774  4.63735833  4.73476385  4.75639031  4.86785191  4.92213328\n",
            "  5.26488235  5.29173313  5.41838996  5.75362945  5.77710303  6.23756346\n",
            "  6.36908604  6.45618526  6.59101257  6.6339152   6.63645371  6.64130435\n",
            "  6.70702269  6.7316684   6.75043262  7.07627167  7.21471724  7.28818798\n",
            "  7.28818798  7.31087934  7.59542083  7.60046906  7.78488251  7.92568719\n",
            "  7.92632729  8.06229951  8.08731981  8.11738085  8.31316325  8.3231737\n",
            "  8.68866768  8.72763856  8.73900788  8.788985    8.79878077  8.82821075\n",
            "  8.86551784  8.92102542  8.93106382  9.15085725  9.27302924  9.5153294\n",
            "  9.59052425  9.84685684  9.94026434 10.2777742  10.55974719 10.5695313\n",
            " 10.71209224 10.71209224 10.76405599 10.78337637 11.05201658 11.14315013\n",
            " 11.1973453  11.20671036 11.30209891 11.32771955 11.36237071 11.40436175\n",
            " 11.42977748 11.48846555 11.5004246  11.63640013 11.85363955 12.11258853\n",
            " 12.41547066 12.47676101 12.61419452 12.65649111 12.66721783 12.77490502\n",
            " 12.99346142 13.14135009 13.17407978 13.21773594 13.31720016 13.35099846\n",
            " 13.38908535 13.49974987 13.629031   13.84704547 13.86501212 13.97015453\n",
            " 14.23393138 14.4428363  14.48268724 14.74084323 14.79184628 14.88122688\n",
            " 14.88441299 14.98189041 15.28050872 15.391202   15.49605711 15.51434486\n",
            " 15.58472402 15.62791379 15.75853122 16.02714744 16.35008744 16.37366584\n",
            " 16.37713157 16.46852267 16.48222744 16.56688882 16.57849204 16.64923446\n",
            " 16.71304954 16.72377464 16.7450412  16.79950179 16.94289694 17.14368551\n",
            " 17.16935615 17.20823744 17.42539593 17.54521965 17.59030283 17.62770013\n",
            " 17.64950049 17.82477869 17.86272096 17.95363516 18.20564345 18.36278416\n",
            " 18.60172814 18.747488   18.77669456 18.78801172 18.83410928 18.86683591\n",
            " 18.89536779 19.31894006 19.35006233 19.53366568 19.54926152 19.55111411\n",
            " 19.66863342 20.11051202 20.29990334 20.30970525 20.4987345  20.55383673\n",
            " 20.71224382 20.71330262 20.82378401 20.8978652  20.90519332 20.93582863\n",
            " 20.97289275 21.04264964 21.14254159 21.15666073 21.20316861 21.31536214\n",
            " 21.32798298 21.35445093 21.49901532 21.53451314 21.65861898 21.69122454\n",
            " 21.91132099 21.93900299 22.06361309 22.0780557  22.09457381 22.40303686\n",
            " 22.47962126 22.51635026 22.61146701 22.62968772 22.63493086 22.65174473\n",
            " 22.84627938 22.86359401 22.93449066 23.00323129 23.05522947 23.08975177\n",
            " 23.41213343 23.49551798 23.76967269 23.78229323 23.89922233 23.93431191\n",
            " 23.95587621 24.13209048 24.16825418 24.27200372 24.38456127 24.50863839\n",
            " 24.69448634 24.79158484 25.11852864 25.16335554 25.1914476  25.35452728\n",
            " 25.47937968 25.50708997 25.52088509 25.55482594 25.63010182 25.71623607\n",
            " 25.82013831 25.91548659 25.9622103  26.22446993 26.23144344 26.28458044\n",
            " 26.29559597 26.31119572 26.4768403  26.5822666  26.58794644 26.74349642\n",
            " 26.83569034 26.8675163  26.91684127 27.11329728]\n",
            "trainset before adding uncertain samples (250, 10) (250,)\n",
            "trainset after adding uncertain samples (500, 10) (500,)\n",
            "updated train set: (500, 10) (500,) unique(labels): [243 257] [0 1]\n",
            "val set: (802, 10) (802,)\n",
            "\n",
            "Train set: (500, 10)\n",
            "Validation set: (802, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.255 s \n",
            "\n",
            "Accuracy rate is 79.262673 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.87      0.86       321\n",
            "           1       0.61      0.58      0.59       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.73      0.72      0.73       434\n",
            "weighted avg       0.79      0.79      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[279  42]\n",
            " [ 48  65]]\n",
            "--------------------------------\n",
            "final active learning accuracies [75.11520737327189, 79.26267281105991]\n",
            "saved /Users/wenxuanhuang/Documents/Repo/ML-for-COVID-19-dataset/Results/Active-learning-experiment-16.pkl /Users/wenxuanhuang/Documents/Repo/ML-for-COVID-19-dataset ['Decision_tree.ipynb', 'dec_git.png', 'Logit_default_f10.pdf', 'Logistic.ipynb', 'SVC.ipynb', 'RF_f5e50_featureimp.pdf', 'log_al.png', 'dec_git.pdf', '.DS_Store', 'log_git.png', 'svm_git.png', 'Logistic_Scikit.ipynb', 'knn_git.pdf', 'knn_git.png', 'rf_al.png', 'Best classifier_RF_f5e50.pdf', 'KNN.ipynb', 'GBDC.ipynb', 'rf_git.png', 'README.md', 'all_training.csv', 'Results', 'svm_al.png', 'Log_ROC.png', 'Logit_default_f7(p_removal).pdf', 'Active_learning.ipynb', 'Random_forest.ipynb', 'Model_select.ipynb', 'gdbc_git.png', '.git', '.vscode', 'Untitled', 'RF_f5e50_modelselect.pdf', 'Logit_default_f8(std_removal).pdf']\n",
            "\n",
            "---------------------------- FINISHED ---------------------------\n",
            "\n",
            "Count = 17, using model = GDBCModel, selection_function = MinStdSelection, k = 125, iteration = 0.\n",
            "\n",
            "initial random chosen samples (125,)\n",
            "initial train set: (125, 10) (125,) unique(labels): [62 63] [0 1]\n",
            "Val set: (1177, 10) (1177,) (125,)\n",
            "\n",
            "Train set: (125, 10)\n",
            "Validation set: (1177, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.771 s \n",
            "\n",
            "Accuracy rate is 78.341014 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.91      0.86       321\n",
            "           1       0.62      0.42      0.51       113\n",
            "\n",
            "    accuracy                           0.78       434\n",
            "   macro avg       0.72      0.67      0.68       434\n",
            "weighted avg       0.77      0.78      0.77       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[292  29]\n",
            " [ 65  48]]\n",
            "--------------------------------\n",
            "val predicted: (1177,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1177, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "std (1177,) [26.45868204 32.81355782 42.38316694 ... 49.39540592 49.75128172\n",
            " 25.60811491]\n",
            "selection [ 986  564   72  603  648  566  536  459   85  584  357  774  976  122\n",
            "  963  940  701  192  410   70 1064  853  861  197  933  263  428  919\n",
            "  189  656  156  415 1123 1164  966 1162  650  597  174  109  298  543\n",
            "  165  261  922   56  743  680  395 1031  773  943  116   22  341  807\n",
            "  682 1105  974  115  805  250  213  354  798  698  447  653  975   13\n",
            "  324  765  200 1080 1051  297    3   80  425  289   32  823   89  479\n",
            "  992  199   64  965 1157  645  741  713  303  262  451  468 1133  317\n",
            "  852  157 1002 1040  246  690  443  416  583  314  249  706  209  231\n",
            "  980  719  851  537 1119  954  734 1007  454  124  667  938  589] (125,) [ 0.09717086  0.16452973  0.38688775  0.46083812  0.61513444  0.68427742\n",
            "  0.93624307  0.96948537  1.13605156  1.22004704  1.48301233  1.62490652\n",
            "  1.70299547  2.02135976  2.10182269  2.19861094  2.26699206  2.37664689\n",
            "  2.41114428  2.46904845  2.59339657  2.68259988  2.74028793  2.84669409\n",
            "  2.88869028  2.88869028  3.18552145  3.33000512  3.44826376  3.80444795\n",
            "  3.95179007  4.1794273   4.26991689  4.300258    4.36411607  4.66109966\n",
            "  4.6855779   4.6855779   4.90173807  4.92057556  4.95059449  5.09137146\n",
            "  5.13826264  5.21844162  5.29861161  5.4701944   5.47643266  5.51293604\n",
            "  5.63504145  5.7117797   5.86328023  6.10008937  6.27320656  6.86105932\n",
            "  6.94929426  7.07685054  7.36854965  7.41097184  7.42053435  7.50812441\n",
            "  7.85479038  8.21126237  8.36906862  8.65126125  8.67586736  8.73152158\n",
            "  8.76165798  8.76944579  8.8857177   8.99577478  9.01395468  9.09528578\n",
            "  9.24508625  9.37553484  9.57719307 10.03147893 10.27458626 10.31537465\n",
            " 10.71370984 10.72194711 10.83688358 11.15166159 11.49997088 11.59999814\n",
            " 11.6566356  11.78127431 11.85378952 11.85810587 11.91790975 12.0207054\n",
            " 12.0524037  12.34816936 12.75216799 12.77844054 12.7900446  13.51763291\n",
            " 13.73311553 14.14609753 14.24218153 14.41702379 14.78392939 14.82675034\n",
            " 14.93425015 15.03846295 15.06573852 15.19921764 15.19928931 15.21590137\n",
            " 15.53674076 15.68771823 15.75182471 16.18120064 16.26384883 16.42699993\n",
            " 16.4765002  16.52117255 16.60278799 16.63402933 16.72587976 16.72793266\n",
            " 16.7698746  17.09532772 17.20533218 17.27141033 17.27141033]\n",
            "trainset before adding uncertain samples (125, 10) (125,)\n",
            "trainset after adding uncertain samples (250, 10) (250,)\n",
            "updated train set: (250, 10) (250,) unique(labels): [ 89 161] [0 1]\n",
            "val set: (1052, 10) (1052,)\n",
            "\n",
            "Train set: (250, 10)\n",
            "Validation set: (1052, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.934 s \n",
            "\n",
            "Accuracy rate is 76.036866 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.85      0.84       321\n",
            "           1       0.54      0.50      0.52       113\n",
            "\n",
            "    accuracy                           0.76       434\n",
            "   macro avg       0.69      0.68      0.68       434\n",
            "weighted avg       0.76      0.76      0.76       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[273  48]\n",
            " [ 56  57]]\n",
            "--------------------------------\n",
            "val predicted: (1052,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1052, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "std (1052,) [40.9691512  42.93130062 48.0859275  ... 48.41168958 49.63872877\n",
            " 14.01539567]\n",
            "selection [ 496  856  892  535  936  340  989  866  450 1021  109  233 1012  633\n",
            "  829  682  799 1044  778  470  237  259  718  512  719  478  182   13\n",
            "  453  192  875  608  820  116 1035  854  428  851  324 1005  136   71\n",
            "  362 1006  775  941  257  993  760   24  652   28  483  768  813  960\n",
            "  369  138  858 1015  370  445  573   54  750  910  438  857  519 1027\n",
            "  147  745  782  557  723  312  355  439  194   93  643   97  343  740\n",
            "  106  999  658  443  556   59 1051  985  103  676  951 1001  466  873\n",
            "  290  611  959  744   44  724  709 1020  946   22  662 1010    5   52\n",
            "   41    7  510  847  207  922  680  839  117  541  403  205   35] (125,) [ 0.022115    0.0486171   0.25088544  0.40083278  0.4920735   0.5582294\n",
            "  0.60060587  0.95263176  1.17445073  1.33106977  1.66894753  1.96570909\n",
            "  2.07991648  2.18591644  2.24759743  2.32334335  2.48990324  2.57480907\n",
            "  2.61191695  2.6743558   2.73218673  3.06802914  3.44899518  3.80847008\n",
            "  4.10785924  4.31996886  4.3783757   4.4601426   4.5303099   4.93184008\n",
            "  5.28194715  5.41159196  5.52791268  5.72304025  5.83574139  5.85258462\n",
            "  5.85849872  6.00389167  6.27892864  6.8016893   6.95112191  7.08097046\n",
            "  7.17500371  7.35176105  7.51557068  7.6287202   7.65755742  7.66086384\n",
            "  7.7137913   7.73366244  8.07225334  8.08449381  8.32459604  8.46686414\n",
            "  8.46781872  8.59702313  8.67595179  8.70770567  9.49677713  9.51004098\n",
            "  9.59618973  9.60746146  9.77597174  9.931566    9.93707633  9.99872497\n",
            " 10.18984114 10.19656221 10.26136574 10.32835633 10.4208862  10.58068615\n",
            " 10.61688068 10.78735436 11.34650191 11.56000135 11.7878138  12.39165423\n",
            " 12.6149174  12.70615699 12.73134126 12.87294722 12.99801111 13.02004241\n",
            " 13.1272748  13.17565325 13.38886813 13.3983181  13.53533541 13.88457031\n",
            " 14.01539567 14.09860503 14.44841646 14.46358255 14.49683313 14.55392457\n",
            " 14.60220694 14.68022624 15.21999999 15.3579493  15.64173823 15.67900744\n",
            " 15.9033731  15.97394824 16.00132393 16.01632362 16.21181428 16.24272451\n",
            " 16.54729873 16.62167407 16.63469263 16.72044478 16.89834004 16.90868216\n",
            " 17.00579073 17.53455776 17.89086201 18.00382008 18.07238075 18.44953049\n",
            " 18.59222734 18.60540322 19.23113143 19.64435497 19.74206021]\n",
            "trainset before adding uncertain samples (250, 10) (250,)\n",
            "trainset after adding uncertain samples (375, 10) (375,)\n",
            "updated train set: (375, 10) (375,) unique(labels): [153 222] [0 1]\n",
            "val set: (927, 10) (927,)\n",
            "\n",
            "Train set: (375, 10)\n",
            "Validation set: (927, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 3\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.072 s \n",
            "\n",
            "Accuracy rate is 80.184332 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.88      0.87       321\n",
            "           1       0.63      0.58      0.61       113\n",
            "\n",
            "    accuracy                           0.80       434\n",
            "   macro avg       0.74      0.73      0.74       434\n",
            "weighted avg       0.80      0.80      0.80       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[282  39]\n",
            " [ 47  66]]\n",
            "--------------------------------\n",
            "val predicted: (927,) [0 1 1 0 1 0 1 1 0 0 0 0 0 1 1 1 0 0 1 0 0 0 0 1 1 0 1 1 0 0 0 1 1 0 0 0 0\n",
            " 1 1 0 0 0 1 0 1 1 1 1 0 1 1 1 0 0 0 1 1 0 0 1 1 1 1 0 1 1 0 1 0 1 0 0 1 0\n",
            " 0 1 0 1 1 1 1 1 1 0 1 0 1 1 0 0 0 0 0 1 0 0 1 1 1 1 0 1 0 0 1 0 0 0 1 0 0\n",
            " 0 0 0 1 0 0 1 0 0 1 1 1 0 0 1 1 0 1 0 1 0 0 1 1 0 1 1 1 1 0 0 1 0 0 0 1 1\n",
            " 1 1 1 0 1 1 0 1 0 0 1 1 0 1 1 1 0 0 0 0 0 1 1 1 0 0 0 0 0 0 1 0 0 0 1 0 1\n",
            " 0 1 1 0 1 0 0 1 0 0 0 0 0 1 1 0 1 1 1 1 1 1 0 0 1 0 1 1 1 1 1 0 1 1 0 1 1\n",
            " 1 0 1 0 0 1 0 1 1 1 1 1 1 0 0 0 1 1 0 0 0 0 0 1 1 1 0 0 0 1 0 1 0 1 0 1 0\n",
            " 0 0 1 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 1 1 0 1 1 0 0 1 0 1 0 0 0 0 1 1 0 0 1\n",
            " 0 0 1 0 1 0 0 1 0 1 0 1 1 0 0 1 1 1 0 1 0 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1\n",
            " 0 0 1 0 0 1 0 1 1 0 0 1 1 0 1 0 1 0 1 0 0 1 1 1 0 1 0 1 0 1 0 1 0 1 1 0 1\n",
            " 1 0 1 0 1 1 1 0 1 1 0 0 0 1 0 0 1 0 0 1 0 0 0 1 0 0 0 1 0 0 1 0 1 1 0 1 0\n",
            " 1 1 1 1 0 1 0 1 0 1 0 0 0 0 0 0 1 1 1 1 0 0 0 1 0 1 1 0 0 1 0 0 1 0 0 0 1\n",
            " 0 0 0 1 0 1 0 0 1 1 0 0 1 1 0 1 0 1 0 1 1 0 0 1 1 1 1 1 0 0 1 0 0 1 1 0 0\n",
            " 1 0 1 1 1 0 0 0 1 0 1 0 0 1 0 0 0 1 0 1 0 1 0 1 1 0 1 1 0 1 1 0 1 1 1 1 0\n",
            " 1 0 1 1 1 1 1 0 0 0 1 0 1 1 1 1 1 0 1 1 1 1 0 1 0 0 0 0 1 0 0 1 0 1 0 1 1\n",
            " 1 0 1 1 1 1 0 0 1 0 1 0 1 0 1 0 0 0 0 0 1 1 1 1 1 1 0 0 0 0 1 1 0 1 0 1 0\n",
            " 1 0 1 0 1 0 0 1 1 0 1 1 1 1 1 0 0 1 0 0 1 1 1 0 0 0 1 1 1 0 0 1 1 1 0 0 1\n",
            " 0 1 1 1 0 0 1 1 1 0 1 0 0 1 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 1 0 1 0 0 1 1\n",
            " 0 1 0 0 1 1 1 0 0 0 0 1 0 1 1 1 1 1 1 0 0 0 0 0 1 0 1 1 1 0 1 1 1 1 0 1 1\n",
            " 0 0 0 0 1 0 0 1 1 0 1 0 0 0 0 0 1 0 0 1 1 0 0 0 0 1 0 0 1 1 1 0 0 0 0 1 0\n",
            " 0 0 1 0 1 0 0 0 1 1 1 0 0 0 1 0 0 0 0 0 1 0 1 1 1 1 0 0 0 1 0 1 1 1 1 0 0\n",
            " 0 0 1 0 0 1 1 0 1 1 1 0 1 0 0 0 0 0 1 0 1 0 1 0 1 1 0 0 0 1 1 0 0 1 1 1 0\n",
            " 0 0 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 1 0 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1\n",
            " 1 0 1 0 0 1 1 0 1 0 0 0 1 0 1 1 0 1 0 0 0 1 0 1 0 1 0 1 1 0 1 1 1 1 1 1 1\n",
            " 0 0 0 0 1 1 0 0 1 0 1 1 0 1 0 1 1 1 0 1 0 0 1 1 1 0 0 1 1 0 0 1 0 1 1 1 0\n",
            " 0 0]\n",
            "probabilities: (927, 2) \n",
            " [0 1 1 0 1 0 1 1 0 0 0 0 0 1 1 1 0 0 1 0 0 0 0 1 1 0 1 1 0 0 0 1 1 0 0 0 0\n",
            " 1 1 0 0 0 1 0 1 1 1 1 0 1 1 1 0 0 0 1 1 0 0 1 1 1 1 0 1 1 0 1 0 1 0 0 1 0\n",
            " 0 1 0 1 1 1 1 1 1 0 1 0 1 1 0 0 0 0 0 1 0 0 1 1 1 1 0 1 0 0 1 0 0 0 1 0 0\n",
            " 0 0 0 1 0 0 1 0 0 1 1 1 0 0 1 1 0 1 0 1 0 0 1 1 0 1 1 1 1 0 0 1 0 0 0 1 1\n",
            " 1 1 1 0 1 1 0 1 0 0 1 1 0 1 1 1 0 0 0 0 0 1 1 1 0 0 0 0 0 0 1 0 0 0 1 0 1\n",
            " 0 1 1 0 1 0 0 1 0 0 0 0 0 1 1 0 1 1 1 1 1 1 0 0 1 0 1 1 1 1 1 0 1 1 0 1 1\n",
            " 1 0 1 0 0 1 0 1 1 1 1 1 1 0 0 0 1 1 0 0 0 0 0 1 1 1 0 0 0 1 0 1 0 1 0 1 0\n",
            " 0 0 1 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 1 1 0 1 1 0 0 1 0 1 0 0 0 0 1 1 0 0 1\n",
            " 0 0 1 0 1 0 0 1 0 1 0 1 1 0 0 1 1 1 0 1 0 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1\n",
            " 0 0 1 0 0 1 0 1 1 0 0 1 1 0 1 0 1 0 1 0 0 1 1 1 0 1 0 1 0 1 0 1 0 1 1 0 1\n",
            " 1 0 1 0 1 1 1 0 1 1 0 0 0 1 0 0 1 0 0 1 0 0 0 1 0 0 0 1 0 0 1 0 1 1 0 1 0\n",
            " 1 1 1 1 0 1 0 1 0 1 0 0 0 0 0 0 1 1 1 1 0 0 0 1 0 1 1 0 0 1 0 0 1 0 0 0 1\n",
            " 0 0 0 1 0 1 0 0 1 1 0 0 1 1 0 1 0 1 0 1 1 0 0 1 1 1 1 1 0 0 1 0 0 1 1 0 0\n",
            " 1 0 1 1 1 0 0 0 1 0 1 0 0 1 0 0 0 1 0 1 0 1 0 1 1 0 1 1 0 1 1 0 1 1 1 1 0\n",
            " 1 0 1 1 1 1 1 0 0 0 1 0 1 1 1 1 1 0 1 1 1 1 0 1 0 0 0 0 1 0 0 1 0 1 0 1 1\n",
            " 1 0 1 1 1 1 0 0 1 0 1 0 1 0 1 0 0 0 0 0 1 1 1 1 1 1 0 0 0 0 1 1 0 1 0 1 0\n",
            " 1 0 1 0 1 0 0 1 1 0 1 1 1 1 1 0 0 1 0 0 1 1 1 0 0 0 1 1 1 0 0 1 1 1 0 0 1\n",
            " 0 1 1 1 0 0 1 1 1 0 1 0 0 1 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 1 0 1 0 0 1 1\n",
            " 0 1 0 0 1 1 1 0 0 0 0 1 0 1 1 1 1 1 1 0 0 0 0 0 1 0 1 1 1 0 1 1 1 1 0 1 1\n",
            " 0 0 0 0 1 0 0 1 1 0 1 0 0 0 0 0 1 0 0 1 1 0 0 0 0 1 0 0 1 1 1 0 0 0 0 1 0\n",
            " 0 0 1 0 1 0 0 0 1 1 1 0 0 0 1 0 0 0 0 0 1 0 1 1 1 1 0 0 0 1 0 1 1 1 1 0 0\n",
            " 0 0 1 0 0 1 1 0 1 1 1 0 1 0 0 0 0 0 1 0 1 0 1 0 1 1 0 0 0 1 1 0 0 1 1 1 0\n",
            " 0 0 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 1 0 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1\n",
            " 1 0 1 0 0 1 1 0 1 0 0 0 1 0 1 1 0 1 0 0 0 1 0 1 0 1 0 1 1 0 1 1 1 1 1 1 1\n",
            " 0 0 0 0 1 1 0 0 1 0 1 1 0 1 0 1 1 1 0 1 0 0 1 1 1 0 0 1 1 0 0 1 0 1 1 1 0\n",
            " 0 0]\n",
            "std (927,) [34.92152206 33.11329121 47.59227018 38.22395865 46.13010997 38.78467259\n",
            " 49.16888048 45.04248429 21.46478707 43.01228596 47.9721268  11.35873887\n",
            " 49.73476039 32.35087556 49.14675755 41.18129376 46.85008842 40.67306899\n",
            " 36.82697932 48.03046177 42.18672122 45.86397149 45.98392699 48.15787973\n",
            " 48.25361145 40.67306899 48.04110564 46.29996965 20.67131546 41.12250098\n",
            " 28.02966067 45.16616038 39.50695994 49.0423742  30.17393186 17.48436704\n",
            " 42.95351073 11.638622   45.50327015 40.23010769 47.41218879 33.94598529\n",
            " 46.44597215 39.65907012 45.46159406 44.45926016 41.67903644 48.78272312\n",
            " 44.41244111 48.99204684 35.8843292  45.27232152 45.81798753 39.09395878\n",
            " 33.23166856 42.87961226 48.55416388 44.90890108 49.29813827 42.49280214\n",
            " 47.33633538 48.24951867 47.1725513  48.81583361 33.73550852 46.35804774\n",
            " 15.2882839  48.6313218  48.87671897 44.80219853 36.9321531   5.05882838\n",
            "  4.09263989 47.92598079 40.97685394 46.0967254  48.76503617 10.14494052\n",
            " 46.4474124  48.04107389 28.82202    49.0279603  40.93939472 45.25368632\n",
            " 29.51347615 40.67306899 48.55770725 38.12899208 48.89932936 47.76901439\n",
            " 49.48488924 32.53951553 22.32857637 48.56307465 32.18561632 47.55998941\n",
            " 48.35371912 48.05652192 39.01206559 48.80679664 42.81875091 45.6609447\n",
            " 42.03360453 45.98017454 42.5125477  48.62261902 33.03240671 48.82889513\n",
            " 39.25705175 35.67183683 48.62820752 47.51069569 19.59385665 40.67306899\n",
            " 46.02996037 31.98757543 49.48624073 43.27965807 32.36002121 42.72939062\n",
            " 48.12602942 20.08646278 46.70671282 36.6038164  42.72658974 19.6034267\n",
            " 43.77276941 37.63078663 45.48487357 42.64675993 48.54109919 45.81135441\n",
            " 40.67306899 48.99444573 46.63889232 48.47954521 47.96571981 33.81415312\n",
            " 47.57696802 48.57408413 46.81656806 44.98244326 46.92457193 28.26891314\n",
            " 49.30013815 34.78864828 24.60112839 48.58332575 47.00183311 44.29036226\n",
            " 42.79087036 42.80962539 40.7964506  42.74097567 48.88293946 43.32451859\n",
            " 48.95269148 40.67306899 42.40487389 41.52152485 24.82182715 47.39662599\n",
            " 45.49237631 47.29568087 47.67851656 27.60442517 46.57828341 37.85139273\n",
            " 38.98589464 45.72779523 46.99600211 47.38547099 44.29890522 47.94556278\n",
            " 23.5300486  42.18782263 47.12647267 48.37106226 48.32245397 47.69314033\n",
            " 49.13235093 44.44117044 13.45400859 40.67306899 42.55479138 48.024818\n",
            " 42.52629823 41.34831344 48.527047   49.15882165 45.53262006 27.77407945\n",
            " 46.35066945 10.41477345 45.46082226 46.59060836 49.77076422 47.21263191\n",
            " 29.36260171 49.29711919 46.95778545 40.41719166 47.42494939 42.78642834\n",
            " 42.27589196 44.11005434 40.45679161 47.05336727 48.76704551 47.17976625\n",
            " 39.47800319 46.99726009 41.59244777 46.35378512 48.40391691 43.49770519\n",
            " 47.98816202 44.28957855 48.88084058 48.40718306 49.24222439 45.35969434\n",
            " 17.86965065 44.83052905 49.01276007 48.18938279 15.0618754  48.32023307\n",
            " 42.76949839 49.13434529 47.30433026 45.52503679 36.68302091 44.22332469\n",
            " 44.20470101  5.03587438 48.4938458  48.31995209 21.97585504 38.1632075\n",
            " 47.65741192 47.95375809 42.95202352 43.54828686 35.28490682 40.61693991\n",
            " 47.39835683 49.37549042 35.62037666 47.74582359 44.19265328 19.42235186\n",
            "  6.32957755 47.34455873 40.67306899 48.87422526 49.61346205 16.36320361\n",
            " 48.66639345 49.13780666 44.07403012 48.53177104 46.7446538  46.33886872\n",
            " 33.46765794 41.9504166  40.23965973 49.53178943 47.59896502 43.64416404\n",
            " 44.87382036 48.0125805  47.29965191 48.09366759 46.75584127 36.48392134\n",
            " 24.59085656 35.03855519 47.15334944 40.67306899 47.56431154 46.33869474\n",
            " 48.87671897 27.88847153 47.10221725 47.78156888 32.53706473 36.84988107\n",
            " 19.75712551 40.95990424  9.2097448  43.40766079 42.02123263  3.85592904\n",
            " 49.24247261 48.86975227 45.34975688 10.2588944   2.32638493 48.69062167\n",
            " 43.53427357 40.67306899 45.18657421 48.7815182  42.90339676 46.28008004\n",
            " 43.79876783 46.00400664 38.48048005 48.55728619 48.59222359 46.82017429\n",
            " 48.33011135 28.50208232 39.23550414 37.27319931 48.04411771 46.54590092\n",
            " 47.0718379  43.49824673 48.97536145 44.8797011  48.97456662 48.40023885\n",
            " 26.92158135 48.22301052 46.87014183 46.68077569  5.00990073 48.16666701\n",
            " 46.20425244 46.63622463 48.12945362 46.35738459 48.56654337 49.05459928\n",
            " 48.51387671 35.875991   40.26345623 49.50477027 41.97771539 44.79718682\n",
            " 41.35342735 35.39187533 45.3127126  46.52361467 40.67306899  9.62910839\n",
            " 40.67306899 47.90502263 45.73548898 48.63905413 49.1290334  13.86217352\n",
            " 48.50397464 47.01376011 47.57164884 47.98723741 38.71129313 40.34422299\n",
            " 44.20187145 13.48116837 48.90826764 24.55885647 47.11702146 44.33541879\n",
            " 45.20551923 46.03770322 49.65284653 31.35809605 48.36184931 48.49882369\n",
            " 47.28559252 16.74410711 47.30211296 45.83865101 35.68087731 33.56062396\n",
            " 48.38576208 35.88408202 49.35284344 41.24240414 44.32228905 47.42677835\n",
            " 49.47981428 26.1579088  43.78834049 43.09022303 40.67306899 48.00791768\n",
            " 42.61876799 43.80737302 33.22608386 31.60766829 32.13253014 47.95911257\n",
            "  2.57599002 48.86698065 43.26083557 11.90297948 48.5774054  39.42150835\n",
            " 42.14092001 48.15360784 26.06209986 48.43109571 19.79825317 45.80781866\n",
            " 36.24307013 27.98057646 46.76222537 24.26253339 40.89794273 44.71973626\n",
            " 44.17156035 49.09638821 48.75869815 47.30844963 39.64139961 48.83765302\n",
            " 46.72639216 49.40550451 44.15785651 46.52647779 44.35487701 48.65159564\n",
            " 45.94462126 46.6997348  49.07154488 49.31484867 46.04837959 44.72864404\n",
            " 46.06711367 29.94964696 20.65804341 48.35638423 45.24792589 47.17238391\n",
            " 39.31076046 38.57929713 45.79739723 33.89260065 35.26272116 35.48766341\n",
            " 48.63346369 40.67306899  6.26312069 30.23859646 49.00930428 47.85535638\n",
            " 29.7868041  44.6295104  19.30857331 10.29989996 40.67306899 16.08473626\n",
            " 41.88245627 36.67038511 49.09026099 39.07058904 49.50838093 25.22543659\n",
            " 48.08551458 48.22897904 48.95273291 37.72903402 31.21019266 41.71414997\n",
            " 36.21684733 42.95078978 46.82790463 46.65252193 36.51039755 43.12928444\n",
            " 49.07065044 49.08191445 46.63040724 48.90823762 29.94001121 36.21835708\n",
            " 47.65173392 48.67213723 43.98094111 45.42569304 49.029777   14.88347511\n",
            " 40.67306899 40.67306899 23.90155544 37.42856747 27.44065738 47.25035036\n",
            " 43.56302875 38.86624633 48.46333377 36.39834493 47.41177879 48.56585194\n",
            " 46.46926738 34.07968223 46.30096388 46.46153402 48.97157483 42.7589243\n",
            " 46.31971832 47.50840402 48.2368409  37.28611693 37.27319931 44.50654712\n",
            " 47.17552232 48.11927513 48.43949811 48.27466836 26.15406908 45.76179814\n",
            " 48.81116843 38.64727721 48.38564414 37.34923933 44.76075622 43.79206862\n",
            " 49.06052977 48.58252477 48.42630356 48.75935601 45.31673839 29.58071156\n",
            " 39.12400907 47.58800452 27.03335428 49.24057538 40.69698012 21.55064071\n",
            " 48.85502607  9.89064659 41.37124196 44.82257661 38.90906825 48.49216246\n",
            " 42.30302071 41.93018445 49.11211297 42.02107598 30.44710102 45.82007508\n",
            " 47.89700305 43.42436658 49.55613346 31.39934202 42.9091893  48.30444293\n",
            " 49.23936842 47.15549764 36.10818351 46.93395286 36.44592869 48.49622834\n",
            " 43.20825711 31.80703444 47.28649459 35.82271832 34.73716802 46.91948476\n",
            " 34.96102766 47.32955035 48.91836475  7.0764288  48.50223473 44.42213237\n",
            " 46.22035917 44.03737943 37.47997948 44.40013117 45.1181314  35.52426664\n",
            " 47.7383916  24.65806113  0.93556482 47.40731011 44.05391088  9.08128713\n",
            " 37.79503071 46.71418349 38.4220022  47.83627681 43.13838429 48.03342899\n",
            " 41.6284662  49.43721809 47.20302472 31.95502237 42.22125331 48.21635407\n",
            " 46.42913827 49.58482585 42.34934181 49.62086581 40.42735357 37.21440926\n",
            " 47.88647967 47.51982516 48.95081751 47.72495636 49.31393533 39.07468966\n",
            " 44.53897852 26.76808749 41.57799987 47.62360303 35.02680755 43.13863325\n",
            " 36.02692825 47.84851978 43.39833349 45.26894778 49.15529831 44.36795554\n",
            " 10.242218   14.3694661  46.75584127 48.11730241 47.68458429 35.748638\n",
            " 49.15092211 48.60713083 40.39438768  2.3959195  41.39683644 43.89057085\n",
            " 48.23297457 46.98311838 42.87882432 24.00063996 43.20816602 43.35417498\n",
            " 31.98965501 47.23851759 46.22824786 39.80521324 40.67306899 35.0827329\n",
            " 46.93467206 48.27189039 31.0073464  40.67306899 40.67306899 44.94230369\n",
            " 40.35491461 48.33841928 39.6593951  49.18416038 25.69398624 48.3782479\n",
            " 47.07956731 39.37775033 48.01930896 48.63514857 24.2017969  32.35087556\n",
            "  3.14124039 46.20738416 43.0448868  33.76133443 48.20379016  1.40205618\n",
            " 31.45914195 49.02612988 40.80657529 48.56155374 41.69001413 45.5162074\n",
            "  0.24585193 22.96812096 47.95933752  0.58228516 47.76925318 48.62407669\n",
            "  7.16315955 48.20246747 39.65774229 47.42424335 47.95068388 46.08588399\n",
            " 39.71212152 33.34698549 23.80273003 48.33145372  9.80216204 48.69310089\n",
            " 49.05493642 42.88646265 45.97329553 47.14345164 46.84826579 23.89849295\n",
            " 27.69576211 47.7920159  49.19463316 45.29009717 27.1034308   6.46843443\n",
            " 22.99884182 48.51917584 40.67306899 14.85087904 47.66105771 48.63395569\n",
            " 26.41371815 49.01620075 36.91723862 47.8184959  38.26938294 38.98404097\n",
            " 40.66311874 46.76737395 46.56258203 48.90814625 47.72147691 47.75823406\n",
            " 20.82153484 31.69489354 42.4599364  44.86651003 49.46683807 42.16720665\n",
            " 49.22295622 40.67306899 47.7830994  49.16219673 48.23654027 47.50656471\n",
            " 41.40557465 48.49453126 46.44027602 44.16037625 44.46816455 47.99255335\n",
            " 41.58641599 45.31358417 46.39100042  7.06995694  2.40511117 48.80679577\n",
            " 47.43988128 29.73642943 47.40162232 46.87557671 48.60800221 47.61049498\n",
            " 46.44762659 48.45982004 33.6531161  48.15858538 34.19767144 49.53930735\n",
            " 47.09015455 33.7026382  47.74116453 48.32389467 45.169242   18.73294024\n",
            " 31.14207292 44.207075   37.49133017 38.15340489  4.86405249 49.36808711\n",
            "  9.65583192 37.59989626 48.9992941  27.52681764 42.57280367 48.62276146\n",
            " 23.05225187 36.629109   48.50405082 41.64447913 38.67485134 47.41451295\n",
            " 37.9687968  48.31722781 30.64560291 37.54040508 45.22781051 47.12782768\n",
            " 47.68444898 48.34657497 49.49658306 36.90367764 49.3076812  49.12918292\n",
            " 49.04679454 46.16606564 33.52054191 48.76278567 41.83726716 44.75760771\n",
            " 45.92752752 48.33347547 48.24851997 32.85154877 47.72670295 49.09671578\n",
            " 46.77329662  8.60032451 48.92255318 27.82841898 38.46196594 10.10176322\n",
            " 47.44135109 47.43750031 27.62422314 47.999172   28.54076597 40.67306899\n",
            " 46.93968812 44.0920988  36.82697932 46.20738416 49.15470446 48.35876892\n",
            " 44.27668931 47.70339618 44.11005434 46.46926738 44.2156578  46.97084317\n",
            " 43.7570723  34.04922024 47.47015074 48.74690436 43.64417556 40.93939472\n",
            " 46.77454286 16.6338339  47.63895011 49.01094587 47.38660118 47.31176934\n",
            " 45.28363809 29.60319112 44.30649893 48.01565894 45.86655554 46.66905015\n",
            " 43.30335734 47.26664732 46.96625794 34.25510243 46.84446189  4.62714387\n",
            " 46.67300034 48.36769449 48.85646661 40.67306899 48.10247842 47.37479813\n",
            " 47.76549029 25.69974882 40.49022187 40.67306899 49.05092853 48.54848426\n",
            " 47.76775991 49.01259814 47.53028836 21.74287604 48.35209951 43.66738303\n",
            " 48.61815008 44.83972082 46.82472434 37.31281134 45.94082666 43.90740404\n",
            " 46.27023061 32.79809273 42.85839308 48.58802195 48.48017526 46.06889658\n",
            " 46.73771203 40.13168284 49.05421641 47.21762047 45.18084543 24.81522157\n",
            " 45.68472248 36.39296224 40.77091854 48.70018306 44.08823785 48.40485439\n",
            " 47.55343349 47.38455387  3.03447698 45.83807112 47.49163073 45.01945666\n",
            " 26.91593806 38.95132006 19.99657315 32.72841356 47.5438669  48.31442201\n",
            " 48.02750892 40.64532104 42.27901963 40.67306899 44.80313241 24.39029767\n",
            "  1.9804942  23.18286972 40.67306899 45.15503708 12.85088074 49.58529673\n",
            " 48.15353689 48.95030255 48.23122886 47.90670692 41.6154061  42.00638688\n",
            " 16.64146596 42.97619445 48.59027039]\n",
            "selection [672 675 578 665 912 298 627 742 396 896 660 293  72 851 766 328 235  71\n",
            " 446 252 701 741 567 678 805 581 290 347 768 688 535 809  77 618 297 453\n",
            " 193  11  37 399 916 182 361 353 619 705 485 226  66 455 257 835 924 373\n",
            "  35 222 761 452 251 112 125 288 406 902 121 434  28 720   8 533 867 238\n",
            "  92 673 702 774 913 174 686 695 488 633 658 411 911 363 276 146 577 887\n",
            " 160 461 652 859 404 514 385 708 607 900 324 530 700 490 771 165 812 696\n",
            " 191 807 283 409  30 143 313 814  80 198  84 527 841 745 450 478 433] (125,) [ 0.24585193  0.58228516  0.93556482  1.40205618  1.9804942   2.32638493\n",
            "  2.3959195   2.40511117  2.57599002  3.03447698  3.14124039  3.85592904\n",
            "  4.09263989  4.62714387  4.86405249  5.00990073  5.03587438  5.05882838\n",
            "  6.26312069  6.32957755  6.46843443  7.06995694  7.0764288   7.16315955\n",
            "  8.60032451  9.08128713  9.2097448   9.62910839  9.65583192  9.80216204\n",
            "  9.89064659 10.10176322 10.14494052 10.242218   10.2588944  10.29989996\n",
            " 10.41477345 11.35873887 11.638622   11.90297948 12.85088074 13.45400859\n",
            " 13.48116837 13.86217352 14.3694661  14.85087904 14.88347511 15.0618754\n",
            " 15.2882839  16.08473626 16.36320361 16.6338339  16.64146596 16.74410711\n",
            " 17.48436704 17.86965065 18.73294024 19.30857331 19.42235186 19.59385665\n",
            " 19.6034267  19.75712551 19.79825317 19.99657315 20.08646278 20.65804341\n",
            " 20.67131546 20.82153484 21.46478707 21.55064071 21.74287604 21.97585504\n",
            " 22.32857637 22.96812096 22.99884182 23.05225187 23.18286972 23.5300486\n",
            " 23.80273003 23.89849295 23.90155544 24.00063996 24.2017969  24.26253339\n",
            " 24.39029767 24.55885647 24.59085656 24.60112839 24.65806113 24.81522157\n",
            " 24.82182715 25.22543659 25.69398624 25.69974882 26.06209986 26.15406908\n",
            " 26.1579088  26.41371815 26.76808749 26.91593806 26.92158135 27.03335428\n",
            " 27.1034308  27.44065738 27.52681764 27.60442517 27.62422314 27.69576211\n",
            " 27.77407945 27.82841898 27.88847153 27.98057646 28.02966067 28.26891314\n",
            " 28.50208232 28.54076597 28.82202    29.36260171 29.51347615 29.58071156\n",
            " 29.60319112 29.73642943 29.7868041  29.94001121 29.94964696]\n",
            "trainset before adding uncertain samples (375, 10) (375,)\n",
            "trainset after adding uncertain samples (500, 10) (500,)\n",
            "updated train set: (500, 10) (500,) unique(labels): [224 276] [0 1]\n",
            "val set: (802, 10) (802,)\n",
            "\n",
            "Train set: (500, 10)\n",
            "Validation set: (802, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 4\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.245 s \n",
            "\n",
            "Accuracy rate is 79.723502 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.87      0.86       321\n",
            "           1       0.62      0.58      0.60       113\n",
            "\n",
            "    accuracy                           0.80       434\n",
            "   macro avg       0.74      0.73      0.73       434\n",
            "weighted avg       0.79      0.80      0.80       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[280  41]\n",
            " [ 47  66]]\n",
            "--------------------------------\n",
            "final active learning accuracies [78.3410138248848, 76.036866359447, 80.18433179723502, 79.72350230414746]\n",
            "saved /Users/wenxuanhuang/Documents/Repo/ML-for-COVID-19-dataset/Results/Active-learning-experiment-17.pkl /Users/wenxuanhuang/Documents/Repo/ML-for-COVID-19-dataset ['Decision_tree.ipynb', 'dec_git.png', 'Logit_default_f10.pdf', 'Logistic.ipynb', 'SVC.ipynb', 'RF_f5e50_featureimp.pdf', 'log_al.png', 'dec_git.pdf', '.DS_Store', 'log_git.png', 'svm_git.png', 'Logistic_Scikit.ipynb', 'knn_git.pdf', 'knn_git.png', 'rf_al.png', 'Best classifier_RF_f5e50.pdf', 'KNN.ipynb', 'GBDC.ipynb', 'rf_git.png', 'README.md', 'all_training.csv', 'Results', 'svm_al.png', 'Log_ROC.png', 'Logit_default_f7(p_removal).pdf', 'Active_learning.ipynb', 'Random_forest.ipynb', 'Model_select.ipynb', 'gdbc_git.png', '.git', '.vscode', 'Untitled', 'RF_f5e50_modelselect.pdf', 'Logit_default_f8(std_removal).pdf']\n",
            "\n",
            "---------------------------- FINISHED ---------------------------\n",
            "\n",
            "Count = 18, using model = GDBCModel, selection_function = MinStdSelection, k = 50, iteration = 0.\n",
            "\n",
            "initial random chosen samples (50,)\n",
            "initial train set: (50, 10) (50,) unique(labels): [25 25] [0 1]\n",
            "Val set: (1252, 10) (1252,) (50,)\n",
            "\n",
            "Train set: (50, 10)\n",
            "Validation set: (1252, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.705 s \n",
            "\n",
            "Accuracy rate is 79.953917 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.93      0.87       321\n",
            "           1       0.69      0.42      0.52       113\n",
            "\n",
            "    accuracy                           0.80       434\n",
            "   macro avg       0.76      0.68      0.70       434\n",
            "weighted avg       0.79      0.80      0.78       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[300  21]\n",
            " [ 66  47]]\n",
            "--------------------------------\n",
            "val predicted: (1252,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1252, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "std (1252,) [49.98275058 39.74677927 49.93974241 ... 48.18169736 49.99826215\n",
            " 48.00541389]\n",
            "selection [1089  103  178  791  461  339  263  564  413  347 1098  811  147  212\n",
            "  760  361  585  569   41 1246  311 1136  307  449  774  595   99  109\n",
            "  939  376  180  847 1222  634  761  548   78 1018  506 1239  410  979\n",
            "   95  303  415  332 1151 1054  148  146] (50,) [ 0.01453075  0.29384746  0.53198004  0.58618289  1.19657769  1.35540988\n",
            "  1.50087767  1.71362442  1.84293504  1.87939957  2.52963643  3.30400618\n",
            "  3.53570846  3.79431638  3.84156855  4.02448284  4.41484503  4.68260012\n",
            "  4.68804032  4.93107538  4.95047377  5.2447783   5.70099379  6.0267518\n",
            "  6.16049291  6.5817638   6.69514317  6.83089029  7.34659735  7.50093985\n",
            "  7.51789743  7.77944279  7.8331511   7.94469354  8.0168235   8.09732927\n",
            "  8.1665145   8.20270709  8.27475526  8.29987742  8.3985965   8.45123788\n",
            "  8.46413057  8.6699113   9.02823768  9.32922432  9.39704804  9.67163118\n",
            " 10.33755051 10.34808496]\n",
            "trainset before adding uncertain samples (50, 10) (50,)\n",
            "trainset after adding uncertain samples (100, 10) (100,)\n",
            "updated train set: (100, 10) (100,) unique(labels): [45 55] [0 1]\n",
            "val set: (1202, 10) (1202,)\n",
            "\n",
            "Train set: (100, 10)\n",
            "Validation set: (1202, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.761 s \n",
            "\n",
            "Accuracy rate is 76.958525 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.87      0.85       321\n",
            "           1       0.57      0.49      0.52       113\n",
            "\n",
            "    accuracy                           0.77       434\n",
            "   macro avg       0.70      0.68      0.69       434\n",
            "weighted avg       0.76      0.77      0.76       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[279  42]\n",
            " [ 58  55]]\n",
            "--------------------------------\n",
            "val predicted: (1202,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1202, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "std (1202,) [49.84811105 49.46220131 49.8585183  ... 43.06805556 49.94341918\n",
            " 49.83004298]\n",
            "selection [1032  681 1050  697 1186  228  699  272   53  783  180  856 1133  452\n",
            "  210  924  321  110 1188  790  887  683  721  935 1066  839   18  868\n",
            " 1051  217  805  265 1033  530  962   92  213   52  820 1041  154  171\n",
            "  247  662  522 1077  593  592 1194  866] (50,) [0.02063687 0.08824302 0.35890309 1.6945427  1.83108306 1.95337551\n",
            " 2.18733639 2.22335502 2.66193544 2.89314433 3.12246819 3.47370145\n",
            " 3.68719978 3.7717128  4.00762009 4.26378764 4.44337269 4.46748755\n",
            " 4.54445756 4.59391535 4.90369331 4.91192745 5.01824661 5.16271192\n",
            " 5.35826368 5.64239008 5.64239008 5.70750844 6.04821294 6.05400781\n",
            " 6.13647991 6.59935667 6.77282093 6.91994524 6.94367988 6.96276194\n",
            " 7.09327736 7.39468695 7.45628307 7.49410026 7.78281801 7.9184693\n",
            " 7.9906212  8.03489888 8.24463989 8.26465474 8.6221138  8.866623\n",
            " 9.57080274 9.86488183]\n",
            "trainset before adding uncertain samples (100, 10) (100,)\n",
            "trainset after adding uncertain samples (150, 10) (150,)\n",
            "updated train set: (150, 10) (150,) unique(labels): [68 82] [0 1]\n",
            "val set: (1152, 10) (1152,)\n",
            "\n",
            "Train set: (150, 10)\n",
            "Validation set: (1152, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 3\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.918 s \n",
            "\n",
            "Accuracy rate is 80.184332 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.90      0.87       321\n",
            "           1       0.65      0.51      0.57       113\n",
            "\n",
            "    accuracy                           0.80       434\n",
            "   macro avg       0.75      0.71      0.72       434\n",
            "weighted avg       0.79      0.80      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[290  31]\n",
            " [ 55  58]]\n",
            "--------------------------------\n",
            "val predicted: (1152,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1152, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "std (1152,) [49.55391426 49.16922189 49.65546878 ... 47.30069795 49.76098301\n",
            " 47.67400503]\n",
            "selection [  33  410  384  267  978  158 1011   91  485  846   58  855  579  520\n",
            "  937  570  917  197 1018  151  473  811   56  810 1098  241 1132  762\n",
            " 1140  753 1103  479  512   49 1055 1039  539 1006  607  461  208  409\n",
            "  260  639  220  435  105  827 1091   65] (50,) [ 0.23252246  0.28810124  0.29786559  0.34242577  0.34242577  0.39657826\n",
            "  0.56772916  1.0067809   1.35078314  1.47625795  1.57189016  2.02467376\n",
            "  2.1603532   2.16048912  2.35798461  2.54100732  2.71294866  3.04638505\n",
            "  3.35007332  3.43005813  3.63989367  3.64129517  3.99107503  4.08432021\n",
            "  4.14199262  4.44069337  4.45219735  5.26617265  5.73178658  5.84462629\n",
            "  5.90519058  6.26948805  6.26948805  6.49893599  6.81475998  7.06308772\n",
            "  7.06644941  7.54806118  8.22940282  8.44764819  8.60018469  8.60734815\n",
            "  8.75285546  8.96357999 10.05845504 10.23692609 10.24162965 10.37643569\n",
            " 10.3824212  10.46014082]\n",
            "trainset before adding uncertain samples (150, 10) (150,)\n",
            "trainset after adding uncertain samples (200, 10) (200,)\n",
            "updated train set: (200, 10) (200,) unique(labels): [ 89 111] [0 1]\n",
            "val set: (1102, 10) (1102,)\n",
            "\n",
            "Train set: (200, 10)\n",
            "Validation set: (1102, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 4\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.941 s \n",
            "\n",
            "Accuracy rate is 79.493088 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.88      0.86       321\n",
            "           1       0.62      0.55      0.58       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.73      0.72      0.72       434\n",
            "weighted avg       0.79      0.79      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[283  38]\n",
            " [ 51  62]]\n",
            "--------------------------------\n",
            "val predicted: (1102,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1102, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "std (1102,) [45.74326492 49.27423048 49.52021323 ... 48.3369754  49.79316601\n",
            " 39.05677519]\n",
            "selection [ 283  775   13  105  240 1000  781  779  121  685  680  838  801   26\n",
            "    8  799  893  533 1054   28  917  903  483  542 1091 1039 1067  343\n",
            "  455  285  183  938  430  874  291  425  906 1077  836  310  406  131\n",
            "  206  899  250  135  301  866  902  913] (50,) [ 0.49762352  0.51889839  0.73439375  1.41608464  1.63228116  2.56530079\n",
            "  2.73771354  3.93322274  4.05814799  4.58319277  4.75515186  4.91927766\n",
            "  5.56567843  5.68592548  6.10064414  6.24892136  6.56171059  6.61985655\n",
            "  6.79804775  7.28753464  7.49437065  7.7151342   8.26216437  8.35313873\n",
            "  8.63845833  9.0522884   9.13520912  9.28777086  9.39300574  9.53831375\n",
            "  9.57776448  9.96347549 10.10240379 10.20435141 10.7619222  10.78063745\n",
            " 11.43557724 11.53590939 11.93106136 13.03679829 13.07166718 13.91045693\n",
            " 14.46721417 14.5424426  14.67576024 15.83556904 16.51042304 16.52504959\n",
            " 16.82038445 17.00601676]\n",
            "trainset before adding uncertain samples (200, 10) (200,)\n",
            "trainset after adding uncertain samples (250, 10) (250,)\n",
            "updated train set: (250, 10) (250,) unique(labels): [110 140] [0 1]\n",
            "val set: (1052, 10) (1052,)\n",
            "\n",
            "Train set: (250, 10)\n",
            "Validation set: (1052, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 5\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.948 s \n",
            "\n",
            "Accuracy rate is 79.262673 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.87      0.86       321\n",
            "           1       0.61      0.57      0.59       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.73      0.72      0.72       434\n",
            "weighted avg       0.79      0.79      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[280  41]\n",
            " [ 49  64]]\n",
            "--------------------------------\n",
            "val predicted: (1052,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1052, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "std (1052,) [32.37460602 47.61487318 49.26962275 ... 46.56686711 49.70467233\n",
            " 33.18016128]\n",
            "selection [ 231  945  146  881  436  927  617  374  891 1048  294  875 1021  301\n",
            "  456 1019  841  797  776  765  468  446  710  525  323  233  922  419\n",
            "  109  145  834 1030  570   22  530    6  148  457  300  191  327   93\n",
            "  874  387  566  729  951  546  751  862] (50,) [1.76922703e-02 4.43428011e-01 4.68871998e-01 1.11377296e+00\n",
            " 1.14001256e+00 1.45231660e+00 1.53459068e+00 3.79032070e+00\n",
            " 3.82083282e+00 3.82992897e+00 4.56357555e+00 4.66554979e+00\n",
            " 5.48861856e+00 6.74550850e+00 6.94013043e+00 7.25720081e+00\n",
            " 7.54498891e+00 7.54786957e+00 7.61303992e+00 7.75881648e+00\n",
            " 7.81764596e+00 8.56717210e+00 9.41945097e+00 9.89977593e+00\n",
            " 1.00897344e+01 1.03444413e+01 1.12083927e+01 1.17998097e+01\n",
            " 1.18798498e+01 1.34998313e+01 1.48421249e+01 1.53017089e+01\n",
            " 1.55834823e+01 1.60448961e+01 1.60818100e+01 1.66734218e+01\n",
            " 1.72240100e+01 1.74170741e+01 1.74334125e+01 1.79893829e+01\n",
            " 1.81874677e+01 1.82639423e+01 1.86107942e+01 1.86526951e+01\n",
            " 1.88810770e+01 1.92879856e+01 1.96016037e+01 1.96423942e+01\n",
            " 1.98514065e+01 2.01647806e+01]\n",
            "trainset before adding uncertain samples (250, 10) (250,)\n",
            "trainset after adding uncertain samples (300, 10) (300,)\n",
            "updated train set: (300, 10) (300,) unique(labels): [146 154] [0 1]\n",
            "val set: (1002, 10) (1002,)\n",
            "\n",
            "Train set: (300, 10)\n",
            "Validation set: (1002, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 6\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.011 s \n",
            "\n",
            "Accuracy rate is 79.723502 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.88      0.87       321\n",
            "           1       0.62      0.56      0.59       113\n",
            "\n",
            "    accuracy                           0.80       434\n",
            "   macro avg       0.74      0.72      0.73       434\n",
            "weighted avg       0.79      0.80      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[283  38]\n",
            " [ 50  63]]\n",
            "--------------------------------\n",
            "val predicted: (1002,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1002, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "std (1002,) [34.16289291 47.86957137 48.12021784 ... 45.14917536 49.37639113\n",
            " 41.79632126]\n",
            "selection [849 743 784 442 466 394 490 330 739  26 108 759   9 110  65 405 605  71\n",
            " 950  49 230 807 847 530 959  13 132 954 706 603  69 627 187 441 512  33\n",
            "  64 190 636 951 496  48 915 740 525 804 351 932 609 846] (50,) [ 2.97514964  4.9784342   5.23842342  6.46103963  7.29275208  7.73382033\n",
            "  8.84158342  9.17207859 10.60505409 12.13067465 13.21017032 13.60058145\n",
            " 14.40087757 14.63788372 15.90578237 15.98600737 16.1279074  16.76161508\n",
            " 16.76205575 17.19852874 17.23804019 17.23804019 17.40864851 17.47021757\n",
            " 17.56114066 19.26039307 19.59369057 20.1858916  20.23827217 20.44687318\n",
            " 20.56502646 21.05865264 21.21925696 22.05675098 23.10668706 23.26810438\n",
            " 23.27006634 23.39448149 23.7030959  23.78929863 24.13509769 24.21596777\n",
            " 24.34015824 24.71838089 25.3611345  25.7937193  25.82862745 25.86640909\n",
            " 25.98673416 26.23378483]\n",
            "trainset before adding uncertain samples (300, 10) (300,)\n",
            "trainset after adding uncertain samples (350, 10) (350,)\n",
            "updated train set: (350, 10) (350,) unique(labels): [167 183] [0 1]\n",
            "val set: (952, 10) (952,)\n",
            "\n",
            "Train set: (350, 10)\n",
            "Validation set: (952, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 7\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.054 s \n",
            "\n",
            "Accuracy rate is 79.953917 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.88      0.87       321\n",
            "           1       0.62      0.58      0.60       113\n",
            "\n",
            "    accuracy                           0.80       434\n",
            "   macro avg       0.74      0.73      0.73       434\n",
            "weighted avg       0.79      0.80      0.80       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[282  39]\n",
            " [ 48  65]]\n",
            "--------------------------------\n",
            "val predicted: (952,) [0 1 1 0 0 1 0 1 1 0 0 0 0 1 1 0 1 0 1 0 0 0 0 1 1 1 0 1 1 0 0 0 1 1 0 0 1\n",
            " 0 1 1 0 0 0 1 1 1 1 1 0 0 1 1 1 1 1 0 1 0 1 0 0 1 1 1 1 1 1 0 1 0 0 0 1 0\n",
            " 0 0 0 0 1 0 0 1 1 1 1 0 1 0 0 1 1 1 0 0 0 0 0 1 1 0 1 0 0 1 0 1 1 0 1 0 1\n",
            " 0 0 1 0 0 0 0 0 1 0 1 1 0 1 0 0 1 1 0 1 1 1 1 1 1 1 0 1 1 0 1 0 1 1 0 1 1\n",
            " 1 1 0 1 0 0 0 1 0 1 1 0 1 1 1 1 0 1 0 1 1 1 1 1 0 0 0 0 0 0 1 1 1 0 0 1 0\n",
            " 0 0 0 0 0 1 1 0 1 0 0 0 1 0 1 0 1 0 1 1 0 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 0\n",
            " 0 1 1 1 0 1 1 1 1 0 1 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 0 0 1 1 0 1 0 0\n",
            " 0 1 1 1 1 0 0 0 0 0 1 0 1 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1\n",
            " 1 0 1 1 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 1 0 1 0 1 0 0 1 0 0 0 1 1 0 1 1 1\n",
            " 0 1 0 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 0 1 1 0 1 0 1 1 0 0 1\n",
            " 0 0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 0 1 0 1 1 0 1 1 0 1 1 1 1 1 0 0 0 0 1 1 0\n",
            " 1 1 0 0 1 0 0 0 1 0 1 0 0 1 1 1 0 1 1 1 1 0 1 0 1 1 1 0 0 0 1 0 0 0 1 1 1\n",
            " 1 1 0 0 0 1 1 0 1 1 0 0 1 0 0 1 0 0 0 1 0 0 0 0 1 1 0 0 0 1 1 0 0 0 1 1 1\n",
            " 0 1 1 1 1 1 0 1 1 0 0 0 0 1 0 0 1 0 1 1 0 0 1 1 1 0 1 0 1 0 0 0 0 1 1 0 1\n",
            " 0 1 1 0 1 1 0 1 1 0 0 1 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0 1 0 0 1 1 1 0 1 1 1\n",
            " 1 0 1 0 0 0 0 1 0 0 1 0 1 0 1 1 1 1 0 1 1 0 1 0 1 1 0 0 1 0 1 0 0 1 0 0 1\n",
            " 0 1 1 1 1 1 0 0 0 1 0 1 0 1 1 0 1 1 1 0 1 0 1 1 0 1 0 0 1 1 0 1 1 1 1 1 0\n",
            " 0 1 0 1 0 0 1 1 1 0 1 1 0 1 0 1 1 1 1 1 1 0 1 1 1 0 1 0 1 1 0 1 0 1 0 1 1\n",
            " 1 0 0 0 1 0 0 1 0 1 1 0 0 0 1 0 0 0 1 1 0 1 0 0 1 0 1 1 0 1 0 0 1 0 1 0 1\n",
            " 1 1 0 0 0 0 1 0 0 1 1 0 1 1 0 0 1 0 1 0 0 0 0 1 0 0 1 1 0 1 0 0 0 1 0 0 1\n",
            " 1 0 1 1 0 0 0 0 1 1 0 0 1 1 0 1 0 1 0 1 0 1 1 0 0 0 1 0 0 1 0 1 1 0 1 0 0\n",
            " 1 0 0 0 0 1 0 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 0 0 1 0 0 1 1 0 1 1\n",
            " 1 0 1 0 1 0 0 0 0 0 1 0 1 0 1 0 1 1 0 0 0 1 0 1 0 0 1 1 1 1 1 1 1 0 1 1 1\n",
            " 0 0 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0\n",
            " 0 0 1 0 1 1 0 1 0 0 1 0 1 0 1 1 1 0 1 1 1 1 0 1 0 0 0 0 0 0 0 1 1 1 0 0 1\n",
            " 0 0 1 1 0 0 1 1 1 1 0 0 1 1 1 1 0 0 0 0 1 0 1 1 0 0 0]\n",
            "probabilities: (952, 2) \n",
            " [0 1 1 0 0 1 0 1 1 0 0 0 0 1 1 0 1 0 1 0 0 0 0 1 1 1 0 1 1 0 0 0 1 1 0 0 1\n",
            " 0 1 1 0 0 0 1 1 1 1 1 0 0 1 1 1 1 1 0 1 0 1 0 0 1 1 1 1 1 1 0 1 0 0 0 1 0\n",
            " 0 0 0 0 1 0 0 1 1 1 1 0 1 0 0 1 1 1 0 0 0 0 0 1 1 0 1 0 0 1 0 1 1 0 1 0 1\n",
            " 0 0 1 0 0 0 0 0 1 0 1 1 0 1 0 0 1 1 0 1 1 1 1 1 1 1 0 1 1 0 1 0 1 1 0 1 1\n",
            " 1 1 0 1 0 0 0 1 0 1 1 0 1 1 1 1 0 1 0 1 1 1 1 1 0 0 0 0 0 0 1 1 1 0 0 1 0\n",
            " 0 0 0 0 0 1 1 0 1 0 0 0 1 0 1 0 1 0 1 1 0 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 0\n",
            " 0 1 1 1 0 1 1 1 1 0 1 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 0 0 1 1 0 1 0 0\n",
            " 0 1 1 1 1 0 0 0 0 0 1 0 1 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1\n",
            " 1 0 1 1 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 1 0 1 0 1 0 0 1 0 0 0 1 1 0 1 1 1\n",
            " 0 1 0 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 0 1 1 0 1 0 1 1 0 0 1\n",
            " 0 0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 0 1 0 1 1 0 1 1 0 1 1 1 1 1 0 0 0 0 1 1 0\n",
            " 1 1 0 0 1 0 0 0 1 0 1 0 0 1 1 1 0 1 1 1 1 0 1 0 1 1 1 0 0 0 1 0 0 0 1 1 1\n",
            " 1 1 0 0 0 1 1 0 1 1 0 0 1 0 0 1 0 0 0 1 0 0 0 0 1 1 0 0 0 1 1 0 0 0 1 1 1\n",
            " 0 1 1 1 1 1 0 1 1 0 0 0 0 1 0 0 1 0 1 1 0 0 1 1 1 0 1 0 1 0 0 0 0 1 1 0 1\n",
            " 0 1 1 0 1 1 0 1 1 0 0 1 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0 1 0 0 1 1 1 0 1 1 1\n",
            " 1 0 1 0 0 0 0 1 0 0 1 0 1 0 1 1 1 1 0 1 1 0 1 0 1 1 0 0 1 0 1 0 0 1 0 0 1\n",
            " 0 1 1 1 1 1 0 0 0 1 0 1 0 1 1 0 1 1 1 0 1 0 1 1 0 1 0 0 1 1 0 1 1 1 1 1 0\n",
            " 0 1 0 1 0 0 1 1 1 0 1 1 0 1 0 1 1 1 1 1 1 0 1 1 1 0 1 0 1 1 0 1 0 1 0 1 1\n",
            " 1 0 0 0 1 0 0 1 0 1 1 0 0 0 1 0 0 0 1 1 0 1 0 0 1 0 1 1 0 1 0 0 1 0 1 0 1\n",
            " 1 1 0 0 0 0 1 0 0 1 1 0 1 1 0 0 1 0 1 0 0 0 0 1 0 0 1 1 0 1 0 0 0 1 0 0 1\n",
            " 1 0 1 1 0 0 0 0 1 1 0 0 1 1 0 1 0 1 0 1 0 1 1 0 0 0 1 0 0 1 0 1 1 0 1 0 0\n",
            " 1 0 0 0 0 1 0 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 0 0 1 0 0 1 1 0 1 1\n",
            " 1 0 1 0 1 0 0 0 0 0 1 0 1 0 1 0 1 1 0 0 0 1 0 1 0 0 1 1 1 1 1 1 1 0 1 1 1\n",
            " 0 0 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0\n",
            " 0 0 1 0 1 1 0 1 0 0 1 0 1 0 1 1 1 0 1 1 1 1 0 1 0 0 0 0 0 0 0 1 1 1 0 0 1\n",
            " 0 0 1 1 0 0 1 1 1 1 0 0 1 1 1 1 0 0 0 0 1 0 1 1 0 0 0]\n",
            "std (952,) [32.78172922 45.14691464 49.03040506 35.73540518 28.20908006 45.56359916\n",
            " 40.7022091  48.82117396 43.30456344 45.05557168 49.72133485 43.98966887\n",
            " 49.37194782 49.4014838  46.55848068 48.3991282  48.95541533 34.39774114\n",
            " 43.76160013 47.56318409 41.78882544 26.79668394 41.03206848 48.39978327\n",
            " 49.54687142 49.15773898 34.39774114 49.12021007 49.41358539 45.36666203\n",
            " 41.88276368 48.986693   45.44847875 46.78966577 49.87134832 49.83836959\n",
            " 22.76999506 30.16376222 43.53789932 47.20919866 43.06727908 49.48492538\n",
            " 46.78048178 47.97336712 45.82760756 48.27201458 32.64500896 49.12411536\n",
            " 43.85153588 48.20638274 49.16763605 42.06362231 49.41389502 48.33541926\n",
            " 42.57865897 48.08065098 49.30257415 40.33756418 49.41987275 48.5070298\n",
            " 49.36408167 49.0306607  48.09144166 48.40652971 48.29531295 36.94608335\n",
            " 49.55746468 49.60216906 48.4826746  44.49267056 49.56798025 21.71817133\n",
            " 49.47962384 43.08804308 31.46978203 40.91901594 24.41805747 49.54402747\n",
            " 49.18005228 48.86334871 37.69397893 48.62241648 49.35519835 48.23892426\n",
            " 45.9620889  45.79751323 49.35927436 49.57984615 34.39774114 48.05831085\n",
            " 36.1395932  47.66020438 28.72693303 35.7398926  48.80289255 48.67403544\n",
            " 49.60712909 44.07753225 46.94061066 49.10128796 49.60517202 43.23593976\n",
            " 45.97132239 49.60171252 49.66655947 48.43282803 49.61785907 44.32111343\n",
            " 48.69304622 49.46857112 45.26039599 49.77548428 49.7519547  46.76059187\n",
            " 24.23235267 43.68177003 49.3236781  49.11990039 34.39774114 49.30620186\n",
            " 49.64140345 49.06372979 44.82494049 49.50944832 44.34477893 30.10880906\n",
            " 49.20193506 49.26150434 40.3204289  47.55678285 44.79758958 39.04250752\n",
            " 47.98595259 38.54746531 47.92858403 22.2627111  48.56796811 44.32505067\n",
            " 49.47034587 48.44001187 48.06045117 41.50126897 34.39774114 49.06648326\n",
            " 43.80591916 49.68189786 48.21236385 37.60795849 47.28368577 49.23514361\n",
            "  5.96574899 47.31343102 45.98765281 49.72079945 38.21277096 48.97497467\n",
            " 37.16847714 48.3512194  46.3396931  44.98018431 31.13566278 47.53818128\n",
            " 43.19532118 44.17102214 49.75896305 47.39103443 34.39774114 48.0237035\n",
            " 46.71599064 48.84889228 49.1113788  48.49163589 48.69232253 48.83308979\n",
            " 41.2668206  44.26263365 47.3334788  45.69385977 47.55654669 48.03828454\n",
            " 48.92688847 33.15340753 42.51498986 48.42550195 47.54917785 29.88796877\n",
            " 47.7926171  49.78104681 47.67414329 49.73607328 49.31926126 37.1906294\n",
            " 47.00855917 44.9377693  49.62985941 49.70789177 34.39774114 46.1928943\n",
            " 49.23928435 46.82538376 29.7166199  42.24029559 48.51207794 49.0297439\n",
            " 47.10436489 48.87685742 46.05473528 49.35342557 41.6463137  49.87261531\n",
            " 47.70957974 49.7813114  47.10256142 34.9363714  49.44304044 47.08414469\n",
            " 46.13207718 48.62921968 45.93601871 47.03793592 47.8814806  49.16815107\n",
            " 49.33130468 46.43154058 49.22683493 48.93423429 49.26281593 49.07608365\n",
            " 48.77457115 49.10681759 47.26347267 48.64610701 45.8844296  49.79811369\n",
            " 49.66748494 49.63538183 49.03102224 38.33380395 46.31253475 49.47732765\n",
            " 46.29666448 49.41117893 40.26495403 46.6675025  42.84246647 49.66282581\n",
            " 47.22817136 48.1455087  35.05405462 47.95748788 48.45232239 49.77129475\n",
            " 49.57316738 48.23962978 45.73477047 48.99491634 49.05005416 43.46321712\n",
            " 43.96016476 46.87201351 45.19079559 48.59776161 49.09968529 49.17755023\n",
            " 49.04389521 34.39774114 49.40490483 34.39774114 45.32005098 49.36248546\n",
            " 34.39774114 49.41712659 47.96814084 49.22586464 49.65953866 46.24915121\n",
            " 48.23770924 48.69424977 49.66388667 46.65991173 43.03094817 44.42955499\n",
            " 40.8777923  41.64740883 36.5377363  49.49703165 48.69524926 46.61874904\n",
            " 44.94318035 49.23094142 48.79255843 48.61579023 48.54367889 35.7373206\n",
            " 45.46197949 47.86512662 49.67725562 34.39774114 37.02643995 49.15520184\n",
            " 48.73218218 49.56798025 49.43997088 44.6977935  49.33271403 46.96919748\n",
            " 46.83964392 36.40788901 48.47697093 49.66469409 47.15888206 37.2992937\n",
            " 48.04320353 47.08402821 40.54490834 49.83573114 49.78796677 46.22469344\n",
            " 33.98661791 49.81434168 49.32090318 34.39774114 47.97901033 49.28717392\n",
            " 47.47422348 49.50345231 47.16425692 30.71917808 29.76033558 48.11720349\n",
            " 48.26769833 48.7398683  48.64138946 33.99592984 41.80715036 49.56021438\n",
            " 46.8601831  34.38562002 40.2686358  47.07273051 47.29611243 45.59513309\n",
            " 48.76235531 48.77440133 33.25362432 45.74759275 48.8061036  46.43308036\n",
            " 48.71006952 49.81717409 49.3600437  48.47320349 32.93912691 41.62470792\n",
            " 49.50445317 49.24594619 48.49680738 49.41937137 41.50777307 49.66245532\n",
            " 49.42906271 49.19169595 48.23726305 38.56289034 47.64851064 45.18088616\n",
            " 47.41406132 37.89399625 45.93966427 49.70285537 34.39774114 34.39774114\n",
            " 48.76059367 48.91759669 48.44357318 49.66893262 49.39460786 48.23421211\n",
            " 49.06019702 47.8989298  47.80576768 47.1445958  47.06709956 48.85155395\n",
            " 47.27575937 49.36332651 28.46273006 49.76298578 47.43567203 46.18988189\n",
            " 48.8177804  49.60158439 48.91603622 48.70555047 49.41960744 49.43505912\n",
            " 48.25936789 48.77228551 48.46981657 40.58308642 49.82299506 45.97169253\n",
            " 46.73749058 44.5992526  49.40579548 48.83491361 48.92736657 41.85186514\n",
            " 48.2904683  43.30244096 34.39774114 49.03812648 48.33924638 46.7059298\n",
            " 27.13621488 47.28538269 49.31410352 49.30627812 43.55370523 48.86262731\n",
            " 48.91730555 42.1256326  49.04480346 48.79329695 49.41670011 49.3505839\n",
            " 46.67384972 49.36032308 48.72138551 49.27093547 49.70935868 49.72110227\n",
            " 48.22892701 38.12622166 44.092996   41.27160038 49.36883669 20.18027082\n",
            " 47.94992186 49.81633354 39.63991215 47.05623517 47.90945663 48.73782941\n",
            " 49.55078053 47.65997254 49.42532526 49.86827195 49.00993169 48.40965123\n",
            " 47.15609259 36.99794256 49.29434307 33.89077175 43.24526855 49.44098749\n",
            " 47.50311094 49.4398037  29.08684295 45.24946823 48.06360188 42.98836948\n",
            " 40.35804213 43.52854919 49.46024046 34.39774114 37.81002827 49.76894486\n",
            " 47.79584787 48.65717123 44.42209805 46.07070902 34.39774114 48.97933698\n",
            " 45.38145651 49.21405172 49.78460776 49.2552452  48.48226889 47.33511652\n",
            " 49.72752518 36.25521065 46.05112647 49.14833091 46.45774735 47.0008313\n",
            " 41.29642944 45.05000847 49.1655282  47.74347142 44.22008441 49.82325471\n",
            " 47.7102488  12.23718781 37.2396137  44.4698283  48.93813341 49.69021007\n",
            " 46.6421227  49.38385522 49.66861637 34.39774114 34.39774114 46.6034618\n",
            " 36.91991074 46.73980687 47.62333078 49.6208867  44.52139996 48.82446877\n",
            " 29.56066607 48.80998623 38.81146377 48.94828002 49.52653625 48.13333896\n",
            " 49.04691781 49.43069063 48.28879473 49.60787269 48.96536218 40.5416078\n",
            " 47.44862841 41.80715036 48.04606486 42.38983454 48.06031656 42.06833758\n",
            " 49.56222637 48.1005139  47.58442934 45.50421849 41.35568882 49.22528997\n",
            " 47.74347142 48.26448029 48.76002018 43.43673822 43.01929587 49.27664964\n",
            " 46.29396587 49.75680082 49.70680814 49.66888905 48.06948167 46.72376232\n",
            " 49.44332069 18.19978054 49.46002329 44.5503595  39.14024509 33.47756321\n",
            " 42.39835875 49.41024794 48.40358638 49.36274226 42.07438386 46.2155318\n",
            " 49.5287497  48.39320867 46.64670238 40.18874142 49.54801462 49.40967299\n",
            " 49.72884097 46.37352075 33.71813691 49.69107953 48.99015287 49.01928177\n",
            " 32.54159981 48.91818744 49.09014429 46.4014986  49.47554827 40.56185207\n",
            " 40.78038834 47.83495553 45.55514444 49.1859428  48.20213395 49.60120622\n",
            " 46.98898363 48.25722684 49.55925018 44.9197134  47.6214423  46.461441\n",
            " 47.40643238 39.12714686 44.68150677 48.53362332 47.456714   30.85941159\n",
            " 49.26298711 48.54617441 48.85244746 45.81768522 47.71981628 48.00441562\n",
            " 29.42945128 49.00400591 15.79276898 44.6836855  40.66976522 48.45094154\n",
            " 44.46781831 49.81985416 49.22382604 45.01090561 49.45860193 41.3598104\n",
            " 42.69562105 49.1728961  41.81298096 49.57782007 49.90296028 36.19089615\n",
            " 49.76271322 44.37318861 36.65482861 49.6687369  48.29331086 49.74695715\n",
            " 49.1997469  49.58788704 48.84110334 47.31044014 30.6362007  40.88473503\n",
            " 49.61235015 33.16452695 47.15336237 34.13817717 44.85872846 49.55613851\n",
            " 49.05477137 44.2365546  49.49157703 45.45292884 31.15264171 49.8137666\n",
            " 48.54367889 49.6377369  41.25943296 49.24313567 49.5390131  49.6941461\n",
            " 36.94063437 35.2454028  41.98600372 49.58363984 47.21468541 43.3489762\n",
            " 39.29791494 47.96092044 43.86580811 49.7133907  39.90861878 48.39042961\n",
            " 43.0422612  41.85515387 49.22648726 49.1345996  48.0849256  44.53530921\n",
            " 46.97572612 11.77228153 34.39774114 34.39774114 48.46330833  7.3473574\n",
            " 39.85173219 49.46502297 49.00564969 49.61944005 30.5168552  45.32224629\n",
            " 47.85174443 36.9832102  40.02054117 49.12893829 49.49746559 44.81826611\n",
            " 49.07405921 48.91375719 48.7240662  49.35847461 40.9262105  47.34561543\n",
            " 48.1340992  33.1309173  40.26523139 47.67190296 43.38577093 48.63009128\n",
            " 49.49953549 48.3061366  49.37187834 48.86803539 44.88806816 30.40116708\n",
            " 49.7177062  49.48576819 48.9039573  39.30604274 39.23942786 49.66094626\n",
            " 49.6847221  49.54184005 49.78636462 36.16465097 49.250112   48.87245349\n",
            " 31.98156905 35.77527142 47.38989654 49.75658506 49.52683298 49.78055538\n",
            " 34.39774114 49.34961204 47.88952911 49.54983361 34.39774114 48.25064247\n",
            " 48.49099471 39.19403129 49.78136238 38.56922449 49.64011513 45.35928978\n",
            " 48.40035071 27.8915313  45.63608885 46.77476488 49.68028039 49.58740438\n",
            " 49.03726809 47.81745113 33.08525068 29.39552226 49.3272001  37.10437147\n",
            " 48.60753699 38.49406157 49.93398836 34.39774114 46.60696872 49.07342894\n",
            " 49.28549425 48.75090171 48.5410273  44.56713251 48.38743659 48.26114488\n",
            " 48.90715332 46.61240456 49.4920537  47.77238279 49.11818861 46.39204828\n",
            " 41.33329256 41.8588656  47.06505057 49.29493212 48.7496564  49.31650911\n",
            " 49.2293047  49.41278406 44.54825708 49.40994411 43.89959748 49.71211497\n",
            " 42.47297122 45.90409082 49.48750036 43.1533402  49.86177328 49.47868192\n",
            " 48.9807595  47.73398929 36.99053098 49.10252488 34.91013454 45.89460125\n",
            " 38.57476611 45.09491448 47.99902767 47.85311864 31.96344685 36.70379642\n",
            " 45.45872932 49.81161358 47.77659251 47.56173356 49.52660512 43.74791453\n",
            " 48.67666478 49.17315824 49.49783101 49.58586055 47.58126609 44.63633843\n",
            " 37.23256866 49.63254337 48.62161358 40.95748666 47.31624991 49.07530798\n",
            " 43.24747747 45.76670147 48.59995782 48.76632961 47.18716937 49.63095127\n",
            " 42.63242216 49.17486348 48.11583089 49.68621508 47.61424541 49.77733248\n",
            " 44.48317443 35.07894624 49.77444708 42.41364207 46.96705061 48.55209176\n",
            " 49.77607689 49.29771406 49.77017065 48.77310973 49.57719685 49.02055548\n",
            " 48.57726298 49.06880175 34.39774114 48.61063027 49.5228872  34.39774114\n",
            " 48.95913968 45.49911816 43.76160013 49.07405921 49.53132489 49.32887492\n",
            " 47.26417636 49.1276802  47.03793592 49.52653625 49.36731326 48.70414648\n",
            " 47.97561982 40.46148057 43.61965717 49.75183051 49.41519866 48.23892426\n",
            " 49.31384564 40.96821608 45.84020189 49.37939062 49.4292557  49.27204668\n",
            " 49.35750233 44.19870977 32.30133961 48.52943474 49.50524428 48.17492996\n",
            " 46.89625944 44.75945918 42.66572808 48.23868758 48.97385947 48.95338955\n",
            " 41.08065779 35.84158907 47.89678067 49.23499171 47.94484438 49.65758507\n",
            " 34.39774114 49.08914589 49.50894986 49.58789597 49.69965327 41.83230741\n",
            " 34.39774114 48.35567098 48.92107995 48.91430047 49.31363928 49.27460938\n",
            " 47.081164   49.68772971 48.24866722 49.56178141 40.35417166 46.01822187\n",
            " 48.93328756 42.97627535 46.41919708 46.00998529 48.99040123 49.56133722\n",
            " 43.14946886 42.0137271  49.53165309 48.0470248  46.4303884  48.02402401\n",
            " 49.41712509 42.0953765  48.46338537 27.56058218 35.36208193 16.5340429\n",
            " 49.7563639  38.82416729 49.68852413 42.05853437 47.47796697 46.81030981\n",
            " 44.74971301 49.50256821 47.30864308 47.76705524 14.6032256  29.82904054\n",
            " 36.39489647 45.70685905 48.88436668 48.65846852 41.06292858 47.26019527\n",
            " 34.39774114 47.82656569 29.52581103 39.30310001 46.92336288 24.96648058\n",
            " 34.39774114 49.82330877 48.97897411 49.23390294 47.24259377 44.86391631\n",
            " 43.75643432 45.62350601 49.3779082  32.95904268]\n",
            "selection [150 671 667 493 928 602 917 547 437  71 135  36 114  76 941  21 414 915\n",
            " 733   4 386  92 458 741 600 938 510 200 328 929 185 125  37 701 676 628\n",
            " 327 593 160 640  74 790 714 866 570  46   0 352 951 740] (50,) [ 5.96574899  7.3473574  11.77228153 12.23718781 14.6032256  15.79276898\n",
            " 16.5340429  18.19978054 20.18027082 21.71817133 22.2627111  22.76999506\n",
            " 24.23235267 24.41805747 24.96648058 26.79668394 27.13621488 27.56058218\n",
            " 27.8915313  28.20908006 28.46273006 28.72693303 29.08684295 29.39552226\n",
            " 29.42945128 29.52581103 29.56066607 29.7166199  29.76033558 29.82904054\n",
            " 29.88796877 30.10880906 30.16376222 30.40116708 30.5168552  30.6362007\n",
            " 30.71917808 30.85941159 31.13566278 31.15264171 31.46978203 31.96344685\n",
            " 31.98156905 32.30133961 32.54159981 32.64500896 32.78172922 32.93912691\n",
            " 32.95904268 33.08525068]\n",
            "trainset before adding uncertain samples (350, 10) (350,)\n",
            "trainset after adding uncertain samples (400, 10) (400,)\n",
            "updated train set: (400, 10) (400,) unique(labels): [193 207] [0 1]\n",
            "val set: (902, 10) (902,)\n",
            "\n",
            "Train set: (400, 10)\n",
            "Validation set: (902, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 8\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 229.361 s \n",
            "\n",
            "Accuracy rate is 79.723502 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.88      0.86       321\n",
            "           1       0.62      0.58      0.60       113\n",
            "\n",
            "    accuracy                           0.80       434\n",
            "   macro avg       0.74      0.73      0.73       434\n",
            "weighted avg       0.79      0.80      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[281  40]\n",
            " [ 48  65]]\n",
            "--------------------------------\n",
            "val predicted: (902,) [1 1 0 1 0 1 1 0 0 0 0 1 1 0 1 0 1 0 0 0 1 1 1 0 1 1 0 0 0 1 1 0 0 1 1 0 0\n",
            " 0 1 1 1 1 0 0 1 1 1 1 1 0 1 0 1 0 0 1 1 1 1 1 1 0 1 0 0 1 0 0 0 1 0 0 1 1\n",
            " 1 1 0 1 0 0 1 1 1 0 0 0 0 1 1 0 1 0 0 1 0 1 1 0 1 0 1 0 0 1 0 0 0 0 1 0 1\n",
            " 1 0 1 0 1 1 0 1 1 1 1 1 1 0 1 1 0 1 0 1 1 0 1 1 1 1 1 0 0 0 1 0 1 1 0 1 1\n",
            " 1 0 1 0 1 1 1 1 1 0 0 0 0 0 0 1 1 1 0 0 1 0 0 0 0 0 1 1 0 1 0 0 0 1 0 1 1\n",
            " 0 1 1 0 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 0 1 1 1 1 0 1 1 0 1 1 1 0\n",
            " 1 1 0 1 1 1 1 1 1 1 1 1 0 0 1 1 0 1 0 0 0 1 1 1 1 0 0 0 0 0 1 0 1 0 0 0 1\n",
            " 0 1 0 0 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 0 1 0 1 0 0 1 1\n",
            " 1 0 0 1 0 1 0 1 0 0 1 0 0 0 0 1 1 1 0 1 0 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 0 0 0 1 1 0 1 0 1 1 0 0 1 0 0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1 0 1 1\n",
            " 0 1 1 0 1 1 1 1 1 0 0 0 0 1 1 0 1 1 0 0 1 0 0 1 0 1 0 0 1 1 1 0 1 1 1 1 0\n",
            " 1 0 1 1 1 0 0 0 0 0 0 1 1 1 1 1 0 0 0 1 1 0 1 1 0 0 1 0 1 0 0 0 1 0 0 0 0\n",
            " 1 1 0 0 0 1 1 0 0 0 1 1 1 0 1 1 1 1 1 0 1 1 0 0 0 1 0 0 1 0 1 1 0 0 1 1 1\n",
            " 0 1 0 1 0 0 0 1 1 0 1 0 1 1 0 1 1 0 1 1 0 0 1 1 0 1 1 1 0 1 1 1 1 1 1 1 0\n",
            " 0 1 0 1 1 1 0 1 1 1 1 0 1 0 0 0 0 1 0 0 1 0 1 0 1 1 1 0 1 1 0 1 0 1 1 0 0\n",
            " 1 0 1 0 0 1 0 0 1 0 1 1 1 1 0 0 1 1 0 1 1 0 1 1 1 0 1 0 1 1 0 1 0 0 1 1 0\n",
            " 1 1 1 1 1 0 1 0 1 0 0 1 1 1 0 1 0 1 0 1 1 1 1 1 1 0 1 1 1 0 1 0 1 1 0 1 0\n",
            " 1 0 1 1 1 0 0 1 0 1 0 1 0 0 0 1 0 0 0 1 1 0 1 0 0 1 0 1 1 0 1 0 0 1 0 1 1\n",
            " 1 1 0 0 0 0 1 0 0 1 1 1 1 0 0 1 0 1 0 0 0 0 1 0 0 1 1 0 1 0 0 1 0 0 1 1 1\n",
            " 0 0 0 0 1 1 0 0 1 1 0 1 0 1 0 1 0 1 1 0 0 0 1 0 0 1 0 1 1 0 1 0 0 1 0 0 0\n",
            " 0 1 0 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 0 0 1 0 0 1 1 0 1 1 1 0 1 0 1\n",
            " 0 0 0 0 0 1 0 1 0 1 0 1 1 0 0 0 1 0 1 0 0 1 1 1 1 1 1 1 0 1 1 1 0 0 1 1 1\n",
            " 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 0 0 1 0 1 1\n",
            " 0 1 0 0 1 0 1 0 1 1 1 0 1 1 1 1 0 1 0 0 0 0 0 1 1 1 0 0 1 0 0 1 0 1 1 1 1\n",
            " 0 0 1 1 1 0 0 0 1 0 1 1 0 0]\n",
            "probabilities: (902, 2) \n",
            " [1 1 0 1 0 1 1 0 0 0 0 1 1 0 1 0 1 0 0 0 1 1 1 0 1 1 0 0 0 1 1 0 0 1 1 0 0\n",
            " 0 1 1 1 1 0 0 1 1 1 1 1 0 1 0 1 0 0 1 1 1 1 1 1 0 1 0 0 1 0 0 0 1 0 0 1 1\n",
            " 1 1 0 1 0 0 1 1 1 0 0 0 0 1 1 0 1 0 0 1 0 1 1 0 1 0 1 0 0 1 0 0 0 0 1 0 1\n",
            " 1 0 1 0 1 1 0 1 1 1 1 1 1 0 1 1 0 1 0 1 1 0 1 1 1 1 1 0 0 0 1 0 1 1 0 1 1\n",
            " 1 0 1 0 1 1 1 1 1 0 0 0 0 0 0 1 1 1 0 0 1 0 0 0 0 0 1 1 0 1 0 0 0 1 0 1 1\n",
            " 0 1 1 0 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 0 1 1 1 1 0 1 1 0 1 1 1 0\n",
            " 1 1 0 1 1 1 1 1 1 1 1 1 0 0 1 1 0 1 0 0 0 1 1 1 1 0 0 0 0 0 1 0 1 0 0 0 1\n",
            " 0 1 0 0 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 0 1 0 1 0 0 1 1\n",
            " 1 0 0 1 0 1 0 1 0 0 1 0 0 0 0 1 1 1 0 1 0 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 0 0 0 1 1 0 1 0 1 1 0 0 1 0 0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1 0 1 1\n",
            " 0 1 1 0 1 1 1 1 1 0 0 0 0 1 1 0 1 1 0 0 1 0 0 1 0 1 0 0 1 1 1 0 1 1 1 1 0\n",
            " 1 0 1 1 1 0 0 0 0 0 0 1 1 1 1 1 0 0 0 1 1 0 1 1 0 0 1 0 1 0 0 0 1 0 0 0 0\n",
            " 1 1 0 0 0 1 1 0 0 0 1 1 1 0 1 1 1 1 1 0 1 1 0 0 0 1 0 0 1 0 1 1 0 0 1 1 1\n",
            " 0 1 0 1 0 0 0 1 1 0 1 0 1 1 0 1 1 0 1 1 0 0 1 1 0 1 1 1 0 1 1 1 1 1 1 1 0\n",
            " 0 1 0 1 1 1 0 1 1 1 1 0 1 0 0 0 0 1 0 0 1 0 1 0 1 1 1 0 1 1 0 1 0 1 1 0 0\n",
            " 1 0 1 0 0 1 0 0 1 0 1 1 1 1 0 0 1 1 0 1 1 0 1 1 1 0 1 0 1 1 0 1 0 0 1 1 0\n",
            " 1 1 1 1 1 0 1 0 1 0 0 1 1 1 0 1 0 1 0 1 1 1 1 1 1 0 1 1 1 0 1 0 1 1 0 1 0\n",
            " 1 0 1 1 1 0 0 1 0 1 0 1 0 0 0 1 0 0 0 1 1 0 1 0 0 1 0 1 1 0 1 0 0 1 0 1 1\n",
            " 1 1 0 0 0 0 1 0 0 1 1 1 1 0 0 1 0 1 0 0 0 0 1 0 0 1 1 0 1 0 0 1 0 0 1 1 1\n",
            " 0 0 0 0 1 1 0 0 1 1 0 1 0 1 0 1 0 1 1 0 0 0 1 0 0 1 0 1 1 0 1 0 0 1 0 0 0\n",
            " 0 1 0 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 0 0 1 0 0 1 1 0 1 1 1 0 1 0 1\n",
            " 0 0 0 0 0 1 0 1 0 1 0 1 1 0 0 0 1 0 1 0 0 1 1 1 1 1 1 1 0 1 1 1 0 0 1 1 1\n",
            " 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 0 0 1 0 1 1\n",
            " 0 1 0 0 1 0 1 0 1 1 1 0 1 1 1 1 0 1 0 0 0 0 0 1 1 1 0 0 1 0 0 1 0 1 1 1 1\n",
            " 0 0 1 1 1 0 0 0 1 0 1 1 0 0]\n",
            "std (902,) [45.71751896 48.4081593   8.43665462 44.07827805 42.27836459 49.00915133\n",
            " 42.51608559 44.48069512 49.38839122 38.52524554 49.18213026 49.48286561\n",
            " 45.28480197 47.93732455 48.01331463 32.89081335 40.58267853 46.55391057\n",
            " 35.92781784 46.80162386 47.1017635  49.38543499 48.84573318 32.89081335\n",
            " 49.03582222 48.64177651 37.18218931 43.20835283 48.44409316 46.37258821\n",
            " 44.86349765 49.80666006 49.6666625  44.28277224 46.17869144 34.97324808\n",
            " 49.52352058 46.52168433 46.58644099 44.24379557 47.44867156 48.68259072\n",
            " 35.9704076  48.41649853 49.3324044  44.35105905 49.17610893 48.03754392\n",
            " 41.18805537 47.93607143 49.24303722 42.06209045 49.18151767 48.18614244\n",
            " 48.92078248 48.33158976 46.55695004 47.93370993 47.64179542 30.00469705\n",
            " 49.42587783 49.18798043 48.0128605  36.03181501 49.50186147 49.24838499\n",
            " 38.18157534 33.81329587 49.24026499 48.36599766 48.30509285 39.20778264\n",
            " 48.94653792 48.96547243 46.52738961 42.66741295 42.44756736 48.68639314\n",
            " 49.23842327 32.89081335 47.12136816 34.39891185 45.69835698 28.18098418\n",
            " 47.44441818 48.55356082 49.51387411 43.79281867 47.55519011 49.26488234\n",
            " 49.42495262 31.05509987 45.15778499 49.46970568 49.21159178 48.09466698\n",
            " 49.66857237 38.13649499 48.09177279 49.37252366 42.79252253 49.67093155\n",
            " 49.54698278 44.85945313 42.06367824 48.9311779  48.06629236 32.89081335\n",
            " 48.92262124 49.59435927 48.4882209  41.86581967 48.49981691 43.20604745\n",
            " 48.68899032 48.85521971 34.90685705 46.1610468  42.17416293 37.98434023\n",
            " 46.94143692 32.62302262 47.14171705 47.75228775 44.39652997 49.41706287\n",
            " 48.54783622 46.72134806 38.38098017 32.89081335 49.12851167 46.66801372\n",
            " 49.42823028 48.42267932 38.78480408 48.18338132 48.97605158 45.16705756\n",
            " 45.00465073 49.4980117  40.28347962 49.10911243 30.54598214 47.62696988\n",
            " 45.59831632 44.55902362 44.82730758 42.58298121 43.45806174 49.56297858\n",
            " 46.49979405 32.89081335 46.76806426 43.47721317 47.73425877 48.78741232\n",
            " 48.50099076 47.90715967 48.55505385 37.17959794 45.25779171 44.1879987\n",
            " 46.89217056 47.40535099 47.99890376 48.74082762 39.99700323 43.896803\n",
            " 48.45645325 48.29319929 46.13474041 49.70712642 47.16444692 49.15664568\n",
            " 49.20853854 35.3698144  46.12625432 40.91261462 49.49887702 49.67069629\n",
            " 32.89081335 45.45821436 49.37185028 46.93398391 38.35128571 48.39614124\n",
            " 48.8864474  46.41987464 49.24557002 41.32705736 49.19431447 41.61320262\n",
            " 49.87364366 47.40295606 49.62683049 44.44179775 27.22048584 49.11190115\n",
            " 45.78704607 44.32720018 47.55786228 42.82484433 45.82690205 46.5167999\n",
            " 48.54003405 48.47671149 45.66240675 49.08866451 48.50408106 48.18431673\n",
            " 48.72792722 48.49864196 48.38733651 45.97300065 48.82871027 44.4042196\n",
            " 49.64245657 49.51387987 49.49102052 48.50822679 40.44309407 39.59929954\n",
            " 49.30677615 46.93389159 49.13273789 33.07322671 47.2457824  42.79242713\n",
            " 49.67032034 45.80485693 46.64816717 38.54849624 46.45132036 48.17752969\n",
            " 49.69922584 48.97191349 48.38259437 46.98957097 47.8940744  47.90490318\n",
            " 42.19975043 45.53484509 46.06106849 46.55626217 48.7823764  48.72703849\n",
            " 49.28977159 47.48378309 32.89081335 49.43244917 32.89081335 36.05617688\n",
            " 49.15418263 32.89081335 49.17627817 49.04256158 49.06424178 49.19174277\n",
            " 45.77282717 47.31078928 48.34494361 49.47625169 46.72859479 41.72205632\n",
            " 36.13740734 45.17754405 44.8262596  37.63903684 48.89742983 48.0729468\n",
            " 45.42650735 46.47855587 49.18026132 48.09821743 47.58642032 48.61897415\n",
            " 36.53386129 42.6298076  47.07839877 49.64799242 32.89081335 28.15074404\n",
            " 49.1005646  47.7810627  49.50186147 49.19867551 37.95674795 48.96768378\n",
            " 44.98455183 46.16906691 43.0163214  46.82308992 49.60873405 44.67111555\n",
            " 30.28022378 47.34471578 45.90899749 41.10866925 49.70708492 49.74288926\n",
            " 39.45715245 37.35158307 49.73718775 49.14076158 32.89081335 41.25755627\n",
            " 49.13472062 47.74630415 49.35438844 44.56614828 44.58567352 47.9414903\n",
            " 48.2159104  47.5438814  38.84858841 36.48163273 49.49115765 45.31597561\n",
            " 27.6032193  35.91693593 45.87945106 47.48541229 41.68605018 47.93062516\n",
            " 48.54111341 26.25592566 39.36995465 48.68234127 45.73560043 48.16428816\n",
            " 49.71678523 48.78891997 48.22020711 40.99058117 49.21375985 48.68715246\n",
            " 48.68235421 49.1282369  44.8795918  49.47168258 49.17359133 48.39847934\n",
            " 47.17292573 36.7655811  48.28240488 45.14740107 44.99576118 29.40339336\n",
            " 45.0887184  49.32668055 32.89081335 32.89081335 48.76433877 46.35435993\n",
            " 48.21718062 49.37977904 49.0679783  47.03808885 48.13083597 47.65419087\n",
            " 45.61386968 43.140797   45.00612559 47.83289325 46.35733148 49.25235002\n",
            " 49.63846224 44.93746357 45.40402429 48.13088492 49.37851563 47.59850236\n",
            " 48.04122694 49.02019768 49.25614128 47.25977149 48.59936845 47.64793286\n",
            " 39.29956318 49.80570274 46.14263984 45.73194028 41.47164979 48.64532221\n",
            " 47.60452129 48.25400836 41.01309267 47.56097311 41.66964367 32.89081335\n",
            " 48.444412   47.03112091 46.61464152 45.82633193 48.53279473 48.81466872\n",
            " 45.07146966 47.45905911 48.76881607 42.98278889 47.13862162 47.29036107\n",
            " 49.2232405  48.75667156 43.95822179 49.04302401 48.93372944 49.08790214\n",
            " 49.51717028 49.57470831 46.7669567  38.09828408 44.9499297  42.0646808\n",
            " 49.12369729 47.7578075  49.70850762 37.18674223 46.93427874 48.11156956\n",
            " 48.69067254 49.48275177 44.78891743 48.94527298 49.72824071 47.18402461\n",
            " 48.45456725 47.93097824 39.60670438 49.03415273 38.68780487 36.16830753\n",
            " 49.29257717 47.48980512 49.31184782 43.69581167 43.74664574 46.34730075\n",
            " 39.58696422 43.32391618 48.4690353  32.89081335 21.03843995 49.66563832\n",
            " 47.27362856 47.61603473 42.62750785 34.7274321  32.89081335 48.57020335\n",
            " 43.32566374 46.63292025 49.65759269 48.97396451 48.5659757  46.43917044\n",
            " 49.67053795 41.42568934 45.90288742 48.80848704 45.9835004  45.642715\n",
            " 42.83649182 43.0420565  49.19391468 48.50755826 45.8226794  49.43423629\n",
            " 45.63068785 33.92552382 44.14661775 49.1465819  49.44697393 44.88835139\n",
            " 48.76793612 49.64486659 32.89081335 32.89081335 47.00408746 34.87436007\n",
            " 44.33010525 47.83692318 49.3257353  43.25403483 48.83929696 48.00577908\n",
            " 26.96387977 48.73149056 49.23328007 46.19496261 47.10321304 49.30240457\n",
            " 46.89101511 49.18679826 47.72163339 43.93834914 46.38721008 36.48163273\n",
            " 46.40160529 37.07794359 46.53323033 23.45975547 49.423706   46.77340081\n",
            " 47.51861732 43.9817477  39.40561441 48.94772278 48.50755826 44.27946783\n",
            " 46.83198668 37.80391236 42.58048822 48.91950774 44.08322137 49.67807318\n",
            " 49.42023302 49.6069959  47.92905968 44.72760664 49.28872448 49.32261232\n",
            " 41.2145963  24.42441922 24.08605364 37.20661661 48.78421043 45.95377269\n",
            " 49.05510844 44.27351647 43.67365068 49.30198045 47.27971219 45.27861573\n",
            " 45.02563908 49.10742004 48.88760019 49.60751766 46.11496592 29.09283296\n",
            " 49.48149845 48.77881249 46.78772366 46.72415822 48.45928374 43.92115915\n",
            " 49.18151386 39.86967569 41.94105927 47.58726766 41.67552308 49.1643029\n",
            " 47.38664289 49.49585924 46.34763477 47.62468115 49.03694962 44.07149221\n",
            " 46.17495067 46.29495083 48.13550015 40.65149818 46.66121187 48.01762233\n",
            " 43.91259447 49.29424304 48.2783525  48.8230512  45.26415619 46.520769\n",
            " 45.99964193 48.78857265 40.14910392 43.27875149 47.64391456 45.5533611\n",
            " 49.5212736  48.68890891 43.59450615 48.68939657 28.12241754 40.08021211\n",
            " 48.60835088 38.19028739 49.30746589 49.77967665 35.30603533 49.2584524\n",
            " 43.41590962 35.60603243 49.41301149 45.96130662 49.5763328  49.25573183\n",
            " 49.39652467 47.88560593 46.87803761 43.26280392 49.42320894 31.04893704\n",
            " 46.9211853  28.33091317 36.83870019 49.33156664 48.79172538 44.28323558\n",
            " 48.88666885 45.49163599 49.62616003 48.61897415 48.95887704 37.59972286\n",
            " 48.78232392 49.35492421 49.60490425 36.00539329 32.80960239 38.8712107\n",
            " 49.46876409 44.66319903 42.57603989 37.4702713  47.35704163 26.08850712\n",
            " 49.56945368 36.09123242 45.5007331  33.32638554 42.34024567 48.72952862\n",
            " 49.10867138 47.85716654 38.45646527 45.3509368  32.89081335 32.89081335\n",
            " 46.38278464 27.43545356 49.48926561 48.66506799 49.37506857 46.2502538\n",
            " 45.15361917 39.42552982 41.40903269 49.13393277 48.75200545 36.22343241\n",
            " 48.7734027  48.62530348 45.48735664 49.47198555 42.78948955 47.21536105\n",
            " 46.9897301  21.79196203 41.92426765 47.05076687 34.45506642 48.56625598\n",
            " 48.94563439 47.54086417 49.564582   48.10876044 42.75981659 49.58195743\n",
            " 49.24677109 48.09056886 38.29208784 36.84471619 49.52316948 49.35142609\n",
            " 49.09231368 49.45725519 29.11828875 49.07437126 48.94920204 33.06101085\n",
            " 47.3639686  49.81190347 49.52361151 49.64481583 32.89081335 48.85362332\n",
            " 47.62520985 49.24039421 32.89081335 48.61255009 48.5409554  34.16362776\n",
            " 49.79828113 31.56495454 49.22742913 46.63492258 46.78661507 46.62753251\n",
            " 42.83085696 49.29546842 49.32939229 48.65867519 45.40647166 48.70164795\n",
            " 40.58414302 48.25346325 38.32174477 49.85587244 32.89081335 46.6691343\n",
            " 48.69827042 48.78582382 48.79614033 48.12957988 42.11697307 45.30116372\n",
            " 47.75655784 48.34177897 45.43083762 48.99934645 48.04919066 49.25635828\n",
            " 42.96766057 37.61215626 42.45706981 46.46309004 48.88842999 47.91259493\n",
            " 46.73523641 48.70419446 49.27774865 42.34386758 49.19096332 40.99024543\n",
            " 49.67557094 40.35997325 41.46139973 49.28788304 35.27795639 49.84753784\n",
            " 49.27772124 47.36963853 48.21106198 31.91716828 47.99206667 42.78943933\n",
            " 45.35630489 42.51626064 43.23947652 47.1838762  45.58313371 36.51902439\n",
            " 45.62392589 49.51148838 48.15037174 44.36502894 49.31913534 41.38146087\n",
            " 47.6620762  48.66404865 49.28798888 49.37239242 47.34041858 36.84399444\n",
            " 28.56027142 49.15212589 48.26688608 42.15641969 46.95201631 48.54860978\n",
            " 40.55890226 47.28532802 48.06296481 49.34659791 46.15990238 49.46068118\n",
            " 42.32395175 44.07071735 46.3895211  49.53388879 47.49173607 49.62386181\n",
            " 44.86808454 35.53832272 49.74808117 40.30839646 45.92882344 46.29357318\n",
            " 49.72174351 48.70396754 49.64978039 48.43991311 48.90249347 47.93159565\n",
            " 46.35992619 48.75389557 32.89081335 48.12102837 49.15377067 32.89081335\n",
            " 47.49699554 39.80716194 40.58267853 48.7734027  49.38704717 48.82414344\n",
            " 47.52474203 47.77429505 45.82690205 49.23328007 48.58830338 48.89540274\n",
            " 45.79964664 40.88580586 43.02779631 49.5682937  49.24204842 46.52738961\n",
            " 49.24328058 39.70530158 43.86171394 49.05902594 49.35895844 48.97650845\n",
            " 48.97523516 43.65521199 49.44807992 49.00890863 47.0634427  46.31679153\n",
            " 44.49850422 41.4563696  46.76405051 48.59104957 48.0409748  41.97110386\n",
            " 31.49922154 47.86755249 48.99536837 47.92255975 48.94734395 32.89081335\n",
            " 48.69382306 49.31937987 49.30020117 49.61933381 40.69673278 32.89081335\n",
            " 48.45243143 48.41139799 48.30432757 49.44841867 48.87286764 44.11753846\n",
            " 49.41546155 46.30347156 49.28823134 41.47210902 42.56274025 48.88770548\n",
            " 45.84188972 45.58961211 45.60083167 48.7600944  49.46105029 41.72175876\n",
            " 37.61947149 49.4048965  47.23140269 39.27880485 46.70166318 49.21330056\n",
            " 17.61945399 47.92466253 33.33625971 49.61631225 41.16211004 49.41570303\n",
            " 39.76720772 46.91164427 47.23831453 39.98194474 48.60035837 47.73152557\n",
            " 48.04680405 40.01269897 42.1277222  48.86322039 48.04687074 36.55337138\n",
            " 48.37776908 32.89081335 46.86258448 35.37348768 46.15852638 32.89081335\n",
            " 49.65049637 47.72748091 49.01130314 47.35849165 44.36740277 44.87107824\n",
            " 42.42101204 49.11575981]\n",
            "selection [  2 870 442 655 501 524 523 623 325 486 196 637 318 580 281  83 601 762\n",
            " 539 674 347  59 294 142 599  91 834 691 741 121 616 797  79 448 129 682\n",
            " 441 389 893 253 304 794 180 280 839  15 706  23 107 889] (50,) [ 8.43665462 17.61945399 21.03843995 21.79196203 23.45975547 24.08605364\n",
            " 24.42441922 26.08850712 26.25592566 26.96387977 27.22048584 27.43545356\n",
            " 27.6032193  28.12241754 28.15074404 28.18098418 28.33091317 28.56027142\n",
            " 29.09283296 29.11828875 29.40339336 30.00469705 30.28022378 30.54598214\n",
            " 31.04893704 31.05509987 31.49922154 31.56495454 31.91716828 32.62302262\n",
            " 32.80960239 32.89081335 32.89081335 32.89081335 32.89081335 32.89081335\n",
            " 32.89081335 32.89081335 32.89081335 32.89081335 32.89081335 32.89081335\n",
            " 32.89081335 32.89081335 32.89081335 32.89081335 32.89081335 32.89081335\n",
            " 32.89081335 32.89081335]\n",
            "trainset before adding uncertain samples (400, 10) (400,)\n",
            "trainset after adding uncertain samples (450, 10) (450,)\n",
            "updated train set: (450, 10) (450,) unique(labels): [229 221] [0 1]\n",
            "val set: (852, 10) (852,)\n",
            "\n",
            "Train set: (450, 10)\n",
            "Validation set: (852, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 9\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 2.344 s \n",
            "\n",
            "Accuracy rate is 79.723502 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.88      0.87       321\n",
            "           1       0.62      0.57      0.59       113\n",
            "\n",
            "    accuracy                           0.80       434\n",
            "   macro avg       0.74      0.72      0.73       434\n",
            "weighted avg       0.79      0.80      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[282  39]\n",
            " [ 49  64]]\n",
            "--------------------------------\n",
            "val predicted: (852,) [1 1 1 0 1 1 0 0 0 0 1 1 0 1 1 0 0 0 1 1 1 1 1 0 0 0 1 1 0 0 1 1 0 0 0 1 1\n",
            " 1 1 0 0 1 1 1 1 1 0 1 0 1 0 0 1 1 1 1 1 0 1 0 0 1 0 0 0 1 0 0 1 1 1 1 0 1\n",
            " 0 1 1 1 0 0 0 1 1 0 1 0 1 0 1 1 0 1 0 1 0 0 1 0 0 0 1 0 1 1 0 1 0 1 1 0 1\n",
            " 1 1 1 1 0 1 1 0 1 1 1 0 1 1 1 1 1 0 0 0 1 1 1 0 1 1 1 0 1 0 1 1 1 1 1 0 0\n",
            " 0 0 0 0 1 1 1 0 0 1 0 0 0 0 0 1 1 0 1 0 0 1 0 1 1 0 1 1 0 1 1 0 0 0 1 1 1\n",
            " 1 1 1 1 1 1 0 0 1 1 1 0 1 1 1 1 0 1 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 0\n",
            " 0 1 1 0 1 0 0 0 1 1 1 1 0 0 0 0 0 1 1 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 1\n",
            " 1 1 1 1 1 1 1 1 1 0 1 0 1 0 1 0 1 0 0 1 1 0 0 1 0 1 0 1 0 1 0 0 0 0 1 1 1\n",
            " 0 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 0 1 0 1 1 0 1 0 0 1 0\n",
            " 1 0 1 1 1 0 1 0 1 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 0 0 0 0 1 1 0 1 1 0 1 0\n",
            " 0 1 0 1 0 0 1 1 1 0 1 1 1 1 0 1 0 1 1 1 0 0 0 0 0 0 1 1 1 1 1 0 0 0 1 1 0\n",
            " 1 1 0 0 1 0 1 0 0 0 1 0 0 1 1 0 0 1 1 0 0 0 1 1 1 0 1 1 1 1 1 0 1 1 0 0 0\n",
            " 1 0 0 1 0 1 1 0 0 1 1 1 0 1 0 1 0 0 1 1 0 1 0 1 1 0 1 1 0 1 1 0 1 1 0 1 1\n",
            " 1 0 1 1 1 1 1 1 1 0 0 1 0 1 1 1 1 1 1 0 1 0 0 0 0 1 0 0 1 1 0 1 1 1 0 1 1\n",
            " 0 1 0 1 1 0 0 1 0 1 0 0 1 0 0 1 0 1 1 1 1 0 0 1 1 0 1 1 0 1 1 1 1 0 1 1 0\n",
            " 1 0 0 1 1 0 1 1 1 1 1 0 1 1 0 1 1 1 0 1 0 1 0 1 1 1 1 1 0 1 1 1 0 1 1 1 0\n",
            " 1 0 1 0 1 1 1 0 0 1 1 0 1 0 0 0 1 0 0 0 1 1 0 1 0 0 1 1 1 0 1 0 0 1 0 1 1\n",
            " 1 1 0 0 0 0 1 0 1 1 1 1 0 0 1 1 0 0 0 0 1 0 0 1 0 1 0 0 1 0 0 1 1 1 0 0 0\n",
            " 1 1 0 0 1 1 0 1 0 1 0 1 0 1 1 0 0 0 1 0 0 1 0 1 1 0 1 0 0 1 0 0 0 0 0 1 1\n",
            " 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 0 1 0 0 1 1 0 1 1 1 0 1 0 1 0 0 0 0 0 1\n",
            " 0 1 0 1 0 1 1 0 0 0 1 1 0 1 1 1 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 1 0 1 1 0 1\n",
            " 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 0 1 1 0 1 0 0 0 1 0 1 1 0 1 0 0 1 0 1 0 1 1\n",
            " 1 0 1 1 1 1 0 1 0 0 0 0 1 1 1 0 0 1 0 0 1 0 1 1 1 1 0 1 1 1 0 0 1 0 1 1 0\n",
            " 0]\n",
            "probabilities: (852, 2) \n",
            " [1 1 1 0 1 1 0 0 0 0 1 1 0 1 1 0 0 0 1 1 1 1 1 0 0 0 1 1 0 0 1 1 0 0 0 1 1\n",
            " 1 1 0 0 1 1 1 1 1 0 1 0 1 0 0 1 1 1 1 1 0 1 0 0 1 0 0 0 1 0 0 1 1 1 1 0 1\n",
            " 0 1 1 1 0 0 0 1 1 0 1 0 1 0 1 1 0 1 0 1 0 0 1 0 0 0 1 0 1 1 0 1 0 1 1 0 1\n",
            " 1 1 1 1 0 1 1 0 1 1 1 0 1 1 1 1 1 0 0 0 1 1 1 0 1 1 1 0 1 0 1 1 1 1 1 0 0\n",
            " 0 0 0 0 1 1 1 0 0 1 0 0 0 0 0 1 1 0 1 0 0 1 0 1 1 0 1 1 0 1 1 0 0 0 1 1 1\n",
            " 1 1 1 1 1 1 0 0 1 1 1 0 1 1 1 1 0 1 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 0\n",
            " 0 1 1 0 1 0 0 0 1 1 1 1 0 0 0 0 0 1 1 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 1\n",
            " 1 1 1 1 1 1 1 1 1 0 1 0 1 0 1 0 1 0 0 1 1 0 0 1 0 1 0 1 0 1 0 0 0 0 1 1 1\n",
            " 0 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 0 1 0 1 1 0 1 0 0 1 0\n",
            " 1 0 1 1 1 0 1 0 1 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 0 0 0 0 1 1 0 1 1 0 1 0\n",
            " 0 1 0 1 0 0 1 1 1 0 1 1 1 1 0 1 0 1 1 1 0 0 0 0 0 0 1 1 1 1 1 0 0 0 1 1 0\n",
            " 1 1 0 0 1 0 1 0 0 0 1 0 0 1 1 0 0 1 1 0 0 0 1 1 1 0 1 1 1 1 1 0 1 1 0 0 0\n",
            " 1 0 0 1 0 1 1 0 0 1 1 1 0 1 0 1 0 0 1 1 0 1 0 1 1 0 1 1 0 1 1 0 1 1 0 1 1\n",
            " 1 0 1 1 1 1 1 1 1 0 0 1 0 1 1 1 1 1 1 0 1 0 0 0 0 1 0 0 1 1 0 1 1 1 0 1 1\n",
            " 0 1 0 1 1 0 0 1 0 1 0 0 1 0 0 1 0 1 1 1 1 0 0 1 1 0 1 1 0 1 1 1 1 0 1 1 0\n",
            " 1 0 0 1 1 0 1 1 1 1 1 0 1 1 0 1 1 1 0 1 0 1 0 1 1 1 1 1 0 1 1 1 0 1 1 1 0\n",
            " 1 0 1 0 1 1 1 0 0 1 1 0 1 0 0 0 1 0 0 0 1 1 0 1 0 0 1 1 1 0 1 0 0 1 0 1 1\n",
            " 1 1 0 0 0 0 1 0 1 1 1 1 0 0 1 1 0 0 0 0 1 0 0 1 0 1 0 0 1 0 0 1 1 1 0 0 0\n",
            " 1 1 0 0 1 1 0 1 0 1 0 1 0 1 1 0 0 0 1 0 0 1 0 1 1 0 1 0 0 1 0 0 0 0 0 1 1\n",
            " 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 0 1 0 0 1 1 0 1 1 1 0 1 0 1 0 0 0 0 0 1\n",
            " 0 1 0 1 0 1 1 0 0 0 1 1 0 1 1 1 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 1 0 1 1 0 1\n",
            " 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 0 1 1 0 1 0 0 0 1 0 1 1 0 1 0 0 1 0 1 0 1 1\n",
            " 1 0 1 1 1 1 0 1 0 0 0 0 1 1 1 0 0 1 0 0 1 0 1 1 1 1 0 1 1 1 0 0 1 0 1 1 0\n",
            " 0]\n",
            "std (852,) [46.11358464 47.77677924 41.97323213 40.53789822 49.05912408 41.31045396\n",
            " 43.20315227 49.16790034 33.49271245 49.2058248  49.20503146 43.25282025\n",
            " 48.03348593 47.47035403 37.67389593 46.41032163 38.51105211 45.8173648\n",
            " 48.22585884 49.34461431 48.44648332 48.82263431 48.33222717 18.54848503\n",
            " 41.92117007 48.10592996 46.05916096 41.5596964  49.62840286 49.63555402\n",
            " 40.91736189 45.07528422 35.36233588 49.25912553 44.92073118 46.62714376\n",
            " 45.44633518 46.71828162 48.76663256 40.81096684 47.76691427 49.07252063\n",
            " 41.74669004 48.88890932 47.81437082 41.98477916 47.27358202 49.14925024\n",
            " 40.70011172 48.92170742 47.74723751 49.13397137 47.45505068 46.41913859\n",
            " 48.26015882 46.88191253 49.32225207 48.89976822 48.3203419  35.59493715\n",
            " 49.21582079 49.27034404 38.68863397 28.05868837 49.15762096 47.6602494\n",
            " 48.57393423 44.40995709 48.76322798 48.52627052 46.47880946 42.2756785\n",
            " 44.99957334 48.71608044 48.65328254 47.96915266 33.97150919 47.09983346\n",
            " 46.55974791 47.95413763 49.45739561 41.58721887 45.49723292 49.16073007\n",
            " 49.24693618 44.27298041 49.50757282 49.17091592 48.13450539 49.16698618\n",
            " 36.87164075 47.7696447  49.18275476 42.87431853 49.55755478 49.4922779\n",
            " 44.07713827 44.88100404 48.7349764  48.01232088 48.95683838 49.54051021\n",
            " 48.20226152 44.38010025 48.10473255 45.25847341 49.03412543 48.83496849\n",
            " 37.87338554 42.88716366 45.09626416 37.219036   48.13001919 45.78111372\n",
            " 47.48380997 42.8058819  49.0244739  48.5073178  45.09584592 34.02709211\n",
            " 49.15866153 45.31735052 49.38886849 47.84343744 36.09484856 48.25166317\n",
            " 48.91736275 45.14644372 39.53851008 49.24984954 36.94663091 49.02614055\n",
            " 47.65482009 45.76114143 43.09226562 43.67891153 44.05909461 44.18709128\n",
            " 49.28228386 44.03336917 45.52212255 47.57547198 44.11872002 47.7386968\n",
            " 48.43100576 47.81271399 48.06705554 48.06934151 32.49373172 45.27627643\n",
            " 44.12072361 45.91125306 46.73100168 48.20731173 48.53229785 30.81902068\n",
            " 42.92383834 48.45515503 47.67337493 45.44002004 49.50809956 46.79947847\n",
            " 49.48860945 48.50893676 36.49096092 45.34131202 41.08880002 49.42763869\n",
            " 49.73639307 45.18021515 48.97365248 47.07850908 39.09733798 48.19290747\n",
            " 49.13085496 46.8284577  49.31619767 42.24528592 48.99541039 42.49193297\n",
            " 49.78957484 46.62914085 49.57718741 43.57306711 49.2360809  45.23584379\n",
            " 46.06135759 48.27095043 43.91893264 45.84514482 45.0349018  48.98855939\n",
            " 48.75932006 46.50802715 48.66934742 48.63260513 47.86635272 48.6951522\n",
            " 47.65990316 48.10855695 46.22030348 47.80467688 43.95549194 49.5655145\n",
            " 49.45101355 49.37887115 48.44164982 40.43659238 37.53006296 49.26759342\n",
            " 44.88099888 48.65207174 15.15346153 46.96491061 40.27830367 49.44602785\n",
            " 46.97719472 47.25658332 41.40132972 43.69835981 48.26484818 49.67300702\n",
            " 49.06400253 48.61319134 46.9662349  48.03867491 48.11104531 39.78866428\n",
            " 46.08355602 44.74148824 44.86698085 48.80799042 48.27363349 48.94444164\n",
            " 47.04448456 45.52212255 49.55180042 45.52212255 34.11298677 49.13176877\n",
            " 49.1695739  48.94248316 48.3584741  49.14627091 45.98918312 47.20686565\n",
            " 48.14723897 49.50893731 47.6014229  43.08922223 44.83604987 44.46722163\n",
            " 39.50099239 32.10879219 48.93821246 48.32037167 44.91149024 46.74191127\n",
            " 48.6869961  47.84534881 47.22628433 48.44255904 31.25820374 43.94189134\n",
            " 45.47363764 49.26417135 48.24357637 47.54294712 49.21582079 49.02074657\n",
            " 39.51620414 48.89772772 43.06620405 44.73111824 41.39905756 45.86045375\n",
            " 49.58382514 44.00864738 46.52025574 44.67343534 42.42862978 49.27377456\n",
            " 49.74266235 41.9850056  35.34848987 49.55576587 48.75087804 41.69059297\n",
            " 48.96512274 46.54385537 49.45594502 35.5066793  45.96409916 47.61673648\n",
            " 47.51873429 47.66392923 27.87672993 38.69920032 49.18611229 46.6622535\n",
            " 25.28788244 46.66786403 47.46187929 41.77137563 48.01599813 48.18803724\n",
            " 40.13934903 48.25666646 45.47711487 47.92443772 49.59071569 48.65994191\n",
            " 48.01812566 38.85505187 48.73594666 48.39825361 48.15780018 49.02839816\n",
            " 42.14645887 49.48281077 49.06196384 47.57302255 46.58075224 35.90424399\n",
            " 48.58272627 45.15142924 46.03655226 44.61152484 49.00710543 45.52212255\n",
            " 45.52212255 48.61910937 45.97089911 48.15027471 49.26160999 48.92110963\n",
            " 47.82564176 48.18942649 48.34639867 44.38032294 44.87918038 45.44614921\n",
            " 46.83575374 45.1845191  49.05886954 49.55060113 41.51487825 46.02268322\n",
            " 48.6363497  49.02691731 47.65875817 46.80093765 48.68525785 49.15794433\n",
            " 47.65990851 48.69005665 47.84563597 42.18019496 49.72323973 43.63346754\n",
            " 45.6363754  40.04065834 48.10396229 48.24772198 49.05473952 42.74083219\n",
            " 47.92713656 38.94467311 48.99954067 46.99757515 45.49187564 45.97043298\n",
            " 47.53412083 48.97154556 47.07711606 39.3092847  48.56193611 43.49963101\n",
            " 47.19197537 45.96145791 48.7572391  48.54980335 46.36437765 48.50784712\n",
            " 48.85933922 48.33485105 49.4479341  49.17169844 46.8707852  35.57100128\n",
            " 42.20978624 42.4872545  48.92803492 48.02473883 49.68100812 33.91885374\n",
            " 46.26529054 47.4087379  47.45665549 49.21271962 47.31829054 49.47171767\n",
            " 49.71536705 47.80948657 47.70779761 46.1408197  36.87394177 48.18050688\n",
            " 39.01041749 32.30555486 49.51497774 47.6675607  49.0773627  42.98900181\n",
            " 44.58888896 45.20280451 42.38598461 34.17617423 48.95340454 49.56490744\n",
            " 47.01830211 47.16635245 38.28152212 43.39753778 48.07411593 36.18526226\n",
            " 45.05664782 49.50812814 47.38801933 47.99638974 46.13039244 49.57545823\n",
            " 36.41741252 45.99326513 48.56727539 45.00789989 44.95074263 39.60107144\n",
            " 45.07430586 49.27775453 48.15208715 39.08296105 49.33684496 45.80521654\n",
            " 36.70508535 44.41459662 48.78624893 49.4763613  44.16822563 48.37078371\n",
            " 49.46129224 45.52212255 45.52212255 46.13808137 31.31144282 45.3718229\n",
            " 47.81167389 49.36389972 37.76133683 48.53048693 47.57873519 48.0737102\n",
            " 49.20236618 47.03555673 46.56048551 49.313612   46.9836472  48.99116144\n",
            " 48.21397716 45.22285983 46.71383783 38.69920032 46.5952883  41.67539755\n",
            " 46.68410854 49.19631736 47.3808314  45.63232531 43.95053025 31.7491037\n",
            " 48.72217468 48.15208715 43.37686037 46.35831461 34.08996857 39.56974611\n",
            " 49.19225457 46.65082601 49.66289214 49.53072788 49.49463745 47.77770578\n",
            " 45.66811353 49.15002259 49.02927526 43.33118248 34.2119775  48.77862077\n",
            " 45.2316953  49.03288797 40.26084269 44.61283273 49.10014694 47.08044607\n",
            " 46.54266954 44.96590011 49.0785682  47.6981887  49.59359861 43.49540536\n",
            " 49.2849092  46.93059401 47.14146969 47.25151044 47.90469652 43.90092068\n",
            " 49.25320976 41.61531865 36.52229049 48.35039837 36.30087712 48.93103275\n",
            " 47.56740235 49.29775327 46.33832197 44.94346364 49.24760828 43.84271917\n",
            " 45.37377963 46.35351916 46.90537521 40.44061802 46.95796237 46.71645174\n",
            " 47.66343374 49.06696457 48.43164897 48.79600502 45.5763107  43.83475739\n",
            " 44.57599577 48.22932175 29.05381266 40.57722968 45.88179772 43.56076188\n",
            " 48.9920589  49.13357327 44.7908347  48.97249561 43.9854716  48.2459904\n",
            " 40.30521926 48.94817064 49.64928298 40.90778043 49.15234646 44.421492\n",
            " 36.40957365 49.33904792 42.9730184  49.56120536 48.9816698  49.21995025\n",
            " 45.32352051 46.65683444 42.87119774 49.40646206 42.14228658 35.55340617\n",
            " 49.24319729 48.6605025  43.82420214 48.13658705 44.99855055 49.37643222\n",
            " 48.44255904 48.69015252 27.40510523 48.55072468 49.38601138 49.48590747\n",
            " 28.98809953 40.12715353 49.13376162 45.97197404 37.9915369  43.72622729\n",
            " 47.84849482 49.49680562 40.0879745  37.21811454 38.25756179 39.10855003\n",
            " 48.39495438 48.44661402 48.22388633 35.68798877 43.56590463 45.52212255\n",
            " 45.52212255 43.94047901 49.37637975 48.95174359 49.39538259 47.06221524\n",
            " 44.39439528 35.54657904 41.64423238 49.30121422 48.72334979 36.8047035\n",
            " 48.69478837 48.35086714 47.58858104 49.17195985 36.63383816 47.39130708\n",
            " 47.83150193 43.21788054 46.7486075  39.30619361 48.49745393 48.34113347\n",
            " 47.55927232 49.26837849 47.97104861 42.33743255 49.33884562 48.68301572\n",
            " 46.64297643 35.0699334  37.98240403 49.45581406 49.48508597 49.37618143\n",
            " 49.52181867 49.03723184 48.99457092 26.22800328 46.76960142 49.7679797\n",
            " 49.24690936 49.63101625 48.32885096 46.58205704 49.21075803 45.52212255\n",
            " 47.18473507 47.71454085 25.25350202 49.71331822 48.82641176 44.31251614\n",
            " 43.25890707 45.47444773 44.99502166 49.2325688  49.08055835 48.91258486\n",
            " 46.41017612 46.54301127 41.08356737 48.84121103 35.8997121  49.71267395\n",
            " 46.98440869 47.75570805 48.8343643  48.78868389 48.19672139 42.62582221\n",
            " 43.52924979 45.77372147 48.00826098 39.91954792 48.70259789 48.05100687\n",
            " 49.20810698 45.44213828 40.14064138 42.20262171 43.75239324 48.44290217\n",
            " 47.82439591 48.51203206 47.87304342 49.1415118  43.62612142 49.05965085\n",
            " 39.70664917 49.24282376 43.71272688 39.55664632 49.20172918 39.51876035\n",
            " 49.71078266 49.04162453 47.84888234 48.66486617 47.01860308 42.58065487\n",
            " 41.24511736 35.3708939  42.78178154 45.11468142 43.52590637 42.03564651\n",
            " 45.43138669 49.55262768 47.16158931 45.48554311 49.30743751 43.35357255\n",
            " 43.61859229 48.41965527 48.83769203 49.30335313 46.88582026 40.58797768\n",
            " 49.41885694 48.37993698 41.11988091 46.69366048 48.37692635 40.02284823\n",
            " 48.00166418 47.74433502 48.81220772 45.6254483  49.46606942 41.7076065\n",
            " 44.1458196  47.40405631 49.44892839 46.05510168 49.385792   40.82408935\n",
            " 32.98082127 49.60190542 38.20976284 46.71088754 42.1853481  49.60935296\n",
            " 48.74169341 49.50961487 47.6922002  48.96512411 48.2867955  47.56878858\n",
            " 48.92187107 48.33215486 49.17888751 47.46165938 43.54957141 37.67389593\n",
            " 48.69478837 49.12344119 49.00907142 44.37211698 47.72683355 45.84514482\n",
            " 49.20236618 48.61647643 48.76677196 46.18796914 38.09270322 40.8505429\n",
            " 49.55072078 49.3231561  46.47880946 48.69859435 38.8627934  44.040274\n",
            " 48.66284151 49.42179374 48.37188694 48.89319521 44.28938209 47.77056881\n",
            " 49.0594508  47.2590392  44.25009234 43.54257809 39.22120121 46.81139158\n",
            " 48.59127863 46.04350979 39.6274898  46.91200037 48.47398182 46.63731534\n",
            " 48.77698297 48.48825535 49.31002188 49.06500337 49.51896775 41.29364378\n",
            " 45.52212255 48.03241658 48.84837538 48.29555131 49.1150391  48.88615114\n",
            " 42.65789426 49.2702581  45.4138403  48.63182742 40.4876681  41.59414621\n",
            " 48.14761915 44.26533923 45.04801599 45.32059185 48.74751081 49.03335823\n",
            " 42.35775338 32.69854149 49.18502635 47.30380601 31.25601871 44.71403794\n",
            " 49.27716916 47.35523654 28.57780444 49.60814868 39.60745823 49.33930091\n",
            " 39.1516218  45.77531081 46.67156516 29.30665966 49.0544646  46.14604119\n",
            " 47.66925859 42.81801072 43.39375588 48.42322036 48.28165511 37.72019426\n",
            " 47.6408819  47.84447151 38.00072167 45.3489863  49.39284067 48.87992066\n",
            " 49.14225666 47.18697063 45.76469695 45.60315446 42.59316145 48.76815241]\n",
            "selection [212  23 650 300 639 578 296  63 824 582 542 831 155 820 262 454 479 253\n",
            " 409 148 817 738   8 395  76 119 484 238 417 496 631 284  32 703 291 607\n",
            " 569 389  59 597 664 323 124 425 520 558 432 164 518 616] (50,) [15.15346153 18.54848503 25.25350202 25.28788244 26.22800328 27.40510523\n",
            " 27.87672993 28.05868837 28.57780444 28.98809953 29.05381266 29.30665966\n",
            " 30.81902068 31.25601871 31.25820374 31.31144282 31.7491037  32.10879219\n",
            " 32.30555486 32.49373172 32.69854149 32.98082127 33.49271245 33.91885374\n",
            " 33.97150919 34.02709211 34.08996857 34.11298677 34.17617423 34.2119775\n",
            " 35.0699334  35.34848987 35.36233588 35.3708939  35.5066793  35.54657904\n",
            " 35.55340617 35.57100128 35.59493715 35.68798877 35.8997121  35.90424399\n",
            " 36.09484856 36.18526226 36.30087712 36.40957365 36.41741252 36.49096092\n",
            " 36.52229049 36.63383816]\n",
            "trainset before adding uncertain samples (450, 10) (450,)\n",
            "trainset after adding uncertain samples (500, 10) (500,)\n",
            "updated train set: (500, 10) (500,) unique(labels): [252 248] [0 1]\n",
            "val set: (802, 10) (802,)\n",
            "\n",
            "Train set: (500, 10)\n",
            "Validation set: (802, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 10\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 2.430 s \n",
            "\n",
            "Accuracy rate is 79.723502 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.88      0.86       321\n",
            "           1       0.62      0.58      0.60       113\n",
            "\n",
            "    accuracy                           0.80       434\n",
            "   macro avg       0.74      0.73      0.73       434\n",
            "weighted avg       0.79      0.80      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[281  40]\n",
            " [ 48  65]]\n",
            "--------------------------------\n",
            "final active learning accuracies [79.95391705069125, 76.95852534562212, 80.18433179723502, 79.49308755760369, 79.26267281105991, 79.72350230414746, 79.95391705069125, 79.72350230414746, 79.72350230414746, 79.72350230414746]\n",
            "saved /Users/wenxuanhuang/Documents/Repo/ML-for-COVID-19-dataset/Results/Active-learning-experiment-18.pkl /Users/wenxuanhuang/Documents/Repo/ML-for-COVID-19-dataset ['Decision_tree.ipynb', 'dec_git.png', 'Logit_default_f10.pdf', 'Logistic.ipynb', 'SVC.ipynb', 'RF_f5e50_featureimp.pdf', 'log_al.png', 'dec_git.pdf', '.DS_Store', 'log_git.png', 'svm_git.png', 'Logistic_Scikit.ipynb', 'knn_git.pdf', 'knn_git.png', 'rf_al.png', 'Best classifier_RF_f5e50.pdf', 'KNN.ipynb', 'GBDC.ipynb', 'rf_git.png', 'README.md', 'all_training.csv', 'Results', 'svm_al.png', 'Log_ROC.png', 'Logit_default_f7(p_removal).pdf', 'Active_learning.ipynb', 'Random_forest.ipynb', 'Model_select.ipynb', 'gdbc_git.png', '.git', '.vscode', 'Untitled', 'RF_f5e50_modelselect.pdf', 'Logit_default_f8(std_removal).pdf']\n",
            "\n",
            "---------------------------- FINISHED ---------------------------\n",
            "\n",
            "Count = 19, using model = GDBCModel, selection_function = MinStdSelection, k = 25, iteration = 0.\n",
            "\n",
            "initial random chosen samples (25,)\n",
            "initial train set: (25, 10) (25,) unique(labels): [15 10] [0 1]\n",
            "Val set: (1277, 10) (1277,) (25,)\n",
            "\n",
            "Train set: (25, 10)\n",
            "Validation set: (1277, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.984 s \n",
            "\n",
            "Accuracy rate is 77.649770 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.84      0.85       321\n",
            "           1       0.57      0.59      0.58       113\n",
            "\n",
            "    accuracy                           0.78       434\n",
            "   macro avg       0.71      0.72      0.71       434\n",
            "weighted avg       0.78      0.78      0.78       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[270  51]\n",
            " [ 46  67]]\n",
            "--------------------------------\n",
            "val predicted: (1277,) [0 1 1 ... 0 0 1]\n",
            "probabilities: (1277, 2) \n",
            " [0 1 1 ... 0 0 1]\n",
            "std (1277,) [44.2020396  37.82287766 45.72698233 ... 49.99670208 49.98447281\n",
            " 45.91724557]\n",
            "selection [ 294   15  115  760  979 1063  286   37  186   94  935  612  906  891\n",
            "  557  850  777   17  652 1177 1171  538  370  599  283] (25,) [0.22164878 0.22348754 0.24839655 0.44343023 0.55015453 0.92319368\n",
            " 1.06447767 1.48540211 1.6016635  2.08619578 2.78840606 3.01214147\n",
            " 3.09057269 3.43854742 3.74050878 3.7954645  4.35288968 4.38363018\n",
            " 4.70258132 4.97638597 4.98182069 5.5400471  5.55687886 6.16599629\n",
            " 6.20569025]\n",
            "trainset before adding uncertain samples (25, 10) (25,)\n",
            "trainset after adding uncertain samples (50, 10) (50,)\n",
            "updated train set: (50, 10) (50,) unique(labels): [28 22] [0 1]\n",
            "val set: (1252, 10) (1252,)\n",
            "\n",
            "Train set: (50, 10)\n",
            "Validation set: (1252, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.995 s \n",
            "\n",
            "Accuracy rate is 77.880184 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.88      0.85       321\n",
            "           1       0.59      0.50      0.54       113\n",
            "\n",
            "    accuracy                           0.78       434\n",
            "   macro avg       0.71      0.69      0.70       434\n",
            "weighted avg       0.77      0.78      0.77       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[281  40]\n",
            " [ 56  57]]\n",
            "--------------------------------\n",
            "val predicted: (1252,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1252, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "std (1252,) [49.50673414 49.69368649 49.93347966 ... 49.95926914 49.97594788\n",
            " 12.84909647]\n",
            "selection [ 356  831  314  492    8  944 1172  442 1222  254  301   91  982  910\n",
            "  128  476 1187  402  896  818  238  788  517  398  632] (25,) [0.09618915 0.70787262 1.28600705 1.67977299 1.74212613 1.78339358\n",
            " 1.88430221 2.05234842 2.45592457 2.61531005 3.18774185 3.4896179\n",
            " 4.19888366 4.36352059 4.51020626 6.48202656 6.77347448 6.85195288\n",
            " 7.66585025 8.56445153 8.77105997 8.88168445 9.04321293 9.38028976\n",
            " 9.44655448]\n",
            "trainset before adding uncertain samples (50, 10) (50,)\n",
            "trainset after adding uncertain samples (75, 10) (75,)\n",
            "updated train set: (75, 10) (75,) unique(labels): [41 34] [0 1]\n",
            "val set: (1227, 10) (1227,)\n",
            "\n",
            "Train set: (75, 10)\n",
            "Validation set: (1227, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 3\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.946 s \n",
            "\n",
            "Accuracy rate is 73.041475 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.78      0.81       321\n",
            "           1       0.49      0.60      0.54       113\n",
            "\n",
            "    accuracy                           0.73       434\n",
            "   macro avg       0.67      0.69      0.67       434\n",
            "weighted avg       0.75      0.73      0.74       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[249  72]\n",
            " [ 45  68]]\n",
            "--------------------------------\n",
            "val predicted: (1227,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1227, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "std (1227,) [37.02203545 49.7907905  49.51909133 ... 49.90803801 49.98921432\n",
            " 27.91434712]\n",
            "selection [ 322  880  730  859  145 1218   26  846 1013 1053   91  401  741  687\n",
            "  259  842   50   42  908  849  209   16  864  273  167] (25,) [0.43195136 0.52889866 0.96658099 1.13959182 1.64754814 2.0073584\n",
            " 2.25205803 2.39165367 2.7805671  3.0197468  3.11946903 3.62771216\n",
            " 4.00831783 4.11610459 4.76008006 4.77647773 4.85799146 5.13489908\n",
            " 5.621903   6.1046798  6.21867102 6.49038056 6.49038056 6.6391227\n",
            " 7.17879752]\n",
            "trainset before adding uncertain samples (75, 10) (75,)\n",
            "trainset after adding uncertain samples (100, 10) (100,)\n",
            "updated train set: (100, 10) (100,) unique(labels): [52 48] [0 1]\n",
            "val set: (1202, 10) (1202,)\n",
            "\n",
            "Train set: (100, 10)\n",
            "Validation set: (1202, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 4\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.068 s \n",
            "\n",
            "Accuracy rate is 74.193548 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.80      0.82       321\n",
            "           1       0.50      0.58      0.54       113\n",
            "\n",
            "    accuracy                           0.74       434\n",
            "   macro avg       0.67      0.69      0.68       434\n",
            "weighted avg       0.76      0.74      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[256  65]\n",
            " [ 47  66]]\n",
            "--------------------------------\n",
            "val predicted: (1202,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1202, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "std (1202,) [44.31684418 49.08889219 48.03606602 ... 48.8954734  49.96731834\n",
            " 34.76574173]\n",
            "selection [ 166  911  223  207 1050  604  812 1018  274 1157  817  372 1105  703\n",
            "  271   25  169  163  162  461  423  746  122  225   24] (25,) [0.18136265 0.20101124 0.21685101 0.35905533 0.6148845  0.72926971\n",
            " 0.74125479 1.14832321 1.14832321 1.32282685 1.41329579 1.73775895\n",
            " 1.82473288 2.11516451 2.41777527 2.54621537 3.10542427 3.52411482\n",
            " 3.5434606  3.57251808 3.68048817 3.68369832 4.13783623 4.36562583\n",
            " 4.82938138]\n",
            "trainset before adding uncertain samples (100, 10) (100,)\n",
            "trainset after adding uncertain samples (125, 10) (125,)\n",
            "updated train set: (125, 10) (125,) unique(labels): [69 56] [0 1]\n",
            "val set: (1177, 10) (1177,)\n",
            "\n",
            "Train set: (125, 10)\n",
            "Validation set: (1177, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 5\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.991 s \n",
            "\n",
            "Accuracy rate is 80.645161 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.91      0.87       321\n",
            "           1       0.67      0.50      0.58       113\n",
            "\n",
            "    accuracy                           0.81       434\n",
            "   macro avg       0.76      0.71      0.73       434\n",
            "weighted avg       0.80      0.81      0.80       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[293  28]\n",
            " [ 56  57]]\n",
            "--------------------------------\n",
            "val predicted: (1177,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1177, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "std (1177,) [44.71203016 46.83211234 46.92340158 ... 49.60096292 49.89150035\n",
            "  8.74968045]\n",
            "selection [ 369  931  958  134  178 1058  578  571  358  653  327  400   53  375\n",
            " 1070  975  771  233 1028 1092  462  217  582  812  899] (25,) [0.1928831  0.31187949 1.51360395 1.58499717 1.61576819 1.89249366\n",
            " 1.9063524  2.61934818 3.20877674 3.24098987 3.58455773 3.60201898\n",
            " 3.6531766  3.79243809 3.80507029 4.27122036 4.31340744 4.39774205\n",
            " 4.44914061 4.6314785  4.64014052 4.76423843 4.90293309 5.12271826\n",
            " 5.27374145]\n",
            "trainset before adding uncertain samples (125, 10) (125,)\n",
            "trainset after adding uncertain samples (150, 10) (150,)\n",
            "updated train set: (150, 10) (150,) unique(labels): [81 69] [0 1]\n",
            "val set: (1152, 10) (1152,)\n",
            "\n",
            "Train set: (150, 10)\n",
            "Validation set: (1152, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 6\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.920 s \n",
            "\n",
            "Accuracy rate is 80.184332 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.91      0.87       321\n",
            "           1       0.66      0.49      0.56       113\n",
            "\n",
            "    accuracy                           0.80       434\n",
            "   macro avg       0.75      0.70      0.72       434\n",
            "weighted avg       0.79      0.80      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[293  28]\n",
            " [ 58  55]]\n",
            "--------------------------------\n",
            "val predicted: (1152,) [0 1 1 ... 0 0 1]\n",
            "probabilities: (1152, 2) \n",
            " [0 1 1 ... 0 0 1]\n",
            "std (1152,) [30.74415871 47.8630148  44.95935971 ... 49.63917312 49.13217193\n",
            " 19.63947814]\n",
            "selection [1078  636  406  444  954  783 1036  102  425 1021 1053  451  509   50\n",
            "  980   76  566  578  299  701  888  975  366  183  197] (25,) [0.19336341 0.58296705 0.68630657 0.74418455 1.51934879 1.66479292\n",
            " 1.6906896  1.6906896  1.7124123  1.99812067 2.25899131 2.58687546\n",
            " 2.64492418 2.74080117 3.14854814 4.08641648 4.13110178 4.33538552\n",
            " 4.72181089 5.04968213 5.07392875 5.17434554 5.19190921 5.41493963\n",
            " 5.59839479]\n",
            "trainset before adding uncertain samples (150, 10) (150,)\n",
            "trainset after adding uncertain samples (175, 10) (175,)\n",
            "updated train set: (175, 10) (175,) unique(labels): [87 88] [0 1]\n",
            "val set: (1127, 10) (1127,)\n",
            "\n",
            "Train set: (175, 10)\n",
            "Validation set: (1127, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 7\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.948 s \n",
            "\n",
            "Accuracy rate is 79.723502 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.89      0.87       321\n",
            "           1       0.63      0.52      0.57       113\n",
            "\n",
            "    accuracy                           0.80       434\n",
            "   macro avg       0.74      0.71      0.72       434\n",
            "weighted avg       0.79      0.80      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[287  34]\n",
            " [ 54  59]]\n",
            "--------------------------------\n",
            "val predicted: (1127,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1127, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "std (1127,) [35.71741752 46.9433632  46.89554687 ... 49.31964962 49.00313688\n",
            " 12.70037747]\n",
            "selection [ 713  144  304  674  511  776  913   91  819 1061  558  202  494  775\n",
            "  206  479  441  428  427  592  168  105  314  312 1106] (25,) [0.89146584 0.89879528 1.13870443 1.61891426 1.69773902 1.89094404\n",
            " 2.1371151  2.21005108 2.27376003 2.3679153  2.42646895 2.49289807\n",
            " 2.89471219 2.92324296 3.96161847 4.68830303 4.75428811 5.28915688\n",
            " 5.28915688 5.28915688 5.28915688 5.28915688 5.28915688 5.28915688\n",
            " 5.28915688]\n",
            "trainset before adding uncertain samples (175, 10) (175,)\n",
            "trainset after adding uncertain samples (200, 10) (200,)\n",
            "updated train set: (200, 10) (200,) unique(labels): [101  99] [0 1]\n",
            "val set: (1102, 10) (1102,)\n",
            "\n",
            "Train set: (200, 10)\n",
            "Validation set: (1102, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 8\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.079 s \n",
            "\n",
            "Accuracy rate is 80.875576 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.91      0.88       321\n",
            "           1       0.67      0.53      0.59       113\n",
            "\n",
            "    accuracy                           0.81       434\n",
            "   macro avg       0.76      0.72      0.73       434\n",
            "weighted avg       0.80      0.81      0.80       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[291  30]\n",
            " [ 53  60]]\n",
            "--------------------------------\n",
            "val predicted: (1102,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1102, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "std (1102,) [39.4964138  44.56968634 47.09403604 ... 48.87468908 49.22192279\n",
            " 19.83440235]\n",
            "selection [ 608 1065 1073  804  777  574  667  987  370  963  775  738  872   14\n",
            " 1063  306  246  876  113  500  900  524  401  995  103] (25,) [0.79438386 0.81684203 0.88291878 1.23234857 1.26088963 1.44796743\n",
            " 2.21688398 2.58083797 3.52693725 5.10086761 5.25032687 5.86470254\n",
            " 5.86818373 6.1976053  6.24590983 6.54460047 6.55647116 6.55647116\n",
            " 6.72078201 6.79242357 7.15993695 7.53175203 7.63690848 8.28269894\n",
            " 8.45820674]\n",
            "trainset before adding uncertain samples (200, 10) (200,)\n",
            "trainset after adding uncertain samples (225, 10) (225,)\n",
            "updated train set: (225, 10) (225,) unique(labels): [113 112] [0 1]\n",
            "val set: (1077, 10) (1077,)\n",
            "\n",
            "Train set: (225, 10)\n",
            "Validation set: (1077, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 9\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.054 s \n",
            "\n",
            "Accuracy rate is 81.336406 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.91      0.88       321\n",
            "           1       0.67      0.55      0.60       113\n",
            "\n",
            "    accuracy                           0.81       434\n",
            "   macro avg       0.76      0.73      0.74       434\n",
            "weighted avg       0.80      0.81      0.81       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[291  30]\n",
            " [ 51  62]]\n",
            "--------------------------------\n",
            "val predicted: (1077,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1077, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "std (1077,) [42.548525   41.15628908 44.25190764 ... 48.07646196 48.64530613\n",
            " 19.52662452]\n",
            "selection [ 854  632   81  566  974  638  216   89  883 1040  250   73  363  865\n",
            "  947  533  801  951  259  989  407  733  220  631 1038] (25,) [ 1.1725917   1.74601695  2.03394029  2.10130401  2.15501822  2.2710094\n",
            "  3.24312667  3.68053532  4.06407078  4.22867002  5.00168253  5.26026842\n",
            "  6.49029468  7.14972675  8.1359832   9.0634765   9.53673438  9.63525864\n",
            "  9.70007287  9.92056335  9.98206543 10.09675534 10.34292646 11.09724027\n",
            " 11.2214502 ]\n",
            "trainset before adding uncertain samples (225, 10) (225,)\n",
            "trainset after adding uncertain samples (250, 10) (250,)\n",
            "updated train set: (250, 10) (250,) unique(labels): [123 127] [0 1]\n",
            "val set: (1052, 10) (1052,)\n",
            "\n",
            "Train set: (250, 10)\n",
            "Validation set: (1052, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 10\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.056 s \n",
            "\n",
            "Accuracy rate is 80.875576 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.89      0.87       321\n",
            "           1       0.65      0.57      0.61       113\n",
            "\n",
            "    accuracy                           0.81       434\n",
            "   macro avg       0.75      0.73      0.74       434\n",
            "weighted avg       0.80      0.81      0.80       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[287  34]\n",
            " [ 49  64]]\n",
            "--------------------------------\n",
            "val predicted: (1052,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1052, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "std (1052,) [42.82394985 39.78114849 45.36263073 ... 48.09227122 48.67931406\n",
            " 18.06333004]\n",
            "selection [ 538  992  602  704  459  896  455   65  170  498  522  519  186  335\n",
            "  346  836  206  652 1041  622 1036  663  421  689  738] (25,) [ 0.21587735  1.32442529  1.64683637  1.83845788  2.3231206   3.13233841\n",
            "  3.66007419  4.31065694  4.97639046  8.11373072  8.8154387   9.14911904\n",
            "  9.55471552 10.60605223 10.82095917 11.75567172 12.03848591 12.7908761\n",
            " 13.01864038 13.55583232 13.77108235 15.17576849 15.30670815 16.03705223\n",
            " 16.59558506]\n",
            "trainset before adding uncertain samples (250, 10) (250,)\n",
            "trainset after adding uncertain samples (275, 10) (275,)\n",
            "updated train set: (275, 10) (275,) unique(labels): [133 142] [0 1]\n",
            "val set: (1027, 10) (1027,)\n",
            "\n",
            "Train set: (275, 10)\n",
            "Validation set: (1027, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 11\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.097 s \n",
            "\n",
            "Accuracy rate is 79.493088 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.88      0.86       321\n",
            "           1       0.62      0.56      0.59       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.73      0.72      0.72       434\n",
            "weighted avg       0.79      0.79      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[282  39]\n",
            " [ 50  63]]\n",
            "--------------------------------\n",
            "val predicted: (1027,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1027, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "std (1027,) [35.55108222 42.52090428 46.73423463 ... 47.75934669 44.17509152\n",
            " 17.4383561 ]\n",
            "selection [ 935   12  870   21  375  492  129  308  843  285  426  979  902  108\n",
            "   41  846  776  638 1023  105  745  169  449  796   26] (25,) [ 1.61445617  3.46997518  4.89779086  5.35379165  5.61089761  5.65992515\n",
            "  6.28021839  6.76753203  6.81366402  7.57576748  9.06903829  9.68303286\n",
            " 10.08230635 10.19086447 11.09089267 12.71480117 13.88362774 15.58696003\n",
            " 16.27522083 16.36344972 16.39573933 16.76161153 16.84089644 16.93406815\n",
            " 17.30287482]\n",
            "trainset before adding uncertain samples (275, 10) (275,)\n",
            "trainset after adding uncertain samples (300, 10) (300,)\n",
            "updated train set: (300, 10) (300,) unique(labels): [144 156] [0 1]\n",
            "val set: (1002, 10) (1002,)\n",
            "\n",
            "Train set: (300, 10)\n",
            "Validation set: (1002, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 12\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.126 s \n",
            "\n",
            "Accuracy rate is 80.184332 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.89      0.87       321\n",
            "           1       0.64      0.56      0.59       113\n",
            "\n",
            "    accuracy                           0.80       434\n",
            "   macro avg       0.74      0.72      0.73       434\n",
            "weighted avg       0.79      0.80      0.80       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[285  36]\n",
            " [ 50  63]]\n",
            "--------------------------------\n",
            "val predicted: (1002,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1002, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "std (1002,) [21.03063089 44.43716536 46.44145077 ... 45.65998508 47.3676928\n",
            " 12.13220823]\n",
            "selection [ 585  178  825  191  411  697  682  356  505  377  931  943   62  563\n",
            " 1001  839  470  402  608  865  215   67  826  251  307] (25,) [ 0.90914054  1.24652654  3.99683086  4.88930514  5.19001143  5.42994474\n",
            "  5.53095332  5.59933779  6.4437574   9.07519727 10.46636254 10.87739859\n",
            " 10.92545297 11.71589824 12.13220823 12.55431719 14.96085305 16.25537205\n",
            " 16.31168428 16.99531071 18.02572634 18.1721317  18.38096211 19.03556419\n",
            " 19.16417588]\n",
            "trainset before adding uncertain samples (300, 10) (300,)\n",
            "trainset after adding uncertain samples (325, 10) (325,)\n",
            "updated train set: (325, 10) (325,) unique(labels): [159 166] [0 1]\n",
            "val set: (977, 10) (977,)\n",
            "\n",
            "Train set: (325, 10)\n",
            "Validation set: (977, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 13\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.144 s \n",
            "\n",
            "Accuracy rate is 80.875576 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.89      0.87       321\n",
            "           1       0.65      0.57      0.61       113\n",
            "\n",
            "    accuracy                           0.81       434\n",
            "   macro avg       0.75      0.73      0.74       434\n",
            "weighted avg       0.80      0.81      0.80       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[287  34]\n",
            " [ 49  64]]\n",
            "--------------------------------\n",
            "val predicted: (977,) [0 1 1 0 0 1 0 0 1 1 0 0 0 1 1 1 0 1 0 1 0 0 0 1 1 1 0 1 1 0 1 0 0 1 0 0 1\n",
            " 0 1 0 1 0 0 0 1 1 0 1 1 1 1 0 0 0 1 1 1 1 1 0 1 0 1 1 0 0 1 1 1 1 1 0 1 1\n",
            " 0 0 1 1 0 0 0 0 1 0 1 1 0 1 1 0 1 0 1 1 1 0 0 0 0 0 0 1 0 0 1 0 1 0 0 1 0\n",
            " 0 1 1 0 0 1 0 0 0 0 0 1 0 0 0 1 1 0 1 1 0 0 1 1 1 1 0 1 1 1 1 0 1 0 1 1 0\n",
            " 1 1 1 0 1 1 1 0 0 0 1 0 1 0 1 1 1 0 1 1 1 1 0 0 0 1 1 0 1 1 1 0 0 1 0 0 0\n",
            " 1 1 1 0 1 0 0 0 0 0 1 0 1 0 0 0 0 1 0 1 0 1 1 0 0 1 1 0 0 0 0 1 1 0 1 1 1\n",
            " 1 1 1 1 1 0 0 1 1 1 0 1 1 1 0 1 1 0 1 1 0 1 1 0 1 1 1 0 1 0 1 1 1 0 1 0 1\n",
            " 0 0 1 1 0 1 1 0 0 0 0 1 1 1 1 0 0 1 0 0 0 0 1 0 1 0 1 0 1 0 0 0 1 0 0 0 0\n",
            " 0 1 1 1 1 0 1 1 1 0 1 1 1 0 1 1 0 1 0 0 0 1 1 0 0 1 0 1 0 1 0 0 1 0 0 1 0\n",
            " 1 0 0 1 1 1 0 1 1 0 1 0 0 1 1 0 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 0 0 1 0 1\n",
            " 0 1 1 0 1 1 1 0 1 0 0 1 1 1 0 1 1 0 1 1 0 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0\n",
            " 0 0 0 1 1 0 0 1 1 0 0 1 0 0 1 0 0 0 1 0 0 1 0 1 1 1 1 0 1 0 1 1 1 1 0 1 0\n",
            " 1 0 1 1 0 0 0 0 0 0 1 1 1 1 1 1 0 0 0 1 1 0 1 0 1 0 0 0 0 0 1 1 0 0 0 0 1\n",
            " 1 0 0 0 1 0 1 0 0 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 0 1 0 0 0 1 0 0 1 1 0 1 1\n",
            " 0 1 1 0 1 0 0 0 0 0 1 0 1 0 1 0 1 1 0 1 1 0 1 1 0 1 1 1 0 1 1 0 1 1 1 1 1\n",
            " 0 0 0 1 0 0 1 1 1 1 1 0 1 1 1 1 1 0 0 0 1 0 1 0 0 0 1 0 1 1 0 1 1 0 1 0 0\n",
            " 1 1 0 0 0 1 0 0 1 0 0 1 0 1 1 1 1 1 0 0 0 0 1 0 1 1 1 0 1 1 1 0 1 1 0 1 1\n",
            " 0 1 0 0 1 1 0 1 1 1 1 1 0 0 1 1 0 0 1 1 1 1 0 1 1 0 1 0 0 1 1 1 0 1 0 1 1\n",
            " 0 1 1 0 1 0 0 1 0 1 0 0 0 0 1 0 1 1 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 1 1 1 0\n",
            " 1 0 0 0 1 1 0 1 0 0 1 1 1 1 1 0 0 0 0 0 0 1 0 1 1 0 1 0 1 1 0 0 1 0 1 0 0\n",
            " 0 0 0 1 0 0 1 1 0 1 0 0 1 0 0 1 0 1 1 1 0 0 0 1 1 0 0 1 0 1 0 1 0 1 0 0 1\n",
            " 0 0 1 0 0 0 1 0 0 0 1 0 1 1 1 0 1 0 0 1 0 0 0 0 1 0 1 1 0 1 1 1 1 1 0 0 1\n",
            " 1 0 1 1 1 1 1 1 1 0 0 1 0 0 0 1 0 0 1 0 1 1 0 1 0 1 0 0 0 1 0 1 0 1 0 1 0\n",
            " 1 1 1 0 0 0 0 1 0 1 1 0 0 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 1 0 1 0 1 1 0\n",
            " 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 0 0 1 1 0 1 0 0 1 0 1 1 0 1 0 0 1 0 1 1 0 1\n",
            " 0 1 1 1 1 1 1 0 1 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 1 0 1 1 0 0 1 0 1\n",
            " 1 0 1 0 0 1 1 1 0 0 1 1 1 0 0]\n",
            "probabilities: (977, 2) \n",
            " [0 1 1 0 0 1 0 0 1 1 0 0 0 1 1 1 0 1 0 1 0 0 0 1 1 1 0 1 1 0 1 0 0 1 0 0 1\n",
            " 0 1 0 1 0 0 0 1 1 0 1 1 1 1 0 0 0 1 1 1 1 1 0 1 0 1 1 0 0 1 1 1 1 1 0 1 1\n",
            " 0 0 1 1 0 0 0 0 1 0 1 1 0 1 1 0 1 0 1 1 1 0 0 0 0 0 0 1 0 0 1 0 1 0 0 1 0\n",
            " 0 1 1 0 0 1 0 0 0 0 0 1 0 0 0 1 1 0 1 1 0 0 1 1 1 1 0 1 1 1 1 0 1 0 1 1 0\n",
            " 1 1 1 0 1 1 1 0 0 0 1 0 1 0 1 1 1 0 1 1 1 1 0 0 0 1 1 0 1 1 1 0 0 1 0 0 0\n",
            " 1 1 1 0 1 0 0 0 0 0 1 0 1 0 0 0 0 1 0 1 0 1 1 0 0 1 1 0 0 0 0 1 1 0 1 1 1\n",
            " 1 1 1 1 1 0 0 1 1 1 0 1 1 1 0 1 1 0 1 1 0 1 1 0 1 1 1 0 1 0 1 1 1 0 1 0 1\n",
            " 0 0 1 1 0 1 1 0 0 0 0 1 1 1 1 0 0 1 0 0 0 0 1 0 1 0 1 0 1 0 0 0 1 0 0 0 0\n",
            " 0 1 1 1 1 0 1 1 1 0 1 1 1 0 1 1 0 1 0 0 0 1 1 0 0 1 0 1 0 1 0 0 1 0 0 1 0\n",
            " 1 0 0 1 1 1 0 1 1 0 1 0 0 1 1 0 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 0 0 1 0 1\n",
            " 0 1 1 0 1 1 1 0 1 0 0 1 1 1 0 1 1 0 1 1 0 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0\n",
            " 0 0 0 1 1 0 0 1 1 0 0 1 0 0 1 0 0 0 1 0 0 1 0 1 1 1 1 0 1 0 1 1 1 1 0 1 0\n",
            " 1 0 1 1 0 0 0 0 0 0 1 1 1 1 1 1 0 0 0 1 1 0 1 0 1 0 0 0 0 0 1 1 0 0 0 0 1\n",
            " 1 0 0 0 1 0 1 0 0 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 0 1 0 0 0 1 0 0 1 1 0 1 1\n",
            " 0 1 1 0 1 0 0 0 0 0 1 0 1 0 1 0 1 1 0 1 1 0 1 1 0 1 1 1 0 1 1 0 1 1 1 1 1\n",
            " 0 0 0 1 0 0 1 1 1 1 1 0 1 1 1 1 1 0 0 0 1 0 1 0 0 0 1 0 1 1 0 1 1 0 1 0 0\n",
            " 1 1 0 0 0 1 0 0 1 0 0 1 0 1 1 1 1 1 0 0 0 0 1 0 1 1 1 0 1 1 1 0 1 1 0 1 1\n",
            " 0 1 0 0 1 1 0 1 1 1 1 1 0 0 1 1 0 0 1 1 1 1 0 1 1 0 1 0 0 1 1 1 0 1 0 1 1\n",
            " 0 1 1 0 1 0 0 1 0 1 0 0 0 0 1 0 1 1 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 1 1 1 0\n",
            " 1 0 0 0 1 1 0 1 0 0 1 1 1 1 1 0 0 0 0 0 0 1 0 1 1 0 1 0 1 1 0 0 1 0 1 0 0\n",
            " 0 0 0 1 0 0 1 1 0 1 0 0 1 0 0 1 0 1 1 1 0 0 0 1 1 0 0 1 0 1 0 1 0 1 0 0 1\n",
            " 0 0 1 0 0 0 1 0 0 0 1 0 1 1 1 0 1 0 0 1 0 0 0 0 1 0 1 1 0 1 1 1 1 1 0 0 1\n",
            " 1 0 1 1 1 1 1 1 1 0 0 1 0 0 0 1 0 0 1 0 1 1 0 1 0 1 0 0 0 1 0 1 0 1 0 1 0\n",
            " 1 1 1 0 0 0 0 1 0 1 1 0 0 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 1 0 1 0 1 1 0\n",
            " 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 0 0 1 1 0 1 0 0 1 0 1 1 0 1 0 0 1 0 1 1 0 1\n",
            " 0 1 1 1 1 1 1 0 1 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 1 0 1 1 0 0 1 0 1\n",
            " 1 0 1 0 0 1 1 1 0 0 1 1 1 0 0]\n",
            "std (977,) [27.47339574 44.84378702 45.01021929 46.79215469 13.62689135 48.35798821\n",
            " 25.26204356 42.81832904 48.82575154 37.58797198 44.30333172 37.72962923\n",
            " 49.74474334 49.10095185 49.44005694 42.60877958 49.07483453 46.50220226\n",
            " 35.45623281 37.00371079 48.01188258 24.4905818  47.24978622 47.64826072\n",
            " 40.3224622  49.15682994 35.45623281 48.41863553 48.37220769 47.12473025\n",
            " 40.55067467 39.24093587 47.8933996  46.44069987 49.63106629 49.80745842\n",
            " 21.53176917 25.03334949 38.02828244 32.63288276 45.77794026 41.74914764\n",
            " 48.81675547 45.54112121 46.02676824 37.56512873 30.51588789 47.95057558\n",
            " 44.5076079  37.04421557 49.39704969 46.50623284 33.78560657 48.71914764\n",
            " 49.16089949 28.1340722  48.16529626 47.56761699 42.22539565 46.54927324\n",
            " 48.98814108 42.148119   45.40299574 48.05674857 48.72030095 49.11500784\n",
            " 47.90575019 47.57389269 46.58959295 32.11660008 49.17941046 49.29194878\n",
            " 48.80235463 43.22351521 49.64156829 40.62471644 49.30276913 42.1289132\n",
            " 43.84535939 36.03081908 49.4851877  43.55690647 48.77731406 49.03925184\n",
            " 46.39236151 48.57845496 25.53037424 47.82881155 46.08353182 47.47433924\n",
            " 48.88401847 49.3504005  47.55981679 32.59578509 46.72652791 36.09681678\n",
            " 19.19438315 47.9499325  49.28540405 49.04705353 47.94195976 49.40520046\n",
            " 36.91848473 48.31672599 49.46353334 49.29183065 48.32148173 22.6301942\n",
            "  7.92171371 39.55184844 46.14178136 48.45335346 45.97118919 44.83699955\n",
            " 49.66974163 49.35825473 47.47478691 26.97893564 45.89311827 49.73136507\n",
            " 47.00292656 35.45623281 48.84237863 23.21054943 43.53340717 49.42734392\n",
            " 46.87149517 46.00424022 49.72759997 42.7997037  29.23291915 20.31605434\n",
            " 49.28104726 48.78620909 28.82156447 39.40195031 29.15461477 46.186307\n",
            " 40.76326809 44.06582704 46.60072519 39.62851124 17.15888919 48.70591959\n",
            " 41.21048444 49.41659997 45.50604045 45.79000727 41.32705961 49.67740765\n",
            " 37.90309063 49.67793271 43.64798238 46.31302073 49.26789202 47.26067283\n",
            " 35.73685067 42.08730587 39.87176285 49.4815451  47.79031067 47.24620214\n",
            " 47.20630978 48.43924567 37.67969079 39.41093578 45.30412413 42.10290592\n",
            " 26.62531845 42.2560729  49.76124765 49.79730263 35.45623281 46.38184132\n",
            " 48.75979752 42.28546867 46.89782131 44.99762953 46.87957907 48.55156742\n",
            " 48.22308246 31.50855433 48.38767897 45.87381293 35.81116031 43.06752428\n",
            " 48.32801191 46.67213985 48.54670814 47.42800489 48.29301466 48.89656453\n",
            " 49.69044528 49.4369361  49.81949503 48.62589711 48.77915695 45.71743707\n",
            " 48.73173466 49.64482738 35.45623281 49.71662415 44.99893083 43.24665669\n",
            " 43.6256053  46.08237781 49.2464953  44.72127391 49.14364827 25.0104088\n",
            " 44.04944215 48.65810474 46.06857639 49.85537942 45.99672732 49.52242245\n",
            " 21.13984851 49.35409958 49.21723055 43.02707067 49.75748919 30.6262512\n",
            " 45.63109691 49.17122773 37.17013524 47.14822436 45.81422431 49.43870285\n",
            " 48.98356109 48.01298628 49.22911149 48.17577443 49.4191068  47.892136\n",
            " 48.07920876 47.7327585  46.9743943  41.96491696 49.41169806 49.74958382\n",
            " 49.57396677 48.14300861 46.86674705 49.32910346 34.98448649 49.47499621\n",
            " 22.41950589 45.11564072 36.33435792 44.23734315 49.35110019 44.86388212\n",
            " 21.24000516 46.54349446 44.54499847  5.94385106 47.71502012 36.34899547\n",
            " 46.91134445 49.78432985 49.35387974 47.00915843 37.40145194 48.66813715\n",
            " 48.18240104 48.18958675 47.45945967 31.3283604  44.41469472 42.22966981\n",
            " 47.07257944 47.53238612 48.37140238 48.05355374 46.44897836 49.48681571\n",
            " 49.3333783  35.45623281 38.20809962 45.71676071 49.76571138 47.75344919\n",
            " 47.79315942 47.85960916 47.98971109 33.53071223 43.58133921 43.32979034\n",
            " 47.34773318 39.0732454  25.47264053 46.09672844 49.36784473 49.36302633\n",
            " 49.02846228 47.27140025 41.58494904 47.46462441 47.63985579 48.56023615\n",
            " 48.28952218 22.00634151 45.31498806 45.21703266 49.1034206  35.45623281\n",
            " 43.22392805 48.57074014 47.79024734 49.64156829 48.2437421  48.29285159\n",
            " 46.84712262 40.02434694 49.45425363 48.33398023 43.84465575 44.2665664\n",
            " 32.29547641 47.30599274 49.62094169 49.80522873 42.52469415 23.27344665\n",
            " 49.74553169 48.81906654 35.45623281 46.87343997 49.34574923 46.32609626\n",
            " 48.09283192 44.58369842 42.25313315 41.71048674 49.43733411 43.63877434\n",
            " 49.11839157 48.65533272 46.61925479 31.13425878 22.9917315  44.80674745\n",
            " 48.53064468 47.50594639 42.71571379 44.32694368 41.64568702 48.63583617\n",
            " 38.50918485 46.61348939 48.87352407 48.25641799 41.49787275 48.27873831\n",
            " 39.19301553 48.15334201 49.6416995  47.33518391 48.88183112 35.20589357\n",
            " 31.18862947 38.18137127 49.49911222 49.02451314 43.08660822 48.80211157\n",
            " 38.3583679  48.62898684 48.68916132 32.09462109 44.79312921 23.89053507\n",
            " 48.43270768 40.87992026 49.37581867 49.29813447 47.77726568 49.19335136\n",
            " 48.4701953  28.99255971 48.85933119 48.73276946 49.06705169 48.55557671\n",
            " 42.44827785 42.3287159  44.45474673 46.17354021 23.00329571 45.34047714\n",
            " 44.27696759 48.96397956 36.08039681 49.12983525 44.44607186 48.21899752\n",
            " 49.27434021 49.16377971 45.38487806 49.47538487 49.13614848 47.40271878\n",
            " 48.69137668 27.42783298 47.96862822 33.57220861 49.42161499 42.5223723\n",
            " 45.85121612 46.03586599 48.27152945 48.33071803 48.0735858  26.29762041\n",
            " 43.01560303 30.5339612  34.30557428 35.45623281 48.12733051 47.92434729\n",
            " 46.90426908 43.88804252 37.00848741 41.34351529 49.28891439 49.09734902\n",
            " 45.95476768 48.70627777 48.32733346 18.30353577 30.76547801 42.63663708\n",
            " 27.42783298 47.84488054 45.82984719 49.1270434  34.73144437 48.50751561\n",
            " 48.36039245 32.89385566 49.08441488 39.53508543 39.37534447 49.38628153\n",
            " 48.57372323 49.33109169 49.32045263 47.87295086 35.46056999 40.8843181\n",
            " 49.0317007  49.08796894 49.69408028 37.10409252 48.17068401 46.6568471\n",
            " 48.42989456 48.17445835 49.57123591 48.62922505 49.59223263 49.87869756\n",
            " 45.02209476 46.70814448 45.33662965 32.679444   47.61357964 49.05671915\n",
            " 45.70416858 49.45438786 34.03705326 46.95465073 30.41453439 46.13077314\n",
            " 44.10722718 35.74286098 49.52827189 35.45623281 47.08645645 49.32724398\n",
            " 47.13073189 48.59224491 36.99509868 49.22638686 35.45623281 46.41365745\n",
            " 49.57756361 45.95947472 49.69909565 49.07925167 47.55175993 39.71737707\n",
            " 48.9076155  38.83362523 48.42177635 37.7910585  47.52151041 38.85837668\n",
            " 43.24230065 42.37682282 49.09516267 48.02664217 36.14694851 49.07360115\n",
            " 49.15822683 25.76705101 42.76491522 26.90366977 24.72886345 47.9694546\n",
            " 49.27759605 47.55306216 27.39087967 49.32993016 49.38886863 35.45623281\n",
            " 47.50627324 27.31097863 40.24262707 46.00532542 49.1300817  43.12948987\n",
            " 48.84242992 19.83424966 48.89466885 26.91625761 33.54731122 48.49799252\n",
            " 48.67436962 42.10005824 45.17763086 49.29765792 49.56615898 47.92697227\n",
            " 49.53488259 47.13791034 42.44711436 39.46528    44.80674745 49.23520475\n",
            " 48.05864199 45.21063017 49.36021809 48.79882637 46.22923649 34.80648417\n",
            " 43.7950922  48.82762605 48.02664217 38.86027618 48.05760257 48.77901613\n",
            " 47.31341948 48.17106824 49.34105274 49.8432643  44.35796469 40.14838515\n",
            " 47.04610234 49.03048291 32.38000655 48.79443291 27.80640463 46.5661582\n",
            " 39.13344267 48.44572101 29.88618703 41.0800562  49.08891457 40.01742996\n",
            " 49.42157007 45.18954855 49.58425937 44.88511591 44.91286385 41.35139496\n",
            " 45.04955057 49.42693932 49.3360206  49.49835141 49.07087647 49.7011021\n",
            " 45.84700881 44.89828162 43.97290437 45.67765714 49.02556761 46.24113344\n",
            " 34.22625018 46.46609919 29.23189957 14.93303069 49.40292028 45.65083456\n",
            " 49.71129356 44.83420142 49.59615423 44.76547803 45.47827463 48.35138114\n",
            " 47.56768611 37.26482707 45.41040554 46.26333363 47.1980262  42.12883862\n",
            " 48.66076264 48.8043824  48.19704813 39.21611602 38.09522139 47.77946245\n",
            " 48.56532806 46.43054635 48.24249506 41.62984577 23.29636907 46.68294652\n",
            " 42.59028793 49.62142861 49.13911019 47.10304019 47.93975982 46.94189896\n",
            " 37.87038047 43.8331849  49.55114776 40.69938377 49.21685577 49.80660546\n",
            " 42.94350507 45.33670076 47.45828368 35.56462394 49.1473251  48.19114604\n",
            " 49.46853655 47.91636407 48.9188515  46.52235002 42.57244237 36.04131004\n",
            " 33.34187311 49.04052223 45.96413282 38.87124817 44.79022079 49.14231676\n",
            " 43.76743796 48.41152512 41.4941451  49.65552782 46.61634311 40.50712449\n",
            " 49.83885092 48.28952218 49.82095528 49.56073842 48.34222984 49.79054409\n",
            " 49.33490755 28.39817272 32.57547375 42.75950772 49.07637358 46.52797613\n",
            " 46.74902518 47.02090924 49.37065807 44.5910891  38.25929527 35.45623281\n",
            " 19.46481974 48.45816195 48.18210216 48.07714715 31.12076532 35.45623281\n",
            " 35.45623281 44.96512316 49.41717858 49.42747237 49.27986264 31.23122911\n",
            " 45.09829343 43.05611374 48.67708588 48.23664968 26.98203034 39.30276446\n",
            " 49.15225419 43.84733095  5.50163078 47.46913177 26.99542114 46.92137008\n",
            " 48.11680314 27.53911479 46.84610615 47.76510336 39.66488079 48.35626263\n",
            " 46.33543857 45.90439015 46.83841929 32.04482266 47.77669488 49.57580385\n",
            " 12.7384262  48.7985769  43.78160012 46.94932144 19.06590505 49.09087559\n",
            " 48.88923482 46.67876194 29.04388004 45.03980766 40.80576537 46.00360761\n",
            " 23.23076192 49.59064521 38.06669161 49.43802208 49.60124159 49.55922611\n",
            " 49.29181559 49.19602233 16.94808958 48.48497452 28.15594179 34.40959926\n",
            " 46.77016348 49.66665325 49.24893074 49.53343249 35.45623281 46.7856819\n",
            " 35.8016088  49.09034706 49.04379857 35.45623281 46.08958774 47.46552296\n",
            " 35.2408785  49.50661751 44.5109745  49.36805379 42.84743395 39.72847405\n",
            "  2.61588465 49.55946483 48.91719521 49.73497019 48.68862466 47.77089962\n",
            " 48.76064408 47.06998951 46.00995617 42.89552304 48.79207983 49.88132659\n",
            " 35.45623281 45.35685826 47.74412889 49.42404304 42.50652011 46.94395396\n",
            " 37.34822975 38.91790198 41.66276359 42.5145729  47.53788897 27.75359844\n",
            " 46.53879102 48.60275674 48.17912723 29.77124489 48.06151462 48.49005163\n",
            " 42.91645326 48.68765434 48.93946694 46.45013032 49.14786309 48.9116341\n",
            " 49.26430098 48.03769739 33.54244851 48.42177635 49.26399491 42.0433322\n",
            " 49.29970604 45.99086175 46.32410123 48.96539867 42.98526849 49.74317021\n",
            " 48.64885635 48.62724707 46.99850922 28.83866306 47.77338189 31.35477194\n",
            " 44.79810134 35.84176533 38.7797021  44.88505002 47.51695703 36.36066064\n",
            " 43.52955931 38.62275654 49.91729874 42.30221679 47.25745674 47.57978937\n",
            " 39.76708098 41.63936759 49.27620447 48.44451728 49.27077669 48.60031688\n",
            " 33.84057438 39.68108754 39.48617808 39.35024464 49.73638827 37.5538201\n",
            " 45.14945346 46.11738965 40.50564348 43.53743588 47.65697747 44.14167645\n",
            " 48.21241981 46.91711139 49.18179656 37.22397239 48.54744875 49.03817464\n",
            " 49.73315317 49.80236089 38.66293676 44.8818131  41.51847715 49.54315595\n",
            " 44.79748563 40.19656121 44.11124435 49.08204268 49.39970969 32.94429546\n",
            " 49.26318286 48.37613475 49.63064276 48.73244175 18.56205886 47.52788653\n",
            " 48.53553597 35.45623281 48.44803798 49.02802523 49.71007681 46.26873285\n",
            " 35.45623281 47.22556937 44.08433213 47.42883006 37.00371079 49.15225419\n",
            " 49.03806225 48.23689735 38.38153154 32.25370327 48.20829719 47.14822436\n",
            " 48.67436962 46.94258551 49.33836414 45.05697263 44.20257828 49.3620024\n",
            " 27.3872679  47.67157625 39.14908367 47.53926539 48.24048734 48.59787544\n",
            " 49.58809503 47.51814338 46.90909407 30.01358303 42.65059098 49.69295073\n",
            " 48.35256634 31.43155756 44.04617917 47.03227057 47.94963577 20.90329124\n",
            " 47.27698141 48.93580606 43.90076544 49.02683479 35.45623281 46.05655793\n",
            " 48.63677831 48.95946989 49.45038825 35.45623281 43.34997913 48.46321423\n",
            " 49.54187169 49.50864122 48.39371192 41.53594003 48.9095872  48.27082117\n",
            " 44.48109852 48.0138648  38.63283637 45.39172581 34.37755907 33.44333819\n",
            " 49.47200226 47.58882735 39.12110278 45.56460368 44.39364792 49.41475699\n",
            " 40.55374538 38.91358146 43.40306427 43.64277413 33.2856696  48.73424902\n",
            " 33.43478086 36.86185627 45.20631085 19.27709597 41.67049908 12.13631842\n",
            " 49.35986634 49.44936105 45.70025693 46.9141565  30.25724062 49.26476169\n",
            " 32.7936239  47.82971358 35.58305796 34.81107569 33.81480954 40.27193477\n",
            " 20.85436485 49.28048085 48.16942212 33.49875688 43.87548683 39.49312797\n",
            " 33.08786561 49.11049554 32.97163767 36.43657611 46.59460405 38.43168939\n",
            " 35.45623281 43.06601506 28.51183667 45.79237817 49.13013358 44.43520241\n",
            " 47.2933706  47.3889553  37.44281307 45.11353256 47.06390639]\n",
            "selection [750 692 255 108 941 708   4 591 728 142 429 856 712  96 939 672 523 131\n",
            " 954 899 216 252  36 301 246] (25,) [ 2.61588465  5.50163078  5.94385106  7.92171371 12.13631842 12.7384262\n",
            " 13.62689135 14.93303069 16.94808958 17.15888919 18.30353577 18.56205886\n",
            " 19.06590505 19.19438315 19.27709597 19.46481974 19.83424966 20.31605434\n",
            " 20.85436485 20.90329124 21.13984851 21.24000516 21.53176917 22.00634151\n",
            " 22.41950589]\n",
            "trainset before adding uncertain samples (325, 10) (325,)\n",
            "trainset after adding uncertain samples (350, 10) (350,)\n",
            "updated train set: (350, 10) (350,) unique(labels): [177 173] [0 1]\n",
            "val set: (952, 10) (952,)\n",
            "\n",
            "Train set: (350, 10)\n",
            "Validation set: (952, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 14\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.215 s \n",
            "\n",
            "Accuracy rate is 80.875576 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.90      0.87       321\n",
            "           1       0.66      0.56      0.60       113\n",
            "\n",
            "    accuracy                           0.81       434\n",
            "   macro avg       0.75      0.73      0.74       434\n",
            "weighted avg       0.80      0.81      0.80       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[288  33]\n",
            " [ 50  63]]\n",
            "--------------------------------\n",
            "val predicted: (952,) [0 1 1 0 1 0 0 1 1 0 0 0 1 1 1 0 1 0 1 0 0 0 1 1 1 0 1 1 0 1 0 0 1 0 0 0 1\n",
            " 0 1 0 0 0 1 1 0 1 1 1 1 0 0 0 1 1 1 1 1 0 1 0 1 1 0 0 1 1 1 1 1 0 1 1 0 0\n",
            " 1 1 0 0 0 0 1 0 1 1 0 1 1 0 1 0 1 1 1 0 0 0 0 0 1 0 0 1 0 1 0 1 0 0 1 1 0\n",
            " 0 1 0 0 0 0 0 1 0 0 0 1 1 0 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 0 1 1 1 0 1 1\n",
            " 1 0 0 0 1 0 1 0 1 1 1 0 1 1 1 1 0 0 0 1 1 0 1 1 1 0 0 1 0 0 0 1 1 1 0 1 0\n",
            " 0 0 0 0 1 0 1 0 0 0 0 1 0 1 0 1 1 0 0 1 1 0 0 0 0 1 0 1 1 1 1 1 1 1 1 0 0\n",
            " 1 1 1 0 1 1 1 0 1 1 0 1 1 0 1 1 0 1 1 0 1 0 1 1 1 0 1 0 0 1 1 0 1 1 0 0 0\n",
            " 0 1 1 1 1 0 0 1 0 0 0 0 1 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 1 1 1 1 1 1 1 0 1\n",
            " 1 1 0 1 1 0 1 0 0 0 1 1 0 0 1 0 1 0 1 0 0 1 0 0 1 0 1 0 0 1 1 1 0 1 1 0 1\n",
            " 0 0 1 1 0 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 0 0 1 0 1 0 1 1 0 1 1 1 0 1 0 0\n",
            " 1 1 1 0 1 1 0 1 1 0 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0 0 0 1 1 0 0 1 1 0 0\n",
            " 1 0 0 1 0 0 0 1 0 0 1 1 1 1 1 0 1 0 1 1 1 1 0 1 0 1 0 1 1 0 0 0 0 0 0 1 1\n",
            " 1 1 1 1 0 0 0 1 1 0 1 0 1 0 0 0 0 0 1 1 0 0 0 0 1 1 0 0 0 1 0 1 0 0 1 1 1\n",
            " 1 1 1 1 1 1 0 1 1 0 0 1 0 1 0 0 0 1 0 0 1 1 0 1 1 0 1 1 0 1 0 0 0 0 1 0 1\n",
            " 0 1 0 1 1 0 1 1 0 1 1 0 1 1 1 0 1 1 0 1 1 1 1 1 0 0 0 1 0 0 1 1 1 1 1 0 1\n",
            " 1 1 1 1 0 0 0 1 0 1 0 0 0 1 0 1 1 0 1 1 0 1 0 1 1 0 0 0 1 0 0 1 0 0 1 0 1\n",
            " 1 1 1 1 0 0 0 0 1 0 1 1 1 0 1 1 1 0 1 1 0 1 1 0 1 0 0 1 1 0 1 1 1 1 1 0 0\n",
            " 1 1 0 0 1 1 1 1 0 1 1 0 1 0 0 1 1 1 0 1 0 1 1 0 1 1 0 1 0 1 0 1 0 0 0 0 1\n",
            " 0 1 1 0 0 0 0 0 0 1 0 1 0 0 1 0 0 1 1 1 0 1 0 0 0 1 0 1 0 1 1 1 1 1 0 0 0\n",
            " 0 0 0 1 0 1 1 1 0 1 1 0 0 1 0 1 0 0 0 0 0 1 0 0 1 1 0 1 0 1 0 0 1 0 1 1 1\n",
            " 0 0 0 1 1 0 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 0 0 1 0 0 0 1 0 1 1 1 0 1 0 0 1\n",
            " 0 0 0 0 1 0 1 1 0 1 1 1 1 1 0 0 1 1 0 1 1 1 1 1 1 1 0 0 1 0 0 0 1 0 0 1 0\n",
            " 1 1 0 1 0 1 0 0 0 1 0 1 0 1 0 1 0 1 1 1 0 0 0 1 0 1 1 0 0 0 1 0 1 1 1 1 1\n",
            " 1 0 0 1 1 1 0 0 1 1 0 1 0 1 1 0 1 1 1 1 1 1 1 0 1 1 1 0 1 1 0 0 1 1 0 1 0\n",
            " 0 1 0 1 1 0 1 0 0 1 0 1 1 0 1 0 1 1 1 1 1 1 0 1 1 0 1 0 0 0 0 1 0 0 0 0 0\n",
            " 1 1 0 0 1 1 1 0 0 1 0 1 1 0 1 0 0 1 1 1 0 0 1 1 1 0 0]\n",
            "probabilities: (952, 2) \n",
            " [0 1 1 0 1 0 0 1 1 0 0 0 1 1 1 0 1 0 1 0 0 0 1 1 1 0 1 1 0 1 0 0 1 0 0 0 1\n",
            " 0 1 0 0 0 1 1 0 1 1 1 1 0 0 0 1 1 1 1 1 0 1 0 1 1 0 0 1 1 1 1 1 0 1 1 0 0\n",
            " 1 1 0 0 0 0 1 0 1 1 0 1 1 0 1 0 1 1 1 0 0 0 0 0 1 0 0 1 0 1 0 1 0 0 1 1 0\n",
            " 0 1 0 0 0 0 0 1 0 0 0 1 1 0 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 0 1 1 1 0 1 1\n",
            " 1 0 0 0 1 0 1 0 1 1 1 0 1 1 1 1 0 0 0 1 1 0 1 1 1 0 0 1 0 0 0 1 1 1 0 1 0\n",
            " 0 0 0 0 1 0 1 0 0 0 0 1 0 1 0 1 1 0 0 1 1 0 0 0 0 1 0 1 1 1 1 1 1 1 1 0 0\n",
            " 1 1 1 0 1 1 1 0 1 1 0 1 1 0 1 1 0 1 1 0 1 0 1 1 1 0 1 0 0 1 1 0 1 1 0 0 0\n",
            " 0 1 1 1 1 0 0 1 0 0 0 0 1 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 1 1 1 1 1 1 1 0 1\n",
            " 1 1 0 1 1 0 1 0 0 0 1 1 0 0 1 0 1 0 1 0 0 1 0 0 1 0 1 0 0 1 1 1 0 1 1 0 1\n",
            " 0 0 1 1 0 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 0 0 1 0 1 0 1 1 0 1 1 1 0 1 0 0\n",
            " 1 1 1 0 1 1 0 1 1 0 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0 0 0 1 1 0 0 1 1 0 0\n",
            " 1 0 0 1 0 0 0 1 0 0 1 1 1 1 1 0 1 0 1 1 1 1 0 1 0 1 0 1 1 0 0 0 0 0 0 1 1\n",
            " 1 1 1 1 0 0 0 1 1 0 1 0 1 0 0 0 0 0 1 1 0 0 0 0 1 1 0 0 0 1 0 1 0 0 1 1 1\n",
            " 1 1 1 1 1 1 0 1 1 0 0 1 0 1 0 0 0 1 0 0 1 1 0 1 1 0 1 1 0 1 0 0 0 0 1 0 1\n",
            " 0 1 0 1 1 0 1 1 0 1 1 0 1 1 1 0 1 1 0 1 1 1 1 1 0 0 0 1 0 0 1 1 1 1 1 0 1\n",
            " 1 1 1 1 0 0 0 1 0 1 0 0 0 1 0 1 1 0 1 1 0 1 0 1 1 0 0 0 1 0 0 1 0 0 1 0 1\n",
            " 1 1 1 1 0 0 0 0 1 0 1 1 1 0 1 1 1 0 1 1 0 1 1 0 1 0 0 1 1 0 1 1 1 1 1 0 0\n",
            " 1 1 0 0 1 1 1 1 0 1 1 0 1 0 0 1 1 1 0 1 0 1 1 0 1 1 0 1 0 1 0 1 0 0 0 0 1\n",
            " 0 1 1 0 0 0 0 0 0 1 0 1 0 0 1 0 0 1 1 1 0 1 0 0 0 1 0 1 0 1 1 1 1 1 0 0 0\n",
            " 0 0 0 1 0 1 1 1 0 1 1 0 0 1 0 1 0 0 0 0 0 1 0 0 1 1 0 1 0 1 0 0 1 0 1 1 1\n",
            " 0 0 0 1 1 0 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 0 0 1 0 0 0 1 0 1 1 1 0 1 0 0 1\n",
            " 0 0 0 0 1 0 1 1 0 1 1 1 1 1 0 0 1 1 0 1 1 1 1 1 1 1 0 0 1 0 0 0 1 0 0 1 0\n",
            " 1 1 0 1 0 1 0 0 0 1 0 1 0 1 0 1 0 1 1 1 0 0 0 1 0 1 1 0 0 0 1 0 1 1 1 1 1\n",
            " 1 0 0 1 1 1 0 0 1 1 0 1 0 1 1 0 1 1 1 1 1 1 1 0 1 1 1 0 1 1 0 0 1 1 0 1 0\n",
            " 0 1 0 1 1 0 1 0 0 1 0 1 1 0 1 0 1 1 1 1 1 1 0 1 1 0 1 0 0 0 0 1 0 0 0 0 0\n",
            " 1 1 0 0 1 1 1 0 0 1 0 1 1 0 1 0 0 1 1 1 0 0 1 1 1 0 0]\n",
            "std (952,) [22.757802   44.43981389 45.60209937 45.73669902 44.5860439  22.65645752\n",
            " 44.08023224 48.84771495 35.13729072 43.20304941 38.20098677 49.85229459\n",
            " 49.42799921 49.25395451 36.28306498 49.18403173 44.76087619 36.44865961\n",
            " 31.70166669 47.75877349 30.24276169 47.9835974  48.32156714 36.38507578\n",
            " 49.09119266 36.44865961 47.99026508 48.67440513 40.63282241 40.09862181\n",
            " 44.97814065 47.75784396 45.8919691  49.82534513 49.7315704  34.64982841\n",
            " 40.28685705 33.07910457 45.23211605 39.73238012 49.06171334 44.44657011\n",
            " 46.72253302 38.32839685 34.56756255 47.78607685 44.356997   43.52026961\n",
            " 49.44738911 47.02145069 38.43396601 48.73184513 48.76582939 30.09093966\n",
            " 48.00462216 45.88491293 37.37684048 47.09882763 48.69633336 43.09064425\n",
            " 35.07502341 48.37267735 48.91805292 49.50394283 48.02808601 46.70064417\n",
            " 45.87317056 36.53240109 49.01985123 49.62367594 48.55906735 44.63136355\n",
            " 49.70151929 36.66961008 49.2489628  45.44339874 44.39578181 35.46942306\n",
            " 49.41652923 39.79981116 47.74211711 49.03522174 45.46326112 48.1056337\n",
            " 23.70141783 47.61454609 47.53743168 47.26908612 48.84619075 49.51703893\n",
            " 46.17979513 36.23138226 46.16248629 28.20874476 48.9517994  48.9958923\n",
            " 48.9823169  47.98195089 49.50504715 42.67042101 48.27296877 49.5113712\n",
            " 49.2031019  47.39913878 23.88329374 41.289053   45.42645145 48.70869336\n",
            " 47.74302119 43.23695071 49.64077067 49.51854773 45.15504319 26.29377405\n",
            " 45.92178371 49.79797315 46.93170537 36.44865961 48.36584236 29.21482637\n",
            " 41.5821611  49.50093196 47.93331879 43.6211592  49.55681636 41.17380207\n",
            " 28.38672137 49.46136692 48.58555148 33.3095374  38.00615    22.17507242\n",
            " 46.56443895 40.72009736 45.19643205 45.8784263  39.97760692 48.26910607\n",
            " 37.06585672 49.34788135 46.57865884 47.7639424  35.89396562 49.36453465\n",
            " 37.60395478 49.79659341 43.82212907 46.11351561 49.17361381 46.15494122\n",
            " 26.98371165 40.21385463 37.9947183  49.75258637 48.8203025  47.3604673\n",
            " 47.96501438 47.52624752 38.26092244 31.30557088 47.1111604  42.93343078\n",
            " 26.60660118 41.21489947 49.80633674 49.79474778 36.44865961 45.97496721\n",
            " 47.3876001  45.07516963 46.50938924 46.43223322 47.51839122 49.2358089\n",
            " 48.57474118 32.56694527 48.22505578 45.23163073 40.25379672 43.82902263\n",
            " 48.50313507 44.97135742 48.70170658 47.19439231 48.38273167 48.97867564\n",
            " 49.84875963 49.12154518 49.8571978  48.98369498 48.2910228  45.69319297\n",
            " 49.09013736 49.7873541  36.44865961 49.60331115 46.31849825 43.54063661\n",
            " 40.05171049 46.78390298 48.75621426 45.81586952 49.18632973 21.3569172\n",
            " 44.87803442 48.80972454 43.95075808 49.85544196 44.88421581 49.32605037\n",
            " 49.37973051 49.3384095  45.2407425  49.68562788 32.4780531  44.86960451\n",
            " 48.76494415 38.34677275 47.57156824 45.74362814 49.52073401 49.56606309\n",
            " 48.08243307 48.67104258 48.55990436 49.47306974 47.63379412 48.36391793\n",
            " 47.15460737 48.17545367 40.22296702 49.38113929 49.81480977 49.64253788\n",
            " 47.55021192 45.16782073 49.39600545 37.75231964 49.1946267  45.31254194\n",
            " 40.09612964 41.20520685 49.36246297 45.28175009 46.62992412 39.05958021\n",
            " 48.47899877 37.24530049 46.20215136 49.81514763 49.67775179 48.38085668\n",
            " 39.10375984 49.31591657 48.21246474 47.67308335 47.15762936 39.03530479\n",
            " 44.4859046  39.02459181 46.56249533 46.52580127 47.4076158  48.45232658\n",
            " 42.05043265 49.54342833 49.42022874 36.44865961 39.54696665 45.94168638\n",
            " 49.80325168 46.41114132 48.13581849 47.04520781 48.6061262  31.52241546\n",
            " 43.2917978  43.23226029 47.83217797 38.97942816 31.02810154 47.40456844\n",
            " 49.6345405  49.2102072  49.38814746 47.81453703 44.47032945 48.03504603\n",
            " 47.6720238  47.97833376 47.59577932 42.43867575 45.47084679 49.43129362\n",
            " 36.44865961 39.66313081 48.67157846 48.10194798 49.70151929 47.9559057\n",
            " 48.11465603 47.78106723 41.32478665 49.73423161 47.15724113 42.58112153\n",
            " 44.12204694 18.30662619 46.74564243 49.85226079 49.8599096  46.66795929\n",
            " 35.54404883 49.77084124 48.90521079 36.44865961 45.31825555 49.26611016\n",
            " 46.80259024 49.1334224  42.8347717  43.88617469 42.48058636 49.56929263\n",
            " 43.75646138 48.80930774 48.31047986 45.62816158 32.78879737 29.01037357\n",
            " 44.35444485 49.14438461 47.45601022 38.1302044  42.9972251  40.28094701\n",
            " 48.13812214 34.03156403 42.94678771 48.9031297  48.04778682 39.72857221\n",
            " 48.67545771 41.88491856 48.18145392 49.70535378 46.35159766 49.33356832\n",
            " 33.28763776 24.44005385 43.0447392  49.18855922 48.89821314 44.63457007\n",
            " 48.38871487 43.46761158 48.71426232 48.62434995 35.41383097 48.02130933\n",
            " 33.03543275 46.05955953 39.67434216 49.50722723 49.00770056 48.11469802\n",
            " 48.43113008 48.18586418 37.30040168 48.54542389 48.48710588 48.44545934\n",
            " 48.54703156 43.50768564 45.38841977 43.12380264 46.35100808 23.19040757\n",
            " 40.67888792 43.84510785 48.64903284 25.24861075 49.26294958 45.92856117\n",
            " 48.55920831 49.65208202 48.76110297 45.23397266 49.36993774 49.33303099\n",
            " 46.31203847 48.81153038 26.38774576 46.52433204 29.59733239 49.522793\n",
            " 42.58742068 46.72869599 44.41050798 47.97416702 48.17069231 49.1830846\n",
            " 27.57101047 44.56718627 33.96474671 38.47938948 36.44865961 48.13374712\n",
            " 48.01396529 47.70629572 44.9432614  33.77076727 36.6112742  49.412744\n",
            " 49.10300984 46.69171378 47.70819889 48.86041065 12.95460988 39.60980483\n",
            " 26.38774576 47.17112449 48.04011995 48.73425273 33.23299657 48.66893815\n",
            " 48.73955536 26.99426289 48.84414628 40.84813207 37.03712152 49.11682876\n",
            " 48.42545135 49.51951834 49.5763309  47.19165289 38.78626025 43.2486066\n",
            " 49.23559522 48.97321518 49.80891007 33.09375573 47.22635557 46.98045891\n",
            " 48.21729357 48.39947453 49.32590019 49.0229668  49.65685442 49.91065843\n",
            " 47.6324767  45.79526603 44.8141107  30.78398819 47.85653176 49.20233618\n",
            " 46.26119219 49.67580691 30.40424336 48.83468827 31.22499059 46.71956624\n",
            " 46.60069382 36.14215925 49.54717502 36.44865961 48.15172534 49.61952372\n",
            " 46.93821657 48.93278445 31.60650878 48.73943701 36.44865961 47.86954759\n",
            " 49.2919046  46.69025789 49.80928231 49.16150257 46.27982165 40.65935693\n",
            " 48.8761826  39.50655954 48.41887529 36.91866142 46.56702348 39.51524836\n",
            " 42.49625005 42.40745323 49.00233291 47.75971496 42.45562793 49.62109683\n",
            " 49.20138193 30.79784768 41.91640713 31.31694451 32.42964076 48.56688826\n",
            " 49.21939025 48.25381176 27.72023759 49.20562663 49.407716   36.44865961\n",
            " 46.33550457 27.19456358 43.76116903 46.08105362 48.94517423 42.72460511\n",
            " 48.35763378 48.59736925 19.74855507 35.58632025 48.02066918 48.59136355\n",
            " 42.30863881 46.54609019 48.68571396 49.73996081 48.32074427 49.37687896\n",
            " 47.40083837 44.74440881 41.15063294 44.35444485 49.29369172 47.83858207\n",
            " 40.50686977 49.68050406 48.50065979 46.59929016 29.84892398 44.30543077\n",
            " 48.21411912 47.75971496 38.39289379 47.8216175  48.69351227 46.94850598\n",
            " 48.69743682 49.31954986 49.89323159 45.40012027 44.84757972 46.50511801\n",
            " 49.28991875 30.03041143 48.77665607 33.66157133 45.364275   34.88140329\n",
            " 48.79670976 35.22681281 40.64424666 49.17870586 39.36142574 49.41787261\n",
            " 44.46473355 49.57383372 47.86078475 46.37584308 30.42085379 45.75492338\n",
            " 49.08560608 48.97025793 49.63690965 48.69362663 49.70942887 47.64792096\n",
            " 45.00923902 41.80837535 45.52737236 49.0802239  44.14263492 25.18139263\n",
            " 47.10377743 28.45045404 49.28498797 45.19950775 49.86248037 47.67655858\n",
            " 49.4986038  44.70506333 44.80603214 48.34938453 47.41063564 33.66706442\n",
            " 43.27142406 45.92644436 46.91431246 36.36435285 48.42215952 48.53201785\n",
            " 48.23521174 29.94272204 26.10803639 48.62425549 49.22082154 45.54702807\n",
            " 48.3726149  37.04543958 19.17983653 47.72943253 40.72531909 49.84419058\n",
            " 49.13881561 45.72500249 47.39813812 46.33240904 40.23445813 42.11651569\n",
            " 49.43021073 39.14182143 48.9182431  49.66480013 41.90648434 47.00280787\n",
            " 48.39981892 39.33521325 49.19703031 49.05645665 49.53876904 47.35262748\n",
            " 48.70840347 48.00893551 42.91898654 35.24834972 41.09342221 49.02903484\n",
            " 46.61276712 40.24986768 44.58399421 49.34392654 40.83126607 47.81433251\n",
            " 36.43744218 49.66001152 45.83820767 35.68162127 49.79308635 47.59577932\n",
            " 49.79493047 49.61771008 48.15629328 49.76867856 49.41458891 28.25374505\n",
            " 22.76789766 45.4590568  49.30978247 46.37686236 48.23473333 46.18553009\n",
            " 49.28226059 43.44057429 33.37117693 36.44865961 48.45912147 48.97706077\n",
            " 48.16927972 25.50790764 36.44865961 36.44865961 47.37712291 49.56912313\n",
            " 49.26026346 49.2283842  33.21390441 44.23326265 41.18583537 48.85064334\n",
            " 49.16678389 21.78456456 40.19400996 48.57614774 46.51243892 47.25489376\n",
            " 30.04031404 47.72733119 48.4209489  33.72129233 47.71894163 47.04280569\n",
            " 38.39072266 48.17843078 43.73937709 45.43713632 48.36056815 25.91967898\n",
            " 47.52970361 49.5408294  48.37104562 41.09311925 46.97795706 49.23359752\n",
            " 48.64671173 45.17023554 20.83671253 41.85230286 42.30285389 45.96808921\n",
            " 23.21923323 49.75292186 34.6901154  49.49957731 49.43377807 49.78256456\n",
            " 49.34590718 49.27490705 48.29163081 35.87508319 32.69987181 45.93991717\n",
            " 49.81864731 49.58470801 49.41562714 36.44865961 46.55706691 34.4330149\n",
            " 49.46698422 49.11459872 36.44865961 47.2086203  46.65501368 32.4816076\n",
            " 49.39909435 43.50200746 49.38130646 41.59198583 43.09837588 49.47687505\n",
            " 48.57735725 49.74455698 48.99498097 47.18163809 48.86652764 47.62364229\n",
            " 45.21447842 44.11871884 49.41509808 49.84061586 36.44865961 45.48514721\n",
            " 48.34506087 49.62333597 46.28502199 45.66394941 42.54542954 35.74686201\n",
            " 41.16703105 38.5801654  47.47734131 27.85263384 47.24308617 47.33429328\n",
            " 47.41527152 30.00243064 49.08452988 48.8117087  43.13812852 48.73360997\n",
            " 48.93515394 45.94096627 49.21658039 47.81175957 49.16146787 47.93296258\n",
            " 34.53672641 48.41887529 49.05473814 38.52432072 49.68022356 47.0194448\n",
            " 46.43648039 49.31026576 41.90891665 49.84207027 49.20415154 48.565829\n",
            " 48.98462297 17.48100623 49.03718817 30.45876058 47.11542932 39.99281575\n",
            " 39.66551121 46.56622339 47.4143105  30.23330462 42.3144175  41.44037437\n",
            " 49.91968454 42.69948959 47.16282591 47.88476127 36.89436284 43.93157739\n",
            " 49.07603424 48.11802356 49.28984374 48.35937833 30.36254107 33.64776486\n",
            " 36.87903389 40.85012844 49.84047279 34.58053781 41.89632005 46.26151262\n",
            " 43.42211786 42.02518212 47.10743352 43.30562571 48.48578148 44.78480313\n",
            " 49.32109877 38.06516643 48.17000361 48.83429741 49.78231383 49.85446212\n",
            " 38.92065212 41.79172426 43.49955332 49.49232592 44.78790074 40.05243235\n",
            " 42.79371047 49.10503053 49.5016691  29.09801193 49.46483465 48.11262727\n",
            " 49.7673849  49.01501857 48.14315009 48.40720728 36.44865961 48.49035035\n",
            " 49.04901733 49.76041557 47.18371457 36.44865961 46.65948159 48.20697636\n",
            " 46.93498125 31.70166669 48.57614774 48.56077916 48.56429938 42.1147621\n",
            " 31.38379111 47.76541431 47.57156824 48.59136355 45.775227   49.3836852\n",
            " 47.50463579 43.34992061 49.33677232 37.50652238 48.57903629 41.91610896\n",
            " 46.1982602  48.14595825 49.0877547  49.02768327 47.47129782 46.28474268\n",
            " 36.25877608 43.21473189 49.73638871 47.67778181 32.92703875 40.47791259\n",
            " 46.37923685 48.26538087 47.70807534 49.15886708 40.48855092 49.50402088\n",
            " 36.44865961 45.45063753 48.60406548 48.68588658 49.46948335 36.44865961\n",
            " 46.28482449 48.01575448 49.65335882 49.52384691 47.78114754 34.93727696\n",
            " 48.21695049 48.63747422 45.48093816 47.96602589 33.67614889 44.23060501\n",
            " 37.22420707 39.02324481 48.96955517 48.93497747 31.10760071 42.79863415\n",
            " 44.30071244 49.26356948 40.74892751 38.45322386 45.02848308 45.5875391\n",
            " 23.11051055 48.64964559 37.41929867 41.62786698 45.19368121 43.3826395\n",
            " 49.60644157 49.11971901 44.61794429 45.17149514 11.27001382 49.23994515\n",
            " 31.89467932 46.60378904 33.46494064 37.30782765 41.08384725 41.69158794\n",
            " 49.10858133 48.26981169 34.42205376 41.618375   40.47226684 32.07418223\n",
            " 48.73427625 29.41148148 28.92281954 47.58519625 38.86807412 36.44865961\n",
            " 39.70900055 32.01131091 43.52573464 48.95622356 41.42114667 47.03616599\n",
            " 46.90367346 35.48891778 46.24687617 48.8762058 ]\n",
            "selection [922 418 781 307 602 512 698 203 673 131   5   0 648 912 377 702  84 104\n",
            " 349 575 381 661 689 596 113] (25,) [11.27001382 12.95460988 17.48100623 18.30662619 19.17983653 19.74855507\n",
            " 20.83671253 21.3569172  21.78456456 22.17507242 22.65645752 22.757802\n",
            " 22.76789766 23.11051055 23.19040757 23.21923323 23.70141783 23.88329374\n",
            " 24.44005385 25.18139263 25.24861075 25.50790764 25.91967898 26.10803639\n",
            " 26.29377405]\n",
            "trainset before adding uncertain samples (350, 10) (350,)\n",
            "trainset after adding uncertain samples (375, 10) (375,)\n",
            "updated train set: (375, 10) (375,) unique(labels): [188 187] [0 1]\n",
            "val set: (927, 10) (927,)\n",
            "\n",
            "Train set: (375, 10)\n",
            "Validation set: (927, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 15\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.358 s \n",
            "\n",
            "Accuracy rate is 80.875576 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.88      0.87       321\n",
            "           1       0.64      0.59      0.62       113\n",
            "\n",
            "    accuracy                           0.81       434\n",
            "   macro avg       0.75      0.74      0.75       434\n",
            "weighted avg       0.80      0.81      0.81       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[284  37]\n",
            " [ 46  67]]\n",
            "--------------------------------\n",
            "val predicted: (927,) [1 1 0 1 0 1 1 0 0 0 1 1 1 0 1 0 1 0 0 0 1 1 1 0 1 1 0 1 0 0 1 0 0 0 1 0 1\n",
            " 0 0 0 1 1 0 1 1 1 1 0 0 0 1 1 1 1 1 0 1 0 1 1 0 0 1 1 1 1 1 0 1 1 0 0 1 1\n",
            " 0 0 0 0 1 0 1 1 1 1 0 1 0 1 1 1 0 0 0 0 0 1 0 0 1 0 1 1 0 0 1 1 0 0 1 0 0\n",
            " 0 0 1 0 0 0 1 1 0 1 1 0 1 1 1 0 1 1 1 1 1 0 1 1 0 1 1 1 0 1 1 1 0 0 0 1 0\n",
            " 1 0 1 1 1 0 1 1 1 1 0 0 0 1 1 0 1 1 1 0 0 1 0 0 0 1 1 1 0 1 0 0 0 0 0 1 0\n",
            " 1 0 0 0 0 1 0 1 0 1 1 0 1 1 0 0 0 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 0 1 1 1\n",
            " 0 1 1 0 1 1 0 1 1 0 1 1 0 1 0 1 1 1 0 1 0 0 1 1 0 1 1 0 0 0 0 1 1 1 1 0 0\n",
            " 1 0 0 0 0 1 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 1 1 1 1 1 1 1 0 1 1 1 0 1 1 0 1\n",
            " 0 0 0 1 0 0 1 0 1 0 1 0 0 1 0 0 1 0 1 0 0 1 1 1 0 1 1 0 1 0 0 1 1 0 1 1 1\n",
            " 1 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 1 1 0 1 1 1 0 1 0 0 1 1 1 0 1 1 0 1 0\n",
            " 1 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0 0 0 1 1 0 0 1 1 0 0 1 0 0 1 0 0 0 1 0 0 1\n",
            " 1 1 1 0 1 0 1 1 1 1 0 1 0 1 0 1 1 0 0 0 0 0 0 1 1 1 1 1 1 0 0 0 1 1 0 1 0\n",
            " 1 0 0 0 0 0 1 1 0 0 0 0 1 1 0 0 0 1 0 1 0 0 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1\n",
            " 0 1 0 0 0 1 0 0 1 1 0 1 1 0 1 1 0 1 0 0 0 1 0 1 0 1 0 1 1 0 1 1 0 1 1 0 1\n",
            " 1 1 0 1 1 0 1 1 1 1 1 0 0 0 1 0 0 1 1 1 1 1 0 1 1 1 1 1 0 0 0 1 0 1 0 0 0\n",
            " 1 0 1 1 0 1 1 1 0 1 1 0 0 0 1 0 0 1 0 0 1 0 1 1 1 1 1 0 0 0 1 0 1 1 0 1 1\n",
            " 1 0 1 1 0 1 1 0 1 0 0 1 1 0 1 1 1 1 1 0 0 1 1 0 0 1 1 1 1 0 1 1 0 1 0 0 1\n",
            " 1 1 0 0 1 1 0 1 1 0 1 0 1 0 1 0 0 0 1 0 1 1 0 0 0 0 0 1 0 1 0 0 1 0 0 1 1\n",
            " 1 0 1 0 0 1 0 1 0 1 1 1 1 0 0 0 0 0 1 0 1 1 1 0 1 1 0 0 1 0 1 0 0 0 0 0 1\n",
            " 0 0 1 1 0 1 0 1 0 0 1 0 1 1 1 0 0 0 1 1 0 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 0\n",
            " 0 1 0 0 0 1 0 1 1 1 0 1 0 0 1 0 0 0 0 0 1 1 0 1 1 1 1 1 0 0 1 1 0 1 1 1 1\n",
            " 1 1 1 0 0 1 0 0 0 1 0 0 1 0 1 1 0 1 0 1 0 0 0 1 0 1 0 1 0 1 0 1 1 1 0 0 0\n",
            " 1 0 1 1 0 0 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 1 0 1 0 1 1 0 1 1 1 1 1 1 1\n",
            " 0 1 1 1 0 1 1 0 0 1 1 0 1 0 0 1 0 1 1 0 1 0 0 1 0 1 1 0 1 0 1 1 1 1 1 1 0\n",
            " 1 0 1 0 0 0 0 1 0 0 0 0 1 1 0 0 1 1 1 0 0 1 0 1 1 0 1 0 0 1 1 1 0 0 1 1 1\n",
            " 0 0]\n",
            "probabilities: (927, 2) \n",
            " [1 1 0 1 0 1 1 0 0 0 1 1 1 0 1 0 1 0 0 0 1 1 1 0 1 1 0 1 0 0 1 0 0 0 1 0 1\n",
            " 0 0 0 1 1 0 1 1 1 1 0 0 0 1 1 1 1 1 0 1 0 1 1 0 0 1 1 1 1 1 0 1 1 0 0 1 1\n",
            " 0 0 0 0 1 0 1 1 1 1 0 1 0 1 1 1 0 0 0 0 0 1 0 0 1 0 1 1 0 0 1 1 0 0 1 0 0\n",
            " 0 0 1 0 0 0 1 1 0 1 1 0 1 1 1 0 1 1 1 1 1 0 1 1 0 1 1 1 0 1 1 1 0 0 0 1 0\n",
            " 1 0 1 1 1 0 1 1 1 1 0 0 0 1 1 0 1 1 1 0 0 1 0 0 0 1 1 1 0 1 0 0 0 0 0 1 0\n",
            " 1 0 0 0 0 1 0 1 0 1 1 0 1 1 0 0 0 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 0 1 1 1\n",
            " 0 1 1 0 1 1 0 1 1 0 1 1 0 1 0 1 1 1 0 1 0 0 1 1 0 1 1 0 0 0 0 1 1 1 1 0 0\n",
            " 1 0 0 0 0 1 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 1 1 1 1 1 1 1 0 1 1 1 0 1 1 0 1\n",
            " 0 0 0 1 0 0 1 0 1 0 1 0 0 1 0 0 1 0 1 0 0 1 1 1 0 1 1 0 1 0 0 1 1 0 1 1 1\n",
            " 1 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 1 1 0 1 1 1 0 1 0 0 1 1 1 0 1 1 0 1 0\n",
            " 1 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0 0 0 1 1 0 0 1 1 0 0 1 0 0 1 0 0 0 1 0 0 1\n",
            " 1 1 1 0 1 0 1 1 1 1 0 1 0 1 0 1 1 0 0 0 0 0 0 1 1 1 1 1 1 0 0 0 1 1 0 1 0\n",
            " 1 0 0 0 0 0 1 1 0 0 0 0 1 1 0 0 0 1 0 1 0 0 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1\n",
            " 0 1 0 0 0 1 0 0 1 1 0 1 1 0 1 1 0 1 0 0 0 1 0 1 0 1 0 1 1 0 1 1 0 1 1 0 1\n",
            " 1 1 0 1 1 0 1 1 1 1 1 0 0 0 1 0 0 1 1 1 1 1 0 1 1 1 1 1 0 0 0 1 0 1 0 0 0\n",
            " 1 0 1 1 0 1 1 1 0 1 1 0 0 0 1 0 0 1 0 0 1 0 1 1 1 1 1 0 0 0 1 0 1 1 0 1 1\n",
            " 1 0 1 1 0 1 1 0 1 0 0 1 1 0 1 1 1 1 1 0 0 1 1 0 0 1 1 1 1 0 1 1 0 1 0 0 1\n",
            " 1 1 0 0 1 1 0 1 1 0 1 0 1 0 1 0 0 0 1 0 1 1 0 0 0 0 0 1 0 1 0 0 1 0 0 1 1\n",
            " 1 0 1 0 0 1 0 1 0 1 1 1 1 0 0 0 0 0 1 0 1 1 1 0 1 1 0 0 1 0 1 0 0 0 0 0 1\n",
            " 0 0 1 1 0 1 0 1 0 0 1 0 1 1 1 0 0 0 1 1 0 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 0\n",
            " 0 1 0 0 0 1 0 1 1 1 0 1 0 0 1 0 0 0 0 0 1 1 0 1 1 1 1 1 0 0 1 1 0 1 1 1 1\n",
            " 1 1 1 0 0 1 0 0 0 1 0 0 1 0 1 1 0 1 0 1 0 0 0 1 0 1 0 1 0 1 0 1 1 1 0 0 0\n",
            " 1 0 1 1 0 0 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 1 0 1 0 1 1 0 1 1 1 1 1 1 1\n",
            " 0 1 1 1 0 1 1 0 0 1 1 0 1 0 0 1 0 1 1 0 1 0 0 1 0 1 1 0 1 0 1 1 1 1 1 1 0\n",
            " 1 0 1 0 0 0 0 1 0 0 0 0 1 1 0 0 1 1 1 0 0 1 0 1 1 0 1 0 0 1 1 1 0 0 1 1 1\n",
            " 0 0]\n",
            "std (927,) [44.1847217  46.10574295 44.78174351 44.67124514 45.14625371 48.22568008\n",
            " 35.49073511 42.62223982 37.55446783 49.73760518 48.62327605 48.52095165\n",
            " 40.85573087 49.03500222 46.42917352 36.55554256 35.76799703 46.49415732\n",
            " 18.90822671 45.57100907 47.61569468 32.71194443 48.47354129 36.55554256\n",
            " 47.63220347 48.60834949 29.7866265  42.22048563 38.50982969 48.25048165\n",
            " 46.19762737 49.80444905 49.69591426 31.28138646 43.93409288 31.2529166\n",
            " 42.86432222 40.5882621  48.68207222 42.50448987 46.06285275 35.41790448\n",
            " 34.08001794 46.46195157 46.23412577 41.37316767 49.00971107 47.55493294\n",
            " 37.67090103 48.80470657 48.17884022 29.49681023 47.14074017 46.42244311\n",
            " 26.29637621 46.57702023 48.55057669 41.29312303 37.05027255 48.10328868\n",
            " 48.13410473 48.88706972 46.74140789 46.8005275  46.11685024 34.63231086\n",
            " 48.76770252 49.5601295  48.40901347 44.38276502 49.64959465 37.75622734\n",
            " 48.73954676 41.30633192 45.06866613 36.98624435 49.05725601 34.15037768\n",
            " 48.03719661 48.90872871 44.50777332 47.44737275 47.58391014 47.56159606\n",
            " 45.55008801 48.7559681  49.39300611 45.81768565 30.23582836 46.52138276\n",
            " 17.62018866 47.86709494 49.23836166 49.31836413 48.37402964 49.38235839\n",
            " 38.89241635 47.92371154 49.40453895 48.49450292 47.03683147 41.01048969\n",
            " 43.74673784 46.52663517 46.48728012 41.18664455 49.43192962 48.74607453\n",
            " 45.04275032 46.70484564 49.54087673 46.50989193 36.55554256 47.93937504\n",
            " 24.44936664 36.44721099 49.55170721 47.52443792 41.27249541 49.15728533\n",
            " 42.98534825 32.17304707 49.04568731 48.28151138 30.07692694 40.4005516\n",
            " 44.01859168 35.86220926 44.73497168 46.11879436 41.24495611 47.647371\n",
            " 40.22143461 48.8630423  46.11164709 46.17851805 27.1192993  49.01968583\n",
            " 39.64305898 49.61736281 44.91753881 45.4170255  48.21918603 43.45818529\n",
            "  2.14895531 40.75447951 39.90468622 49.58844036 48.22904372 45.87176933\n",
            " 47.16429207 46.75455824 37.83717389 31.96438499 47.75699347 43.32024395\n",
            " 20.90874664 42.21527572 49.6127281  49.68490345 36.55554256 46.55130291\n",
            " 45.79436094 44.91691426 46.36541182 43.5083138  46.64739126 49.1105284\n",
            " 48.36712527 25.42444593 47.55948825 43.48024737 42.2326345  37.86846072\n",
            " 47.73719402 45.79532415 46.76829986 46.68383605 47.34891012 48.60761287\n",
            " 49.78554916 48.563958   49.79086164 48.72091829 48.25673496 47.21551043\n",
            " 48.80176698 49.78408534 36.55554256 49.49599583 47.15512198 37.92887406\n",
            " 41.33316138 45.97490712 48.57313651 45.72721359 49.08515942 42.52281768\n",
            " 48.32396726 42.01708414 49.76486537 46.11835588 48.81850686 49.52203068\n",
            " 49.1447876  43.16599584 49.64380904 39.3448927  45.71623711 48.12664389\n",
            " 40.48839222 47.74185983 43.09553061 49.52694687 49.06763955 47.97367454\n",
            " 48.87944407 47.50862429 48.80578342 46.23469883 48.50247943 47.29409949\n",
            " 47.55300617 38.74924084 49.01912102 49.72708128 49.40540155 46.8366859\n",
            " 45.05710608 49.21038272 36.15526539 48.90700486 44.53716816 42.6884298\n",
            " 38.44668577 49.23954036 43.14300888 45.6263802  39.51337688 47.34023485\n",
            " 34.89332688 41.82948796 49.70801537 49.53918787 47.92181418 37.3656431\n",
            " 48.36722899 46.91985223 47.50586915 46.80616686 40.46143378 44.23022115\n",
            " 36.13701205 48.38269366 46.86404519 45.39875395 48.98914583 38.54496332\n",
            " 49.33544991 49.21552824 36.55554256 34.59869251 40.97115787 49.66392441\n",
            " 46.26640748 46.5333699  47.2735016  48.60561628 29.01596649 42.84368941\n",
            " 40.0736637  46.05437739 42.18670088 32.44256114 47.13279542 49.73409032\n",
            " 48.98037349 49.07362628 46.84105355 39.9350437  48.15611278 47.43401946\n",
            " 47.27541262 47.21976051 42.76955359 45.87377004 49.24291862 36.55554256\n",
            " 38.55967086 48.86597494 48.04824702 49.64959465 47.60306098 47.8831456\n",
            " 46.74474413 39.27661802 49.69258414 47.54941068 41.78773148 44.90410029\n",
            " 46.68110878 49.70485872 49.76546429 46.6905091  35.1247248  49.60163522\n",
            " 47.31629055 36.55554256 46.16664954 48.76230193 47.01756383 48.59979644\n",
            " 40.25519766 44.78838155 41.7850615  49.36679422 43.07331603 47.89875149\n",
            " 47.60292266 45.40339923 35.46505118 35.6102036  43.24806264 49.18534757\n",
            " 46.70028371 28.53594285 46.25854619 40.07716369 48.05963137 27.809268\n",
            " 40.20457144 48.41324367 46.98832124 42.41687616 48.2995063  42.06174823\n",
            " 48.67718536 49.66237176 47.19416015 48.98092999 30.24475826 41.17305553\n",
            " 48.05755087 48.43491782 41.36786152 48.86467381 42.5836744  48.440061\n",
            " 48.36604913 34.41814352 48.7408199  35.46927588 45.57999672 40.32414794\n",
            " 49.40663006 48.86933308 47.58630748 47.91765702 47.25286786 39.849122\n",
            " 49.01348838 48.47261827 47.8377025  48.32431587 42.67058307 40.38950333\n",
            " 41.66293541 44.43879678 40.75717004 27.38734641 48.60952821 49.15052177\n",
            " 43.26852651 48.04405515 49.25484116 47.41619075 44.79582004 49.25196585\n",
            " 48.82598652 46.25969132 48.16326866 31.5115514  46.44456405 28.60776823\n",
            " 49.45538816 38.67744708 44.87707061 43.70598218 48.21929109 47.03379486\n",
            " 48.73430987 27.85156162 42.10303262 36.63913077 39.57075473 36.55554256\n",
            " 47.54490445 46.7074716  45.48648814 43.96977674 35.13374581 35.33325299\n",
            " 49.19604035 48.88331023 45.8833775  47.15868939 47.73740755 37.96761822\n",
            " 31.5115514  46.57627699 47.45906741 47.36065211 34.84073439 48.80745529\n",
            " 48.35635412 18.61502529 48.31278192 36.29357238 33.05328631 49.3677444\n",
            " 48.50862913 49.49004087 49.47777427 44.83304566 41.52458328 42.97789328\n",
            " 49.26997108 48.81767518 49.71096269 14.46264169 46.07334086 46.71212839\n",
            " 48.34490821 47.52053183 49.1541012  48.38849934 49.35503351 49.86422838\n",
            " 45.91844853 46.82876784 43.9253254  27.27629281 48.20995347 48.53213712\n",
            " 46.46496122 49.42725195 27.73894274 46.95991412 36.23720865 43.77246382\n",
            " 47.04384082 36.47957866 49.60763319 36.55554256 44.79504587 49.53504624\n",
            " 46.27202068 48.69427807 15.28416479 48.00208045 36.55554256 48.06661788\n",
            " 48.21883869 44.9291907  49.54244046 48.81545763 45.46981957 41.89648659\n",
            " 48.76496928 41.25772733 48.35356407 39.15064947 46.19229428 40.25927213\n",
            " 41.09893275 42.30870621 48.75364034 46.87129747 38.98670426 49.20653655\n",
            " 48.84538853 30.27888032 41.22107633 23.92348547 36.97328718 47.4229544\n",
            " 48.95222294 47.75239035 26.48399798 49.33148857 49.39458169 36.55554256\n",
            " 46.26649003 32.18968492 44.07082162 44.81642561 48.74656535 43.53265053\n",
            " 48.4826853  46.94686118 34.37088825 47.21393424 48.34769322 43.26133607\n",
            " 46.26650578 47.69511367 49.49798908 47.04431294 49.09548511 47.4880971\n",
            " 43.80580977 40.96509487 43.24806264 48.15426791 47.45470725 42.79630903\n",
            " 49.59450252 48.39607401 45.29365399 29.75101927 45.08384849 46.81169964\n",
            " 46.87129747 40.69947979 47.18470904 48.58304723 46.58543771 48.50627037\n",
            " 49.13557601 49.75579783 45.82500198 40.43397397 42.69734519 48.37727859\n",
            " 25.38811615 48.49211037 33.64488588 45.219392   26.86317469 47.88461714\n",
            " 25.15605996 41.02740152 48.62220282 38.52790014 49.1449476  41.16969242\n",
            " 49.29102298 46.46843988 45.78826551 24.89407278 46.4432551  48.743899\n",
            " 47.48922411 49.41898767 46.47759961 49.58158056 46.84208591 42.93933952\n",
            " 43.86678453 45.72215802 48.71675983 44.55807993 46.44991515 23.81850016\n",
            " 49.20392027 42.54303979 49.71024325 45.40117894 49.55850973 42.16230763\n",
            " 43.92433015 48.14399921 47.35223044 32.73076582 44.03396074 45.45624435\n",
            " 45.28255507 37.41109436 48.34197017 48.01528392 47.65505172 39.26167473\n",
            " 47.97623781 48.50161252 41.47649735 48.55414202 30.80531144 48.04173768\n",
            " 37.46427374 49.66324958 48.80734448 43.39213803 47.54384134 41.9462189\n",
            " 40.80314567 41.29142579 48.7278827  41.68098873 48.76350635 49.45135527\n",
            " 41.205213   47.37529375 47.52618632 35.50537678 48.7467434  47.66881984\n",
            " 49.24734503 47.61019094 48.40127058 48.35610216 44.20362172 38.0652729\n",
            " 39.31097097 49.11344979 47.81410978 39.91171345 41.06752683 48.90621407\n",
            " 43.5400025  47.06232538 39.10049662 48.94418159 44.14562049 31.12257807\n",
            " 49.62160893 47.21976051 49.41234487 49.69292392 48.44804854 49.60939808\n",
            " 49.21748087 27.40973306 46.41158915 49.30265337 46.62764264 47.27094062\n",
            " 46.06426752 49.01548294 41.22077769 32.0289636  36.55554256 47.81430935\n",
            " 48.84869295 47.00457227 36.55554256 36.55554256 45.40627224 49.36280894\n",
            " 48.98745578 48.81203206 33.03591779 44.27694152 38.58067078 48.96865179\n",
            " 48.36278659 38.90367714 48.53666254 44.80367092 45.64199626 23.60866298\n",
            " 47.27564157 47.42345687 31.85300186 46.1077125  46.05773581 38.97256543\n",
            " 47.58364383 42.19940403 45.90525476 46.03982075 47.34006674 49.14737116\n",
            " 46.46167597 43.24926598 46.1230055  48.95485589 47.93086954 45.32562676\n",
            " 40.5787855  39.98750496 43.64224122 49.73914563 27.00986674 49.38002282\n",
            " 49.37353631 49.67354636 49.29324134 49.3443628  48.33224181 31.11951219\n",
            " 33.87516488 44.66630715 49.71143489 49.21008874 49.23681966 36.55554256\n",
            " 46.30480068 28.69990753 49.34330809 47.99516671 36.55554256 46.2125464\n",
            " 45.38562266 23.913923   49.63548685 42.33418921 49.29918596 41.02039268\n",
            " 39.37381663 48.35088128 48.49498072 49.67893576 48.18546904 45.02782023\n",
            " 47.01314788 48.12261171 44.87793494 41.5825986  47.80425409 49.71892982\n",
            " 36.55554256 44.02269627 48.29142243 49.33903103 46.61769336 46.10195413\n",
            " 33.08119181 35.48709759 39.14991013 39.89331841 45.19628736 30.58849657\n",
            " 45.5078916  47.35499436 46.83553015 28.76323323 47.69407763 48.65839058\n",
            " 43.47887101 48.33367218 48.39673022 45.52077819 47.41230581 46.64226505\n",
            " 49.10323491 46.99540762 36.74258604 48.35356407 48.76904214 42.13260508\n",
            " 49.32843269 46.76409547 42.95041364 49.10491434 37.08411816 49.71937041\n",
            " 48.75416514 47.6461289  49.10135287 48.41275061 27.72512213 45.38256037\n",
            " 35.48079292 41.00954107 46.9566688  46.90729323 31.47033112 40.42800015\n",
            " 36.63883028 49.86306974 41.80107204 46.91121339 47.2532529  37.7773631\n",
            " 43.27907079 48.88575313 47.58382921 48.94700783 47.9393598  34.87329533\n",
            " 21.46516338 37.52175832 38.8584859  49.80701818 34.07254395 37.01345439\n",
            " 46.40949036 43.60276626 43.38436255 46.48647806 46.51873936 48.18766003\n",
            " 44.81427447 49.21804443 40.44280222 46.09927725 48.52415261 49.68531212\n",
            " 49.74631365 34.92318718 39.91818764 41.52673952 49.31998896 45.94960315\n",
            " 41.86526379 40.33088377 48.608445   49.23474196 29.23416177 49.43745876\n",
            " 47.67569485 49.65638818 48.665816   48.26692371 48.31962687 36.55554256\n",
            " 47.4163423  48.72116253 49.68029705 45.02820673 36.55554256 46.50345018\n",
            " 48.07451066 47.1012731  35.76799703 48.53666254 48.50313611 48.24978289\n",
            " 43.88274683 27.11779696 47.14882955 47.74185983 48.34769322 45.46596792\n",
            " 48.88995414 45.70109934 43.8316031  48.99972658 34.90391803 48.85389138\n",
            " 42.22564302 44.83097912 48.19649221 49.40354976 47.38331855 47.5494212\n",
            " 45.40257779 36.12619143 39.72156191 49.62681121 47.64342428 32.20352556\n",
            " 38.75464538 46.69682883 48.14727006 47.36656018 49.32432868 41.82057027\n",
            " 49.14952629 36.55554256 46.12115005 48.0007839  48.19248069 49.1584758\n",
            " 36.55554256 45.15220704 48.16336525 49.38747159 49.05391829 47.88337832\n",
            " 30.2401083  47.59342915 47.75266415 45.29976234 48.11161886  2.96112886\n",
            " 39.49154866 38.3148489  39.48956652 48.66113448 48.75473162 29.69523181\n",
            " 40.77851568 40.31456898 49.1214677  41.38369961 35.31279805 35.75561731\n",
            " 45.27843767 46.51191573 35.81125517 38.48791276 45.58457114 37.07698751\n",
            " 49.51754024 48.8196705  44.70180164 46.67021016 49.10062637 34.09616566\n",
            " 45.1266499  35.63659138 18.30926093 43.25592406 41.54158348 48.68572342\n",
            " 47.37321785 20.57791996 39.16563708 36.85286704 18.51865819 48.55905359\n",
            " 32.08164708 27.19893033 46.88566516 34.58855717 36.55554256 39.68300652\n",
            " 24.47408586 43.94407452 48.98718713 45.95662721 46.24701285 45.53046863\n",
            " 34.56479406 46.16464956 46.78952543]\n",
            "selection [144 875 429 458  90 902 910 415  18 907 156 780 659 563 703 483 114 918\n",
            " 549 540 534 169  54 488 538] (25,) [ 2.14895531  2.96112886 14.46264169 15.28416479 17.62018866 18.30926093\n",
            " 18.51865819 18.61502529 18.90822671 20.57791996 20.90874664 21.46516338\n",
            " 23.60866298 23.81850016 23.913923   23.92348547 24.44936664 24.47408586\n",
            " 24.89407278 25.15605996 25.38811615 25.42444593 26.29637621 26.48399798\n",
            " 26.86317469]\n",
            "trainset before adding uncertain samples (375, 10) (375,)\n",
            "trainset after adding uncertain samples (400, 10) (400,)\n",
            "updated train set: (400, 10) (400,) unique(labels): [196 204] [0 1]\n",
            "val set: (902, 10) (902,)\n",
            "\n",
            "Train set: (400, 10)\n",
            "Validation set: (902, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 16\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.262 s \n",
            "\n",
            "Accuracy rate is 80.875576 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.88      0.87       321\n",
            "           1       0.64      0.60      0.62       113\n",
            "\n",
            "    accuracy                           0.81       434\n",
            "   macro avg       0.75      0.74      0.75       434\n",
            "weighted avg       0.81      0.81      0.81       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[283  38]\n",
            " [ 45  68]]\n",
            "--------------------------------\n",
            "val predicted: (902,) [1 1 0 1 0 1 1 0 0 0 1 1 1 0 1 0 1 0 0 1 1 1 0 1 1 0 1 0 0 1 0 0 0 1 0 1 0\n",
            " 0 0 1 1 0 1 1 1 1 0 0 0 1 1 1 1 0 1 0 1 1 0 0 1 1 1 1 1 0 1 1 0 0 1 1 0 0\n",
            " 0 0 1 0 1 1 1 1 0 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 1 0 0 1 1 0 0 1 0 0 0 0 1\n",
            " 0 0 1 1 0 1 1 0 1 1 1 0 1 1 1 1 1 0 1 1 0 1 1 1 0 1 1 1 0 0 1 0 1 0 1 1 1\n",
            " 0 1 1 1 0 0 0 1 1 0 1 1 1 0 0 0 0 0 1 1 1 0 1 0 0 0 0 0 1 0 1 0 0 0 0 1 0\n",
            " 1 0 1 1 0 1 1 0 0 0 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 0 1 1 1 0 1 1 0 1 1 0\n",
            " 1 1 0 1 1 0 1 0 1 1 1 0 1 0 0 1 1 0 1 1 0 0 0 0 1 1 1 1 0 0 1 0 0 0 0 1 0\n",
            " 1 0 1 0 1 0 0 0 1 0 0 0 0 0 1 1 1 1 1 1 1 0 1 1 1 0 1 1 0 1 0 0 0 1 0 0 1\n",
            " 0 1 0 1 0 0 1 0 0 1 0 1 0 0 1 1 1 0 1 1 0 1 0 0 1 1 0 1 1 1 1 1 1 1 1 1 1\n",
            " 0 0 1 1 1 0 0 1 0 1 0 1 1 0 1 1 1 0 1 0 0 1 1 1 0 1 1 0 1 0 1 1 1 1 0 1 1\n",
            " 0 1 1 1 1 1 1 0 0 0 0 1 1 0 0 1 1 0 0 1 0 0 1 0 0 0 1 0 0 1 1 1 1 0 1 0 1\n",
            " 1 1 0 1 0 1 0 1 1 0 0 0 0 0 1 1 1 1 1 1 0 0 0 1 1 0 1 0 1 0 0 0 0 0 1 1 0\n",
            " 0 0 0 1 1 0 0 1 0 1 0 0 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 0 1 0 0 1 0 1 1 0 1\n",
            " 1 0 1 1 0 1 0 0 0 1 0 1 0 1 0 1 1 0 1 1 0 1 1 0 1 1 1 0 1 1 0 1 1 1 1 1 0\n",
            " 0 0 1 0 1 1 1 1 1 1 1 1 1 0 0 0 0 1 0 0 0 1 0 1 1 0 1 1 1 1 1 0 0 0 1 0 0\n",
            " 1 0 0 1 0 1 1 1 1 1 0 0 0 1 0 1 1 0 1 1 1 0 1 1 0 1 1 0 1 0 0 1 1 0 1 1 1\n",
            " 1 1 0 0 1 1 0 0 1 1 1 1 0 1 1 0 1 0 0 1 1 1 0 0 1 1 0 1 1 0 1 0 1 0 1 0 0\n",
            " 0 1 0 1 1 0 0 0 0 0 1 0 1 0 1 0 0 1 1 1 0 1 0 0 1 0 1 0 1 1 1 1 0 0 0 0 0\n",
            " 1 0 1 1 1 0 1 1 0 0 1 0 1 0 0 0 0 0 1 0 1 1 0 1 0 1 0 0 1 0 1 1 1 0 0 0 1\n",
            " 1 0 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 0 0 1 0 0 0 1 0 1 1 1 0 1 0 0 1 0 0 0 0\n",
            " 0 1 1 0 1 1 1 1 1 0 0 1 1 0 1 1 1 1 1 1 1 0 1 0 0 0 1 0 0 1 0 1 1 0 1 0 1\n",
            " 0 0 0 1 0 1 0 1 0 1 0 1 1 1 0 0 0 1 0 1 1 0 0 0 1 0 1 1 1 1 1 1 0 0 1 1 1\n",
            " 0 0 1 1 0 1 0 1 1 0 1 1 1 1 1 1 1 0 1 1 1 0 1 1 0 0 1 1 0 1 0 0 1 0 1 1 0\n",
            " 1 0 0 1 1 1 0 1 0 1 1 1 1 1 1 0 1 0 1 0 0 0 0 1 0 0 0 0 1 1 0 1 1 1 0 1 1\n",
            " 1 0 1 0 0 1 1 0 0 1 1 1 0 0]\n",
            "probabilities: (902, 2) \n",
            " [1 1 0 1 0 1 1 0 0 0 1 1 1 0 1 0 1 0 0 1 1 1 0 1 1 0 1 0 0 1 0 0 0 1 0 1 0\n",
            " 0 0 1 1 0 1 1 1 1 0 0 0 1 1 1 1 0 1 0 1 1 0 0 1 1 1 1 1 0 1 1 0 0 1 1 0 0\n",
            " 0 0 1 0 1 1 1 1 0 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 1 0 0 1 1 0 0 1 0 0 0 0 1\n",
            " 0 0 1 1 0 1 1 0 1 1 1 0 1 1 1 1 1 0 1 1 0 1 1 1 0 1 1 1 0 0 1 0 1 0 1 1 1\n",
            " 0 1 1 1 0 0 0 1 1 0 1 1 1 0 0 0 0 0 1 1 1 0 1 0 0 0 0 0 1 0 1 0 0 0 0 1 0\n",
            " 1 0 1 1 0 1 1 0 0 0 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 0 1 1 1 0 1 1 0 1 1 0\n",
            " 1 1 0 1 1 0 1 0 1 1 1 0 1 0 0 1 1 0 1 1 0 0 0 0 1 1 1 1 0 0 1 0 0 0 0 1 0\n",
            " 1 0 1 0 1 0 0 0 1 0 0 0 0 0 1 1 1 1 1 1 1 0 1 1 1 0 1 1 0 1 0 0 0 1 0 0 1\n",
            " 0 1 0 1 0 0 1 0 0 1 0 1 0 0 1 1 1 0 1 1 0 1 0 0 1 1 0 1 1 1 1 1 1 1 1 1 1\n",
            " 0 0 1 1 1 0 0 1 0 1 0 1 1 0 1 1 1 0 1 0 0 1 1 1 0 1 1 0 1 0 1 1 1 1 0 1 1\n",
            " 0 1 1 1 1 1 1 0 0 0 0 1 1 0 0 1 1 0 0 1 0 0 1 0 0 0 1 0 0 1 1 1 1 0 1 0 1\n",
            " 1 1 0 1 0 1 0 1 1 0 0 0 0 0 1 1 1 1 1 1 0 0 0 1 1 0 1 0 1 0 0 0 0 0 1 1 0\n",
            " 0 0 0 1 1 0 0 1 0 1 0 0 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 0 1 0 0 1 0 1 1 0 1\n",
            " 1 0 1 1 0 1 0 0 0 1 0 1 0 1 0 1 1 0 1 1 0 1 1 0 1 1 1 0 1 1 0 1 1 1 1 1 0\n",
            " 0 0 1 0 1 1 1 1 1 1 1 1 1 0 0 0 0 1 0 0 0 1 0 1 1 0 1 1 1 1 1 0 0 0 1 0 0\n",
            " 1 0 0 1 0 1 1 1 1 1 0 0 0 1 0 1 1 0 1 1 1 0 1 1 0 1 1 0 1 0 0 1 1 0 1 1 1\n",
            " 1 1 0 0 1 1 0 0 1 1 1 1 0 1 1 0 1 0 0 1 1 1 0 0 1 1 0 1 1 0 1 0 1 0 1 0 0\n",
            " 0 1 0 1 1 0 0 0 0 0 1 0 1 0 1 0 0 1 1 1 0 1 0 0 1 0 1 0 1 1 1 1 0 0 0 0 0\n",
            " 1 0 1 1 1 0 1 1 0 0 1 0 1 0 0 0 0 0 1 0 1 1 0 1 0 1 0 0 1 0 1 1 1 0 0 0 1\n",
            " 1 0 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 0 0 1 0 0 0 1 0 1 1 1 0 1 0 0 1 0 0 0 0\n",
            " 0 1 1 0 1 1 1 1 1 0 0 1 1 0 1 1 1 1 1 1 1 0 1 0 0 0 1 0 0 1 0 1 1 0 1 0 1\n",
            " 0 0 0 1 0 1 0 1 0 1 0 1 1 1 0 0 0 1 0 1 1 0 0 0 1 0 1 1 1 1 1 1 0 0 1 1 1\n",
            " 0 0 1 1 0 1 0 1 1 0 1 1 1 1 1 1 1 0 1 1 1 0 1 1 0 0 1 1 0 1 0 0 1 0 1 1 0\n",
            " 1 0 0 1 1 1 0 1 0 1 1 1 1 1 1 0 1 0 1 0 0 0 0 1 0 0 0 0 1 1 0 1 1 1 0 1 1\n",
            " 1 0 1 0 0 1 1 0 0 1 1 1 0 0]\n",
            "std (902,) [42.13929886 45.65584298 44.17287389 43.68674735 45.19025717 48.43130713\n",
            " 32.56263509 42.40233858 28.95539641 49.61497838 48.61337429 48.7726843\n",
            " 40.26067445 48.63811531 46.87103181 34.50812945 30.06741385 44.82142207\n",
            " 44.00408489 47.72121377 39.70808647 48.7295935  34.50812945 47.58339553\n",
            " 48.15399371 13.90625569 40.98597984 28.57517455 46.94370854 45.22025898\n",
            " 49.72059327 49.61596797 35.55570833 46.16249503 28.65623098 42.19389566\n",
            " 37.26041354 48.5306927  41.3052943  44.09063982 33.64902546 37.99613944\n",
            " 46.23381574 44.8810287  42.24845375 49.17019394 47.05722099 37.51444003\n",
            " 48.16597761 47.98092795 33.58905746 46.1506535  46.74738671 45.88468388\n",
            " 48.08471251 40.74611314 38.48795856 48.45174519 48.42436053 48.89711005\n",
            " 46.46104296 47.45973779 46.25523539 33.1738124  48.39635094 49.36070386\n",
            " 48.33840923 42.77392303 49.54558114 11.51952875 47.88995546 38.6990492\n",
            " 43.72613419 36.44757063 48.15774532 27.07910865 47.65300715 48.05525573\n",
            " 43.66879429 46.23891008 46.48877166 47.76579667 42.75564517 47.90121911\n",
            " 49.30523564 43.13740972 27.68317944 45.20944889 47.92399247 49.18372132\n",
            " 49.21785621 48.4887514  49.48530869 38.29704847 47.79266301 49.28798641\n",
            " 49.00732809 46.48332067 32.81550696 44.55939174 45.62967634 47.87781589\n",
            " 36.91013548 49.48140408 48.88690744 45.70995509 46.03660826 49.19400239\n",
            " 47.16500801 34.50812945 47.3916928  39.97082739 49.5454721  47.18167547\n",
            " 39.69992325 48.98085849 42.61037924 33.37873566 47.56236736 48.32716717\n",
            " 36.91478401 39.5006533  38.13753525 39.17653256 46.08268976 45.19067238\n",
            " 44.42306733 47.5162715  42.21081962 49.09958599 47.00252601 44.53962164\n",
            " 25.98040214 49.14641583 41.40870248 49.41315957 44.04762206 46.4390756\n",
            " 48.58058353 40.29296499 41.13957576 44.31093684 49.46943595 47.59857476\n",
            " 42.83768314 47.60837616 47.15137562 41.00987683 32.24240924 46.48198103\n",
            " 41.16943192 42.20690717 49.55383065 49.55070125 34.50812945 46.10204378\n",
            " 44.31346424 43.24288351 46.04566776 44.1379353  47.68678052 48.1870564\n",
            " 47.84302193 47.93505769 41.22713131 34.38493732 38.52555211 47.44365825\n",
            " 44.03745161 46.26089114 47.98453431 47.77359112 47.32358666 49.77406037\n",
            " 48.06168476 49.57001113 48.47325627 46.91575968 46.91018303 48.0329141\n",
            " 49.71557105 34.50812945 49.35035575 47.55292402 26.8806234  39.03023829\n",
            " 45.20413968 48.47882658 44.57894818 49.0525675  44.00504966 48.79883398\n",
            " 45.06661525 49.68108713 45.87538196 48.79839512 49.15150325 48.69969323\n",
            " 44.65744607 49.64281833 35.19232182 45.86695109 47.79330263 42.97244855\n",
            " 48.10176844 37.99201784 49.32656024 48.65280164 48.24890505 49.19876333\n",
            " 47.79581696 48.42713909 44.66111936 47.87701847 47.04800323 47.52802772\n",
            " 35.05939501 48.6506599  49.67295732 49.49897444 47.02498934 43.81430356\n",
            " 49.13029478 42.71127406 48.40385964 45.4038886  41.83585737 37.92849328\n",
            " 49.31166977 35.39592492 47.30180266 34.91393802 47.26694087 31.48105011\n",
            " 39.80704084 49.2011805  49.09413329 48.01088835 41.40719125 48.1708347\n",
            " 45.97248817 47.74650311 46.85082211 41.26449238 44.49257256 30.81493019\n",
            " 45.83193157 47.19915674 46.76126077 49.31682426 43.51100266 49.33940843\n",
            " 49.31913316 34.50812945 17.41202644 40.006726   49.52805433 44.5826836\n",
            " 44.70949871 47.36705802 48.42689474 28.37295009 46.11498121 42.66895384\n",
            " 41.93248978 42.60129391 25.68172952 45.13594241 49.67647838 48.12308162\n",
            " 49.07719979 46.97381766 39.51544936 48.05002726 46.81220957 48.36064697\n",
            " 45.95887188 41.30897014 43.11673622 49.27467497 34.50812945 36.88641202\n",
            " 48.43314409 46.44714936 49.54558114 47.91736199 48.29418281 44.63877841\n",
            " 43.12007333 49.66525294 47.43946362 40.98804933 43.01742626 47.14633992\n",
            " 49.676271   49.71709911 38.79831058 36.61903085 49.52038196 46.99400404\n",
            " 34.50812945 42.8289826  48.78640717 46.80379034 48.3934092  39.40548255\n",
            " 40.17653948 36.02614091 48.90389027 46.03921595 47.93948873 46.58402048\n",
            " 45.27549731 29.55572118 38.34284955 42.75786688 47.97403939 47.8793537\n",
            " 16.40275211 43.75639482 33.06254185 48.34624334 18.53997321 42.22072509\n",
            " 47.95859372 47.62854662 43.13765616 46.9868545  39.7762537  48.74666094\n",
            " 49.6752131  47.23703183 47.5585397  25.5540189  31.78006648 48.50478084\n",
            " 48.11602566 42.25148146 49.2113724  40.61681892 48.91341376 47.49102339\n",
            " 39.24177677 48.70859573 36.49142064 45.67078465 38.99205567 49.22449637\n",
            " 48.66154731 47.76111174 47.61843595 47.71777086 30.75277832 48.80838345\n",
            " 47.85537535 47.5651902  48.40554771 42.71683687 43.29019851 42.33182771\n",
            " 44.53369749 42.80114802 25.29327317 47.96282268 48.67320478 44.28453284\n",
            " 47.89955098 49.14802979 46.37874492 44.18032761 48.94842044 48.87163508\n",
            " 45.91401009 48.72054372 34.18272043 46.50066088 34.71920995 49.24993779\n",
            " 37.77368875 45.04240787 40.93484612 47.64535535 46.46422697 49.11894415\n",
            " 30.23901527 41.83264188 26.9931242  43.53664853 34.50812945 47.83679432\n",
            " 44.81695645 42.84131055 42.74136594 27.71988235 33.31959798 48.18572219\n",
            " 48.87381235 47.95188381 45.01473484 47.37956531 38.2290325  34.18272043\n",
            " 44.05016038 44.90612509 48.31297006 28.80162794 49.20842196 47.54910213\n",
            " 47.78562307 35.86602761 40.96591277 49.1466388  48.71526694 49.0755516\n",
            " 49.54915898 45.65671631 40.95367289 31.79296968 49.03233328 48.76209166\n",
            " 49.19883285 47.32778574 46.77056685 47.57755575 48.29361966 49.28182633\n",
            " 48.51084607 48.80273422 49.74192204 47.46719748 46.08040451 43.49066845\n",
            " 12.0931801  47.70178043 48.5477217  47.65336647 49.06008624 32.71222616\n",
            " 46.50540755 34.03589473 42.30712608 45.60109571 37.08123528 49.45534644\n",
            " 34.50812945 41.29675485 49.51952598 47.10383307 47.6829392  46.9962288\n",
            " 34.50812945 48.25499206 46.77425586 43.18599006 49.72669183 49.18427189\n",
            " 44.02867957 42.55121373 49.22249617 42.19968316 48.10994084 41.16237638\n",
            " 46.52668311 39.4947421  39.82446472 41.9708345  48.26421431 46.39239429\n",
            " 42.56746469 48.99538869 49.00156233 23.85999075 42.37030084 35.63866111\n",
            " 46.50312112 48.99268425 47.41099462 48.743196   49.53914458 34.50812945\n",
            " 45.9119543  21.69212024 38.11712599 44.42172166 49.03994538 43.42462111\n",
            " 48.72669759 46.27816887 30.75919958 48.00466625 48.64442734 43.00652425\n",
            " 45.70622281 46.37676503 49.46996453 45.32041672 48.76578884 47.14221358\n",
            " 44.50654745 39.1742324  42.75786688 47.76986821 47.57107752 36.43002965\n",
            " 49.50607909 47.8188896  42.9564336  33.75866363 45.52256132 47.53617681\n",
            " 46.39239429 39.91515828 47.39497913 48.03891046 44.30495812 48.73938901\n",
            " 47.87837683 49.439238   45.01948261 39.08763246 46.30578271 47.23720931\n",
            " 48.42901949 31.77383651 45.75472088 48.29258058 41.93898977 47.74792695\n",
            " 40.91327899 48.96503857 38.72965398 49.13666337 44.36905636 46.90125321\n",
            " 47.12344851 49.19756333 46.35459665 49.42361053 43.92574986 49.48508954\n",
            " 45.95324633 44.95155482 42.47517602 43.91146788 48.63187847 44.76418588\n",
            " 47.24045129 48.6305615  42.49231253 49.57495592 43.56026146 49.51179946\n",
            " 39.89383823 46.29598976 48.06924009 47.28088625 32.90961608 45.50421856\n",
            " 44.82442032 43.80464895 35.52341951 48.34251321 48.1352807  47.61235473\n",
            " 30.67046743 46.38163468 47.67647194 37.03742242 49.0685483  31.78197989\n",
            " 48.38155023 38.2571336  49.62475984 48.20606224 44.13060998 47.8303554\n",
            " 37.8206132  37.27191397 42.86701137 47.78648817 40.2576998  48.66638809\n",
            " 49.18594448 41.3968319  47.80463209 41.94165367 36.28769969 47.66858311\n",
            " 47.65957889 49.53750051 48.04530675 48.66627686 47.07013087 44.50167539\n",
            " 38.97814314 40.01034008 48.55222256 46.6002437  36.79998984 40.4202825\n",
            " 48.58843129 38.80370674 47.69359733 37.555509   48.80623483 45.69221449\n",
            " 33.07635547 49.59261142 45.95887188 48.44288819 49.61352268 47.14025579\n",
            " 49.45443758 49.26971261 23.46794604 44.79497792 49.3147601  46.40295616\n",
            " 47.55695395 45.42261446 49.11026091 38.71731575 31.2310189  34.50812945\n",
            " 47.82792267 48.73713805 48.07049014 34.50812945 34.50812945 44.97137006\n",
            " 48.32373438 49.27179716 48.74757505 33.54076596 44.58811576 35.09486271\n",
            " 49.34288717 48.74545401 37.52602256 48.23743844 46.6218388  45.36669577\n",
            " 45.5891407  47.18857207 37.26746272 47.29601991 46.24226359 41.12456671\n",
            " 45.57796627 39.38002468 46.02856148 48.02496103 45.14905463 48.9507337\n",
            " 48.07540093 42.40906578 48.02832066 48.31133991 47.33388834 46.8362139\n",
            " 44.45476942 40.79952141 42.21609587 49.57672476 23.11942196 49.38731754\n",
            " 49.21925877 49.18845301 49.51409935 49.24551478 48.66414131 29.18745874\n",
            " 31.8031247  45.96587832 49.7032417  49.03843493 49.142126   34.50812945\n",
            " 45.75598843 32.97399489 48.37263917 48.30182453 34.50812945 45.60458581\n",
            " 44.06855223 49.18153395 40.10990783 49.56829097 42.75414748 35.01263951\n",
            " 46.50442788 48.32292467 49.37418788 48.06443977 45.23111724 42.2743802\n",
            " 48.47698993 43.96830317 44.14786814 47.87921707 49.6107258  34.50812945\n",
            " 45.87413957 48.30387579 49.15647252 46.41786537 46.36481484 25.24195741\n",
            " 33.72102496 39.15021876 35.57526871 44.95705158 38.79754181 43.74111407\n",
            " 46.54779233 47.32634599 25.35109696 47.94935846 48.94666551 42.46458467\n",
            " 48.56059457 47.98876864 46.79389456 44.16864601 47.82002638 48.71164977\n",
            " 47.23912426 32.54177464 48.10994084 48.29884599 35.25716186 49.33722308\n",
            " 45.31276202 34.06292332 49.21673408 36.48794841 49.77925383 48.42421488\n",
            " 47.07640961 48.89246943 47.24851027 33.65434683 44.0650338  33.48859529\n",
            " 40.64539471 47.9427327  46.77870901 26.88996319 37.98105399 16.82029452\n",
            " 49.58413592 42.60958735 46.23855843 47.40462815 35.17502925 40.52200045\n",
            " 49.10353902 48.48582676 48.92177914 47.24826374 32.3115384  33.42073559\n",
            " 36.95730011 49.54898568 33.94773183 36.88473576 45.95021742 45.42890071\n",
            " 39.9532203  46.73261629 46.28702539 47.71492687 44.64361892 49.42598163\n",
            " 39.74047055 42.52136422 48.27013882 49.38325721 49.51097082 37.3422983\n",
            " 40.52364521 39.97467757 49.39967959 44.38150808 42.68586832 41.97488955\n",
            " 48.60033288 48.69681232 36.44234695 49.42110752 47.5147263  49.43920786\n",
            " 48.5989046  46.68221035 47.66136497 34.50812945 46.2622786  48.66162101\n",
            " 49.5712537  37.93551133 34.50812945 45.36384764 48.4283188  45.44610993\n",
            " 30.06741385 48.23743844 48.6171699  47.12099239 45.15608502 27.0365368\n",
            " 45.81912511 48.10176844 48.64442734 45.92395278 48.73765249 46.56478949\n",
            " 45.31327682 48.83482141 25.60446422 47.24920336 37.59209281 46.33900737\n",
            " 46.69243455 48.81823371 47.37443451 47.70336783 43.94368889 33.02137661\n",
            " 41.96256509 49.61364077 47.85393936 28.61154197 43.32442694 46.39696464\n",
            " 47.47144335 46.89895937 49.09117253 42.08922361 48.72044607 34.50812945\n",
            " 45.04920907 48.54302781 47.86639279 48.93890112 34.50812945 44.88098608\n",
            " 46.45286453 48.69770258 48.90329188 46.91814545 28.37915521 46.01477233\n",
            " 48.64092978 41.74069932 47.6508882  40.98457737 39.34936239 39.70184989\n",
            " 48.49188815 49.36800968 26.07632056 42.0148111  42.60448125 49.23860741\n",
            " 40.72548423 34.47994695 31.28541307 45.63084615 43.97812916 37.48673621\n",
            " 28.20473259 47.44429951 38.52173109 49.57401325 47.19514579 45.98648952\n",
            " 47.64703912 48.98511278 34.42772703 45.77342722 38.84527132 39.00741476\n",
            " 39.35096036 48.77320235 47.47349949 40.45729455 34.69235351 47.65883831\n",
            " 31.88770492 17.09126134 45.60098491 30.08252526 34.50812945 39.05235811\n",
            " 42.62623689 48.39471969 46.02490574 47.58814087 45.96161392 41.98667499\n",
            " 42.56417543 47.14268933]\n",
            "selection [ 69 432  25 318 749 889 254 322 481 664 614 471 707 362 716 333 818 266\n",
            " 132 860 184 747 386 809  75] (25,) [11.51952875 12.0931801  13.90625569 16.40275211 16.82029452 17.09126134\n",
            " 17.41202644 18.53997321 21.69212024 23.11942196 23.46794604 23.85999075\n",
            " 25.24195741 25.29327317 25.35109696 25.5540189  25.60446422 25.68172952\n",
            " 25.98040214 26.07632056 26.8806234  26.88996319 26.9931242  27.0365368\n",
            " 27.07910865]\n",
            "trainset before adding uncertain samples (400, 10) (400,)\n",
            "trainset after adding uncertain samples (425, 10) (425,)\n",
            "updated train set: (425, 10) (425,) unique(labels): [209 216] [0 1]\n",
            "val set: (877, 10) (877,)\n",
            "\n",
            "Train set: (425, 10)\n",
            "Validation set: (877, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 17\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.270 s \n",
            "\n",
            "Accuracy rate is 81.336406 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.89      0.88       321\n",
            "           1       0.65      0.60      0.63       113\n",
            "\n",
            "    accuracy                           0.81       434\n",
            "   macro avg       0.76      0.74      0.75       434\n",
            "weighted avg       0.81      0.81      0.81       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[285  36]\n",
            " [ 45  68]]\n",
            "--------------------------------\n",
            "val predicted: (877,) [1 1 0 1 0 1 1 0 0 0 1 1 1 0 1 0 1 0 0 1 1 1 0 1 1 1 0 0 1 0 0 0 1 0 1 0 0\n",
            " 0 1 1 0 1 1 1 1 0 0 0 1 1 1 1 0 1 0 1 1 0 0 1 1 1 1 1 0 1 1 0 1 1 0 0 0 1\n",
            " 0 1 1 1 1 0 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 1 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1\n",
            " 1 0 1 1 0 1 1 1 0 1 1 1 1 1 0 1 1 0 1 1 0 1 1 1 0 0 1 0 1 0 1 1 1 0 1 1 1\n",
            " 0 0 0 1 1 0 1 1 1 0 0 0 0 0 1 1 1 0 1 0 0 0 0 0 1 0 1 0 0 0 0 1 1 0 1 1 0\n",
            " 1 1 0 0 0 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 0 1 1 1 0 1 1 0 1 1 0 1 1 0 1 1\n",
            " 0 1 0 1 1 1 0 1 0 0 1 1 0 1 1 0 0 0 0 1 1 1 1 0 0 1 0 0 0 1 0 1 0 1 0 1 0\n",
            " 0 1 0 0 0 0 0 1 1 1 1 1 1 1 0 1 1 1 0 1 1 0 1 0 0 0 1 0 0 1 0 1 0 1 0 0 1\n",
            " 0 0 1 0 1 0 0 1 1 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 0 1 0 1\n",
            " 0 1 1 0 1 1 1 0 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0 0 0\n",
            " 1 1 0 0 1 0 0 1 0 0 1 0 0 0 1 0 0 1 1 1 1 0 1 0 1 1 1 0 1 0 1 0 1 1 0 0 0\n",
            " 0 0 1 1 1 1 1 1 0 0 0 1 1 1 0 1 0 0 0 0 0 1 1 0 0 0 0 1 1 0 0 1 0 1 0 0 1\n",
            " 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 0 0 1 0 1 1 0 1 0 1 1 0 1 0 0 0 1 0 1 0 1 0\n",
            " 1 1 0 1 1 0 1 1 0 1 1 1 0 1 1 0 1 1 1 1 1 0 0 0 1 0 1 1 1 1 1 1 1 1 1 0 0\n",
            " 0 0 1 0 0 0 1 0 1 1 0 1 1 1 1 1 0 0 0 1 0 0 1 0 0 1 0 1 1 1 1 1 0 0 0 1 0\n",
            " 1 1 0 1 1 1 0 1 1 0 1 1 0 1 0 0 1 1 0 1 1 1 1 1 0 0 1 1 0 0 1 1 1 1 0 1 1\n",
            " 0 1 0 0 1 1 1 0 1 1 0 1 1 0 1 0 1 0 1 0 0 0 1 0 1 1 0 0 0 0 0 1 0 1 0 1 0\n",
            " 0 1 1 1 0 1 0 0 1 0 1 0 1 1 1 1 0 0 0 0 1 0 1 1 1 0 1 1 0 0 1 0 1 0 0 0 0\n",
            " 0 1 0 1 1 0 1 0 1 0 0 1 0 1 1 1 0 0 0 1 1 0 0 1 1 0 1 0 1 0 0 1 0 1 0 0 0\n",
            " 1 0 0 0 1 0 1 1 1 0 1 0 0 1 0 0 0 0 0 1 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1\n",
            " 0 1 0 0 0 1 0 0 1 0 1 1 0 1 0 1 0 0 0 1 0 1 0 1 0 1 0 1 1 1 0 0 0 1 0 1 1\n",
            " 0 0 0 1 0 1 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 1 0 1 1 1 0 1\n",
            " 1 0 0 1 1 0 1 0 0 1 0 1 1 0 1 0 0 1 1 1 0 1 0 1 1 1 1 1 0 1 0 1 0 0 0 0 1\n",
            " 0 0 0 0 1 1 0 1 1 1 0 1 1 1 1 0 0 1 1 0 0 1 1 1 0 0]\n",
            "probabilities: (877, 2) \n",
            " [1 1 0 1 0 1 1 0 0 0 1 1 1 0 1 0 1 0 0 1 1 1 0 1 1 1 0 0 1 0 0 0 1 0 1 0 0\n",
            " 0 1 1 0 1 1 1 1 0 0 0 1 1 1 1 0 1 0 1 1 0 0 1 1 1 1 1 0 1 1 0 1 1 0 0 0 1\n",
            " 0 1 1 1 1 0 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 1 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1\n",
            " 1 0 1 1 0 1 1 1 0 1 1 1 1 1 0 1 1 0 1 1 0 1 1 1 0 0 1 0 1 0 1 1 1 0 1 1 1\n",
            " 0 0 0 1 1 0 1 1 1 0 0 0 0 0 1 1 1 0 1 0 0 0 0 0 1 0 1 0 0 0 0 1 1 0 1 1 0\n",
            " 1 1 0 0 0 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 0 1 1 1 0 1 1 0 1 1 0 1 1 0 1 1\n",
            " 0 1 0 1 1 1 0 1 0 0 1 1 0 1 1 0 0 0 0 1 1 1 1 0 0 1 0 0 0 1 0 1 0 1 0 1 0\n",
            " 0 1 0 0 0 0 0 1 1 1 1 1 1 1 0 1 1 1 0 1 1 0 1 0 0 0 1 0 0 1 0 1 0 1 0 0 1\n",
            " 0 0 1 0 1 0 0 1 1 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 0 1 0 1\n",
            " 0 1 1 0 1 1 1 0 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0 0 0\n",
            " 1 1 0 0 1 0 0 1 0 0 1 0 0 0 1 0 0 1 1 1 1 0 1 0 1 1 1 0 1 0 1 0 1 1 0 0 0\n",
            " 0 0 1 1 1 1 1 1 0 0 0 1 1 1 0 1 0 0 0 0 0 1 1 0 0 0 0 1 1 0 0 1 0 1 0 0 1\n",
            " 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 0 0 1 0 1 1 0 1 0 1 1 0 1 0 0 0 1 0 1 0 1 0\n",
            " 1 1 0 1 1 0 1 1 0 1 1 1 0 1 1 0 1 1 1 1 1 0 0 0 1 0 1 1 1 1 1 1 1 1 1 0 0\n",
            " 0 0 1 0 0 0 1 0 1 1 0 1 1 1 1 1 0 0 0 1 0 0 1 0 0 1 0 1 1 1 1 1 0 0 0 1 0\n",
            " 1 1 0 1 1 1 0 1 1 0 1 1 0 1 0 0 1 1 0 1 1 1 1 1 0 0 1 1 0 0 1 1 1 1 0 1 1\n",
            " 0 1 0 0 1 1 1 0 1 1 0 1 1 0 1 0 1 0 1 0 0 0 1 0 1 1 0 0 0 0 0 1 0 1 0 1 0\n",
            " 0 1 1 1 0 1 0 0 1 0 1 0 1 1 1 1 0 0 0 0 1 0 1 1 1 0 1 1 0 0 1 0 1 0 0 0 0\n",
            " 0 1 0 1 1 0 1 0 1 0 0 1 0 1 1 1 0 0 0 1 1 0 0 1 1 0 1 0 1 0 0 1 0 1 0 0 0\n",
            " 1 0 0 0 1 0 1 1 1 0 1 0 0 1 0 0 0 0 0 1 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1\n",
            " 0 1 0 0 0 1 0 0 1 0 1 1 0 1 0 1 0 0 0 1 0 1 0 1 0 1 0 1 1 1 0 0 0 1 0 1 1\n",
            " 0 0 0 1 0 1 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 1 0 1 1 1 0 1\n",
            " 1 0 0 1 1 0 1 0 0 1 0 1 1 0 1 0 0 1 1 1 0 1 0 1 1 1 1 1 0 1 0 1 0 0 0 0 1\n",
            " 0 0 0 0 1 1 0 1 1 1 0 1 1 1 1 0 0 1 1 0 0 1 1 1 0 0]\n",
            "std (877,) [43.3809959  45.73912302 44.62413284 41.94763184 44.94175513 48.59617556\n",
            " 38.77319577 41.91704322 30.04082631 49.25704205 48.99385303 48.72112786\n",
            " 41.36261274 48.8671396  46.36197812 34.61357597 33.16636882 47.01702482\n",
            " 44.35666591 47.86231278 39.30487287 48.39093121 34.61357597 48.14441194\n",
            " 48.03220776 39.85450929 36.94014804 47.57670517 45.43529163 49.81157741\n",
            " 49.59939921 33.64580893 44.60402706 31.18420399 45.52016389 37.30160014\n",
            " 48.68209554 42.0666652  45.00833894 35.57287116 40.95951123 44.60388397\n",
            " 45.18215029 42.83487216 49.10714412 48.08018818 28.17209294 47.54245619\n",
            " 48.06641477 35.39733908 47.50123611 47.02034113 46.23340605 48.21217867\n",
            " 40.63704372 35.84377504 48.49909893 47.1283011  49.23161252 46.78573945\n",
            " 47.61989126 46.40428013 35.22679773 48.53493749 48.8161231  48.33082634\n",
            " 44.46175894 49.57170364 48.23456667 39.91360676 42.45029397 28.0907204\n",
            " 48.48184951 47.38157953 48.72061425 44.80696067 46.16728312 46.59531036\n",
            " 47.38646576 45.90729463 47.99049409 47.95563556 45.37629487 35.10090829\n",
            " 45.12522029 47.54898082 48.7901912  49.3850855  49.08428815 49.48074716\n",
            " 32.99928861 47.07104589 49.3874034  48.63863386 47.23495779 32.85094316\n",
            " 35.03006684 47.13823458 47.5971577  37.14993584 49.49906103 49.40080585\n",
            " 44.04566464 46.00393352 49.36898271 47.23257995 34.61357597 47.60493828\n",
            " 38.56381648 49.14845462 47.08302366 40.7426606  49.11925793 36.91158305\n",
            " 30.20842484 49.17747191 48.0601009  42.9802217  38.52722324 37.47011628\n",
            " 39.02088209 46.43055579 44.48864895 41.31771671 46.99950857 41.32318717\n",
            " 49.12758253 47.46871067 44.40137436 49.13754705 40.9002154  49.24184465\n",
            " 45.67313968 46.24331873 48.37784279 42.44037006 44.86714741 45.90170359\n",
            " 49.2829869  48.04925983 43.52866444 47.30978732 46.58054433 42.15182929\n",
            " 39.65612789 46.29731621 40.54922524 43.19853884 49.61300629 49.64463666\n",
            " 34.61357597 45.72971648 42.09217143 37.35576814 46.7926603  42.8564037\n",
            " 48.07974738 48.7529108  47.94489489 46.07440573 41.98059192 41.1147593\n",
            " 41.37104973 47.47556088 44.18032738 46.95340791 46.71256132 48.13366846\n",
            " 45.51442063 49.63525879 48.13616872 49.64639338 48.12199996 47.51005572\n",
            " 44.92326483 48.35645856 49.58364559 34.61357597 49.05681247 47.53116957\n",
            " 41.08732818 46.30230443 48.76628959 44.98483691 49.18512054 45.07149216\n",
            " 48.63463874 45.07837249 49.79788116 43.68560289 48.65627663 48.94226829\n",
            " 48.68619158 44.28692498 49.60147272 30.89987063 46.30217626 47.66205022\n",
            " 40.3992636  48.24741296 40.12737144 49.25692238 49.00073892 48.23582102\n",
            " 48.97616978 48.17524468 47.98809316 44.69128817 48.18139437 46.51533165\n",
            " 47.34770514 38.39817665 48.94344677 49.53115459 49.64777833 47.05068577\n",
            " 42.81590842 48.9935388  42.75529329 48.88287047 46.78951417 42.33608983\n",
            " 40.39990528 49.4697942  32.03279453 46.67790482 37.69818551 47.59697132\n",
            " 36.48379784 38.98401804 49.38726006 48.72725566 47.62392143 39.71078207\n",
            " 47.49933693 46.27738299 48.12881146 46.1701122  38.92155906 45.36231023\n",
            " 32.1176884  46.06496679 46.88045386 46.71134089 48.94123582 46.29436035\n",
            " 49.53609044 49.00413844 34.61357597 44.11775428 49.29064987 44.51233887\n",
            " 46.54565919 47.57355929 48.93750099 33.07257483 46.90304077 41.66788875\n",
            " 42.15753767 41.12713497 46.16802395 49.81029761 49.04552785 49.11769207\n",
            " 46.46730661 43.64803408 48.76097767 45.79206285 48.41006832 47.03090189\n",
            " 39.56984974 43.74448349 49.27945205 34.61357597 28.58233007 48.95081795\n",
            " 46.82950253 49.57170364 48.28371747 48.37046594 44.87075329 40.03166175\n",
            " 49.52673104 46.85987863 39.7044417  45.14501244 46.65847679 49.73553106\n",
            " 49.67659838 37.46072631 38.65795022 49.48023151 48.42263971 34.61357597\n",
            " 36.10416194 48.3362283  46.54178936 48.47424309 39.09589577 41.39781363\n",
            " 43.46014765 49.01704763 44.89531001 48.2396872  47.0337037  45.78435541\n",
            " 28.85163001 38.50604614 39.23538628 48.15226614 47.37442215 45.78624047\n",
            " 41.50319182 48.21835636 40.09007951 47.84114391 47.90347268 42.37695805\n",
            " 46.92800949 42.18450853 48.81931663 49.51324987 47.08707271 46.39894857\n",
            " 24.84065229 48.24252739 48.3598434  43.32373085 48.65327034 39.48166785\n",
            " 48.71483351 48.51193615 35.39273623 47.91082276 39.19361502 45.49838686\n",
            " 37.34948143 49.12042587 48.58973537 47.52401367 46.06277555 47.45658273\n",
            " 35.39867661 48.863818   48.19537694 47.40319039 48.42676799 41.64087315\n",
            " 38.99697209 42.9347106  37.7882245  42.50891903 48.15206334 48.28746761\n",
            " 44.30117939 48.10130322 48.92091663 46.0326543  45.55247542 47.44361098\n",
            " 48.79513356 46.91512927 48.52520269 36.32754873 47.26698901 33.29965277\n",
            " 49.31284654 34.46263943 45.88347196 40.38287314 48.42749869 47.33356695\n",
            " 49.18007307 34.10425443 39.99284874 41.51669281 34.61357597 47.78725289\n",
            " 46.38048713 46.62613609 43.81678529 25.1819594  32.51964049 48.66843025\n",
            " 49.20464254 45.89180549 39.75200308 47.69741066 38.70752943 36.32754873\n",
            " 46.51139631 42.37462097 47.59342418 27.49584785 49.22232944 47.13492083\n",
            " 47.61227754 26.71936736 40.50658277 49.07938229 48.44331309 49.32639777\n",
            " 49.44058034 45.72357044 44.72328939 42.10441666 49.16117991 48.66916631\n",
            " 49.64242866 47.27024085 47.02564702 46.89519316 48.31248394 48.87113094\n",
            " 48.57728211 49.22130828 49.82393261 47.35224554 45.03839819 44.47682255\n",
            " 47.86820221 48.31692651 46.98767931 49.11986922 38.12675011 43.73712965\n",
            " 41.83529588 42.39213438 44.82729008 39.27408708 49.03627632 34.61357597\n",
            " 32.38932297 49.57318299 47.19327673 48.48701846 46.56752172 34.61357597\n",
            " 48.25741684 46.00351418 42.89103045 49.42947683 48.05363872 45.05111488\n",
            " 41.75143756 49.18293524 41.61503007 47.47601309 41.64201508 46.1683139\n",
            " 42.49297016 36.81561032 43.39521854 48.34044886 47.1457024  40.6671661\n",
            " 49.24946785 48.91589625 41.81035842 35.49956455 47.44602983 48.9377403\n",
            " 46.88387147 48.59940941 49.51450355 34.61357597 43.87481967 37.9089116\n",
            " 43.5589266  48.75209137 41.96373496 48.93401945 43.94962836 39.15562249\n",
            " 48.06416179 48.45663254 42.02887876 46.06266242 44.70470951 49.50823422\n",
            " 47.10913371 49.02108753 47.15815412 45.70286769 38.96307371 39.23538628\n",
            " 46.11174789 46.55374842 40.70221898 49.47734498 48.20306961 42.45417859\n",
            " 29.32191359 44.25779933 47.21403365 47.1457024  40.87698148 45.65237917\n",
            " 48.57021158 44.83620801 48.5110814  48.26032349 49.69275837 46.63950189\n",
            " 39.62589261 46.57787233 48.15384385 47.74371562 32.66300523 43.56376555\n",
            " 47.39037996 42.39020004 47.9095126  40.8222686  48.34233849 43.08221739\n",
            " 48.89379591 46.73611658 45.1740031  46.16390984 48.67008638 43.29475634\n",
            " 49.12584558 44.93856333 49.38536553 46.7460821  45.15203188 43.38381919\n",
            " 45.28626588 48.69907825 44.54191662 46.7620513  48.52530741 41.22037238\n",
            " 49.5339217  42.79512218 49.47888052 44.69961665 43.77465948 48.04232041\n",
            " 47.66814777 40.89507791 45.86848466 43.94109346 44.82966327 33.91346866\n",
            " 48.86304622 48.4320952  48.10358705 36.92074234 46.01060363 48.05541864\n",
            " 42.21102183 48.74518521 33.19558737 48.27151717 34.43669809 49.4587238\n",
            " 48.56210917 43.46213413 47.69165788 31.88894953 42.03212769 43.21525831\n",
            " 49.00876353 40.18719485 48.54248089 49.17647869 43.06677983 47.98884457\n",
            " 45.90097379 35.64436453 47.93764007 45.74959464 49.31941678 47.88296183\n",
            " 48.48081468 47.75281721 44.5707691  38.29853202 39.66659635 48.39825804\n",
            " 47.2321336  35.69651773 38.35032629 49.06789541 38.00507995 48.10439763\n",
            " 41.53511784 48.61902597 42.81564225 35.63008175 49.3691017  47.03090189\n",
            " 48.59659723 49.69860929 47.28079383 49.42499089 48.73641604 46.4929693\n",
            " 49.3613567  46.40794784 44.1448452  45.2113379  48.97024476 35.89639458\n",
            " 39.22071725 34.61357597 47.40425619 48.56399412 47.35934448 34.61357597\n",
            " 34.61357597 39.76376518 48.93511317 49.25020113 48.25387457 33.30949985\n",
            " 45.77876593 31.74831284 49.25977776 48.86550004 23.08013238 47.361593\n",
            " 45.89372897 46.69726946 45.99743074 47.77659763 30.7797395  45.29699989\n",
            " 46.6451046  41.30482646 46.41571638 39.88212864 46.54795948 47.13588875\n",
            " 47.42812436 48.91951468 47.99321021 42.31955976 44.71367007 48.61885989\n",
            " 48.31713244 44.83275117 42.60272351 40.50082212 38.35007039 49.31750267\n",
            " 49.60838507 49.1687339  49.50373337 49.43699486 49.24221649 48.58659434\n",
            " 30.51860121 28.33131643 45.06199771 49.73276203 49.40121005 48.96899072\n",
            " 34.61357597 44.61115907 32.00291383 48.42756281 47.87452542 34.61357597\n",
            " 47.07298842 45.92639927 49.48642143 42.08267474 49.23639678 43.88494229\n",
            " 38.18250257 46.61192334 48.57133145 49.27139174 48.48398918 45.21559528\n",
            " 38.83688634 47.58687496 41.49718639 42.46963137 46.42381428 49.35388126\n",
            " 34.61357597 46.18520408 48.6447522  49.16642458 47.11365616 46.5105202\n",
            " 37.05747728 33.95591935 38.63122863 44.54624908 34.84140151 45.25877767\n",
            " 47.56665645 47.45637906 47.96873455 48.59239821 44.33444319 47.38500165\n",
            " 48.71395145 45.36161396 41.20088507 48.60882442 48.85726174 47.4648636\n",
            " 39.57773395 47.47601309 47.99411229 40.46105018 49.34137631 44.79699517\n",
            " 38.40144784 49.18812288 34.04168126 49.76379889 48.31467259 46.53190211\n",
            " 46.70764667 47.56551506 24.02090778 44.49402344 31.10754061 39.34808732\n",
            " 46.72701715 47.24653464 38.77227372 49.61266884 42.35727891 46.16160307\n",
            " 48.43345576 38.02812632 44.85351416 48.20143399 48.01342053 48.65502475\n",
            " 45.8891205  34.63183163 31.2516152  36.85803027 49.3614967  31.18745978\n",
            " 37.959901   45.93812479 42.85797457 44.1955438  46.25998136 46.44824733\n",
            " 46.1723489  44.25010121 49.46288873 41.27904904 43.0335467  47.16599197\n",
            " 49.05260557 49.63907503 35.84718024 39.53998242 38.65265916 49.48208784\n",
            " 44.06758371 43.2092304  40.27519734 48.41827299 48.86913314 28.86598098\n",
            " 49.47731943 46.57060204 49.24744591 48.04708042 42.5871774  48.37139235\n",
            " 34.61357597 46.84206177 48.35445003 49.66555126 36.85502223 34.61357597\n",
            " 45.81941257 47.33281292 43.78795764 33.16636882 47.361593   48.29348992\n",
            " 47.31357803 42.22085341 46.69030306 48.24741296 48.45663254 46.02318552\n",
            " 48.67520522 47.29860142 46.51544387 48.45124012 47.38169944 39.94389044\n",
            " 46.76788855 47.29448784 49.12321859 46.58138329 47.70293124 40.82889572\n",
            " 29.15927127 46.43035364 49.58218673 47.75946666 29.09497079 41.24393515\n",
            " 44.68175638 48.30350522 47.09972047 49.17679242 43.35600107 48.60319857\n",
            " 34.61357597 45.72672472 48.45718869 47.64514975 48.63614734 34.61357597\n",
            " 46.02286609 47.18593078 48.37166112 49.01248945 46.93579731 31.54576954\n",
            " 46.69027267 48.33117171 44.67877756 47.7546171  38.91643439 41.51948842\n",
            " 42.95595333 48.37235682 48.9446531  41.2515194  41.16346503 49.06983402\n",
            " 41.94259461 37.79281474 33.15266689 43.56877459 47.18928634 33.12082331\n",
            " 29.30386639 46.63673428 34.4440879  49.63845367 46.75347501 46.41666605\n",
            " 46.43216573 49.24877007 30.42572936 46.52889992 43.88777021 41.26517376\n",
            " 38.31255026 48.72548609 47.20855702 40.78962934 33.5429879  47.38006151\n",
            " 29.03734699 42.6222538  20.40520887 34.61357597 41.51143863 38.23760874\n",
            " 48.44452476 46.82083354 47.72942684 43.89977267 40.01391075 44.27527044\n",
            " 46.16080199]\n",
            "selection [866 622 722 324 381 397 393  71  46 655 274 306 767 864 808 804 846 492\n",
            "   8 114 854 654 628 195 724] (25,) [20.40520887 23.08013238 24.02090778 24.84065229 25.1819594  26.71936736\n",
            " 27.49584785 28.0907204  28.17209294 28.33131643 28.58233007 28.85163001\n",
            " 28.86598098 29.03734699 29.09497079 29.15927127 29.30386639 29.32191359\n",
            " 30.04082631 30.20842484 30.42572936 30.51860121 30.7797395  30.89987063\n",
            " 31.10754061]\n",
            "trainset before adding uncertain samples (425, 10) (425,)\n",
            "trainset after adding uncertain samples (450, 10) (450,)\n",
            "updated train set: (450, 10) (450,) unique(labels): [220 230] [0 1]\n",
            "val set: (852, 10) (852,)\n",
            "\n",
            "Train set: (450, 10)\n",
            "Validation set: (852, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 18\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.310 s \n",
            "\n",
            "Accuracy rate is 81.336406 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.89      0.88       321\n",
            "           1       0.65      0.60      0.63       113\n",
            "\n",
            "    accuracy                           0.81       434\n",
            "   macro avg       0.76      0.74      0.75       434\n",
            "weighted avg       0.81      0.81      0.81       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[285  36]\n",
            " [ 45  68]]\n",
            "--------------------------------\n",
            "val predicted: (852,) [1 1 0 1 0 1 1 0 0 1 1 1 0 1 0 1 0 0 1 1 1 0 1 1 1 0 0 1 0 0 0 1 0 1 0 0 0\n",
            " 1 1 0 1 1 1 1 0 0 1 1 1 1 0 1 0 1 1 0 0 1 1 1 1 1 0 1 1 0 1 1 0 0 1 0 1 1\n",
            " 1 1 0 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 1 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 1\n",
            " 0 1 1 1 0 1 1 1 1 1 0 1 1 0 1 1 0 1 1 1 0 0 1 0 1 0 1 1 1 0 1 1 1 0 0 0 1\n",
            " 1 0 1 1 1 0 0 0 0 0 1 1 1 0 1 0 0 0 0 0 1 0 1 0 0 0 0 1 1 0 1 1 0 1 1 0 0\n",
            " 0 0 1 0 1 1 1 1 1 1 1 0 0 1 1 1 0 1 1 1 0 1 1 0 1 1 0 1 1 0 1 1 0 1 0 1 1\n",
            " 1 0 1 0 0 1 1 0 1 1 0 0 0 0 1 1 1 1 0 0 1 0 0 0 1 0 1 0 1 0 1 0 0 1 0 0 0\n",
            " 0 0 1 1 1 1 1 1 1 0 1 1 0 1 1 0 1 0 0 0 1 0 0 1 0 1 0 1 0 0 1 0 0 1 0 1 0\n",
            " 0 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 0 1 1 0 1 1 1 0\n",
            " 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0 0 0 1 1 0 0 1 0 0 1\n",
            " 0 0 1 0 0 1 0 0 1 1 1 1 0 1 1 1 1 1 0 1 0 1 1 0 0 0 0 0 1 1 1 1 1 1 0 0 0\n",
            " 1 1 1 0 1 0 0 0 0 0 1 1 0 0 0 0 1 1 0 0 1 0 1 0 0 1 1 1 1 1 1 1 1 1 0 1 1\n",
            " 0 0 1 1 0 0 1 0 1 1 0 1 0 1 1 0 1 0 0 0 1 0 1 0 1 0 1 1 0 1 1 0 1 1 0 1 1\n",
            " 0 1 1 0 1 1 1 1 1 0 0 0 1 0 1 1 1 1 1 1 1 1 1 0 0 0 0 1 0 0 0 1 0 1 1 0 1\n",
            " 1 1 1 1 0 0 0 1 0 0 1 0 0 1 0 1 1 1 1 1 0 0 0 1 0 1 1 0 1 1 1 0 1 1 0 1 1\n",
            " 0 1 0 0 1 1 0 1 1 1 1 1 0 0 1 1 0 0 1 1 1 1 0 1 1 0 1 0 0 1 1 1 0 1 1 0 1\n",
            " 1 0 1 0 1 0 1 0 0 0 1 0 1 1 0 0 0 0 1 0 1 0 1 0 1 1 1 0 1 0 0 1 0 1 0 1 1\n",
            " 1 1 0 0 0 0 1 0 1 1 1 1 0 0 1 0 1 0 0 0 0 0 1 0 1 1 0 1 0 1 0 0 1 0 1 1 1\n",
            " 0 0 0 1 1 0 0 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 0 0 0 1 0 1 1 1 0 1 0 0 1 0 0\n",
            " 0 0 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 0 1 0 0 0 1 0 0 1 0 1 1 0 1 0 1 0 0\n",
            " 0 1 0 1 0 1 0 1 0 1 1 0 0 0 1 0 1 1 0 0 0 1 0 1 1 1 1 1 1 0 1 1 1 0 0 1 1\n",
            " 1 0 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 0 1 0 1 1 0 1 0 0 1 1 1 0\n",
            " 1 0 1 1 1 1 1 0 1 0 1 0 0 0 1 0 0 0 1 1 0 1 1 1 0 1 1 1 0 1 1 0 0 1 1 1 0\n",
            " 0]\n",
            "probabilities: (852, 2) \n",
            " [1 1 0 1 0 1 1 0 0 1 1 1 0 1 0 1 0 0 1 1 1 0 1 1 1 0 0 1 0 0 0 1 0 1 0 0 0\n",
            " 1 1 0 1 1 1 1 0 0 1 1 1 1 0 1 0 1 1 0 0 1 1 1 1 1 0 1 1 0 1 1 0 0 1 0 1 1\n",
            " 1 1 0 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 1 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 1\n",
            " 0 1 1 1 0 1 1 1 1 1 0 1 1 0 1 1 0 1 1 1 0 0 1 0 1 0 1 1 1 0 1 1 1 0 0 0 1\n",
            " 1 0 1 1 1 0 0 0 0 0 1 1 1 0 1 0 0 0 0 0 1 0 1 0 0 0 0 1 1 0 1 1 0 1 1 0 0\n",
            " 0 0 1 0 1 1 1 1 1 1 1 0 0 1 1 1 0 1 1 1 0 1 1 0 1 1 0 1 1 0 1 1 0 1 0 1 1\n",
            " 1 0 1 0 0 1 1 0 1 1 0 0 0 0 1 1 1 1 0 0 1 0 0 0 1 0 1 0 1 0 1 0 0 1 0 0 0\n",
            " 0 0 1 1 1 1 1 1 1 0 1 1 0 1 1 0 1 0 0 0 1 0 0 1 0 1 0 1 0 0 1 0 0 1 0 1 0\n",
            " 0 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 0 1 1 0 1 1 1 0\n",
            " 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0 0 0 1 1 0 0 1 0 0 1\n",
            " 0 0 1 0 0 1 0 0 1 1 1 1 0 1 1 1 1 1 0 1 0 1 1 0 0 0 0 0 1 1 1 1 1 1 0 0 0\n",
            " 1 1 1 0 1 0 0 0 0 0 1 1 0 0 0 0 1 1 0 0 1 0 1 0 0 1 1 1 1 1 1 1 1 1 0 1 1\n",
            " 0 0 1 1 0 0 1 0 1 1 0 1 0 1 1 0 1 0 0 0 1 0 1 0 1 0 1 1 0 1 1 0 1 1 0 1 1\n",
            " 0 1 1 0 1 1 1 1 1 0 0 0 1 0 1 1 1 1 1 1 1 1 1 0 0 0 0 1 0 0 0 1 0 1 1 0 1\n",
            " 1 1 1 1 0 0 0 1 0 0 1 0 0 1 0 1 1 1 1 1 0 0 0 1 0 1 1 0 1 1 1 0 1 1 0 1 1\n",
            " 0 1 0 0 1 1 0 1 1 1 1 1 0 0 1 1 0 0 1 1 1 1 0 1 1 0 1 0 0 1 1 1 0 1 1 0 1\n",
            " 1 0 1 0 1 0 1 0 0 0 1 0 1 1 0 0 0 0 1 0 1 0 1 0 1 1 1 0 1 0 0 1 0 1 0 1 1\n",
            " 1 1 0 0 0 0 1 0 1 1 1 1 0 0 1 0 1 0 0 0 0 0 1 0 1 1 0 1 0 1 0 0 1 0 1 1 1\n",
            " 0 0 0 1 1 0 0 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 0 0 0 1 0 1 1 1 0 1 0 0 1 0 0\n",
            " 0 0 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 0 1 0 0 0 1 0 0 1 0 1 1 0 1 0 1 0 0\n",
            " 0 1 0 1 0 1 0 1 0 1 1 0 0 0 1 0 1 1 0 0 0 1 0 1 1 1 1 1 1 0 1 1 1 0 0 1 1\n",
            " 1 0 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 0 1 0 1 1 0 1 0 0 1 1 1 0\n",
            " 1 0 1 1 1 1 1 0 1 0 1 0 0 0 1 0 0 0 1 1 0 1 1 1 0 1 1 1 0 1 1 0 0 1 1 1 0\n",
            " 0]\n",
            "std (852,) [43.7642602  46.05228573 40.29601223 40.94250682 45.41803397 48.2693769\n",
            " 39.10962881 39.72372939 49.22093879 48.8338817  48.77942186 40.43335822\n",
            " 49.17056717 44.32635937 33.81583496 34.97916054 44.22140467 46.80245096\n",
            " 48.75972554 34.8495665  47.8771067  33.81583496 48.20083866 47.8509501\n",
            " 42.55263376 35.15417019 47.39992948 46.58527788 49.67516335 49.34164036\n",
            " 32.40165323 43.77829377 29.22001568 44.20394465 38.83827702 48.85519748\n",
            " 43.19368907 45.61119375 31.0115564  34.31529144 45.55569807 45.37495487\n",
            " 42.33813099 48.48819509 47.59754695 48.67260714 48.07231126 37.05299764\n",
            " 48.06125505 47.01681447 46.42110718 47.77395755 37.47631161 29.76741163\n",
            " 48.37654772 46.71250624 48.89145472 46.76398    47.66020908 46.35267122\n",
            " 29.83632574 48.54963947 47.56506795 48.402325   44.45328382 49.5449579\n",
            " 48.57858894 39.49363788 34.21333795 48.18359083 47.50649363 48.23299957\n",
            " 44.82583666 45.08458862 47.0416819  47.97515541 43.5697222  48.21318131\n",
            " 49.07379458 45.7176548  37.51168894 44.8124313  46.61478717 48.44933128\n",
            " 49.36620755 48.56646504 49.35863339 39.49267991 46.35942635 49.54610837\n",
            " 48.91437182 46.48951759 32.98164324 35.73438996 44.72035175 47.06763293\n",
            " 35.06604826 49.5707744  49.081474   43.71740437 44.54615839 49.18988761\n",
            " 47.26586294 33.81583496 47.74219335 37.1054728  49.3455674  47.21774977\n",
            " 43.43936011 47.5105413  36.10877577 48.69817226 47.72519187 43.18513079\n",
            " 37.969809   29.26248861 43.8526264  47.4327677  45.2226954  41.54119432\n",
            " 46.77895736 38.70706194 48.69330186 47.27918101 44.60782927 48.97465627\n",
            " 43.38623975 48.7582767  44.43632117 45.45562327 46.95925291 42.43805219\n",
            " 44.97999779 44.19833057 48.73308743 47.99813926 44.5386805  47.54586725\n",
            " 46.81361289 42.58042131 37.89261359 47.4781372  41.69055766 43.55352498\n",
            " 49.39293723 49.18669222 33.81583496 46.4594664  43.21520051 39.89644964\n",
            " 47.07176446 44.14692361 47.1704559  48.63515649 47.14670797 46.32396109\n",
            " 44.9649028  41.92237004 41.37621347 47.36965178 45.7500161  47.21600524\n",
            " 47.55134885 47.43661186 46.10471792 49.00755875 46.43793813 49.47066822\n",
            " 48.44359479 47.03226423 47.02612966 48.74029368 49.5695465  33.81583496\n",
            " 49.07224385 47.31586588 39.20221015 44.89285007 48.64810733 44.89299131\n",
            " 49.30885838 44.67275186 48.1159255  43.7093911  49.72893414 43.08815892\n",
            " 49.2004306  49.23727828 48.50683434 44.39686967 49.60359404 47.45433372\n",
            " 47.88781077 43.16491    48.70705018 39.85005207 48.89535055 48.82866724\n",
            " 48.37119284 48.59072105 48.11426421 47.2759343  43.44883563 48.35239142\n",
            " 47.62974044 46.95346452 38.99210951 49.20542173 49.21252387 49.53165152\n",
            " 46.92621158 28.19871501 48.77050133 43.01115226 48.65454363 47.02660959\n",
            " 44.09298591 26.51195915 49.47982078 25.06831208 45.85922374 40.68450589\n",
            " 47.31632417 21.13235543 38.0401131  49.34993425 47.62072602 48.07703901\n",
            " 42.03146942 47.90293198 44.40142264 48.15857661 41.10628108 43.60505521\n",
            " 45.40518269 17.95331049 45.10776136 47.11359148 47.60866761 49.25104245\n",
            " 45.26936769 49.39797554 48.89835135 33.81583496 45.16605069 49.27126905\n",
            " 43.73936068 47.16019027 47.75540279 48.92065084 29.89849331 46.8035717\n",
            " 39.75552711 41.96849396 41.10574496 46.49332311 49.78039212 48.07463295\n",
            " 48.86132894 44.36036645 43.38856598 48.57622701 45.07507356 47.41868968\n",
            " 47.51981991 41.51494207 45.43531423 49.20815521 33.81583496 48.47268979\n",
            " 47.15104041 49.5449579  47.85648304 48.2416966  42.71694292 43.05423409\n",
            " 49.60840671 45.3902014  39.78258871 45.09879784 46.87423831 49.33401519\n",
            " 49.71301102 37.76030053 38.20008616 49.42235411 48.24492295 33.81583496\n",
            " 33.20616942 48.39638906 45.77655719 48.63789523 41.2626325  35.10500603\n",
            " 43.43571931 48.78099044 41.54706581 47.19367218 46.82519659 46.39444043\n",
            " 35.94867607 42.09620655 47.19506435 47.91653609 44.91214512 41.97874791\n",
            " 48.08240704 40.84411715 47.76206895 46.88410345 38.44918101 47.72662211\n",
            " 43.31572401 48.95167492 49.68342388 47.7997594  47.90074906 47.70318015\n",
            " 47.55513176 44.08186751 49.38227046 41.03014276 48.44836619 48.05325409\n",
            " 39.95175403 49.18517127 38.39570185 45.50355267 39.5814332  49.22903417\n",
            " 48.25226833 48.02072744 45.18460179 47.37397399 33.75975391 48.37936373\n",
            " 48.81718727 47.3690641  47.79071916 40.58027137 41.7738812  42.74990198\n",
            " 37.5174976  40.67627735 48.49810335 49.07711812 45.21928192 48.16150611\n",
            " 48.32761175 47.09989277 44.08607041 48.16024094 48.85292674 46.19514737\n",
            " 48.09362235 36.02558609 47.40051205 35.94537993 49.23574682 37.50523117\n",
            " 44.28725192 37.99485221 48.06915104 47.127163   48.89205052 35.1469668\n",
            " 39.98603721 42.48186535 33.81583496 47.84192404 40.45617288 43.35762834\n",
            " 43.21772089 17.12122567 48.40350091 49.1083525  46.76309336 40.5272755\n",
            " 47.86869247 38.32889129 36.02558609 47.94925445 40.63355525 47.20327565\n",
            " 49.0259727  45.17953086 47.42113022 41.92627342 48.67061789 49.07769721\n",
            " 48.97038586 49.52693177 45.01593829 41.28214466 41.75514507 48.48812728\n",
            " 48.77817159 49.48136327 46.09433098 46.17178274 47.4289233  48.15354636\n",
            " 48.32322238 47.79377843 49.04747264 49.80705627 44.54284416 44.87119052\n",
            " 44.99007521 48.15089344 48.79887929 47.95017111 48.44043706 39.58615083\n",
            " 44.03239651 41.1745353  44.91333166 44.67144248 33.57575899 49.10289218\n",
            " 33.81583496 24.19227005 49.49872707 46.14701428 48.7872884  41.9948532\n",
            " 33.81583496 48.61944833 42.66201976 43.65688517 49.43814688 48.38774983\n",
            " 45.01991514 42.15103886 49.12436561 42.66747462 47.47607791 42.10619161\n",
            " 46.65032232 43.27164658 39.99033297 41.54362771 48.2957496  47.63129734\n",
            " 34.65469461 48.86109114 48.8733237  40.40748801 29.4833748  47.72646593\n",
            " 48.68500466 45.43372764 49.07328107 49.40831904 33.81583496 43.94035909\n",
            " 33.51509694 44.47882094 48.98919352 39.18391438 48.30445128 44.75859359\n",
            " 34.84637284 46.92639428 48.35484386 42.7957337  46.98180964 45.60546045\n",
            " 49.50813241 47.46857305 49.3722377  47.05049212 45.96699636 39.91788356\n",
            " 42.09620655 44.07106835 46.63142876 41.12444367 49.50175568 48.02482182\n",
            " 42.97220063 44.01113091 46.65226192 47.63129734 43.18778831 45.22932591\n",
            " 48.83368966 45.23560358 48.6551795  48.82806325 49.69122049 46.72158901\n",
            " 37.48754357 44.74087502 48.16662158 47.98275843 31.90043719 44.65492167\n",
            " 48.06558177 43.70526655 47.89606223 43.56342586 48.76928044 40.95573324\n",
            " 48.75709259 45.08878361 47.11708259 46.82425103 48.76061952 39.26240693\n",
            " 49.29207921 45.47960839 49.64002435 46.1825637  45.83241445 44.55696268\n",
            " 44.87262734 48.85224477 43.90143114 46.99512754 48.49834059 42.79359964\n",
            " 49.35600022 45.02409535 49.15876622 43.67681995 44.50806527 47.18523576\n",
            " 46.15475116 38.60521711 45.04803164 40.80148645 43.65110902 35.0835535\n",
            " 48.83297957 48.58997436 48.06724667 38.66138338 45.46117865 47.3385211\n",
            " 35.34429245 48.8733419  32.10789004 48.18592203 37.15204713 48.61651381\n",
            " 48.69423292 43.18698452 48.34015601 23.68785739 39.66015891 44.16470543\n",
            " 49.02830645 41.32201252 49.03495931 49.20062196 43.83946621 47.31783615\n",
            " 44.70400375 36.51645859 48.7943699  40.99036603 49.44019771 47.82473952\n",
            " 48.27439752 47.40421329 44.36024733 31.99563362 41.41498187 48.96966812\n",
            " 47.56759549 38.09555674 38.10290461 49.00308124 40.17180977 47.9263812\n",
            " 42.06920021 47.95403379 45.90417942 31.33607168 49.3509931  47.51981991\n",
            " 47.83176523 49.49605484 47.82671407 49.53316645 49.31173551 46.84772036\n",
            " 49.38524865 46.16397379 44.01650428 45.58898513 48.8957644  39.54130396\n",
            " 34.84949741 33.81583496 47.08532928 48.53519841 47.45713783 33.81583496\n",
            " 33.81583496 38.98477137 49.21376266 48.79587582 48.84673485 33.43671947\n",
            " 47.70360928 37.84499497 49.13208349 48.35590891 48.21619916 45.39225575\n",
            " 47.2751815  45.0723111  47.83260801 47.36571959 46.13379108 40.36023636\n",
            " 45.00363785 31.75448587 46.89687823 47.32599675 45.89106816 48.72693797\n",
            " 46.32498454 42.86838529 40.50041017 48.25476157 47.99684068 45.79088994\n",
            " 41.84766249 36.17346674 30.82398882 49.33362028 49.31078058 49.2694195\n",
            " 49.15801206 49.27374639 49.29131011 48.72375749 44.55430188 49.77391676\n",
            " 49.24154875 49.16597147 33.81583496 45.88200611 26.46868667 48.57205573\n",
            " 47.5358197  33.81583496 45.69853309 45.07415393 49.48010054 38.78829214\n",
            " 49.28155157 38.98622239 35.65127714 44.05388682 48.46856479 49.00412577\n",
            " 48.00505732 47.31830466 39.03845062 47.60701803 41.93978089 41.87117556\n",
            " 47.11952487 49.29402042 33.81583496 46.84134721 48.51340761 49.0335563\n",
            " 47.21184591 46.24045062 38.97899021 38.28976669 38.96844928 41.69914629\n",
            " 35.97372399 43.30686235 47.96218419 47.0464331  48.73195379 48.0442165\n",
            " 43.87120485 47.84171597 48.07575033 46.24636582 34.11704331 47.93008153\n",
            " 49.00007022 47.57183387 39.22393889 47.47607791 48.22483436 40.55504681\n",
            " 48.97958045 47.15924561 37.80306949 48.64434705 37.07221216 49.65913697\n",
            " 46.37299977 46.9565225  46.60472323 47.51406209 45.19222423 39.5571414\n",
            " 47.55800578 46.84616431 39.14880556 49.48052626 41.34928466 45.59315948\n",
            " 47.46160592 38.13252563 44.26455822 48.42436221 47.75928067 48.56338901\n",
            " 46.70865689 33.23650557 31.61316364 38.27810879 49.59332402 26.95472836\n",
            " 39.5262579  46.93599986 41.43464769 43.2661776  47.30328447 46.7287446\n",
            " 47.06961856 44.01912427 49.27003109 44.22338335 39.48782436 47.16882691\n",
            " 49.07795619 49.27681834 41.70940776 38.05266813 35.97493566 49.41974877\n",
            " 43.01035473 43.6281958  41.37104675 48.7170297  48.94155875 49.61254738\n",
            " 47.65039745 47.7862104  48.79396731 43.52490821 48.19781688 33.81583496\n",
            " 46.16787118 48.95799086 49.63513148 29.99535419 33.81583496 45.43187924\n",
            " 47.59662884 45.01620071 34.97916054 48.21619916 48.1171467  47.45188122\n",
            " 43.29826468 46.31642162 48.70705018 48.35484386 46.32317976 48.75395139\n",
            " 47.2517675  45.13469397 48.92813732 48.53508108 38.10201104 45.67775779\n",
            " 46.80004895 49.27875104 45.55209233 47.99049687 42.86143991 45.08738654\n",
            " 49.58704525 47.23139058 42.71147842 45.73362124 48.47078441 47.87261957\n",
            " 49.00318261 42.19028017 48.34506592 33.81583496 47.05403179 48.55246618\n",
            " 48.07182681 48.75464263 33.81583496 46.21532171 47.22903042 45.48312958\n",
            " 48.90890167 47.35975542 35.0786698  46.76023898 48.65960383 40.78531288\n",
            " 47.6761842  42.64124695 42.79600841 42.59770445 48.49459469 48.9403103\n",
            " 41.95663701 42.42253637 49.02471316 43.38668046 41.43268633 32.21658916\n",
            " 45.47668989 46.9991777  37.79154207 48.64500049 33.15141564 49.54926382\n",
            " 47.83855155 45.25899942 45.7302848  48.92055685 46.09158113 44.69896764\n",
            " 38.22776603 41.22284169 48.21565284 47.51912152 38.57396126 36.74012417\n",
            " 47.34969838 43.11585957 33.81583496 39.8083297  38.48881037 47.74690904\n",
            " 48.11322592 46.61404958 45.40447014 41.93852585 46.04226517 47.18488807]\n",
            "selection [373 235 223 549 421 219 646 217 725 211  32 115 448  53  60 250 759 632\n",
            "  38 579 722 619 496 567 542] (25,) [17.12122567 17.95331049 21.13235543 23.68785739 24.19227005 25.06831208\n",
            " 26.46868667 26.51195915 26.95472836 28.19871501 29.22001568 29.26248861\n",
            " 29.4833748  29.76741163 29.83632574 29.89849331 29.99535419 30.82398882\n",
            " 31.0115564  31.33607168 31.61316364 31.75448587 31.90043719 31.99563362\n",
            " 32.10789004]\n",
            "trainset before adding uncertain samples (450, 10) (450,)\n",
            "trainset after adding uncertain samples (475, 10) (475,)\n",
            "updated train set: (475, 10) (475,) unique(labels): [234 241] [0 1]\n",
            "val set: (827, 10) (827,)\n",
            "\n",
            "Train set: (475, 10)\n",
            "Validation set: (827, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 19\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.313 s \n",
            "\n",
            "Accuracy rate is 80.184332 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.88      0.87       321\n",
            "           1       0.63      0.58      0.60       113\n",
            "\n",
            "    accuracy                           0.80       434\n",
            "   macro avg       0.74      0.73      0.73       434\n",
            "weighted avg       0.80      0.80      0.80       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[283  38]\n",
            " [ 48  65]]\n",
            "--------------------------------\n",
            "val predicted: (827,) [1 1 0 1 0 1 1 0 0 1 1 1 0 1 0 1 0 0 1 1 1 0 1 1 1 0 0 1 0 0 0 1 1 0 0 0 1\n",
            " 0 1 1 1 1 0 0 1 1 1 1 0 1 0 1 0 0 1 1 1 1 0 1 1 0 1 1 0 0 1 0 1 1 1 1 0 1\n",
            " 0 1 1 1 0 0 0 0 1 0 0 1 0 1 1 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 1 0 1 1 1\n",
            " 1 1 1 1 1 0 1 1 0 1 1 0 1 1 1 0 0 1 0 1 0 1 1 1 0 1 1 1 0 0 0 1 1 0 1 1 1\n",
            " 0 0 0 0 0 1 1 1 0 1 0 0 0 0 0 1 0 1 0 0 0 0 1 1 0 1 1 0 1 1 0 0 0 0 1 0 1\n",
            " 1 1 1 1 1 1 0 0 1 1 1 0 1 1 1 0 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 0 0 1 1 0 1\n",
            " 1 0 0 0 1 1 1 1 0 0 1 0 0 0 1 0 1 0 0 1 0 0 1 0 0 0 0 0 1 1 1 1 1 1 1 0 1\n",
            " 1 0 1 1 0 1 0 0 0 1 0 0 1 0 1 0 1 0 0 1 0 0 1 0 1 0 0 1 1 1 1 1 0 1 0 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 0 1 1 0 1 1 1 0 1 0 0 1 1 1 0 1 1 0 1\n",
            " 1 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0 0 0 1 1 0 0 1 0 0 1 0 0 1 0 1 0 0 1 1 1 1\n",
            " 0 1 1 1 1 1 0 1 0 1 1 0 0 0 0 0 1 1 1 1 1 1 0 0 0 1 1 1 0 1 0 0 0 0 0 1 1\n",
            " 0 0 0 1 1 0 0 1 0 1 0 0 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 1 1 0 1 0 1\n",
            " 1 0 1 0 0 0 1 0 1 0 1 0 1 1 0 1 1 0 1 1 0 1 1 0 1 1 0 1 1 1 1 1 0 0 0 1 0\n",
            " 1 1 1 1 1 1 1 1 0 0 0 0 1 0 0 0 1 0 1 1 0 1 1 1 1 1 0 0 0 1 0 0 1 0 0 1 0\n",
            " 1 1 1 1 1 0 0 0 1 1 1 0 1 1 1 1 1 0 1 1 0 1 0 0 1 1 0 1 1 1 1 1 0 1 1 0 0\n",
            " 1 1 1 1 0 1 0 1 0 0 1 1 1 0 1 1 0 1 1 0 1 0 1 0 1 0 0 0 1 0 1 1 0 0 0 0 1\n",
            " 0 1 0 1 0 1 1 1 1 0 0 1 0 1 0 1 1 1 1 0 0 0 1 0 1 1 1 1 0 0 1 0 1 0 0 0 0\n",
            " 1 0 1 1 0 1 0 1 0 0 1 0 1 1 1 0 0 0 1 1 0 0 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1\n",
            " 0 0 0 1 0 1 1 1 0 1 0 0 1 0 0 0 0 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 0 0\n",
            " 1 0 0 1 0 1 1 0 1 0 1 0 0 0 1 0 1 0 1 0 1 0 1 1 0 0 0 1 0 1 1 0 0 1 0 1 1\n",
            " 1 1 1 1 0 1 1 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 0\n",
            " 1 0 1 1 0 1 0 0 1 1 1 0 1 0 1 1 1 1 1 0 1 0 1 0 0 0 1 0 0 0 1 1 0 1 1 1 0\n",
            " 1 1 1 0 1 1 0 0 1 1 1 0 0]\n",
            "probabilities: (827, 2) \n",
            " [1 1 0 1 0 1 1 0 0 1 1 1 0 1 0 1 0 0 1 1 1 0 1 1 1 0 0 1 0 0 0 1 1 0 0 0 1\n",
            " 0 1 1 1 1 0 0 1 1 1 1 0 1 0 1 0 0 1 1 1 1 0 1 1 0 1 1 0 0 1 0 1 1 1 1 0 1\n",
            " 0 1 1 1 0 0 0 0 1 0 0 1 0 1 1 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 1 0 1 1 1\n",
            " 1 1 1 1 1 0 1 1 0 1 1 0 1 1 1 0 0 1 0 1 0 1 1 1 0 1 1 1 0 0 0 1 1 0 1 1 1\n",
            " 0 0 0 0 0 1 1 1 0 1 0 0 0 0 0 1 0 1 0 0 0 0 1 1 0 1 1 0 1 1 0 0 0 0 1 0 1\n",
            " 1 1 1 1 1 1 0 0 1 1 1 0 1 1 1 0 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 0 0 1 1 0 1\n",
            " 1 0 0 0 1 1 1 1 0 0 1 0 0 0 1 0 1 0 0 1 0 0 1 0 0 0 0 0 1 1 1 1 1 1 1 0 1\n",
            " 1 0 1 1 0 1 0 0 0 1 0 0 1 0 1 0 1 0 0 1 0 0 1 0 1 0 0 1 1 1 1 1 0 1 0 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 0 1 1 0 1 1 1 0 1 0 0 1 1 1 0 1 1 0 1\n",
            " 1 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0 0 0 1 1 0 0 1 0 0 1 0 0 1 0 1 0 0 1 1 1 1\n",
            " 0 1 1 1 1 1 0 1 0 1 1 0 0 0 0 0 1 1 1 1 1 1 0 0 0 1 1 1 0 1 0 0 0 0 0 1 1\n",
            " 0 0 0 1 1 0 0 1 0 1 0 0 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 1 1 0 1 0 1\n",
            " 1 0 1 0 0 0 1 0 1 0 1 0 1 1 0 1 1 0 1 1 0 1 1 0 1 1 0 1 1 1 1 1 0 0 0 1 0\n",
            " 1 1 1 1 1 1 1 1 0 0 0 0 1 0 0 0 1 0 1 1 0 1 1 1 1 1 0 0 0 1 0 0 1 0 0 1 0\n",
            " 1 1 1 1 1 0 0 0 1 1 1 0 1 1 1 1 1 0 1 1 0 1 0 0 1 1 0 1 1 1 1 1 0 1 1 0 0\n",
            " 1 1 1 1 0 1 0 1 0 0 1 1 1 0 1 1 0 1 1 0 1 0 1 0 1 0 0 0 1 0 1 1 0 0 0 0 1\n",
            " 0 1 0 1 0 1 1 1 1 0 0 1 0 1 0 1 1 1 1 0 0 0 1 0 1 1 1 1 0 0 1 0 1 0 0 0 0\n",
            " 1 0 1 1 0 1 0 1 0 0 1 0 1 1 1 0 0 0 1 1 0 0 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1\n",
            " 0 0 0 1 0 1 1 1 0 1 0 0 1 0 0 0 0 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 0 0\n",
            " 1 0 0 1 0 1 1 0 1 0 1 0 0 0 1 0 1 0 1 0 1 0 1 1 0 0 0 1 0 1 1 0 0 1 0 1 1\n",
            " 1 1 1 1 0 1 1 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 0\n",
            " 1 0 1 1 0 1 0 0 1 1 1 0 1 0 1 1 1 1 1 0 1 0 1 0 0 0 1 0 0 0 1 1 0 1 1 1 0\n",
            " 1 1 1 0 1 1 0 0 1 1 1 0 0]\n",
            "std (827,) [41.93891853 45.42604138 33.87564408 39.17747143 42.72693274 48.09032521\n",
            " 37.11343134 38.89268498 49.46789829 48.77377311 48.66311686 40.82879227\n",
            " 48.09476051 44.79767859 33.92958827 25.82812203 44.01130989 46.43535809\n",
            " 48.01202286 32.99621963 48.43122469 33.92958827 47.88965277 47.90711116\n",
            " 43.05528129 40.68582233 47.96225476 46.0242556  49.49473033 49.67446897\n",
            " 25.15833233 44.23388845 43.8619176  38.88738921 48.79496462 42.15502594\n",
            " 45.10392924 40.82239626 44.55850625 45.36209169 40.48929685 48.24502106\n",
            " 44.2414643  48.07320878 47.8790163  36.49157165 47.86219133 46.04148655\n",
            " 45.61811912 47.67564103 38.52927037 48.02191855 47.12412775 49.10061582\n",
            " 44.35523582 46.67905563 44.85765314 48.39112419 48.75498768 47.49666407\n",
            " 42.15531234 48.92261639 47.78939103 41.23130452 31.30533358 48.46251077\n",
            " 47.16169288 47.9606232  43.84487773 46.50348043 46.39768353 47.54811303\n",
            " 43.65388907 47.78736158 48.80836522 43.94485031 32.39559586 46.14255985\n",
            " 47.54941603 48.02111184 49.1631821  48.67765289 49.15563015 33.17573332\n",
            " 46.51121631 49.40998174 48.79448659 46.4140677  36.02532612 33.4029125\n",
            " 45.29456693 47.45626734 32.87551108 49.28218917 49.23157591 40.89117378\n",
            " 47.08055471 48.53953188 46.87137718 33.92958827 47.68955283 31.54110799\n",
            " 49.31974284 47.16286917 41.26312605 48.7798372  35.53045416 48.5824279\n",
            " 47.10034477 40.97453506 37.93098344 41.97023874 46.70736367 44.01104581\n",
            " 42.82053055 46.47471412 40.20686863 48.28741567 46.13353833 39.89038554\n",
            " 48.9592309  42.42807395 48.41984915 44.56649831 43.05055427 47.61134217\n",
            " 43.87816627 44.86712279 41.86167735 49.03311901 47.33699229 41.89610502\n",
            " 46.38427582 46.8616657  42.03441881 41.24423601 45.04251181 41.83245908\n",
            " 41.90818573 49.02036133 49.08697659 33.92958827 45.85308102 42.58191238\n",
            " 39.76663562 45.92456586 44.89390515 48.07326325 48.30846568 47.41790555\n",
            " 44.4867534  43.32752187 41.59933783 42.00381415 47.15397881 45.26072706\n",
            " 43.27670024 47.31209698 47.26269224 46.00768842 49.31914628 44.93208679\n",
            " 49.27348412 47.98050325 43.99899524 45.87582111 49.06255207 49.64478295\n",
            " 33.92958827 48.87573694 46.41268755 36.87412943 45.58706032 48.21426807\n",
            " 44.03553422 48.97588797 41.88376182 48.73042349 42.21596196 49.74409068\n",
            " 43.63379216 48.09204093 49.14646484 47.55765099 43.43154835 49.21139909\n",
            " 45.26967121 47.22731995 41.64434357 47.25939343 39.39165031 48.94145015\n",
            " 48.12456636 48.12402655 48.57733861 46.38639694 45.50956321 43.52096126\n",
            " 48.12571457 46.60982421 47.48689585 38.23559307 48.80576109 49.01081482\n",
            " 49.5218695  46.75449599 48.59610964 40.70096234 47.26776922 44.9315167\n",
            " 44.61089475 49.32236299 45.63909447 36.03276271 46.58849293 40.02307609\n",
            " 49.25402802 47.39381235 46.85442745 40.23711449 47.49729578 43.74963692\n",
            " 48.05280931 41.27163158 44.8553286  44.22754398 46.80973549 47.07943901\n",
            " 45.67668009 48.76573803 43.69048439 49.42410527 48.9680752  33.92958827\n",
            " 47.72233291 49.02715781 44.53697731 45.40506763 47.08571882 48.42904932\n",
            " 45.84138752 39.3763903  44.8832729  39.67865969 43.73112655 49.70441822\n",
            " 47.95577624 48.15704146 44.25527073 41.30992728 48.22774147 45.39513162\n",
            " 46.62436515 46.84848877 41.56261836 44.00673642 49.15528341 33.92958827\n",
            " 48.27990658 46.7392865  48.92261639 48.22648888 47.94930998 43.970218\n",
            " 42.25271798 49.4422737  44.83159061 34.23004505 43.10524866 46.36510759\n",
            " 49.14360151 49.57121863 27.67457826 37.00088392 49.40889791 47.70504865\n",
            " 33.92958827 34.93484688 48.50898177 44.926135   48.74140353 42.34409586\n",
            " 39.8142566  43.01439871 47.92823038 43.23688084 46.84528577 46.57472073\n",
            " 45.45949019 34.03401303 40.45828971 46.72919184 46.99243114 42.3090353\n",
            " 40.68679477 48.05099815 40.13533372 47.11822439 47.26711302 37.25310056\n",
            " 47.32296343 42.7140057  48.46472387 49.5007431  46.9659648  47.94435393\n",
            " 47.27882466 47.64192939 44.98559814 49.16856896 40.32792647 48.20643805\n",
            " 47.73519133 38.97716276 48.83854983 40.55852363 44.50622639 38.44364333\n",
            " 48.88964253 47.65707329 47.93811747 45.23566804 47.54404767 33.0071818\n",
            " 48.26339453 47.84329259 46.81011624 47.79559987 44.40923288 41.48601373\n",
            " 42.75811648 40.05336629 41.00313367 47.77821937 49.08527027 45.68707232\n",
            " 47.33299632 49.06859892 44.05293381 43.29047367 48.35203043 48.902798\n",
            " 46.30588927 47.4763506  35.24179796 45.34502295 38.42460337 49.52592901\n",
            " 27.96959844 44.00241838 32.75901946 47.85093735 46.83380266 48.23811683\n",
            " 29.86422079 38.05864645 40.98028278 33.92958827 48.11978032 45.04582321\n",
            " 44.44280618 44.47183939 47.80229242 49.09562644 46.16375139 40.19460259\n",
            " 47.56939045 37.85249472 35.24179796 46.41437709 43.00296998 47.49373623\n",
            " 48.59251858 45.13625414 47.69095689 40.08479164 48.51847684 47.54203977\n",
            " 49.04727117 49.33106174 45.08573115 45.14518295 42.15853008 49.01583306\n",
            " 48.03461589 49.2620397  45.81010161 45.41756972 47.71018569 47.79215113\n",
            " 48.33866331 47.04070336 49.32140085 49.6353323  45.98269279 46.11108538\n",
            " 44.20031458 47.79931437 48.71395902 47.04199963 48.4684062  29.81769525\n",
            " 45.7391669  40.74252423 42.81387367 40.59494168 28.26257747 49.04320143\n",
            " 33.92958827 49.57018537 47.12731695 47.54152047 37.01330541 33.92958827\n",
            " 47.74784044 43.18548677 43.31396612 49.25422659 48.47071206 45.26739513\n",
            " 41.73638836 48.93467995 44.24350442 47.88523043 43.30036953 43.21265772\n",
            " 40.20684767 36.1751232  40.45604709 48.02582936 47.15924687 39.30190721\n",
            " 48.89947309 48.98683176 37.38719272 47.24593228 49.00232252 47.40630368\n",
            " 49.07579765 49.36057331 33.92958827 44.50698194 28.24846271 44.01001045\n",
            " 48.97510085 42.31763632 48.28157719 46.86807247 32.54280323 47.47272907\n",
            " 48.16366579 39.67641604 45.01525921 46.95613054 49.56097232 46.88654954\n",
            " 48.97767477 45.15998017 44.99614935 36.01631553 40.45828971 47.83669477\n",
            " 45.67931734 40.5921819  49.30528585 48.07940424 43.51263577 45.26245467\n",
            " 46.93876315 47.15924687 40.06673043 45.12531531 48.45222172 43.59982763\n",
            " 48.75451808 48.32269144 49.60526861 46.81711534 38.87225204 45.4207743\n",
            " 47.96295627 48.30148515 42.83958495 48.03175882 41.97216999 48.14951969\n",
            " 42.90673732 48.09178114 37.51965445 48.68751221 45.36644912 46.04512232\n",
            " 45.92841885 48.27944272 41.13127672 49.28747859 45.78633355 49.2594761\n",
            " 45.83978681 43.57505531 45.42308079 45.04563345 48.67459789 40.18775882\n",
            " 47.76237166 47.94015314 43.69989688 49.30495848 45.81442093 49.10031501\n",
            " 41.31887693 45.52911848 46.48692175 42.03913095 38.27863668 43.33228442\n",
            " 41.01384763 45.45124125 32.06318333 48.65387116 47.51759568 47.25542477\n",
            " 32.20661161 44.62218601 47.039629   29.9186391  48.94831848 48.25130892\n",
            " 39.08169915 49.19260451 47.83356334 42.87163731 47.47167036 40.71065938\n",
            " 42.69619851 46.73826414 40.72806373 48.70328384 49.1206752  37.93268469\n",
            " 48.06800283 43.36053926 34.93788719 48.05518913 43.06015343 49.39136328\n",
            " 47.74048803 48.38773689 46.56892297 43.28861425 39.68352325 48.75307605\n",
            " 46.65586577 35.50673973 36.82666375 48.94767755 33.25573224 47.75837237\n",
            " 42.99974209 49.02190993 44.82782418 49.55391135 46.84848877 48.86361851\n",
            " 48.97915006 47.20868108 48.87760008 49.24433254 40.39955852 49.21073118\n",
            " 44.75869313 44.48115855 46.56892363 48.91334787 37.17209535 33.85021261\n",
            " 33.92958827 47.49180235 48.86396162 47.41897037 33.92958827 33.92958827\n",
            " 29.34980705 48.9807504  48.57492655 48.83067046 32.5149593  46.33418258\n",
            " 39.19107495 48.76832989 48.11736903 48.13574756 46.70930117 46.49265144\n",
            " 40.36880943 48.41857868 46.21651129 46.29217505 38.42724599 45.38077475\n",
            " 46.74850254 47.30348289 43.74026679 48.16749259 46.99357521 42.44059954\n",
            " 35.40090174 48.58713324 47.90988332 45.80608531 43.05593602 36.71422833\n",
            " 49.28820038 48.9791111  48.8170594  49.29510874 49.21360008 49.03404952\n",
            " 47.977357   45.52157686 49.54879103 49.23681582 48.7833203  33.92958827\n",
            " 45.32389049 47.86188888 47.93390898 33.92958827 46.26611506 45.02582423\n",
            " 49.53949105 38.20128453 48.83606337 37.50627823 32.14005965 43.64504171\n",
            " 48.32758223 48.76755518 47.71014751 45.32018569 37.8914188  47.85877562\n",
            " 43.62724065 33.83381814 46.86819133 49.49244581 33.92958827 44.24826006\n",
            " 47.99065607 49.09143712 48.2129522  46.46200324 39.44621152 37.06562119\n",
            " 38.39238777 40.07686593 39.23093637 43.29993859 48.63443439 46.5094521\n",
            " 48.53313705 47.88650682 40.04498049 47.2883916  47.64808822 46.3322023\n",
            " 38.52539308 47.18311771 48.51907335 47.77156069 39.30232401 47.88523043\n",
            " 48.10111861 37.96319938 49.2328408  46.72564998 39.31812791 48.1411169\n",
            " 33.53926286 49.7798964  49.0021074  46.92352967 46.93441086 47.46128173\n",
            " 44.35594195 36.97515427 47.46682632 43.30675723 40.63826612 49.3541956\n",
            " 44.41591391 45.70032608 48.32502043 32.9781216  42.97005095 48.39204937\n",
            " 47.81302181 48.37939232 46.77393662 35.56058941 32.5117809  49.23036546\n",
            " 40.81533004 45.4667596  42.6647877  40.26228456 46.85064662 47.16599076\n",
            " 47.80789796 44.12365648 49.00755942 42.34267236 37.54933446 45.43183642\n",
            " 49.17731668 49.23711281 34.67771611 40.29114686 39.31509872 49.44569879\n",
            " 39.58197617 43.88243863 44.1049762  48.12136215 47.63796767 49.4801084\n",
            " 45.37473405 48.49586832 48.10124947 47.21512545 47.82627163 33.92958827\n",
            " 47.26745165 48.85641026 48.62422635 33.92958827 46.26479754 45.93294803\n",
            " 45.37015001 25.82812203 48.13574756 48.18350337 47.59660795 45.07164359\n",
            " 45.75847435 47.25939343 48.16366579 45.64209645 48.56569457 42.98528401\n",
            " 41.40789216 48.89400908 47.79896953 40.70452688 41.7470258  46.65759472\n",
            " 49.09140456 46.74496811 47.66011489 40.29817795 45.19087061 49.37565543\n",
            " 46.63659495 43.98201096 44.20240774 47.98034781 47.25509543 48.81295684\n",
            " 43.11347746 48.75397845 33.92958827 46.56758632 47.56503431 48.20353641\n",
            " 48.68547044 33.92958827 45.47119455 47.11711022 47.84493512 48.53795601\n",
            " 47.55875857 24.63617721 46.71531421 48.90667121 42.90356384 47.1750964\n",
            " 40.98061993 42.36033449 35.3540175  47.98137952 49.0114146  41.92160313\n",
            " 39.86942283 48.87372938 43.18465365 43.38154327 39.09370314 39.06570103\n",
            " 47.83010859 37.77611126 47.5203868  32.20879817 48.85916887 47.75481065\n",
            " 46.00080654 46.31148105 48.1957369  45.23113644 42.23859561 37.64897141\n",
            " 40.26717834 47.80857954 47.4028274  43.4399993  39.98529755 46.7521538\n",
            " 44.47864728 33.92958827 39.46534128 33.07604531 47.15035338 47.82475998\n",
            " 46.05616993 45.85252871 40.15769541 43.52454202 46.88067295]\n",
            "selection [781  30 739  15 272 348 442 406 582 401 354 525  64 101 518 634 522 801\n",
            "  76 700 586 448 350  92 693] (25,) [24.63617721 25.15833233 25.82812203 25.82812203 27.67457826 27.96959844\n",
            " 28.24846271 28.26257747 29.34980705 29.81769525 29.86422079 29.9186391\n",
            " 31.30533358 31.54110799 32.06318333 32.14005965 32.20661161 32.20879817\n",
            " 32.39559586 32.5117809  32.5149593  32.54280323 32.75901946 32.87551108\n",
            " 32.9781216 ]\n",
            "trainset before adding uncertain samples (475, 10) (475,)\n",
            "trainset after adding uncertain samples (500, 10) (500,)\n",
            "updated train set: (500, 10) (500,) unique(labels): [249 251] [0 1]\n",
            "val set: (802, 10) (802,)\n",
            "\n",
            "Train set: (500, 10)\n",
            "Validation set: (802, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 20\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.353 s \n",
            "\n",
            "Accuracy rate is 80.414747 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.88      0.87       321\n",
            "           1       0.64      0.58      0.60       113\n",
            "\n",
            "    accuracy                           0.80       434\n",
            "   macro avg       0.75      0.73      0.74       434\n",
            "weighted avg       0.80      0.80      0.80       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[284  37]\n",
            " [ 48  65]]\n",
            "--------------------------------\n",
            "final active learning accuracies [77.64976958525345, 77.88018433179722, 73.04147465437788, 74.19354838709677, 80.64516129032258, 80.18433179723502, 79.72350230414746, 80.87557603686636, 81.33640552995391, 80.87557603686636, 79.49308755760369, 80.18433179723502, 80.87557603686636, 80.87557603686636, 80.87557603686636, 80.87557603686636, 81.33640552995391, 81.33640552995391, 80.18433179723502, 80.4147465437788]\n",
            "saved /Users/wenxuanhuang/Documents/Repo/ML-for-COVID-19-dataset/Results/Active-learning-experiment-19.pkl /Users/wenxuanhuang/Documents/Repo/ML-for-COVID-19-dataset ['Decision_tree.ipynb', 'dec_git.png', 'Logit_default_f10.pdf', 'Logistic.ipynb', 'SVC.ipynb', 'RF_f5e50_featureimp.pdf', 'log_al.png', 'dec_git.pdf', '.DS_Store', 'log_git.png', 'svm_git.png', 'Logistic_Scikit.ipynb', 'knn_git.pdf', 'knn_git.png', 'rf_al.png', 'Best classifier_RF_f5e50.pdf', 'KNN.ipynb', 'GBDC.ipynb', 'rf_git.png', 'README.md', 'all_training.csv', 'Results', 'svm_al.png', 'Log_ROC.png', 'Logit_default_f7(p_removal).pdf', 'Active_learning.ipynb', 'Random_forest.ipynb', 'Model_select.ipynb', 'gdbc_git.png', '.git', '.vscode', 'Untitled', 'RF_f5e50_modelselect.pdf', 'Logit_default_f8(std_removal).pdf']\n",
            "\n",
            "---------------------------- FINISHED ---------------------------\n",
            "\n",
            "Count = 20, using model = GDBCModel, selection_function = MinStdSelection, k = 10, iteration = 0.\n",
            "\n",
            "initial random chosen samples (10,)\n",
            "initial train set: (10, 10) (10,) unique(labels): [5 5] [0 1]\n",
            "Val set: (1292, 10) (1292,) (10,)\n",
            "\n",
            "Train set: (10, 10)\n",
            "Validation set: (1292, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.679 s \n",
            "\n",
            "Accuracy rate is 73.732719 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.86      0.83       321\n",
            "           1       0.49      0.38      0.43       113\n",
            "\n",
            "    accuracy                           0.74       434\n",
            "   macro avg       0.65      0.62      0.63       434\n",
            "weighted avg       0.72      0.74      0.73       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[277  44]\n",
            " [ 70  43]]\n",
            "--------------------------------\n",
            "val predicted: (1292,) [0 1 1 ... 0 0 1]\n",
            "probabilities: (1292, 2) \n",
            " [0 1 1 ... 0 0 1]\n",
            "std (1292,) [32.12203547 49.81591451 28.15168998 ... 49.98831632 48.75244603\n",
            " 39.59726058]\n",
            "selection [1165  118  603 1262  772  479  687  607   70  431] (10,) [0.0173031  0.0173031  0.24266082 0.49884544 0.82706695 0.84391175\n",
            " 1.16846138 1.21652775 1.50789234 1.55378566]\n",
            "trainset before adding uncertain samples (10, 10) (10,)\n",
            "trainset after adding uncertain samples (20, 10) (20,)\n",
            "updated train set: (20, 10) (20,) unique(labels): [ 8 12] [0 1]\n",
            "val set: (1282, 10) (1282,)\n",
            "\n",
            "Train set: (20, 10)\n",
            "Validation set: (1282, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.820 s \n",
            "\n",
            "Accuracy rate is 77.188940 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.88      0.85       321\n",
            "           1       0.57      0.48      0.52       113\n",
            "\n",
            "    accuracy                           0.77       434\n",
            "   macro avg       0.70      0.68      0.69       434\n",
            "weighted avg       0.76      0.77      0.76       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[281  40]\n",
            " [ 59  54]]\n",
            "--------------------------------\n",
            "val predicted: (1282,) [1 1 1 ... 0 0 1]\n",
            "probabilities: (1282, 2) \n",
            " [1 1 1 ... 0 0 1]\n",
            "std (1282,) [33.65245125 49.00400046 49.9376036  ... 49.99909973 49.99357634\n",
            " 18.81700691]\n",
            "selection [ 157  983  772  535 1266  235 1199  360 1134  768] (10,) [0.12414595 0.24691621 0.77121197 0.79061484 0.83221583 0.93272075\n",
            " 1.40257535 1.53825424 1.58396881 2.1464656 ]\n",
            "trainset before adding uncertain samples (20, 10) (20,)\n",
            "trainset after adding uncertain samples (30, 10) (30,)\n",
            "updated train set: (30, 10) (30,) unique(labels): [13 17] [0 1]\n",
            "val set: (1272, 10) (1272,)\n",
            "\n",
            "Train set: (30, 10)\n",
            "Validation set: (1272, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 3\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.718 s \n",
            "\n",
            "Accuracy rate is 77.188940 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.89      0.85       321\n",
            "           1       0.59      0.42      0.49       113\n",
            "\n",
            "    accuracy                           0.77       434\n",
            "   macro avg       0.70      0.66      0.67       434\n",
            "weighted avg       0.76      0.77      0.76       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[287  34]\n",
            " [ 65  48]]\n",
            "--------------------------------\n",
            "val predicted: (1272,) [0 0 1 ... 0 0 0]\n",
            "probabilities: (1272, 2) \n",
            " [0 0 1 ... 0 0 0]\n",
            "std (1272,) [44.5432803  23.26804194 49.86660869 ... 49.99563589 49.65683247\n",
            " 12.41358141]\n",
            "selection [1241  774  790  730  716  303  609  155 1161  936] (10,) [0.0699992  0.27480427 0.73339379 0.93032199 1.10565527 1.1382482\n",
            " 1.25943712 1.46563175 1.47868843 1.522927  ]\n",
            "trainset before adding uncertain samples (30, 10) (30,)\n",
            "trainset after adding uncertain samples (40, 10) (40,)\n",
            "updated train set: (40, 10) (40,) unique(labels): [15 25] [0 1]\n",
            "val set: (1262, 10) (1262,)\n",
            "\n",
            "Train set: (40, 10)\n",
            "Validation set: (1262, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 4\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.690 s \n",
            "\n",
            "Accuracy rate is 76.728111 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.88      0.85       321\n",
            "           1       0.57      0.45      0.50       113\n",
            "\n",
            "    accuracy                           0.77       434\n",
            "   macro avg       0.69      0.66      0.68       434\n",
            "weighted avg       0.75      0.77      0.76       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[282  39]\n",
            " [ 62  51]]\n",
            "--------------------------------\n",
            "val predicted: (1262,) [0 0 1 ... 0 0 0]\n",
            "probabilities: (1262, 2) \n",
            " [0 0 1 ... 0 0 0]\n",
            "std (1262,) [42.0740773  14.2296298  49.93038135 ... 49.95233949 48.53030252\n",
            " 42.10455008]\n",
            "selection [ 940  607   78  982  358  268  911 1232  296  371] (10,) [0.04513863 0.13537732 0.26229745 0.51913096 0.69087948 0.69739134\n",
            " 0.84653613 0.96447213 1.09693658 1.10945206]\n",
            "trainset before adding uncertain samples (40, 10) (40,)\n",
            "trainset after adding uncertain samples (50, 10) (50,)\n",
            "updated train set: (50, 10) (50,) unique(labels): [18 32] [0 1]\n",
            "val set: (1252, 10) (1252,)\n",
            "\n",
            "Train set: (50, 10)\n",
            "Validation set: (1252, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 5\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.729 s \n",
            "\n",
            "Accuracy rate is 71.198157 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.76      0.80       321\n",
            "           1       0.46      0.58      0.51       113\n",
            "\n",
            "    accuracy                           0.71       434\n",
            "   macro avg       0.65      0.67      0.65       434\n",
            "weighted avg       0.74      0.71      0.72       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[244  77]\n",
            " [ 48  65]]\n",
            "--------------------------------\n",
            "val predicted: (1252,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1252, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "std (1252,) [39.00242226 45.87539522 49.96401981 ... 49.62376266 49.65150146\n",
            " 12.09635105]\n",
            "selection [1221  126  477  531  397  874  360  876 1040  234] (10,) [0.13446112 0.19377916 0.53271769 0.72485351 0.75514596 1.04981331\n",
            " 1.09065889 1.63979502 2.00347599 2.05115165]\n",
            "trainset before adding uncertain samples (50, 10) (50,)\n",
            "trainset after adding uncertain samples (60, 10) (60,)\n",
            "updated train set: (60, 10) (60,) unique(labels): [23 37] [0 1]\n",
            "val set: (1242, 10) (1242,)\n",
            "\n",
            "Train set: (60, 10)\n",
            "Validation set: (1242, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 6\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.754 s \n",
            "\n",
            "Accuracy rate is 76.497696 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.86      0.84       321\n",
            "           1       0.55      0.50      0.53       113\n",
            "\n",
            "    accuracy                           0.76       434\n",
            "   macro avg       0.69      0.68      0.69       434\n",
            "weighted avg       0.76      0.76      0.76       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[275  46]\n",
            " [ 56  57]]\n",
            "--------------------------------\n",
            "val predicted: (1242,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1242, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "std (1242,) [46.88793865 48.20866862 49.73071621 ... 49.54056752 49.53059012\n",
            " 32.79171126]\n",
            "selection [ 210 1029 1040 1077   16  949  752  604  847 1049] (10,) [0.05454458 0.36191667 0.45605405 0.56647058 0.62399629 0.68390143\n",
            " 0.75126966 1.10328437 1.12743251 1.15285969]\n",
            "trainset before adding uncertain samples (60, 10) (60,)\n",
            "trainset after adding uncertain samples (70, 10) (70,)\n",
            "updated train set: (70, 10) (70,) unique(labels): [30 40] [0 1]\n",
            "val set: (1232, 10) (1232,)\n",
            "\n",
            "Train set: (70, 10)\n",
            "Validation set: (1232, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 7\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.773 s \n",
            "\n",
            "Accuracy rate is 77.880184 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.89      0.86       321\n",
            "           1       0.60      0.45      0.52       113\n",
            "\n",
            "    accuracy                           0.78       434\n",
            "   macro avg       0.71      0.67      0.69       434\n",
            "weighted avg       0.76      0.78      0.77       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[287  34]\n",
            " [ 62  51]]\n",
            "--------------------------------\n",
            "val predicted: (1232,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1232, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "std (1232,) [47.33748027 48.39867206 48.76014857 ... 49.30338704 49.8194824\n",
            " 32.16012776]\n",
            "selection [ 855 1000 1125  638 1100  375 1015  131  163   65] (10,) [0.11741119 0.24183513 0.29036314 1.10775917 1.12581272 1.27701295\n",
            " 1.46296491 1.57525092 1.7075577  1.75706073]\n",
            "trainset before adding uncertain samples (70, 10) (70,)\n",
            "trainset after adding uncertain samples (80, 10) (80,)\n",
            "updated train set: (80, 10) (80,) unique(labels): [33 47] [0 1]\n",
            "val set: (1222, 10) (1222,)\n",
            "\n",
            "Train set: (80, 10)\n",
            "Validation set: (1222, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 8\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.812 s \n",
            "\n",
            "Accuracy rate is 78.110599 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86       321\n",
            "           1       0.59      0.51      0.55       113\n",
            "\n",
            "    accuracy                           0.78       434\n",
            "   macro avg       0.71      0.69      0.70       434\n",
            "weighted avg       0.77      0.78      0.78       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[281  40]\n",
            " [ 55  58]]\n",
            "--------------------------------\n",
            "val predicted: (1222,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1222, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "std (1222,) [47.99329849 49.08975903 47.43776562 ... 44.60145452 49.49483716\n",
            " 42.78374205]\n",
            "selection [1170  710  739 1181 1179 1034  982 1184  642  936] (10,) [0.52834667 0.56500124 0.59141276 0.63029993 0.70330633 0.84634894\n",
            " 0.90581072 1.22390246 1.40503006 1.52293417]\n",
            "trainset before adding uncertain samples (80, 10) (80,)\n",
            "trainset after adding uncertain samples (90, 10) (90,)\n",
            "updated train set: (90, 10) (90,) unique(labels): [37 53] [0 1]\n",
            "val set: (1212, 10) (1212,)\n",
            "\n",
            "Train set: (90, 10)\n",
            "Validation set: (1212, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 9\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.812 s \n",
            "\n",
            "Accuracy rate is 77.880184 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.88      0.85       321\n",
            "           1       0.59      0.50      0.54       113\n",
            "\n",
            "    accuracy                           0.78       434\n",
            "   macro avg       0.71      0.69      0.70       434\n",
            "weighted avg       0.77      0.78      0.77       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[282  39]\n",
            " [ 57  56]]\n",
            "--------------------------------\n",
            "val predicted: (1212,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1212, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "std (1212,) [47.32635371 48.0375172  46.6944185  ... 47.18694427 49.27818845\n",
            " 46.49856141]\n",
            "selection [1108  148  683  804 1045  892  637  199 1184  619] (10,) [0.01675757 0.07734099 0.1789759  0.8059516  1.00216166 1.031342\n",
            " 1.08503547 1.38353853 1.47382458 1.48002544]\n",
            "trainset before adding uncertain samples (90, 10) (90,)\n",
            "trainset after adding uncertain samples (100, 10) (100,)\n",
            "updated train set: (100, 10) (100,) unique(labels): [43 57] [0 1]\n",
            "val set: (1202, 10) (1202,)\n",
            "\n",
            "Train set: (100, 10)\n",
            "Validation set: (1202, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 10\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.809 s \n",
            "\n",
            "Accuracy rate is 77.880184 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.86      0.85       321\n",
            "           1       0.58      0.55      0.56       113\n",
            "\n",
            "    accuracy                           0.78       434\n",
            "   macro avg       0.71      0.70      0.71       434\n",
            "weighted avg       0.78      0.78      0.78       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[276  45]\n",
            " [ 51  62]]\n",
            "--------------------------------\n",
            "val predicted: (1202,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1202, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "std (1202,) [45.82363229 48.8716733  42.66564139 ... 35.91619613 49.26448956\n",
            " 47.19812735]\n",
            "selection [ 128  637 1123  638  431  499 1152  880   90  318] (10,) [0.05856612 0.081516   0.10403209 0.23705435 0.5933609  0.61256823\n",
            " 0.86206029 0.99457081 1.15476119 1.33498241]\n",
            "trainset before adding uncertain samples (100, 10) (100,)\n",
            "trainset after adding uncertain samples (110, 10) (110,)\n",
            "updated train set: (110, 10) (110,) unique(labels): [48 62] [0 1]\n",
            "val set: (1192, 10) (1192,)\n",
            "\n",
            "Train set: (110, 10)\n",
            "Validation set: (1192, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 11\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.827 s \n",
            "\n",
            "Accuracy rate is 79.032258 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86       321\n",
            "           1       0.61      0.52      0.56       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.73      0.70      0.71       434\n",
            "weighted avg       0.78      0.79      0.78       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[284  37]\n",
            " [ 54  59]]\n",
            "--------------------------------\n",
            "val predicted: (1192,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1192, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "std (1192,) [42.34272036 49.14613988 42.55205688 ... 20.68607625 48.86698191\n",
            " 45.09503674]\n",
            "selection [ 623 1071  288  442  480  819  169   93  122  492] (10,) [0.03872056 0.17034977 0.17034977 0.20303393 0.90202    1.22134017\n",
            " 1.40209528 1.5457672  1.61290175 1.75344881]\n",
            "trainset before adding uncertain samples (110, 10) (110,)\n",
            "trainset after adding uncertain samples (120, 10) (120,)\n",
            "updated train set: (120, 10) (120,) unique(labels): [52 68] [0 1]\n",
            "val set: (1182, 10) (1182,)\n",
            "\n",
            "Train set: (120, 10)\n",
            "Validation set: (1182, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 12\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.844 s \n",
            "\n",
            "Accuracy rate is 79.032258 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86       321\n",
            "           1       0.61      0.52      0.56       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.73      0.70      0.71       434\n",
            "weighted avg       0.78      0.79      0.78       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[284  37]\n",
            " [ 54  59]]\n",
            "--------------------------------\n",
            "val predicted: (1182,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1182, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "std (1182,) [39.36013614 48.99777528 46.55147018 ... 44.89086962 48.90678345\n",
            " 43.6585894 ]\n",
            "selection [726 554 775 279 429 951 287 448 558 968] (10,) [0.01740629 0.02037383 0.02864252 0.08729553 0.24667267 0.39964593\n",
            " 0.51315241 0.54801701 0.57065177 0.73804048]\n",
            "trainset before adding uncertain samples (120, 10) (120,)\n",
            "trainset after adding uncertain samples (130, 10) (130,)\n",
            "updated train set: (130, 10) (130,) unique(labels): [55 75] [0 1]\n",
            "val set: (1172, 10) (1172,)\n",
            "\n",
            "Train set: (130, 10)\n",
            "Validation set: (1172, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 13\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.876 s \n",
            "\n",
            "Accuracy rate is 79.723502 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.89      0.87       321\n",
            "           1       0.63      0.54      0.58       113\n",
            "\n",
            "    accuracy                           0.80       434\n",
            "   macro avg       0.74      0.71      0.72       434\n",
            "weighted avg       0.79      0.80      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[285  36]\n",
            " [ 52  61]]\n",
            "--------------------------------\n",
            "val predicted: (1172,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1172, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "std (1172,) [34.61561553 48.04551307 48.11464021 ... 41.40179421 49.32185962\n",
            " 41.67329663]\n",
            "selection [  99  111  884   63  861  265  935 1034  319 1127] (10,) [0.13109002 0.15922285 0.44894252 0.67147474 0.79817157 1.49374616\n",
            " 1.50774995 1.54926808 1.71377144 2.0147051 ]\n",
            "trainset before adding uncertain samples (130, 10) (130,)\n",
            "trainset after adding uncertain samples (140, 10) (140,)\n",
            "updated train set: (140, 10) (140,) unique(labels): [60 80] [0 1]\n",
            "val set: (1162, 10) (1162,)\n",
            "\n",
            "Train set: (140, 10)\n",
            "Validation set: (1162, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 14\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.878 s \n",
            "\n",
            "Accuracy rate is 78.571429 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86       321\n",
            "           1       0.60      0.52      0.56       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.72      0.70      0.71       434\n",
            "weighted avg       0.78      0.79      0.78       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[282  39]\n",
            " [ 54  59]]\n",
            "--------------------------------\n",
            "val predicted: (1162,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1162, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "std (1162,) [35.7065772  48.29191553 47.71477531 ... 45.61543095 49.04018438\n",
            " 43.15488232]\n",
            "selection [ 203   75  896  454  197  426 1035  205  527  803] (10,) [0.08690543 0.33245303 0.56749926 0.65407618 1.06104168 1.3596463\n",
            " 2.14557156 2.32929426 2.72661308 3.07534348]\n",
            "trainset before adding uncertain samples (140, 10) (140,)\n",
            "trainset after adding uncertain samples (150, 10) (150,)\n",
            "updated train set: (150, 10) (150,) unique(labels): [64 86] [0 1]\n",
            "val set: (1152, 10) (1152,)\n",
            "\n",
            "Train set: (150, 10)\n",
            "Validation set: (1152, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 15\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.903 s \n",
            "\n",
            "Accuracy rate is 79.262673 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.89      0.86       321\n",
            "           1       0.62      0.52      0.57       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.73      0.70      0.72       434\n",
            "weighted avg       0.78      0.79      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[285  36]\n",
            " [ 54  59]]\n",
            "--------------------------------\n",
            "val predicted: (1152,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1152, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "std (1152,) [33.66270391 48.1017005  46.71417109 ... 41.81437943 49.46874394\n",
            " 43.76006485]\n",
            "selection [  51  966  162  481 1144  348 1110  955  122  774] (10,) [0.16631833 0.17459073 0.52392612 0.68361885 0.91354601 1.00756304\n",
            " 1.30180503 1.95641476 1.97167402 2.1791291 ]\n",
            "trainset before adding uncertain samples (150, 10) (150,)\n",
            "trainset after adding uncertain samples (160, 10) (160,)\n",
            "updated train set: (160, 10) (160,) unique(labels): [68 92] [0 1]\n",
            "val set: (1142, 10) (1142,)\n",
            "\n",
            "Train set: (160, 10)\n",
            "Validation set: (1142, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 16\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.916 s \n",
            "\n",
            "Accuracy rate is 79.262673 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86       321\n",
            "           1       0.62      0.53      0.57       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.73      0.71      0.72       434\n",
            "weighted avg       0.78      0.79      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[284  37]\n",
            " [ 53  60]]\n",
            "--------------------------------\n",
            "val predicted: (1142,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1142, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "std (1142,) [33.9023499  46.73083481 47.11525595 ... 41.19339183 48.93001392\n",
            " 43.7940335 ]\n",
            "selection [ 833 1124  756  803  148  944 1030  948  752  823] (10,) [0.15737397 0.42585143 0.66264893 0.68032697 1.47048427 1.73417852\n",
            " 1.84476175 2.0202092  2.08722261 2.35610526]\n",
            "trainset before adding uncertain samples (160, 10) (160,)\n",
            "trainset after adding uncertain samples (170, 10) (170,)\n",
            "updated train set: (170, 10) (170,) unique(labels): [73 97] [0 1]\n",
            "val set: (1132, 10) (1132,)\n",
            "\n",
            "Train set: (170, 10)\n",
            "Validation set: (1132, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 17\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.921 s \n",
            "\n",
            "Accuracy rate is 75.345622 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.81      0.83       321\n",
            "           1       0.52      0.60      0.56       113\n",
            "\n",
            "    accuracy                           0.75       434\n",
            "   macro avg       0.69      0.70      0.69       434\n",
            "weighted avg       0.77      0.75      0.76       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[259  62]\n",
            " [ 45  68]]\n",
            "--------------------------------\n",
            "val predicted: (1132,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1132, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "std (1132,) [38.32289786 47.97128853 48.1630668  ... 39.62934894 47.77004865\n",
            " 46.8580357 ]\n",
            "selection [ 830  509   87 1004  684  588  659 1040  252  781] (10,) [0.05584959 0.14200903 0.37444746 0.47587434 1.07865194 1.20573939\n",
            " 1.82833623 1.84306022 2.28360016 2.66718164]\n",
            "trainset before adding uncertain samples (170, 10) (170,)\n",
            "trainset after adding uncertain samples (180, 10) (180,)\n",
            "updated train set: (180, 10) (180,) unique(labels): [ 77 103] [0 1]\n",
            "val set: (1122, 10) (1122,)\n",
            "\n",
            "Train set: (180, 10)\n",
            "Validation set: (1122, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 18\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.956 s \n",
            "\n",
            "Accuracy rate is 73.502304 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.79      0.81       321\n",
            "           1       0.49      0.59      0.54       113\n",
            "\n",
            "    accuracy                           0.74       434\n",
            "   macro avg       0.67      0.69      0.68       434\n",
            "weighted avg       0.75      0.74      0.74       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[252  69]\n",
            " [ 46  67]]\n",
            "--------------------------------\n",
            "val predicted: (1122,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1122, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "std (1122,) [31.99463451 48.81886925 47.07173705 ... 44.46538917 46.47037267\n",
            " 42.51987877]\n",
            "selection [156 266 960 644 896 517 288 696 745 617] (10,) [0.31619974 0.38029381 0.38029381 0.86146129 0.86393885 1.0826319\n",
            " 1.21527156 1.29944657 1.44152583 1.52253646]\n",
            "trainset before adding uncertain samples (180, 10) (180,)\n",
            "trainset after adding uncertain samples (190, 10) (190,)\n",
            "updated train set: (190, 10) (190,) unique(labels): [ 80 110] [0 1]\n",
            "val set: (1112, 10) (1112,)\n",
            "\n",
            "Train set: (190, 10)\n",
            "Validation set: (1112, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 19\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.119 s \n",
            "\n",
            "Accuracy rate is 74.423963 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.79      0.82       321\n",
            "           1       0.51      0.62      0.56       113\n",
            "\n",
            "    accuracy                           0.74       434\n",
            "   macro avg       0.68      0.70      0.69       434\n",
            "weighted avg       0.76      0.74      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[253  68]\n",
            " [ 43  70]]\n",
            "--------------------------------\n",
            "val predicted: (1112,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1112, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "std (1112,) [13.59019207 48.57727914 46.96985222 ... 44.83622828 46.65097892\n",
            " 43.25513495]\n",
            "selection [158 252 500 867 121 809 198 562 119 828] (10,) [0.80607072 0.99370051 1.27006256 1.35720205 1.41881976 1.79990768\n",
            " 2.81203623 3.22217207 3.36105434 3.82399263]\n",
            "trainset before adding uncertain samples (190, 10) (190,)\n",
            "trainset after adding uncertain samples (200, 10) (200,)\n",
            "updated train set: (200, 10) (200,) unique(labels): [ 85 115] [0 1]\n",
            "val set: (1102, 10) (1102,)\n",
            "\n",
            "Train set: (200, 10)\n",
            "Validation set: (1102, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 20\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.002 s \n",
            "\n",
            "Accuracy rate is 73.963134 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.79      0.82       321\n",
            "           1       0.50      0.61      0.55       113\n",
            "\n",
            "    accuracy                           0.74       434\n",
            "   macro avg       0.68      0.70      0.68       434\n",
            "weighted avg       0.76      0.74      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[252  69]\n",
            " [ 44  69]]\n",
            "--------------------------------\n",
            "val predicted: (1102,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1102, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "std (1102,) [ 9.58235422 49.22591712 47.2826553  ... 42.63244399 48.94134453\n",
            " 40.11347733]\n",
            "selection [910 659 827 468 841 706 419 788 137 308] (10,) [0.02547206 0.80143736 1.0603794  1.23657784 2.21095084 2.4574451\n",
            " 3.07092539 3.10965786 3.39505496 3.40767327]\n",
            "trainset before adding uncertain samples (200, 10) (200,)\n",
            "trainset after adding uncertain samples (210, 10) (210,)\n",
            "updated train set: (210, 10) (210,) unique(labels): [ 93 117] [0 1]\n",
            "val set: (1092, 10) (1092,)\n",
            "\n",
            "Train set: (210, 10)\n",
            "Validation set: (1092, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 21\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.982 s \n",
            "\n",
            "Accuracy rate is 74.193548 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.78      0.82       321\n",
            "           1       0.50      0.63      0.56       113\n",
            "\n",
            "    accuracy                           0.74       434\n",
            "   macro avg       0.68      0.71      0.69       434\n",
            "weighted avg       0.76      0.74      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[251  70]\n",
            " [ 42  71]]\n",
            "--------------------------------\n",
            "val predicted: (1092,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1092, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "std (1092,) [11.68364839 49.0588605  46.21341789 ... 44.75297471 48.63150422\n",
            " 43.67517419]\n",
            "selection [ 629    4  913  782   18  184 1088  488  289  190] (10,) [0.27363502 0.28054326 0.57871301 1.46054668 1.46054668 3.03215876\n",
            " 3.80228608 4.37721434 4.56007001 4.98693102]\n",
            "trainset before adding uncertain samples (210, 10) (210,)\n",
            "trainset after adding uncertain samples (220, 10) (220,)\n",
            "updated train set: (220, 10) (220,) unique(labels): [ 96 124] [0 1]\n",
            "val set: (1082, 10) (1082,)\n",
            "\n",
            "Train set: (220, 10)\n",
            "Validation set: (1082, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 22\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.999 s \n",
            "\n",
            "Accuracy rate is 73.963134 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.79      0.82       321\n",
            "           1       0.50      0.61      0.55       113\n",
            "\n",
            "    accuracy                           0.74       434\n",
            "   macro avg       0.68      0.70      0.68       434\n",
            "weighted avg       0.76      0.74      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[252  69]\n",
            " [ 44  69]]\n",
            "--------------------------------\n",
            "val predicted: (1082,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1082, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "std (1082,) [ 6.47465447 49.05685228 46.47623869 ... 44.02989657 48.71556279\n",
            " 38.11432148]\n",
            "selection [ 430   26   50  813    3 1044  778  721  550  748] (10,) [1.2071278  1.31502492 1.87747154 2.07978    2.84354096 4.36140937\n",
            " 4.49912071 4.54990511 5.00983959 5.68222287]\n",
            "trainset before adding uncertain samples (220, 10) (220,)\n",
            "trainset after adding uncertain samples (230, 10) (230,)\n",
            "updated train set: (230, 10) (230,) unique(labels): [105 125] [0 1]\n",
            "val set: (1072, 10) (1072,)\n",
            "\n",
            "Train set: (230, 10)\n",
            "Validation set: (1072, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 23\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.021 s \n",
            "\n",
            "Accuracy rate is 74.193548 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.79      0.82       321\n",
            "           1       0.50      0.61      0.55       113\n",
            "\n",
            "    accuracy                           0.74       434\n",
            "   macro avg       0.68      0.70      0.69       434\n",
            "weighted avg       0.76      0.74      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[253  68]\n",
            " [ 44  69]]\n",
            "--------------------------------\n",
            "val predicted: (1072,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1072, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "std (1072,) [ 9.98364461 48.98238743 45.93704438 ... 39.75329666 48.86026984\n",
            " 31.60032048]\n",
            "selection [ 145  341 1030  788   54  974  773  944  968  700] (10,) [0.61138852 0.84477002 1.92604579 2.17218779 2.35244828 4.89053656\n",
            " 5.12121339 5.74872321 7.24770355 7.82234443]\n",
            "trainset before adding uncertain samples (230, 10) (230,)\n",
            "trainset after adding uncertain samples (240, 10) (240,)\n",
            "updated train set: (240, 10) (240,) unique(labels): [110 130] [0 1]\n",
            "val set: (1062, 10) (1062,)\n",
            "\n",
            "Train set: (240, 10)\n",
            "Validation set: (1062, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 24\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.025 s \n",
            "\n",
            "Accuracy rate is 74.423963 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.79      0.82       321\n",
            "           1       0.51      0.63      0.56       113\n",
            "\n",
            "    accuracy                           0.74       434\n",
            "   macro avg       0.68      0.71      0.69       434\n",
            "weighted avg       0.77      0.74      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[252  69]\n",
            " [ 42  71]]\n",
            "--------------------------------\n",
            "val predicted: (1062,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1062, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "std (1062,) [ 6.61530166 48.69301091 46.18919039 ... 42.00383745 49.2739699\n",
            " 36.06020792]\n",
            "selection [ 493  533 1002   96  893   65   13  780  714  249] (10,) [0.53043025 2.4000725  2.82464856 3.41321847 4.18281337 4.48002095\n",
            " 4.82572414 5.38001954 5.85866485 6.55207841]\n",
            "trainset before adding uncertain samples (240, 10) (240,)\n",
            "trainset after adding uncertain samples (250, 10) (250,)\n",
            "updated train set: (250, 10) (250,) unique(labels): [114 136] [0 1]\n",
            "val set: (1052, 10) (1052,)\n",
            "\n",
            "Train set: (250, 10)\n",
            "Validation set: (1052, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 25\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.053 s \n",
            "\n",
            "Accuracy rate is 75.806452 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.81      0.83       321\n",
            "           1       0.53      0.61      0.57       113\n",
            "\n",
            "    accuracy                           0.76       434\n",
            "   macro avg       0.69      0.71      0.70       434\n",
            "weighted avg       0.77      0.76      0.76       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[260  61]\n",
            " [ 44  69]]\n",
            "--------------------------------\n",
            "val predicted: (1052,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1052, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "std (1052,) [ 3.48617367 48.7100125  46.66394327 ... 42.89710138 48.92622715\n",
            " 33.79908646]\n",
            "selection [ 775   21 1018    0  616  345  972  118  200  371] (10,) [1.10983097 2.25980933 2.33959695 3.48617367 5.45956341 5.97395296\n",
            " 6.49056353 6.69210609 7.84633078 8.50907141]\n",
            "trainset before adding uncertain samples (250, 10) (250,)\n",
            "trainset after adding uncertain samples (260, 10) (260,)\n",
            "updated train set: (260, 10) (260,) unique(labels): [119 141] [0 1]\n",
            "val set: (1042, 10) (1042,)\n",
            "\n",
            "Train set: (260, 10)\n",
            "Validation set: (1042, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 26\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.047 s \n",
            "\n",
            "Accuracy rate is 75.806452 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.80      0.83       321\n",
            "           1       0.53      0.65      0.58       113\n",
            "\n",
            "    accuracy                           0.76       434\n",
            "   macro avg       0.70      0.72      0.71       434\n",
            "weighted avg       0.78      0.76      0.77       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[256  65]\n",
            " [ 40  73]]\n",
            "--------------------------------\n",
            "val predicted: (1042,) [1 1 1 ... 0 0 0]\n",
            "probabilities: (1042, 2) \n",
            " [1 1 1 ... 0 0 0]\n",
            "std (1042,) [47.96202118 46.33220358 32.43377994 ... 38.75360094 49.04584332\n",
            " 30.51280964]\n",
            "selection [343  21 708 193  22  10 778 530 838 367] (10,) [0.08703123 0.24563258 1.93293082 2.33527323 2.3512496  4.71946748\n",
            " 6.95771699 7.76161011 8.08206673 8.09893378]\n",
            "trainset before adding uncertain samples (260, 10) (260,)\n",
            "trainset after adding uncertain samples (270, 10) (270,)\n",
            "updated train set: (270, 10) (270,) unique(labels): [124 146] [0 1]\n",
            "val set: (1032, 10) (1032,)\n",
            "\n",
            "Train set: (270, 10)\n",
            "Validation set: (1032, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 27\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.076 s \n",
            "\n",
            "Accuracy rate is 74.884793 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.79      0.82       321\n",
            "           1       0.51      0.63      0.57       113\n",
            "\n",
            "    accuracy                           0.75       434\n",
            "   macro avg       0.69      0.71      0.69       434\n",
            "weighted avg       0.77      0.75      0.76       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[254  67]\n",
            " [ 42  71]]\n",
            "--------------------------------\n",
            "val predicted: (1032,) [1 1 1 ... 0 0 0]\n",
            "probabilities: (1032, 2) \n",
            " [1 1 1 ... 0 0 0]\n",
            "std (1032,) [48.06794759 47.6035008  37.66664813 ... 41.61241526 48.57486972\n",
            " 26.04101531]\n",
            "selection [ 96   3 386 286 314 351 906  68 938 787] (10,) [2.24087835 2.74745658 2.85388373 2.94613211 4.06140604 5.14774676\n",
            " 5.62709465 5.76136673 5.96080391 7.95161853]\n",
            "trainset before adding uncertain samples (270, 10) (270,)\n",
            "trainset after adding uncertain samples (280, 10) (280,)\n",
            "updated train set: (280, 10) (280,) unique(labels): [128 152] [0 1]\n",
            "val set: (1022, 10) (1022,)\n",
            "\n",
            "Train set: (280, 10)\n",
            "Validation set: (1022, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 28\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.078 s \n",
            "\n",
            "Accuracy rate is 74.654378 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.79      0.82       321\n",
            "           1       0.51      0.62      0.56       113\n",
            "\n",
            "    accuracy                           0.75       434\n",
            "   macro avg       0.68      0.71      0.69       434\n",
            "weighted avg       0.77      0.75      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[254  67]\n",
            " [ 43  70]]\n",
            "--------------------------------\n",
            "val predicted: (1022,) [1 1 1 ... 0 0 0]\n",
            "probabilities: (1022, 2) \n",
            " [1 1 1 ... 0 0 0]\n",
            "std (1022,) [47.79434877 45.79387435 31.71060006 ... 42.23751691 48.51418713\n",
            " 30.53831779]\n",
            "selection [ 691  648  845  512  553 1006  663  855  230  701] (10,) [0.34075595 1.56831955 2.5626835  3.11403604 4.1252081  5.09914205\n",
            " 5.11047784 5.67452151 5.71674074 5.73671006]\n",
            "trainset before adding uncertain samples (280, 10) (280,)\n",
            "trainset after adding uncertain samples (290, 10) (290,)\n",
            "updated train set: (290, 10) (290,) unique(labels): [132 158] [0 1]\n",
            "val set: (1012, 10) (1012,)\n",
            "\n",
            "Train set: (290, 10)\n",
            "Validation set: (1012, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 29\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.080 s \n",
            "\n",
            "Accuracy rate is 74.654378 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.79      0.82       321\n",
            "           1       0.51      0.62      0.56       113\n",
            "\n",
            "    accuracy                           0.75       434\n",
            "   macro avg       0.68      0.71      0.69       434\n",
            "weighted avg       0.77      0.75      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[254  67]\n",
            " [ 43  70]]\n",
            "--------------------------------\n",
            "val predicted: (1012,) [1 1 1 ... 0 0 0]\n",
            "probabilities: (1012, 2) \n",
            " [1 1 1 ... 0 0 0]\n",
            "std (1012,) [46.64486307 47.08088973 31.4121811  ... 44.27766508 49.27763534\n",
            " 25.359367  ]\n",
            "selection [950 927 125 187 216 754 626 417 647 100] (10,) [ 0.9890677   2.52269148  3.88433961  4.09427343  6.62728607  8.68658814\n",
            "  9.06853182  9.14539781  9.75932044 10.55575678]\n",
            "trainset before adding uncertain samples (290, 10) (290,)\n",
            "trainset after adding uncertain samples (300, 10) (300,)\n",
            "updated train set: (300, 10) (300,) unique(labels): [140 160] [0 1]\n",
            "val set: (1002, 10) (1002,)\n",
            "\n",
            "Train set: (300, 10)\n",
            "Validation set: (1002, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 30\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.104 s \n",
            "\n",
            "Accuracy rate is 75.345622 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.79      0.82       321\n",
            "           1       0.52      0.66      0.58       113\n",
            "\n",
            "    accuracy                           0.75       434\n",
            "   macro avg       0.69      0.72      0.70       434\n",
            "weighted avg       0.78      0.75      0.76       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[252  69]\n",
            " [ 38  75]]\n",
            "--------------------------------\n",
            "val predicted: (1002,) [1 1 1 ... 0 0 0]\n",
            "probabilities: (1002, 2) \n",
            " [1 1 1 ... 0 0 0]\n",
            "std (1002,) [45.51902109 46.68176549 39.78754274 ... 42.41869878 49.4678636\n",
            " 32.67627089]\n",
            "selection [838 114 411 103 522 255 850  41  80 256] (10,) [ 3.18884398  3.63671852  4.35939076 10.01941911 10.4423792  11.11790672\n",
            " 11.1709962  12.24829903 15.43611785 16.0926414 ]\n",
            "trainset before adding uncertain samples (300, 10) (300,)\n",
            "trainset after adding uncertain samples (310, 10) (310,)\n",
            "updated train set: (310, 10) (310,) unique(labels): [146 164] [0 1]\n",
            "val set: (992, 10) (992,)\n",
            "\n",
            "Train set: (310, 10)\n",
            "Validation set: (992, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 31\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.109 s \n",
            "\n",
            "Accuracy rate is 75.806452 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.80      0.83       321\n",
            "           1       0.53      0.65      0.58       113\n",
            "\n",
            "    accuracy                           0.76       434\n",
            "   macro avg       0.70      0.72      0.71       434\n",
            "weighted avg       0.78      0.76      0.77       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[256  65]\n",
            " [ 40  73]]\n",
            "--------------------------------\n",
            "val predicted: (992,) [1 1 1 0 0 1 1 0 0 0 0 1 1 1 0 1 1 1 0 0 0 1 1 1 1 1 1 1 1 0 1 0 0 0 1 1 0\n",
            " 0 1 0 1 1 0 0 0 1 1 0 1 1 1 0 0 1 1 1 1 0 1 0 1 1 0 0 1 1 1 1 1 1 0 1 0 1\n",
            " 0 0 1 1 0 0 0 0 1 0 0 1 1 0 1 0 1 0 1 1 1 1 0 0 0 0 1 0 1 0 1 0 1 1 0 0 1\n",
            " 0 0 0 0 0 0 0 1 1 0 1 1 0 1 1 0 1 1 1 1 0 1 1 1 1 1 1 0 1 0 1 1 0 1 1 1 1\n",
            " 0 1 1 1 1 0 0 1 0 0 0 1 1 1 1 0 1 1 0 1 0 1 1 1 1 0 1 1 1 0 0 0 0 0 0 0 0\n",
            " 1 1 1 0 0 1 0 0 0 0 0 0 1 1 1 0 1 1 0 0 1 1 0 1 1 0 1 1 0 1 1 0 0 0 0 0 0\n",
            " 1 0 1 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 0 1 1 0 1 1 0 1 1 0 1 0 1 1 1 1 1 1\n",
            " 1 1 1 0 0 1 1 0 1 1 0 0 1 1 1 1 0 1 0 1 0 1 0 1 1 1 0 1 0 0 1 0 1 0 1 0 0\n",
            " 0 0 0 0 0 0 0 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 0 0 1 0 1 1 1 0 1\n",
            " 0 1 0 1 1 0 1 0 0 1 0 1 0 0 1 1 1 1 0 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 0 0 1 1 1 0 0 0 1 0 0 1 1 0 1 1 0 1 1 1 1 1 0 1 0 0 1 1 1 1 0 1 1 0 1 1 1\n",
            " 0 1 0 1 1 0 1 1 0 1 1 1 0 1 1 0 0 0 0 1 1 0 0 1 1 0 1 1 0 0 0 1 0 1 0 1 1\n",
            " 0 0 1 0 1 1 1 1 0 0 1 1 1 1 0 1 0 1 0 1 1 0 0 0 0 0 0 1 1 1 1 1 1 0 0 0 1\n",
            " 1 1 0 1 0 1 0 0 1 0 0 0 1 1 0 0 1 1 0 0 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1\n",
            " 1 1 0 1 1 0 0 1 0 0 1 0 0 1 1 1 1 1 1 1 1 0 1 0 1 0 0 0 0 1 0 1 0 1 0 1 1\n",
            " 0 1 1 0 1 1 0 0 1 1 1 1 0 1 1 1 0 1 1 1 0 0 0 1 0 1 1 1 1 0 1 1 1 0 1 0 0\n",
            " 0 0 1 0 1 1 0 0 0 1 0 1 0 1 1 1 0 1 1 0 1 1 0 1 0 0 0 1 0 0 1 0 0 1 0 1 1\n",
            " 1 1 1 1 0 0 0 1 0 1 1 1 1 0 1 1 1 0 1 1 0 1 0 1 0 0 1 1 0 1 1 1 1 0 1 1 0\n",
            " 1 1 1 0 1 0 0 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 0 1 0 1 1 0 1 0 1 1 1 0\n",
            " 0 0 1 1 0 0 0 1 0 0 0 1 0 0 1 1 0 1 0 0 0 1 1 1 0 1 0 1 1 1 1 1 1 1 0 0 0\n",
            " 0 1 0 1 1 0 1 1 0 0 1 1 1 0 0 0 1 0 1 0 0 1 0 1 0 0 1 0 0 1 0 1 1 1 0 0 0\n",
            " 1 1 1 0 0 1 0 1 0 1 1 0 1 0 1 0 1 1 0 0 0 0 1 1 0 0 1 0 1 1 1 1 0 1 0 1 0\n",
            " 0 0 0 1 0 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 0 0 1 0 0 1 1 1 0 1 1 1\n",
            " 0 1 0 0 0 0 0 1 0 0 1 1 0 1 0 1 1 1 0 0 0 1 1 0 1 1 1 0 0 1 1 0 1 1 0 1 1\n",
            " 1 0 1 1 0 0 1 1 1 0 1 0 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 0 1\n",
            " 1 1 0 1 0 1 1 0 0 0 0 1 0 1 1 0 1 0 1 0 1 0 1 1 1 1 1 0 0 1 0 0 0 1 0 0 0\n",
            " 1 0 1 0 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1 0 0 1 1 0 1 1 1 0 0 0]\n",
            "probabilities: (992, 2) \n",
            " [1 1 1 0 0 1 1 0 0 0 0 1 1 1 0 1 1 1 0 0 0 1 1 1 1 1 1 1 1 0 1 0 0 0 1 1 0\n",
            " 0 1 0 1 1 0 0 0 1 1 0 1 1 1 0 0 1 1 1 1 0 1 0 1 1 0 0 1 1 1 1 1 1 0 1 0 1\n",
            " 0 0 1 1 0 0 0 0 1 0 0 1 1 0 1 0 1 0 1 1 1 1 0 0 0 0 1 0 1 0 1 0 1 1 0 0 1\n",
            " 0 0 0 0 0 0 0 1 1 0 1 1 0 1 1 0 1 1 1 1 0 1 1 1 1 1 1 0 1 0 1 1 0 1 1 1 1\n",
            " 0 1 1 1 1 0 0 1 0 0 0 1 1 1 1 0 1 1 0 1 0 1 1 1 1 0 1 1 1 0 0 0 0 0 0 0 0\n",
            " 1 1 1 0 0 1 0 0 0 0 0 0 1 1 1 0 1 1 0 0 1 1 0 1 1 0 1 1 0 1 1 0 0 0 0 0 0\n",
            " 1 0 1 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 0 1 1 0 1 1 0 1 1 0 1 0 1 1 1 1 1 1\n",
            " 1 1 1 0 0 1 1 0 1 1 0 0 1 1 1 1 0 1 0 1 0 1 0 1 1 1 0 1 0 0 1 0 1 0 1 0 0\n",
            " 0 0 0 0 0 0 0 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 0 0 1 0 1 1 1 0 1\n",
            " 0 1 0 1 1 0 1 0 0 1 0 1 0 0 1 1 1 1 0 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 0 0 1 1 1 0 0 0 1 0 0 1 1 0 1 1 0 1 1 1 1 1 0 1 0 0 1 1 1 1 0 1 1 0 1 1 1\n",
            " 0 1 0 1 1 0 1 1 0 1 1 1 0 1 1 0 0 0 0 1 1 0 0 1 1 0 1 1 0 0 0 1 0 1 0 1 1\n",
            " 0 0 1 0 1 1 1 1 0 0 1 1 1 1 0 1 0 1 0 1 1 0 0 0 0 0 0 1 1 1 1 1 1 0 0 0 1\n",
            " 1 1 0 1 0 1 0 0 1 0 0 0 1 1 0 0 1 1 0 0 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1\n",
            " 1 1 0 1 1 0 0 1 0 0 1 0 0 1 1 1 1 1 1 1 1 0 1 0 1 0 0 0 0 1 0 1 0 1 0 1 1\n",
            " 0 1 1 0 1 1 0 0 1 1 1 1 0 1 1 1 0 1 1 1 0 0 0 1 0 1 1 1 1 0 1 1 1 0 1 0 0\n",
            " 0 0 1 0 1 1 0 0 0 1 0 1 0 1 1 1 0 1 1 0 1 1 0 1 0 0 0 1 0 0 1 0 0 1 0 1 1\n",
            " 1 1 1 1 0 0 0 1 0 1 1 1 1 0 1 1 1 0 1 1 0 1 0 1 0 0 1 1 0 1 1 1 1 0 1 1 0\n",
            " 1 1 1 0 1 0 0 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 0 1 0 1 1 0 1 0 1 1 1 0\n",
            " 0 0 1 1 0 0 0 1 0 0 0 1 0 0 1 1 0 1 0 0 0 1 1 1 0 1 0 1 1 1 1 1 1 1 0 0 0\n",
            " 0 1 0 1 1 0 1 1 0 0 1 1 1 0 0 0 1 0 1 0 0 1 0 1 0 0 1 0 0 1 0 1 1 1 0 0 0\n",
            " 1 1 1 0 0 1 0 1 0 1 1 0 1 0 1 0 1 1 0 0 0 0 1 1 0 0 1 0 1 1 1 1 0 1 0 1 0\n",
            " 0 0 0 1 0 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 0 0 1 0 0 1 1 1 0 1 1 1\n",
            " 0 1 0 0 0 0 0 1 0 0 1 1 0 1 0 1 1 1 0 0 0 1 1 0 1 1 1 0 0 1 1 0 1 1 0 1 1\n",
            " 1 0 1 1 0 0 1 1 1 0 1 0 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 0 1\n",
            " 1 1 0 1 0 1 1 0 0 0 0 1 0 1 1 0 1 0 1 0 1 0 1 1 1 1 1 0 0 1 0 0 0 1 0 0 0\n",
            " 1 0 1 0 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1 0 0 1 1 0 1 1 1 0 0 0]\n",
            "std (992,) [46.49249186 45.91624511 32.53442862 45.12067544 26.91373506 45.02831692\n",
            " 26.86383521 22.98155339 41.6491294  49.10876494 49.71272061 46.28148678\n",
            " 49.0362142  39.47050226 45.07804014 39.40798734 12.70980862 42.5165163\n",
            " 43.42450502 48.24396099 41.54693629 47.03228773 30.92961488 28.09696091\n",
            " 45.95250859 49.11668277 12.70980862 47.57255257 48.79352326 40.91907889\n",
            " 47.9431896  27.58222714 37.09379914 48.01630159 46.21513319 39.71655262\n",
            " 49.5709628  49.64847658 29.81119696 36.49039774 42.68506543 26.40577292\n",
            " 43.10703799 49.25301243 34.13197018 44.76361458 35.91893754 22.36710999\n",
            " 46.83822814 38.08588459 48.8540757  46.00821959 46.97399517 49.50187399\n",
            " 37.90555573 48.46742166 47.12599976 46.67487123 48.21958464 43.16522565\n",
            " 37.67999799 46.29221647 48.77596963 49.73682239 23.28700542 48.11780529\n",
            " 45.38663169 45.7682714  44.37374445 33.51231366 48.28519643 47.76285382\n",
            " 26.80125213 48.04744816 49.13040411 36.11632493 48.43149885 36.79822824\n",
            " 42.5406033  39.21560804 48.65126826 39.96168637 47.95881051 47.68537303\n",
            " 41.9571423  46.43595738 48.32436555 35.99746569 40.85711814 36.75447941\n",
            " 48.21957202 47.66528171 12.70980862 47.95208777 43.57000183 45.75209339\n",
            " 48.88672287 45.92632283 49.62011457 48.51871185 48.54019084 48.88442738\n",
            " 47.88668219 49.67382994 48.71772753  7.83474457 42.50508287 49.15525155\n",
            " 40.99666099 41.79019088 46.17500802 46.93932649 49.20453596 49.23656891\n",
            " 45.102932   49.04910835 47.8756009  35.09982667 12.70980862 47.67058489\n",
            " 49.65035683 48.06938555 45.17584147 49.71168324 34.17756172 36.83694218\n",
            " 47.3002121  48.92700159 39.93671883 37.57644173 25.7127907  37.6541448\n",
            " 34.5198244  40.71485766 43.56200161 40.5812971  47.80184356 22.54301831\n",
            " 33.46637986 47.89589865 39.43362085 48.02576206 47.80913461 43.01672772\n",
            " 42.17604962 12.70980862 49.2412152  42.75082839 48.63202163 47.79168293\n",
            " 35.56316949 48.37772863 47.26172658 45.20485316 34.18426911 46.43509443\n",
            " 43.50948269 48.67588014 34.17666058 44.60225525 47.74115164 46.33703123\n",
            " 40.84588115 45.37122911 36.3472211  43.70211318 49.58420607 44.98672834\n",
            " 49.47565103 12.70980862 45.09862997  7.8244233  40.55439998 32.33256615\n",
            " 44.32643314 47.08758162 45.91084804 42.75695005 47.68502451 40.5780965\n",
            " 25.39427904 46.17211537 39.46051026 47.60670335 30.67935488 46.63632771\n",
            " 47.77113228 46.48660884 44.17615048 40.29204003 42.78923993 44.64303919\n",
            " 16.18567325 40.71153596 49.04153987 46.33539848 49.25371445 30.17535454\n",
            " 48.39410686 34.78684975 44.48625392 37.18555344 23.02566521 48.38976926\n",
            " 49.60095408 12.70980862 46.50115363 49.24514656 47.19064292 40.82907416\n",
            " 47.38073552 48.21378886 42.15874514 47.08763134 38.20743911 48.84050645\n",
            " 34.53996995 24.93018274 30.7922126  49.60412023 39.0134066  44.56301838\n",
            " 49.25089137 47.86916937 41.25313181 40.08266363 44.3001071  41.58963162\n",
            " 42.55751439 46.25370943 48.90114593 48.3265785  46.92733713 48.085717\n",
            " 40.7171961  48.62872578 48.97513709 47.32852301 46.61465935 47.19295915\n",
            " 47.85341127 44.88000488 33.34869257 48.59959277 48.35480212 48.79461152\n",
            " 42.65723117 47.66165626 48.73682596 48.45937986 49.61301913 46.19837503\n",
            " 39.16779768 48.63256085 42.38560212 43.90530409 36.54372798 42.49806599\n",
            " 47.16237253 46.83548642 42.62830599 34.69477181 49.55811649 46.70263517\n",
            " 46.26204912 36.1151748  47.06110958 44.29989018 46.82482885 39.43229826\n",
            " 44.63132039 29.06725149 47.5578901  47.30593788 48.41139942 46.59203078\n",
            " 12.70980862 49.35346806 12.70980862 35.07023019 24.51699868 38.3195952\n",
            " 48.58306484 12.70980862 47.77344213 49.46241342 20.53615441 42.57956885\n",
            " 49.25425164 46.07143146 46.19760557 48.30131005 48.94146689 30.16780231\n",
            " 46.3475226  46.74394156 37.71194865 24.00065304 48.64802362 49.70263029\n",
            " 48.22159584 45.52148239 33.55925259 46.54335253 45.60136253 47.51839527\n",
            " 48.07364687 22.30573486 21.87798485 44.55174141 46.80233704 46.81743601\n",
            " 12.70980862 12.08513098 47.74986544 46.83993706 49.13040411 47.84839472\n",
            " 35.94416688 47.87929103 46.44871018 44.16694227 43.9098648  49.70001985\n",
            " 46.64450625 24.56102994 32.15271591 24.86537068 44.81262974 47.5176239\n",
            " 24.92438506 48.82149638 49.41055112 47.89885786 17.67891455 49.58875731\n",
            " 47.55086942 12.70980862 49.29674113 47.79952299 47.58596801 49.38388816\n",
            " 47.6388374  43.34525339 48.5045891  48.99232736 48.96012825 46.00550993\n",
            " 48.07976421 38.04079757 47.60043562 28.83641836 43.58543583 44.20979566\n",
            " 44.49534587 39.35778714 31.87510967 43.38896649 24.60833083 49.32564584\n",
            " 25.0002618  23.72143466 48.42953384 46.6218124  27.07076394 46.60236132\n",
            " 45.41054798 43.46216714 48.59660638 46.06834689 29.19179366 42.02418895\n",
            " 47.65794805 48.28409473 47.40848683 49.12939693 36.27379595 49.32951869\n",
            " 49.02743205 47.95870851 19.28622827 39.52456657 42.12479194 49.78117013\n",
            " 45.92369244 44.57732572 38.31520935 48.4805042  48.34796544 12.70980862\n",
            " 12.70980862 47.04990795 48.62377977 46.24794888 28.86205111 49.23411553\n",
            " 47.47754821 44.39749527 44.93531805 46.9659071  46.6855426  35.51335313\n",
            " 47.22861817 47.85817225 44.25209761 45.97160073 49.0311469  27.37825144\n",
            " 48.4409773  22.90072036 44.36263381 46.83323241 49.75382749 34.12925236\n",
            " 45.63783595 49.11800679 49.06354201 47.79452655 37.38287394 31.09812472\n",
            " 45.07054083 37.65435929 49.51069007 37.05207484 37.31126329 44.19380985\n",
            " 46.48869654 45.8710558  49.65346299 22.16545534 33.17064702 45.92445118\n",
            " 47.72503687 12.70980862 46.55342113 44.11173826 44.21014663 40.35567079\n",
            " 44.39380135 27.64132802 26.31866938 48.37869555 47.75306377 14.81052895\n",
            " 46.90022424 45.34391889 41.27544218 12.86782757 27.13895319 37.76781451\n",
            " 37.38287394 48.4656553  46.05898164 15.18027439 47.39224625 47.41568929\n",
            " 46.2962411  48.88969702 26.66921476 43.3120681  48.95750377 48.2220416\n",
            " 49.35156202 48.91797132 45.38572336 42.59399069 44.46524717 48.43609876\n",
            " 45.40962679 49.61299766 40.63268392 40.99854594 46.93778098 43.84229302\n",
            " 48.37478537 26.73611313 47.75398623 48.86677791 49.63099618 48.06864441\n",
            " 43.99751685 30.26794144 35.48726815 42.64679594 48.91634107 49.15596027\n",
            " 44.6899667  47.68836639 34.43578671 41.03956544 45.0643313  41.18796548\n",
            " 42.44581085  7.67679506 12.70980862 46.98334823 49.4791879  45.56878535\n",
            " 48.68040077 32.38377577 23.3477688  27.83691338 12.70980862 45.94439372\n",
            " 40.73428138 43.46926616 48.87839392 40.92287215 49.74202625 49.06600362\n",
            " 42.39602143 47.81181452 38.56649469 27.53020505 46.33960294 43.1196464\n",
            " 48.74961254 44.97743308 35.1315678  43.07699486 36.77783726 46.53731304\n",
            " 46.10422402 49.51242163 44.33562748 49.1719713  40.89690747 44.94707914\n",
            " 48.63915061 46.39435288 19.33302583 48.16562044 48.03860117 31.23287342\n",
            " 12.70980862 12.70980862 44.02942163 44.42196506 46.37492464 40.7988313\n",
            " 47.00083203 46.3086671  48.79844874 28.36209591 46.56434314 31.75425896\n",
            " 47.89196432 48.13222056 27.20113415 46.5804981  47.27941119 47.48416916\n",
            " 46.03711453 48.8542349  47.79558593 48.93155204 37.6648371  43.58543583\n",
            " 44.08431727 43.5152913  42.76380036 38.1712065  48.71963092 48.62228437\n",
            " 44.56825177 44.07106094 45.62449126 41.93743407 39.82386151 45.9847045\n",
            " 46.10422402 48.40836024 43.94762874 49.16123798 49.08681252 49.41831923\n",
            " 38.98604162 24.35398075 43.45008298 47.89461784 49.25814741 45.62853892\n",
            " 28.43061203 48.52934846 12.88605756 45.6372124  37.42698711 48.84826538\n",
            " 36.87146264 45.04785951 49.62119947 44.16361579 41.90936002 20.72627901\n",
            " 26.80715819 44.18467512 26.73843261 47.68060392 47.19530334 33.75593022\n",
            " 49.26602968 34.48949155 41.23677935 48.66821386 44.47862735 45.25811704\n",
            " 34.75943691 44.79692529 44.77542691 48.47043213 37.09038188 34.4078417\n",
            " 47.07956709 48.41292539 35.13840274 45.29815044 48.2363652  45.66935178\n",
            " 49.33441575 39.37871748 47.01420121 45.84955383 43.35331497 39.55002305\n",
            " 46.04690897 46.14317063 46.42192426 38.32559276 45.51475087 22.15217076\n",
            " 47.11541145 48.2317016  42.02341224 41.87494343 47.78387981 32.63245799\n",
            " 46.54242035 44.18588373 40.44590564 34.91321989 44.74223727 45.9640885\n",
            " 49.40901496 48.07014846 36.25238479 47.22704399 40.67377176 45.73529759\n",
            " 41.83489922 47.33460083 49.10276858 49.66312149 36.03628683 49.14212848\n",
            " 29.19739389 40.23126872 49.03730391 48.03556365 48.30555112 42.99942811\n",
            " 48.35437725 38.59518975 36.79869913 48.2083321  47.85596025 31.9065503\n",
            " 48.26761367 48.88354304 42.07769532 48.3661041  33.40239865 49.62805524\n",
            " 33.33329984 48.07364687 49.47392366 48.40439488 38.37494069 47.33874569\n",
            " 48.85824072 48.63079685 18.04260243 34.37638611 35.30351892 47.39428746\n",
            " 45.84986359 39.06085148 34.30688017 48.74612786 37.89478867 46.70619773\n",
            " 12.70980862 21.02142727 43.61162048 46.6874571  48.08138566 24.72854533\n",
            " 40.68450095 43.65300204 28.29172015 12.70980862 12.70980862 45.15592144\n",
            " 44.29213805 30.27491053 48.47735588 48.30384245 36.28063687 49.40272819\n",
            " 44.65070381 17.67489589 41.93519393 46.43491483 48.80183608 26.3023233\n",
            " 47.52475707 41.7713717  32.48692167 48.23258406 30.80848074 44.64660206\n",
            " 47.60365289 39.22684663 48.99506936 25.02749317 41.02617495 48.37627916\n",
            " 41.30856066 47.9893075  49.07799483 48.4753593  43.97309578 49.02095011\n",
            " 33.41842469 44.07585877 48.63698092 46.46652646 31.75080955 35.86696744\n",
            " 19.84539559 49.58675628 49.6483605  48.73437196 49.50159085 45.5486862\n",
            " 44.36109386 33.00443128 30.70864796 46.17156413 49.27282794 49.03333875\n",
            " 48.01446736 12.70980862 46.48155916 36.05265769 44.14280386 48.72999858\n",
            " 12.70980862 47.16642438 45.32655584 34.54736708 49.42215175 48.70634651\n",
            " 33.25404713 46.26159159 48.18146002 46.7362967  48.51575169 49.0690356\n",
            " 48.3206483  43.95549747 40.44787253 43.94565073 41.89443823 17.49939624\n",
            " 49.28908104 33.96834788 49.8400737  12.70980862 41.89846414 48.10612038\n",
            " 49.77693886 44.6995353  43.45835041 33.01626643 45.39204217 46.74744217\n",
            " 48.22908665 43.20846235 39.34339412 45.70929753 49.50701872 48.31402232\n",
            " 49.1459346  47.12891892 41.1007426  39.64313001 37.32971946 43.50520223\n",
            " 47.50680876 47.65999124 26.87853577 48.65171773 49.32437182 48.14369107\n",
            " 40.4658098  48.74961254 46.6209192  37.68754747 46.60803918 48.34221072\n",
            " 40.02308218 48.84113832 39.25210277 49.43823802 45.42108816 48.24800775\n",
            " 48.40775977 30.23968364 48.46160158 24.99669188 45.20542473 37.74601975\n",
            " 41.27232804 44.38871386 42.623933   43.96190627 34.19358227 47.3373111\n",
            " 49.813345   46.18468368 49.63021357 44.59021525 38.34217089 46.71788414\n",
            " 49.39057547 46.53126338 42.60287828 28.89698534 33.3627772  49.47547126\n",
            " 43.98625908 42.07321146 33.57262868 44.73841298 38.6051796  48.68740241\n",
            " 27.43883429 48.04136874 47.11025872 35.78783723 45.29572202 49.78594318\n",
            " 33.05784138 47.96042939 49.6766625  39.72800391 49.56662468 47.0214139\n",
            " 43.53096536 37.46418119 27.868886   49.29823868 38.39855351 38.2786389\n",
            " 49.15744596 47.28785271 43.16945841 49.32365172 44.33804837 48.6126682\n",
            " 48.2570387  47.37356023 47.62022526 36.25146051 26.01919477 12.70980862\n",
            " 43.26770483 46.75803383 47.86381025 34.01786334 12.70980862 46.33927665\n",
            " 44.04090024 42.5165163  47.52475707 22.24803339 48.14934958 48.16506908\n",
            " 47.88791317 47.50558421 48.13222056 48.28172311 47.24856274 47.10446008\n",
            " 33.71757825 48.01002278 46.44721382 38.47722735 46.57348274 28.68563907\n",
            " 42.26109865 49.00343303 47.6820712  41.21234661 47.18794041 46.22340906\n",
            " 32.87126777 49.31127929 47.27147103 43.20361903 42.15345341 45.30399526\n",
            " 48.17179113 44.7606886  26.69864349 35.79135621 44.39629144 48.52816584\n",
            " 47.73121023 48.70590085 12.70980862 45.29016406 48.8193645  48.44148706\n",
            " 49.16817903 31.37359541 12.70980862 43.99134108 48.77744252 48.67988589\n",
            " 49.1202825  47.05168271 45.55976443 49.37971406 48.75549637 37.09593816\n",
            " 44.86484867 43.53724415 42.51817732 36.38258307 26.17844631 29.9137164\n",
            " 33.78836348 49.25929371 49.33585813 38.58861111 33.65014885 42.07421678\n",
            " 42.17610924 49.45359074 42.22113072 45.52327539 34.1435227  49.59155435\n",
            " 28.19984932 44.42350561 42.82760355 49.3686809  48.79600628 42.86542152\n",
            " 49.18989635 31.29042526 34.61022023 43.47625498 41.45983374 46.72397961\n",
            " 37.69834654 45.19839302 49.08461306 46.29403589 42.01811265 13.86005634\n",
            " 12.70980862 48.50379975 35.39458403 39.68824105 43.13359792 12.70980862\n",
            " 44.81807735 27.92146652 36.66222017 49.67688919 47.76054816 48.08610462\n",
            " 43.70911291 47.58490875 46.47335347 23.56335189 30.4080874  44.24050253\n",
            " 49.08104528 28.59914654]\n",
            "selection [493 171 105 313 920 777 312  26 756 751] (10,) [ 7.67679506  7.8244233   7.83474457 12.08513098 12.70980862 12.70980862\n",
            " 12.70980862 12.70980862 12.70980862 12.70980862]\n",
            "trainset before adding uncertain samples (310, 10) (310,)\n",
            "trainset after adding uncertain samples (320, 10) (320,)\n",
            "updated train set: (320, 10) (320,) unique(labels): [153 167] [0 1]\n",
            "val set: (982, 10) (982,)\n",
            "\n",
            "Train set: (320, 10)\n",
            "Validation set: (982, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 32\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.131 s \n",
            "\n",
            "Accuracy rate is 80.875576 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.88      0.87       321\n",
            "           1       0.64      0.61      0.62       113\n",
            "\n",
            "    accuracy                           0.81       434\n",
            "   macro avg       0.75      0.74      0.75       434\n",
            "weighted avg       0.81      0.81      0.81       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[282  39]\n",
            " [ 44  69]]\n",
            "--------------------------------\n",
            "val predicted: (982,) [1 1 1 0 0 1 1 0 0 0 0 1 1 1 0 1 0 1 0 0 0 1 1 1 1 1 1 1 0 1 0 0 0 1 1 0 0\n",
            " 1 0 1 1 0 0 0 1 1 0 1 1 1 0 0 1 1 1 1 0 1 0 1 1 0 0 1 1 1 1 1 1 0 1 0 1 0\n",
            " 0 1 1 0 0 0 0 1 0 0 1 1 0 1 0 1 0 0 1 1 1 0 0 0 0 1 0 1 0 1 1 1 0 0 1 0 0\n",
            " 0 0 0 0 0 0 1 0 1 1 0 1 1 0 1 1 1 1 0 1 1 1 1 1 1 0 1 0 1 1 0 1 0 1 1 0 1\n",
            " 1 1 1 0 0 1 0 0 0 1 1 1 1 0 1 1 0 1 0 0 1 1 0 1 1 1 0 0 0 0 0 0 0 0 1 1 1\n",
            " 0 0 1 0 0 0 0 0 0 1 1 1 0 1 1 0 0 0 1 0 1 1 0 1 1 0 1 1 0 0 0 0 0 0 1 0 1\n",
            " 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 0 1 1 0 1 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1\n",
            " 0 0 1 1 0 1 1 0 0 1 1 1 1 0 0 0 0 0 1 0 1 0 1 0 1 0 0 1 0 1 0 1 0 0 0 0 0\n",
            " 0 0 0 0 1 1 1 1 1 0 1 1 1 1 1 0 1 0 1 0 0 1 0 0 0 1 0 1 1 1 0 1 0 1 0 1 0\n",
            " 0 1 0 0 1 0 1 0 0 1 1 1 1 0 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1\n",
            " 0 0 0 1 0 0 1 1 0 1 1 0 1 1 0 0 1 0 1 0 0 1 1 1 1 0 1 1 0 1 1 1 0 1 0 1 1\n",
            " 0 1 1 0 1 1 1 0 1 1 0 0 0 0 1 1 0 0 1 1 0 0 1 0 0 0 1 0 1 0 1 1 0 0 1 0 1\n",
            " 1 1 1 0 0 1 1 1 1 0 1 0 1 0 1 1 0 0 0 0 0 0 1 1 1 1 1 1 0 0 0 1 1 1 0 1 0\n",
            " 1 0 0 1 0 0 0 0 0 0 1 1 0 0 1 0 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0\n",
            " 0 1 0 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 1 0 0 0 0 1 0 1 0 1 0 1 1 0 1 1 0 1 1\n",
            " 0 0 1 1 1 1 0 1 1 1 0 1 1 1 0 0 0 1 0 1 1 1 1 0 1 1 1 0 1 0 0 0 0 1 0 1 1\n",
            " 0 0 0 1 0 1 0 1 1 1 0 1 1 0 1 1 0 1 0 0 0 1 0 0 1 0 0 1 0 1 1 1 1 1 1 0 0\n",
            " 0 1 0 1 1 1 1 0 1 1 1 0 1 1 0 1 0 1 0 0 1 1 0 1 1 1 1 0 1 1 0 1 1 1 0 1 0\n",
            " 0 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 0 0 0 1 0 1 1 0 1 0 0 0 1 0 0 0 1 1 0 0\n",
            " 0 1 0 0 0 1 0 0 1 1 0 1 0 0 0 1 1 1 0 1 0 1 1 1 1 1 1 1 0 0 0 0 1 0 1 1 0\n",
            " 1 1 0 0 1 1 0 0 0 0 1 0 0 1 0 1 0 0 1 0 0 1 0 1 1 1 0 0 0 1 1 0 0 1 0 1 0\n",
            " 1 1 0 1 0 1 0 1 1 0 0 0 0 1 1 0 0 1 0 1 1 1 1 0 1 0 1 0 0 0 0 1 0 1 1 1 1\n",
            " 1 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 0 0 1 0 0 1 1 1 0 1 1 1 0 1 0 0 0 0 0 1 0\n",
            " 0 1 1 0 1 0 1 1 1 0 0 0 1 1 0 0 1 1 0 0 0 1 0 1 1 0 1 1 1 0 1 1 0 0 1 1 1\n",
            " 0 1 0 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 0 1 1 0 0 1 0 1 1 0 0 0\n",
            " 0 1 0 1 1 0 1 0 1 0 1 0 1 1 1 1 1 0 0 1 0 0 0 1 0 0 0 1 0 1 0 0 1 1 0 1 0\n",
            " 0 1 1 1 1 0 1 1 1 0 0 1 1 0 1 1 1 0 0 0]\n",
            "probabilities: (982, 2) \n",
            " [1 1 1 0 0 1 1 0 0 0 0 1 1 1 0 1 0 1 0 0 0 1 1 1 1 1 1 1 0 1 0 0 0 1 1 0 0\n",
            " 1 0 1 1 0 0 0 1 1 0 1 1 1 0 0 1 1 1 1 0 1 0 1 1 0 0 1 1 1 1 1 1 0 1 0 1 0\n",
            " 0 1 1 0 0 0 0 1 0 0 1 1 0 1 0 1 0 0 1 1 1 0 0 0 0 1 0 1 0 1 1 1 0 0 1 0 0\n",
            " 0 0 0 0 0 0 1 0 1 1 0 1 1 0 1 1 1 1 0 1 1 1 1 1 1 0 1 0 1 1 0 1 0 1 1 0 1\n",
            " 1 1 1 0 0 1 0 0 0 1 1 1 1 0 1 1 0 1 0 0 1 1 0 1 1 1 0 0 0 0 0 0 0 0 1 1 1\n",
            " 0 0 1 0 0 0 0 0 0 1 1 1 0 1 1 0 0 0 1 0 1 1 0 1 1 0 1 1 0 0 0 0 0 0 1 0 1\n",
            " 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 0 1 1 0 1 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1\n",
            " 0 0 1 1 0 1 1 0 0 1 1 1 1 0 0 0 0 0 1 0 1 0 1 0 1 0 0 1 0 1 0 1 0 0 0 0 0\n",
            " 0 0 0 0 1 1 1 1 1 0 1 1 1 1 1 0 1 0 1 0 0 1 0 0 0 1 0 1 1 1 0 1 0 1 0 1 0\n",
            " 0 1 0 0 1 0 1 0 0 1 1 1 1 0 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1\n",
            " 0 0 0 1 0 0 1 1 0 1 1 0 1 1 0 0 1 0 1 0 0 1 1 1 1 0 1 1 0 1 1 1 0 1 0 1 1\n",
            " 0 1 1 0 1 1 1 0 1 1 0 0 0 0 1 1 0 0 1 1 0 0 1 0 0 0 1 0 1 0 1 1 0 0 1 0 1\n",
            " 1 1 1 0 0 1 1 1 1 0 1 0 1 0 1 1 0 0 0 0 0 0 1 1 1 1 1 1 0 0 0 1 1 1 0 1 0\n",
            " 1 0 0 1 0 0 0 0 0 0 1 1 0 0 1 0 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0\n",
            " 0 1 0 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 1 0 0 0 0 1 0 1 0 1 0 1 1 0 1 1 0 1 1\n",
            " 0 0 1 1 1 1 0 1 1 1 0 1 1 1 0 0 0 1 0 1 1 1 1 0 1 1 1 0 1 0 0 0 0 1 0 1 1\n",
            " 0 0 0 1 0 1 0 1 1 1 0 1 1 0 1 1 0 1 0 0 0 1 0 0 1 0 0 1 0 1 1 1 1 1 1 0 0\n",
            " 0 1 0 1 1 1 1 0 1 1 1 0 1 1 0 1 0 1 0 0 1 1 0 1 1 1 1 0 1 1 0 1 1 1 0 1 0\n",
            " 0 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 0 0 0 1 0 1 1 0 1 0 0 0 1 0 0 0 1 1 0 0\n",
            " 0 1 0 0 0 1 0 0 1 1 0 1 0 0 0 1 1 1 0 1 0 1 1 1 1 1 1 1 0 0 0 0 1 0 1 1 0\n",
            " 1 1 0 0 1 1 0 0 0 0 1 0 0 1 0 1 0 0 1 0 0 1 0 1 1 1 0 0 0 1 1 0 0 1 0 1 0\n",
            " 1 1 0 1 0 1 0 1 1 0 0 0 0 1 1 0 0 1 0 1 1 1 1 0 1 0 1 0 0 0 0 1 0 1 1 1 1\n",
            " 1 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 0 0 1 0 0 1 1 1 0 1 1 1 0 1 0 0 0 0 0 1 0\n",
            " 0 1 1 0 1 0 1 1 1 0 0 0 1 1 0 0 1 1 0 0 0 1 0 1 1 0 1 1 1 0 1 1 0 0 1 1 1\n",
            " 0 1 0 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 0 1 1 0 0 1 0 1 1 0 0 0\n",
            " 0 1 0 1 1 0 1 0 1 0 1 0 1 1 1 1 1 0 0 1 0 0 0 1 0 0 0 1 0 1 0 0 1 1 0 1 0\n",
            " 0 1 1 1 1 0 1 1 1 0 0 1 1 0 1 1 1 0 0 0]\n",
            "std (982,) [41.31094681 46.41228808 30.77469862 46.1368955  18.56006497 43.93768543\n",
            " 29.56913368 28.91856655 40.45806134 49.36066336 49.66715475 44.95001378\n",
            " 49.2174379  35.60309898 45.90195495 36.23365678 40.86143358 41.26040288\n",
            " 42.325438   48.48467993 41.17186557 46.71670546 21.85190852 25.56840922\n",
            " 45.06144854 48.76867955 47.62537586 48.54035815 43.77275423 48.19600932\n",
            " 35.32143659 34.63047309 47.93558378 44.86600653 43.13098513 49.6342597\n",
            " 49.81051503 16.30317274 38.96128082 45.28113703 24.75234606 41.91152495\n",
            " 49.0865291  32.03463058 39.47770578 39.93125015 24.51909217 46.39752882\n",
            " 38.544472   48.47124483 45.65921707 47.07277884 49.461016   39.74071302\n",
            " 48.88472927 46.20565812 47.23771089 48.17196058 42.36663053 34.97531013\n",
            " 45.37643943 48.76997794 49.69186858 25.01289249 47.77382033 47.30879465\n",
            " 44.60933252 45.06224513 37.08807048 48.65444527 47.7627743  37.59490236\n",
            " 47.7462126  49.11157926 38.38548278 48.39597105 30.09519859 40.69927404\n",
            " 32.07145595 48.28999156 35.31883582 48.56767443 48.5338046  39.90453627\n",
            " 46.25856197 47.72510262 26.93693376 43.13800838 37.83421811 48.29359048\n",
            " 48.32705958 40.86143358 47.29154171 45.03187229 43.94083561 48.80749903\n",
            " 45.68521857 49.8206277  48.53538129 48.85138128 49.29250614 46.88808163\n",
            " 49.75650717 48.16691958 39.47605857 48.85548668 40.16856167 39.33094158\n",
            " 45.43906865 46.69492107 49.43197761 49.27788166 46.36181458 48.96860378\n",
            " 48.38834226 37.4790468  40.86143358 47.40698288 49.47733529 48.30814248\n",
            " 45.94506357 49.70338998 30.0497586  38.02055095 47.77243383 48.58041394\n",
            " 38.84324443 40.22377532 16.89338793 40.6461948  31.25399148 40.90672783\n",
            " 45.66998244 34.71958466 47.09662553 29.83187467 38.67697082 47.10269255\n",
            " 45.76412566 47.81761645 46.76689337 38.83843788 32.8338005  40.86143358\n",
            " 48.91644712 43.17631607 49.10723323 47.28083378 26.9500503  48.70184716\n",
            " 45.42989001 44.59028979 31.34036127 44.8779011  41.21366022 48.87456261\n",
            " 29.2825891  43.88829997 47.69760641 46.19136855 39.30988553 44.85688072\n",
            " 34.59246172 42.33140125 49.63104463 46.96120636 49.45579654 40.86143358\n",
            " 44.96831416 38.67613899 26.45444526 44.88589264 47.02138006 43.96755214\n",
            " 44.3712878  47.91369029 42.63308953 13.16187005 42.15596484 42.40804006\n",
            " 47.43565963 30.63961619 42.89321344 47.96606995 44.79884022 44.9706598\n",
            " 39.15112504 44.08381081 45.26007496 28.51368369 40.89991724 49.39188256\n",
            " 47.2533319  49.46344303 31.25196167 48.32599152 39.61140186 45.23590443\n",
            " 26.5820227  27.03482083 48.7202945  49.64995565 40.86143358 47.26408474\n",
            " 48.46158314 47.55137223 41.895662   47.44726889 48.33356364 40.00410939\n",
            " 47.21440499 37.61904925 48.90364616 34.99162756 18.37618259 33.4953899\n",
            " 49.59876466 41.90238657 43.26105822 49.47432658 47.16670934 41.73110288\n",
            " 41.31792773 45.62615648 42.493514   44.57004725 44.65571352 48.20623425\n",
            " 48.37534263 47.11824143 47.1581367  42.53823488 48.48737156 49.02762477\n",
            " 47.37868918 42.66892444 47.91665915 43.96254495 44.56976595 31.04292603\n",
            " 48.88495717 49.34058232 48.86637926 41.01244013 47.70393676 48.47115799\n",
            " 48.48246605 49.56151388 45.73370678 41.41353786 48.47862545 40.14061412\n",
            " 44.98502906 30.43145053 43.68620146 45.42881594 47.9818938  36.08712644\n",
            " 32.38909958 49.48399126 47.75423287 45.82195572 39.43728299 46.89127241\n",
            " 42.52895356 46.98696699 39.17075505 47.40288947 28.74127475 46.28528276\n",
            " 46.78365298 48.85869848 47.57844505 40.86143358 49.59672189 40.86143358\n",
            " 34.57580543 27.4426651  33.97152593 48.5689824  40.86143358 47.86807597\n",
            " 49.61062571 23.29865086 40.57606278 49.14990687 45.54413305 46.43713937\n",
            " 47.82482495 49.04887509 34.46432077 45.90014624 47.17216832 33.17166727\n",
            " 29.71029498 49.05387077 49.72180497 48.92275554 45.30833085 31.94654498\n",
            " 46.3430214  41.22803127 47.67817642 47.13877443 36.13453065 34.75626103\n",
            " 45.61491777 46.30850512 44.99631344 46.3947634  45.40170171 49.11157926\n",
            " 47.01848993 36.97777014 48.04752136 44.4901605  44.30572884 42.7957792\n",
            " 49.7629036  45.81620372 27.39688352 35.30434043 25.94114406 45.52612124\n",
            " 47.48674251 27.74727702 49.25411321 49.33830743 47.82859657 20.00088247\n",
            " 49.56699338 47.7767228  40.86143358 49.26626573 47.19613466 48.17992436\n",
            " 49.18790836 47.41186836 43.42144426 48.55258349 48.86473983 49.27992295\n",
            " 45.06218154 47.70260089 33.90874087 47.90315649 21.27988516 41.81866798\n",
            " 45.17106098 44.53590485 40.24656715 31.47522694 39.48793263 30.08649352\n",
            " 49.24190309 22.94294583 25.38022549 47.74324275 45.92251399 31.88629323\n",
            " 46.98070612 46.21288704 43.05358197 48.68557514 44.06804515 25.97989197\n",
            " 32.88081733 46.77768076 47.99098339 47.148317   49.12364446 34.6646299\n",
            " 49.18147094 48.73684354 47.93171143 16.80448608 42.69850615 39.93762155\n",
            " 49.81776301 44.84336837 45.51616998 36.59447944 48.1239589  48.58790516\n",
            " 40.86143358 40.86143358 46.35895483 48.24132059 45.26540303 29.43942983\n",
            " 49.20634382 47.00851312 44.56947723 46.89775149 46.75346644 46.9271792\n",
            " 34.39997871 47.27279211 48.37716766 45.07349031 47.30548735 48.80892928\n",
            " 23.13014935 48.59218921 28.03727285 44.37267034 46.73555577 49.82767754\n",
            " 37.63690295 45.03502184 49.17725006 48.96217632 48.06970716 39.67478494\n",
            " 23.84198438 45.55538086 36.21888983 49.59526214 36.871399   37.96217936\n",
            " 42.80841683 46.71839462 46.1904335  49.60042115 15.70895971 34.91557605\n",
            " 44.42643106 48.32510114 40.86143358 47.19180203 45.46196338 45.23956947\n",
            " 40.05612164 44.33431074 21.68440745 22.67339431 48.74943653 47.16451552\n",
            " 24.54660698 47.31535353 47.28355722 39.07051361 36.07425832 24.61130868\n",
            " 39.1279718  39.67478494 48.43560821 46.40493159 17.98460619 45.90636327\n",
            " 46.74184132 45.67961619 48.5806779  21.39356342 45.03020348 48.59721481\n",
            " 48.49959046 49.49956503 49.10465667 44.88031811 41.73473911 47.10901099\n",
            " 49.12373514 44.43526927 49.78619759 44.07278453 42.0844283  47.19445107\n",
            " 43.4438122  47.19226363 25.4376715  47.96972431 48.58241955 49.77424031\n",
            " 48.98663484 43.31273359 28.50628837 32.91928556 45.17400684 49.09784106\n",
            " 49.23374471 43.64014938 48.71415239 31.11228258 44.10572843 45.14957064\n",
            " 42.45628238 42.16458344 40.86143358 46.927332   49.38295356 45.43578624\n",
            " 48.64809145 29.02968627 34.65980666 33.5643439  40.86143358 45.50565256\n",
            " 38.06198383 45.73415908 48.79562249 42.37280183 49.79002231 49.17076058\n",
            " 34.90845806 47.45570671 40.05971031 29.41611997 47.29937191 39.39423744\n",
            " 48.40490024 45.18109243 33.77158433 43.4288874  41.18457076 47.07475693\n",
            " 44.30369991 49.55599996 44.48066496 49.0360184  37.52344893 45.33507644\n",
            " 47.98907682 44.34129682 24.33232569 47.69055221 48.41378343 33.51164034\n",
            " 40.86143358 40.86143358 42.57974966 43.53488616 47.41227441 41.82694712\n",
            " 45.33912337 48.7167522  47.92540179 27.46603002 46.88877119 27.93303368\n",
            " 48.08403365 48.0759026  24.54273195 47.07710926 47.00637121 47.44922224\n",
            " 45.7787355  48.71918507 47.35095943 49.01161616 36.92042067 41.81866798\n",
            " 45.7040736  45.34569459 43.18166753 41.15823677 48.75237452 48.2930178\n",
            " 46.07387292 44.26355525 47.00540356 45.91044228 38.85047839 46.50039028\n",
            " 44.30369991 49.14587275 44.03234187 49.20201947 49.23481134 49.81144442\n",
            " 43.07629663 27.05781924 42.85950813 48.09472039 49.26218994 44.36906308\n",
            " 31.66404325 48.55189815 11.33215267 42.09327787 39.425511   48.03731702\n",
            " 28.37124076 45.64797408 49.63671197 43.05028356 42.07825204 10.45599042\n",
            " 24.83859231 44.67233065 24.49133732 46.98022856 48.53408502 37.83976482\n",
            " 49.387134   28.00375811 39.47945194 48.71262714 45.15500823 47.48889072\n",
            " 32.8998232  45.43974191 41.74093569 48.6539455  39.47070616 31.59059502\n",
            " 47.42526877 47.72295877 37.39398458 43.35877279 49.01937024 45.31727672\n",
            " 49.59780205 41.69261135 48.35334621 45.86639633 42.84077916 41.71159322\n",
            " 46.35080353 44.96717315 47.77197444 33.62169838 41.3091625  24.96679314\n",
            " 47.31439643 48.2048894  41.51292208 40.74499707 47.92749368 30.96126756\n",
            " 46.67732904 42.79852504 44.33824286 22.1392706  44.35181732 44.52635783\n",
            " 49.50619152 47.67594362 36.65760567 47.55648343 37.31152161 45.54417828\n",
            " 42.52859543 47.8280278  48.85005239 49.68063764 33.86416821 49.2237084\n",
            " 35.99748976 33.97718346 49.38281066 48.41892936 48.22004987 44.15216096\n",
            " 47.46054598 35.1885773  32.55282762 48.18394517 47.0180919  33.30804066\n",
            " 47.74158806 48.69950278 43.62753011 48.64166971 35.79896771 49.59442254\n",
            " 31.29825721 47.13877443 49.67993113 48.7415759  35.61424219 46.72452484\n",
            " 48.31839335 48.53278808 18.28722313 33.35430967 37.05793142 45.61812941\n",
            " 46.68444317 43.66849007 35.95132242 48.03082306 33.96412257 46.88189033\n",
            " 40.86143358 26.82640001 43.34428526 47.61428038 48.35652917 31.62538501\n",
            " 41.95342592 45.27974956 25.71812765 40.86143358 40.86143358 46.63302203\n",
            " 44.30858063 28.34202684 48.71116632 48.11454993 37.20785041 49.41782675\n",
            " 44.79456851 27.05121496 39.7815622  47.29257085 49.10155607 22.70764738\n",
            " 47.59522232 44.96853503 38.29804483 48.26541595 30.90654339 42.73021891\n",
            " 46.75350392 40.42384719 48.89899036 32.52187115 41.71078916 47.17214035\n",
            " 38.81418895 48.10524823 48.87289586 48.47096372 45.48630412 48.88866482\n",
            " 32.90726415 44.9718843  48.04425749 46.80679718 14.97250736 36.60342672\n",
            "  8.37789421 49.5502302  49.7778399  49.04866384 49.46118158 45.39505284\n",
            " 44.9669499  36.86419711  1.33361063 45.73827658 49.35206927 49.05749928\n",
            " 48.35138841 46.56484798 38.15777396 46.61328582 48.87851647 47.30100712\n",
            " 44.10534553 34.8677068  49.41469281 48.43620648 33.27528492 47.4777672\n",
            " 46.96758668 48.13477013 48.44768202 49.11108676 48.48633204 46.08044367\n",
            " 36.16948531 39.96368412 40.71281153 19.43889065 49.23981329 30.7445926\n",
            " 49.87454797 41.36820121 47.79330573 49.74922266 44.51982022 43.02549761\n",
            " 40.01645183 46.12015854 46.42428627 48.49454252 40.59965387 41.38191971\n",
            " 45.43181501 49.53848591 47.36305969 49.40655916 47.40846588 40.60868036\n",
            " 39.98783159 41.78677279 44.74103171 47.93233476 43.91781104 25.41231734\n",
            " 49.27520868 49.16322609 47.06547532 40.42385437 48.40490024 46.7650291\n",
            " 37.5540608  45.50585583 48.86038618 38.23839851 49.17943006 42.72188697\n",
            " 49.6066584  47.6598105  48.0671925  48.76528329 13.00321623 48.6644401\n",
            " 31.42713502 42.4354424  36.52621388 43.77503507 44.92055536 42.61988877\n",
            " 45.46614448 38.91076643 44.39193585 49.87666805 45.20779963 49.67617382\n",
            " 43.80775857 40.49640988 45.65425058 49.35562794 45.51518585 43.83633679\n",
            " 29.13139538 39.40693425 49.43811209 44.70544849 42.40995482 38.79551977\n",
            " 41.2478086  37.9411843  48.6857708  36.95171187 47.93011516 46.60312722\n",
            " 34.12455128 45.21382678 49.837512   30.75688076 48.76208376 49.60127862\n",
            " 38.01880601 49.71931383 47.31580236 41.66015203 37.40844088 19.75365185\n",
            " 49.24317726 35.59972733 37.27046216 49.13109593 46.39150698 44.21957697\n",
            " 49.21199437 43.67609184 48.83065712 48.00246928 47.33549736 47.69501494\n",
            " 36.45963528 34.73010986 40.86143358 41.26815646 46.84990113 48.59272807\n",
            " 34.0672897  40.86143358 46.97674664 43.87822591 41.26040288 47.59522232\n",
            "  8.2862536  47.45499537 47.98363493 47.89791477 47.20531775 48.0759026\n",
            " 47.96643459 48.12795486 47.49655197 39.00915516 47.74822593 43.71493873\n",
            " 34.83616811 45.74345757 33.27210534 43.75825749 49.01693592 47.98501184\n",
            " 41.13747551 47.17130873 45.45081582 34.83854875 49.39270423 47.43263612\n",
            " 41.59534023 32.56358053 44.23313243 48.21146803 46.60086    27.45112267\n",
            " 36.48258728 44.99736393 48.81176784 48.04977226 48.82190056 44.35916102\n",
            " 48.84757471 48.5892847  49.04437954 34.59216008 40.86143358 43.44374038\n",
            " 48.60355329 48.80104319 48.61937453 46.23268827 45.87794543 49.42189586\n",
            " 49.2213505  38.2389742  43.73301432 43.62364318 42.86424465 30.02796788\n",
            " 22.47780247 34.1608937  37.65359326 48.96208118 49.21584532 40.86573575\n",
            " 28.33334702 41.11360462 34.07699739 49.46761966 38.12921128 45.4234617\n",
            " 38.55474457 49.49002549 29.27292236 44.03161993 44.03546427 49.64818029\n",
            " 49.09254469 42.39152938 49.31242229 35.95085941 33.30263097 40.51095204\n",
            " 40.9259638  46.4781599  40.43612373 44.95954454 48.86313781 46.25746257\n",
            " 41.15451163 17.52408589 40.86143358 48.06014237 30.47502183 38.21704491\n",
            " 43.64744451 40.86143358 42.35146652 32.4829631  31.98522433 49.77696978\n",
            " 48.68566734 47.93129224 45.2667644  47.74056817 46.40380006 25.18665404\n",
            " 35.61806002 43.46420576 49.01400675 31.42048504]\n",
            "selection [740 876 732 587 578 808 177 730 424  37] (10,) [ 1.33361063  8.2862536   8.37789421 10.45599042 11.33215267 13.00321623\n",
            " 13.16187005 14.97250736 15.70895971 16.30317274]\n",
            "trainset before adding uncertain samples (320, 10) (320,)\n",
            "trainset after adding uncertain samples (330, 10) (330,)\n",
            "updated train set: (330, 10) (330,) unique(labels): [157 173] [0 1]\n",
            "val set: (972, 10) (972,)\n",
            "\n",
            "Train set: (330, 10)\n",
            "Validation set: (972, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 33\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.141 s \n",
            "\n",
            "Accuracy rate is 80.184332 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.87      0.87       321\n",
            "           1       0.62      0.60      0.61       113\n",
            "\n",
            "    accuracy                           0.80       434\n",
            "   macro avg       0.74      0.74      0.74       434\n",
            "weighted avg       0.80      0.80      0.80       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[280  41]\n",
            " [ 45  68]]\n",
            "--------------------------------\n",
            "val predicted: (972,) [1 1 1 0 0 1 1 0 0 0 0 1 1 1 0 1 0 1 0 0 0 1 1 1 1 1 1 1 0 1 0 0 0 1 1 0 0\n",
            " 0 1 1 0 0 0 1 1 0 1 1 1 0 0 1 1 1 1 0 1 0 1 1 0 0 1 1 1 1 1 1 0 1 0 1 0 0\n",
            " 1 1 0 0 0 0 1 0 0 1 1 0 1 0 1 0 0 1 1 1 0 0 0 0 1 0 1 0 1 1 1 0 0 1 0 0 0\n",
            " 0 0 0 0 0 1 0 1 1 0 1 1 0 1 1 1 1 0 1 1 1 1 1 1 0 1 0 1 1 0 1 0 1 1 0 1 1\n",
            " 1 1 0 0 1 0 0 0 1 1 1 1 0 1 1 0 1 0 0 1 1 0 1 1 1 0 0 0 0 0 0 0 1 1 1 0 0\n",
            " 1 0 0 0 0 0 0 1 1 1 0 1 1 0 0 0 1 0 1 1 0 1 1 0 1 1 0 0 0 0 0 0 1 0 1 1 1\n",
            " 1 1 1 0 0 1 1 0 1 0 1 1 1 1 0 1 1 0 1 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1 0 0\n",
            " 1 1 0 1 1 0 0 1 1 1 1 0 0 0 0 0 1 0 1 0 1 0 1 0 0 1 0 1 0 1 0 0 0 0 0 0 0\n",
            " 0 0 1 1 1 1 1 0 1 1 1 1 1 0 1 0 1 0 0 1 0 0 0 1 0 1 1 1 0 1 0 1 0 1 0 0 1\n",
            " 0 0 1 0 1 0 0 1 1 1 1 0 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 0 0\n",
            " 0 1 0 0 1 1 0 1 1 0 1 1 0 0 1 0 1 0 0 1 1 1 1 0 1 1 0 1 1 1 0 1 0 1 1 0 1\n",
            " 1 0 1 1 1 0 1 1 0 0 0 0 1 1 0 1 1 0 0 1 0 0 0 1 0 1 0 1 1 0 0 1 0 1 1 1 1\n",
            " 0 0 1 1 1 1 0 1 0 1 0 1 1 0 0 0 0 0 0 1 1 1 1 1 1 0 0 0 1 1 1 0 1 0 1 0 0\n",
            " 1 0 0 0 0 0 0 1 1 0 0 1 0 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 0\n",
            " 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 1 0 0 0 0 1 0 1 0 1 0 1 1 0 1 1 0 1 1 0 0 1\n",
            " 1 1 1 0 1 1 1 0 1 1 1 0 0 0 1 0 1 1 1 1 1 1 1 0 1 0 0 0 1 0 1 1 0 0 0 1 0\n",
            " 1 0 1 1 1 0 1 1 0 1 1 0 1 0 0 0 1 0 0 1 0 0 1 0 1 1 1 1 1 1 0 0 0 1 0 1 1\n",
            " 1 1 0 1 1 1 0 1 1 0 1 0 1 0 0 1 1 0 1 1 1 1 0 1 1 0 1 1 1 0 1 0 0 1 0 0 1\n",
            " 1 1 1 1 1 0 1 1 1 1 1 1 0 0 0 1 0 1 1 0 1 0 0 0 1 0 0 0 1 1 0 0 0 1 0 0 0\n",
            " 1 0 0 1 1 0 1 0 0 0 1 1 1 0 1 0 1 1 1 1 1 1 0 0 0 1 0 1 1 0 1 0 0 1 1 0 0\n",
            " 0 0 1 0 0 1 0 1 0 0 1 0 0 1 0 1 1 1 0 0 0 1 1 0 0 1 0 1 0 1 1 0 1 0 1 0 1\n",
            " 1 0 0 0 0 1 1 0 0 1 0 1 1 1 1 0 1 0 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 0 1 0 1\n",
            " 1 1 1 1 1 0 0 0 0 1 0 0 1 1 1 0 1 1 1 0 1 0 0 0 0 0 1 0 0 1 1 0 1 0 1 1 1\n",
            " 0 0 0 1 1 0 0 1 1 0 0 0 1 0 1 1 1 1 1 0 1 1 0 0 1 1 1 0 1 0 1 1 0 1 1 1 0\n",
            " 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 0 1 1 0 0 1 0 1 1 0 0 0 0 1 0 1 1 0 1 0 1 0\n",
            " 1 0 1 1 1 1 1 0 0 1 0 0 0 1 0 0 0 1 0 1 0 0 1 1 0 1 0 0 1 1 1 1 0 1 1 1 0\n",
            " 0 1 1 0 1 1 1 0 0 0]\n",
            "probabilities: (972, 2) \n",
            " [1 1 1 0 0 1 1 0 0 0 0 1 1 1 0 1 0 1 0 0 0 1 1 1 1 1 1 1 0 1 0 0 0 1 1 0 0\n",
            " 0 1 1 0 0 0 1 1 0 1 1 1 0 0 1 1 1 1 0 1 0 1 1 0 0 1 1 1 1 1 1 0 1 0 1 0 0\n",
            " 1 1 0 0 0 0 1 0 0 1 1 0 1 0 1 0 0 1 1 1 0 0 0 0 1 0 1 0 1 1 1 0 0 1 0 0 0\n",
            " 0 0 0 0 0 1 0 1 1 0 1 1 0 1 1 1 1 0 1 1 1 1 1 1 0 1 0 1 1 0 1 0 1 1 0 1 1\n",
            " 1 1 0 0 1 0 0 0 1 1 1 1 0 1 1 0 1 0 0 1 1 0 1 1 1 0 0 0 0 0 0 0 1 1 1 0 0\n",
            " 1 0 0 0 0 0 0 1 1 1 0 1 1 0 0 0 1 0 1 1 0 1 1 0 1 1 0 0 0 0 0 0 1 0 1 1 1\n",
            " 1 1 1 0 0 1 1 0 1 0 1 1 1 1 0 1 1 0 1 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1 0 0\n",
            " 1 1 0 1 1 0 0 1 1 1 1 0 0 0 0 0 1 0 1 0 1 0 1 0 0 1 0 1 0 1 0 0 0 0 0 0 0\n",
            " 0 0 1 1 1 1 1 0 1 1 1 1 1 0 1 0 1 0 0 1 0 0 0 1 0 1 1 1 0 1 0 1 0 1 0 0 1\n",
            " 0 0 1 0 1 0 0 1 1 1 1 0 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 0 0\n",
            " 0 1 0 0 1 1 0 1 1 0 1 1 0 0 1 0 1 0 0 1 1 1 1 0 1 1 0 1 1 1 0 1 0 1 1 0 1\n",
            " 1 0 1 1 1 0 1 1 0 0 0 0 1 1 0 1 1 0 0 1 0 0 0 1 0 1 0 1 1 0 0 1 0 1 1 1 1\n",
            " 0 0 1 1 1 1 0 1 0 1 0 1 1 0 0 0 0 0 0 1 1 1 1 1 1 0 0 0 1 1 1 0 1 0 1 0 0\n",
            " 1 0 0 0 0 0 0 1 1 0 0 1 0 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 0\n",
            " 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 1 0 0 0 0 1 0 1 0 1 0 1 1 0 1 1 0 1 1 0 0 1\n",
            " 1 1 1 0 1 1 1 0 1 1 1 0 0 0 1 0 1 1 1 1 1 1 1 0 1 0 0 0 1 0 1 1 0 0 0 1 0\n",
            " 1 0 1 1 1 0 1 1 0 1 1 0 1 0 0 0 1 0 0 1 0 0 1 0 1 1 1 1 1 1 0 0 0 1 0 1 1\n",
            " 1 1 0 1 1 1 0 1 1 0 1 0 1 0 0 1 1 0 1 1 1 1 0 1 1 0 1 1 1 0 1 0 0 1 0 0 1\n",
            " 1 1 1 1 1 0 1 1 1 1 1 1 0 0 0 1 0 1 1 0 1 0 0 0 1 0 0 0 1 1 0 0 0 1 0 0 0\n",
            " 1 0 0 1 1 0 1 0 0 0 1 1 1 0 1 0 1 1 1 1 1 1 0 0 0 1 0 1 1 0 1 0 0 1 1 0 0\n",
            " 0 0 1 0 0 1 0 1 0 0 1 0 0 1 0 1 1 1 0 0 0 1 1 0 0 1 0 1 0 1 1 0 1 0 1 0 1\n",
            " 1 0 0 0 0 1 1 0 0 1 0 1 1 1 1 0 1 0 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 0 1 0 1\n",
            " 1 1 1 1 1 0 0 0 0 1 0 0 1 1 1 0 1 1 1 0 1 0 0 0 0 0 1 0 0 1 1 0 1 0 1 1 1\n",
            " 0 0 0 1 1 0 0 1 1 0 0 0 1 0 1 1 1 1 1 0 1 1 0 0 1 1 1 0 1 0 1 1 0 1 1 1 0\n",
            " 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 0 1 1 0 0 1 0 1 1 0 0 0 0 1 0 1 1 0 1 0 1 0\n",
            " 1 0 1 1 1 1 1 0 0 1 0 0 0 1 0 0 0 1 0 1 0 0 1 1 0 1 0 0 1 1 1 1 0 1 1 1 0\n",
            " 0 1 1 0 1 1 1 0 0 0]\n",
            "std (972,) [44.975929   46.32719933 35.31201107 45.75688379  6.02072024 46.49383379\n",
            " 33.13767712 22.78889647 40.9726286  49.02311517 49.50476961 45.91945901\n",
            " 49.55681386 39.4592716  45.24582183 39.79255165 41.46161998 42.79781123\n",
            " 42.55376414 47.3694385  29.9703246  46.5733748  24.9100781  26.35581905\n",
            " 47.09814883 48.45960794 45.72920977 48.31999434 41.1311179  48.73740731\n",
            " 32.53941349 33.23422223 47.59641292 45.30462667 42.14161542 49.64766968\n",
            " 49.76429933 40.17254725 43.46075253 33.03608203 42.73279147 49.1629628\n",
            " 37.14926148 39.38055533 34.33190233 27.35043693 45.89536913 38.86872677\n",
            " 48.79048169 46.22088204 47.94789273 49.51649154 41.46638221 49.05428317\n",
            " 46.72250194 47.51483423 48.39652374 43.87480102 38.33532572 45.18487173\n",
            " 47.98011974 49.59572051 19.903456   47.66012309 47.24347922 45.95858487\n",
            " 45.99273361 40.50745228 48.7360893  47.96419698 27.74585626 47.61084234\n",
            " 49.36229443 31.90703946 48.77973993 35.73691009 40.29993437 17.66080897\n",
            " 48.71326676 36.29812682 48.41196907 48.32650309 39.72360462 47.3024983\n",
            " 48.54310159 27.18536676 40.694345   35.50601455 47.97475397 48.46380752\n",
            " 41.46161998 47.15726994 43.72284607 41.32854117 48.86657288 46.78051285\n",
            " 49.74617434 48.8462498  48.81426634 48.86969163 47.60752048 49.59419015\n",
            " 48.13481415 41.84738227 48.53623924 36.09002642 41.14996363 46.38984737\n",
            " 47.6141382  49.2786561  49.11294724 46.36241516 49.17323275 48.45601682\n",
            " 36.20084089 41.46161998 47.13703573 49.51127427 48.1785771  45.90892355\n",
            " 49.66045096 29.58706573 37.17540019 47.71915596 48.6264268  38.80283966\n",
            " 43.24390908 29.09852267 41.17746163 35.66602462 41.1342436  45.88800821\n",
            " 37.91351697 47.23313231 28.29338022 38.41477931 46.86981062 43.39833511\n",
            " 48.48153814 47.59438845 42.32822676 29.90871944 41.46161998 48.79457423\n",
            " 43.57140571 48.76583242 46.73825881 28.89193131 48.44068273 47.21052841\n",
            " 45.18422142 35.96716102 45.12092505 42.7247526  48.85990962 34.20367228\n",
            " 43.00502405 47.75240909 46.19610588 40.75993457 45.00331336 35.2542123\n",
            " 43.74025322 49.58417455 45.22740698 49.58453475 41.46161998 45.51102592\n",
            " 41.66660622 19.81723786 44.58269678 46.05688783 46.09446007 45.20000709\n",
            " 48.2064042  42.67980002 45.90890515 38.85758537 47.89413757 29.31484741\n",
            " 46.05956758 46.50075635 46.14437034 42.30639683 39.33725017 45.36599333\n",
            " 46.11759163 25.06007536 36.29468439 49.36325109 46.85287644 49.35866658\n",
            " 28.09445858 48.10611097 40.34098438 46.0426778  17.86882186 29.94149117\n",
            " 49.01015323 49.6393719  41.46161998 47.11948868 49.03424198 46.59092234\n",
            " 41.56243617 47.17002809 48.66628815 41.9802232  46.8397461  36.22014814\n",
            " 48.90676878 40.15510873 29.23052129 34.45272036 49.60213444 40.23838293\n",
            " 43.88689263 49.27843888 47.00296571 38.77363908 38.75675917 43.46928829\n",
            " 43.1817571  43.40307038 43.35736652 48.41457445 48.30316937 46.20147495\n",
            " 46.86027858 40.087071   48.43518739 49.09264354 46.94576293 44.75962336\n",
            " 48.16373061 46.19983105 44.32400122 29.61649383 49.03731546 48.93707394\n",
            " 48.69189964 42.70806974 47.76856242 48.50285756 48.2560971  49.49520396\n",
            " 47.31176562 43.0673133  48.18669667 39.62510402 44.5249603  35.60023642\n",
            " 41.45313918 46.49521228 47.22541021 41.22122805 31.28329414 49.42943431\n",
            " 47.5680235  45.93387631 39.45065776 46.53743748 44.31264699 46.64399211\n",
            " 41.34886846 47.03256288 29.01763385 47.26294501 46.77941383 49.15910796\n",
            " 47.1917336  41.46161998 49.52536795 41.46161998 33.17406576 25.53212264\n",
            " 31.84228427 48.71089918 41.46161998 47.68039306 49.24620067 19.27093962\n",
            " 43.87320528 49.04458237 43.49727264 45.74150031 48.43960636 49.25983478\n",
            " 28.30912671 47.05356318 45.164522   33.94095079 26.40510576 48.73388239\n",
            " 49.7677831  48.67898419 46.0973647  35.48509272 46.78020699 45.94629824\n",
            " 48.18716061 47.41282459 34.85458319 25.74333548 43.75983761 45.91667219\n",
            " 45.52208819 45.04095248 46.07480545 49.36229443 47.65200566 36.27400962\n",
            " 48.45364346 45.55084741 43.31572711 43.68882983 49.79393763 46.8375162\n",
            " 31.38300355 34.36165768 30.93991881 42.14307872 46.56793216 31.42303922\n",
            " 49.30870584 49.28756735 47.91510003 15.45178961 49.43559909 47.38485555\n",
            " 41.46161998 48.8351639  47.55775962 46.98495123 49.5264054  47.27967612\n",
            " 42.26325545 48.5210011  48.58779201 49.06800362 47.16274266 47.2831696\n",
            " 36.66032746 47.14115665 26.06247302 40.41526503 47.19859896 46.51953985\n",
            " 42.0425833  23.3255483  42.16393671 32.81134517 49.19718313 13.01305364\n",
            " 30.97437526 48.3004555  47.05532434 30.26291548 47.26223944 44.60969083\n",
            " 43.78157698 48.53639555 46.22536038 30.0750422  35.8419221  47.14618111\n",
            " 47.87452212 47.84522563 49.09375477 37.6240859  49.39143464 48.97847693\n",
            " 48.10254075 18.28353326 40.82610697 38.39167649 49.73708818 45.62413262\n",
            " 43.92388986 33.74141438 47.99492396 47.75300703 41.46161998 41.46161998\n",
            " 47.22584646 48.11556379 46.60457191 23.37303134 49.29060969 46.99199264\n",
            " 45.24854983 44.68544141 46.66286799 46.80111621 39.71190323 45.81346602\n",
            " 48.55704276 45.33933737 47.00825477 48.75130228 30.21540795 48.51319669\n",
            " 25.29446431 44.01826845 47.30521733 49.79844362 36.59567779 45.78742828\n",
            " 49.23988546 49.08721408 48.52688461 43.76142384 14.49699082 45.78612373\n",
            " 34.97173761 49.61857078 35.58800287 43.03406312 42.69119159 46.35899975\n",
            " 43.12905631 49.43585215 31.41462806 44.24465878 47.7221176  41.46161998\n",
            " 47.47779321 45.08725245 43.2208435  39.82419959 43.85110541 26.44776977\n",
            " 33.06159502 48.76706561 46.91625406 24.12260457 46.1340144  47.69400555\n",
            " 40.88702077 36.15651171 26.85822982 40.65200876 43.76142384 48.49447879\n",
            " 44.85765614 11.36840607 47.12594585 45.4750354  46.08270771 48.72663738\n",
            " 20.54357011 46.48258148 48.42432943 48.74400547 49.50480055 49.22789597\n",
            " 44.65875849 43.220902   46.69719299 48.82739009 42.1138389  49.79977296\n",
            " 45.85365036 43.22998333 47.12109254 44.43757661 46.78416642 27.8582479\n",
            " 47.48067683 48.67155738 49.61152253 48.94155604 43.21466842 18.09249453\n",
            " 37.33119622 40.51469605 48.87742447 49.2895025  44.49738504 48.82043373\n",
            " 38.6118193  39.8783222  47.26455367 43.04681984 39.99272587 41.46161998\n",
            " 45.13882118 49.42122949 45.88242343 48.86102191 30.87824436 26.10360738\n",
            " 31.84823886 41.46161998 46.26848186 41.38769398 44.3886709  49.25920703\n",
            " 43.81252772 49.69998998 48.8542     36.49144652 47.21395097 41.25324561\n",
            " 23.91253381 47.91661458 41.31059521 48.63712888 45.75752018 35.48835925\n",
            " 42.66854433 41.55854446 47.22368852 45.66813219 49.54791644 44.72884469\n",
            " 49.16946751 39.08287006 44.37590971 47.21860122 44.30650277 18.1951934\n",
            " 46.94852728 48.31064747 33.21326123 41.46161998 41.46161998 40.86353726\n",
            " 33.11116688 46.9209569  43.88953827 45.98535804 48.0773982  48.45063525\n",
            " 30.07999398 45.49898595 28.33760202 47.96339225 48.39819348 30.04253175\n",
            " 47.54250638 46.76599144 46.59138113 45.24708708 47.63971401 46.27943956\n",
            " 48.57278737 38.27336324 40.41526503 45.83884284 45.63603992 45.11063986\n",
            " 38.39848369 48.45886269 48.540084   44.0146043  45.90294953 46.60030698\n",
            " 43.45910934 38.94792204 48.32968056 45.66813219 49.40019968 43.54387248\n",
            " 49.11641781 48.98569234 49.51871308 44.4527781  32.33377895 44.45626963\n",
            " 47.50938043 49.31327389 43.83969646 35.66221159 47.98260418 42.41279771\n",
            " 38.18987767 48.14462891 29.9273662  45.6985413  49.41925585 44.05670084\n",
            " 46.38152268 29.3960204  45.32300719 24.1350363  47.09169746 48.95284172\n",
            " 33.07324022 49.05010479 35.70604699 37.91511992 48.59744825 46.46822211\n",
            " 47.47603259 37.69259432 46.10837371 43.0486505  48.81751582 37.82496346\n",
            " 28.65132979 47.18728943 48.385313   44.26482379 45.78249426 48.87769097\n",
            " 42.27463944 49.48532212 41.82871922 47.85744466 46.03347741 44.55709882\n",
            " 39.5902481  45.04127336 45.38071391 47.22756363 33.5682813  45.02468083\n",
            " 18.18574074 46.94938346 48.08776527 43.02455579 42.18148203 48.25467563\n",
            " 34.25332702 47.50197672 39.60676735 41.86129001 30.34852027 41.81148844\n",
            " 46.72071249 49.50931575 46.91908835 38.53790247 47.73800714 32.88022629\n",
            " 45.95096268 43.19381381 47.11699291 48.5633962  49.71648182 39.43601733\n",
            " 49.35763938 33.52086272 35.97184602 49.30416095 48.48026797 48.92812507\n",
            " 44.48726967 48.17062478 33.51575646 37.45366978 48.0385607  47.41169588\n",
            " 33.35211815 48.01297109 48.50795262 41.06410987 47.28013626 31.23794064\n",
            " 49.74964633 29.59049074 47.41282459 49.6624151  48.88639154 39.61564435\n",
            " 47.56364698 48.30187621 47.98701615 17.84992613 33.03347204 38.65664384\n",
            " 46.43416595 45.50241273 43.07129268 41.38999823 48.56516746 33.9776465\n",
            " 47.80632919 41.46161998 24.34197559 43.51852872 48.04687059 48.33246578\n",
            " 26.39340968 40.13155705 45.60471119 24.85147376 41.46161998 41.46161998\n",
            " 46.57781171 44.00931202 27.25921144 48.75408272 47.8336248  36.77066599\n",
            " 48.88929134 43.8992707  17.86452359 39.34467858 46.97906116 49.11533524\n",
            " 26.50383285 48.02192473 45.38386046 40.75146042 48.31262497 23.67390252\n",
            " 43.94392841 46.4829175  40.20125168 49.00821448 28.94614932 40.77976951\n",
            " 47.73078272 41.47397375 46.9938755  49.09008078 48.38717657 42.94362525\n",
            " 48.77880599 30.38815374 43.24614136 48.43864441 47.82225825 31.86312785\n",
            " 49.43982432 49.67198168 48.61129067 49.47953442 45.26444773 45.33399796\n",
            " 32.0658233  44.72997231 49.26243143 48.95464759 48.45039371 43.71096573\n",
            " 39.300538   45.77618073 48.51581454 47.8858063  43.24498912 32.90792075\n",
            " 49.3440832  48.63156023 33.24123331 47.67266509 46.84534319 47.30443577\n",
            " 48.45807895 49.1002279  48.7084065  45.70409075 37.29901691 40.83145647\n",
            " 41.03165116 25.84335478 49.37189092 25.46036979 49.89434791 42.77515477\n",
            " 46.95080345 49.54167546 44.56148094 44.99620924 39.40484515 43.60319357\n",
            " 47.26127337 48.51546082 39.56742168 42.67510638 44.1772797  49.33254581\n",
            " 47.20904266 49.11586815 46.7004208  42.33989333 41.8951215  41.5097787\n",
            " 46.70663736 48.29165674 43.39936924 26.46017948 49.00237166 48.93082895\n",
            " 48.68910835 40.76842564 48.63712888 47.14410185 33.72542303 45.13283454\n",
            " 48.66226993 36.82559243 48.63056212 41.20945789 49.68585712 47.02835501\n",
            " 48.78104127 48.56160007 48.8172478  29.8438483  44.57554252 35.78926146\n",
            " 43.88160161 45.8315829  43.14274037 45.57182735 40.40210981 45.9772008\n",
            " 49.86758426 43.95473167 49.589511   40.56623856 42.53569649 45.52824832\n",
            " 49.28012287 42.03701239 42.83398106 22.55062031 29.14847867 49.53859374\n",
            " 40.26343094 42.26879237 39.79979466 42.54566683 32.25167363 48.63353105\n",
            " 33.76223762 48.24961298 48.03264278 37.31108422 46.1310655  49.80000745\n",
            " 31.84138509 48.39339084 49.66175576 36.7345119  49.67091599 46.78633657\n",
            " 38.55198462 33.53718723 26.36499525 49.12172405 32.28182776 39.86840054\n",
            " 49.21098973 46.71963046 44.11220551 48.94633364 43.86244849 49.20061909\n",
            " 48.07859934 46.76658937 46.78431558 32.68336286 29.43989925 41.46161998\n",
            " 44.49726752 47.87193305 48.90871991 36.19765249 41.46161998 46.51317905\n",
            " 43.9131839  42.79781123 48.02192473 48.22588888 47.76070155 47.4095917\n",
            " 47.41193842 48.39819348 48.40493294 48.08669902 47.2155013  39.53492912\n",
            " 48.09370133 47.43503005 32.95804602 46.47194894 40.91726094 43.69220167\n",
            " 48.75693838 47.52537683 44.04969261 47.04633828 44.84117303 32.31615227\n",
            " 49.09939143 45.96591437 41.28432578 38.47041367 44.66792832 47.82845324\n",
            " 46.60724302 24.46317707 36.13612157 44.04264125 48.29840569 48.1015688\n",
            " 49.14514339 45.33480304 49.02605152 47.13811343 49.13564807 35.10451365\n",
            " 41.46161998 43.52074062 47.72344114 49.24010089 49.13727061 47.70705218\n",
            " 45.76148891 49.42120141 49.33975152 39.17790849 43.78816368 46.77470099\n",
            " 41.55961748 33.11684731 22.44379429 31.30754694 32.38947271 48.90998089\n",
            " 49.20936521 40.84134776 25.86820922 41.41490517 39.10388683 49.37707153\n",
            " 41.82206156 45.87801071 33.53871645 49.62695474 33.12200997 44.90037692\n",
            " 45.4756503  49.4449506  48.7461475  43.02849289 48.90368385 35.56184509\n",
            " 35.33152247 41.95239273 44.25814092 45.39457051 39.9673224  44.52762489\n",
            " 48.92026682 46.31430956 40.59749116 12.71788481 41.46161998 48.16498061\n",
            " 30.00051023 39.44277668 42.49552341 41.46161998 43.73274981 33.55368853\n",
            " 25.41121629 49.75742533 48.51842099 48.53291223 43.90541876 47.96352377\n",
            " 46.88600701 26.99920202 31.71781271 44.43194518 49.02858553 25.80825284]\n",
            "selection [  4 445 951 353 412 327  77 669 698 196] (10,) [ 6.02072024 11.36840607 12.71788481 13.01305364 14.49699082 15.45178961\n",
            " 17.66080897 17.84992613 17.86452359 17.86882186]\n",
            "trainset before adding uncertain samples (330, 10) (330,)\n",
            "trainset after adding uncertain samples (340, 10) (340,)\n",
            "updated train set: (340, 10) (340,) unique(labels): [165 175] [0 1]\n",
            "val set: (962, 10) (962,)\n",
            "\n",
            "Train set: (340, 10)\n",
            "Validation set: (962, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 34\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.153 s \n",
            "\n",
            "Accuracy rate is 80.645161 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.88      0.87       321\n",
            "           1       0.64      0.59      0.61       113\n",
            "\n",
            "    accuracy                           0.81       434\n",
            "   macro avg       0.75      0.74      0.74       434\n",
            "weighted avg       0.80      0.81      0.80       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[283  38]\n",
            " [ 46  67]]\n",
            "--------------------------------\n",
            "val predicted: (962,) [1 1 1 0 1 1 0 0 0 0 1 1 1 0 1 0 1 0 0 0 1 1 1 1 1 1 1 0 1 0 0 0 1 1 0 0 0\n",
            " 1 1 0 0 0 1 1 0 1 1 1 0 0 1 1 1 1 0 1 0 1 1 0 0 1 1 1 1 1 1 0 1 0 1 0 0 1\n",
            " 1 0 0 0 1 0 0 1 1 0 1 0 1 0 0 1 1 1 0 0 0 0 1 0 1 0 1 1 1 0 0 1 0 0 0 0 0\n",
            " 0 0 0 1 0 1 1 0 1 1 0 1 1 1 1 0 1 1 1 1 1 1 0 1 0 1 1 0 1 0 1 1 0 1 1 1 1\n",
            " 0 0 1 0 0 0 1 1 1 1 0 1 1 0 1 0 0 1 1 0 1 1 1 0 0 0 0 0 0 0 1 1 1 0 0 1 0\n",
            " 0 0 0 0 0 1 1 1 0 1 0 0 0 1 0 1 1 0 1 1 0 1 1 0 0 0 0 0 0 1 0 1 1 1 1 1 1\n",
            " 0 0 1 1 0 1 0 1 1 1 1 0 1 1 0 1 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1 0 0 1 1 0\n",
            " 1 1 0 0 1 1 1 1 0 0 0 0 0 1 0 1 0 1 0 1 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 1\n",
            " 1 1 1 1 0 1 1 1 1 1 0 1 0 1 0 0 1 0 0 0 1 0 1 1 1 0 1 0 0 1 0 0 1 0 0 1 0\n",
            " 1 0 0 1 1 1 1 0 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 0 0 0 1 0 0 1\n",
            " 1 0 1 1 0 1 1 0 0 1 0 1 0 0 1 1 1 1 0 1 1 0 1 1 1 0 1 0 1 1 0 1 1 0 1 1 1\n",
            " 1 1 0 0 0 0 1 1 0 1 1 0 0 1 0 0 0 1 0 1 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1 1 0\n",
            " 1 0 1 0 1 1 0 0 0 0 0 0 1 1 1 1 1 1 0 0 0 1 1 1 0 1 0 1 0 0 1 0 0 0 0 0 0\n",
            " 1 1 0 0 1 0 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 0 0 1 0 0 1 1 1\n",
            " 0 0 1 1 1 0 1 0 1 0 0 0 0 1 0 1 0 1 0 1 1 0 1 1 0 1 1 0 0 1 1 1 1 0 1 1 1\n",
            " 0 1 1 1 0 0 0 1 0 1 1 1 1 1 1 1 0 1 0 0 0 1 0 1 1 0 0 0 1 0 1 0 1 1 1 0 1\n",
            " 1 0 1 1 0 1 0 0 0 1 0 0 1 0 0 1 0 1 1 1 1 1 1 0 0 0 1 0 1 1 1 1 0 1 1 1 0\n",
            " 1 1 0 1 0 1 0 0 1 1 0 1 1 1 1 0 1 1 0 1 1 1 0 1 0 0 1 0 0 1 1 1 1 1 0 1 1\n",
            " 1 1 1 1 0 0 0 1 0 1 1 0 1 0 0 0 1 0 0 0 1 1 0 0 1 0 0 0 1 0 0 1 1 0 1 0 0\n",
            " 0 1 1 1 0 1 0 1 1 1 1 1 1 0 0 0 1 0 1 1 0 1 0 0 1 1 0 0 0 0 1 0 0 1 0 1 0\n",
            " 0 1 0 0 1 0 1 1 1 0 0 0 1 1 0 0 1 0 1 0 1 1 0 1 0 1 0 1 1 0 0 0 0 1 1 0 0\n",
            " 1 0 1 1 1 1 0 1 0 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 0 0\n",
            " 1 0 0 1 1 1 0 1 1 1 0 1 0 0 0 0 0 1 0 0 1 1 0 1 0 1 1 1 0 0 0 1 1 0 0 1 1\n",
            " 0 0 0 1 0 1 1 1 1 1 0 1 1 0 0 1 1 1 0 1 0 1 1 0 1 1 1 0 1 1 1 1 1 1 1 0 1\n",
            " 0 1 1 0 1 1 0 1 1 0 0 1 0 1 1 0 0 0 0 1 0 1 1 0 1 0 1 0 1 0 1 1 1 1 1 0 0\n",
            " 1 0 0 0 1 0 0 0 1 0 1 0 0 1 1 0 1 0 1 1 1 1 0 1 1 1 0 0 1 1 0 1 1 1 0 0 0]\n",
            "probabilities: (962, 2) \n",
            " [1 1 1 0 1 1 0 0 0 0 1 1 1 0 1 0 1 0 0 0 1 1 1 1 1 1 1 0 1 0 0 0 1 1 0 0 0\n",
            " 1 1 0 0 0 1 1 0 1 1 1 0 0 1 1 1 1 0 1 0 1 1 0 0 1 1 1 1 1 1 0 1 0 1 0 0 1\n",
            " 1 0 0 0 1 0 0 1 1 0 1 0 1 0 0 1 1 1 0 0 0 0 1 0 1 0 1 1 1 0 0 1 0 0 0 0 0\n",
            " 0 0 0 1 0 1 1 0 1 1 0 1 1 1 1 0 1 1 1 1 1 1 0 1 0 1 1 0 1 0 1 1 0 1 1 1 1\n",
            " 0 0 1 0 0 0 1 1 1 1 0 1 1 0 1 0 0 1 1 0 1 1 1 0 0 0 0 0 0 0 1 1 1 0 0 1 0\n",
            " 0 0 0 0 0 1 1 1 0 1 0 0 0 1 0 1 1 0 1 1 0 1 1 0 0 0 0 0 0 1 0 1 1 1 1 1 1\n",
            " 0 0 1 1 0 1 0 1 1 1 1 0 1 1 0 1 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1 0 0 1 1 0\n",
            " 1 1 0 0 1 1 1 1 0 0 0 0 0 1 0 1 0 1 0 1 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 1\n",
            " 1 1 1 1 0 1 1 1 1 1 0 1 0 1 0 0 1 0 0 0 1 0 1 1 1 0 1 0 0 1 0 0 1 0 0 1 0\n",
            " 1 0 0 1 1 1 1 0 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 0 0 0 1 0 0 1\n",
            " 1 0 1 1 0 1 1 0 0 1 0 1 0 0 1 1 1 1 0 1 1 0 1 1 1 0 1 0 1 1 0 1 1 0 1 1 1\n",
            " 1 1 0 0 0 0 1 1 0 1 1 0 0 1 0 0 0 1 0 1 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1 1 0\n",
            " 1 0 1 0 1 1 0 0 0 0 0 0 1 1 1 1 1 1 0 0 0 1 1 1 0 1 0 1 0 0 1 0 0 0 0 0 0\n",
            " 1 1 0 0 1 0 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 0 0 1 0 0 1 1 1\n",
            " 0 0 1 1 1 0 1 0 1 0 0 0 0 1 0 1 0 1 0 1 1 0 1 1 0 1 1 0 0 1 1 1 1 0 1 1 1\n",
            " 0 1 1 1 0 0 0 1 0 1 1 1 1 1 1 1 0 1 0 0 0 1 0 1 1 0 0 0 1 0 1 0 1 1 1 0 1\n",
            " 1 0 1 1 0 1 0 0 0 1 0 0 1 0 0 1 0 1 1 1 1 1 1 0 0 0 1 0 1 1 1 1 0 1 1 1 0\n",
            " 1 1 0 1 0 1 0 0 1 1 0 1 1 1 1 0 1 1 0 1 1 1 0 1 0 0 1 0 0 1 1 1 1 1 0 1 1\n",
            " 1 1 1 1 0 0 0 1 0 1 1 0 1 0 0 0 1 0 0 0 1 1 0 0 1 0 0 0 1 0 0 1 1 0 1 0 0\n",
            " 0 1 1 1 0 1 0 1 1 1 1 1 1 0 0 0 1 0 1 1 0 1 0 0 1 1 0 0 0 0 1 0 0 1 0 1 0\n",
            " 0 1 0 0 1 0 1 1 1 0 0 0 1 1 0 0 1 0 1 0 1 1 0 1 0 1 0 1 1 0 0 0 0 1 1 0 0\n",
            " 1 0 1 1 1 1 0 1 0 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 0 0\n",
            " 1 0 0 1 1 1 0 1 1 1 0 1 0 0 0 0 0 1 0 0 1 1 0 1 0 1 1 1 0 0 0 1 1 0 0 1 1\n",
            " 0 0 0 1 0 1 1 1 1 1 0 1 1 0 0 1 1 1 0 1 0 1 1 0 1 1 1 0 1 1 1 1 1 1 1 0 1\n",
            " 0 1 1 0 1 1 0 1 1 0 0 1 0 1 1 0 0 0 0 1 0 1 1 0 1 0 1 0 1 0 1 1 1 1 1 0 0\n",
            " 1 0 0 0 1 0 0 0 1 0 1 0 0 1 1 0 1 0 1 1 1 1 0 1 1 1 0 0 1 1 0 1 1 1 0 0 0]\n",
            "std (962,) [43.36824417 46.08451867 40.68222142 45.98867532 46.78724389 39.31240075\n",
            " 28.11025321 41.66146867 49.16853202 49.65120125 45.28403365 49.41904072\n",
            " 38.40810161 45.84276393 36.93287193 41.9537581  40.81799964 44.22842777\n",
            " 48.21166249 32.93372455 46.18835674 10.19547834 19.94583268 46.36740548\n",
            " 48.28807252 45.62244279 48.38833163 43.79335518 48.40099146 32.85794075\n",
            " 36.06516905 47.02002063 44.63452168 44.36991828 49.62967423 49.63939879\n",
            " 36.81712801 40.97974251 25.93893679 39.99450565 49.10088487 35.02049034\n",
            " 41.51549229 38.41675966 27.36633137 47.35985716 37.93516559 48.74099873\n",
            " 44.9336097  47.29938519 49.58997009 36.51780772 48.54652488 45.64218736\n",
            " 47.88978532 48.11183767 43.36047544 42.97014156 44.50086182 47.73729033\n",
            " 49.6023746  11.62247065 47.41618739 47.834023   44.75570012 45.5718963\n",
            " 38.29093124 48.01145166 47.95433436 37.56055128 47.87572327 49.21872348\n",
            " 29.08075092 48.92510325 37.77189373 41.67296536 48.49167176 37.93696547\n",
            " 48.33820344 47.72803037 42.67028537 47.7008678  47.73719986 23.66506703\n",
            " 40.71422802 36.41559108 47.82050182 48.50628556 41.9537581  46.66485372\n",
            " 42.77644938 42.33838397 48.91646766 46.23187379 49.67811343 48.22933279\n",
            " 48.36657318 49.00629883 47.15850371 49.57949326 47.54385374 42.53414286\n",
            " 48.62745961 31.45242677 43.76775566 45.67486669 47.55314499 49.52897504\n",
            " 49.22725496 45.82423093 48.79414658 48.22761958 35.0876709  41.9537581\n",
            " 47.65211378 49.5510473  48.02304527 46.14339793 49.58973355 34.80907315\n",
            " 36.49374519 46.99193976 48.48260367 38.5078949  42.14782104 28.99842684\n",
            " 39.74129488 33.03597673 39.66027276 45.66866585 37.15888071 46.77905903\n",
            " 24.43584954 34.07446314 47.26994412 46.1146197  48.29388401 47.67586928\n",
            " 40.23463635 32.01269371 41.9537581  48.77423983 43.70851263 48.83226863\n",
            " 47.21519582 20.88204375 48.28285138 46.80797486 42.81400794 39.03152721\n",
            " 45.93575977 42.53032329 49.24829493 34.47946028 41.6073951  47.28941618\n",
            " 46.50624483 40.03426078 42.25428547 33.84122628 41.26398812 49.46572296\n",
            " 46.05104793 49.41017166 41.9537581  44.7948389  39.27111356 24.57055403\n",
            " 44.28651148 46.70184835 43.02524945 45.16012315 48.45236394 45.3412843\n",
            " 45.33247377 41.87109572 45.87938406 26.86581405 45.16575189 46.61567984\n",
            " 45.22276029 44.86215512 37.88269486 45.07771203 46.70709632 28.90672757\n",
            " 38.8057545  49.49672613 47.0692763  49.32346934 25.32017067 46.92419589\n",
            " 40.23793719 46.19202084 29.51532606 48.78137764 49.39960696 41.9537581\n",
            " 45.55230343 48.98269075 46.43064317 38.99184133 47.63365212 48.57783636\n",
            " 42.1572207  46.58238535 37.50393274 48.77282737 40.97736769 29.94923967\n",
            " 37.25754463 49.22913533 37.07314795 43.63024924 49.38070961 47.14753331\n",
            " 38.28882358 39.99502364 43.917028   44.15102231 44.49716272 43.8385378\n",
            " 48.26092122 48.07437903 45.34564417 46.27529849 39.64348936 48.56356594\n",
            " 48.93843762 46.93224247 43.88106156 48.18254423 46.17939264 46.65679143\n",
            " 30.91395594 48.77640569 49.05605881 48.46335535 43.59146882 47.99915886\n",
            " 48.44235001 48.29239544 49.49771448 46.88658359 43.67899673 48.25894422\n",
            " 35.04299475 46.58212301 33.05837976 42.54812041 44.0051716  46.57095889\n",
            " 41.49882527 30.69520925 49.33909639 47.08510543 43.65782378 39.62910727\n",
            " 45.79475485 46.24651622 47.73157263 37.9176891  45.8302053  35.27183862\n",
            " 45.67123947 47.28662359 49.41164723 46.57638213 41.9537581  49.41899815\n",
            " 41.9537581  35.6399812  29.70375064 28.4640792  48.68368465 41.9537581\n",
            " 47.72900832 49.56995758 27.83339615 44.50925758 48.97131849 43.78836375\n",
            " 47.54708292 48.23333761 49.21549129 29.23175639 46.91615899 46.34963161\n",
            " 34.73041482 32.35293327 48.18057424 49.72374316 48.38449842 45.71759153\n",
            " 31.08788961 45.4546195  46.6972332  47.85641378 47.08633698 28.6541396\n",
            " 30.4679475  41.3055849  45.70931586 46.20371398 45.2336291  45.67435688\n",
            " 49.21872348 47.78029393 35.84991413 47.89707577 43.51461594 43.09283491\n",
            " 43.89492089 49.65579198 47.35924438 29.15302585 26.08666486 31.19387504\n",
            " 43.22372103 46.39275878 30.34900311 49.31519011 49.13074982 46.3460436\n",
            " 49.54132511 46.81433316 41.9537581  48.85167489 47.14564668 45.78026698\n",
            " 48.77023205 47.26189722 41.1644598  48.1088657  48.76826098 49.17089441\n",
            " 45.8243945  46.1485942  35.50078533 48.31748638 19.34984588 41.25938403\n",
            " 47.06843792 43.78357025 39.50826725 24.00701717 39.224165   26.05895752\n",
            " 49.25324403 31.93138939 47.0972652  46.97021133 27.95156054 46.46588434\n",
            " 43.17176251 43.24879463 47.5350397  45.10167136 27.93727328 36.2699951\n",
            " 46.33545206 47.28082934 47.15086575 48.78575307 38.14259655 48.88616242\n",
            " 49.10638446 47.94800986 18.31390627 41.30324002 36.9764254  49.69697191\n",
            " 44.7041264  45.0086752  34.90644412 48.14324151 47.42128817 41.9537581\n",
            " 41.9537581  47.04315924 48.76516857 46.49925724 21.93170809 49.4441188\n",
            " 46.97765951 44.97452342 45.63718154 46.70263883 47.68114023 36.87095102\n",
            " 44.68912491 48.4474916  45.35143318 46.52313906 48.82756283 30.29767717\n",
            " 48.33609014 25.39706897 45.50439516 46.79358548 49.80133786 36.85668751\n",
            " 44.98290289 48.67410937 48.62678673 48.18179674 39.32015183 46.37121107\n",
            " 32.64677282 49.52912422 36.35328563 38.77777327 42.74996221 46.17537706\n",
            " 44.20060759 49.65470718 26.24893756 43.2384931  47.75657848 41.9537581\n",
            " 46.87921024 45.80514207 45.07662432 39.69863153 40.35417133 29.26572172\n",
            " 22.73011305 48.59177038 46.12214223  7.02339837 46.58948288 47.20341738\n",
            " 40.98915235 32.89921362 22.47148587 33.37573729 39.32015183 47.98868521\n",
            " 41.01207991 46.15021073 45.50070372 46.21561625 48.46242776 10.76017664\n",
            " 44.57009135 48.4221227  47.85256102 49.28731823 48.78878281 44.18367786\n",
            " 42.86791859 42.81001632 48.85999299 42.25108614 49.66118808 43.0086041\n",
            " 41.84173047 46.95558261 42.29706303 46.87464167 29.23980579 46.17592943\n",
            " 47.96866977 49.67070436 48.94758555 43.77908112 18.93069805 34.52605038\n",
            " 39.73190324 48.51526136 48.97877761 45.32734313 48.56593876 36.5201775\n",
            " 41.13494856 45.89544609 38.36447279 41.68187924 41.9537581  44.63587437\n",
            " 49.20505286 45.4447744  48.83110097 23.24828033 27.8503513  31.811256\n",
            " 41.9537581  45.03032332 38.35924908 45.46449488 48.80042649 42.00956314\n",
            " 49.75591226 49.06614075 31.8018831  47.55662574 40.26179757 24.1113543\n",
            " 47.85011827 38.75531708 48.57638317 44.06977295 34.42482508 43.79923104\n",
            " 41.08792084 46.3695129  43.44641997 49.54882053 45.07495046 48.86505501\n",
            " 42.20004186 45.9045998  47.03666134 44.52163686 15.37124867 45.45364561\n",
            " 48.08482197 35.07373633 41.9537581  41.9537581  37.77360329 29.87854984\n",
            " 45.57905664 43.98771713 46.48673477 46.8520435  48.06925531 36.52942756\n",
            " 46.59608843 26.30003262 47.93355439 48.47849812 31.40647265 47.15004811\n",
            " 47.10485063 46.63068829 46.59283106 47.63979199 45.52052235 48.84600429\n",
            " 35.75723912 41.25938403 45.27975452 47.07865341 44.90006884 31.17742999\n",
            " 48.45586284 48.507841   44.71418616 45.49577015 46.96539059 43.64420952\n",
            " 39.28580949 48.18866633 43.44641997 49.23901034 40.820076   48.90998796\n",
            " 49.28453169 49.58101242 43.42013694 31.51204815 44.1869347  47.88875603\n",
            " 49.27559669 43.51877232 36.44118028 48.48277672 39.97584118 35.95312819\n",
            " 48.75147773 34.42234028 46.04214057 49.40997469 42.6463987  44.22627629\n",
            " 28.07144368 44.35456961 20.40982039 47.54314283 48.08848695 29.46678485\n",
            " 49.48274222 34.19297281 39.79580882 47.85010258 46.77714968 47.60838133\n",
            " 35.22419869 46.63066103 43.28774053 48.8420057  37.76339803 32.12426451\n",
            " 46.54448008 48.11202996 39.34169622 45.4674591  48.50934824 38.994144\n",
            " 48.93469279 38.83282202 49.00088875 44.05440932 44.63216569 42.88168351\n",
            " 46.41565011 43.54899056 46.99356213 35.2260477  43.02067996  6.57761223\n",
            " 46.58968689 47.63250744 40.95390303 42.92226988 47.88330934 35.12638691\n",
            " 46.20694401 37.10568254 38.89187423 27.97992938 43.68427491 46.79711596\n",
            " 49.48551279 47.93645105 38.76760844 47.69488607 35.50936184 45.68058519\n",
            " 43.76308928 46.70914123 48.18727842 49.69770004 39.1808233  49.50510347\n",
            " 34.25606559 33.88941762 49.12172617 48.51087017 48.39757845 45.08534973\n",
            " 48.04057365 30.25187946 35.80903878 47.48678223 43.41782006 31.19371873\n",
            " 46.19870357 48.53440657 42.71562552 48.11555261 39.09733053 49.70388267\n",
            " 34.73495534 47.08633698 49.58931074 48.76262636 39.47609736 47.35435702\n",
            " 48.28179654 47.95842773 32.96776115 36.64938822 46.62772076 44.64641211\n",
            " 41.65150346 39.05645587 48.70276086 36.86996219 47.26358299 41.9537581\n",
            " 29.02700608 44.95458175 48.11666217 47.67627588 29.89455942 38.11902488\n",
            " 44.92830472 15.04793464 41.9537581  41.9537581  46.89872289 41.93876547\n",
            " 19.58223966 48.67749872 48.10767753 37.37239969 49.16552058 43.67360657\n",
            " 31.11279006 47.35979116 49.32526479 29.16500016 47.9753837  45.03233602\n",
            " 39.41592255 48.45533529 23.47038798 42.20137714 46.54218089 29.52564558\n",
            " 48.71940514 25.60399991 42.47344157 47.04820638 41.75704334 48.00312263\n",
            " 49.29422675 48.64606723 44.12590637 48.82524032 24.87759994 43.38525223\n",
            " 48.55391638 47.71395358 33.40511278 49.17513239 49.680969   48.65811275\n",
            " 49.38938224 43.42729678 46.39817728 27.63678043 45.55668964 49.02163798\n",
            " 49.03552346 48.5133991  44.95775619 36.99838747 44.74562953 48.40203172\n",
            " 48.192661   44.45865008 37.33841488 49.11506606 47.77229292 33.07200086\n",
            " 46.71178946 47.99097303 48.17553601 48.38789433 48.8128629  48.8787445\n",
            " 46.6875393  36.29669483 38.3223547  41.21412761 27.18448328 49.36696217\n",
            " 28.58628379 49.8088702  43.63693132 46.49869043 49.62626997 45.73021536\n",
            " 44.19638122 38.74925771 43.90236161 46.89139192 48.15200203 39.10828239\n",
            " 41.28817623 43.18977993 49.19333481 46.57764606 49.47546697 47.19111156\n",
            " 40.43731969 40.9927277  35.07651882 46.41836685 48.55416175 44.94795269\n",
            " 24.44590645 49.18332046 48.96944026 48.32503842 40.10369392 48.57638317\n",
            " 47.7097912  35.39690579 43.86107087 49.06722654 32.42221578 49.1182896\n",
            " 43.25581775 49.70082543 47.57496673 48.62718096 47.75440641 47.67367709\n",
            " 27.73466391 45.72682764 39.75832214 41.0285877  46.77101974 38.8899442\n",
            " 45.58380324 40.79472436 44.60237838 49.79818137 43.08207402 49.66744809\n",
            " 38.27628285 41.45257554 44.00938583 49.17281117 42.36333002 42.72141483\n",
            " 20.86279247 34.64748655 49.26505053 43.07061808 44.53786698 37.512252\n",
            " 42.98105766 36.22121732 48.78453425 29.56819226 47.67844826 48.39153048\n",
            " 34.86291935 46.33445274 49.77484501 34.57518972 48.55318101 49.40600225\n",
            " 31.34741414 49.56434384 46.21603907 36.82692538 33.75898476 22.88888689\n",
            " 48.90773085 29.57328531 36.95618329 48.9577933  47.10549279 44.10848029\n",
            " 49.04057779 45.25371468 49.07247539 48.18241676 43.75835692 46.71594569\n",
            " 30.41052869 24.3141917  41.9537581  45.07880401 47.18748708 48.07329545\n",
            " 39.10878952 41.9537581  45.49574779 44.78859635 40.81799964 47.9753837\n",
            " 48.59559621 47.29438554 47.18472571 47.19621656 48.47849812 48.48694078\n",
            " 48.49723169 47.42609203 36.11109672 48.27455619 46.94844311 34.3251431\n",
            " 46.17514473 37.21405424 44.54271241 48.51022288 47.06996883 44.64179193\n",
            " 46.92309963 46.16362134 33.4982567  48.68957916 44.6663848  43.19653639\n",
            " 36.29938404 44.00790448 48.00712397 46.09920993  2.84485396 40.76310071\n",
            " 45.49998689 48.05242692 48.4143417  48.94032986 45.63524797 48.84797424\n",
            " 46.36801525 49.10820593 34.69165331 41.9537581  43.64043904 47.441728\n",
            " 48.2720041  49.14652676 48.28061764 41.68717565 49.37927189 48.98786228\n",
            " 37.54299931 41.60998295 45.9222472  42.87918639 29.886568   29.0745434\n",
            " 34.4884935  32.50954253 48.85971158 49.09952956 38.96466976 26.99794497\n",
            " 40.84322247 39.83188341 49.34643573 37.00953145 43.95347469 38.6469375\n",
            " 49.66381905 31.53891775 41.53981647 41.40976385 49.52254057 49.29327959\n",
            " 41.5380543  48.47141377 23.18919076 32.22651559 42.98097367 41.5491824\n",
            " 44.10121334 38.526154   43.63493237 48.61072269 47.17865779 40.20987468\n",
            " 41.9537581  47.72716869 25.86013837 37.6418246  40.13465348 41.9537581\n",
            " 41.95101193 28.84457647 36.07444654 49.64658101 48.16707573 48.40481971\n",
            " 44.12608989 47.3683411  46.73169295 29.06575211 31.94222901 41.4258048\n",
            " 49.30448377 28.68582353]\n",
            "selection [886 611 429  21 443  61 679 514 368 466] (10,) [ 2.84485396  6.57761223  7.02339837 10.19547834 10.76017664 11.62247065\n",
            " 15.04793464 15.37124867 18.31390627 18.93069805]\n",
            "trainset before adding uncertain samples (340, 10) (340,)\n",
            "trainset after adding uncertain samples (350, 10) (350,)\n",
            "updated train set: (350, 10) (350,) unique(labels): [170 180] [0 1]\n",
            "val set: (952, 10) (952,)\n",
            "\n",
            "Train set: (350, 10)\n",
            "Validation set: (952, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 35\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.175 s \n",
            "\n",
            "Accuracy rate is 80.875576 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.89      0.87       321\n",
            "           1       0.65      0.58      0.61       113\n",
            "\n",
            "    accuracy                           0.81       434\n",
            "   macro avg       0.75      0.73      0.74       434\n",
            "weighted avg       0.80      0.81      0.80       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[286  35]\n",
            " [ 48  65]]\n",
            "--------------------------------\n",
            "val predicted: (952,) [1 1 1 0 1 1 0 0 0 0 1 1 1 0 1 0 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 0 0 1\n",
            " 1 0 0 0 1 1 0 1 1 1 0 0 1 1 1 1 0 1 0 1 1 0 0 1 1 1 1 1 0 1 0 1 0 0 1 1 0\n",
            " 0 0 1 0 0 1 1 0 1 0 1 0 0 1 1 1 0 0 0 0 1 0 1 0 1 1 1 0 0 1 0 0 0 0 0 0 0\n",
            " 0 1 0 1 1 0 1 1 0 1 1 1 1 0 1 1 1 1 1 1 0 1 0 1 1 0 1 0 1 1 0 1 1 1 1 0 0\n",
            " 1 0 0 0 1 1 1 1 0 1 1 0 1 0 0 1 1 0 1 1 1 0 0 0 0 0 0 0 1 1 1 0 0 1 0 0 0\n",
            " 0 0 0 1 1 1 0 1 0 0 0 1 0 1 1 0 1 1 0 1 1 0 0 0 0 0 0 1 0 1 1 1 1 1 1 0 0\n",
            " 1 1 0 1 0 1 1 1 1 0 1 1 0 1 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1 0 0 1 1 0 1 1\n",
            " 0 0 1 1 1 1 0 0 0 0 0 1 0 1 0 1 0 1 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 1 1 1\n",
            " 1 1 0 1 1 1 1 1 0 1 0 1 0 0 1 0 0 0 1 0 1 1 1 0 1 0 0 1 0 0 1 0 0 1 0 1 0\n",
            " 0 1 1 1 1 0 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 0 0 0 1 0 1 1 0 1\n",
            " 1 0 1 1 0 0 1 0 1 0 0 1 1 1 1 0 1 1 0 1 1 1 0 1 0 1 1 0 1 1 0 1 1 1 1 1 0\n",
            " 0 0 0 1 1 0 1 1 0 0 1 0 0 0 1 0 1 0 1 0 0 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 1\n",
            " 1 0 0 0 0 0 0 1 1 1 1 1 1 0 0 0 1 1 0 1 0 1 0 0 1 0 0 0 0 0 0 1 1 0 0 1 0\n",
            " 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 0 0 1 0 1 1 1 0 0 1 1 1 0 1\n",
            " 0 1 0 0 0 0 1 0 1 0 1 0 1 1 0 1 1 0 1 1 0 0 1 1 1 1 0 1 1 1 0 1 1 1 0 0 0\n",
            " 1 0 1 1 1 1 1 1 1 0 1 0 0 0 1 0 1 1 0 0 0 1 0 1 0 1 1 1 0 1 1 0 1 1 0 1 0\n",
            " 0 0 1 0 0 1 0 0 1 0 1 1 1 1 1 0 0 0 1 0 1 1 1 1 0 1 1 1 0 1 1 0 1 0 1 0 0\n",
            " 1 1 0 1 1 1 1 0 1 1 0 1 1 1 0 1 0 0 1 0 0 1 1 1 1 1 0 1 1 1 1 1 1 0 0 0 1\n",
            " 0 1 1 0 1 0 0 1 0 0 0 1 1 0 0 1 0 0 0 1 0 0 1 1 0 1 0 0 0 1 1 1 0 1 0 1 1\n",
            " 1 1 1 1 0 0 0 1 0 1 1 0 1 0 0 1 1 0 0 0 0 1 0 0 1 0 1 0 0 1 0 0 1 0 1 1 1\n",
            " 0 0 0 1 1 0 0 1 0 1 0 1 1 0 1 0 1 0 1 1 0 0 0 0 1 1 0 0 1 0 1 1 1 1 0 1 0\n",
            " 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 0 0 1 0 0 1 1 1 0 1 1\n",
            " 1 0 1 0 0 0 0 0 1 0 0 1 1 0 1 0 1 1 1 0 0 0 1 1 0 0 1 1 0 0 0 1 0 1 1 1 1\n",
            " 1 0 1 1 0 0 1 1 1 0 1 0 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 0 1 1 0 1 1 0\n",
            " 0 1 0 1 1 0 0 0 0 1 0 1 1 0 1 0 1 0 1 0 1 1 1 1 1 0 0 1 0 0 0 1 0 0 0 1 0\n",
            " 1 0 0 1 1 0 1 0 1 1 1 1 0 1 1 1 0 0 1 1 0 1 1 1 0 0 0]\n",
            "probabilities: (952, 2) \n",
            " [1 1 1 0 1 1 0 0 0 0 1 1 1 0 1 0 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 0 0 1\n",
            " 1 0 0 0 1 1 0 1 1 1 0 0 1 1 1 1 0 1 0 1 1 0 0 1 1 1 1 1 0 1 0 1 0 0 1 1 0\n",
            " 0 0 1 0 0 1 1 0 1 0 1 0 0 1 1 1 0 0 0 0 1 0 1 0 1 1 1 0 0 1 0 0 0 0 0 0 0\n",
            " 0 1 0 1 1 0 1 1 0 1 1 1 1 0 1 1 1 1 1 1 0 1 0 1 1 0 1 0 1 1 0 1 1 1 1 0 0\n",
            " 1 0 0 0 1 1 1 1 0 1 1 0 1 0 0 1 1 0 1 1 1 0 0 0 0 0 0 0 1 1 1 0 0 1 0 0 0\n",
            " 0 0 0 1 1 1 0 1 0 0 0 1 0 1 1 0 1 1 0 1 1 0 0 0 0 0 0 1 0 1 1 1 1 1 1 0 0\n",
            " 1 1 0 1 0 1 1 1 1 0 1 1 0 1 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1 0 0 1 1 0 1 1\n",
            " 0 0 1 1 1 1 0 0 0 0 0 1 0 1 0 1 0 1 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 1 1 1\n",
            " 1 1 0 1 1 1 1 1 0 1 0 1 0 0 1 0 0 0 1 0 1 1 1 0 1 0 0 1 0 0 1 0 0 1 0 1 0\n",
            " 0 1 1 1 1 0 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 0 0 0 1 0 1 1 0 1\n",
            " 1 0 1 1 0 0 1 0 1 0 0 1 1 1 1 0 1 1 0 1 1 1 0 1 0 1 1 0 1 1 0 1 1 1 1 1 0\n",
            " 0 0 0 1 1 0 1 1 0 0 1 0 0 0 1 0 1 0 1 0 0 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 1\n",
            " 1 0 0 0 0 0 0 1 1 1 1 1 1 0 0 0 1 1 0 1 0 1 0 0 1 0 0 0 0 0 0 1 1 0 0 1 0\n",
            " 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 0 0 1 0 1 1 1 0 0 1 1 1 0 1\n",
            " 0 1 0 0 0 0 1 0 1 0 1 0 1 1 0 1 1 0 1 1 0 0 1 1 1 1 0 1 1 1 0 1 1 1 0 0 0\n",
            " 1 0 1 1 1 1 1 1 1 0 1 0 0 0 1 0 1 1 0 0 0 1 0 1 0 1 1 1 0 1 1 0 1 1 0 1 0\n",
            " 0 0 1 0 0 1 0 0 1 0 1 1 1 1 1 0 0 0 1 0 1 1 1 1 0 1 1 1 0 1 1 0 1 0 1 0 0\n",
            " 1 1 0 1 1 1 1 0 1 1 0 1 1 1 0 1 0 0 1 0 0 1 1 1 1 1 0 1 1 1 1 1 1 0 0 0 1\n",
            " 0 1 1 0 1 0 0 1 0 0 0 1 1 0 0 1 0 0 0 1 0 0 1 1 0 1 0 0 0 1 1 1 0 1 0 1 1\n",
            " 1 1 1 1 0 0 0 1 0 1 1 0 1 0 0 1 1 0 0 0 0 1 0 0 1 0 1 0 0 1 0 0 1 0 1 1 1\n",
            " 0 0 0 1 1 0 0 1 0 1 0 1 1 0 1 0 1 0 1 1 0 0 0 0 1 1 0 0 1 0 1 1 1 1 0 1 0\n",
            " 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 0 0 1 0 0 1 1 1 0 1 1\n",
            " 1 0 1 0 0 0 0 0 1 0 0 1 1 0 1 0 1 1 1 0 0 0 1 1 0 0 1 1 0 0 0 1 0 1 1 1 1\n",
            " 1 0 1 1 0 0 1 1 1 0 1 0 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 0 1 1 0 1 1 0\n",
            " 0 1 0 1 1 0 0 0 0 1 0 1 1 0 1 0 1 0 1 0 1 1 1 1 1 0 0 1 0 0 0 1 0 0 0 1 0\n",
            " 1 0 0 1 1 0 1 0 1 1 1 1 0 1 1 1 0 0 1 1 0 1 1 1 0 0 0]\n",
            "std (952,) [42.09774392 46.01502564 38.36827056 44.23990979 46.41759495 37.87652042\n",
            " 32.05912281 38.82188732 49.1684462  49.5462039  44.26513798 49.25484959\n",
            " 33.63233655 46.07736348 37.31882818 42.34228834 40.60456187 44.6997526\n",
            " 47.62239363 31.35035613 47.00130184 18.2888484  45.59362501 48.05653814\n",
            " 44.89526846 48.06451692 41.41016712 48.15023551 35.56326277 36.49474913\n",
            " 45.95762087 44.78408096 43.46914383 49.52723382 49.58335218 37.70986097\n",
            " 43.13288549 32.77000409 40.55089694 49.20793017 37.97756772 39.40328991\n",
            " 30.50738226 26.79061889 46.1761539  37.18129835 48.37914538 45.67266469\n",
            " 48.18035752 49.47887088 38.72198358 47.92661942 45.88935886 47.78004661\n",
            " 48.23941178 42.68735239 39.55257197 44.32890723 47.51604894 49.56040512\n",
            " 48.20919192 48.17563009 40.82830145 45.8277347  34.78901989 47.24931501\n",
            " 48.19824214 39.1145606  47.47084972 49.0969079  25.29404254 48.36517026\n",
            " 37.02616241 39.89363696 48.66802554 40.63834723 48.54540139 47.53810898\n",
            " 31.62730706 46.48943206 48.0156695  24.983234   41.81200575 40.18372107\n",
            " 47.80624572 48.41115667 42.34228834 46.09808328 43.07929514 39.46770345\n",
            " 48.15154819 46.49443024 49.55276642 48.91678298 48.7958885  48.5398146\n",
            " 45.68635916 49.58755635 46.44653485 43.16572137 48.46181984 35.00571903\n",
            " 40.64523136 43.08484834 47.88053526 49.52996958 48.22599785 46.17372172\n",
            " 49.18199722 47.52104072 34.679412   42.34228834 46.77341313 49.67382259\n",
            " 47.6964315  44.64642398 49.53752118 40.38882794 35.8840108  46.7912607\n",
            " 47.57327697 37.32229327 41.08582495 18.14180071 36.46608999 23.78976413\n",
            " 38.59640748 46.13349668 37.48992306 46.46940059 27.47476661 35.36292713\n",
            " 46.19215929 42.94072529 48.20713018 47.42666212 44.94440531 33.4165087\n",
            " 42.34228834 48.84131253 44.94123086 48.34527753 46.80905742  4.89724205\n",
            " 48.32275695 45.78552726 45.04072916 38.42307925 41.92380522 44.22085375\n",
            " 48.37710327 34.58713218 42.06820941 47.66444044 46.61800397 39.47580752\n",
            " 40.65807444 30.57483477 38.77640169 49.19967677 45.84005034 49.3411561\n",
            " 42.34228834 43.45393937 41.75275564 23.97811735 44.95489339 45.57219736\n",
            " 44.45480192 45.38977702 48.24353447 44.2207133  46.93167385 40.34742437\n",
            " 47.11188944 20.93410611 44.48080511 46.62653747 46.03724846 45.36722684\n",
            " 38.90359162 42.50571808 46.24997862 32.07405956 33.45434426 49.22727878\n",
            " 48.18795159 49.27193882 18.76812731 47.9291634  40.02406275 46.97605537\n",
            " 31.60938812 49.26126076 49.51388892 42.34228834 44.9059439  48.92513033\n",
            " 45.8390897  38.51797851 46.93031014 48.49811213 43.91062557 46.22122582\n",
            " 36.98843653 48.77207747 41.50272398 32.47958676 37.28436344 49.34213607\n",
            " 40.56581709 44.49849307 49.24403316 47.79475906 39.32369002 38.81190576\n",
            " 42.96873811 44.14260708 44.65922006 43.8739313  47.07987421 48.09347073\n",
            " 45.94226909 45.20975901 39.11167449 47.6838395  48.74188406 47.90964893\n",
            " 44.96343801 48.16749677 45.94205431 46.26618939 32.13286324 48.4324981\n",
            " 48.75922973 48.15997472 41.87464667 47.87443282 48.05151923 48.18822269\n",
            " 49.18190878 46.89894101 43.42287518 48.01723809 29.83298542 46.66450923\n",
            " 33.83342756 42.89094404 46.45513051 46.63607827 41.24381311 26.99984393\n",
            " 49.59682251 47.66293581 46.14847112 42.21930447 46.11660619 43.76166097\n",
            " 46.74704801 38.39686932 45.22579066 38.06223889 46.28212946 47.32831558\n",
            " 49.00388962 44.87631035 42.34228834 48.91594154 42.34228834 34.65857593\n",
            " 34.13862414 35.95336657 48.33640553 42.34228834 46.14506262 49.50067464\n",
            " 31.52745882 40.82707342 49.1789181  42.96737999 45.0648075  47.34999203\n",
            " 48.49803366 24.42228231 46.52539927 44.56573642 38.11473894 33.01867445\n",
            " 48.70093276 49.58690117 48.31547816 45.38220822 38.88445694 47.30081482\n",
            " 45.10901745 48.09723106 46.93979291 35.04200958 26.88318707 42.71279922\n",
            " 46.73606022 46.93367652 45.4612843  43.29772059 49.0969079  47.11050926\n",
            " 38.75167726 48.52239013 44.10085526 41.2983091  47.04485381 49.67386007\n",
            " 42.75644287 35.50480738 33.78776011 31.87016579 44.74289568 46.7601278\n",
            " 24.73926879 48.88138438 49.24126222 46.58823406 49.61121587 47.95757386\n",
            " 42.34228834 48.71867256 47.35832015 45.59959821 48.80663179 46.38014284\n",
            " 38.30999173 48.5801688  47.72229296 48.41660278 46.22305214 47.34906712\n",
            " 38.17140857 47.61988849 20.66981973 39.77102662 46.65010665 44.83155006\n",
            " 40.02579643 27.93352267 39.58674001 37.55002983 48.90478188 31.82289247\n",
            " 47.17086669 45.82791068 18.51235083 46.21115055 45.55575149 45.34961025\n",
            " 47.98562721 42.29141856 23.06990033 35.25525012 45.40478478 46.54947508\n",
            " 46.08023698 48.91809223 37.49127948 49.33260638 48.74232674 48.60634021\n",
            " 40.22767153 38.11009466 49.6584706  44.26977118 44.9331151  37.44419634\n",
            " 47.62738228 48.04978459 42.34228834 42.34228834 46.35808354 48.400695\n",
            " 46.2098107  14.5724959  49.25599312 48.34896182 45.16374855 45.57723525\n",
            " 46.44510111 46.48533592 38.1350182  45.02523151 47.23321533 46.37778749\n",
            " 46.34245082 48.30376659 21.87719637 48.4324945  18.73308831 43.57872554\n",
            " 48.10750263 49.68863429 36.00569525 45.43353825 48.63546004 48.59341963\n",
            " 47.61012128 41.71535469 46.86745131 36.54143032 49.7134338  41.19979348\n",
            " 40.41794878 42.05051109 47.85128916 42.83127892 49.47722296 28.55598754\n",
            " 44.88153276 46.91963949 42.34228834 46.82622608 47.58024404 43.45177049\n",
            " 36.86348001 44.12892207 34.9355579  31.49250039 48.07409201 43.80019338\n",
            " 48.02452537 47.12010186 40.59986326 31.70268297 25.99750542 34.00905783\n",
            " 41.71535469 48.29363635 41.01663522 45.78095455 47.5220293  45.56868276\n",
            " 48.05998378 44.28440842 47.84668977 48.64866115 49.49538242 48.93564319\n",
            " 42.50261273 42.07703733 43.18449667 47.70257239 42.54517421 49.7058634\n",
            " 37.04892641 43.71000803 47.47051112 41.89442219 46.46965481 12.99894698\n",
            " 47.29571782 48.08778802 49.67821846 48.15127351 42.72941951 35.83166346\n",
            " 38.81277726 49.09078181 48.69355861 45.38975401 48.91445816 34.19859822\n",
            " 44.91308322 45.5538632  38.65297471 40.73719131 42.34228834 42.14520797\n",
            " 48.95035634 44.95080634 49.13136546 20.09762367 24.55417993 35.11400763\n",
            " 42.34228834 47.87350968 39.17422569 46.18466011 48.69316571 40.65258053\n",
            " 49.68654976 47.76767665 32.68835084 47.51531617 39.09199366 23.9231082\n",
            " 45.67587994 38.83800433 48.20085465 42.28740208 32.53348241 42.64837371\n",
            " 40.82668187 45.26490816 43.8546989  49.18618642 43.76995445 48.64418231\n",
            " 41.91729213 46.03802119 47.49123315 41.9798412  44.72345984 48.04300759\n",
            " 34.49421752 42.34228834 42.34228834 36.12297272 29.74458294 45.41008202\n",
            " 44.93401788 42.27724798 46.61120106 47.16908075 28.21177311 44.30426576\n",
            " 30.18106082 45.34742294 47.58201649 35.18492036 47.04745914 43.70778544\n",
            " 47.24682629 45.28853173 48.26125724 45.45173308 48.64976456 36.07035529\n",
            " 39.77102662 45.64023262 45.6887821  42.14245481 34.87751223 48.44456968\n",
            " 48.32403827 43.93471248 44.92306583 46.91450928 42.69982097 37.97236173\n",
            " 47.48884892 43.8546989  49.02526195 42.07562159 48.87468807 49.11835043\n",
            " 49.56969682 39.88467868 33.29457283 40.90922248 47.94103658 49.05571574\n",
            " 44.52172556 36.53668373 47.72542538 40.25882352 36.83554319 48.04203511\n",
            " 36.24053793 45.9750137  49.07972632 44.20290831 43.73603073 25.21424893\n",
            " 46.20482279 21.27414158 46.85130719 48.53013963 21.98821656 49.57862863\n",
            " 33.42399601 39.5571117  47.97813018 46.70438829 48.47030849 37.82127309\n",
            " 46.30496288 43.08528119 48.33918624 27.94872498 29.35662859 46.31569026\n",
            " 48.12399586 42.01925655 44.78816974 49.02281804 34.32440946 48.89519862\n",
            " 37.25444996 47.55137813 41.65942508 44.73820379 36.67930963 42.60772867\n",
            " 44.30183087 46.50578638 30.48156845 40.79864723 46.67617051 46.62988403\n",
            " 42.48790975 44.35798816 47.87274163 32.78068328 45.86479052 37.90545345\n",
            " 44.87819153 31.44378872 45.45135742 45.39006076 49.56767206 48.38417956\n",
            " 36.28773904 47.92718726 33.98012906 46.50169452 41.76425138 47.0560129\n",
            " 47.83965353 49.61585295 39.03262069 48.97203901 37.46525266 36.63839367\n",
            " 49.052852   46.92599508 47.64312482 46.22032474 47.47736769 31.66443607\n",
            " 37.64043225 46.50976797 47.22056237 31.05129348 46.75044119 47.86669489\n",
            " 40.10231335 48.55059069 36.30386037 49.44422071 34.60665869 46.93979291\n",
            " 49.533203   48.5590293  36.0440676  46.8668228  48.48151247 46.4318932\n",
            " 35.04390358 40.29385115 45.8303613  45.27934013 41.829304   41.76934147\n",
            " 48.12965067 37.85328675 45.99779336 42.34228834 23.35779916 43.99816373\n",
            " 48.01464093 47.2228498  27.8083334  35.64808244 42.11428068 42.34228834\n",
            " 42.34228834 46.8234639  43.7906958  27.26644847 49.14074649 47.87240216\n",
            " 32.75792572 48.78183404 40.26862597 35.02799408 47.11176659 48.81437577\n",
            " 34.86718415 46.74713681 41.89016904 41.9891908  48.47484878 10.69818132\n",
            " 42.6407863  45.89444926 36.05692266 48.95740772 22.41545046 39.53140397\n",
            " 46.59446025 43.32632375 43.94149998 49.19695731 48.37555006 42.4427095\n",
            " 48.38302016 24.53964776 44.84830719 47.67883076 46.78006252 29.70917257\n",
            " 49.03159976 49.3900073  48.73304593 49.55001603 46.63302224 45.79850646\n",
            " 34.67697875 44.45485733 49.20569668 48.884248   48.70581489 45.65234786\n",
            " 39.67651195 45.77892465 48.17238752 47.82227889 44.63865736 37.53216477\n",
            " 49.21673587 48.24537395 37.9680943  47.81521903 48.39351448 46.75007767\n",
            " 48.70696672 48.92480584 48.81379254 46.09675717 38.54177133 40.1564278\n",
            " 41.16410913 21.97006197 49.47380139 31.35958145 49.88202217 45.38919928\n",
            " 46.30760745 49.33759626 45.13017477 43.48684338 36.16849791 43.32301211\n",
            " 46.3814349  47.74945436 39.90710197 43.37896112 41.50995964 48.7207691\n",
            " 44.4305077  48.44149613 46.76735826 44.01958091 40.58458598 35.01146723\n",
            " 45.73608965 48.38840395 41.40048005 23.29343821 48.65909209 49.15909614\n",
            " 47.77975602 31.36589861 48.20085465 46.1678157  38.39356354 42.96837391\n",
            " 48.38456866 33.53264688 48.8519934  41.98902201 49.5547291  46.18706058\n",
            " 47.67105983 48.26023524 48.1357535  20.37139835 44.83173498 37.20168541\n",
            " 41.93270676 45.78142704 42.98253221 46.91141464 41.93987755 44.82730765\n",
            " 49.75669152 44.32928811 49.53243564 35.26983227 39.23519756 45.09820004\n",
            " 49.12560392 44.33872097 41.70852095 25.55681474 35.60644001 49.49373633\n",
            " 42.34298943 44.21784193 37.48257875 43.36695525 34.11178164 48.73927501\n",
            " 32.29768191 47.86176469 48.10654998 32.09375295 46.7865134  49.64195167\n",
            " 38.35573689 47.42212514 49.28016235 33.93998791 49.68696199 45.91140625\n",
            " 37.09287666 33.5729296  29.78079496 48.94451267 24.93349987 30.24928571\n",
            " 49.32256567 47.54287136 44.7273145  49.05292421 45.05424683 48.853499\n",
            " 47.97714045 45.00236111 45.46049109 36.89462387 27.32979533 42.34228834\n",
            " 45.08485064 46.26344136 49.08232055 30.41066251 42.34228834 46.15761428\n",
            " 45.72076599 40.60456187 46.74713681 48.09017291 46.49251203 47.61589996\n",
            " 46.63064325 47.58201649 48.38597614 48.5403963  45.99065611 36.76645154\n",
            " 47.41066568 46.08726077 35.86586291 43.87182555 37.59500701 41.81893334\n",
            " 48.4828191  47.75413653 44.06461201 47.79869456 45.37879925 31.61961957\n",
            " 48.92495495 45.25369801 41.59136521 36.80802199 44.48924826 46.91827907\n",
            " 45.60575268 36.40576053 46.29932242 48.37664215 47.59280329 48.98875285\n",
            " 41.39973985 49.1876033  47.73160277 49.12292747 37.45171104 42.34228834\n",
            " 44.35744689 46.5009422  48.28129572 48.88321981 46.69117151 44.47412064\n",
            " 48.96951434 48.12261786 33.49058673 39.39090796 42.94665389 41.79691843\n",
            " 25.50248475 25.08832755 23.52471302 31.02318704 48.82184008 48.05012709\n",
            " 40.1816874  33.82203036 43.09205865 40.53415282 49.36635767 38.02238403\n",
            " 43.53246748 40.62054599 49.09416318 25.50111964 41.99741494 42.74442713\n",
            " 49.41180921 48.8752112  38.62123959 48.76499312 30.95197798 33.62466703\n",
            " 44.7739094  42.96451564 41.37773538 35.95576173 44.73050967 48.60363281\n",
            " 46.98544728 38.50636295 42.34228834 47.7579192  31.12691981 40.90344849\n",
            " 42.63776019 42.34228834 41.92640386 29.27692831 33.7305485  49.77716132\n",
            " 47.9424341  48.07079593 42.12318999 47.8939926  47.13287835 25.98076354\n",
            " 27.16540773 38.97722469 49.09838951 24.49564199]\n",
            "selection [143 689 455 379 123  21 350 394 188 477] (10,) [ 4.89724205 10.69818132 12.99894698 14.5724959  18.14180071 18.2888484\n",
            " 18.51235083 18.73308831 18.76812731 20.09762367]\n",
            "trainset before adding uncertain samples (350, 10) (350,)\n",
            "trainset after adding uncertain samples (360, 10) (360,)\n",
            "updated train set: (360, 10) (360,) unique(labels): [176 184] [0 1]\n",
            "val set: (942, 10) (942,)\n",
            "\n",
            "Train set: (360, 10)\n",
            "Validation set: (942, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 36\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.197 s \n",
            "\n",
            "Accuracy rate is 81.105991 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.89      0.87       321\n",
            "           1       0.65      0.59      0.62       113\n",
            "\n",
            "    accuracy                           0.81       434\n",
            "   macro avg       0.76      0.74      0.75       434\n",
            "weighted avg       0.81      0.81      0.81       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[285  36]\n",
            " [ 46  67]]\n",
            "--------------------------------\n",
            "val predicted: (942,) [1 1 1 0 1 1 0 0 0 0 1 1 1 0 1 0 1 0 0 0 1 1 1 1 1 0 1 0 0 0 1 1 0 0 0 1 1\n",
            " 0 0 0 1 1 0 1 1 1 0 0 1 1 1 1 0 1 0 1 1 0 0 1 1 1 1 1 0 1 0 1 0 0 1 1 0 0\n",
            " 0 1 0 0 1 1 0 1 0 1 0 0 1 1 1 0 0 0 0 1 0 1 0 1 1 1 0 0 1 0 0 0 0 0 0 0 0\n",
            " 1 0 1 1 0 1 1 0 1 1 1 0 1 1 1 1 1 1 0 1 0 1 1 0 1 0 1 1 0 1 1 1 0 0 1 0 0\n",
            " 0 1 1 1 1 0 1 1 0 1 0 0 1 1 0 1 1 1 0 0 0 0 0 0 0 1 1 1 0 0 1 0 0 0 0 0 0\n",
            " 1 1 0 1 0 0 0 1 0 1 1 0 1 1 0 1 1 0 0 0 0 0 0 1 0 1 1 1 1 1 1 0 0 1 1 0 1\n",
            " 0 1 1 1 1 0 1 1 0 1 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1 0 0 1 1 0 1 1 0 0 1 1\n",
            " 1 1 0 0 0 0 0 1 0 1 0 1 0 1 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 1\n",
            " 1 1 1 1 0 1 0 1 0 0 1 0 0 0 1 0 1 1 1 0 1 0 0 1 0 0 1 0 0 1 0 1 0 0 1 1 1\n",
            " 1 0 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 0 0 0 1 0 1 1 0 1 1 0 1 1 0\n",
            " 0 1 0 1 0 1 1 1 1 0 1 1 0 1 1 1 0 1 1 1 0 1 1 0 1 1 1 1 1 0 0 0 0 1 1 0 1\n",
            " 1 0 0 1 0 0 0 1 0 1 0 1 0 0 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 1 1 0 0 0 0 0 0\n",
            " 1 1 1 1 1 0 0 0 1 1 0 1 0 1 0 0 1 0 0 0 0 0 0 1 1 0 1 0 1 1 1 0 1 0 0 1 1\n",
            " 1 1 1 1 1 1 1 1 0 1 1 0 0 1 0 0 1 0 1 1 1 0 0 1 1 1 0 1 0 1 0 0 0 0 1 0 1\n",
            " 0 1 0 1 1 0 1 1 0 1 1 0 0 1 1 1 1 0 1 1 1 0 1 1 1 0 0 0 1 0 1 1 1 1 1 1 1\n",
            " 0 1 0 0 0 1 0 1 1 0 0 0 1 0 1 0 1 1 1 0 1 1 0 1 1 0 1 0 0 0 1 0 0 1 0 0 1\n",
            " 0 1 1 1 1 1 0 0 0 1 0 1 1 1 1 0 1 1 1 0 1 1 0 1 0 1 0 0 1 1 0 1 1 1 1 0 1\n",
            " 1 0 1 1 1 0 1 0 0 1 0 0 1 1 1 1 1 0 1 1 1 1 1 1 0 0 0 1 0 1 1 0 1 0 0 1 0\n",
            " 0 0 1 1 0 0 1 0 0 0 1 0 0 1 0 1 0 0 0 1 1 1 0 1 0 1 1 1 1 1 1 0 0 0 1 0 1\n",
            " 1 0 1 0 0 1 1 0 0 0 0 1 0 0 1 0 1 0 0 1 0 0 1 0 1 1 1 0 0 0 1 1 0 0 1 0 1\n",
            " 0 1 1 0 1 0 1 0 1 1 0 0 0 0 1 1 0 0 1 0 1 1 1 1 0 1 0 1 0 0 0 0 0 1 1 1 1\n",
            " 1 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 0 0 1 0 0 1 1 1 0 1 1 1 0 1 0 0 0 0 0 1 0\n",
            " 0 1 1 0 1 0 1 1 1 0 0 0 1 1 0 0 1 1 0 0 0 1 0 1 1 1 1 1 0 1 1 0 0 1 1 1 0\n",
            " 1 0 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 0 1 1 0 1 1 0 0 1 0 1 1 0 0 0 0 1\n",
            " 0 1 1 0 1 0 1 0 1 0 1 1 1 1 1 0 0 1 0 0 0 1 0 0 0 1 0 1 0 0 1 1 0 1 0 1 1\n",
            " 1 1 0 1 1 1 0 0 1 1 0 1 1 1 0 0 0]\n",
            "probabilities: (942, 2) \n",
            " [1 1 1 0 1 1 0 0 0 0 1 1 1 0 1 0 1 0 0 0 1 1 1 1 1 0 1 0 0 0 1 1 0 0 0 1 1\n",
            " 0 0 0 1 1 0 1 1 1 0 0 1 1 1 1 0 1 0 1 1 0 0 1 1 1 1 1 0 1 0 1 0 0 1 1 0 0\n",
            " 0 1 0 0 1 1 0 1 0 1 0 0 1 1 1 0 0 0 0 1 0 1 0 1 1 1 0 0 1 0 0 0 0 0 0 0 0\n",
            " 1 0 1 1 0 1 1 0 1 1 1 0 1 1 1 1 1 1 0 1 0 1 1 0 1 0 1 1 0 1 1 1 0 0 1 0 0\n",
            " 0 1 1 1 1 0 1 1 0 1 0 0 1 1 0 1 1 1 0 0 0 0 0 0 0 1 1 1 0 0 1 0 0 0 0 0 0\n",
            " 1 1 0 1 0 0 0 1 0 1 1 0 1 1 0 1 1 0 0 0 0 0 0 1 0 1 1 1 1 1 1 0 0 1 1 0 1\n",
            " 0 1 1 1 1 0 1 1 0 1 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1 0 0 1 1 0 1 1 0 0 1 1\n",
            " 1 1 0 0 0 0 0 1 0 1 0 1 0 1 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 1\n",
            " 1 1 1 1 0 1 0 1 0 0 1 0 0 0 1 0 1 1 1 0 1 0 0 1 0 0 1 0 0 1 0 1 0 0 1 1 1\n",
            " 1 0 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 0 0 0 1 0 1 1 0 1 1 0 1 1 0\n",
            " 0 1 0 1 0 1 1 1 1 0 1 1 0 1 1 1 0 1 1 1 0 1 1 0 1 1 1 1 1 0 0 0 0 1 1 0 1\n",
            " 1 0 0 1 0 0 0 1 0 1 0 1 0 0 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 1 1 0 0 0 0 0 0\n",
            " 1 1 1 1 1 0 0 0 1 1 0 1 0 1 0 0 1 0 0 0 0 0 0 1 1 0 1 0 1 1 1 0 1 0 0 1 1\n",
            " 1 1 1 1 1 1 1 1 0 1 1 0 0 1 0 0 1 0 1 1 1 0 0 1 1 1 0 1 0 1 0 0 0 0 1 0 1\n",
            " 0 1 0 1 1 0 1 1 0 1 1 0 0 1 1 1 1 0 1 1 1 0 1 1 1 0 0 0 1 0 1 1 1 1 1 1 1\n",
            " 0 1 0 0 0 1 0 1 1 0 0 0 1 0 1 0 1 1 1 0 1 1 0 1 1 0 1 0 0 0 1 0 0 1 0 0 1\n",
            " 0 1 1 1 1 1 0 0 0 1 0 1 1 1 1 0 1 1 1 0 1 1 0 1 0 1 0 0 1 1 0 1 1 1 1 0 1\n",
            " 1 0 1 1 1 0 1 0 0 1 0 0 1 1 1 1 1 0 1 1 1 1 1 1 0 0 0 1 0 1 1 0 1 0 0 1 0\n",
            " 0 0 1 1 0 0 1 0 0 0 1 0 0 1 0 1 0 0 0 1 1 1 0 1 0 1 1 1 1 1 1 0 0 0 1 0 1\n",
            " 1 0 1 0 0 1 1 0 0 0 0 1 0 0 1 0 1 0 0 1 0 0 1 0 1 1 1 0 0 0 1 1 0 0 1 0 1\n",
            " 0 1 1 0 1 0 1 0 1 1 0 0 0 0 1 1 0 0 1 0 1 1 1 1 0 1 0 1 0 0 0 0 0 1 1 1 1\n",
            " 1 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 0 0 1 0 0 1 1 1 0 1 1 1 0 1 0 0 0 0 0 1 0\n",
            " 0 1 1 0 1 0 1 1 1 0 0 0 1 1 0 0 1 1 0 0 0 1 0 1 1 1 1 1 0 1 1 0 0 1 1 1 0\n",
            " 1 0 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 0 1 1 0 1 1 0 0 1 0 1 1 0 0 0 0 1\n",
            " 0 1 1 0 1 0 1 0 1 0 1 1 1 1 1 0 0 1 0 0 0 1 0 0 0 1 0 1 0 0 1 1 0 1 0 1 1\n",
            " 1 1 0 1 1 1 0 0 1 1 0 1 1 1 0 0 0]\n",
            "std (942,) [41.83797499 46.00734306 38.30712163 41.91761753 44.29248973 35.60215946\n",
            " 31.02141455 39.82955931 49.24572705 49.77920101 44.8079874  49.32409156\n",
            " 35.6370598  45.65135492 35.92484426 41.02988418 36.24397316 45.06175977\n",
            " 47.49556357 36.38581378 44.66904087 40.71948672 48.34003926 44.70159964\n",
            " 47.33711477 38.56594962 48.15847672 35.25475361 40.26663079 44.31886542\n",
            " 42.14839882 43.45932643 49.43394498 49.48847368 37.42484209 43.57115628\n",
            " 25.22426696 40.47982215 48.9964024  36.39012508 35.01197704 24.64027051\n",
            " 27.16587256 44.04305652 33.01487382 48.22575966 45.8894776  47.16408473\n",
            " 49.38156586 32.30684633 47.58689337 44.87802491 47.87884906 47.45843954\n",
            " 39.61848057 36.0266188  44.69201614 46.03633877 49.67520243 47.17485093\n",
            " 47.43626641 41.81979155 44.16452198 31.86971383 46.22889527 46.85088268\n",
            " 38.35857037 45.81253849 48.97632873 26.96829039 48.01929119 30.03256614\n",
            " 35.44229622 48.21694049 39.04365387 48.21343274 47.67469558 35.3373917\n",
            " 44.23416927 46.75672319 30.6947188  38.28448245 39.47101517 48.30739774\n",
            " 47.5255271  41.02988418 42.90049597 42.4592614  39.48396799 48.6866307\n",
            " 44.1804282  49.66809287 47.99954933 48.72273381 48.49611668 43.2896601\n",
            " 49.66836378 47.04867447 42.88808263 48.73425665 30.74937835 38.17273107\n",
            " 44.98057537 47.76918467 49.41019262 48.57932132 47.54200346 48.94603593\n",
            " 48.43849001 35.42527566 41.02988418 46.60027188 49.62929746 47.30850138\n",
            " 44.50201723 49.60788054 34.46673907 35.19816863 47.36391348 47.0891815\n",
            " 39.14072894 41.80746182 30.26133261 22.04633814 37.34058986 45.96329124\n",
            " 39.33509989 46.44385534 23.67447377 34.49865663 46.17978978 46.23309257\n",
            " 46.20764175 47.19116474 42.94184697 34.61600699 41.02988418 48.54261382\n",
            " 44.41263269 48.35301171 47.23844811 47.52051919 42.69858143 45.17517014\n",
            " 41.27637779 44.9683544  41.59414241 48.66388054 29.50229494 43.98326753\n",
            " 47.36332291 46.20135495 41.24832233 45.83180717 33.04926901 39.80526561\n",
            " 49.45342744 46.00893479 49.37968247 41.02988418 42.29071204 39.21418445\n",
            " 26.13692787 42.44345611 44.33377503 44.23026409 42.78826524 47.58283932\n",
            " 42.11249178 45.3568232  41.07715268 47.0145906  24.11753182 42.8508525\n",
            " 47.28584728 46.66097804 47.31155967 39.28640716 45.07637963 45.86775131\n",
            " 29.36953213 36.68717935 48.92120643 47.95278796 49.34259768 47.44627776\n",
            " 42.12944254 46.68840288 29.03384074 49.27008771 48.99002229 41.02988418\n",
            " 45.62749632 48.96959101 44.7015362  38.30868005 46.32329027 48.0163296\n",
            " 43.68264473 46.72192664 41.16609905 48.70332896 37.58732524 33.05878014\n",
            " 39.94959897 49.53823268 39.89370151 38.72312854 49.04273726 46.08619373\n",
            " 37.63516897 37.40056239 44.16951878 43.93787471 46.72635339 43.51639296\n",
            " 46.95080702 48.0055175  43.76810096 44.4428153  35.76543164 48.1799147\n",
            " 49.13540734 47.50668704 44.1773688  47.48499117 42.82995855 46.79348043\n",
            " 29.83286304 47.95749641 48.93934835 48.72889369 39.3797273  47.69879617\n",
            " 47.54941703 47.58356488 49.31350563 45.16452562 40.1964094  48.35522402\n",
            " 27.90712058 46.35495824 34.17763989 38.54626419 45.35650669 45.82411104\n",
            " 37.97220578 25.9878068  49.32755964 44.96125648 42.53292902 40.32407713\n",
            " 47.30194774 42.39825824 46.89447135 36.41395251 43.89547102 37.08799533\n",
            " 44.06571949 46.0768463  49.01331861 46.0515222  41.02988418 49.27048255\n",
            " 41.02988418 34.04625743 29.40929523 35.08726951 48.56104356 41.02988418\n",
            " 46.98704676 49.70775641 23.30869298 38.9586531  49.03443591 43.25056688\n",
            " 47.50185315 46.79817496 48.65849425 14.60592168 44.57410456 44.11713521\n",
            " 37.4092552  32.14601116 47.90869488 49.77600627 48.31686584 46.11831874\n",
            " 37.12361937 46.85726518 45.94322111 47.13921244 47.13081326 31.35732306\n",
            " 32.19586869 43.15806164 47.24610089 47.88994709 45.24574177 43.88545809\n",
            " 48.97632873 46.40964544 33.92088225 48.06856821 44.62087666 40.70180276\n",
            " 45.87230388 49.49482922 43.96470398 29.96617849 31.97849657 39.42556915\n",
            " 41.48038274 46.72775041 22.04517548 48.96950214 48.75747613 46.60792073\n",
            " 49.56482904 46.61816303 41.02988418 47.65136539 45.15727127 46.07424076\n",
            " 48.59054886 47.16057319 45.71315135 48.14596286 48.46617108 48.60694016\n",
            " 43.10127866 47.17940169 36.87977798 47.42750717 22.50179298 36.74126742\n",
            " 45.13908256 44.46093003 40.38984279 17.61244169 34.43612594 35.44362117\n",
            " 48.60032379 26.66068823 45.73982956 45.17362199 45.01763092 46.055869\n",
            " 44.58012827 48.2964825  43.8383298  23.87384514 30.65669493 43.69367197\n",
            " 47.39663742 46.65815606 48.16863235 33.55926038 48.95393136 48.7797091\n",
            " 47.43373681 38.50375114 36.10870982 49.75894251 44.48293786 43.93483259\n",
            " 38.57055134 46.02109227 47.6958057  41.02988418 41.02988418 45.63892841\n",
            " 48.39019279 45.94288567 49.45997489 47.84738141 45.434018   46.12132566\n",
            " 46.43839467 48.30411763 37.87336735 45.64876472 47.32543252 44.40065617\n",
            " 46.66709086 47.70773413 18.5154261  47.84369313 45.2288502  46.63005452\n",
            " 49.69214933 33.90616772 45.485703   48.80464193 48.02519986 46.3761009\n",
            " 40.6256428  45.4662043  33.79582116 49.52745884 42.18715405 36.71509214\n",
            " 41.84104051 47.11101359 42.77952076 49.49156409 27.72099703 40.7390632\n",
            " 47.96220896 41.02988418 46.70409778 47.19284931 42.38180629 40.73465556\n",
            " 37.12476825 34.33107849 23.41436445 47.64938397 45.39611089 47.66997879\n",
            " 45.80702718 41.1426231  31.4465108  26.27135108 35.92173964 40.6256428\n",
            " 48.44731117 43.28442682 43.65462477 45.71558946 44.09483947 47.93385494\n",
            " 43.59363847 46.92290165 48.47176993 49.47461989 49.1210837  41.02055617\n",
            " 41.94206521 44.66416814 47.23308719 43.82784503 49.66317083 41.86176273\n",
            " 43.27606361 46.99270836 45.68606477 44.74308425 47.49106942 47.94327016\n",
            " 49.67458099 48.25453035 40.84004755 38.23430078 38.07290634 48.65121541\n",
            " 48.40320509 43.65819313 48.75348352 36.69348354 44.73711956 45.91373124\n",
            " 41.2053411  42.62587753 41.02988418 42.72896633 48.84034967 46.01370385\n",
            " 48.77790318 21.91104933 27.17482319 41.02988418 46.9584515  40.37491468\n",
            " 44.7001272  48.98753738 38.14762684 49.69304587 48.92765927 36.65823756\n",
            " 47.14133448 37.04422616 28.15775082 46.4255189  35.95330877 47.65105717\n",
            " 42.25433075 36.5332209  38.74194745 38.64841534 44.74039814 45.55660952\n",
            " 49.45200002 41.28569438 48.74961154 41.09532633 45.2324764  46.27533269\n",
            " 39.63787686 43.97914927 48.64797334 31.82600978 41.02988418 41.02988418\n",
            " 36.25958222 26.06894331 46.06037966 43.42458723 45.73392952 47.89287713\n",
            " 45.24709837 31.66076884 45.99608888 26.8519767  47.16470319 47.39611247\n",
            " 24.25472284 46.89511018 45.00302675 48.24300604 43.99166956 46.65085753\n",
            " 43.74945476 49.19152411 39.63771209 36.74126742 42.38417985 45.47893861\n",
            " 39.83149083 31.54541334 48.52314535 46.91810265 44.9119992  43.4391657\n",
            " 46.23251269 38.50572596 36.32044873 46.89567532 45.55660952 48.97619304\n",
            " 41.99510983 48.77923971 48.80504342 49.67014099 44.39596974 39.87073913\n",
            " 42.53951544 47.25665243 49.07677396 41.16649383 27.64698235 47.91468677\n",
            " 36.60253158 37.37857706 47.62825965 37.69550588 44.66650453 49.55369649\n",
            " 42.32437742 43.75473712 19.89990338 41.78259556 26.77717027 47.11428277\n",
            " 48.11106995 26.31918776 49.58012281 29.10262683 40.24059535 47.86170655\n",
            " 46.64374321 47.9109993  34.37982319 44.30545314 37.04319713 48.78153959\n",
            " 32.09966483 29.88001422 45.20412803 47.28101058 39.88650109 42.57105187\n",
            " 48.73161181 40.55326385 48.38649113 37.84346789 47.978826   42.49694401\n",
            " 43.15001871 38.70796371 45.96256445 43.94953564 46.37168753 31.76579772\n",
            " 41.37225638 46.14451923 47.13309542 36.97208139 44.90037569 46.30821244\n",
            " 37.42298874 47.22438037 36.00726815 43.7385375  18.98404216 42.96844571\n",
            " 45.12642006 49.53061974 46.88077946 34.70869765 47.5814443  31.9222298\n",
            " 45.06751938 42.52407011 47.70617115 47.80133924 49.75617145 38.04889191\n",
            " 49.11284124 38.06236432 35.06354467 48.58768995 47.38790335 47.96761727\n",
            " 43.40596225 46.86348116 34.47014289 35.45734912 47.22032172 45.55873888\n",
            " 33.65081546 46.29290241 48.19702232 40.39364986 48.28925056 40.17889569\n",
            " 49.45512527 33.00602306 47.13081326 49.40741347 47.8370801  32.90822741\n",
            " 47.19224744 47.38644413 46.57026676 32.86077234 38.09936011 45.56969505\n",
            " 46.25225561 42.94468768 37.95208063 47.34491815 34.01330973 46.09942697\n",
            " 41.02988418 26.56910081 41.6755084  47.86345594 47.14456183 29.88093055\n",
            " 28.37638584 41.06503468 41.02988418 41.02988418 46.70754826 42.05468605\n",
            " 31.44183155 48.91485222 47.37041186 35.10677493 49.36927942 45.82908095\n",
            " 32.67323985 46.44974416 49.33719993 31.85385704 47.18410057 41.72889775\n",
            " 43.82427379 48.30778781 41.76302545 47.39754203 34.18839025 48.68351629\n",
            " 11.8071465  33.89409647 45.40383664 40.7116313  48.38501804 48.73422551\n",
            " 48.73016247 44.02788762 48.26465406 24.22648961 43.57325349 47.32832169\n",
            " 44.47581926 25.5227671  48.76471472 49.56376708 49.13084263 49.34512981\n",
            " 44.93041258 45.89766296 33.33047922 44.58655576 48.9140006  49.12220501\n",
            " 47.8957367  45.01581121 30.84408481 44.96485611 48.70138292 45.78527713\n",
            " 42.28755823 39.12109125 49.04110567 48.53853309 40.5502653  47.51445765\n",
            " 48.15796432 46.68739729 48.04903817 47.56148848 48.92872001 46.64784018\n",
            " 32.33105209 38.27032208 39.53797687 26.30207443 49.48775674 35.64032634\n",
            " 49.86681864 42.25152366 46.06245458 49.71440897 45.15332347 40.01201796\n",
            " 33.50327319 41.79543803 45.6009415  47.2217186  41.68461002 43.50881175\n",
            " 38.87800642 49.16526227 43.92942018 49.37315089 46.2111515  36.48140962\n",
            " 36.57579521 30.546006   45.06366874 47.3705518  42.39352546 27.37648457\n",
            " 48.98732899 48.05825053 47.25211881 36.21804851 47.65105717 45.03689011\n",
            " 35.63486845 41.71395018 48.76634444 27.33188318 48.7726619  40.43676021\n",
            " 49.54536454 44.40845997 48.04869198 48.06951915 48.10842006 23.73606947\n",
            " 43.54197323 34.77570626 38.31782797 44.71654713 42.25013047 43.71807458\n",
            " 33.37965043 44.8372607  49.73107684 44.2345994  49.67813678 34.38269463\n",
            " 41.59538159 41.86627536 48.88749812 40.88544049 39.62933484 16.3079726\n",
            " 38.19378441 49.15486617 43.8006522  43.66106831 33.0708254  43.12683729\n",
            " 34.65405128 48.59448605 27.34560876 46.57606882 47.75698755 35.13293323\n",
            " 44.28128183 49.7514683  31.5323403  47.84487996 49.3027331  31.94009791\n",
            " 49.61986784 47.00991203 35.8632531  37.11611411 20.64583218 49.08229203\n",
            " 30.65809251 34.27383    48.99772833 47.7408882  41.93064276 49.2885556\n",
            " 40.55008997 47.96957973 47.98367393 43.57343349 44.85450384 34.17804288\n",
            " 28.35651141 41.02988418 43.25756602 46.71631378 48.81284551 24.05159686\n",
            " 41.02988418 46.01512508 41.75821114 36.24397316 47.18410057 47.29254355\n",
            " 46.64014343 46.83462791 46.13546808 47.39611247 47.65308855 47.8699136\n",
            " 48.49618741 38.43064656 47.67924897 47.76601306 21.35517057 43.69756267\n",
            " 32.28188444 44.72736096 47.85420228 45.3502825  38.9497059  46.42828072\n",
            " 43.01707092 31.13373933 48.50854767 45.69501384 42.768439   38.32575394\n",
            " 44.50564448 47.29869636 46.40869259 33.59467945 45.52739398 48.47241447\n",
            " 47.75513223 49.13034571 43.40089507 48.93027418 46.20974932 48.74722929\n",
            " 29.60367661 41.02988418 45.46954786 47.15120009 47.43285078 48.14766224\n",
            " 46.30806748 43.01316263 49.32017804 49.02519009 31.55868677 38.46296992\n",
            " 46.48229337 41.16041451 28.89648943 24.24597077 25.28903206 20.1436842\n",
            " 48.57986305 48.2738471  42.6698955  34.67865331 41.45610502 34.76036387\n",
            " 49.28050257 39.61223991 44.60523206 38.92257034 49.4559799  27.5635867\n",
            " 40.74673466 42.43346507 49.44357882 48.67359813 37.24218649 48.24356915\n",
            " 22.02629474 31.47195519 44.35917484 42.97345461 40.53689418 35.39738085\n",
            " 44.40400161 47.16981348 47.98396306 38.46648092 41.02988418 47.41730958\n",
            " 31.43565236 36.43310769 41.59004049 41.02988418 41.40762939 33.39588172\n",
            " 27.05364239 49.74223691 47.80848957 47.92392698 43.47424882 48.20584552\n",
            " 47.071859   24.34709202 29.21906638 39.73584253 49.32318457 18.05523703]\n",
            "selection [684 279 791 339 941 386 604 560 893 814] (10,) [11.8071465  14.60592168 16.3079726  17.61244169 18.05523703 18.5154261\n",
            " 18.98404216 19.89990338 20.1436842  20.64583218]\n",
            "trainset before adding uncertain samples (360, 10) (360,)\n",
            "trainset after adding uncertain samples (370, 10) (370,)\n",
            "updated train set: (370, 10) (370,) unique(labels): [180 190] [0 1]\n",
            "val set: (932, 10) (932,)\n",
            "\n",
            "Train set: (370, 10)\n",
            "Validation set: (932, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 37\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.275 s \n",
            "\n",
            "Accuracy rate is 81.566820 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.89      0.88       321\n",
            "           1       0.66      0.60      0.63       113\n",
            "\n",
            "    accuracy                           0.82       434\n",
            "   macro avg       0.76      0.75      0.75       434\n",
            "weighted avg       0.81      0.82      0.81       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[286  35]\n",
            " [ 45  68]]\n",
            "--------------------------------\n",
            "val predicted: (932,) [1 1 1 0 1 1 0 0 0 0 1 1 1 0 1 0 1 0 0 0 1 1 1 1 1 0 1 0 0 0 1 1 0 0 0 1 1\n",
            " 0 0 0 1 1 0 1 1 1 0 0 1 1 1 1 0 1 0 1 1 0 0 1 1 1 1 1 0 1 0 1 0 0 1 1 0 0\n",
            " 0 1 0 0 1 1 0 1 0 1 0 0 1 1 1 0 0 0 0 1 0 1 0 1 1 1 0 0 1 0 0 0 0 0 0 0 0\n",
            " 1 0 1 1 0 1 1 0 1 1 1 0 1 1 1 1 1 1 0 1 0 1 1 0 1 0 1 1 0 1 1 1 0 0 1 0 0\n",
            " 0 1 1 1 1 0 1 1 0 1 0 0 1 1 0 1 1 1 0 0 0 0 0 0 0 1 1 1 0 0 1 0 0 0 0 0 0\n",
            " 1 1 0 1 0 0 0 1 0 1 1 0 1 1 0 1 1 0 0 0 0 0 0 1 0 1 1 1 1 1 1 0 0 1 1 0 1\n",
            " 0 1 1 1 1 0 1 1 0 1 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1 0 0 1 1 0 1 1 0 0 1 1\n",
            " 1 1 0 0 0 0 0 1 0 1 0 1 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 1 1\n",
            " 1 1 1 0 1 0 1 0 0 1 0 0 0 1 0 1 1 1 0 1 0 0 1 0 0 1 0 0 1 0 1 0 0 1 1 1 1\n",
            " 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 0 0 0 1 0 1 1 0 1 1 0 1 1 0 0 1\n",
            " 0 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 0 0 0 0 1 1 0 1 1 0 0\n",
            " 1 0 0 0 1 0 1 0 1 0 0 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 1 1 0 0 0 0 0 0 1 1 1\n",
            " 1 1 0 0 0 1 1 0 1 0 1 0 0 1 0 0 0 0 0 0 1 1 0 1 0 1 1 1 0 1 0 0 1 1 1 1 1\n",
            " 1 1 1 1 1 0 1 1 0 0 1 0 0 1 0 1 1 1 0 0 1 1 1 0 1 0 1 0 0 0 0 1 0 1 0 1 0\n",
            " 1 1 0 1 1 0 1 1 0 0 1 1 1 1 0 1 1 1 0 1 1 1 0 0 0 1 0 1 1 1 1 1 1 1 0 1 0\n",
            " 0 0 0 1 1 0 0 0 1 0 1 0 1 1 1 0 1 1 0 1 1 0 1 0 0 0 1 0 0 1 0 0 1 0 1 1 1\n",
            " 1 1 0 0 0 1 0 1 1 1 0 1 1 1 0 1 1 0 1 0 1 0 0 1 1 0 1 1 1 1 0 1 1 0 1 1 1\n",
            " 0 1 0 0 1 0 0 1 1 1 1 1 0 1 1 1 1 1 1 0 0 0 1 0 1 1 0 1 0 0 1 0 0 0 1 1 0\n",
            " 0 1 0 0 0 1 0 0 1 0 1 0 0 1 1 1 0 1 0 1 1 1 1 1 1 0 0 0 1 0 1 1 0 1 0 0 1\n",
            " 1 0 0 0 0 1 0 0 1 0 1 0 0 1 0 0 1 0 1 1 1 0 0 0 1 1 0 0 1 0 1 0 1 1 0 1 0\n",
            " 1 0 1 1 0 0 0 0 1 1 0 0 1 0 1 1 1 1 0 1 0 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 0\n",
            " 1 0 1 1 1 1 1 1 0 0 0 1 0 0 1 1 1 0 1 1 1 0 1 0 0 0 0 0 1 0 1 1 0 1 0 1 1\n",
            " 1 0 0 0 1 1 0 0 1 1 0 0 0 1 0 1 1 1 1 1 0 1 1 0 0 1 1 1 0 1 0 1 1 0 1 1 1\n",
            " 0 1 1 1 1 1 1 1 1 0 1 1 0 1 1 0 1 1 0 0 1 0 1 1 0 0 0 0 1 0 1 1 0 1 1 0 1\n",
            " 0 1 1 1 1 1 0 0 1 0 0 0 1 0 0 0 1 0 1 0 0 1 1 0 1 0 1 1 1 1 0 1 1 1 0 0 1\n",
            " 1 0 1 1 1 0 0]\n",
            "probabilities: (932, 2) \n",
            " [1 1 1 0 1 1 0 0 0 0 1 1 1 0 1 0 1 0 0 0 1 1 1 1 1 0 1 0 0 0 1 1 0 0 0 1 1\n",
            " 0 0 0 1 1 0 1 1 1 0 0 1 1 1 1 0 1 0 1 1 0 0 1 1 1 1 1 0 1 0 1 0 0 1 1 0 0\n",
            " 0 1 0 0 1 1 0 1 0 1 0 0 1 1 1 0 0 0 0 1 0 1 0 1 1 1 0 0 1 0 0 0 0 0 0 0 0\n",
            " 1 0 1 1 0 1 1 0 1 1 1 0 1 1 1 1 1 1 0 1 0 1 1 0 1 0 1 1 0 1 1 1 0 0 1 0 0\n",
            " 0 1 1 1 1 0 1 1 0 1 0 0 1 1 0 1 1 1 0 0 0 0 0 0 0 1 1 1 0 0 1 0 0 0 0 0 0\n",
            " 1 1 0 1 0 0 0 1 0 1 1 0 1 1 0 1 1 0 0 0 0 0 0 1 0 1 1 1 1 1 1 0 0 1 1 0 1\n",
            " 0 1 1 1 1 0 1 1 0 1 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1 0 0 1 1 0 1 1 0 0 1 1\n",
            " 1 1 0 0 0 0 0 1 0 1 0 1 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 1 1\n",
            " 1 1 1 0 1 0 1 0 0 1 0 0 0 1 0 1 1 1 0 1 0 0 1 0 0 1 0 0 1 0 1 0 0 1 1 1 1\n",
            " 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 0 0 0 1 0 1 1 0 1 1 0 1 1 0 0 1\n",
            " 0 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 0 0 0 0 1 1 0 1 1 0 0\n",
            " 1 0 0 0 1 0 1 0 1 0 0 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 1 1 0 0 0 0 0 0 1 1 1\n",
            " 1 1 0 0 0 1 1 0 1 0 1 0 0 1 0 0 0 0 0 0 1 1 0 1 0 1 1 1 0 1 0 0 1 1 1 1 1\n",
            " 1 1 1 1 1 0 1 1 0 0 1 0 0 1 0 1 1 1 0 0 1 1 1 0 1 0 1 0 0 0 0 1 0 1 0 1 0\n",
            " 1 1 0 1 1 0 1 1 0 0 1 1 1 1 0 1 1 1 0 1 1 1 0 0 0 1 0 1 1 1 1 1 1 1 0 1 0\n",
            " 0 0 0 1 1 0 0 0 1 0 1 0 1 1 1 0 1 1 0 1 1 0 1 0 0 0 1 0 0 1 0 0 1 0 1 1 1\n",
            " 1 1 0 0 0 1 0 1 1 1 0 1 1 1 0 1 1 0 1 0 1 0 0 1 1 0 1 1 1 1 0 1 1 0 1 1 1\n",
            " 0 1 0 0 1 0 0 1 1 1 1 1 0 1 1 1 1 1 1 0 0 0 1 0 1 1 0 1 0 0 1 0 0 0 1 1 0\n",
            " 0 1 0 0 0 1 0 0 1 0 1 0 0 1 1 1 0 1 0 1 1 1 1 1 1 0 0 0 1 0 1 1 0 1 0 0 1\n",
            " 1 0 0 0 0 1 0 0 1 0 1 0 0 1 0 0 1 0 1 1 1 0 0 0 1 1 0 0 1 0 1 0 1 1 0 1 0\n",
            " 1 0 1 1 0 0 0 0 1 1 0 0 1 0 1 1 1 1 0 1 0 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 0\n",
            " 1 0 1 1 1 1 1 1 0 0 0 1 0 0 1 1 1 0 1 1 1 0 1 0 0 0 0 0 1 0 1 1 0 1 0 1 1\n",
            " 1 0 0 0 1 1 0 0 1 1 0 0 0 1 0 1 1 1 1 1 0 1 1 0 0 1 1 1 0 1 0 1 1 0 1 1 1\n",
            " 0 1 1 1 1 1 1 1 1 0 1 1 0 1 1 0 1 1 0 0 1 0 1 1 0 0 0 0 1 0 1 1 0 1 1 0 1\n",
            " 0 1 1 1 1 1 0 0 1 0 0 0 1 0 0 0 1 0 1 0 0 1 1 0 1 0 1 1 1 1 0 1 1 1 0 0 1\n",
            " 1 0 1 1 1 0 0]\n",
            "std (932,) [40.70000096 43.68440056 37.01939432 44.54623301 44.72619032 34.16974532\n",
            " 29.08943238 33.54483764 49.14602115 49.71297236 44.8749932  48.89894034\n",
            " 35.67695018 46.66323021 27.20126047 42.56804224 38.70526367 44.79590689\n",
            " 47.76309525 34.84496493 45.5563571  41.96958589 47.76263004 47.20730361\n",
            " 46.41608798 28.06395332 47.26522155 35.91180569 38.96293631 45.68010281\n",
            " 44.27517929 43.18175583 49.45399135 49.62167612 41.08395067 43.49549076\n",
            " 23.78997318 43.84757892 48.80190903 37.50693143 37.11059975 33.21516481\n",
            " 26.78127659 44.9434611  34.50129023 48.47961424 43.26312083 47.96428986\n",
            " 49.27124508 34.04700311 47.1748797  44.2657078  47.5715549  47.37412692\n",
            " 37.28124749 33.81367912 46.3546141  46.71255915 49.65864963 47.27396173\n",
            " 47.6959719  42.9760548  44.33923273 31.29494529 46.25504786 47.29888793\n",
            " 39.28692378 46.93605968 49.17400172 20.93078146 46.23059373 37.66463979\n",
            " 36.46389936 48.2833384  38.9352399  47.90523191 47.76885191 39.42032953\n",
            " 44.93925408 46.89427516 32.58648737 40.87447281 39.36910997 47.34567627\n",
            " 48.02416304 42.56804224 43.77765514 40.4636118  38.96651092 48.38827008\n",
            " 44.47011105 49.53865717 48.80413212 48.79843286 48.65158304 45.63833457\n",
            " 49.48568583 46.45908577 40.66061945 48.0333705  33.92739195 41.66573085\n",
            " 45.79204983 48.4100767  49.54666326 48.45713395 47.24620752 49.19243587\n",
            " 48.10536267 33.68566829 42.56804224 45.89982935 49.76817252 47.3334109\n",
            " 42.73631212 49.59317317 29.37654129 34.29004845 46.51072626 47.48186612\n",
            " 37.39932855 37.13008756 28.0719856  25.70208529 40.12719337 46.62577866\n",
            " 39.91894549 45.1959826  31.05740845 35.32612351 45.68389112 45.20876214\n",
            " 45.5354196  47.77496451 42.63059386 31.15301778 42.56804224 48.92887356\n",
            " 42.80994134 48.35379263 46.0530363  48.25580227 44.01934307 43.70988456\n",
            " 42.62253795 42.55636375 39.74730867 48.79088646 32.21658323 43.16027352\n",
            " 46.19660636 46.15005419 37.64916165 44.40068364 36.84821709 32.78346449\n",
            " 49.3394539  46.73184642 49.40991179 42.56804224 38.68983095 39.30602046\n",
            " 26.76422896 40.43281868 43.32881347 44.57832809 45.5869653  46.57785216\n",
            " 43.03799381 46.50158435 40.29343368 46.92369143 33.35968387 42.59119726\n",
            " 47.70912819 44.85560317 43.31513874 35.81141858 41.90505154 45.52056431\n",
            " 35.89347038 37.45734116 49.26886009 47.7960727  49.28755655 47.73672408\n",
            " 41.17999859 45.75246845 36.57248439 49.44097186 49.48473325 42.56804224\n",
            " 44.08196321 48.69910961 42.78324813 41.03479124 47.16019955 47.65269245\n",
            " 42.94945683 46.81750161 41.26127472 48.49296673 42.39686755 34.65256116\n",
            " 36.78132804 49.47593119 40.98065739 42.66020682 48.90221723 46.97494144\n",
            " 35.17417679 37.97262642 39.98501468 41.90623621 45.37998698 40.1308143\n",
            " 47.36475279 48.41881794 46.94465108 44.42412218 39.82135128 45.80764017\n",
            " 48.91858765 47.30613135 42.35356184 45.18586645 44.22754459 45.33051788\n",
            " 33.14535519 46.74071451 48.59460331 48.42932452 37.84533058 47.91676546\n",
            " 47.30930264 47.80000529 49.3104752  44.81811803 39.60697425 48.32948697\n",
            " 24.50282199 45.64029454 34.46951393 40.31074751 45.33392071 45.49955201\n",
            " 44.64888716 20.01359671 49.52876329 46.82500978 44.59414903 40.95196296\n",
            " 47.77141111 41.77523956 45.13746393 32.10544572 43.66395336 36.40566103\n",
            " 43.40496142 44.57652077 48.46479359 45.60724989 42.56804224 49.15800541\n",
            " 42.56804224 28.37678628 28.19199843 35.26149203 48.0086185  42.56804224\n",
            " 45.79490878 49.57379089 30.84195082 39.46937719 49.29163264 42.21244619\n",
            " 47.02184161 46.47174629 48.69692439 45.67153686 42.77457828 39.77601436\n",
            " 32.36850259 48.39235923 49.70814684 47.47031512 46.33540291 37.73651429\n",
            " 46.73829658 45.425432   47.2541587  45.92848379 33.22248718 26.34303227\n",
            " 40.88400753 46.11090515 46.81510239 45.64784971 41.80548218 49.17400172\n",
            " 45.73523204 40.99778407 47.56940073 44.31541634 40.7373871  46.71653778\n",
            " 49.4619841  44.25556596 34.02306651 28.12769689 42.58741201 40.86390942\n",
            " 47.05567058 20.5278941  48.89520266 48.9331186  41.88012798 49.48010383\n",
            " 46.8077564  42.56804224 47.25430243 46.29526422 45.27583171 48.48751611\n",
            " 46.84208445 44.76299717 47.9981468  48.4130969  48.61881214 39.5572988\n",
            " 47.32541256 29.85492724 47.41174381 18.44563294 34.87695334 44.74819837\n",
            " 43.60137965 41.0079737  35.56546794 30.98620265 48.56082103 25.9895969\n",
            " 45.66131598 45.61125435 45.3207063  45.04226314 44.29667    48.55166802\n",
            " 40.51515744 22.58286886 32.29036491 38.66635701 47.17391102 46.61614562\n",
            " 48.56665137 33.20753179 49.25641963 47.22226307 48.23168955 36.81095924\n",
            " 36.03771388 49.57356888 43.06219015 41.46885684 39.33544278 46.57245657\n",
            " 48.36029336 42.56804224 42.56804224 45.20756598 47.49006294 46.95840063\n",
            " 49.59091364 47.82140133 45.70830918 46.69793985 46.03630119 47.97273699\n",
            " 37.50156837 41.10697389 46.81378543 41.8321289  46.32559244 46.17086988\n",
            " 47.48058066 43.33170504 45.90834826 49.71351615 24.88939977 45.41436892\n",
            " 48.3812775  47.97098801 47.03413589 40.68580457 44.62508268 36.13697663\n",
            " 49.56610188 43.95447957 35.36802433 40.35348121 47.49307277 44.86417848\n",
            " 49.49060701 34.03816203 42.93658459 46.47052987 42.56804224 45.84948384\n",
            " 46.30848007 41.19966767 37.68827792 38.96041601 29.87864209 27.0338295\n",
            " 46.74310992 45.54728408 48.25615282 40.64164994 43.41999397 31.08154427\n",
            " 28.59556102 37.82403801 40.68580457 47.52566552 42.76958721 41.39898691\n",
            " 46.81507155 45.98128588 47.7007125  42.68295953 47.76150324 48.6667658\n",
            " 49.49321782 48.90927636 43.94017937 40.71319933 42.57369555 47.96114062\n",
            " 45.34457423 49.63976037 43.40535268 43.18515699 46.8823995  46.07858897\n",
            " 43.44569156 46.89376142 48.105431   49.71496506 48.43055919 39.10002507\n",
            " 39.96988714 40.04076533 48.69150851 48.68759532 44.47613397 48.54142079\n",
            " 32.48862806 43.35638357 46.4978918  36.04733241 42.89938391 42.56804224\n",
            " 36.24994621 48.84148257 43.37160451 48.73695714 27.0321275  22.54732546\n",
            " 42.56804224 47.28644409 42.64133403 42.54705606 48.86559178 38.07513739\n",
            " 49.73881912 49.26133187 29.17299558 47.19987739 38.58888618 32.60546448\n",
            " 46.13056231 35.58368313 47.90982342 37.17280491 30.92327154 38.33382573\n",
            " 40.74118763 42.49194933 45.92201006 49.39282045 41.99411293 47.93422998\n",
            " 39.1887365  45.32187026 44.96776307 41.59323643 45.12716784 48.68072703\n",
            " 39.9138704  42.56804224 42.56804224 34.1055481  30.53170251 45.23693077\n",
            " 43.94135741 46.49772397 42.80973742 45.65128151 27.32998582 47.36737888\n",
            " 30.39041174 47.05703036 47.15362137 33.07073092 47.08080835 45.29652349\n",
            " 48.16209174 45.88541008 47.19356743 41.39168749 48.34655029 38.3912356\n",
            " 34.87695334 45.61829788 45.83687011 35.35283189 28.82938016 48.49255687\n",
            " 47.30644817 45.25207973 44.76835465 46.56371262 41.88135631 37.78697354\n",
            " 45.14683982 45.92201006 48.31522042 43.80238015 48.04130463 48.47870609\n",
            " 49.66132423 44.67139839 42.44492637 44.88449307 46.48700506 49.0394177\n",
            " 43.93411725 32.61865701 47.29589824 35.54778537 36.68299236 48.11881153\n",
            " 36.31514568 46.35097469 49.58960969 41.81027644 44.08402907 43.98818832\n",
            " 25.94114334 45.63339664 43.91401217 29.85819347 49.53645823 22.98079181\n",
            " 41.55926702 47.69294462 46.05942803 47.81178025 33.58945702 45.85727019\n",
            " 40.37169783 48.24962954 35.53399392 30.56403742 45.5119039  46.5927585\n",
            " 42.09904919 41.45722324 48.86981438 43.56990892 48.95142591 31.02002067\n",
            " 48.06900895 41.96766857 43.42036186 38.83583255 46.44759236 42.41107939\n",
            " 44.02016819 29.85391297 44.68140983 46.93473892 46.03488393 41.0492937\n",
            " 44.97170753 47.5583245  32.12175171 46.49648181 34.02943899 44.28937907\n",
            " 41.69398598 43.34077537 49.59028312 46.42554657 41.84028669 46.92543962\n",
            " 28.04453928 45.65149105 43.4683482  47.20478464 45.87013614 49.67523856\n",
            " 39.01635802 49.22009498 36.27399894 37.24373174 47.83735877 47.76167079\n",
            " 48.14104516 42.99121885 46.28960565 21.13344676 38.25642123 45.88931164\n",
            " 45.39017887 34.88340124 47.3846591  47.27849807 41.42738894 48.73942464\n",
            " 37.16470175 49.62544501 31.33884104 45.92848379 49.41277965 48.5040848\n",
            " 35.03655631 44.94762349 48.0739893  46.2838266  27.42697982 30.92558833\n",
            " 47.55298402 46.31183793 41.29286659 34.50888434 47.34529613 37.10591122\n",
            " 43.82265591 42.56804224 16.4510743  31.74180032 47.7969674  46.79953226\n",
            " 24.15527261 31.61834033 40.93473563 42.56804224 42.56804224 45.80606182\n",
            " 38.69027896 29.31501745 49.13024365 47.47490277 35.42592391 48.76473921\n",
            " 46.09978333 34.49351234 47.02550156 49.33982556 36.20714957 47.50055509\n",
            " 41.79517537 45.16325122 48.08369159 44.87565429 46.91229461 40.81651064\n",
            " 48.97177882 35.65393245 45.43790654 41.17890528 48.50179392 48.53096299\n",
            " 48.39942198 41.81597748 47.92250518 20.32916896 41.87948633 47.67380751\n",
            " 46.28254074 19.32261511 48.99613445 49.50007376 48.67122367 49.47234262\n",
            " 46.59403643 45.2076235  33.49003642 42.46152094 48.89097074 49.25286944\n",
            " 46.90632069 43.5509721  33.21972667 45.4591868  49.07244164 46.68168865\n",
            " 40.09295926 27.71534583 49.06981831 47.78342056 37.03946311 47.60620351\n",
            " 48.43816887 48.41834985 47.56871062 48.69244932 48.58044664 45.29208897\n",
            " 37.86507289 38.68501302 42.36120585 29.88741342 49.32176102 34.15296415\n",
            " 49.79695718 43.36450425 46.02588574 49.62778869 44.17503462 42.05853758\n",
            " 32.02694763 40.68019681 41.60061023 47.16136881 38.01052659 39.56145474\n",
            " 40.39866876 49.08700328 43.44997089 49.24477825 45.78397421 39.79063404\n",
            " 39.36457354 34.68579053 45.78484865 48.00782171 37.66656504 21.21564699\n",
            " 48.8657387  47.76828543 46.34072275 38.6198657  47.90982342 45.13404683\n",
            " 33.7607033  42.79694798 48.96070986 34.07121778 48.83822398 41.29552994\n",
            " 49.71732264 45.38802695 46.89334485 47.59144738 47.71570903 18.45783578\n",
            " 44.36296781 37.0891085  39.09971218 44.76601335 40.81587572 44.21340368\n",
            " 35.04315743 43.48006199 49.7357241  42.80157202 49.60735473 34.54681502\n",
            " 42.80392682 42.20426422 48.80663753 39.15756381 38.37703845 37.77608171\n",
            " 49.28840601 42.66850124 42.53795858 35.67775203 44.07701069 37.38181779\n",
            " 48.07711815 35.46803352 47.65641768 47.58705197 40.52214099 42.96323797\n",
            " 49.77814793 28.47325197 48.33213805 49.3784554  36.12182028 49.50815126\n",
            " 46.64922489 33.7459045  33.58640106 48.48361869 20.89386648 31.36521278\n",
            " 48.94178859 47.18723387 41.51208521 48.92037693 40.01304497 48.51313288\n",
            " 48.49285216 44.5773216  45.42699454 33.19789971 30.6764565  42.56804224\n",
            " 45.27262358 46.88153486 49.08857712 26.56565082 42.56804224 44.8441513\n",
            " 44.61725451 38.70526367 47.50055509 47.18082729 45.04362443 44.85872859\n",
            " 46.84184659 47.15362137 47.98432561 48.38434129 47.41194295 40.66896846\n",
            " 47.04757458 48.16087857 25.75111847 42.7156215  35.47679042 43.73382534\n",
            " 48.00241489 45.89166946 36.50050444 46.12850452 43.60221332 28.61823852\n",
            " 48.95862685 45.36333166 42.23752068 32.02665634 39.54429865 45.91601533\n",
            " 46.58806272 33.61142272 44.37819838 48.2936909  46.83557441 49.06449004\n",
            " 41.90456789 48.74450887 44.40165535 48.06328019 26.63352318 42.56804224\n",
            " 45.32767683 47.19930767 48.08190121 47.34134762 45.41940134 44.33942737\n",
            " 49.42638362 48.48881761 32.61699042 43.55175863 46.21969703 42.97938858\n",
            " 22.16369791 26.83016632 17.78936604 48.58129048 47.56539998 41.0414053\n",
            " 35.81903313 43.85315558 39.5822473  48.83477885 36.86340253 43.8879278\n",
            " 37.34034195 49.02009286 24.21661341 42.28314793 37.35052069 49.50431794\n",
            " 47.64690996 31.52229817 48.24100411 24.4351838  33.58971587 44.78533835\n",
            " 45.95817571 39.70208502 39.63776904 44.43218184 47.79334056 47.77622628\n",
            " 36.88762169 42.56804224 48.02003883 27.85699858 37.25103145 42.17139497\n",
            " 42.56804224 41.42441407 27.73970109 27.27379542 49.75966831 48.10771711\n",
            " 47.76027789 41.7488379  48.20848881 46.97971478 17.04368863 20.61207493\n",
            " 39.87505811 49.0485836 ]\n",
            "selection [650 928 884 333 767 691 247 687 313 929] (10,) [16.4510743  17.04368863 17.78936604 18.44563294 18.45783578 19.32261511\n",
            " 20.01359671 20.32916896 20.5278941  20.61207493]\n",
            "trainset before adding uncertain samples (370, 10) (370,)\n",
            "trainset after adding uncertain samples (380, 10) (380,)\n",
            "updated train set: (380, 10) (380,) unique(labels): [184 196] [0 1]\n",
            "val set: (922, 10) (922,)\n",
            "\n",
            "Train set: (380, 10)\n",
            "Validation set: (922, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 38\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.203 s \n",
            "\n",
            "Accuracy rate is 81.566820 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.89      0.88       321\n",
            "           1       0.66      0.60      0.63       113\n",
            "\n",
            "    accuracy                           0.82       434\n",
            "   macro avg       0.76      0.75      0.75       434\n",
            "weighted avg       0.81      0.82      0.81       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[286  35]\n",
            " [ 45  68]]\n",
            "--------------------------------\n",
            "val predicted: (922,) [1 1 1 0 1 1 0 0 0 0 1 1 1 0 1 0 1 0 0 0 1 1 1 1 1 0 1 0 0 0 1 1 0 0 0 1 1\n",
            " 0 0 0 1 1 0 1 1 1 0 0 1 1 1 1 0 1 0 1 1 0 0 1 1 1 1 1 0 1 0 1 0 0 1 1 0 0\n",
            " 0 1 0 0 1 1 0 1 0 1 0 0 1 1 1 0 0 0 0 1 0 1 0 1 1 1 0 0 1 0 0 0 0 0 0 0 0\n",
            " 1 0 1 1 0 1 1 0 1 1 1 0 1 1 1 1 1 1 0 1 0 1 1 0 1 0 1 1 0 1 1 1 0 0 1 0 0\n",
            " 0 1 1 1 1 0 1 1 0 1 0 0 1 1 0 1 1 1 0 0 0 0 0 0 0 1 1 1 0 0 1 0 0 0 0 0 0\n",
            " 1 1 0 1 0 0 0 1 0 1 1 0 1 1 0 1 1 0 0 0 0 0 0 1 0 1 1 1 1 1 1 0 0 1 1 0 1\n",
            " 0 1 1 1 1 0 1 1 0 1 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 0 1 1 0 0 1 1 1\n",
            " 1 0 0 0 0 0 1 0 1 0 1 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 1 1 1\n",
            " 1 1 0 1 0 1 0 0 1 0 0 0 1 0 1 1 0 1 0 0 1 0 0 1 0 0 1 0 1 0 0 1 1 1 1 1 0\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 0 0 0 1 0 1 1 0 1 1 0 1 1 0 0 1 0 1 0\n",
            " 1 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 0 0 0 0 1 1 0 1 1 0 0 1 0 0\n",
            " 0 1 0 1 0 1 0 0 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 1 1 0 0 0 0 0 0 1 1 1 1 1 0\n",
            " 0 0 1 1 0 1 0 1 0 0 1 0 0 0 0 0 0 1 1 0 1 0 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1\n",
            " 1 1 0 1 1 0 0 1 0 0 1 0 1 1 1 0 0 1 1 1 0 1 0 1 0 0 0 0 1 0 1 0 1 0 1 1 0\n",
            " 1 1 0 1 1 0 0 1 1 1 1 0 1 1 1 0 1 1 1 0 0 0 1 0 1 1 1 1 1 1 1 0 1 0 0 0 0\n",
            " 1 1 0 0 0 1 0 1 0 1 1 1 0 1 1 0 1 1 0 1 0 0 0 1 0 0 1 0 0 1 0 1 1 1 1 1 0\n",
            " 0 0 1 0 1 1 1 0 1 1 1 0 1 1 0 1 0 1 0 0 1 1 0 1 1 1 1 0 1 1 0 1 1 1 0 1 0\n",
            " 0 1 0 0 1 1 1 1 1 0 1 1 1 1 1 1 0 0 1 0 1 1 0 1 0 0 1 0 0 0 1 1 0 0 1 0 0\n",
            " 0 1 0 0 1 0 1 0 0 1 1 1 0 1 0 1 1 1 1 1 0 0 1 0 1 1 0 1 0 0 1 1 0 0 0 0 1\n",
            " 0 0 1 0 1 0 0 1 0 0 1 0 1 1 1 0 0 0 1 1 0 0 1 0 1 0 1 1 0 1 0 1 0 1 1 0 0\n",
            " 0 0 1 1 0 0 1 0 1 1 1 1 0 1 0 1 0 0 0 0 0 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1\n",
            " 1 0 0 0 1 0 0 1 1 1 0 1 1 1 0 1 0 0 0 0 0 1 0 1 1 0 1 0 1 1 1 0 0 0 1 1 0\n",
            " 0 1 1 0 0 0 1 0 1 1 1 1 1 0 1 1 0 0 1 1 1 0 1 0 1 1 0 1 1 1 0 1 1 1 1 1 1\n",
            " 1 1 0 1 1 0 1 1 0 1 1 0 0 1 0 1 1 0 0 0 0 1 0 1 1 0 1 0 1 0 1 1 1 1 1 0 0\n",
            " 1 0 0 0 1 0 0 0 1 0 1 0 0 1 1 0 1 0 1 1 1 1 0 1 1 1 0 0 1 1 0 1 0 0]\n",
            "probabilities: (922, 2) \n",
            " [1 1 1 0 1 1 0 0 0 0 1 1 1 0 1 0 1 0 0 0 1 1 1 1 1 0 1 0 0 0 1 1 0 0 0 1 1\n",
            " 0 0 0 1 1 0 1 1 1 0 0 1 1 1 1 0 1 0 1 1 0 0 1 1 1 1 1 0 1 0 1 0 0 1 1 0 0\n",
            " 0 1 0 0 1 1 0 1 0 1 0 0 1 1 1 0 0 0 0 1 0 1 0 1 1 1 0 0 1 0 0 0 0 0 0 0 0\n",
            " 1 0 1 1 0 1 1 0 1 1 1 0 1 1 1 1 1 1 0 1 0 1 1 0 1 0 1 1 0 1 1 1 0 0 1 0 0\n",
            " 0 1 1 1 1 0 1 1 0 1 0 0 1 1 0 1 1 1 0 0 0 0 0 0 0 1 1 1 0 0 1 0 0 0 0 0 0\n",
            " 1 1 0 1 0 0 0 1 0 1 1 0 1 1 0 1 1 0 0 0 0 0 0 1 0 1 1 1 1 1 1 0 0 1 1 0 1\n",
            " 0 1 1 1 1 0 1 1 0 1 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 0 1 1 0 0 1 1 1\n",
            " 1 0 0 0 0 0 1 0 1 0 1 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 1 1 1\n",
            " 1 1 0 1 0 1 0 0 1 0 0 0 1 0 1 1 0 1 0 0 1 0 0 1 0 0 1 0 1 0 0 1 1 1 1 1 0\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 0 0 0 1 0 1 1 0 1 1 0 1 1 0 0 1 0 1 0\n",
            " 1 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 0 0 0 0 1 1 0 1 1 0 0 1 0 0\n",
            " 0 1 0 1 0 1 0 0 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 1 1 0 0 0 0 0 0 1 1 1 1 1 0\n",
            " 0 0 1 1 0 1 0 1 0 0 1 0 0 0 0 0 0 1 1 0 1 0 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1\n",
            " 1 1 0 1 1 0 0 1 0 0 1 0 1 1 1 0 0 1 1 1 0 1 0 1 0 0 0 0 1 0 1 0 1 0 1 1 0\n",
            " 1 1 0 1 1 0 0 1 1 1 1 0 1 1 1 0 1 1 1 0 0 0 1 0 1 1 1 1 1 1 1 0 1 0 0 0 0\n",
            " 1 1 0 0 0 1 0 1 0 1 1 1 0 1 1 0 1 1 0 1 0 0 0 1 0 0 1 0 0 1 0 1 1 1 1 1 0\n",
            " 0 0 1 0 1 1 1 0 1 1 1 0 1 1 0 1 0 1 0 0 1 1 0 1 1 1 1 0 1 1 0 1 1 1 0 1 0\n",
            " 0 1 0 0 1 1 1 1 1 0 1 1 1 1 1 1 0 0 1 0 1 1 0 1 0 0 1 0 0 0 1 1 0 0 1 0 0\n",
            " 0 1 0 0 1 0 1 0 0 1 1 1 0 1 0 1 1 1 1 1 0 0 1 0 1 1 0 1 0 0 1 1 0 0 0 0 1\n",
            " 0 0 1 0 1 0 0 1 0 0 1 0 1 1 1 0 0 0 1 1 0 0 1 0 1 0 1 1 0 1 0 1 0 1 1 0 0\n",
            " 0 0 1 1 0 0 1 0 1 1 1 1 0 1 0 1 0 0 0 0 0 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1\n",
            " 1 0 0 0 1 0 0 1 1 1 0 1 1 1 0 1 0 0 0 0 0 1 0 1 1 0 1 0 1 1 1 0 0 0 1 1 0\n",
            " 0 1 1 0 0 0 1 0 1 1 1 1 1 0 1 1 0 0 1 1 1 0 1 0 1 1 0 1 1 1 0 1 1 1 1 1 1\n",
            " 1 1 0 1 1 0 1 1 0 1 1 0 0 1 0 1 1 0 0 0 0 1 0 1 1 0 1 0 1 0 1 1 1 1 1 0 0\n",
            " 1 0 0 0 1 0 0 0 1 0 1 0 0 1 1 0 1 0 1 1 1 1 0 1 1 1 0 0 1 1 0 1 0 0]\n",
            "std (922,) [41.13426433 44.33054751 38.94637173 43.69497892 43.99766047 34.24740795\n",
            " 29.94200806 37.73610993 48.84362936 49.71007062 45.29208781 48.50427403\n",
            " 34.56505124 45.90730475 33.52206109 41.49586285 38.99319981 44.43457391\n",
            " 47.25422607 36.21230158 43.43891936 43.8153027  47.95331512 46.95632504\n",
            " 46.6823901  19.82088366 46.41634747 38.18108299 40.45770594 46.29432606\n",
            " 42.7295241  43.32072998 49.32986932 49.60878305 36.90481095 41.1931929\n",
            " 27.99387511 41.96318179 49.10566238 35.41395388 36.89541231 26.65999129\n",
            " 21.22699581 44.09369093 32.32081027 47.93514896 44.60971938 48.33548816\n",
            " 48.58312619 38.13689724 47.52770169 43.9538741  47.25106023 47.10694845\n",
            " 36.08517203 37.94858049 42.73528663 47.16925008 49.55583916 46.05769433\n",
            " 47.28978144 45.01990374 45.33521649 29.79637523 47.05431791 47.85425844\n",
            " 36.87273832 47.05138171 49.18915717 28.2761914  47.10451836 38.32568824\n",
            " 36.17971281 48.17162435 40.02940145 48.31316833 48.43233726 37.68069722\n",
            " 42.84020646 46.73138383 29.44656221 38.33963953 40.49898886 47.83478637\n",
            " 48.1673252  41.49586285 44.0836296  41.33249018 39.1158385  48.46295667\n",
            " 46.34828428 49.62919716 48.62623483 48.76230379 48.5927818  44.69393812\n",
            " 49.4175461  46.92512572 41.87658907 48.29561182 30.68092681 40.01404709\n",
            " 44.12745023 48.65186418 49.41289804 48.25259516 47.26058695 49.21254617\n",
            " 47.83431971 36.8459577  41.49586285 46.30106786 49.69826394 46.98477966\n",
            " 44.49701138 49.56097413 30.99027341 35.18256496 46.59013292 47.3038409\n",
            " 37.51446818 38.61518629 34.50583123 17.40336089 34.95903498 45.35494418\n",
            " 40.61582841 46.20382746 30.08585802 32.4473058  46.72112475 44.96545359\n",
            " 46.25246263 47.77966397 43.40467977 32.94101345 41.49586285 49.09048865\n",
            " 43.32642658 48.5109401  47.35164086 47.34262443 43.63669784 45.76620901\n",
            " 42.91249517 43.568505   37.45053092 48.49325152 34.49251429 41.1436398\n",
            " 46.21407463 47.33274233 39.01966914 42.47475861 36.32695516 38.24502156\n",
            " 49.3551445  44.32888392 49.56468144 41.49586285 41.16803292 40.12794374\n",
            " 27.11383772 41.04599058 45.22111358 44.40455608 44.25842529 46.8456142\n",
            " 44.30612497 45.8119824  36.53664828 47.20729222 32.01462116 43.51222129\n",
            " 47.53230047 45.13667039 39.7608549  39.32330316 43.44122371 46.51263178\n",
            " 33.42971558 36.30329456 49.06403402 47.41581068 48.97793841 46.2953688\n",
            " 37.94585081 46.16790634 29.97677431 49.32190078 49.34052106 41.49586285\n",
            " 44.70640334 48.54719662 43.57782388 34.0486434  45.68941025 48.20546657\n",
            " 43.25117603 46.79647392 37.06640234 48.26695209 41.78943607 33.97003866\n",
            " 37.63067747 49.53365212 42.18460106 42.58186451 48.70941399 46.16533719\n",
            " 35.51863295 35.31169857 42.52457502 42.98798903 44.89806001 42.55199258\n",
            " 47.19861939 48.09782102 44.35184941 46.87133693 41.16776395 46.86588678\n",
            " 49.18935779 47.74819652 42.32514394 47.06048287 44.85939889 46.29964527\n",
            " 30.21990158 47.8065732  48.84222691 48.35532958 44.63784407 47.86991455\n",
            " 46.12273617 47.53369335 49.44328015 45.91094018 41.21171573 47.65636656\n",
            " 27.92628422 46.6529092  31.87574031 36.9622999  44.43756534 46.20356787\n",
            " 43.75603439 49.56708201 46.71971088 43.70745927 41.16376886 47.47894082\n",
            " 43.59298688 47.44579478 35.8091775  43.59719976 37.11021301 45.62347143\n",
            " 45.41172275 48.16983997 46.03729677 41.49586285 49.22653997 41.49586285\n",
            " 30.55175245 26.90327088 29.36282379 47.28522885 41.49586285 47.29915588\n",
            " 49.47270569 24.55184119 42.13414483 49.01858948 41.91491352 46.68250317\n",
            " 47.37377031 48.94024541 45.93783501 45.82049299 39.90517697 26.5386946\n",
            " 48.71404226 49.7539721  48.42639231 45.72141126 36.96365294 45.84822406\n",
            " 45.27546606 47.0458027  46.50576143 30.29719094 31.09364829 43.81272134\n",
            " 46.13847312 46.61577123 44.90833544 43.88086598 49.18915717 46.87997691\n",
            " 38.68399111 47.42783391 44.24090924 42.55008304 45.79960348 49.4655542\n",
            " 45.1183838  36.19285865 27.90706347 38.90956701 37.04770229 46.42614651\n",
            " 49.14266498 48.76828616 43.66590841 49.42983556 46.47245263 41.49586285\n",
            " 45.60927133 47.98458411 45.62604154 48.99462103 46.50547807 44.45009832\n",
            " 47.40767542 47.80876639 48.5760125  43.24576336 46.91193959 29.01026035\n",
            " 47.03473731 28.2130384  44.49873183 42.48193818 37.97917713 39.46167429\n",
            " 32.37189873 48.88905531 32.07286563 45.03251687 45.03739133 45.74202897\n",
            " 46.04351004 45.05418996 47.96722053 43.63524781 17.39837439 35.2922487\n",
            " 44.90398136 47.42547893 45.53387136 48.87072414 38.09304753 49.19669874\n",
            " 48.26138323 48.17517824 38.91274191 33.11494319 49.48625461 41.58130777\n",
            " 44.35105102 35.18546584 46.00511936 48.38844624 41.49586285 41.49586285\n",
            " 45.98472918 46.88744496 47.13585174 49.43948827 47.88110075 42.30215131\n",
            " 47.1480844  46.55492246 48.21684173 37.79277651 44.54194514 45.88789211\n",
            " 45.45946085 45.97395975 47.61141682 47.33011205 44.46373946 46.66263633\n",
            " 49.71568219 35.98251999 44.8304014  48.2959603  48.23942193 46.25814786\n",
            " 40.26520794 45.26900822 32.91591339 49.53930725 44.07057936 39.32587836\n",
            " 42.6961836  46.43903143 45.18923443 49.40156908 33.34453233 39.67124155\n",
            " 46.1512012  41.49586285 45.73131475 46.84276263 39.76982777 38.46479907\n",
            " 38.69522429 33.84168819 25.7656535  47.89035637 45.00411964 48.39637873\n",
            " 40.97868235 42.45582959 34.18053811 29.64328885 38.18598882 40.26520794\n",
            " 47.6404152  45.78978917 44.92993076 45.21640937 43.20821599 47.71653596\n",
            " 41.81350008 47.72087156 48.55525347 49.43501722 48.51811785 45.74080038\n",
            " 41.05888581 42.50952262 48.04189352 44.39886035 49.6270732  44.38288739\n",
            " 43.03257258 47.66408933 45.93703235 45.6546087  47.44746896 48.05775117\n",
            " 49.69171778 48.44169324 41.27090885 38.49283397 43.44367633 48.48429552\n",
            " 48.3061515  43.54572888 48.58344203 34.7009073  42.56582945 47.36766937\n",
            " 36.04526459 43.02252348 41.49586285 41.2314979  48.79794656 44.84040659\n",
            " 48.56047716 23.38605745 19.13522019 41.49586285 47.16715761 43.8190064\n",
            " 43.83651058 49.14143047 34.95930298 49.61557895 48.76087709 32.23416024\n",
            " 47.27691196 43.70596208 34.19040395 45.81194227 36.3981075  47.89027691\n",
            " 41.97176558 36.59628867 38.42802293 38.30043884 43.73967507 45.0471173\n",
            " 49.29446975 40.8687119  48.2964798  37.10436801 45.09689387 46.73391946\n",
            " 43.14543967 45.0440671  48.1726129  38.32394761 41.49586285 41.49586285\n",
            " 35.10976508 30.73539594 45.72397792 44.48969636 46.21892267 44.304881\n",
            " 47.00603102 26.60056568 46.96926678 35.58996335 47.78642975 47.50651933\n",
            " 34.48534007 47.12317929 45.85765238 48.36332204 45.25246132 47.19906399\n",
            " 44.15822631 47.72393548 35.48286127 28.2130384  45.77793498 45.22803706\n",
            " 39.58877708 33.40053834 48.61707157 47.76608456 44.65565901 42.57355685\n",
            " 45.73142166 42.20573593 39.77486795 47.27312859 45.0471173  48.46044747\n",
            " 39.59891535 48.16675171 48.60820302 49.49613794 45.89098588 37.12178732\n",
            " 46.28597743 46.7442437  48.75470683 38.09667194 29.48033808 47.21394246\n",
            " 38.70809382 34.42022524 47.63938445 38.57600523 44.34470265 49.42827293\n",
            " 44.68956825 44.50407661 44.78349566 26.7506389  47.2720395  43.42007551\n",
            " 36.99924767 49.52991725 21.32065897 41.10525632 47.36742075 45.9675997\n",
            " 47.12172991 32.65978499 44.46791985 41.47911258 48.27457623 30.55994512\n",
            " 33.72271837 45.87285479 46.53549208 42.62118034 44.59765908 49.04658481\n",
            " 43.62370455 49.06833839 25.40744794 47.19506394 38.71715798 42.34159816\n",
            " 38.73685896 44.22193532 42.39813602 44.92091094 28.40155577 43.17353486\n",
            " 46.86063387 46.79710298 38.98711715 43.41888016 47.30009996 33.77149847\n",
            " 45.6361797  36.72737047 43.02664625 40.13588869 42.96954079 49.39089437\n",
            " 46.88256472 41.43175783 46.32291782 30.64769454 44.58383496 41.01523283\n",
            " 47.4711475  47.20320488 49.70743552 38.43840807 49.40380115 33.93466813\n",
            " 35.79175752 47.98334447 47.18531206 47.02420913 43.84529057 47.71585809\n",
            " 29.21942649 37.99859181 46.05085139 46.02061251 29.36776358 47.16540226\n",
            " 47.95626872 39.20060463 48.41706445 38.05371202 49.56683744 34.097007\n",
            " 46.50576143 49.42304791 48.42292738 26.45321196 46.44421281 46.73906532\n",
            " 46.63420764 32.42646559 34.67776199 46.11873342 46.33467899 41.23146903\n",
            " 39.61543461 47.06347597 38.76878454 46.86078233 41.49586285 42.72672341\n",
            " 48.36709482 45.86212177 24.59003738 33.41689414 37.92742263 41.49586285\n",
            " 41.49586285 46.39450725 41.32746076 28.00726129 49.21709524 47.54833273\n",
            " 32.19612651 48.63740701 46.2451384  31.39793574 46.95589537 49.30225534\n",
            " 34.7519357  47.72400084 44.89055556 42.53941978 48.31787738 43.1872896\n",
            " 47.47680643 38.60306725 48.950926   34.25252232 46.99420998 40.1157094\n",
            " 47.61311153 48.38006843 48.5263499  42.85752217 48.0033945  43.30634705\n",
            " 47.61267483 46.74502735 48.88958156 49.46793474 48.85973734 49.05760579\n",
            " 45.53821933 44.64542754 33.39637408 44.54875492 49.14002619 49.16519159\n",
            " 47.8154847  44.32656627 31.4993603  44.08923602 49.05046402 47.24821572\n",
            " 41.37258252 26.37215043 49.09530496 47.96665702 39.13397822 46.13313908\n",
            " 48.25505451 48.43810101 47.64637444 48.91432391 48.67582479 46.08905217\n",
            " 40.29179814 38.28219878 40.30539837 24.64944994 49.31567322 33.33791143\n",
            " 49.74321122 44.19786992 45.91093991 49.51808122 44.62211585 43.99731059\n",
            " 40.22743332 39.17060718 42.30410974 46.06049991 37.38700284 37.68109749\n",
            " 41.8462669  49.26972465 46.28964204 49.27645325 44.16951416 41.75170295\n",
            " 37.85841481 34.06720758 45.49006364 48.28473093 44.53215066 22.26297513\n",
            " 48.98743752 48.40913763 46.86038704 39.97959662 47.89027691 45.53866425\n",
            " 41.21875666 40.34772577 48.85814069 31.20625928 48.90863281 38.81814101\n",
            " 49.5507415  45.84854731 47.34218022 48.03520054 46.7185251  44.26770755\n",
            " 38.24680859 38.93832563 45.60031919 42.52678713 43.92531284 32.64385363\n",
            " 44.3789573  49.67997531 43.01204627 49.65035111 37.78728507 43.85130883\n",
            " 40.87403774 48.8293504  43.86863109 41.38675342 35.13406246 49.33793054\n",
            " 40.49385123 44.67137075 38.21100921 44.34009034 40.49855842 48.63463305\n",
            " 26.95647179 47.67085109 47.56862751 36.37944842 46.02604054 49.62520744\n",
            " 36.14436951 48.08726726 49.23930619 38.56765922 49.15731324 46.6447036\n",
            " 38.63546387 34.27942745 48.64869999 27.79964141 34.7951886  48.72669338\n",
            " 47.41955227 44.45627963 48.75273144 41.67157757 48.18581752 47.79401082\n",
            " 45.77438459 45.66923987 33.06274438 25.65709669 41.49586285 45.37246528\n",
            " 45.68771815 49.11592064 30.06465879 41.49586285 43.56347825 43.18783103\n",
            " 38.99319981 47.72400084 46.74510299 45.39706847 46.01731787 46.95264607\n",
            " 47.50651933 47.49257176 48.41445483 47.20036522 36.06469157 47.44684513\n",
            " 47.11195966 32.67863961 43.12261706 35.35800059 45.74313868 47.92272468\n",
            " 47.02138654 39.8226918  45.6436123  42.39158627 25.9320846  48.63302769\n",
            " 43.94266569 43.92378384 36.29181804 42.07152062 46.0825194  44.28720227\n",
            " 32.2489829  45.61996783 47.92167523 47.27732661 48.94237101 42.38653399\n",
            " 48.72904451 46.43452559 48.60445247 30.01949676 41.49586285 44.4968569\n",
            " 46.83032555 48.37895856 47.15305072 46.67490476 44.72561971 49.46731805\n",
            " 48.78041574 33.78490002 43.03692254 45.66113231 44.06729124 28.91976255\n",
            " 27.38706325 48.71759207 47.80642371 39.71648434 31.48913367 43.75117185\n",
            " 42.07969189 49.02475062 38.40204204 42.08281076 35.58795785 49.3810669\n",
            " 34.17424522 42.6498161  38.1404224  49.49869158 47.85221739 36.806798\n",
            " 47.63376617 29.91697949 32.37033684 45.77431368 46.37468648 42.19396244\n",
            " 41.10579611 40.95061547 47.44477189 48.21826249 36.1989188  41.49586285\n",
            " 48.01033014 31.57517876 35.49206857 41.6625375  41.49586285 40.76509529\n",
            " 31.65226195 25.20231751 49.71073195 48.24857602 47.78008327 40.78512212\n",
            " 47.72261888 47.47363982 39.55282589 48.94244354]\n",
            "selection [346 123 464  25  42 560 743 463 271 650] (10,) [17.39837439 17.40336089 19.13522019 19.82088366 21.22699581 21.32065897\n",
            " 22.26297513 23.38605745 24.55184119 24.59003738]\n",
            "trainset before adding uncertain samples (380, 10) (380,)\n",
            "trainset after adding uncertain samples (390, 10) (390,)\n",
            "updated train set: (390, 10) (390,) unique(labels): [187 203] [0 1]\n",
            "val set: (912, 10) (912,)\n",
            "\n",
            "Train set: (390, 10)\n",
            "Validation set: (912, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 39\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.225 s \n",
            "\n",
            "Accuracy rate is 81.105991 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.88      0.87       321\n",
            "           1       0.64      0.61      0.63       113\n",
            "\n",
            "    accuracy                           0.81       434\n",
            "   macro avg       0.76      0.75      0.75       434\n",
            "weighted avg       0.81      0.81      0.81       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[283  38]\n",
            " [ 44  69]]\n",
            "--------------------------------\n",
            "val predicted: (912,) [1 1 1 0 1 1 0 0 0 0 1 1 1 0 1 0 1 0 0 0 1 1 1 1 1 1 0 0 0 1 1 0 0 0 1 1 0\n",
            " 0 0 1 1 1 1 1 0 0 1 1 1 1 0 1 0 1 1 0 0 1 1 1 1 1 0 1 0 1 0 0 1 1 0 0 0 1\n",
            " 0 0 1 1 0 1 0 1 0 0 1 1 1 0 0 0 0 1 0 1 0 1 1 1 0 0 1 0 0 0 0 0 0 0 0 1 0\n",
            " 1 1 0 1 1 0 1 1 1 0 1 1 1 1 1 0 1 0 1 1 0 1 0 1 1 0 1 1 1 0 0 1 0 0 0 1 1\n",
            " 1 1 0 1 1 0 1 0 0 1 1 0 1 1 1 0 0 0 0 0 0 0 1 1 1 0 0 1 0 0 0 0 0 0 1 1 0\n",
            " 1 0 0 0 1 0 1 1 0 1 1 0 1 1 0 0 0 0 0 0 1 0 1 1 1 1 1 1 0 0 1 1 0 1 0 1 1\n",
            " 1 1 0 1 1 0 1 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 0 1 1 0 0 1 1 1 1 0 0\n",
            " 0 0 0 1 0 1 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 1 1 1 1 1 0 1\n",
            " 0 1 0 0 1 0 0 0 1 0 1 1 0 1 0 0 1 0 0 1 0 0 1 0 1 0 0 1 1 1 1 1 0 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 0 1 1 1 0 0 0 1 0 1 1 0 1 1 0 1 1 0 0 1 0 1 0 1 1 1 1 0\n",
            " 1 1 0 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 0 0 0 0 1 1 0 1 1 0 0 1 0 0 0 1 0 1 0\n",
            " 1 0 0 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 1 1 0 0 0 0 0 0 1 1 1 1 1 0 0 0 1 1 0\n",
            " 1 0 1 0 0 1 0 0 0 0 0 0 1 1 0 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0\n",
            " 1 0 0 1 0 1 1 1 0 0 1 1 1 0 1 0 1 0 0 0 0 1 0 1 0 1 0 1 1 0 1 1 0 1 1 0 0\n",
            " 1 1 1 1 0 1 1 1 0 1 1 1 0 0 0 1 0 1 1 1 1 1 1 1 0 1 0 0 0 0 1 1 0 0 0 0 1\n",
            " 0 1 1 1 0 1 1 0 1 1 0 1 0 0 0 1 0 0 1 0 0 1 0 1 1 1 1 1 0 0 0 1 0 1 1 1 0\n",
            " 1 1 1 0 1 1 0 1 0 1 0 0 1 1 0 1 1 1 1 0 1 1 0 1 1 1 0 1 0 0 1 0 0 1 1 1 1\n",
            " 1 0 1 1 1 1 1 1 0 0 1 0 1 0 1 0 0 1 0 0 0 1 1 0 0 1 0 0 0 1 0 0 1 0 1 0 0\n",
            " 1 1 1 0 1 0 1 1 1 1 1 0 0 1 0 1 1 0 1 0 0 1 1 0 0 0 0 1 0 0 1 0 1 0 0 1 0\n",
            " 0 1 0 1 1 1 0 0 0 1 1 0 0 1 0 1 0 1 1 0 1 0 1 0 1 1 0 0 0 0 1 0 0 1 0 1 1\n",
            " 1 1 0 1 0 1 0 0 0 0 0 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 0 1 0 0 1 1 1\n",
            " 0 1 1 1 0 1 0 0 0 0 0 1 0 1 1 0 1 0 1 1 1 0 0 0 1 1 0 0 1 1 0 0 0 1 0 1 1\n",
            " 1 1 1 0 1 1 0 0 1 1 1 0 1 0 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 0 1 1 0 1\n",
            " 1 0 0 1 0 1 1 0 0 0 0 1 0 1 1 0 1 0 1 0 1 1 1 1 1 0 0 1 0 0 0 1 0 0 0 1 0\n",
            " 1 0 0 1 1 0 1 0 1 1 1 1 0 1 1 1 0 0 1 1 0 1 0 0]\n",
            "probabilities: (912, 2) \n",
            " [1 1 1 0 1 1 0 0 0 0 1 1 1 0 1 0 1 0 0 0 1 1 1 1 1 1 0 0 0 1 1 0 0 0 1 1 0\n",
            " 0 0 1 1 1 1 1 0 0 1 1 1 1 0 1 0 1 1 0 0 1 1 1 1 1 0 1 0 1 0 0 1 1 0 0 0 1\n",
            " 0 0 1 1 0 1 0 1 0 0 1 1 1 0 0 0 0 1 0 1 0 1 1 1 0 0 1 0 0 0 0 0 0 0 0 1 0\n",
            " 1 1 0 1 1 0 1 1 1 0 1 1 1 1 1 0 1 0 1 1 0 1 0 1 1 0 1 1 1 0 0 1 0 0 0 1 1\n",
            " 1 1 0 1 1 0 1 0 0 1 1 0 1 1 1 0 0 0 0 0 0 0 1 1 1 0 0 1 0 0 0 0 0 0 1 1 0\n",
            " 1 0 0 0 1 0 1 1 0 1 1 0 1 1 0 0 0 0 0 0 1 0 1 1 1 1 1 1 0 0 1 1 0 1 0 1 1\n",
            " 1 1 0 1 1 0 1 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 0 1 1 0 0 1 1 1 1 0 0\n",
            " 0 0 0 1 0 1 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 1 1 1 1 1 0 1\n",
            " 0 1 0 0 1 0 0 0 1 0 1 1 0 1 0 0 1 0 0 1 0 0 1 0 1 0 0 1 1 1 1 1 0 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 0 1 1 1 0 0 0 1 0 1 1 0 1 1 0 1 1 0 0 1 0 1 0 1 1 1 1 0\n",
            " 1 1 0 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 0 0 0 0 1 1 0 1 1 0 0 1 0 0 0 1 0 1 0\n",
            " 1 0 0 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 1 1 0 0 0 0 0 0 1 1 1 1 1 0 0 0 1 1 0\n",
            " 1 0 1 0 0 1 0 0 0 0 0 0 1 1 0 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0\n",
            " 1 0 0 1 0 1 1 1 0 0 1 1 1 0 1 0 1 0 0 0 0 1 0 1 0 1 0 1 1 0 1 1 0 1 1 0 0\n",
            " 1 1 1 1 0 1 1 1 0 1 1 1 0 0 0 1 0 1 1 1 1 1 1 1 0 1 0 0 0 0 1 1 0 0 0 0 1\n",
            " 0 1 1 1 0 1 1 0 1 1 0 1 0 0 0 1 0 0 1 0 0 1 0 1 1 1 1 1 0 0 0 1 0 1 1 1 0\n",
            " 1 1 1 0 1 1 0 1 0 1 0 0 1 1 0 1 1 1 1 0 1 1 0 1 1 1 0 1 0 0 1 0 0 1 1 1 1\n",
            " 1 0 1 1 1 1 1 1 0 0 1 0 1 0 1 0 0 1 0 0 0 1 1 0 0 1 0 0 0 1 0 0 1 0 1 0 0\n",
            " 1 1 1 0 1 0 1 1 1 1 1 0 0 1 0 1 1 0 1 0 0 1 1 0 0 0 0 1 0 0 1 0 1 0 0 1 0\n",
            " 0 1 0 1 1 1 0 0 0 1 1 0 0 1 0 1 0 1 1 0 1 0 1 0 1 1 0 0 0 0 1 0 0 1 0 1 1\n",
            " 1 1 0 1 0 1 0 0 0 0 0 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 0 1 0 0 1 1 1\n",
            " 0 1 1 1 0 1 0 0 0 0 0 1 0 1 1 0 1 0 1 1 1 0 0 0 1 1 0 0 1 1 0 0 0 1 0 1 1\n",
            " 1 1 1 0 1 1 0 0 1 1 1 0 1 0 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 0 1 1 0 1\n",
            " 1 0 0 1 0 1 1 0 0 0 0 1 0 1 1 0 1 0 1 0 1 1 1 1 1 0 0 1 0 0 0 1 0 0 0 1 0\n",
            " 1 0 0 1 1 0 1 0 1 1 1 1 0 1 1 1 0 0 1 1 0 1 0 0]\n",
            "std (912,) [40.619347   43.93672135 37.84799656 42.79580045 45.2395904  34.22066944\n",
            " 32.48950182 37.46489106 49.35367965 49.54210097 44.65767057 48.60742673\n",
            " 38.25609109 47.37433106 40.01266967 39.54867495 39.21448233 46.12587476\n",
            " 39.35283824 39.36048812 43.12810392 42.50705089 47.61464264 45.87390519\n",
            " 46.31737786 47.31524361 39.062277   34.23516878 44.45378088 41.64463616\n",
            " 41.86089489 49.57464398 49.62317566 39.12751409 43.68867296 39.23258887\n",
            " 40.93548563 48.695262   38.92988528 40.84041196 30.99118226 43.44358724\n",
            " 31.9908929  48.19801413 44.99579281 48.26132004 48.40276114 34.31811552\n",
            " 47.03269548 43.88058343 47.15874636 46.58369364 29.34339508 39.26636572\n",
            " 45.70418363 46.44814308 49.54067364 46.45679252 47.20624735 44.79286539\n",
            " 45.25897869 25.16254042 48.07431276 46.60757898 38.65178291 47.06639233\n",
            " 49.12664051 23.14751859 47.47247608 41.3960267  40.44497977 48.89405334\n",
            " 36.40738362 47.8976394  47.9701942  39.84487987 43.09950362 47.29506888\n",
            " 24.77643117 39.68388732 37.60848588 47.58934677 48.61882332 39.54867495\n",
            " 44.55873306 40.45074007 37.79750663 48.38758087 46.17354981 49.49884323\n",
            " 48.99241371 48.44843389 48.64550653 44.32188014 48.94963453 46.38172459\n",
            " 41.28913367 48.33471336 27.04882709 43.19496599 44.2562428  48.82710699\n",
            " 49.54233167 48.81599228 47.42493046 49.28669246 47.63725333 38.94116263\n",
            " 39.54867495 45.66670274 49.67731784 45.73888225 44.79226895 49.38789147\n",
            " 33.0450457  32.36047085 46.44530972 46.51318205 41.21278605 38.52324957\n",
            " 34.31966871 38.16202203 46.42428564 40.35238554 45.77375804 26.92158802\n",
            " 36.96415581 46.47777629 43.63125939 47.87773484 47.86181447 44.23571759\n",
            " 31.94501175 39.54867495 49.02076836 41.09655144 48.66874112 45.96943211\n",
            " 47.40424882 44.05118061 34.21418479 43.90433049 44.50268447 40.0757996\n",
            " 49.03090331 35.27186123 40.91454993 46.08808464 47.39260473 42.25938374\n",
            " 44.7489879  35.05161622 39.77567603 49.39485146 45.36036294 49.29546807\n",
            " 39.54867495 41.57467418 41.56630841 22.79203199 41.84387141 47.52429279\n",
            " 42.81729895 46.32344976 46.78972356 35.79142233 45.8155654  39.37099567\n",
            " 47.6800599  37.46542896 46.77553354 47.52639235 46.02286796 39.19526873\n",
            " 39.98989686 43.61204039 46.83216071 31.81191709 36.82554198 49.53786266\n",
            " 47.66899121 49.22123722 46.44321573 39.70697988 45.0389388  28.31965258\n",
            " 49.31651429 49.47937068 39.54867495 43.54111246 48.39942373 42.69763253\n",
            " 36.21374259 46.7823546  47.32047839 43.66857982 47.19341892 39.14128853\n",
            " 48.29442313 41.36320871 27.32584363 37.96769508 49.46233898 40.57171754\n",
            " 44.78848092 48.92784247 47.72189918 35.77362802 33.05319598 39.06522001\n",
            " 40.43987261 45.2688851  41.6789612  47.64356681 47.86492022 44.81789857\n",
            " 47.62159766 39.65971121 47.53538345 49.24786696 47.73152928 44.33365679\n",
            " 46.32591584 47.05900716 46.58909218 37.91841622 47.03723055 48.86261463\n",
            " 47.59506492 43.83101431 46.67100311 46.77885753 47.2701805  49.37598417\n",
            " 45.34352232 42.16597737 47.88517596 28.89472821 46.38966043 35.29125903\n",
            " 36.32422848 43.42853369 44.60557587 44.12273391 49.50991612 46.51213088\n",
            " 42.58017702 43.2628845  46.68531773 40.49999381 47.36969546 37.07895341\n",
            " 44.12120911 38.77507993 45.8286047  43.90901622 48.09039854 44.56314452\n",
            " 39.54867495 49.19467363 39.54867495 35.74721136 24.70756339 28.9744752\n",
            " 47.73171717 39.54867495 47.0980411  49.44227906 43.15541922 48.98492392\n",
            " 42.40588987 47.74296714 46.20049186 49.09069578 44.89156983 43.46126926\n",
            " 40.91520128 34.58404337 48.87311835 49.66387575 48.37050301 45.5844616\n",
            " 39.86744043 46.08714844 45.27577133 46.41013855 46.36151412 27.78540353\n",
            " 26.10888755 39.66202958 46.31685538 45.41817854 44.67198527 44.54860325\n",
            " 49.12664051 47.40243064 34.32985157 47.05217645 42.97367729 41.45667625\n",
            " 46.40813108 49.56750922 45.51720733 37.70465569 26.82685976 37.76656273\n",
            " 40.64991036 46.32837278 49.39267279 48.72914165 42.70734192 49.58132352\n",
            " 42.7857217  39.54867495 43.02322627 49.00225563 46.79043677 48.74589604\n",
            " 46.97757049 45.50977848 46.95124306 48.19354921 47.95187252 44.00726673\n",
            " 46.5992404  37.69198936 47.15942958 33.26285124 47.35800158 41.71157729\n",
            " 35.83838379 35.2247456  30.72942372 48.48747144 32.54180101 44.09954204\n",
            " 45.95784037 46.5041674  45.37374576 45.93861922 47.80947866 44.7491534\n",
            " 32.10866445 45.39577651 46.45136251 46.3063567  48.9286069  37.96353394\n",
            " 49.40447032 48.61428151 47.60490169 40.41080005 36.75915312 49.37317058\n",
            " 46.98530933 44.13746157 38.44822551 44.15620215 48.00861327 39.54867495\n",
            " 39.54867495 45.68017021 44.95827328 47.59146024 49.34537592 47.54675344\n",
            " 43.61215617 46.4242627  46.05530145 47.67716004 42.04126548 42.85607858\n",
            " 45.09689892 44.16695165 46.53513861 47.59414636 47.01292553 43.80511773\n",
            " 45.5491258  49.66500747 35.79443162 45.54628789 48.79143003 46.58826235\n",
            " 46.33976189 33.80262583 44.52371245 31.72269219 49.47940115 43.1280516\n",
            " 38.50701866 37.59511819 45.87807115 44.77318931 49.17958881 35.51669565\n",
            " 38.95975563 43.80258395 39.54867495 46.25277858 45.66098862 40.79301626\n",
            " 33.81171245 33.46280375 35.9702123  16.90931362 47.2111239  46.52149351\n",
            " 47.80601042 40.93002333 40.46827576 36.00466085 27.93590353 32.99167446\n",
            " 33.80262583 47.93938892 43.40516451 47.76570274 45.84977834 44.07002114\n",
            " 47.99476653 44.01393412 47.6743765  48.56960841 49.34557795 48.65685441\n",
            " 45.02614333 43.65426676 42.61528709 48.95241699 44.97398968 49.62219989\n",
            " 39.56278937 43.5964629  48.0086689  45.02340014 47.76202312 46.04969308\n",
            " 48.11417725 49.69925547 48.05692535 41.21429638 39.76967237 24.47216207\n",
            " 48.70786101 48.72138539 44.52457272 48.75656857 31.69982877 43.63167771\n",
            " 46.99851897 40.0492692  40.51794159 39.54867495 40.93504799 48.57869226\n",
            " 45.71178367 48.52179547 39.54867495 46.64091365 44.27517849 43.15602192\n",
            " 48.40632407 34.11986313 49.4891121  48.84406065 42.66118455 47.95298566\n",
            " 43.13257395 25.63961063 47.15745514 35.47316896 47.75074728 41.07134858\n",
            " 30.84878413 39.60291153 40.87803312 44.27135584 45.67310568 49.37771736\n",
            " 43.09255312 48.66953777 40.57359668 45.88979357 48.2852831  43.32302446\n",
            " 44.51002804 48.27046875 38.4652857  39.54867495 39.54867495 40.86348217\n",
            " 28.24738261 43.85599229 45.24089085 46.79593144 43.30564214 47.76699827\n",
            " 20.75936926 47.18176774 34.67913821 47.27463411 47.49066544 30.06848475\n",
            " 46.39914625 46.78691219 47.56623152 45.60711885 46.16182868 43.29491739\n",
            " 48.30179583 34.22229198 33.26285124 47.04799769 45.60981863 42.40086206\n",
            " 35.26341777 49.0624731  47.46428129 45.28597582 42.30813097 46.54156733\n",
            " 38.8842955  34.23490255 46.8924924  45.67310568 47.34261375 42.3941582\n",
            " 48.52406705 48.58405272 49.64162064 46.01604558 36.31098814 43.23771653\n",
            " 48.01299775 48.94189877 40.5079818  18.11919677 47.01528728 37.62257386\n",
            " 34.09025849 47.81048768 38.05676116 43.41269892 49.2759685  44.48229568\n",
            " 43.63029679 45.38874527 27.97604105 47.74788887 45.579928   35.54903252\n",
            " 49.59050688 42.98053651 46.97725689 46.57817322 47.6233156  22.87758954\n",
            " 42.94134698 43.14323204 48.41540476 31.09181752 26.29973766 46.24954632\n",
            " 45.67466894 45.21290716 45.21205864 49.32613346 44.00483276 48.67617884\n",
            " 31.62481539 46.96380727 44.54458106 45.27484507 40.11100814 44.90807084\n",
            " 43.98038966 46.22043382 25.73476071 43.74287758 46.83893135 45.7835211\n",
            " 38.43377675 46.19243831 47.37733405 29.75782286 46.77160093 31.79364999\n",
            " 39.66663794 41.21713879 45.14087568 49.70595895 45.45224245 42.34781601\n",
            " 46.98860662 19.35516477 44.98478232 42.6559407  47.36066073 46.43343782\n",
            " 49.67687807 33.79768674 49.03103249 39.56349994 38.72377628 48.16307019\n",
            " 47.5818107  47.67244037 43.47047154 48.34992186 41.12741996 38.73886586\n",
            " 45.7013112  45.88270978 33.50176103 46.47535738 48.01989276 41.40362455\n",
            " 48.85019533 40.85641956 49.48618011 36.52633781 46.36151412 49.46034589\n",
            " 48.48797635 21.44766741 46.15814732 45.95182546 48.92381239 38.10361068\n",
            " 39.46565036 46.76559731 44.48286253 42.19406715 41.36346569 47.37819763\n",
            " 35.06975799 45.38308986 39.54867495 43.87630057 48.40979454 46.41049063\n",
            " 29.59887965 41.35757528 39.54867495 39.54867495 46.81893198 37.96245699\n",
            " 31.66300156 49.02645217 47.56844262 25.36281387 48.24373472 46.37461373\n",
            " 34.83232235 47.74475252 49.18515067 31.89332489 47.97294837 44.49906322\n",
            " 18.6360378  47.94733144 39.34042733 46.71995005 39.79573786 48.88719386\n",
            " 37.06048885 44.77096928 39.76415698 48.24385563 48.3934245  48.71744158\n",
            " 43.11779685 47.99821525 40.43191891 48.19775098 45.83135785 48.79789289\n",
            " 49.34860445 48.91749839 49.38607741 46.01220389 44.32622357 36.51968186\n",
            " 44.16711602 49.10918388 49.06618261 47.07996936 46.77150149 32.7222221\n",
            " 44.28126237 49.07271765 45.54029535 42.06309785 27.29869138 48.76679431\n",
            " 48.50484659 42.46490152 47.13102958 47.73248727 47.8631363  48.09612778\n",
            " 49.02983086 48.8500222  46.28969047 37.60026005 38.47480414 43.72625347\n",
            " 28.32665031 49.20534563 34.88553828 49.75617839 39.75766971 46.21241478\n",
            " 49.43938063 46.53219938 43.08938757 36.51687737 36.46204724 41.26426982\n",
            " 45.35780238 40.02395538 41.37931333 44.14952941 48.9807282  46.70644312\n",
            " 49.42670149 44.20523382 37.04979225 39.69401246 23.90551407 46.36223978\n",
            " 47.80504926 44.11292224 48.71445184 48.30261043 46.80867941 41.85626952\n",
            " 47.75074728 46.06276345 43.17513614 43.10617963 49.17918246 31.2607505\n",
            " 49.06338632 38.26095803 49.59504935 46.91802893 46.54012967 48.62456494\n",
            " 48.08505388 46.78786756 37.4422292  36.21708873 46.63543398 42.20102941\n",
            " 44.87948088 35.76880418 44.02910155 49.77070352 42.71290431 49.50542475\n",
            " 36.94157165 40.18624982 43.88579447 48.69287959 47.53883386 37.53768903\n",
            " 36.18870653 49.4606662  42.45503152 44.16775508 38.14918305 44.82869058\n",
            " 38.07970395 48.25724538 31.19989843 47.09619109 48.44414869 36.15071034\n",
            " 47.31099271 49.73775192 34.77236227 47.26395231 49.42594551 35.74571346\n",
            " 49.58285406 43.93075572 41.11113409 37.84849596 48.75120849 26.22013449\n",
            " 37.81971303 48.80573346 48.11554547 43.09333086 48.92326897 42.23248726\n",
            " 49.20219878 48.11544518 44.23123648 45.26510389 32.39736643 27.39865178\n",
            " 39.54867495 46.49006728 46.39204752 49.31292111 30.26472246 39.54867495\n",
            " 45.17548014 43.43973958 39.21448233 47.97294837 47.08886586 46.21577188\n",
            " 47.86551859 44.95593071 47.49066544 47.90254735 48.64658613 47.12569391\n",
            " 36.8566892  47.57949273 46.38109407 28.90181027 43.54174473 38.87644089\n",
            " 44.6708298  47.66383831 45.67674462 42.32351337 45.69359465 42.26620241\n",
            " 31.14785412 48.36980677 43.43782203 44.16916976 36.25937243 42.14321206\n",
            " 45.64591375 45.4437078  24.38612299 46.83830674 48.10241526 46.31618386\n",
            " 49.00814579 42.98057285 48.80778273 45.80433248 48.407945   26.75244691\n",
            " 39.54867495 46.678889   46.47723384 48.04963909 48.56534834 47.2656201\n",
            " 44.43695627 49.09711075 48.0959239  37.36120559 41.36364299 46.33808452\n",
            " 44.82424503 28.58546049 31.11669782 48.82523915 48.71965226 38.87582936\n",
            "  7.30139081 44.09478585 43.45334782 49.12536791 36.80132773 43.51402746\n",
            " 31.08482095 49.41407837 33.96804981 43.07013722 34.12984126 49.53657597\n",
            " 48.57923298 37.87617669 47.84935748 21.23575816 29.07725377 45.09459671\n",
            " 46.72407566 40.13745862 43.46916211 43.00375498 47.41445099 47.97034511\n",
            " 32.48302927 39.54867495 47.47537783 28.03179424 39.78807062 45.63336569\n",
            " 39.54867495 37.93600278 33.16628617 25.72326167 49.78881506 47.09077372\n",
            " 47.69338761 40.81929817 46.6686429  48.12504349 38.25094168 48.84065281]\n",
            "selection [870 405 537 660 595 498 885 625 159 557] (10,) [ 7.30139081 16.90931362 18.11919677 18.6360378  19.35516477 20.75936926\n",
            " 21.23575816 21.44766741 22.79203199 22.87758954]\n",
            "trainset before adding uncertain samples (390, 10) (390,)\n",
            "trainset after adding uncertain samples (400, 10) (400,)\n",
            "updated train set: (400, 10) (400,) unique(labels): [194 206] [0 1]\n",
            "val set: (902, 10) (902,)\n",
            "\n",
            "Train set: (400, 10)\n",
            "Validation set: (902, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 40\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.247 s \n",
            "\n",
            "Accuracy rate is 81.336406 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.89      0.88       321\n",
            "           1       0.65      0.60      0.63       113\n",
            "\n",
            "    accuracy                           0.81       434\n",
            "   macro avg       0.76      0.74      0.75       434\n",
            "weighted avg       0.81      0.81      0.81       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[285  36]\n",
            " [ 45  68]]\n",
            "--------------------------------\n",
            "val predicted: (902,) [1 1 1 0 1 1 0 0 0 0 1 1 1 0 1 0 1 0 0 0 1 1 1 1 1 1 0 0 0 1 1 0 0 0 1 1 0\n",
            " 0 0 1 1 1 1 1 0 0 1 1 1 1 0 1 0 1 1 0 0 1 1 1 1 1 0 1 0 1 0 0 1 1 0 0 0 1\n",
            " 0 0 1 1 0 1 0 1 0 0 1 1 1 0 0 0 0 1 0 1 0 1 1 1 0 0 1 0 0 0 0 0 0 0 0 1 0\n",
            " 1 1 0 1 1 0 1 1 1 0 1 1 1 1 1 0 1 0 1 1 0 1 0 1 1 0 1 1 1 0 0 1 0 0 0 1 1\n",
            " 1 1 0 1 1 0 1 0 0 1 1 1 1 1 0 0 0 0 0 0 0 1 1 1 0 0 1 0 0 0 0 0 0 1 1 0 1\n",
            " 0 0 0 1 0 1 1 0 1 1 0 1 1 0 0 0 0 0 0 1 0 1 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1\n",
            " 1 0 1 1 0 1 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 0 1 1 0 0 1 1 1 1 0 0 0\n",
            " 0 0 1 0 1 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 1 1 1 1 1 0 1 0\n",
            " 1 0 0 1 0 0 0 1 0 1 1 0 1 0 0 1 0 0 1 0 0 1 0 1 0 0 1 1 1 1 1 0 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 0 1 1 1 0 0 0 1 0 1 1 0 1 1 0 1 1 0 0 1 0 1 0 1 1 1 1 0 1\n",
            " 1 0 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 0 0 0 0 1 1 0 1 1 0 0 1 0 0 0 1 0 0 1 0\n",
            " 0 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 1 1 0 0 0 0 0 0 1 1 1 1 1 0 0 0 1 1 0 1 0\n",
            " 1 0 0 1 0 0 0 0 0 0 1 1 0 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 0\n",
            " 0 1 0 1 1 1 0 0 1 1 1 0 1 0 1 0 0 0 1 0 1 0 1 0 1 1 0 1 1 0 1 1 0 0 1 1 1\n",
            " 1 0 1 1 1 0 1 1 1 0 0 0 1 0 1 1 1 1 1 1 0 1 0 0 0 0 1 1 0 0 0 0 1 0 1 1 0\n",
            " 1 1 0 1 1 0 1 0 0 0 1 0 0 1 0 0 1 0 1 1 1 1 1 0 0 0 1 0 1 1 1 0 1 1 1 1 1\n",
            " 0 1 0 1 0 0 1 1 0 1 1 1 1 0 1 1 0 1 1 1 0 1 0 0 1 0 0 1 1 1 1 0 1 1 1 1 1\n",
            " 1 0 0 1 0 1 0 1 0 0 1 0 0 0 1 1 0 0 1 0 0 0 1 0 1 0 1 0 0 1 1 1 0 1 0 1 1\n",
            " 1 1 1 0 0 1 0 1 1 0 1 0 0 1 1 0 0 0 0 1 0 0 1 0 1 0 0 1 0 0 1 0 1 1 1 0 0\n",
            " 0 1 1 0 0 1 0 1 0 1 1 0 1 0 1 0 1 1 0 0 0 0 1 0 0 1 0 1 1 1 1 0 1 0 1 0 0\n",
            " 0 0 0 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 0 1 0 0 1 1 1 0 1 1 1 0 1 0 0\n",
            " 0 0 0 1 0 1 1 0 1 0 1 1 1 0 0 0 1 1 0 0 1 1 0 0 0 1 0 1 1 1 1 1 0 1 1 0 0\n",
            " 1 1 1 0 1 0 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 0 1 1 0 1 1 0 0 1 0 1 1 0\n",
            " 0 0 0 1 0 1 1 0 1 0 1 1 1 1 1 1 0 0 1 0 0 0 1 0 0 1 0 1 0 0 1 1 0 1 0 1 1\n",
            " 1 1 0 1 1 1 0 0 1 1 0 1 0 0]\n",
            "probabilities: (902, 2) \n",
            " [1 1 1 0 1 1 0 0 0 0 1 1 1 0 1 0 1 0 0 0 1 1 1 1 1 1 0 0 0 1 1 0 0 0 1 1 0\n",
            " 0 0 1 1 1 1 1 0 0 1 1 1 1 0 1 0 1 1 0 0 1 1 1 1 1 0 1 0 1 0 0 1 1 0 0 0 1\n",
            " 0 0 1 1 0 1 0 1 0 0 1 1 1 0 0 0 0 1 0 1 0 1 1 1 0 0 1 0 0 0 0 0 0 0 0 1 0\n",
            " 1 1 0 1 1 0 1 1 1 0 1 1 1 1 1 0 1 0 1 1 0 1 0 1 1 0 1 1 1 0 0 1 0 0 0 1 1\n",
            " 1 1 0 1 1 0 1 0 0 1 1 1 1 1 0 0 0 0 0 0 0 1 1 1 0 0 1 0 0 0 0 0 0 1 1 0 1\n",
            " 0 0 0 1 0 1 1 0 1 1 0 1 1 0 0 0 0 0 0 1 0 1 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1\n",
            " 1 0 1 1 0 1 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 0 1 1 0 0 1 1 1 1 0 0 0\n",
            " 0 0 1 0 1 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 1 1 1 1 1 0 1 0\n",
            " 1 0 0 1 0 0 0 1 0 1 1 0 1 0 0 1 0 0 1 0 0 1 0 1 0 0 1 1 1 1 1 0 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 0 1 1 1 0 0 0 1 0 1 1 0 1 1 0 1 1 0 0 1 0 1 0 1 1 1 1 0 1\n",
            " 1 0 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 0 0 0 0 1 1 0 1 1 0 0 1 0 0 0 1 0 0 1 0\n",
            " 0 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 1 1 0 0 0 0 0 0 1 1 1 1 1 0 0 0 1 1 0 1 0\n",
            " 1 0 0 1 0 0 0 0 0 0 1 1 0 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 0\n",
            " 0 1 0 1 1 1 0 0 1 1 1 0 1 0 1 0 0 0 1 0 1 0 1 0 1 1 0 1 1 0 1 1 0 0 1 1 1\n",
            " 1 0 1 1 1 0 1 1 1 0 0 0 1 0 1 1 1 1 1 1 0 1 0 0 0 0 1 1 0 0 0 0 1 0 1 1 0\n",
            " 1 1 0 1 1 0 1 0 0 0 1 0 0 1 0 0 1 0 1 1 1 1 1 0 0 0 1 0 1 1 1 0 1 1 1 1 1\n",
            " 0 1 0 1 0 0 1 1 0 1 1 1 1 0 1 1 0 1 1 1 0 1 0 0 1 0 0 1 1 1 1 0 1 1 1 1 1\n",
            " 1 0 0 1 0 1 0 1 0 0 1 0 0 0 1 1 0 0 1 0 0 0 1 0 1 0 1 0 0 1 1 1 0 1 0 1 1\n",
            " 1 1 1 0 0 1 0 1 1 0 1 0 0 1 1 0 0 0 0 1 0 0 1 0 1 0 0 1 0 0 1 0 1 1 1 0 0\n",
            " 0 1 1 0 0 1 0 1 0 1 1 0 1 0 1 0 1 1 0 0 0 0 1 0 0 1 0 1 1 1 1 0 1 0 1 0 0\n",
            " 0 0 0 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 0 1 0 0 1 1 1 0 1 1 1 0 1 0 0\n",
            " 0 0 0 1 0 1 1 0 1 0 1 1 1 0 0 0 1 1 0 0 1 1 0 0 0 1 0 1 1 1 1 1 0 1 1 0 0\n",
            " 1 1 1 0 1 0 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 0 1 1 0 1 1 0 0 1 0 1 1 0\n",
            " 0 0 0 1 0 1 1 0 1 0 1 1 1 1 1 1 0 0 1 0 0 0 1 0 0 1 0 1 0 0 1 1 0 1 0 1 1\n",
            " 1 1 0 1 1 1 0 0 1 1 0 1 0 0]\n",
            "std (902,) [43.2548548  44.11294447 37.8530436  44.81151943 43.80001727 32.59982575\n",
            " 25.43695491 41.26244206 48.59537427 49.55540335 45.1820681  49.01169991\n",
            " 34.30881944 45.99649214 40.9490852  39.7802032  36.63214266 44.53480846\n",
            " 43.81531698 39.04615941 43.27471606 40.95090831 47.99787644 46.77534789\n",
            " 47.18525771 47.20859817 37.5091754  41.97587956 46.6649535  41.9332823\n",
            " 43.32172018 49.53354554 49.52179944 39.16286571 42.81864965 35.19013198\n",
            " 43.834829   49.2543945  37.12973135 40.07760472 29.16497744 44.30423481\n",
            " 36.77332979 48.131762   44.83263283 48.47930832 48.99121848 36.73704417\n",
            " 47.4273122  46.37236166 47.62872088 47.11616156 33.79541132 34.97400525\n",
            " 44.58956445 46.70459572 49.52121734 45.56916834 46.60443699 43.63259893\n",
            " 44.34238559 28.44490531 47.46849251 46.51006178 37.51009084 47.12143764\n",
            " 49.27201892 29.97628372 47.02886856 39.33704663 36.51163871 48.33854852\n",
            " 34.62248498 48.11748231 47.01974705 41.40107982 42.24522934 46.89188795\n",
            " 36.61033777 40.49849392 39.99566316 47.38583285 47.42051034 39.7802032\n",
            " 44.77560908 40.93461756 39.83891645 47.00446358 46.06981812 49.34763418\n",
            " 48.74135399 48.2871474  48.21846552 46.42376345 49.23656352 45.77944472\n",
            " 37.39211968 48.49027769 25.225545   41.86683902 45.65175067 48.06374218\n",
            " 49.66635055 48.49427182 47.44791416 48.95818805 47.5950871  41.26141196\n",
            " 39.7802032  45.76570361 49.66521823 46.8509366  38.78056624 49.2490251\n",
            " 34.41630736 34.889102   46.9064462  46.20531039 39.96893539 40.03252126\n",
            " 34.22133944 37.51044627 45.45528471 40.9744937  44.23572744 25.65911849\n",
            " 35.84138728 46.4797472  43.18206417 48.03991665 47.80992535 43.80322149\n",
            " 34.34971593 39.7802032  48.90460003 41.23066046 47.21896372 46.98352046\n",
            " 47.31649536 43.95814997 37.70301054 42.55919149 41.72949454 39.7824071\n",
            " 48.68444708 33.5315314  42.41874382 46.20940125 46.92872608 40.2129471\n",
            " 42.5677372  34.06231077 38.68203304 49.14676336 39.58442928 49.66806919\n",
            " 39.7802032  41.32071066 41.43862093 40.61384577 44.39787389 44.44339939\n",
            " 45.32792869 47.36424358 40.10641761 44.90394571 38.03252481 47.66814794\n",
            " 31.8159674  45.39335637 47.31306084 44.492443   39.05445776 42.11535182\n",
            " 44.06514041 46.33033304 33.95971673 37.86236355 48.99376887 47.13841804\n",
            " 49.10840647 46.90340352 40.14670955 46.45604049 26.58991665 49.42985485\n",
            " 49.45930034 39.7802032  42.89027731 48.14622907 43.26132583 32.90291017\n",
            " 45.53499513 47.7287339  42.03955592 46.33536457 40.49090921 48.5214063\n",
            " 42.11849292 34.61822571 35.36526665 49.46673623 40.55551483 44.17388919\n",
            " 48.51442403 47.09940768 35.86504308 38.15777987 40.32137609 40.15426686\n",
            " 45.30989043 39.62892413 47.92428717 47.74638325 42.83056489 47.17893393\n",
            " 42.98831345 47.11455819 48.50103458 47.34210996 44.07238536 46.28482398\n",
            " 46.3024621  47.11134806 35.70207529 47.16006108 47.76106819 48.25363645\n",
            " 43.73343386 44.89501006 46.62476455 46.28006405 49.05823531 45.64726642\n",
            " 38.46882128 47.57343775 21.50616857 45.67191689 33.1730214  33.82099794\n",
            " 39.23025404 45.87000649 40.9601211  49.61358732 45.43639126 45.16731024\n",
            " 42.40369526 47.51823206 42.87907224 47.46845546 37.70318772 44.61377776\n",
            " 38.95681192 44.78846956 46.02481333 48.40213313 38.60172659 39.7802032\n",
            " 49.40306216 39.7802032  39.31483414 30.82164284 29.38751182 47.4888394\n",
            " 39.7802032  46.57160781 49.42004368 42.51031954 49.09150511 44.03637441\n",
            " 47.9560926  46.22555299 48.91648672 42.00396009 45.06159732 40.06639279\n",
            " 32.6319409  48.6517573  49.66492205 47.3356977  43.67680316 37.32813991\n",
            " 47.35319068 45.81802028 46.00081226 45.86718485 22.64790229 34.88770199\n",
            " 41.54609522 46.45595613 46.06306625 45.41537002 43.22524627 49.27201892\n",
            " 46.82190314 33.69097589 47.45916691 45.7453473  42.25993907 46.61610111\n",
            " 49.62659945 45.18825074 28.9150404  33.19927301 37.42731879 38.04270584\n",
            " 44.50417145 48.13324787 48.88807056 42.57431724 49.64088842 46.40862502\n",
            " 39.7802032  46.08720646 47.60854996 45.89677043 48.92588744 46.65369874\n",
            " 42.8995408  47.40387733 47.62888862 46.07453489 43.09917203 46.11850905\n",
            " 34.02519799 45.22052963 34.53700468 45.53005167 40.42976968 35.63831743\n",
            " 35.03828638 29.56640331 48.76958168 30.20509241 43.54554025 45.68311408\n",
            " 45.48167516 45.46941478 44.82851982 47.67645377 42.15062872 35.82636148\n",
            " 46.83715369 46.75238749 46.82284536 48.63776247 37.22518595 49.29181519\n",
            " 48.34283365 47.98881825 36.26236111 33.5423704  49.12780225 46.42602448\n",
            " 44.78613462 35.20027875 45.60154151 47.43208512 39.7802032  39.7802032\n",
            " 45.17466626 42.59855299 46.80711352 49.14924193 47.38589575 34.9710581\n",
            " 46.29341184 46.02929191 47.4402464  40.00998168 43.96474152 45.53699677\n",
            " 42.13837728 46.62464544 47.47680318 46.51846224 42.80028525 46.68940216\n",
            " 49.66324174 39.79570769 45.50597761 48.62097602 48.30802755 46.40783213\n",
            " 42.14120498 45.34664174 32.98738793 49.72573957 41.85381033 40.97214463\n",
            " 38.25708826 45.72661578 44.752603   49.06080345 38.00891917 39.21817494\n",
            " 45.35052351 39.7802032  45.74785272 45.66936692 41.26990899 32.54211059\n",
            " 35.5983868  34.76590509 48.0005647  46.7361002  48.30113094 36.90655572\n",
            " 41.7450747  33.73645571 27.85491318 30.90443269 42.14120498 48.01456904\n",
            " 45.68633325 46.17317646 46.36023187 45.40043125 47.69518914 42.69634871\n",
            " 47.94846198 48.01693619 49.51332159 48.46438731 44.50974279 43.01276688\n",
            " 45.23622038 48.59351448 44.93136423 49.7202886  33.21558471 43.90776846\n",
            " 47.40925354 45.59416272 47.17639843 47.02560305 48.17652165 49.63412451\n",
            " 46.81086284 40.31121456 36.65072829 30.15090817 48.57600143 48.86142341\n",
            " 43.74575919 47.82781715 30.10317985 42.78196719 46.99084133 39.35012605\n",
            " 46.11630332 39.7802032  37.69927786 49.1053678  45.09192279 48.79764314\n",
            " 39.7802032  47.15496723 44.3226403  42.12974729 47.58436865 37.3570902\n",
            " 49.50407024 48.53960611 38.29757832 46.79028279 42.79141757 32.51995391\n",
            " 46.55202535 35.13090263 47.85044439 42.28494662 34.85351266 39.99253968\n",
            " 41.86153356 44.86283273 45.55875098 48.99657595 43.69208125 48.18642427\n",
            " 42.5990813  46.90298584 47.05724266 43.17450656 46.16271382 47.89573764\n",
            " 34.69023518 39.7802032  39.7802032  35.66798142 29.41686465 44.62717671\n",
            " 44.3128876  46.88880137 46.19421394 47.1957433  46.27552362 29.46519932\n",
            " 46.86020919 46.48123343 35.1840071  46.390836   47.22071235 47.90789658\n",
            " 45.78340216 47.76320113 42.7312004  46.81792324 31.59845013 34.53700468\n",
            " 44.85365518 44.54244238 42.02412063 41.36774163 48.78262259 46.62569186\n",
            " 44.475527   35.15991237 45.36905128 41.94958227 31.69839822 46.54514756\n",
            " 45.55875098 47.95488459 41.26329049 47.95982924 48.63846253 49.60408598\n",
            " 45.28375409 41.35878715 42.86160308 47.94018063 48.44918258 37.30190822\n",
            " 46.43114072 42.35958135 35.53110323 48.08066249 35.97490445 36.29214425\n",
            " 49.22470217 40.40672077 44.94906108 44.3638798  28.86409937 46.86353273\n",
            " 43.54535573 33.90592877 49.40934935 43.86665412 47.448326   47.0490608\n",
            " 47.19073439 44.18383546 43.82927426 48.34168084 27.44965762 27.96447265\n",
            " 45.85097709 46.97064455 42.37028916 43.78878794 48.65858073 41.17313788\n",
            " 48.88783819 34.95081408 45.7220472  41.03690804 44.34728362 39.0809906\n",
            " 43.9606384  41.76412027 41.63479139 30.00010715 42.67626197 46.90603538\n",
            " 46.1232837  36.73212206 45.74900901 46.65393696 37.47042124 46.60242394\n",
            " 37.99061029 44.02157497 40.77110379 45.52021988 49.10153779 46.4229095\n",
            " 41.00957501 46.46280424 45.13019744 39.85463074 45.65369339 47.26978733\n",
            " 49.65667271 34.14103198 48.99450363 34.33393673 35.26353821 47.89791211\n",
            " 42.17625362 47.52454269 42.39694792 48.01238886 41.09747021 41.6300275\n",
            " 45.5812808  45.86914232 32.15857884 46.58606689 48.12018864 42.09069543\n",
            " 47.53934681 37.53474776 49.56791066 32.78497986 45.86718485 49.31193576\n",
            " 48.34067437 46.08007932 47.15366157 48.16733312 35.72156477 36.43278153\n",
            " 46.4871957  44.52086304 40.87312764 38.62877221 47.52341152 36.70227657\n",
            " 45.46103153 39.7802032  44.31576352 48.62546493 46.00356898 31.4014695\n",
            " 41.70357148 39.7802032  39.7802032  46.77003117 38.30730612 33.57299473\n",
            " 48.89412071 47.69628756 29.50006691 47.69329159 42.454884   34.02082691\n",
            " 47.23286175 47.97151957 34.10627475 47.58963914 43.95128095 48.29857008\n",
            " 41.20353116 46.47671039 41.17158799 48.99282699 37.44121619 44.93705564\n",
            " 36.14435852 47.5475978  48.71046722 47.56674092 42.3131982  47.29659615\n",
            " 41.50483962 47.81306216 45.90186763 49.109391   48.95624672 48.99847605\n",
            " 49.32034468 45.05811341 44.52418745 28.59375168 43.7845018  49.32179139\n",
            " 48.64889477 46.97875527 46.24594151 29.16396802 45.29891487 48.92039819\n",
            " 46.28160782 43.46718203 24.26307005 49.31243911 48.08250038 44.479386\n",
            " 44.81818303 47.94763985 46.65367715 48.21413392 48.28956879 48.8665416\n",
            " 45.72667852 39.62570063 40.37606968 39.37485524 32.21466764 49.16502804\n",
            " 32.95338404 49.81637328 43.73950206 46.36555477 49.34051391 46.59989918\n",
            " 40.87928068 35.99125128 40.01804258 37.97991385 43.99967047 40.75201414\n",
            " 37.42071753 39.77918626 48.46956001 45.45375818 49.18577823 45.05684495\n",
            " 28.62046702 39.72626389 30.09704611 46.13175024 47.47376209 41.43261349\n",
            " 47.18432302 48.77405089 46.71337229 36.38829655 47.85044439 44.42848709\n",
            " 42.73679506 41.85995184 49.02461838 35.07824675 48.31077799 36.94201184\n",
            " 49.622085   44.78046377 47.58503126 47.54758311 48.16501983 45.71487031\n",
            " 37.32625403 34.25910062 45.6785663  40.76002261 45.73456113 32.39651885\n",
            " 45.70726143 49.71179106 43.36369303 49.51159702 38.55608304 43.80617717\n",
            " 44.90431232 48.85886367 45.90127326 40.86377116 32.87969522 49.3564404\n",
            " 42.78099974 44.01227637 39.31361606 42.7466169  39.30869502 48.43830774\n",
            " 33.23916261 47.40547923 47.81406621 35.28221249 46.43002648 49.5755008\n",
            " 31.03876936 44.45580679 49.291259   39.65618089 49.51022326 43.21188927\n",
            " 36.1650034  34.9148497  48.67054981 28.06192395 41.89133516 48.96089485\n",
            " 47.66540704 43.69350836 48.8699278  42.46244753 48.78074313 48.09843961\n",
            " 46.08985761 45.20099974 30.4976062  31.54695861 39.7802032  45.42362758\n",
            " 46.6138294  49.08444631 24.24148687 39.7802032  43.77913206 45.6715659\n",
            " 36.63214266 47.58963914 46.92720716 45.55996728 47.32381167 45.54740788\n",
            " 46.48123343 46.82718383 48.31228188 44.95327407 29.6816997  47.81188069\n",
            " 47.54279717 28.86287122 44.57299091 32.46959824 45.04193145 47.07525683\n",
            " 47.57366704 39.13060673 45.88144872 43.02600585 35.3208745  48.45242127\n",
            " 44.26392161 40.72606056 33.95887843 41.67558992 46.4382713  38.81271349\n",
            " 29.59580969 46.5175364  47.78865135 45.41630026 48.45381797 42.44030749\n",
            " 48.96221517 44.43697883 48.07389228 24.49296326 39.7802032  46.2408291\n",
            " 47.07974266 47.28311949 48.65493773 46.52593914 46.08789513 48.91935474\n",
            " 47.54700981 37.9701615  41.7283456  45.59170376 42.89421972 30.27855069\n",
            " 28.70814402 48.54553359 48.47964253 39.46336227 40.94981724 38.73990633\n",
            " 49.10100898 35.77086752 43.54679906 25.77479513 49.3974971  36.11434991\n",
            " 39.71418632 40.30059423 49.04719362 47.82248897 40.30129351 48.35054079\n",
            "  6.25063307 44.88895256 46.34204779 43.26496311 40.14248336 42.33077374\n",
            " 47.69625954 48.36050535 37.91471069 39.7802032  47.31630851 25.83631198\n",
            " 30.74885106 42.95456349 39.7802032  35.96777379 33.11325111 33.46039026\n",
            " 49.61434716 47.53755821 47.35472725 40.68856613 46.89984458 46.61259372\n",
            " 39.99168579 48.13442341]\n",
            "selection [876 236 286 800 686 843  98   6 125 867] (10,) [ 6.25063307 21.50616857 22.64790229 24.24148687 24.26307005 24.49296326\n",
            " 25.225545   25.43695491 25.65911849 25.77479513]\n",
            "trainset before adding uncertain samples (400, 10) (400,)\n",
            "trainset after adding uncertain samples (410, 10) (410,)\n",
            "updated train set: (410, 10) (410,) unique(labels): [201 209] [0 1]\n",
            "val set: (892, 10) (892,)\n",
            "\n",
            "Train set: (410, 10)\n",
            "Validation set: (892, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 41\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.293 s \n",
            "\n",
            "Accuracy rate is 81.566820 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.89      0.88       321\n",
            "           1       0.66      0.60      0.63       113\n",
            "\n",
            "    accuracy                           0.82       434\n",
            "   macro avg       0.76      0.75      0.75       434\n",
            "weighted avg       0.81      0.82      0.81       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[286  35]\n",
            " [ 45  68]]\n",
            "--------------------------------\n",
            "val predicted: (892,) [1 1 1 0 1 1 0 0 0 1 1 1 0 1 0 1 0 0 0 1 1 1 1 1 1 0 0 0 1 1 0 0 0 1 1 0 0\n",
            " 0 1 1 1 1 1 0 0 1 1 1 1 0 1 0 1 1 0 0 1 1 1 1 1 0 1 0 1 0 0 1 1 0 0 0 1 0\n",
            " 0 1 1 0 1 0 1 0 0 1 1 1 0 0 0 0 1 0 1 0 1 1 1 0 1 0 0 0 0 0 0 0 0 1 0 1 1\n",
            " 0 1 1 0 1 1 1 0 1 1 1 1 0 1 0 1 1 0 1 0 1 1 0 1 1 1 0 0 1 0 0 0 1 1 1 1 0\n",
            " 1 1 0 1 0 0 1 1 1 1 1 0 0 0 0 0 0 0 1 1 1 0 0 1 0 0 0 0 0 0 1 1 0 1 0 0 0\n",
            " 1 0 1 1 0 1 1 0 1 1 0 0 0 0 0 0 1 0 1 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 0 1\n",
            " 1 0 1 1 0 1 1 0 1 0 1 1 1 1 1 1 1 0 0 1 1 0 1 1 0 0 1 1 1 1 0 0 0 0 0 1 0\n",
            " 1 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 1 1 1 1 1 0 1 0 1 0 0 1 0\n",
            " 0 0 1 0 1 1 0 1 0 0 1 0 0 1 0 0 1 0 1 0 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 0 1 1 1 0 0 0 1 0 1 1 0 1 1 0 1 1 0 0 1 0 1 0 1 1 1 1 0 1 1 0 1 1 1\n",
            " 1 1 1 0 1 1 0 1 1 1 1 1 0 0 0 0 1 1 0 1 1 0 0 1 0 0 0 1 0 0 1 0 0 1 0 1 1\n",
            " 1 1 0 1 1 1 1 1 0 1 0 1 1 0 0 0 0 0 0 1 1 1 1 1 0 0 0 1 1 0 1 0 1 0 0 1 0\n",
            " 0 0 0 0 0 1 1 0 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 0 0 1 0 1 1\n",
            " 1 0 0 1 1 1 0 1 0 1 0 0 0 1 0 1 0 1 0 1 1 0 1 1 0 1 1 0 0 1 1 1 1 0 1 1 1\n",
            " 0 1 1 1 0 0 0 1 0 1 1 1 1 1 1 0 1 0 0 0 0 1 1 0 0 0 0 1 0 1 1 0 1 1 0 1 1\n",
            " 0 1 0 0 0 1 0 0 1 0 0 1 0 1 1 1 1 1 0 0 0 1 0 1 1 1 0 1 1 1 1 1 0 1 0 1 0\n",
            " 0 1 1 0 1 1 1 1 0 1 1 0 1 1 1 0 1 0 0 1 0 0 1 1 1 1 0 1 1 1 1 1 1 0 0 1 0\n",
            " 1 0 1 0 0 1 0 0 0 1 1 0 0 1 0 0 0 1 0 1 0 1 0 0 1 1 1 0 1 0 1 1 1 1 1 0 0\n",
            " 1 0 1 1 0 1 0 0 1 1 0 0 0 0 1 0 1 0 1 0 0 1 0 0 1 0 1 1 1 0 0 0 1 1 0 0 1\n",
            " 0 1 0 1 1 0 1 0 1 0 1 1 0 0 0 0 1 0 0 1 0 1 1 1 1 0 1 0 1 0 0 0 0 0 1 1 1\n",
            " 1 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 0 1 0 0 1 1 1 0 1 1 1 0 1 0 0 0 0 0 1 0 1\n",
            " 1 0 1 0 1 1 1 0 0 0 1 1 0 0 1 1 0 0 1 0 1 1 1 1 1 0 1 1 0 0 1 1 1 0 1 0 1\n",
            " 1 0 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 0 1 1 0 1 0 0 1 0 1 1 0 0 0 0 1 0 1 1 0\n",
            " 1 0 1 1 1 1 1 1 0 1 0 0 0 1 0 0 0 1 0 0 1 1 0 1 0 1 1 1 1 0 1 1 1 0 0 1 1\n",
            " 0 1 0 0]\n",
            "probabilities: (892, 2) \n",
            " [1 1 1 0 1 1 0 0 0 1 1 1 0 1 0 1 0 0 0 1 1 1 1 1 1 0 0 0 1 1 0 0 0 1 1 0 0\n",
            " 0 1 1 1 1 1 0 0 1 1 1 1 0 1 0 1 1 0 0 1 1 1 1 1 0 1 0 1 0 0 1 1 0 0 0 1 0\n",
            " 0 1 1 0 1 0 1 0 0 1 1 1 0 0 0 0 1 0 1 0 1 1 1 0 1 0 0 0 0 0 0 0 0 1 0 1 1\n",
            " 0 1 1 0 1 1 1 0 1 1 1 1 0 1 0 1 1 0 1 0 1 1 0 1 1 1 0 0 1 0 0 0 1 1 1 1 0\n",
            " 1 1 0 1 0 0 1 1 1 1 1 0 0 0 0 0 0 0 1 1 1 0 0 1 0 0 0 0 0 0 1 1 0 1 0 0 0\n",
            " 1 0 1 1 0 1 1 0 1 1 0 0 0 0 0 0 1 0 1 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 0 1\n",
            " 1 0 1 1 0 1 1 0 1 0 1 1 1 1 1 1 1 0 0 1 1 0 1 1 0 0 1 1 1 1 0 0 0 0 0 1 0\n",
            " 1 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 1 1 1 1 1 0 1 0 1 0 0 1 0\n",
            " 0 0 1 0 1 1 0 1 0 0 1 0 0 1 0 0 1 0 1 0 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 0 1 1 1 0 0 0 1 0 1 1 0 1 1 0 1 1 0 0 1 0 1 0 1 1 1 1 0 1 1 0 1 1 1\n",
            " 1 1 1 0 1 1 0 1 1 1 1 1 0 0 0 0 1 1 0 1 1 0 0 1 0 0 0 1 0 0 1 0 0 1 0 1 1\n",
            " 1 1 0 1 1 1 1 1 0 1 0 1 1 0 0 0 0 0 0 1 1 1 1 1 0 0 0 1 1 0 1 0 1 0 0 1 0\n",
            " 0 0 0 0 0 1 1 0 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 0 0 1 0 1 1\n",
            " 1 0 0 1 1 1 0 1 0 1 0 0 0 1 0 1 0 1 0 1 1 0 1 1 0 1 1 0 0 1 1 1 1 0 1 1 1\n",
            " 0 1 1 1 0 0 0 1 0 1 1 1 1 1 1 0 1 0 0 0 0 1 1 0 0 0 0 1 0 1 1 0 1 1 0 1 1\n",
            " 0 1 0 0 0 1 0 0 1 0 0 1 0 1 1 1 1 1 0 0 0 1 0 1 1 1 0 1 1 1 1 1 0 1 0 1 0\n",
            " 0 1 1 0 1 1 1 1 0 1 1 0 1 1 1 0 1 0 0 1 0 0 1 1 1 1 0 1 1 1 1 1 1 0 0 1 0\n",
            " 1 0 1 0 0 1 0 0 0 1 1 0 0 1 0 0 0 1 0 1 0 1 0 0 1 1 1 0 1 0 1 1 1 1 1 0 0\n",
            " 1 0 1 1 0 1 0 0 1 1 0 0 0 0 1 0 1 0 1 0 0 1 0 0 1 0 1 1 1 0 0 0 1 1 0 0 1\n",
            " 0 1 0 1 1 0 1 0 1 0 1 1 0 0 0 0 1 0 0 1 0 1 1 1 1 0 1 0 1 0 0 0 0 0 1 1 1\n",
            " 1 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 0 1 0 0 1 1 1 0 1 1 1 0 1 0 0 0 0 0 1 0 1\n",
            " 1 0 1 0 1 1 1 0 0 0 1 1 0 0 1 1 0 0 1 0 1 1 1 1 1 0 1 1 0 0 1 1 1 0 1 0 1\n",
            " 1 0 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 0 1 1 0 1 0 0 1 0 1 1 0 0 0 0 1 0 1 1 0\n",
            " 1 0 1 1 1 1 1 1 0 1 0 0 0 1 0 0 0 1 0 0 1 1 0 1 0 1 1 1 1 0 1 1 1 0 0 1 1\n",
            " 0 1 0 0]\n",
            "std (892,) [41.855874   43.39651487 39.6243738  43.83159084 45.3149805  33.86242777\n",
            " 39.78917892 48.65490047 49.59802103 46.31870403 49.15004829 36.8430682\n",
            " 46.52568114 42.02013306 37.45285274 40.70542926 43.97911844 43.65766208\n",
            " 39.25621762 45.20097194 45.07276877 47.56347879 45.72332534 47.415991\n",
            " 46.95785022 37.68281168 39.39240436 46.92283634 40.78151484 40.73189453\n",
            " 49.48335282 49.35514435 39.13478713 39.14189618 33.65098632 42.0692408\n",
            " 49.06313556 39.54909285 40.72723522 25.88031557 43.51453133 33.84670264\n",
            " 47.94947025 44.8595227  48.14297484 49.04396944 36.25278261 48.34303779\n",
            " 45.03362667 47.00991511 47.4845057  29.15117646 37.62417888 46.03224106\n",
            " 46.82614815 49.48741077 43.32974741 47.06978352 47.14959835 42.16324875\n",
            " 25.17343895 47.06069463 46.80797181 39.45684596 47.29367568 49.04511448\n",
            " 29.77514896 48.39595361 40.32784931 35.81482995 47.4651281  33.1493122\n",
            " 48.33219506 46.924457   36.64733353 41.29571482 46.373894   35.06700018\n",
            " 38.45879065 41.3461608  48.05572962 47.5796845  37.45285274 45.85385934\n",
            " 41.1534995  37.82745833 46.12878426 46.97230754 49.2001861  48.32940382\n",
            " 48.31109682 48.59361998 46.96699026 49.18149681 47.26323304 38.81045593\n",
            " 48.37505831 40.05908617 47.20450736 48.42199431 49.33760308 48.65200655\n",
            " 46.52746688 48.92922686 47.2726733  40.97434582 37.45285274 46.74228414\n",
            " 49.6187556  46.14409999 44.31680447 49.14351403 35.71750104 31.0508836\n",
            " 47.13410603 46.65660161 40.34089004 37.88379838 40.26273735 33.50804548\n",
            " 45.47573446 38.33668916 44.34856989 39.62250131 45.99253402 43.16305933\n",
            " 48.49439085 47.32827361 43.24949553 33.36809634 37.45285274 49.0299983\n",
            " 42.10845152 47.83142034 46.39387701 47.7223547  45.81023415 39.87155769\n",
            " 42.88320285 43.4858572  41.38543358 48.2073266  36.07085086 39.83021465\n",
            " 45.96424078 47.40285264 40.80191584 44.0369036  30.78366321 39.14395446\n",
            " 49.27257652 38.29713595 49.5731154  37.45285274 43.44928326 39.3122082\n",
            " 43.46923079 46.85063842 43.45650533 45.76282359 47.12767012 39.51869156\n",
            " 45.37058703 39.12679366 46.31924282 32.16104094 46.20703322 47.71509898\n",
            " 45.5093741  44.09522574 38.24651878 43.54154861 46.44008723 32.39402007\n",
            " 38.93275257 49.17494721 47.92000134 48.81871798 46.75451844 38.87569356\n",
            " 44.74755129 15.08577614 49.0687357  49.38594467 37.45285274 45.37902929\n",
            " 48.37727158 42.92872447 33.55945716 46.29527224 47.80085954 43.23229687\n",
            " 46.27946972 35.11522759 48.00750708 38.41753129 32.98441027 32.8105858\n",
            " 49.56033754 42.23776599 44.03825934 48.64419451 47.20071516 36.28962072\n",
            " 32.91057857 40.30418774 41.06711042 44.65987331 39.60574868 47.66129111\n",
            " 46.75561126 44.67500147 48.22416413 41.69915319 47.52064695 47.88010231\n",
            " 47.71971628 42.38712285 47.35729884 46.28271062 44.81527922 37.20900675\n",
            " 47.03045543 48.54497013 48.40018987 45.71273563 45.85749329 46.59803133\n",
            " 47.36957705 48.8093659  45.08640302 39.07660179 48.02119609 46.65082341\n",
            " 37.66220339 34.63354293 30.67458451 45.60402174 41.33764218 49.56698668\n",
            " 44.94946427 44.20003214 41.59461894 45.90500098 46.00492874 47.70351772\n",
            " 37.55755182 45.18537838 41.04707072 43.20920492 45.76876401 48.56749624\n",
            " 32.78699009 37.45285274 49.37743801 37.45285274 39.03582405 22.99404589\n",
            " 20.38811938 47.66188529 37.45285274 48.05572546 49.26157051 43.90094985\n",
            " 48.70522748 45.14714579 47.14551833 46.16096423 48.94217083 42.62513541\n",
            " 45.98281001 40.96280168 35.49697243 48.86094687 49.59336481 47.79534515\n",
            " 45.10957826 36.93575954 46.48812432 44.38335968 45.74149652 46.56231383\n",
            " 35.84624566 41.91631249 44.51852277 45.06108515 44.80298406 42.74730061\n",
            " 49.04511448 47.76123067 35.30267743 47.8253375  41.76232796 38.08504721\n",
            " 43.69243859 49.62549563 44.81641954 39.01902678 29.39950062 37.07277855\n",
            " 41.72544605 43.96210296 48.99419999 48.77861847 44.78291138 49.46573991\n",
            " 45.82912292 37.45285274 46.71792239 48.66326127 45.08896412 48.79610033\n",
            " 45.98170139 45.93018849 47.42853876 47.46953084 46.66251034 44.16087388\n",
            " 46.63996919 37.35435409 43.77736099 31.31713522 46.96857171 39.10147675\n",
            " 34.7038452  38.63576747 29.52236468 48.61312183 31.86230367 45.00309899\n",
            " 45.17974746 46.25037604 44.95727033 42.26084961 46.41666629 43.98378743\n",
            " 29.37752101 47.94560306 46.79251049 46.46230051 47.66106646 37.60784698\n",
            " 48.60124449 48.38773195 47.67008696 38.12834976 36.11292009 49.33064378\n",
            " 46.26562682 45.90260907 36.00543022 44.96570044 47.29898321 37.45285274\n",
            " 37.45285274 45.96517718 44.2685093  46.71387505 48.77967293 47.38491511\n",
            " 36.69472797 46.28427205 46.50754125 47.69772818 40.26850641 44.41621332\n",
            " 45.14042369 42.36160195 45.99110316 47.18775162 46.86422461 43.71776856\n",
            " 46.04243672 49.21067068 43.94901976 44.35192057 47.57341022 48.14386891\n",
            " 46.65416161 42.27904642 46.38178322 32.48162432 49.5877181  40.35531268\n",
            " 39.91389767 37.71771076 45.82467814 46.2888656  48.98969002 30.31331785\n",
            " 39.79508903 44.99830871 37.45285274 45.89638653 45.93521084 44.24111656\n",
            " 35.49237796 36.14958184 36.36514518 48.09788726 47.54401428 47.82817199\n",
            " 35.97897944 43.76406895 33.92130747 28.54932456 36.02205365 42.27904642\n",
            " 48.10183853 45.62883549 46.30124061 45.75320707 44.87570975 47.47198081\n",
            " 43.61677749 47.36390052 46.95169911 49.34721588 48.13645212 46.14843752\n",
            " 45.04827274 43.6257306  48.73494752 42.39223559 49.63538786 29.97900199\n",
            " 43.65536602 47.54263195 44.51197878 47.83803976 46.96875581 48.2043964\n",
            " 49.48960723 46.02625712 41.2949899  38.51600583 36.61827186 48.08306894\n",
            " 48.91968083 43.98303424 47.93100967 27.85452133 42.83773309 45.82397751\n",
            " 41.54023195 46.05430755 37.45285274 41.69475299 48.17776886 44.49444027\n",
            " 48.90268595 37.45285274 45.68478059 44.03086921 42.31754802 46.75707917\n",
            " 32.5056822  49.54693183 48.02094153 37.63038096 47.69008596 42.13654222\n",
            " 31.53585883 45.67288251 38.18194596 47.22510854 43.69113154 36.03823084\n",
            " 39.19343524 38.58133087 46.18553309 44.92644234 49.43072153 41.37508534\n",
            " 48.45953651 43.6845077  45.02119823 48.52719472 43.18606721 45.15360025\n",
            " 47.53158648 37.74651056 37.45285274 37.45285274 42.88026446 29.63642399\n",
            " 44.3485139  43.47692936 48.00177485 47.50363965 47.88043027 46.46645036\n",
            " 31.94083939 47.05723068 47.52917795 32.21454157 46.15161477 46.28197705\n",
            " 48.24870409 45.75379549 47.36070322 44.86598354 46.23939706 37.27913683\n",
            " 31.31713522 44.02812877 43.79074694 41.51828269 40.95080122 48.55244174\n",
            " 47.82887141 46.38495824 35.78591495 45.96714717 40.18831094 34.9271299\n",
            " 46.98267331 44.92644234 47.89457291 36.32093688 47.70281217 48.90189978\n",
            " 49.56057257 45.44948942 25.5739604  44.23062054 48.11760274 48.38748196\n",
            " 35.81130686 48.30485724 43.77737222 39.54587808 47.57467349 39.63572011\n",
            " 37.67532475 48.90841304 41.2121938  45.22428491 44.77583606 24.27351492\n",
            " 47.68947826 41.99670758 33.02299267 49.56079002 43.08286301 47.69250695\n",
            " 45.82895605 47.16399532 40.78565528 43.56232665 48.46600798 28.84864822\n",
            " 31.04425048 44.86354429 47.20360659 39.71058434 45.62951267 48.71032969\n",
            " 41.84660137 49.14747155 38.16059215 46.50389124 42.43022098 45.31070233\n",
            " 33.52238268 42.66138159 42.27490447 44.60702414 31.05192317 45.94111856\n",
            " 46.52929373 47.00667213 41.03792626 44.24767061 46.74762872 30.69457011\n",
            " 44.54891249 35.72530358 39.82449143 41.19273996 42.38644304 49.30654948\n",
            " 47.02124709 41.60969407 46.25170849 45.64013596 38.6011427  46.16419292\n",
            " 48.06215821 49.48973233 30.63811066 48.64275541 39.00373107 33.97558934\n",
            " 48.18628845 42.66902784 47.64243931 43.60723094 48.22343439 41.37368385\n",
            " 37.39759861 45.66888783 44.31356558 27.41573165 47.67919382 47.81130187\n",
            " 38.86280937 47.98848175 38.10827522 49.27848576 34.61338337 46.56231383\n",
            " 49.25935939 48.34940052 46.7344773  47.32033941 48.91971537 38.11163235\n",
            " 40.07454147 46.7976047  45.76769212 42.03993674 38.20352585 47.79204679\n",
            " 36.13503477 43.43660296 37.45285274 45.82603382 48.68714194 45.02303129\n",
            " 34.1821341  40.150465   37.45285274 37.45285274 45.49061616 33.46340503\n",
            " 32.93344247 48.78483445 48.55512107 30.89900984 48.18324766 41.18859105\n",
            " 31.36706801 47.44431879 48.37525076 34.70975487 48.04834798 42.96110648\n",
            " 47.80387138 40.95081516 46.22487637 41.646663   48.93367666 33.09612706\n",
            " 46.27488292 39.55750938 47.25374327 48.56612797 46.98569269 40.99991121\n",
            " 48.05548675 41.62519738 48.09481154 46.17757453 48.68265393 48.76913861\n",
            " 49.20008457 49.47355475 44.14746027 45.37464374 34.02860343 44.56221796\n",
            " 49.26064996 48.89030878 48.34677567 47.41874163 27.20597906 44.9947189\n",
            " 48.84870801 46.36982522 43.92052742 48.97534533 48.15981192 42.01772281\n",
            " 43.19627367 47.99016784 46.26722988 48.0628344  48.34614862 47.99284318\n",
            " 46.30013818 39.40904319 37.74140221 40.1648134  31.5143904  49.31209619\n",
            " 35.75445712 49.66582276 43.72361196 45.94616541 49.01405796 46.37378326\n",
            " 44.61995975 33.60172234 37.5706199  37.4037761  44.57268011 41.06561538\n",
            " 33.27506345 43.59833568 48.5058938  47.41959871 48.52949587 44.4537594\n",
            " 28.37307219 37.7210629  32.07435531 46.35991811 47.81226515 43.06619538\n",
            " 47.94153087 48.78664022 47.03224876 36.63582565 47.22510854 47.42623248\n",
            " 43.7792696  43.57963    48.74119132 29.36515589 48.57642427 37.73948826\n",
            " 49.51031929 46.00909256 47.95424158 47.97177421 47.50179896 43.60562989\n",
            " 34.98895651 35.80209648 46.64035568 40.0090598  43.35819032 31.38076999\n",
            " 44.29172942 49.62500232 41.15641934 49.26187043 42.96614483 42.78753312\n",
            " 42.29862725 48.71089545 46.83468168 39.48454802 35.16964905 48.89210537\n",
            " 41.55401384 43.68678988 39.09204209 43.2517036  39.09715832 48.15277839\n",
            " 32.23633766 46.49191216 47.4994487  41.64693947 46.42758689 49.40193146\n",
            " 35.46909566 44.18976983 49.28147279 37.0868271  49.60272295 45.37250265\n",
            " 40.248705   33.61096875 48.74160852 32.22128088 37.93338718 48.86975205\n",
            " 47.67472227 41.4694175  48.9910917  41.60671863 48.7586728  47.57546597\n",
            " 46.50538829 45.65701175 28.44077536 32.22920571 37.45285274 46.46526556\n",
            " 47.71054112 49.01246964 37.45285274 45.03978722 43.91312009 40.70542926\n",
            " 48.04834798 47.16106235 46.16334665 47.53624979 45.1553964  47.52917795\n",
            " 46.4734315  47.57789623 45.68707333 21.89770358 48.62145304 45.81150181\n",
            " 32.19849363 41.7380073  37.12396778 44.09854676 47.90137628 47.21992353\n",
            " 42.01576273 46.39712219 43.11122772 33.42976088 48.42581736 43.4308959\n",
            " 43.0322498  36.21603389 42.94267326 46.58751033 35.41136547 23.90768875\n",
            " 45.16218385 47.57921985 45.25967321 48.63547696 45.00249244 48.89083662\n",
            " 47.26507772 48.43655233 37.45285274 46.62626714 47.40752256 48.10028637\n",
            " 49.04490361 47.84224725 45.70928759 48.04987641 47.060321   40.78441143\n",
            " 42.92271442 45.73452213 42.46039009 30.97825558 28.15230637 48.76688423\n",
            " 48.12785485 40.72298764 43.10088709 41.7251344  49.09957059 35.022081\n",
            " 43.53625526 49.58494044 37.75763459 42.16521423 38.47018795 48.94508813\n",
            " 48.620381   42.50631996 47.49563085 44.20575506 46.22698739 44.08750989\n",
            " 41.26603647 42.18873342 47.85828628 47.50109378 37.27012354 37.45285274\n",
            " 47.52850123 29.60466228 21.83598663 46.14997505 37.45285274 40.18118296\n",
            " 31.3980775  22.9520775  49.68748005 46.983415   48.31958779 41.80805848\n",
            " 47.43573305 47.7645818  35.89530393 48.16866349]\n",
            "selection [181 258 878 807 883 257 827 539  60 524] (10,) [15.08577614 20.38811938 21.83598663 21.89770358 22.9520775  22.99404589\n",
            " 23.90768875 24.27351492 25.17343895 25.5739604 ]\n",
            "trainset before adding uncertain samples (410, 10) (410,)\n",
            "trainset after adding uncertain samples (420, 10) (420,)\n",
            "updated train set: (420, 10) (420,) unique(labels): [206 214] [0 1]\n",
            "val set: (882, 10) (882,)\n",
            "\n",
            "Train set: (420, 10)\n",
            "Validation set: (882, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 42\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.254 s \n",
            "\n",
            "Accuracy rate is 82.718894 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.90      0.89       321\n",
            "           1       0.69      0.61      0.65       113\n",
            "\n",
            "    accuracy                           0.83       434\n",
            "   macro avg       0.78      0.76      0.77       434\n",
            "weighted avg       0.82      0.83      0.82       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[290  31]\n",
            " [ 44  69]]\n",
            "--------------------------------\n",
            "val predicted: (882,) [1 1 1 0 1 1 0 0 0 1 1 1 0 1 0 1 0 0 0 1 1 1 1 1 1 0 0 0 1 1 0 0 0 1 1 0 0\n",
            " 0 1 1 1 1 1 0 0 1 1 1 1 0 1 0 1 1 0 0 1 1 1 1 0 1 0 1 0 0 1 1 0 0 0 1 0 0\n",
            " 1 1 0 1 0 1 0 0 1 1 1 0 0 0 0 1 0 1 0 1 1 1 0 1 0 0 0 0 0 0 0 0 1 0 1 1 0\n",
            " 1 1 0 1 1 1 0 1 1 1 1 0 1 0 1 1 0 1 0 1 1 0 1 1 1 0 0 1 0 0 0 1 1 1 1 0 1\n",
            " 1 0 1 0 0 1 1 1 1 1 0 0 0 0 0 0 0 1 1 1 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 1 0\n",
            " 1 1 0 1 1 0 1 1 0 0 0 0 0 0 1 0 1 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 0 1 1 0\n",
            " 1 1 0 1 1 0 1 0 1 1 1 1 1 1 1 0 0 1 1 0 1 1 0 0 1 1 1 1 0 0 0 0 0 1 0 1 0\n",
            " 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 1 1 1 1 1 0 1 0 1 0 0 1 0 0 0 1 0\n",
            " 1 1 0 1 0 0 1 0 0 1 0 0 1 0 1 0 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0\n",
            " 1 1 1 0 0 0 1 0 1 1 0 1 1 0 1 1 0 0 1 0 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1 0\n",
            " 1 1 0 1 1 1 1 1 0 0 0 0 1 1 0 1 1 0 0 1 0 0 0 1 0 0 1 0 0 1 0 1 1 1 1 0 1\n",
            " 1 1 1 1 0 1 0 1 1 0 0 0 0 0 0 1 1 1 1 1 0 0 0 1 1 0 1 0 1 0 0 1 0 0 0 0 0\n",
            " 0 1 1 0 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 0 0 1 0 1 1 1 0 0 1\n",
            " 1 1 0 1 0 1 0 0 0 1 0 1 0 1 0 1 1 0 1 1 0 1 1 0 0 1 1 1 1 0 1 1 1 0 1 1 1\n",
            " 0 0 1 0 1 1 1 1 1 1 0 1 0 0 0 0 1 0 0 0 0 1 0 1 1 0 1 1 0 1 1 0 1 0 0 0 1\n",
            " 0 0 1 0 0 1 0 1 1 1 1 1 0 0 0 1 0 1 1 1 0 1 1 1 1 1 0 1 0 1 0 0 1 1 0 1 1\n",
            " 1 1 0 1 1 0 1 1 1 0 1 0 0 1 0 0 1 1 1 1 0 1 1 1 1 1 1 0 0 1 0 1 0 1 0 0 1\n",
            " 0 0 0 1 1 0 0 1 0 0 0 1 0 1 0 1 0 0 1 1 1 0 1 0 1 1 1 1 1 0 0 1 0 1 1 0 1\n",
            " 0 0 1 1 0 0 0 0 1 0 1 0 1 0 0 1 0 0 1 0 1 1 1 0 0 0 1 1 0 0 1 0 1 0 1 1 0\n",
            " 1 0 1 0 1 1 0 0 0 0 1 0 0 1 0 1 1 1 1 0 1 0 1 0 0 0 0 0 1 1 1 1 1 1 1 1 0\n",
            " 1 0 1 1 1 1 1 1 0 0 0 1 0 0 1 1 1 0 1 1 1 0 1 0 0 0 0 0 1 0 1 1 0 1 0 1 1\n",
            " 1 0 0 0 1 1 0 0 1 1 0 0 1 0 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 1 1 0 1 1 1 0 1\n",
            " 1 1 1 1 1 1 0 1 1 0 1 1 0 1 0 0 1 0 1 1 0 0 0 0 1 0 1 1 0 1 0 1 1 1 1 1 1\n",
            " 0 1 0 0 0 1 0 0 0 1 0 0 1 1 0 1 0 1 1 1 0 1 1 0 0 1 1 0 1 0 0]\n",
            "probabilities: (882, 2) \n",
            " [1 1 1 0 1 1 0 0 0 1 1 1 0 1 0 1 0 0 0 1 1 1 1 1 1 0 0 0 1 1 0 0 0 1 1 0 0\n",
            " 0 1 1 1 1 1 0 0 1 1 1 1 0 1 0 1 1 0 0 1 1 1 1 0 1 0 1 0 0 1 1 0 0 0 1 0 0\n",
            " 1 1 0 1 0 1 0 0 1 1 1 0 0 0 0 1 0 1 0 1 1 1 0 1 0 0 0 0 0 0 0 0 1 0 1 1 0\n",
            " 1 1 0 1 1 1 0 1 1 1 1 0 1 0 1 1 0 1 0 1 1 0 1 1 1 0 0 1 0 0 0 1 1 1 1 0 1\n",
            " 1 0 1 0 0 1 1 1 1 1 0 0 0 0 0 0 0 1 1 1 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 1 0\n",
            " 1 1 0 1 1 0 1 1 0 0 0 0 0 0 1 0 1 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 0 1 1 0\n",
            " 1 1 0 1 1 0 1 0 1 1 1 1 1 1 1 0 0 1 1 0 1 1 0 0 1 1 1 1 0 0 0 0 0 1 0 1 0\n",
            " 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 1 1 1 1 1 0 1 0 1 0 0 1 0 0 0 1 0\n",
            " 1 1 0 1 0 0 1 0 0 1 0 0 1 0 1 0 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0\n",
            " 1 1 1 0 0 0 1 0 1 1 0 1 1 0 1 1 0 0 1 0 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1 0\n",
            " 1 1 0 1 1 1 1 1 0 0 0 0 1 1 0 1 1 0 0 1 0 0 0 1 0 0 1 0 0 1 0 1 1 1 1 0 1\n",
            " 1 1 1 1 0 1 0 1 1 0 0 0 0 0 0 1 1 1 1 1 0 0 0 1 1 0 1 0 1 0 0 1 0 0 0 0 0\n",
            " 0 1 1 0 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 0 0 1 0 1 1 1 0 0 1\n",
            " 1 1 0 1 0 1 0 0 0 1 0 1 0 1 0 1 1 0 1 1 0 1 1 0 0 1 1 1 1 0 1 1 1 0 1 1 1\n",
            " 0 0 1 0 1 1 1 1 1 1 0 1 0 0 0 0 1 0 0 0 0 1 0 1 1 0 1 1 0 1 1 0 1 0 0 0 1\n",
            " 0 0 1 0 0 1 0 1 1 1 1 1 0 0 0 1 0 1 1 1 0 1 1 1 1 1 0 1 0 1 0 0 1 1 0 1 1\n",
            " 1 1 0 1 1 0 1 1 1 0 1 0 0 1 0 0 1 1 1 1 0 1 1 1 1 1 1 0 0 1 0 1 0 1 0 0 1\n",
            " 0 0 0 1 1 0 0 1 0 0 0 1 0 1 0 1 0 0 1 1 1 0 1 0 1 1 1 1 1 0 0 1 0 1 1 0 1\n",
            " 0 0 1 1 0 0 0 0 1 0 1 0 1 0 0 1 0 0 1 0 1 1 1 0 0 0 1 1 0 0 1 0 1 0 1 1 0\n",
            " 1 0 1 0 1 1 0 0 0 0 1 0 0 1 0 1 1 1 1 0 1 0 1 0 0 0 0 0 1 1 1 1 1 1 1 1 0\n",
            " 1 0 1 1 1 1 1 1 0 0 0 1 0 0 1 1 1 0 1 1 1 0 1 0 0 0 0 0 1 0 1 1 0 1 0 1 1\n",
            " 1 0 0 0 1 1 0 0 1 1 0 0 1 0 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 1 1 0 1 1 1 0 1\n",
            " 1 1 1 1 1 1 0 1 1 0 1 1 0 1 0 0 1 0 1 1 0 0 0 0 1 0 1 1 0 1 0 1 1 1 1 1 1\n",
            " 0 1 0 0 0 1 0 0 0 1 0 0 1 1 0 1 0 1 1 1 0 1 1 0 0 1 1 0 1 0 0]\n",
            "std (882,) [39.55225144 44.24307382 39.95702987 44.15077296 44.52692436 32.65955726\n",
            " 38.30978126 49.39678238 49.45748901 46.0344237  48.68914754 37.90916865\n",
            " 46.3284601  42.53761975 38.98159334 39.41228697 45.51591387 42.05764548\n",
            " 36.69181803 44.56661043 44.17092725 48.11103255 45.13890402 47.24438388\n",
            " 46.78471822 37.75952436 41.93168343 45.56808287 42.16133109 39.4608572\n",
            " 49.58331517 49.60356217 39.84104837 38.61872983 33.4355199  43.00262111\n",
            " 48.76041787 42.27295274 41.58289944 23.51148901 43.01728578 34.55544826\n",
            " 47.96056862 45.7677455  47.0837506  49.20492092 32.82470483 47.53742239\n",
            " 45.91430671 47.25567394 47.12485838 28.64580896 33.95645547 44.63580067\n",
            " 46.32360008 49.58199524 43.47554894 46.34525564 45.51497482 45.00075364\n",
            " 48.0910272  47.24528403 40.8855526  47.34501058 49.23769418 33.39305548\n",
            " 47.70445346 41.09838335 36.64500981 47.86164707 36.66508221 48.38434827\n",
            " 47.86649076 41.1530897  42.28511057 47.6523168  35.39960904 37.92742473\n",
            " 41.05771149 47.96351229 47.60381482 38.98159334 45.26479447 38.1916623\n",
            " 41.17148701 48.00361601 44.49147154 49.07165445 48.97071962 47.87128471\n",
            " 48.26842326 45.58185889 49.22083315 45.87590104 41.33756599 48.0879991\n",
            " 43.89419538 44.36225458 48.16154621 49.72480813 49.11975607 48.53277117\n",
            " 49.18355741 47.22544328 41.36526891 38.98159334 47.10430001 49.49804185\n",
            " 45.34460286 43.45176087 49.50627584 34.86417791 28.51244977 47.2208432\n",
            " 46.92808611 39.55113044 36.97343683 39.80983572 33.70378751 45.52474076\n",
            " 39.96245286 43.12617394 33.78392886 46.05775479 41.18203082 48.45816323\n",
            " 47.46769026 43.76564548 31.63255636 38.98159334 48.90645177 42.02142123\n",
            " 48.43323774 45.99604489 47.47528462 45.25425776 35.3847983  43.56658427\n",
            " 43.48614163 43.39028686 48.60539593 35.60307444 40.41396593 45.23546188\n",
            " 46.75740568 35.46603883 43.89616484 32.53940256 39.00278612 49.50068856\n",
            " 40.65627893 49.5441347  38.98159334 40.4249664  37.39051675 44.12728517\n",
            " 46.62615576 40.87376057 45.98263403 47.70526016 39.88005262 42.87577402\n",
            " 39.34114113 47.57635524 33.20829372 46.86732947 48.03862565 45.31571788\n",
            " 45.5507801  43.06718876 43.33118578 46.36595594 31.48320581 40.44033705\n",
            " 49.24144411 48.43142663 49.25634861 46.69251961 35.74910494 46.69401608\n",
            " 49.58105051 49.55508325 38.98159334 42.60397714 47.67340998 42.06278514\n",
            " 35.65283738 46.69003367 48.1150707  42.30931632 46.30631867 36.64589078\n",
            " 48.185473   41.86422415 31.68873638 34.90323134 49.48045954 42.97842235\n",
            " 44.70081555 48.87638476 47.09391096 32.39133542 30.9683638  41.10692248\n",
            " 41.65569665 42.34667614 39.49729633 47.56639231 47.38741833 43.70369615\n",
            " 47.61340391 39.57383094 46.61281383 48.61761056 47.79028977 42.9887515\n",
            " 47.17815755 47.10888474 46.56511073 38.02596728 46.40181943 48.78419533\n",
            " 48.05276633 45.71377421 46.28051541 46.92929121 46.86263184 48.82912067\n",
            " 45.2909234  39.8798144  47.8405574  46.4812807  39.60547993 35.21675758\n",
            " 35.06853648 44.56056691 43.20326469 49.55839655 46.45511374 44.35405547\n",
            " 39.63685395 47.55384848 42.7681881  47.23793193 38.25899295 42.3860284\n",
            " 35.2746487  43.09122279 44.69059019 47.2252175  40.61719504 38.98159334\n",
            " 49.03275212 38.98159334 34.71578195 47.46732714 38.98159334 46.98611819\n",
            " 48.93604689 43.84541687 49.41503602 43.84900052 47.89649269 45.95794395\n",
            " 48.61662017 44.87969007 44.68411216 40.72299132 36.75094732 49.07959831\n",
            " 49.70555954 48.35659594 45.75509368 38.90407386 47.02026322 45.80790894\n",
            " 46.31060626 46.03907595 25.18858883 40.84989741 46.71527811 46.18467673\n",
            " 43.52707124 44.51380634 49.23769418 47.50185308 36.23934956 48.07601681\n",
            " 45.74847569 38.89499188 45.20110407 49.42652567 44.11869677 41.06486341\n",
            " 23.58640515 38.60145214 42.48085263 46.35202033 49.37016555 48.74218853\n",
            " 40.17645801 49.66370031 44.58438662 38.98159334 46.20306893 48.47800142\n",
            " 44.95227663 48.36175489 46.83361743 43.42030009 46.71946479 47.86798475\n",
            " 46.85551975 43.46597442 46.8992406  41.58325527 43.62586622 31.05779279\n",
            " 47.11280775 39.26489587 35.92499708 36.34123149 29.49296039 48.30705648\n",
            " 27.77060002 45.40981015 45.28506063 46.49872055 44.25653078 43.16174959\n",
            " 46.49802642 41.97285878 34.71499416 47.05570219 46.54380612 46.14442291\n",
            " 47.7715445  37.84415746 49.20475183 48.26029541 48.20013509 32.64179728\n",
            " 32.89896776 49.07340504 44.8745464  45.47727135 34.61116524 44.12291975\n",
            " 48.10610178 38.98159334 38.98159334 46.37888092 45.19855811 47.54571295\n",
            " 49.1370285  47.23854836 37.58708306 45.54601254 46.61497967 47.71794382\n",
            " 41.34771357 42.23946659 45.25671844 43.52320392 46.90250847 47.1297613\n",
            " 47.27170411 45.36064362 45.51307854 49.64045946 39.93777647 46.80327204\n",
            " 47.19440424 48.18751261 46.39523873 41.02812823 46.29756325 31.64793234\n",
            " 49.63197999 43.81604201 40.26625917 39.75682166 45.58353627 45.82007948\n",
            " 49.01023463 33.64340758 41.40391598 44.65385777 38.98159334 46.27336671\n",
            " 46.75383246 44.51880845 32.87564387 34.73608259 33.06722076 47.87458002\n",
            " 45.95345929 47.34036203 36.00850265 43.11971802 33.50313102 30.27038286\n",
            " 33.5630112  41.02812823 48.14284303 44.75356448 47.30629846 46.51058252\n",
            " 43.84490817 48.23620792 43.36753397 47.98616529 47.28509675 49.51483775\n",
            " 47.50007329 44.6562889  46.59046826 45.54121215 48.50954639 44.39600522\n",
            " 49.69526231 34.73484047 43.96190961 47.80085127 42.1436534  47.86874195\n",
            " 45.28654323 48.67595616 49.58305915 48.20387402 40.8607204  39.17354617\n",
            " 32.19998912 48.0663731  48.70309602 44.11547285 48.72791099 31.14563488\n",
            " 41.91818621 46.52276681 35.75109236 44.71919967 38.98159334 38.04360582\n",
            " 48.61990561 44.75138651 48.5563781  38.98159334 45.15578421 42.08398718\n",
            " 41.40414673 48.3726775  33.16773671 49.30902563 48.19911992 42.54901406\n",
            " 47.83886415 42.89811276 27.72481338 45.05093708 36.34746203 47.53703306\n",
            " 42.87648191 35.32173472 40.58391474 40.36980428 44.21706941 46.54613821\n",
            " 49.49675396 43.96921068 48.93752914 44.35193694 46.4773237  48.1434895\n",
            " 42.89373028 45.57237986 47.83293505 32.39170445 38.98159334 38.98159334\n",
            " 37.04551808 22.25343892 42.29497129 45.28778812 46.03872049 46.62624597\n",
            " 47.45140514 47.15076638 32.5894399  47.58857438 47.29635475 33.46133273\n",
            " 46.65772932 47.65600855 48.24250775 46.50852588 46.43490027 44.21027777\n",
            " 47.06781999 33.37934391 31.05779279 46.68725645 45.01162371 42.95836689\n",
            " 35.3281578  49.1711659  47.42880823 46.60944886 28.13993573 46.95691607\n",
            " 37.71724339 28.97128171 45.16163559 46.54613821 47.65359401 37.1963577\n",
            " 47.56657259 48.66896804 49.58855234 46.44572205 43.9693507  47.68743767\n",
            " 48.97842291 39.08601413 47.58301258 42.93698654 37.48266693 48.23622987\n",
            " 39.6690894  36.77088058 49.26416155 43.20723034 46.3770541  44.35155095\n",
            " 47.61770179 45.4913531  34.7578611  49.4553219  44.61343622 47.68535776\n",
            " 47.62971881 46.63813265 40.94523351 40.53024421 48.68842247 25.60297973\n",
            " 29.72796409 45.61505306 47.31818664 42.47847857 43.92921008 48.83515784\n",
            " 42.10115291 48.91276492 34.43341588 45.86354301 44.8463108  45.39216028\n",
            " 40.09023999 43.5980549  42.99440612 43.93759201 34.73684198 43.24091217\n",
            " 47.62739338 45.74829232 39.7294646  46.76764092 47.57713831 35.64186726\n",
            " 46.10038055 40.01435102 40.40518949 41.86922406 42.55355954 49.65638186\n",
            " 47.35422596 41.33361329 46.79761011 43.49621996 41.96478507 47.21592759\n",
            " 47.56132151 49.61148299 31.44395628 49.07141664 39.40899266 37.5283372\n",
            " 47.41601643 45.40062885 47.30305765 42.7639302  48.11809987 38.68804661\n",
            " 35.83350014 46.64644465 46.07877772 27.05519691 46.32393777 47.49413453\n",
            " 38.37005982 48.72323391 42.05283576 49.28870647 35.77644675 46.03907595\n",
            " 49.53576104 48.20245851 46.20680565 47.40510638 48.13003301 31.65268277\n",
            " 39.31191302 46.39442089 44.86967707 41.51385574 37.15002187 48.11639139\n",
            " 31.64978771 45.11064248 38.98159334 45.74912878 48.84412647 45.50383755\n",
            " 28.29913535 43.37659918 38.98159334 38.98159334 45.51914236 32.75524886\n",
            " 34.77959769 49.0077514  47.74133797 30.52808279 48.15654635 40.9926055\n",
            " 30.21583552 47.87383667 48.59126898 39.4899628  47.19406252 44.8366092\n",
            " 48.26106571 41.38277407 45.79152516 40.10540006 48.73543888 34.8335806\n",
            " 45.1994698  40.63692659 48.03179925 48.67965044 47.910074   41.20721546\n",
            " 47.95519132 43.82441299 48.32921956 45.60674617 49.17660751 48.88567455\n",
            " 49.05390744 49.69156133 45.26934208 45.36304413 27.24144481 43.91305811\n",
            " 49.16740513 48.87670074 47.25919686 45.99803254 34.64033028 44.67466958\n",
            " 49.32191328 45.62327478 45.76559545 49.32520275 47.69237139 42.88695563\n",
            " 45.40756481 47.95245318 48.01425307 48.15415964 48.7637832  48.83438433\n",
            " 46.59111527 39.65312377 35.18251542 42.48996501 31.20791596 49.31878694\n",
            " 33.65501847 49.78717353 41.8445972  45.25576342 49.29265255 47.34368909\n",
            " 42.14783255 30.10912376 37.87262096 38.07728985 45.6926483  42.25619798\n",
            " 33.8664414  44.14198015 48.51398397 45.42008736 48.8064797  43.29543818\n",
            " 34.87084234 38.31681701 24.04563895 46.46364849 47.45631283 42.31623894\n",
            " 48.43483453 48.75134752 47.59425894 33.91686137 47.53703306 46.48238342\n",
            " 40.92934807 43.50080136 49.19079148 31.31828595 49.00731432 39.01628702\n",
            " 49.68843271 46.55043277 47.6186868  47.34047047 48.3054214  45.71986211\n",
            " 36.12192948 31.19056391 46.55775797 38.69086046 41.16346426 37.60577893\n",
            " 44.84157073 49.75327586 41.07960584 49.44500402 37.88247352 39.26802866\n",
            " 44.69632749 48.83070038 47.72850413 38.18755387 35.13338108 49.3873866\n",
            " 43.29467584 43.56770081 36.54600283 44.44331815 32.0865507  48.07408072\n",
            " 32.16488273 47.2362412  47.98119503 38.46794283 47.13036464 49.54384474\n",
            " 30.96912264 47.33515702 49.46342932 36.99850232 49.67885902 45.4262249\n",
            " 37.25030392 36.98424914 47.77669448 32.38853892 42.01726119 48.97976315\n",
            " 47.88613913 39.8192186  48.63819735 42.31768027 48.80206816 47.95986525\n",
            " 46.56039998 45.28181162 23.74944525 33.20055421 38.98159334 47.00431339\n",
            " 47.17428942 49.05642973 38.98159334 44.75825041 42.18424595 39.41228697\n",
            " 47.19406252 47.90421557 46.2551208  47.82657816 45.91662078 47.29635475\n",
            " 46.27918812 48.5119129  45.35337957 48.05016677 46.35830763 30.48256229\n",
            " 44.36083977 36.4298468  40.94750182 47.92350411 47.28166044 38.54719921\n",
            " 45.14179333 43.97946822 33.47672417 48.50111072 44.76924202 44.07259249\n",
            " 33.40565828 42.09103605 46.20281968 37.64788182 46.52939426 46.75380672\n",
            " 44.20049494 49.10737849 43.00996587 49.0420507  47.18035426 48.40261215\n",
            " 38.98159334 47.91914261 46.86295532 48.70085665 48.86320077 47.3154212\n",
            " 46.06874006 49.01401433 47.63815424 40.72711916 39.71362276 41.9695145\n",
            " 44.3812395  29.90050992 30.30663572 48.83386891 48.70838425 39.88362006\n",
            " 45.24531556 43.52517222 49.14804978 34.28429463 43.63574529 48.99303142\n",
            " 26.36843388 38.60906842 33.23707198 49.23965014 48.18817493 40.1283677\n",
            " 47.52329482 45.59085341 45.44126074 42.2451453  39.36442536 42.71669515\n",
            " 47.98783695 48.26245112 37.32509267 38.98159334 46.1597353  29.05786613\n",
            " 45.8659683  38.98159334 39.79988106 32.46435507 49.80210109 47.61641789\n",
            " 48.0423295  43.59762617 47.78981063 47.63974823 40.37737939 47.93749098]\n",
            "selection [481  39 294 782 710 278 545 852 597 664] (10,) [22.25343892 23.51148901 23.58640515 23.74944525 24.04563895 25.18858883\n",
            " 25.60297973 26.36843388 27.05519691 27.24144481]\n",
            "trainset before adding uncertain samples (420, 10) (420,)\n",
            "trainset after adding uncertain samples (430, 10) (430,)\n",
            "updated train set: (430, 10) (430,) unique(labels): [208 222] [0 1]\n",
            "val set: (872, 10) (872,)\n",
            "\n",
            "Train set: (430, 10)\n",
            "Validation set: (872, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 43\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.276 s \n",
            "\n",
            "Accuracy rate is 82.258065 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.90      0.88       321\n",
            "           1       0.68      0.61      0.64       113\n",
            "\n",
            "    accuracy                           0.82       434\n",
            "   macro avg       0.77      0.75      0.76       434\n",
            "weighted avg       0.82      0.82      0.82       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[288  33]\n",
            " [ 44  69]]\n",
            "--------------------------------\n",
            "val predicted: (872,) [1 1 1 0 1 1 0 0 0 1 1 1 0 1 0 1 0 0 0 1 1 1 1 1 1 0 0 0 1 1 0 0 0 1 1 0 0\n",
            " 0 1 1 1 1 0 0 1 1 1 1 0 1 0 1 1 0 0 1 1 1 1 0 1 0 1 0 0 1 1 0 0 0 1 0 0 1\n",
            " 1 0 1 0 1 0 0 1 1 1 0 0 0 0 1 0 1 0 1 1 1 0 1 0 0 0 0 0 0 0 0 1 0 1 1 0 1\n",
            " 1 0 1 1 1 0 1 1 1 1 0 1 0 1 1 0 1 0 1 1 0 1 1 1 0 0 1 0 0 0 1 1 1 1 0 1 1\n",
            " 0 1 0 0 1 1 1 1 1 0 0 0 0 0 0 0 1 1 1 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 1 0 1\n",
            " 1 0 1 1 0 1 1 0 0 0 0 0 0 1 0 1 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 0 1 1 0 1\n",
            " 1 0 1 1 0 1 0 1 1 1 1 1 1 1 0 0 1 1 0 1 1 0 0 1 1 1 1 0 0 0 0 0 1 0 1 0 0\n",
            " 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 0 0 0 1 1 0\n",
            " 1 0 0 1 0 0 1 0 0 1 0 1 0 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1\n",
            " 0 0 0 1 0 1 1 0 1 1 0 1 1 0 0 1 0 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 0\n",
            " 1 1 1 1 1 0 0 0 0 1 1 0 1 1 0 0 1 0 0 0 1 0 0 1 0 0 1 0 1 1 1 1 0 1 1 1 1\n",
            " 1 0 1 0 1 1 0 0 0 0 0 0 1 1 1 1 1 0 0 0 1 1 0 1 0 1 0 0 1 0 0 0 0 0 0 1 1\n",
            " 0 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 0 0 1 0 1 1 1 0 0 1 1 0 1\n",
            " 0 1 0 0 0 1 0 1 0 1 0 1 1 0 1 1 0 1 1 0 0 1 1 1 1 0 1 1 1 0 1 1 1 0 0 1 0\n",
            " 1 1 1 1 1 1 0 1 0 0 0 0 1 0 0 0 0 1 0 1 1 0 1 0 1 1 0 1 0 0 0 1 0 0 1 0 0\n",
            " 1 0 1 1 1 1 1 0 0 0 1 0 1 1 1 0 1 1 1 1 1 0 1 0 1 0 0 1 1 0 1 1 1 1 0 1 1\n",
            " 1 1 1 0 1 0 0 1 0 0 1 1 1 1 0 1 1 1 1 1 1 0 0 1 0 1 0 1 0 0 1 0 0 0 1 1 0\n",
            " 0 1 0 0 0 1 0 1 0 1 0 0 1 1 1 0 1 0 1 1 1 1 1 0 0 1 0 1 1 1 0 0 1 1 0 0 0\n",
            " 0 1 0 1 0 1 0 0 1 0 0 1 0 1 1 1 0 0 0 1 1 0 0 1 0 1 0 1 1 0 1 0 1 0 1 1 0\n",
            " 0 0 1 0 0 1 0 1 1 1 1 0 1 0 1 0 0 0 0 0 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1\n",
            " 0 0 0 1 0 0 1 1 1 0 1 1 1 0 1 0 0 0 0 0 1 0 1 1 0 1 0 1 1 1 0 0 0 1 0 0 1\n",
            " 1 0 0 1 0 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 1 1 0 1 1 1 0 1 1 1 1 1 1 1 0 1 1\n",
            " 0 1 1 0 1 0 0 1 0 1 1 0 0 0 0 1 0 1 1 0 1 0 1 1 1 1 1 1 0 0 0 0 1 0 0 0 1\n",
            " 0 0 1 1 0 1 0 1 1 1 0 1 1 0 0 1 1 0 1 0 0]\n",
            "probabilities: (872, 2) \n",
            " [1 1 1 0 1 1 0 0 0 1 1 1 0 1 0 1 0 0 0 1 1 1 1 1 1 0 0 0 1 1 0 0 0 1 1 0 0\n",
            " 0 1 1 1 1 0 0 1 1 1 1 0 1 0 1 1 0 0 1 1 1 1 0 1 0 1 0 0 1 1 0 0 0 1 0 0 1\n",
            " 1 0 1 0 1 0 0 1 1 1 0 0 0 0 1 0 1 0 1 1 1 0 1 0 0 0 0 0 0 0 0 1 0 1 1 0 1\n",
            " 1 0 1 1 1 0 1 1 1 1 0 1 0 1 1 0 1 0 1 1 0 1 1 1 0 0 1 0 0 0 1 1 1 1 0 1 1\n",
            " 0 1 0 0 1 1 1 1 1 0 0 0 0 0 0 0 1 1 1 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 1 0 1\n",
            " 1 0 1 1 0 1 1 0 0 0 0 0 0 1 0 1 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 0 1 1 0 1\n",
            " 1 0 1 1 0 1 0 1 1 1 1 1 1 1 0 0 1 1 0 1 1 0 0 1 1 1 1 0 0 0 0 0 1 0 1 0 0\n",
            " 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 0 0 0 1 1 0\n",
            " 1 0 0 1 0 0 1 0 0 1 0 1 0 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1\n",
            " 0 0 0 1 0 1 1 0 1 1 0 1 1 0 0 1 0 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 0\n",
            " 1 1 1 1 1 0 0 0 0 1 1 0 1 1 0 0 1 0 0 0 1 0 0 1 0 0 1 0 1 1 1 1 0 1 1 1 1\n",
            " 1 0 1 0 1 1 0 0 0 0 0 0 1 1 1 1 1 0 0 0 1 1 0 1 0 1 0 0 1 0 0 0 0 0 0 1 1\n",
            " 0 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 0 0 1 0 1 1 1 0 0 1 1 0 1\n",
            " 0 1 0 0 0 1 0 1 0 1 0 1 1 0 1 1 0 1 1 0 0 1 1 1 1 0 1 1 1 0 1 1 1 0 0 1 0\n",
            " 1 1 1 1 1 1 0 1 0 0 0 0 1 0 0 0 0 1 0 1 1 0 1 0 1 1 0 1 0 0 0 1 0 0 1 0 0\n",
            " 1 0 1 1 1 1 1 0 0 0 1 0 1 1 1 0 1 1 1 1 1 0 1 0 1 0 0 1 1 0 1 1 1 1 0 1 1\n",
            " 1 1 1 0 1 0 0 1 0 0 1 1 1 1 0 1 1 1 1 1 1 0 0 1 0 1 0 1 0 0 1 0 0 0 1 1 0\n",
            " 0 1 0 0 0 1 0 1 0 1 0 0 1 1 1 0 1 0 1 1 1 1 1 0 0 1 0 1 1 1 0 0 1 1 0 0 0\n",
            " 0 1 0 1 0 1 0 0 1 0 0 1 0 1 1 1 0 0 0 1 1 0 0 1 0 1 0 1 1 0 1 0 1 0 1 1 0\n",
            " 0 0 1 0 0 1 0 1 1 1 1 0 1 0 1 0 0 0 0 0 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1\n",
            " 0 0 0 1 0 0 1 1 1 0 1 1 1 0 1 0 0 0 0 0 1 0 1 1 0 1 0 1 1 1 0 0 0 1 0 0 1\n",
            " 1 0 0 1 0 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 1 1 0 1 1 1 0 1 1 1 1 1 1 1 0 1 1\n",
            " 0 1 1 0 1 0 0 1 0 1 1 0 0 0 0 1 0 1 1 0 1 0 1 1 1 1 1 1 0 0 0 0 1 0 0 0 1\n",
            " 0 0 1 1 0 1 0 1 1 1 0 1 1 0 0 1 1 0 1 0 0]\n",
            "std (872,) [36.79706886 44.22568529 38.00265371 44.21771082 45.41148942 22.59041119\n",
            " 36.26531927 49.04320726 49.50373391 46.66890059 48.59900198 36.79215459\n",
            " 46.76034369 38.25504545 38.62416951 33.10395934 44.67312958 36.13927079\n",
            " 36.87453028 44.41326826 42.14032404 47.9651905  46.34804621 47.60499012\n",
            " 45.0350726  38.14210962 41.97427914 46.22554651 44.26890295 40.80726612\n",
            " 49.47681226 49.38516186 35.04470046 39.66723936 27.15729752 42.58770747\n",
            " 48.74819326 42.97275549 42.22407668 44.2943473  36.30264927 48.33999448\n",
            " 45.20713969 47.96077931 49.00839878 33.56650419 48.16234273 45.48392402\n",
            " 47.42593742 46.0105515  32.19058061 37.11485425 46.31625432 45.30465757\n",
            " 49.56425287 42.36394269 46.86104586 44.60188737 43.58701547 47.67841201\n",
            " 45.69824896 38.68262067 46.85431307 49.12893581 35.04150232 47.40162859\n",
            " 41.3944363  37.64397749 47.90548897 34.3689034  48.31041131 48.12976013\n",
            " 43.45439757 44.74022102 46.77371825 29.98708061 38.13023045 39.00223291\n",
            " 47.36724266 48.53903124 38.62416951 45.44645733 39.95785754 41.74645008\n",
            " 47.25138782 45.75279858 49.34483922 48.8935976  47.89296106 48.06076838\n",
            " 46.26208788 49.07244849 46.34900535 41.08348031 48.43095591 42.16427088\n",
            " 44.78188235 48.51749147 49.67518823 48.97362688 48.00440182 49.26106421\n",
            " 46.92798472 39.903373   38.62416951 46.49828208 49.47031366 46.51436488\n",
            " 43.7223869  49.30017727 26.45460938 32.7121887  47.70687444 46.16935344\n",
            " 40.77754752 38.86100294 38.35086058 38.58883141 45.92053441 38.18346449\n",
            " 44.52763827 35.60845178 46.34702589 41.53449145 48.53380532 47.50641282\n",
            " 43.49977917 31.89589663 38.62416951 48.83407733 38.58874111 48.42049738\n",
            " 46.12894025 47.16518628 45.15160785 35.73894159 40.76622658 43.4560473\n",
            " 40.10187357 48.91569297 36.50112038 44.46109759 45.77434274 46.26091268\n",
            " 39.3388302  40.30796783 30.90368065 41.23175237 49.21840271 41.12223013\n",
            " 49.55518452 38.62416951 43.46602929 37.73073964 41.22842822 45.38783203\n",
            " 44.73684321 46.01854329 44.94619721 35.65995172 43.75449792 43.24309613\n",
            " 47.67755185 36.21181142 44.88630496 47.65329892 45.93433773 43.97678753\n",
            " 41.4446485  42.48284105 46.07256996 32.01048259 38.09339382 49.21688931\n",
            " 47.31247653 49.26090988 47.17896494 36.00464748 44.92896426 49.48475981\n",
            " 49.56525635 38.62416951 39.26035109 47.98171205 43.34269879 34.76426931\n",
            " 46.86523606 47.51475111 43.0442947  47.15977107 33.29386896 48.33467451\n",
            " 40.10238489 26.52583802 41.75242596 49.29561169 44.83390242 45.12567277\n",
            " 48.71608027 46.58307971 36.74860362 35.15241768 39.95909789 37.60075983\n",
            " 44.09338769 40.63777012 48.44738537 47.05372853 43.88070817 47.65970617\n",
            " 41.69444084 47.79501696 48.94261449 46.87170608 44.93692425 46.89845354\n",
            " 46.8265452  46.78186632 35.74133867 45.79762579 48.38130651 48.65781116\n",
            " 44.35150479 45.60211087 46.61827481 47.16641625 48.94318845 42.87077275\n",
            " 34.3924613  48.47266918 46.32449315 39.16009831 36.1105214  34.67046332\n",
            " 46.29788142 41.76614851 49.59393934 47.22684536 43.11794085 41.56794734\n",
            " 46.49540079 40.88821064 47.44550513 35.60074538 42.81652905 34.67481128\n",
            " 45.91452816 42.76770269 47.86327193 42.72958178 38.62416951 49.06159169\n",
            " 38.62416951 38.40953402 48.13560456 38.62416951 47.86608123 48.98387026\n",
            " 42.58413148 49.29984443 43.37359397 48.0452856  46.1259773  48.58844527\n",
            " 44.85030751 44.58801436 39.86284854 30.44949153 49.12274841 49.48684865\n",
            " 47.99314895 46.42652662 39.3344013  45.29019206 45.97049193 46.76647366\n",
            " 46.30060519 42.37504167 46.64554045 47.1588802  46.37893691 45.01735841\n",
            " 49.12893581 47.23140284 36.18412776 47.3881547  44.19448534 42.03947162\n",
            " 42.31564737 49.63577854 40.05807695 35.1986477  37.24852914 37.08930732\n",
            " 45.53378106 49.06047872 48.68735538 37.693769   49.61174964 44.70298905\n",
            " 38.62416951 45.91853666 48.13107463 47.15958483 48.71999507 46.01044043\n",
            " 40.16529365 45.20079639 47.76704437 47.86229629 43.66283525 46.39664598\n",
            " 37.70916108 45.45479261 36.01004249 46.21164795 41.18466475 34.89359277\n",
            " 37.18454898 20.32904162 48.48097277 26.82009689 43.17142311 46.67950805\n",
            " 46.31893981 41.65136271 40.21479375 46.81575709 44.73912567 28.67369456\n",
            " 47.68266455 47.29758302 46.96369671 48.75210061 40.4754742  49.06881567\n",
            " 48.84928331 47.76176368 39.74379483 34.9212453  49.23870217 44.33853184\n",
            " 44.60729694 33.12540652 44.41189187 47.65460909 38.62416951 38.62416951\n",
            " 45.60915872 46.33034542 47.42442025 49.17145425 46.06929802 37.76041407\n",
            " 46.6814938  45.78577036 47.01523036 40.60241223 42.35835474 46.79039176\n",
            " 42.52444526 45.02306267 47.23108066 47.4803017  42.66885139 42.08458006\n",
            " 49.52907278 41.3086585  45.69832399 48.31045165 48.34681414 45.58742931\n",
            " 40.12248244 44.84524566 23.21728994 49.46714916 40.56726485 40.00182427\n",
            " 36.56666518 44.18292225 46.10722281 49.48572606 40.37498312 38.94086937\n",
            " 44.62067797 38.62416951 46.03021782 45.63219623 41.31045802 23.85752819\n",
            " 28.76218361 32.12100868 46.71169248 47.26690545 47.26990237 39.54960117\n",
            " 44.41750697 33.65351423 27.0473965  34.68039786 40.12248244 47.33348455\n",
            " 43.40735399 46.91498566 44.598725   44.55452408 47.89736142 43.35402485\n",
            " 47.98488216 46.58047241 49.47380149 48.26498368 43.84951829 42.77595476\n",
            " 44.24668332 48.27141294 44.12508082 49.56635583 36.01208328 44.00934804\n",
            " 48.02400421 43.77576514 47.76642661 45.82867741 48.94490817 49.56933198\n",
            " 47.76740793 39.82481899 38.18834636 34.67351532 47.99284875 48.96410919\n",
            " 45.03786279 48.58371025 32.66535254 43.70857415 47.83352314 39.56587338\n",
            " 43.69889979 38.62416951 37.82787413 48.59916121 45.23132341 48.4452453\n",
            " 38.62416951 41.64107384 38.54858399 39.7445993  47.82062849 28.82017037\n",
            " 49.46555766 47.69524311 40.32896751 46.84566273 42.94478165 34.59010108\n",
            " 45.59711503 37.25633776 47.7813946  43.74015749 38.42646739 42.24253605\n",
            " 40.48751881 43.62162544 45.6278709  49.51960449 41.60047455 48.56320901\n",
            " 40.73271269 45.23017662 47.90030463 43.69950979 46.28277933 48.37547966\n",
            " 24.83586556 38.62416951 38.62416951 38.66068234 41.5243397  45.44419261\n",
            " 46.70429607 45.34360643 47.68593029 46.32818769 30.23309403 46.62491726\n",
            " 47.83895519 33.23601737 43.84046313 47.10619904 48.8926793  46.64144208\n",
            " 47.29967127 44.13931716 46.40644913 39.25036821 36.01004249 47.24233099\n",
            " 45.61184178 42.87385856 36.84108649 48.97477565 47.74408721 46.11132773\n",
            " 35.68150846 46.5577066  39.78531551 25.82440796 45.36959736 45.6278709\n",
            " 46.1512844  39.28522983 48.01464184 48.70013973 49.6016561  43.43707658\n",
            " 43.34121552 47.34210629 48.76682621 40.51929734 47.87600254 39.79659425\n",
            " 38.24392632 47.54806016 35.03535937 41.35496424 49.03747132 42.92766187\n",
            " 44.5720952  43.96352608 47.5852643  43.11694391 33.56731044 49.40683931\n",
            " 45.35229728 45.76695937 46.62124487 46.52090856 44.21563968 40.82378245\n",
            " 48.05279032 27.01835024 45.87505936 46.50729149 39.69282486 42.33724122\n",
            " 48.80443044 38.8981234  49.01184206 27.91222982 45.82709978 41.77086299\n",
            " 46.50186822 38.59387915 43.71812342 42.09159409 45.00519712 31.71444501\n",
            " 44.65979651 47.26797168 46.26998505 37.50696676 46.68179854 47.51757364\n",
            " 30.39267863 45.59588509 32.93548884 37.42742271 42.13686209 40.51440611\n",
            " 49.24187309 46.4562832  38.84923705 46.49443282 39.87542247 42.15688115\n",
            " 46.03747072 47.51005044 49.42971702 25.3308779  49.1656169  39.2149959\n",
            " 40.23139363 47.2419242  45.40969481 46.9458865  40.71663763 48.28784679\n",
            " 41.92642266 37.36031605 46.63679973 41.67222306 48.14588532 48.06764362\n",
            " 38.12118918 48.63048056 41.58095985 49.40755568 39.00964818 46.30060519\n",
            " 49.426417   48.39842372 45.95518053 47.23047961 48.51580302 33.39880633\n",
            " 36.77363612 46.59584077 44.84209978 40.45772809 36.62621467 47.73777033\n",
            " 33.62749334 45.03170618 38.62416951 45.38027428 48.76369346 46.04653103\n",
            " 34.48485966 41.38261296 38.62416951 38.62416951 41.813933   27.40365702\n",
            " 33.29654962 49.2133629  48.33826639 30.53374702 47.86527436 42.73160545\n",
            " 38.59947894 48.53980941 48.56068234 35.35827209 47.49030836 44.17068627\n",
            " 47.37691027 29.4871587  47.24065215 40.16626185 48.29802258 36.69755742\n",
            " 44.80178272 36.02491515 47.52308801 48.85877934 47.69319527 41.46677919\n",
            " 48.01991443 41.76913748 48.01777143 45.77557009 48.85060761 49.15786759\n",
            " 48.96282009 49.5526696  43.09501743 45.55490662 44.46006383 49.11415659\n",
            " 48.99639934 46.98602392 44.99110207 34.26824238 44.46932467 48.80778912\n",
            " 46.85138112 43.54456727 49.47769299 46.94034362 40.72456659 40.00899229\n",
            " 48.37981224 47.52555981 47.17756607 48.62404663 48.7222949  45.26191772\n",
            " 40.60097761 35.97661207 44.23819663 34.77256416 48.87604903 31.215792\n",
            " 49.73907058 38.92835056 47.1560529  49.3073046  45.7930706  40.2070633\n",
            " 31.64362796 39.48666898 36.81579617 43.77833427 42.14276619 35.0104176\n",
            " 42.9950619  48.9866793  45.12533385 48.4740572  44.70376174 33.5786512\n",
            " 38.31337421 46.19964167 47.5082057  42.62042565 48.41608094 48.83714061\n",
            " 47.15831409 36.44543144 47.7813946  45.18025093 43.29585565 42.58136936\n",
            " 48.80040075 34.66241502 48.73570435 38.99169151 49.47540719 46.45189444\n",
            " 45.61893598 48.27913914 47.44878948 46.2665566  34.8613489  22.45392617\n",
            " 44.50952958 40.04894469 39.73460703 38.37804794 42.34483555 49.70331171\n",
            " 42.14370141 49.39152375 35.21663537 42.00926704 42.76284376 48.74348541\n",
            " 46.91196969 37.98122326 40.40474892 49.24883914 40.426372   42.33076996\n",
            " 39.30458869 42.70936    38.73559687 47.17576117 29.30458704 46.05555668\n",
            " 48.13781407 42.506934   46.07695765 49.61619994 30.41629132 45.12714055\n",
            " 49.37409487 39.57302655 49.43811157 45.35207066 40.36206917 34.99395293\n",
            " 48.58967562 34.14894314 43.72700219 48.55251819 48.17759828 39.49133395\n",
            " 49.10398009 41.8827397  48.78637355 47.62587062 44.33797074 46.15216332\n",
            " 30.94331975 38.62416951 46.81803366 47.30257184 49.0587381  38.62416951\n",
            " 45.79510241 44.98486152 33.10395934 47.49030836 46.6956093  45.72073902\n",
            " 47.71895763 44.49335274 47.83895519 47.12700693 48.55616068 46.14110443\n",
            " 47.93827678 46.73749212 19.56436314 43.84468278 38.07615781 41.45416817\n",
            " 47.53086092 47.78388135 37.942534   45.86662072 43.98798553 29.77315703\n",
            " 48.48349906 43.23077006 43.14102787 31.02576742 42.88660249 46.84010824\n",
            " 38.04163594 46.84826329 46.94390176 42.37976722 49.00972651 44.72884151\n",
            " 48.46167613 45.62399926 48.10351457 38.62416951 46.24886795 47.51217159\n",
            " 48.34931973 49.06940401 46.35951031 46.50958062 49.08937781 48.00230939\n",
            " 40.91792043 44.15693792 43.87536145 43.66182496 34.41571037 28.08481129\n",
            " 48.59986191 49.00779149 31.74230447 43.48527704 43.56505209 49.04662866\n",
            " 38.25028828 42.57967397 49.41254919 41.31387724 34.44347879 49.23039195\n",
            " 47.65582436 39.74182901 48.18694349 44.09615455 43.98481724 43.10672251\n",
            " 41.42085504 43.28682949 47.55442859 47.1574632  37.81162344 38.62416951\n",
            " 45.44993412 26.69631941 44.55559062 38.62416951 38.07492738 36.24848137\n",
            " 49.73923609 47.50908409 48.27541326 43.93650352 47.96783167 47.17515796\n",
            " 34.68876269 48.10503367]\n",
            "selection [794 319 725   5 374 389 474 579 507 110] (10,) [19.56436314 20.32904162 22.45392617 22.59041119 23.21728994 23.85752819\n",
            " 24.83586556 25.3308779  25.82440796 26.45460938]\n",
            "trainset before adding uncertain samples (430, 10) (430,)\n",
            "trainset after adding uncertain samples (440, 10) (440,)\n",
            "updated train set: (440, 10) (440,) unique(labels): [213 227] [0 1]\n",
            "val set: (862, 10) (862,)\n",
            "\n",
            "Train set: (440, 10)\n",
            "Validation set: (862, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 44\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.275 s \n",
            "\n",
            "Accuracy rate is 82.258065 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.90      0.88       321\n",
            "           1       0.68      0.59      0.64       113\n",
            "\n",
            "    accuracy                           0.82       434\n",
            "   macro avg       0.77      0.75      0.76       434\n",
            "weighted avg       0.82      0.82      0.82       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[290  31]\n",
            " [ 46  67]]\n",
            "--------------------------------\n",
            "val predicted: (862,) [1 1 1 0 1 0 0 0 1 1 1 0 1 0 1 0 0 0 1 1 1 1 1 1 0 0 0 1 1 0 0 0 1 1 0 0 0\n",
            " 1 1 1 1 0 0 1 1 1 1 0 1 0 1 1 0 0 1 1 1 1 0 1 0 1 0 0 1 1 0 0 0 1 0 0 1 1\n",
            " 0 1 0 1 0 0 1 1 1 0 0 0 0 1 0 1 0 1 1 1 0 1 0 0 0 0 0 0 0 0 1 0 1 1 0 1 0\n",
            " 1 1 1 0 1 1 1 1 0 1 0 1 1 0 1 0 1 1 0 1 1 1 0 0 1 0 0 0 1 1 1 1 0 1 1 0 1\n",
            " 0 0 1 1 1 1 1 0 0 0 0 0 0 0 1 1 1 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 1 0 1 1 0\n",
            " 1 1 0 1 1 0 0 0 0 0 0 1 0 1 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 0 1 1 0 1 1 0\n",
            " 1 1 0 1 0 1 1 1 1 1 1 1 0 0 1 1 0 1 1 0 0 1 1 1 1 0 0 0 0 0 1 0 1 0 0 0 1\n",
            " 0 1 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 0 0 0 1 1 0 1 0\n",
            " 0 1 0 0 1 0 0 1 0 1 0 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 0 0\n",
            " 1 0 1 1 0 1 1 0 1 1 0 0 1 0 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 0 1 1 1\n",
            " 1 0 0 0 0 1 1 0 1 1 0 0 1 0 0 1 0 0 1 0 0 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 1\n",
            " 1 0 0 0 0 0 0 1 1 1 1 1 0 0 0 1 1 0 1 0 1 0 0 1 0 0 0 0 0 0 1 1 0 1 1 1 0\n",
            " 1 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 0 0 1 0 1 1 0 0 1 1 0 1 0 1 0 0 0 1\n",
            " 0 1 0 1 0 1 1 0 1 1 0 1 1 0 0 1 1 1 1 0 1 1 0 1 1 1 0 0 1 0 1 1 1 1 1 1 0\n",
            " 1 0 0 0 0 1 0 0 0 0 1 0 1 1 0 1 0 1 1 0 1 0 0 0 1 0 0 1 0 0 1 0 1 1 1 1 1\n",
            " 0 0 0 1 0 1 1 1 0 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 0 1\n",
            " 0 0 1 1 1 1 0 1 1 1 1 1 1 0 0 1 0 1 0 1 0 0 1 0 0 0 1 1 0 0 1 0 0 0 1 0 1\n",
            " 0 1 0 0 1 1 1 0 1 0 1 1 1 1 1 0 0 1 0 1 1 1 0 0 1 1 0 0 0 0 1 0 1 0 1 0 0\n",
            " 1 0 0 1 0 1 1 1 0 0 0 1 1 0 0 1 0 1 0 1 1 0 1 0 1 0 1 1 0 0 0 1 0 0 1 0 1\n",
            " 1 1 1 0 1 0 1 0 0 0 0 0 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 0 1 0 0 1 1 1\n",
            " 0 1 1 1 0 1 0 0 0 0 0 1 0 1 1 0 1 0 1 1 1 0 0 0 1 0 0 1 1 0 0 1 0 1 1 1 1\n",
            " 1 0 1 1 0 0 1 1 1 0 1 1 0 1 1 1 0 1 1 1 1 1 1 1 0 1 1 0 1 1 0 1 0 0 1 0 1\n",
            " 1 0 0 0 0 1 0 1 1 0 1 0 1 1 1 1 1 1 0 0 0 0 1 0 0 0 1 0 0 1 1 0 1 0 1 1 1\n",
            " 0 1 1 0 0 1 1 0 1 0 0]\n",
            "probabilities: (862, 2) \n",
            " [1 1 1 0 1 0 0 0 1 1 1 0 1 0 1 0 0 0 1 1 1 1 1 1 0 0 0 1 1 0 0 0 1 1 0 0 0\n",
            " 1 1 1 1 0 0 1 1 1 1 0 1 0 1 1 0 0 1 1 1 1 0 1 0 1 0 0 1 1 0 0 0 1 0 0 1 1\n",
            " 0 1 0 1 0 0 1 1 1 0 0 0 0 1 0 1 0 1 1 1 0 1 0 0 0 0 0 0 0 0 1 0 1 1 0 1 0\n",
            " 1 1 1 0 1 1 1 1 0 1 0 1 1 0 1 0 1 1 0 1 1 1 0 0 1 0 0 0 1 1 1 1 0 1 1 0 1\n",
            " 0 0 1 1 1 1 1 0 0 0 0 0 0 0 1 1 1 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 1 0 1 1 0\n",
            " 1 1 0 1 1 0 0 0 0 0 0 1 0 1 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 0 1 1 0 1 1 0\n",
            " 1 1 0 1 0 1 1 1 1 1 1 1 0 0 1 1 0 1 1 0 0 1 1 1 1 0 0 0 0 0 1 0 1 0 0 0 1\n",
            " 0 1 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 0 0 0 1 1 0 1 0\n",
            " 0 1 0 0 1 0 0 1 0 1 0 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 0 0\n",
            " 1 0 1 1 0 1 1 0 1 1 0 0 1 0 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 0 1 1 1\n",
            " 1 0 0 0 0 1 1 0 1 1 0 0 1 0 0 1 0 0 1 0 0 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 1\n",
            " 1 0 0 0 0 0 0 1 1 1 1 1 0 0 0 1 1 0 1 0 1 0 0 1 0 0 0 0 0 0 1 1 0 1 1 1 0\n",
            " 1 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 0 0 1 0 1 1 0 0 1 1 0 1 0 1 0 0 0 1\n",
            " 0 1 0 1 0 1 1 0 1 1 0 1 1 0 0 1 1 1 1 0 1 1 0 1 1 1 0 0 1 0 1 1 1 1 1 1 0\n",
            " 1 0 0 0 0 1 0 0 0 0 1 0 1 1 0 1 0 1 1 0 1 0 0 0 1 0 0 1 0 0 1 0 1 1 1 1 1\n",
            " 0 0 0 1 0 1 1 1 0 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 0 1\n",
            " 0 0 1 1 1 1 0 1 1 1 1 1 1 0 0 1 0 1 0 1 0 0 1 0 0 0 1 1 0 0 1 0 0 0 1 0 1\n",
            " 0 1 0 0 1 1 1 0 1 0 1 1 1 1 1 0 0 1 0 1 1 1 0 0 1 1 0 0 0 0 1 0 1 0 1 0 0\n",
            " 1 0 0 1 0 1 1 1 0 0 0 1 1 0 0 1 0 1 0 1 1 0 1 0 1 0 1 1 0 0 0 1 0 0 1 0 1\n",
            " 1 1 1 0 1 0 1 0 0 0 0 0 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 0 1 0 0 1 1 1\n",
            " 0 1 1 1 0 1 0 0 0 0 0 1 0 1 1 0 1 0 1 1 1 0 0 0 1 0 0 1 1 0 0 1 0 1 1 1 1\n",
            " 1 0 1 1 0 0 1 1 1 0 1 1 0 1 1 1 0 1 1 1 1 1 1 1 0 1 1 0 1 1 0 1 0 0 1 0 1\n",
            " 1 0 0 0 0 1 0 1 1 0 1 0 1 1 1 1 1 1 0 0 0 0 1 0 0 0 1 0 0 1 1 0 1 0 1 1 1\n",
            " 0 1 1 0 0 1 1 0 1 0 0]\n",
            "std (862,) [40.81515934 41.03905553 35.28823729 45.13647755 45.16160996 34.12196618\n",
            " 49.11092344 49.48146147 45.77831428 49.07840211 28.78370443 46.38614855\n",
            " 40.46482032 38.98081183 38.44925272 44.37929077 40.94563202 39.71911872\n",
            " 45.69430024 42.20187182 48.22761857 46.17096728 46.9186402  45.14861339\n",
            " 33.13768843 44.41842101 46.7446543  42.74168949 38.84506892 49.53909295\n",
            " 49.37266081 37.74494581 36.39105126 36.53097515 43.43195069 48.9279229\n",
            " 41.31990258 42.27257337 44.48089328 32.29360261 48.58058676 42.62971486\n",
            " 47.42481283 49.17970821 33.10761972 47.16990274 45.70111661 47.7974073\n",
            " 47.37872982 32.72141464 35.46522454 44.49363262 45.71831044 49.52839498\n",
            " 45.66122809 47.10991197 42.58688046 44.62244001 48.08457522 47.60889004\n",
            " 40.56889346 45.53886996 49.30187822 29.70479295 48.13778405 38.26602273\n",
            " 32.12558944 47.46789905 34.8673361  47.90295921 47.15664127 44.52920835\n",
            " 42.47288354 47.38214659 29.64323448 39.84141094 41.9060422  47.22157366\n",
            " 48.57889696 38.98081183 43.32830463 39.98302503 37.79335876 47.95358601\n",
            " 46.62104592 49.26333234 48.80622835 48.13355746 48.48281979 44.82330796\n",
            " 49.26682375 46.18393666 42.99972705 48.58296756 42.62344972 42.88767497\n",
            " 48.32119537 49.42588259 49.00570159 47.75096658 48.996766   47.34655904\n",
            " 38.8035225  38.98081183 47.28013412 49.64262028 45.80718651 44.86362116\n",
            " 49.28481014 25.49158981 47.72701491 45.29774437 39.57867914 31.93061106\n",
            " 43.25860573 34.98135701 44.57639498 39.00994397 45.69268774 34.4911602\n",
            " 46.41808962 41.5996678  47.77078431 47.38620239 44.48661996 32.88180677\n",
            " 38.98081183 49.07946983 42.76040593 48.28123746 47.31395148 47.05827102\n",
            " 42.58303374 37.46310844 42.92672936 42.08070375 40.54216572 48.79665063\n",
            " 36.98161128 44.36520856 44.47331441 46.25817767 37.54151513 38.6095397\n",
            " 35.25967548 40.34100939 49.27281598 41.86113641 49.55332504 38.98081183\n",
            " 41.30294599 35.52210626 42.48681054 45.89264107 42.11198065 46.13473459\n",
            " 45.81870438 33.65994881 44.43210319 41.70418998 47.82718075 37.06012138\n",
            " 46.99778277 47.81931277 46.66923489 45.74385514 40.9422808  44.50967737\n",
            " 46.18820359 28.56599124 43.37135596 49.24254627 47.4066658  49.11263281\n",
            " 47.1181331  31.37064645 46.43163466 49.56413461 49.56205264 38.98081183\n",
            " 42.22121017 47.96737444 43.81951677 37.39508124 47.16229337 48.12932004\n",
            " 41.31087449 46.91990798 36.90074561 48.38482996 41.62024001 34.56809948\n",
            " 38.08266222 49.46990518 42.6133788  45.5893011  48.84587944 47.19237913\n",
            " 34.52559909 34.33587634 38.94737586 43.37308067 39.97058341 42.61018381\n",
            " 48.38429763 46.86809074 42.68880063 47.42995445 38.59793185 46.7261124\n",
            " 48.52567676 47.16156749 44.1691706  45.49788568 46.57642188 47.13176708\n",
            " 36.49904554 47.63564897 48.69603118 47.78876044 44.23570317 46.08228795\n",
            " 47.0071879  46.59765056 48.85046157 43.48287364 34.48049579 48.17848739\n",
            " 46.5110576  36.86521385 35.48669154 36.06955338 45.48549273 39.44801838\n",
            " 49.53771346 44.29280459 44.52866321 42.88773388 46.66967868 38.70241697\n",
            " 46.96067383 42.59250766 43.20770364 30.92188179 45.49186173 46.78460952\n",
            " 48.19637046 40.45386088 38.98081183 48.97442626 38.98081183 36.61576407\n",
            " 47.95710286 38.98081183 47.49484702 49.12002974 42.82555423 48.94310515\n",
            " 41.62225971 47.76996175 45.97722867 49.09622351 45.23029378 43.98599547\n",
            " 40.16005543 31.26983822 49.19644383 49.57428275 47.88480587 46.38547594\n",
            " 38.08488116 46.01624219 45.706264   46.07874165 47.49796788 39.61685203\n",
            " 44.49302937 46.41815908 46.13086353 45.19871654 49.30187822 47.0481761\n",
            " 35.52541386 47.82280256 47.52041177 39.74861421 43.99078996 49.61681398\n",
            " 42.82658109 38.99391228 37.04942615 38.74407369 46.08316586 49.33127418\n",
            " 48.83167812 42.41949508 49.57691552 44.69645379 38.98081183 45.02523876\n",
            " 47.3485405  45.93489307 48.87287869 46.51025093 41.45335954 44.96409766\n",
            " 47.70080297 47.623963   41.3536342  47.05303287 35.08923419 46.29333081\n",
            " 33.44742638 47.08000842 39.40161508 36.41327304 39.38403082 48.55249062\n",
            " 31.6187833  43.21106445 47.12838521 48.02382181 42.78219114 40.46594982\n",
            " 47.4392271  43.07488409 31.30319777 46.93811497 46.99328709 46.48909848\n",
            " 48.00569376 35.53558189 48.85703291 48.58518588 47.79674819 39.05948733\n",
            " 36.81114283 49.35283982 40.91155962 45.23221124 33.27270992 45.84212871\n",
            " 48.05295549 38.98081183 38.98081183 47.20612489 46.09906645 46.87710603\n",
            " 49.07451669 45.13604512 40.30349243 45.67697465 46.4110708  46.7508682\n",
            " 37.0789573  42.72119915 46.79716387 42.54323033 46.38633899 47.54555201\n",
            " 47.81914482 43.80337404 43.24855298 49.59533751 42.42652398 46.87452406\n",
            " 48.43394513 47.73050853 45.83352489 36.76685453 45.49347113 49.62394581\n",
            " 40.06424606 41.34885527 37.06117055 45.53604092 41.70658481 49.39294206\n",
            " 35.25074714 39.69510218 44.8918183  38.98081183 46.05124689 46.01451665\n",
            " 43.98672205 32.76057606 30.68972029 47.95621327 45.71518498 47.47225275\n",
            " 36.87811769 41.73117711 31.89843848 29.38518093 34.61798469 36.76685453\n",
            " 47.62423832 42.79433772 46.26723257 44.86113949 43.39109495 48.06790796\n",
            " 44.61010935 47.58724975 47.318654   49.39034823 47.5447569  43.55947562\n",
            " 43.79360729 44.70888874 48.98501329 43.93630397 49.67204975 39.60819695\n",
            " 42.59510831 46.92210044 42.88724331 47.94765176 46.11138285 48.43109857\n",
            " 49.5064719  48.47593403 44.83196741 43.57555382 38.64246239 48.88576936\n",
            " 48.81306995 45.28168045 48.3890729  27.51835545 43.83032855 48.16985984\n",
            " 37.61223736 45.8032989  38.98081183 39.41043176 49.27661029 45.73862924\n",
            " 48.52022002 38.98081183 43.05354877 34.2807095  43.76525477 48.93352317\n",
            " 33.21495994 49.43746547 48.87971466 39.18068782 46.23406233 44.21208434\n",
            " 30.18453183 45.46989478 37.67690758 47.92960029 44.07687031 31.91281972\n",
            " 42.60064402 40.29982749 46.2131565  46.25489047 49.4941271  42.48595829\n",
            " 48.59349972 40.68536447 45.85305925 47.57273803 43.062875   46.42107795\n",
            " 48.04298274 38.98081183 38.98081183 42.2811525  42.25996134 45.76306876\n",
            " 46.41609733 44.05518489 47.85473975 47.36873536 32.1140609  46.87761988\n",
            " 47.48316319 33.53630215 45.55758141 47.60515957 48.08412502 47.00972829\n",
            " 47.36592164 42.10557394 47.90349322 39.88156816 33.44742638 47.34402125\n",
            " 45.88795525 43.1901976  36.15856328 49.28201125 48.09895062 43.81337375\n",
            " 36.73883538 47.32789815 40.54338486 46.56212876 46.25489047 46.28567554\n",
            " 38.79037946 47.7094516  48.49141389 49.49747642 44.81290355 44.82439761\n",
            " 47.75862107 48.20565739 37.4528733  47.94056432 36.70666364 37.73550866\n",
            " 48.31696289 36.78074934 41.77742148 49.11362571 42.69808063 46.78069196\n",
            " 45.51403005 47.79219186 43.15368415 34.41775444 49.44100577 43.33665931\n",
            " 47.45448749 47.25144971 46.0475786  44.67477917 43.00362615 48.81272489\n",
            " 28.15106116 45.46161243 47.81437839 41.13530074 41.39670804 48.5219064\n",
            " 39.8078336  48.84566001 36.20782827 44.56899673 43.37171972 45.93714518\n",
            " 39.08530564 43.55195382 42.69929313 45.71363963 35.19980118 43.29926109\n",
            " 47.41845731 45.78715211 36.26447207 46.77245615 47.4283642  31.88556548\n",
            " 44.32404991 34.12091241 39.87604209 38.68602979 35.17363569 49.30241577\n",
            " 46.59432873 36.23279206 47.57906202 40.91570989 42.49188049 46.16077148\n",
            " 47.83011618 49.57465187 49.2817636  39.5421661  36.84043152 48.2241559\n",
            " 46.07293116 47.54860273 45.25250651 47.45460102 37.25236144 38.91541954\n",
            " 47.1906672  41.81610387 46.29790638 48.01557298 41.60895862 47.994744\n",
            " 37.9388692  49.47570304 32.95209888 47.49796788 49.18240922 48.49569378\n",
            " 47.06896158 47.77745222 47.67118896 35.91623811 34.72311896 44.41178674\n",
            " 42.22924283 42.85625753 35.98235714 47.91695053 35.20705019 45.66546778\n",
            " 38.98081183 46.57030398 48.50034661 45.22425058 31.47995772 40.98361495\n",
            " 38.98081183 38.98081183 43.47053189 25.92755477 33.27013552 48.94368528\n",
            " 47.84685933 30.20040432 47.72708549 43.90645759 32.42122068 47.70220214\n",
            " 48.76846314 34.42462937 47.3983864  42.9994326  48.20177223 35.2076131\n",
            " 47.21928226 40.96107734 48.70410847 37.76821729 46.51382526 39.48396211\n",
            " 47.97853808 48.85800375 47.8903488  42.27627604 48.17707079 38.98698344\n",
            " 48.14135676 42.17158552 49.0342553  49.16531687 48.87565129 49.36816045\n",
            " 45.22472807 45.41391976 44.15671768 49.22957786 48.95214855 47.16624445\n",
            " 45.35977542 28.9822596  42.11849275 48.70282975 45.33859463 44.15629678\n",
            " 49.46317468 46.17441128 39.42908106 42.6250007  48.4650131  48.42344405\n",
            " 48.06169226 48.60178139 48.11679054 46.76000147 39.77399126 32.24866906\n",
            " 45.28131788 33.76310769 49.21728852 30.19665221 49.74708003 44.52598995\n",
            " 44.83641038 49.31158884 47.26545091 38.30285709 37.92231573 39.72215666\n",
            " 36.90172258 44.49097326 43.84384683 36.7585819  37.66882843 48.27882683\n",
            " 45.76183041 48.91289889 41.84190174 31.66475295 39.22156222 47.10731867\n",
            " 47.22680155 44.36397116 48.66744117 49.01754088 46.58898022 32.1706495\n",
            " 47.92960029 46.532959   42.56524758 41.49162588 48.60691741 32.10941363\n",
            " 48.82972553 40.34916411 49.64559131 46.56789154 47.35167519 48.21020648\n",
            " 47.62616439 45.78610411 38.88099217 42.3940931  39.93415962 38.28298513\n",
            " 35.39406173 44.86829691 49.67757544 43.16709137 49.2684987  36.42243634\n",
            " 43.80064707 43.60269363 48.71280713 44.50905935 34.9911592  37.70275904\n",
            " 49.00694954 40.23837715 41.83455028 38.15561279 44.923496   36.26856338\n",
            " 48.41033115 31.8662306  45.57728276 47.81292944 40.11619222 44.3341887\n",
            " 49.74251518 32.69223831 45.20367095 49.32125592 38.51675784 49.41853676\n",
            " 44.35603418 42.46844347 36.55006083 48.27386582 28.81404387 40.50318076\n",
            " 48.93312727 47.78167018 39.11395785 48.72868385 41.64924117 49.01811178\n",
            " 47.89047845 42.28066011 46.38547681 32.31609301 38.98081183 45.75358563\n",
            " 45.94883178 49.041454   38.98081183 42.31483021 44.87618187 38.44925272\n",
            " 47.3983864  47.0366083  44.82706973 46.81825708 44.52458334 47.48316319\n",
            " 47.36725819 48.36371689 47.10305203 46.88360085 46.37913656 44.99503359\n",
            " 34.93247932 38.55690267 47.77357192 47.86721053 41.87818062 45.9254314\n",
            " 44.26060663 24.11442338 48.45508808 44.60176994 41.08375159 35.72843972\n",
            " 38.26582142 46.89542767 37.21792127 46.33097312 47.18012814 44.54697601\n",
            " 49.21352911 40.95717755 48.88337576 46.84087321 48.61253187 38.98081183\n",
            " 46.31305385 47.5866938  48.53292185 48.89104308 47.13141077 43.6947775\n",
            " 49.1654861  47.41915749 41.53665825 42.94074049 46.45531546 41.63179281\n",
            " 30.50848278 30.7161022  48.83348162 48.98573514 38.14797348 38.80202516\n",
            " 40.1712327  49.0107376  31.97966854 45.46127348 49.30701238 41.57892663\n",
            " 38.89247074 49.2469553  48.41634245 44.06020943 47.83530272 45.33316825\n",
            " 44.72665152 40.09261841 37.54734081 40.98064999 47.30098922 46.77391241\n",
            " 37.36333003 38.98081183 46.80600359 33.88374255 43.5746484  38.98081183\n",
            " 37.5280354  34.9114461  49.71462509 47.244727   47.92091796 44.65593789\n",
            " 47.08989563 45.7260916  40.78548716 48.62153132]\n",
            "selection [793 109 615 429 534 169  10 754 655 393] (10,) [24.11442338 25.49158981 25.92755477 27.51835545 28.15106116 28.56599124\n",
            " 28.78370443 28.81404387 28.9822596  29.38518093]\n",
            "trainset before adding uncertain samples (440, 10) (440,)\n",
            "trainset after adding uncertain samples (450, 10) (450,)\n",
            "updated train set: (450, 10) (450,) unique(labels): [217 233] [0 1]\n",
            "val set: (852, 10) (852,)\n",
            "\n",
            "Train set: (450, 10)\n",
            "Validation set: (852, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 45\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.292 s \n",
            "\n",
            "Accuracy rate is 81.797235 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.89      0.88       321\n",
            "           1       0.67      0.60      0.63       113\n",
            "\n",
            "    accuracy                           0.82       434\n",
            "   macro avg       0.77      0.75      0.76       434\n",
            "weighted avg       0.81      0.82      0.81       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[287  34]\n",
            " [ 45  68]]\n",
            "--------------------------------\n",
            "val predicted: (852,) [1 1 1 0 1 0 0 0 1 1 0 1 0 1 0 0 0 1 1 1 1 1 1 0 0 0 1 1 0 0 0 1 1 0 0 0 1\n",
            " 1 1 1 0 0 1 1 1 1 0 1 0 1 1 0 0 1 1 1 1 0 1 0 1 0 0 1 1 0 0 0 1 0 0 1 1 0\n",
            " 1 0 1 0 0 1 1 1 0 0 0 0 1 0 1 0 1 1 1 0 1 0 0 0 0 0 0 0 0 1 0 1 1 0 0 1 1\n",
            " 1 0 1 1 1 1 0 1 0 1 1 0 1 0 1 1 0 1 1 1 0 0 1 0 0 0 1 1 1 1 0 1 1 0 1 0 0\n",
            " 1 1 1 1 1 0 0 0 0 0 0 0 1 1 1 0 0 1 0 0 0 0 0 1 1 0 0 0 0 1 0 1 1 0 1 1 0\n",
            " 1 1 0 0 0 0 0 0 1 0 1 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 0 1 1 0 1 1 0 1 1 0\n",
            " 1 0 1 1 1 1 1 1 1 0 0 1 1 0 1 1 0 0 1 1 1 1 0 0 0 0 0 1 0 1 0 0 0 1 0 1 0\n",
            " 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 0 0 0 1 1 0 1 0 0 1 0\n",
            " 0 1 0 0 1 0 1 0 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 0 0 1 0 1\n",
            " 1 0 1 1 0 1 1 0 0 1 0 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 0 1 1 1 1 0 0\n",
            " 0 0 1 1 0 1 1 0 0 1 0 0 1 0 0 1 0 0 1 0 1 1 1 0 1 1 1 1 1 0 1 0 1 1 0 0 0\n",
            " 0 0 0 1 1 1 1 1 0 0 0 1 1 0 1 0 1 0 1 0 0 0 0 0 0 1 1 0 1 1 1 0 1 0 0 1 1\n",
            " 1 1 1 1 1 1 1 1 0 1 1 0 0 1 0 0 1 0 1 1 0 0 1 1 0 1 0 1 0 0 0 1 0 1 0 1 0\n",
            " 1 1 0 1 1 0 1 1 0 0 1 1 1 1 0 1 1 0 1 1 1 0 0 1 0 1 1 1 1 1 1 0 1 0 0 0 0\n",
            " 1 0 0 0 0 1 0 1 1 0 1 1 1 0 1 0 0 0 1 0 0 1 0 0 1 0 1 1 1 1 1 0 0 0 1 0 1\n",
            " 1 1 0 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 0 1 0 0 1 1 1 1\n",
            " 0 1 1 1 1 1 1 0 0 1 0 1 0 1 0 0 1 0 0 1 1 0 0 1 0 0 0 1 0 1 0 1 0 0 1 1 1\n",
            " 0 1 0 1 1 1 1 1 0 0 1 0 1 1 1 0 0 1 1 0 0 0 1 0 1 0 1 0 0 1 0 0 1 0 1 1 1\n",
            " 0 0 0 1 1 0 0 1 0 1 0 1 1 0 1 0 1 0 1 1 0 0 0 1 0 0 1 0 1 1 1 1 0 1 0 1 0\n",
            " 0 0 0 0 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 0 1 0 0 1 1 1 0 1 1 1 0 1 0 0\n",
            " 0 0 0 1 0 1 0 1 0 1 1 1 0 0 0 1 0 0 1 1 0 0 1 0 1 1 1 1 1 0 1 1 0 0 1 1 1\n",
            " 0 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 0 1 0 0 1 0 1 1 0 0 0 0 1 0 1 1 0\n",
            " 1 0 1 1 1 1 1 1 0 0 0 0 1 0 0 0 1 0 0 1 1 0 1 0 1 1 1 0 1 1 0 0 1 1 0 1 0\n",
            " 0]\n",
            "probabilities: (852, 2) \n",
            " [1 1 1 0 1 0 0 0 1 1 0 1 0 1 0 0 0 1 1 1 1 1 1 0 0 0 1 1 0 0 0 1 1 0 0 0 1\n",
            " 1 1 1 0 0 1 1 1 1 0 1 0 1 1 0 0 1 1 1 1 0 1 0 1 0 0 1 1 0 0 0 1 0 0 1 1 0\n",
            " 1 0 1 0 0 1 1 1 0 0 0 0 1 0 1 0 1 1 1 0 1 0 0 0 0 0 0 0 0 1 0 1 1 0 0 1 1\n",
            " 1 0 1 1 1 1 0 1 0 1 1 0 1 0 1 1 0 1 1 1 0 0 1 0 0 0 1 1 1 1 0 1 1 0 1 0 0\n",
            " 1 1 1 1 1 0 0 0 0 0 0 0 1 1 1 0 0 1 0 0 0 0 0 1 1 0 0 0 0 1 0 1 1 0 1 1 0\n",
            " 1 1 0 0 0 0 0 0 1 0 1 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 0 1 1 0 1 1 0 1 1 0\n",
            " 1 0 1 1 1 1 1 1 1 0 0 1 1 0 1 1 0 0 1 1 1 1 0 0 0 0 0 1 0 1 0 0 0 1 0 1 0\n",
            " 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 0 0 0 1 1 0 1 0 0 1 0\n",
            " 0 1 0 0 1 0 1 0 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 0 0 1 0 1\n",
            " 1 0 1 1 0 1 1 0 0 1 0 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 0 1 1 1 1 0 0\n",
            " 0 0 1 1 0 1 1 0 0 1 0 0 1 0 0 1 0 0 1 0 1 1 1 0 1 1 1 1 1 0 1 0 1 1 0 0 0\n",
            " 0 0 0 1 1 1 1 1 0 0 0 1 1 0 1 0 1 0 1 0 0 0 0 0 0 1 1 0 1 1 1 0 1 0 0 1 1\n",
            " 1 1 1 1 1 1 1 1 0 1 1 0 0 1 0 0 1 0 1 1 0 0 1 1 0 1 0 1 0 0 0 1 0 1 0 1 0\n",
            " 1 1 0 1 1 0 1 1 0 0 1 1 1 1 0 1 1 0 1 1 1 0 0 1 0 1 1 1 1 1 1 0 1 0 0 0 0\n",
            " 1 0 0 0 0 1 0 1 1 0 1 1 1 0 1 0 0 0 1 0 0 1 0 0 1 0 1 1 1 1 1 0 0 0 1 0 1\n",
            " 1 1 0 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 0 1 0 0 1 1 1 1\n",
            " 0 1 1 1 1 1 1 0 0 1 0 1 0 1 0 0 1 0 0 1 1 0 0 1 0 0 0 1 0 1 0 1 0 0 1 1 1\n",
            " 0 1 0 1 1 1 1 1 0 0 1 0 1 1 1 0 0 1 1 0 0 0 1 0 1 0 1 0 0 1 0 0 1 0 1 1 1\n",
            " 0 0 0 1 1 0 0 1 0 1 0 1 1 0 1 0 1 0 1 1 0 0 0 1 0 0 1 0 1 1 1 1 0 1 0 1 0\n",
            " 0 0 0 0 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 0 1 0 0 1 1 1 0 1 1 1 0 1 0 0\n",
            " 0 0 0 1 0 1 0 1 0 1 1 1 0 0 0 1 0 0 1 1 0 0 1 0 1 1 1 1 1 0 1 1 0 0 1 1 1\n",
            " 0 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 0 1 0 0 1 0 1 1 0 0 0 0 1 0 1 1 0\n",
            " 1 0 1 1 1 1 1 1 0 0 0 0 1 0 0 0 1 0 0 1 1 0 1 0 1 1 1 0 1 1 0 0 1 1 0 1 0\n",
            " 0]\n",
            "std (852,) [38.14190629 42.11973911 34.84177502 44.13149295 44.27984053 35.85465467\n",
            " 49.0817381  49.32928388 46.41598614 48.96434127 46.30690456 40.74609076\n",
            " 37.03896388 36.34925431 43.65639251 33.30110601 36.09646416 45.46079115\n",
            " 42.83896207 47.80841377 46.90283604 46.49182977 46.01181032 34.88593127\n",
            " 41.65068959 46.41393537 44.80656115 39.71826088 49.53947595 49.34960213\n",
            " 36.70493435 41.16407573 35.93803135 42.69204646 48.64670876 42.87641205\n",
            " 45.03832956 43.929074   40.55348239 48.57543921 42.83427566 47.38092543\n",
            " 49.18394106 34.18014444 47.02741614 45.40466203 47.06442447 46.01242713\n",
            " 31.47889979 34.83325628 46.19729994 44.20169691 49.5629828  44.64488848\n",
            " 45.99964945 44.04375662 44.13096965 48.88253352 47.28535464 39.53997912\n",
            " 46.67995474 48.94530116 30.56243751 47.09054946 40.10525974 37.09676854\n",
            " 47.56880669 35.37075243 48.3015854  48.66035771 41.54787164 40.83632902\n",
            " 47.12930804 35.07329133 41.1209199  39.10057501 47.81951919 48.69352211\n",
            " 37.03896388 43.75953995 39.41828025 42.1305806  48.45405418 47.21033825\n",
            " 49.38323171 48.8727495  48.11356184 47.60528168 46.05968706 48.91489124\n",
            " 46.26354245 42.96637926 48.82061701 41.56198897 46.52860445 48.14192595\n",
            " 49.54628195 48.41662172 48.32955761 49.12207597 47.16266578 37.41018875\n",
            " 37.03896388 47.84064438 49.5362762  47.30211614 44.34148089 49.38958165\n",
            " 47.14585688 45.01733513 38.5717797  33.42076149 41.701568   37.68875438\n",
            " 44.72241737 41.34472839 44.51472852 38.07352872 46.66614141 44.29660111\n",
            " 47.94354488 47.21900199 45.32961962 28.22954751 37.03896388 49.18158472\n",
            " 43.69073411 48.53198629 45.46214544 47.17095764 43.4564001  35.97866386\n",
            " 43.6679942  41.80655006 37.75337818 48.84626197 37.38570277 45.92305634\n",
            " 45.08981428 45.98014781 40.0586167  39.69687328 35.19845872 40.17558703\n",
            " 49.15190141 43.26394251 49.61568026 37.03896388 41.37271544 38.6775712\n",
            " 41.60839161 45.2528579  45.75382457 46.07887007 46.47308843 33.87058722\n",
            " 42.94733729 42.88569286 45.89671024 35.0967365  46.45230989 47.98705728\n",
            " 47.07782176 43.20391565 42.06565819 46.47245359 46.21687677 37.76673975\n",
            " 49.39742397 46.01673345 48.70866574 47.97660096 32.55473611 43.74008831\n",
            " 49.51859561 49.63820276 37.03896388 40.58678751 47.09570923 43.75306605\n",
            " 35.88722003 46.87683893 47.78853399 41.19690702 46.94699544 38.81085595\n",
            " 48.3291611  38.63294665 29.0390952  39.84517215 49.43176903 42.99666036\n",
            " 45.20223497 48.83089059 47.02663563 42.54257484 30.11095051 41.66611138\n",
            " 42.95970415 41.53112    40.0403973  48.05225811 45.10425409 46.23821936\n",
            " 47.97887339 41.40088384 47.09773349 48.838843   46.6752318  45.32082251\n",
            " 47.29724499 47.06392156 47.52178275 39.31727118 47.15108655 48.70983373\n",
            " 49.04389805 43.98703042 46.12099429 47.69173685 46.72967434 48.71009461\n",
            " 45.13880666 36.25906103 48.71764863 46.18896743 40.23442584 36.43022445\n",
            " 34.47126933 46.94905386 41.7827178  49.49384326 47.3917329  45.49601528\n",
            " 43.53222189 47.47497197 41.6839581  47.4394147  42.64669887 41.33692909\n",
            " 26.88737511 46.15928708 46.08900143 47.90989756 39.91911745 37.03896388\n",
            " 48.9233717  37.03896388 38.01037508 48.00708412 37.03896388 47.75894106\n",
            " 49.06897484 41.89271436 49.27063729 44.84560607 46.26422211 46.85613009\n",
            " 48.6020447  45.07199863 38.7901993  41.25852912 35.60954836 48.84599827\n",
            " 49.60666205 47.92717352 46.1884013  40.38575034 46.19606385 45.09158788\n",
            " 47.08266011 47.22143614 42.10065946 45.98783973 47.28535421 45.97348874\n",
            " 45.42159101 48.94530116 47.25599764 30.08705258 47.30053421 47.94888024\n",
            " 42.69781768 41.41474416 49.56432221 42.44280498 39.89031843 37.87859752\n",
            " 36.14035383 45.32346917 49.04860715 48.86612407 38.13156558 49.63295923\n",
            " 43.86427354 37.03896388 45.65581237 47.80894119 45.59338566 48.83787326\n",
            " 45.71398881 38.40430989 45.01860737 47.76907106 48.25711858 43.80031416\n",
            " 46.68252384 28.67495514 43.56110677 36.80335481 46.76115162 42.01313963\n",
            " 34.09583387 38.73668967 48.68337791 33.06432768 43.59187494 46.69113103\n",
            " 47.33855018 42.35899234 40.24006821 47.95276777 45.66768273 30.22009555\n",
            " 46.23553686 48.30919219 46.0322588  48.25254256 40.88303722 49.02407757\n",
            " 48.68858577 48.07340801 40.4803814  36.77033185 49.18551283 42.72654124\n",
            " 45.36396424 30.67698153 45.38591813 48.07199501 37.03896388 37.03896388\n",
            " 46.85533801 45.57024546 47.26617496 49.1446011  43.98119832 38.65303314\n",
            " 45.79207505 46.20860933 47.54105555 39.07936738 44.63078606 47.46880113\n",
            " 44.41205106 45.082463   47.85079697 48.15449004 43.04315399 44.15632209\n",
            " 49.61404763 34.88571488 45.62969415 48.59319622 48.41658607 45.65945717\n",
            " 38.78761963 45.08807106 49.6441987  43.08353891 36.65699003 40.31318876\n",
            " 44.82189054 44.96876327 49.02611406 31.9046643  34.84686094 44.5097055\n",
            " 37.03896388 45.94787551 44.95334118 42.26955588 34.80013377 35.28747035\n",
            " 47.63721404 46.90984997 46.62916013 39.44215676 45.23525601 31.87572305\n",
            " 35.78862475 38.78761963 46.77100961 43.46191868 46.72855578 44.23645307\n",
            " 45.79631346 48.04625276 44.66130048 48.02788029 47.1494222  49.52893602\n",
            " 48.77792762 45.18169553 45.67054063 43.21794962 48.95141778 44.21135996\n",
            " 49.52065716 33.63369475 42.64424854 47.16410556 44.70082425 48.01226446\n",
            " 46.63587606 48.34752066 49.23524658 47.85604549 40.96503041 43.43970108\n",
            " 31.54663973 48.93495376 48.94916996 45.80884768 48.55399084 43.57892863\n",
            " 47.91967642 37.90727188 45.84965214 37.03896388 38.58508904 48.99533745\n",
            " 44.84391455 48.45631341 37.03896388 43.53675583 29.05624482 41.59354252\n",
            " 48.71349001 30.27087768 49.37755608 48.79689884 40.36278601 47.62427193\n",
            " 42.79022081 35.52584571 45.17881925 38.14111135 47.64626815 43.82739166\n",
            " 33.89593909 42.09581312 41.72742678 44.60566332 45.84322643 49.31162964\n",
            " 44.70182822 48.58902053 41.85202481 44.66940562 48.07763655 44.58159351\n",
            " 47.53319549 48.01147422 37.03896388 37.03896388 42.13113517 43.08260601\n",
            " 45.65021482 47.22100446 40.65373573 48.11375763 47.46658581 34.01166055\n",
            " 47.34778428 47.98091963 36.65724672 45.38958683 46.7280577  48.92409653\n",
            " 45.0847023  47.03460647 40.43329706 48.69841911 42.84174736 36.80335481\n",
            " 46.83509725 45.16835677 43.11447605 39.55670956 49.27401198 47.80743541\n",
            " 46.38977148 33.49021651 46.78753336 39.23148038 46.61350799 45.84322643\n",
            " 44.18667499 40.25325907 47.88522499 48.39031416 49.19321136 43.41190522\n",
            " 44.97067784 47.30436563 48.8719701  41.43849046 47.92808516 36.55094808\n",
            " 36.60712236 48.14668967 39.55281041 41.90289234 49.49781389 45.45338456\n",
            " 44.89464412 42.72086475 47.52893316 41.01846384 26.70730558 49.37226048\n",
            " 40.94189044 46.29736352 47.23437899 46.81291104 43.2373888  39.76374837\n",
            " 48.40743536 45.84474421 47.42337202 40.02887653 42.19666191 48.58274158\n",
            " 33.98253055 48.91235244 30.19031285 44.78370719 45.39524067 44.53648471\n",
            " 39.02302345 45.08023604 44.19539778 43.50441788 35.54397969 43.93668841\n",
            " 47.2516869  46.623619   38.04452601 46.16809572 47.25761672 30.64949927\n",
            " 43.90905965 36.58140951 40.74973763 41.84795271 35.74518897 49.39342828\n",
            " 45.76808783 38.49922628 46.40331435 40.54978699 42.04213175 45.52681423\n",
            " 47.84998077 49.16290137 49.24212554 36.63323037 39.24091101 47.37061467\n",
            " 45.97840023 47.91027534 45.25326947 47.76347544 38.97164681 39.44361289\n",
            " 47.37254762 42.87336792 47.84889351 48.14969494 39.92122474 48.22462489\n",
            " 37.65480875 49.36885199 35.75847068 47.22143614 49.1766341  48.54227676\n",
            " 46.90313077 48.28009856 48.45924534 27.15763676 40.31100912 45.96641906\n",
            " 44.2351725  41.72543472 34.93434177 48.17547865 37.15262522 45.70656164\n",
            " 37.03896388 44.02669036 48.81930233 46.35638136 32.94872443 41.46995033\n",
            " 37.03896388 37.03896388 43.9407437  35.87389134 49.17978567 48.20413263\n",
            " 26.18011702 48.52363426 42.28661213 41.49359115 48.34064135 48.90533366\n",
            " 35.32522907 46.88776068 44.14853725 47.80765741 30.10095569 47.6826721\n",
            " 40.33743348 48.37969039 37.76955336 45.81860578 40.47725319 46.61502836\n",
            " 48.80765542 48.22287784 41.24713334 48.28490939 35.31888914 48.27165027\n",
            " 44.88520972 49.13450813 49.26697989 48.67746302 49.47169023 44.7177031\n",
            " 45.49230127 44.51375438 49.15192089 48.90308803 46.28128199 45.08628408\n",
            " 42.99657623 48.9149351  46.49487913 43.35281634 49.23703903 46.07819104\n",
            " 40.63525117 44.12743556 48.27479702 48.10805638 47.25783707 48.40707394\n",
            " 48.56425723 45.94479944 39.3299864  33.94907198 46.11460284 34.36799669\n",
            " 48.61303652 33.19762663 49.73060553 44.09883448 46.67452112 49.48451906\n",
            " 47.68240725 41.86869519 33.0471857  36.18178654 37.19131378 44.87645116\n",
            " 42.87543579 39.89648363 41.49401996 48.60503844 46.14405001 48.90297836\n",
            " 45.84832189 34.37905943 38.46334062 46.31319341 47.80623553 42.46786118\n",
            " 47.6980906  48.95589405 47.38160127 37.25120764 47.64626815 46.82686305\n",
            " 42.94448735 43.71021758 48.89144306 39.59687052 48.40238197 36.27965766\n",
            " 49.59832227 47.26532411 45.57050744 48.16495565 48.23338068 44.80485923\n",
            " 36.06077296 42.94886632 42.40720735 39.16166786 36.83536866 42.71133033\n",
            " 49.57356041 43.66234099 49.32117275 38.19026076 44.24612101 43.70339236\n",
            " 48.60991227 44.90352924 30.21351101 42.12854598 49.0540232  42.67225672\n",
            " 42.05255369 37.68746237 45.47648881 36.5943552  47.78154646 25.67486181\n",
            " 46.9744257  47.23019741 41.80258722 45.40894117 49.69699252 38.38253324\n",
            " 45.23012511 49.28825954 33.98146396 49.41568126 44.77992476 42.17191379\n",
            " 33.76004493 48.7988842  43.75828915 48.8537547  48.33679731 38.66155204\n",
            " 49.1106981  43.49523637 49.2534155  47.29231684 44.07394443 46.61168237\n",
            " 37.55585863 37.03896388 46.81270495 46.8689701  48.75826647 37.03896388\n",
            " 45.00306368 44.98470331 36.34925431 46.88776068 48.1803     42.60048371\n",
            " 47.45250386 45.13741406 47.98091963 46.56926209 48.46576363 47.00161068\n",
            " 47.82736472 46.31691238 44.5708494  36.59379009 40.45811717 46.89461595\n",
            " 47.34792949 40.25514216 44.67028522 43.22317844 48.89209352 44.07105939\n",
            " 42.60689069 37.32338827 40.6997126  46.9328577  39.44706449 47.45968263\n",
            " 47.57487349 44.55657575 49.0137959  42.61904848 48.70280788 47.05312782\n",
            " 48.15068854 37.03896388 47.36267206 47.64050364 48.73742303 48.5875924\n",
            " 46.49429795 44.32615237 49.10673569 47.23603757 41.53965824 43.30573438\n",
            " 45.19230076 41.55440895 35.24483757 26.1048612  48.94877759 48.92426385\n",
            " 37.51776955 42.22924391 40.7176495  49.34233403 38.18392158 44.03872664\n",
            " 48.3453187  43.79053885 29.08936427 49.08425964 47.45915049 43.27906193\n",
            " 48.62556928 46.31715722 45.15258459 40.58700844 40.58310136 40.51328187\n",
            " 47.68520437 47.96773007 39.41238673 37.03896388 45.40364574 34.48388639\n",
            " 45.97360992 37.03896388 39.4020794  37.64268516 49.72734645 46.8570642\n",
            " 48.63859056 42.63863577 47.27040753 46.19213632 39.98351618 48.69563351]\n",
            "selection [731 813 612 520 240 591 123 307 188 436] (10,) [25.67486181 26.1048612  26.18011702 26.70730558 26.88737511 27.15763676\n",
            " 28.22954751 28.67495514 29.0390952  29.05624482]\n",
            "trainset before adding uncertain samples (450, 10) (450,)\n",
            "trainset after adding uncertain samples (460, 10) (460,)\n",
            "updated train set: (460, 10) (460,) unique(labels): [224 236] [0 1]\n",
            "val set: (842, 10) (842,)\n",
            "\n",
            "Train set: (460, 10)\n",
            "Validation set: (842, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 46\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.299 s \n",
            "\n",
            "Accuracy rate is 80.414747 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.88      0.87       321\n",
            "           1       0.64      0.58      0.60       113\n",
            "\n",
            "    accuracy                           0.80       434\n",
            "   macro avg       0.75      0.73      0.74       434\n",
            "weighted avg       0.80      0.80      0.80       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[284  37]\n",
            " [ 48  65]]\n",
            "--------------------------------\n",
            "val predicted: (842,) [1 1 1 0 1 0 0 0 1 1 0 1 0 1 0 0 0 1 1 1 1 1 1 0 0 0 1 1 0 0 0 1 1 0 0 0 1\n",
            " 1 1 1 0 0 1 1 1 1 0 1 0 1 1 0 0 1 1 1 1 0 1 0 1 0 0 1 1 0 0 0 1 0 0 1 1 0\n",
            " 1 0 1 0 0 1 1 1 0 0 0 0 1 0 1 0 1 1 1 0 1 0 0 0 0 0 0 0 0 1 0 1 1 0 0 1 1\n",
            " 1 0 1 1 1 1 0 1 0 1 1 0 0 1 1 0 1 1 1 0 0 1 0 0 0 1 1 1 1 0 1 1 0 1 0 0 1\n",
            " 1 1 1 1 0 0 0 0 0 0 0 1 1 1 0 0 1 0 0 0 0 0 1 1 0 0 0 0 1 0 1 1 0 1 1 0 1\n",
            " 1 0 0 0 0 0 1 0 1 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 0 1 1 0 1 1 0 1 1 0 1 0\n",
            " 1 1 1 1 1 1 1 0 0 1 1 0 1 1 0 0 1 1 1 0 0 0 0 0 1 0 1 0 0 0 1 0 1 0 0 0 0\n",
            " 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 0 0 0 1 1 0 1 0 0 1 0 0 1 0\n",
            " 0 1 0 1 0 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 0 0 1 0 1 1 0 1 1\n",
            " 0 1 1 0 0 1 0 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 0 1 1 1 1 0 0 0 0 1 1\n",
            " 0 1 1 0 0 1 0 0 1 0 0 1 0 0 1 0 1 1 1 0 1 1 1 1 1 0 1 0 1 1 0 0 0 0 0 0 1\n",
            " 1 1 1 1 0 0 0 1 1 0 1 0 1 0 1 0 0 0 0 0 0 1 1 0 1 1 0 1 0 0 1 1 1 1 1 1 1\n",
            " 1 1 1 0 1 1 0 0 1 0 0 1 0 1 1 0 0 1 1 0 1 0 1 0 0 0 1 0 1 0 1 0 1 1 0 1 1\n",
            " 0 1 1 0 0 1 1 1 1 0 1 1 0 1 1 1 0 0 1 0 1 1 1 1 1 1 0 1 0 0 0 0 1 0 0 0 1\n",
            " 0 1 1 0 1 1 1 0 1 0 0 0 1 0 0 1 0 0 1 0 1 1 1 1 1 0 0 0 1 0 1 1 1 0 1 1 1\n",
            " 1 1 0 1 0 0 0 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 0 1 0 0 1 1 1 0 1 1 1 1 1 1\n",
            " 0 0 1 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 0 1 0 1 0 1 0 0 1 1 1 0 1 0 1 1 1 1 1\n",
            " 0 0 1 0 1 1 1 0 0 1 1 0 0 0 1 0 1 0 1 0 0 1 0 0 1 0 1 1 1 0 0 0 1 1 0 0 1\n",
            " 0 1 0 1 1 0 1 0 1 0 1 1 0 0 0 1 0 0 1 0 1 1 1 1 0 1 0 1 0 0 0 0 0 1 1 1 1\n",
            " 1 1 1 0 1 0 1 1 1 1 1 1 0 0 0 1 0 0 1 1 0 1 1 1 0 1 0 0 0 0 0 1 0 1 0 1 0\n",
            " 1 1 1 0 0 0 1 0 0 1 1 0 0 1 0 1 1 1 1 1 0 1 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1\n",
            " 1 1 1 1 1 0 1 1 0 1 1 0 1 0 0 1 0 1 1 0 0 0 0 1 0 1 1 1 0 1 1 1 1 1 1 0 0\n",
            " 0 0 1 0 0 0 1 0 0 1 1 0 1 0 1 1 1 0 1 1 0 0 1 1 0 1 0 0]\n",
            "probabilities: (842, 2) \n",
            " [1 1 1 0 1 0 0 0 1 1 0 1 0 1 0 0 0 1 1 1 1 1 1 0 0 0 1 1 0 0 0 1 1 0 0 0 1\n",
            " 1 1 1 0 0 1 1 1 1 0 1 0 1 1 0 0 1 1 1 1 0 1 0 1 0 0 1 1 0 0 0 1 0 0 1 1 0\n",
            " 1 0 1 0 0 1 1 1 0 0 0 0 1 0 1 0 1 1 1 0 1 0 0 0 0 0 0 0 0 1 0 1 1 0 0 1 1\n",
            " 1 0 1 1 1 1 0 1 0 1 1 0 0 1 1 0 1 1 1 0 0 1 0 0 0 1 1 1 1 0 1 1 0 1 0 0 1\n",
            " 1 1 1 1 0 0 0 0 0 0 0 1 1 1 0 0 1 0 0 0 0 0 1 1 0 0 0 0 1 0 1 1 0 1 1 0 1\n",
            " 1 0 0 0 0 0 1 0 1 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 0 1 1 0 1 1 0 1 1 0 1 0\n",
            " 1 1 1 1 1 1 1 0 0 1 1 0 1 1 0 0 1 1 1 0 0 0 0 0 1 0 1 0 0 0 1 0 1 0 0 0 0\n",
            " 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 0 0 0 1 1 0 1 0 0 1 0 0 1 0\n",
            " 0 1 0 1 0 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 0 0 1 0 1 1 0 1 1\n",
            " 0 1 1 0 0 1 0 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 0 1 1 1 1 0 0 0 0 1 1\n",
            " 0 1 1 0 0 1 0 0 1 0 0 1 0 0 1 0 1 1 1 0 1 1 1 1 1 0 1 0 1 1 0 0 0 0 0 0 1\n",
            " 1 1 1 1 0 0 0 1 1 0 1 0 1 0 1 0 0 0 0 0 0 1 1 0 1 1 0 1 0 0 1 1 1 1 1 1 1\n",
            " 1 1 1 0 1 1 0 0 1 0 0 1 0 1 1 0 0 1 1 0 1 0 1 0 0 0 1 0 1 0 1 0 1 1 0 1 1\n",
            " 0 1 1 0 0 1 1 1 1 0 1 1 0 1 1 1 0 0 1 0 1 1 1 1 1 1 0 1 0 0 0 0 1 0 0 0 1\n",
            " 0 1 1 0 1 1 1 0 1 0 0 0 1 0 0 1 0 0 1 0 1 1 1 1 1 0 0 0 1 0 1 1 1 0 1 1 1\n",
            " 1 1 0 1 0 0 0 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 0 1 0 0 1 1 1 0 1 1 1 1 1 1\n",
            " 0 0 1 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 0 1 0 1 0 1 0 0 1 1 1 0 1 0 1 1 1 1 1\n",
            " 0 0 1 0 1 1 1 0 0 1 1 0 0 0 1 0 1 0 1 0 0 1 0 0 1 0 1 1 1 0 0 0 1 1 0 0 1\n",
            " 0 1 0 1 1 0 1 0 1 0 1 1 0 0 0 1 0 0 1 0 1 1 1 1 0 1 0 1 0 0 0 0 0 1 1 1 1\n",
            " 1 1 1 0 1 0 1 1 1 1 1 1 0 0 0 1 0 0 1 1 0 1 1 1 0 1 0 0 0 0 0 1 0 1 0 1 0\n",
            " 1 1 1 0 0 0 1 0 0 1 1 0 0 1 0 1 1 1 1 1 0 1 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1\n",
            " 1 1 1 1 1 0 1 1 0 1 1 0 1 0 0 1 0 1 1 0 0 0 0 1 0 1 1 1 0 1 1 1 1 1 1 0 0\n",
            " 0 0 1 0 0 0 1 0 0 1 1 0 1 0 1 1 1 0 1 1 0 0 1 1 0 1 0 0]\n",
            "std (842,) [36.98239044 42.83219049 37.05930497 43.10960865 43.13428048 36.41360322\n",
            " 49.32561225 49.51216475 46.04223497 47.97392    46.6179149  40.42066145\n",
            " 36.22404025 35.73727168 46.06480102 36.29287307 41.20248736 46.84362133\n",
            " 42.19530145 47.12897545 44.08207075 47.1728913  43.69380563 31.36613516\n",
            " 39.97364447 45.43770612 45.86875127 37.53817437 49.57270345 49.4848091\n",
            " 32.07089996 39.79739851 29.39809152 35.51288863 48.69900835 42.34819012\n",
            " 41.44215473 43.16220589 41.9665786  48.04984895 43.49598194 46.41037\n",
            " 48.33525811 29.78234718 47.57137735 44.4500538  46.78867666 46.40139345\n",
            " 30.37330844 33.38982588 45.88463206 44.54500117 49.68888589 42.73166491\n",
            " 46.42142069 41.47993755 44.04015956 48.41429315 46.54429211 40.53937139\n",
            " 46.83577678 49.36916234 29.8850486  46.7007401  40.98431572 37.83644403\n",
            " 48.02058169 33.02573144 46.80675469 48.68900759 40.10889863 37.71602559\n",
            " 46.22633163 27.96991174 39.9550859  40.8859989  47.66043534 47.98444326\n",
            " 36.22404025 44.10046197 38.82401803 41.74613336 48.70123751 45.61926996\n",
            " 49.54427876 49.31609029 47.31402892 48.43914616 45.51296158 49.20653072\n",
            " 44.62715659 43.84306937 48.17573546 41.22751917 46.20451946 48.28320694\n",
            " 49.6428763  49.09215037 48.31112254 49.19663999 47.20985524 35.53343128\n",
            " 36.22404025 46.30981814 49.61110199 45.96222447 44.35384416 49.28559383\n",
            " 47.32655154 45.21833833 38.60868075 22.78449939 44.29984452 36.33868626\n",
            " 43.12720182 40.67727548 44.59154427 34.52752464 45.90745672 43.54367726\n",
            " 46.80812936 47.03696663 46.02741807 36.22404025 48.71539893 41.1068266\n",
            " 48.67900166 45.52925426 47.30185594 43.0845115  39.67463349 43.06028361\n",
            " 43.10405667 35.95490275 49.05747647 37.38609887 45.18027782 43.85111446\n",
            " 45.2885212  38.19846085 39.24854686 31.77633636 38.14719687 49.33767752\n",
            " 38.62622151 49.49608992 36.22404025 39.2494876  36.37935436 43.03097252\n",
            " 44.75125932 44.89779502 46.51615452 47.34110101 37.33315123 45.20948819\n",
            " 41.76254115 45.0549913  31.39769524 45.28340827 46.79027247 46.62686243\n",
            " 43.30497222 41.06690743 39.76405971 45.99539965 40.48063451 49.36077176\n",
            " 47.51549156 49.28078393 47.89046175 31.03901117 47.11404521 49.48756102\n",
            " 49.58854409 36.22404025 41.31139582 48.50209917 42.83061088 34.97087822\n",
            " 48.0671454  47.21833237 40.10044434 47.18017752 37.85669934 47.85961617\n",
            " 40.11955453 41.22058419 49.24840906 44.02588127 44.39714682 48.45970658\n",
            " 47.80489158 42.92306902 29.9077004  41.16561435 41.25580973 41.38370268\n",
            " 39.61328276 46.93110029 45.8602473  44.57874396 46.39416373 39.94147784\n",
            " 46.66798554 48.77611625 46.72373871 44.27107913 46.08262003 45.38695427\n",
            " 46.18392762 37.5491127  46.64014708 48.85753741 48.49188087 42.74250099\n",
            " 46.54782166 47.12977915 45.51983834 48.83666726 42.58279481 38.41858723\n",
            " 48.15834103 46.23866306 40.97028242 32.71245311 26.53405868 47.36173993\n",
            " 39.7337678  49.37179298 47.04972681 46.14625655 42.4474227  47.61164633\n",
            " 34.16957107 45.64856175 40.52673567 41.44151003 44.02781891 45.26876027\n",
            " 44.70321679 38.5359597  36.22404025 48.87096667 36.22404025 41.65245452\n",
            " 47.36311045 36.22404025 47.0117968  48.98532356 44.62805069 49.32977728\n",
            " 43.93558325 47.6236637  46.27149542 48.73872979 45.71728117 41.39336725\n",
            " 41.13379776 34.47646882 49.30854599 49.65814165 47.61515152 46.79040555\n",
            " 40.7332176  44.85673661 45.24209763 46.02932483 46.65062122 43.43366359\n",
            " 45.39544394 46.34272603 44.49229691 45.22159023 49.36916234 46.35013744\n",
            " 32.11150479 47.81205682 47.12638372 40.66078414 42.76443125 49.47848091\n",
            " 38.71039453 39.40946023 41.55032923 39.98066868 45.11146544 49.26795622\n",
            " 48.33668621 41.7772514  49.60895131 42.60169521 36.22404025 42.50153834\n",
            " 47.05155989 44.59841573 48.4896032  46.76689958 35.83154698 46.58263676\n",
            " 47.94335905 48.24581092 41.69009441 46.63776263 45.29160228 35.70197402\n",
            " 47.54105827 39.35292096 33.58739034 37.04309502 48.06583889 26.32723706\n",
            " 42.82102014 45.19213022 46.48238113 44.54623122 38.6488325  46.44010102\n",
            " 41.99012917 29.66107963 45.09017436 46.47667635 46.29806533 47.45022803\n",
            " 41.36287113 49.03455465 48.02527935 48.1146788  37.60134505 36.81315731\n",
            " 49.20102215 40.4136029  44.61185494 35.13510657 45.20782866 47.41923923\n",
            " 36.22404025 36.22404025 45.0465026  45.18882777 46.35569923 49.42234379\n",
            " 44.83475174 40.31535324 45.83583121 45.36447329 47.77149801 35.61714317\n",
            " 42.92509531 46.48911697 42.12444581 44.60798212 46.73282875 46.81275031\n",
            " 41.03854635 45.00682073 49.67892135 35.78443783 44.2545672  47.90590978\n",
            " 48.36805897 45.56843772 30.79339357 45.20973895 49.61282407 42.89551538\n",
            " 41.46809065 38.56338741 44.63714917 44.15485774 49.3314229  34.08011367\n",
            " 33.51416479 43.91676796 36.22404025 44.7769241  47.01436198 40.62555934\n",
            " 37.94562735 34.07797269 47.87659527 46.2894793  47.2895669  35.22848193\n",
            " 43.30403312 32.53450773 38.71615047 30.79339357 47.07226791 42.11636279\n",
            " 43.53420463 44.52534191 46.16089379 47.04238798 39.51104041 48.54721896\n",
            " 46.593607   49.57749244 47.92514586 42.67110675 45.36980186 44.55863514\n",
            " 48.7436757  44.89655407 49.66172891 29.33162548 42.46971663 46.11115479\n",
            " 42.39313705 47.28122232 46.95121582 48.7082533  49.54325169 48.35166685\n",
            " 43.43799328 41.92728499 29.3113957  48.7246088  48.54989593 44.78402971\n",
            " 48.87041554 40.7106812  46.9775799  38.32351934 44.52480909 36.22404025\n",
            " 37.15622334 48.13494908 44.4829071  48.87658808 36.22404025 42.61409598\n",
            " 42.64772426 48.5563618  34.81982138 49.39770472 48.77337502 37.00251097\n",
            " 45.9426593  38.18184647 28.03088584 45.38764483 39.51770858 47.52967506\n",
            " 42.20797043 38.26475024 39.97622767 40.36413078 44.08249341 45.39052661\n",
            " 49.56632143 43.40644938 48.3679816  42.98586081 46.18424136 46.94237183\n",
            " 41.59662062 47.43596951 47.16147316 36.22404025 36.22404025 42.37552892\n",
            " 41.99403905 45.32549559 44.78074254 41.11409486 46.71443996 47.19090657\n",
            " 31.27967944 46.03578444 47.49432257 34.95025367 46.05097745 46.08743832\n",
            " 48.40033877 46.24078111 46.12616748 42.70834202 48.12379315 39.09859174\n",
            " 35.70197402 47.35112077 44.21923595 41.49260666 26.19970383 49.45227137\n",
            " 47.02934774 42.68775291 32.59211384 46.8307955  33.03109786 43.74253056\n",
            " 45.39052661 44.99299497 35.79848557 47.66395002 47.34491603 49.30319331\n",
            " 43.42637209 43.93324889 47.84776975 48.51100697 41.10775265 47.2253687\n",
            " 38.74220781 36.54015845 48.02734172 37.00773177 41.07510303 49.33261488\n",
            " 45.89628024 46.40683684 43.97919758 47.07083797 36.64403302 49.25517074\n",
            " 39.57383146 46.68604447 47.44765292 46.01821263 43.14880245 38.32780147\n",
            " 48.09211631 44.36892138 47.01930212 37.38000954 36.30543574 48.75416794\n",
            " 39.06806875 48.75674581 33.90952186 45.5809325  45.64640983 44.67268532\n",
            " 36.48998109 46.31074709 43.18559476 43.61605618 33.71446848 42.05480622\n",
            " 46.25497203 44.2975066  34.74189065 45.61130639 47.49444859 31.91116299\n",
            " 43.13996813 32.72390816 41.06949583 40.98487451 35.44918899 49.495429\n",
            " 45.97747375 34.61411626 46.48012409 41.20280851 39.87143875 47.23849835\n",
            " 47.43056925 49.26628099 49.28110263 38.84372219 37.29663985 46.24543734\n",
            " 45.28201299 46.95452015 44.69496313 47.5196699  37.40527125 37.64411364\n",
            " 46.34298042 42.90221844 46.95448753 47.91689409 37.48691788 47.99921056\n",
            " 32.44443634 49.20601006 40.13350178 46.65062122 49.1408644  48.84009546\n",
            " 46.09877705 48.75124365 46.83390272 37.27818255 45.1457339  43.27080535\n",
            " 42.72883071 36.50799234 47.97428731 30.71884943 44.8527547  36.22404025\n",
            " 42.65048844 48.84317132 44.41438351 25.58837824 43.65805196 36.22404025\n",
            " 36.22404025 44.6838391  31.0423543  49.14678998 47.49571228 48.85341597\n",
            " 40.58209209 40.01080724 48.38421874 49.01139466 36.10359325 47.72561196\n",
            " 41.23779525 47.88069708 32.67797405 46.62246055 37.41453834 47.66804541\n",
            " 37.8941467  44.50030085 40.03977396 48.27566377 48.5277893  47.9658056\n",
            " 39.15328851 47.68131217 37.20781554 47.889074   43.13336446 49.30520182\n",
            " 49.28401336 48.66965355 49.65775734 43.45950725 44.82780378 43.0297032\n",
            " 49.32723924 49.17023405 45.89443713 44.75501093 43.46697421 49.05244262\n",
            " 47.37738183 43.12947247 49.13890453 44.9965749  41.79390349 45.93313216\n",
            " 48.24752418 46.92045238 47.28562617 48.71933788 48.80504125 46.24267868\n",
            " 35.18635639 33.94805142 42.73057665 39.94285986 48.96225572 37.45432476\n",
            " 49.72174812 44.30005793 46.15849146 49.52360372 47.20554666 39.34814885\n",
            " 36.91257076 36.99532921 40.69924461 44.69630033 41.4086633  36.87178297\n",
            " 32.62317211 47.8271581  43.97693493 48.92034453 46.60728905 35.34106907\n",
            " 42.89124659 45.47011775 48.07280575 41.19433329 48.53397874 48.47926103\n",
            " 46.19365683 32.62934839 47.52967506 45.69946499 32.78674422 42.57543827\n",
            " 48.81600565 39.20290948 48.91836469 38.00919633 49.53501337 46.57634415\n",
            " 46.84416429 47.17816293 47.80648172 43.80694389 37.22856737 37.099278\n",
            " 43.279355   41.86114132 36.79932277 42.21228879 49.58766223 41.59922684\n",
            " 49.4340883  36.11517768 41.89945817 42.20801038 48.52953697 40.24131688\n",
            " 33.89367588 36.86815736 49.06348374 43.26565575 43.43436833 35.09297794\n",
            " 47.18566677 28.59870543 47.79544908 48.02461074 46.19882155 37.66295409\n",
            " 41.83120396 49.74344185 32.59465337 43.28825432 49.56707135 34.43794082\n",
            " 49.44267831 44.55436964 41.46135209 38.00559836 48.54659941 42.61288324\n",
            " 48.86776002 48.3883002  39.66679945 48.59394773 41.99002985 48.94681881\n",
            " 47.62696278 44.49622969 45.61511029 37.26636969 36.22404025 45.25741678\n",
            " 44.72788737 49.08856756 36.22404025 44.90563994 44.66339547 35.73727168\n",
            " 47.72561196 47.16266041 44.21375148 42.97000674 45.19301425 47.49432257\n",
            " 45.30827534 48.29151442 47.31728864 45.60700124 45.63701954 44.57000923\n",
            " 34.60852858 38.93290977 47.49780074 47.78055379 35.04056411 45.22376753\n",
            " 42.81225631 48.63696209 44.07573568 39.56245848 38.82694275 42.14532831\n",
            " 45.81949376 37.31504247 46.14186322 48.20883904 44.44053769 49.31219445\n",
            " 40.3895912  48.87755236 47.10002982 47.46790817 36.22404025 47.93347298\n",
            " 46.70311421 48.64432015 47.98123811 44.81334516 45.1587746  49.272948\n",
            " 47.88732644 38.42683172 41.32025479 46.03668307 39.4602997  37.05220118\n",
            " 48.63109586 48.67821404 34.99716818 40.76768254 39.9933949  48.93651527\n",
            " 39.51091936 42.23170811 49.10070569 38.6099232  31.64942454 49.38746423\n",
            " 47.40787267 43.19148604 47.82491503 45.79360138 42.89049531 35.9964414\n",
            " 35.5052437  40.32086265 46.83832044 47.58734759 37.33639305 36.22404025\n",
            " 45.97548107 31.02310388 40.78842591 36.22404025 37.49691245 14.44141581\n",
            " 49.82847572 47.08017834 47.85076786 40.09522944 47.45080099 44.01369619\n",
            " 40.79361272 48.38036619]\n",
            "selection [833 111 597 484 311 226  73 440 721 416] (10,) [14.44141581 22.78449939 25.58837824 26.19970383 26.32723706 26.53405868\n",
            " 27.96991174 28.03088584 28.59870543 29.3113957 ]\n",
            "trainset before adding uncertain samples (460, 10) (460,)\n",
            "trainset after adding uncertain samples (470, 10) (470,)\n",
            "updated train set: (470, 10) (470,) unique(labels): [228 242] [0 1]\n",
            "val set: (832, 10) (832,)\n",
            "\n",
            "Train set: (470, 10)\n",
            "Validation set: (832, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 47\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.315 s \n",
            "\n",
            "Accuracy rate is 80.875576 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.89      0.87       321\n",
            "           1       0.65      0.58      0.61       113\n",
            "\n",
            "    accuracy                           0.81       434\n",
            "   macro avg       0.75      0.74      0.74       434\n",
            "weighted avg       0.80      0.81      0.81       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[285  36]\n",
            " [ 47  66]]\n",
            "--------------------------------\n",
            "val predicted: (832,) [1 1 1 0 1 0 0 0 1 1 0 1 0 1 0 0 0 1 1 1 1 1 1 0 0 0 1 1 0 0 0 1 1 0 0 0 1\n",
            " 1 1 1 0 0 1 1 1 1 0 1 0 1 1 0 0 1 1 1 1 0 1 0 1 0 0 1 1 0 0 0 1 0 0 1 1 1\n",
            " 0 1 0 0 1 1 1 0 0 0 0 1 0 1 0 1 1 1 0 1 0 0 0 0 0 0 0 0 1 0 1 1 0 0 1 1 0\n",
            " 1 1 1 1 0 1 0 1 1 0 0 1 1 0 1 1 1 0 0 1 0 0 0 1 1 1 1 0 1 1 0 1 0 0 1 1 1\n",
            " 1 1 0 0 0 0 0 0 0 1 1 1 0 0 1 0 0 0 0 0 1 1 0 0 0 0 1 0 1 1 0 1 1 0 1 1 0\n",
            " 0 0 0 0 1 0 1 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 0 1 1 0 1 1 0 1 1 0 1 0 1 1\n",
            " 1 1 1 1 0 0 1 1 0 1 1 0 0 1 1 1 0 0 0 0 0 1 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0\n",
            " 0 0 0 1 1 1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 0 0 0 1 1 0 1 0 0 1 0 0 1 0 0 1 0\n",
            " 1 0 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 0 0 1 0 1 1 0 1 1 0 1 1 0\n",
            " 0 1 0 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 0 1 1 1 1 0 0 0 0 1 1 0 1 1 0\n",
            " 0 1 0 0 1 0 0 1 0 0 1 0 1 1 1 0 1 1 1 1 1 0 1 0 1 1 0 0 0 0 0 0 1 1 1 1 1\n",
            " 0 0 0 1 1 1 0 1 0 1 0 0 0 0 0 0 1 1 0 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 0 1 1\n",
            " 0 0 1 0 0 1 0 1 1 0 0 1 1 0 1 0 1 0 0 0 1 0 1 0 1 0 1 1 0 1 1 0 1 1 0 1 1\n",
            " 1 1 0 1 1 0 1 1 1 0 0 1 0 1 1 1 1 1 1 0 1 0 0 0 0 1 0 0 0 1 0 1 1 0 1 1 1\n",
            " 0 1 0 0 0 1 0 0 1 0 0 1 0 1 1 1 1 1 0 0 0 1 0 1 1 1 0 1 1 1 1 1 0 1 0 0 0\n",
            " 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 0 1 0 0 1 1 1 0 1 1 1 1 1 1 0 0 1 0 1 1 0\n",
            " 0 1 0 0 1 0 0 1 0 0 0 1 0 1 0 1 0 0 1 1 1 0 1 0 1 1 1 1 1 0 0 1 0 1 1 1 0\n",
            " 0 1 1 0 0 0 1 0 1 0 1 0 0 1 0 0 1 0 1 1 1 0 0 0 1 1 0 0 1 0 1 0 1 1 0 1 0\n",
            " 1 0 1 1 0 0 0 1 0 0 1 0 1 1 1 1 0 1 0 1 0 0 0 0 0 1 1 1 1 1 1 1 0 1 0 1 1\n",
            " 1 1 1 1 0 0 0 1 0 0 1 0 1 1 1 0 1 0 0 0 0 0 1 0 1 0 1 0 1 1 1 0 0 0 1 0 0\n",
            " 1 1 0 0 1 0 1 1 1 1 1 0 1 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0\n",
            " 1 1 0 1 0 0 1 0 1 1 0 0 0 0 1 0 1 1 1 0 1 1 1 1 1 1 0 0 0 0 1 0 0 0 1 0 0\n",
            " 1 1 0 1 0 1 1 1 0 1 0 0 1 1 0 1 0 0]\n",
            "probabilities: (832, 2) \n",
            " [1 1 1 0 1 0 0 0 1 1 0 1 0 1 0 0 0 1 1 1 1 1 1 0 0 0 1 1 0 0 0 1 1 0 0 0 1\n",
            " 1 1 1 0 0 1 1 1 1 0 1 0 1 1 0 0 1 1 1 1 0 1 0 1 0 0 1 1 0 0 0 1 0 0 1 1 1\n",
            " 0 1 0 0 1 1 1 0 0 0 0 1 0 1 0 1 1 1 0 1 0 0 0 0 0 0 0 0 1 0 1 1 0 0 1 1 0\n",
            " 1 1 1 1 0 1 0 1 1 0 0 1 1 0 1 1 1 0 0 1 0 0 0 1 1 1 1 0 1 1 0 1 0 0 1 1 1\n",
            " 1 1 0 0 0 0 0 0 0 1 1 1 0 0 1 0 0 0 0 0 1 1 0 0 0 0 1 0 1 1 0 1 1 0 1 1 0\n",
            " 0 0 0 0 1 0 1 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 0 1 1 0 1 1 0 1 1 0 1 0 1 1\n",
            " 1 1 1 1 0 0 1 1 0 1 1 0 0 1 1 1 0 0 0 0 0 1 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0\n",
            " 0 0 0 1 1 1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 0 0 0 1 1 0 1 0 0 1 0 0 1 0 0 1 0\n",
            " 1 0 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 0 0 1 0 1 1 0 1 1 0 1 1 0\n",
            " 0 1 0 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 0 1 1 1 1 0 0 0 0 1 1 0 1 1 0\n",
            " 0 1 0 0 1 0 0 1 0 0 1 0 1 1 1 0 1 1 1 1 1 0 1 0 1 1 0 0 0 0 0 0 1 1 1 1 1\n",
            " 0 0 0 1 1 1 0 1 0 1 0 0 0 0 0 0 1 1 0 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 0 1 1\n",
            " 0 0 1 0 0 1 0 1 1 0 0 1 1 0 1 0 1 0 0 0 1 0 1 0 1 0 1 1 0 1 1 0 1 1 0 1 1\n",
            " 1 1 0 1 1 0 1 1 1 0 0 1 0 1 1 1 1 1 1 0 1 0 0 0 0 1 0 0 0 1 0 1 1 0 1 1 1\n",
            " 0 1 0 0 0 1 0 0 1 0 0 1 0 1 1 1 1 1 0 0 0 1 0 1 1 1 0 1 1 1 1 1 0 1 0 0 0\n",
            " 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 0 1 0 0 1 1 1 0 1 1 1 1 1 1 0 0 1 0 1 1 0\n",
            " 0 1 0 0 1 0 0 1 0 0 0 1 0 1 0 1 0 0 1 1 1 0 1 0 1 1 1 1 1 0 0 1 0 1 1 1 0\n",
            " 0 1 1 0 0 0 1 0 1 0 1 0 0 1 0 0 1 0 1 1 1 0 0 0 1 1 0 0 1 0 1 0 1 1 0 1 0\n",
            " 1 0 1 1 0 0 0 1 0 0 1 0 1 1 1 1 0 1 0 1 0 0 0 0 0 1 1 1 1 1 1 1 0 1 0 1 1\n",
            " 1 1 1 1 0 0 0 1 0 0 1 0 1 1 1 0 1 0 0 0 0 0 1 0 1 0 1 0 1 1 1 0 0 0 1 0 0\n",
            " 1 1 0 0 1 0 1 1 1 1 1 0 1 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0\n",
            " 1 1 0 1 0 0 1 0 1 1 0 0 0 0 1 0 1 1 1 0 1 1 1 1 1 1 0 0 0 0 1 0 0 0 1 0 0\n",
            " 1 1 0 1 0 1 1 1 0 1 0 0 1 1 0 1 0 0]\n",
            "std (832,) [37.48090905 43.52857175 36.66641616 43.07642135 43.61789154 34.82791447\n",
            " 49.41882256 49.2851395  45.19489619 47.81350811 47.20567965 39.89902039\n",
            " 36.66740777 35.87552876 45.89959218 40.08788653 39.46351781 46.57998234\n",
            " 40.76718254 47.09494761 44.32092051 46.84514666 42.34959604 32.27075471\n",
            " 41.17593037 46.93675636 45.92170056 40.78546719 49.61407117 49.66127954\n",
            " 32.71075662 38.37776903 31.62922394 41.59980814 48.41306869 42.72143738\n",
            " 41.02886343 44.00422658 42.40131777 47.91760671 43.19559817 46.20203262\n",
            " 48.56769709 27.89024222 47.60336974 45.44590958 46.05221012 46.27794973\n",
            " 31.3683664  32.44071485 44.33808973 43.47738045 49.6930142  43.55162834\n",
            " 46.25889006 43.63567674 43.47727538 48.58102789 47.88030032 39.27343525\n",
            " 44.86884376 49.14404476 25.03827064 46.47584157 36.90865342 36.16510527\n",
            " 46.81391138 29.10243798 47.18350133 49.07248978 37.90903349 38.14535307\n",
            " 46.59944114 39.98603103 43.0531909  47.68541006 48.33561185 36.66740777\n",
            " 44.33494975 37.29598523 42.63522062 47.72245599 47.0663366  49.49789129\n",
            " 49.18906218 47.3200654  47.71638712 45.30975885 48.86154734 45.55165538\n",
            " 39.35968277 48.41992289 40.41371628 44.98275853 48.5500542  49.51749008\n",
            " 48.96233266 47.37195655 49.01750054 46.50031649 30.46034533 36.66740777\n",
            " 46.38033126 49.51069559 45.59200944 45.9981965  49.18358523 47.42851544\n",
            " 45.67439408 41.1613455  41.68667609 36.44282526 42.90207179 35.83754737\n",
            " 44.75711819 36.60887067 46.72445228 42.72413824 46.63455693 46.62407697\n",
            " 44.34171849 36.66740777 48.99605389 42.89915214 48.27025079 46.00688734\n",
            " 46.46894213 43.13899367 39.7358487  41.47478317 41.89295524 36.97169794\n",
            " 48.88755192 37.37284151 46.30709917 44.16190625 46.7838884  36.47661218\n",
            " 40.48153929 35.89182603 38.31789787 49.24390407 38.00113133 49.51227791\n",
            " 36.66740777 40.21869947 40.52226944 42.15862322 39.97492029 45.85538662\n",
            " 46.71572952 47.42567987 30.49644147 42.65340229 40.95704297 43.59247608\n",
            " 32.16248348 42.0097393  47.71931433 46.80449632 42.96287964 39.76430673\n",
            " 45.01707811 46.35297394 43.47988365 49.48766984 47.70676662 49.38010415\n",
            " 47.75292394 29.72138239 46.14366434 49.45059403 49.55061547 36.66740777\n",
            " 44.09414682 47.39216774 44.50623812 35.84310913 47.67011592 47.75687215\n",
            " 38.44538785 47.64538079 38.675553   47.96703649 37.98488441 40.56035265\n",
            " 49.29723072 42.88225763 46.19470243 48.73145141 47.07668016 41.52796503\n",
            " 29.45450056 40.46880718 43.95433982 41.28790673 41.0585911  47.7413864\n",
            " 45.29828817 45.89639677 45.97738425 41.2453482  46.74443373 48.76074055\n",
            " 47.06033967 42.46553928 47.01611199 42.51937877 46.64318636 34.39146239\n",
            " 46.51138481 49.07407163 48.89095177 44.54872805 45.30883688 47.2971698\n",
            " 46.53107295 48.80671923 43.93846447 31.48476762 48.38057616 45.62516046\n",
            " 40.44276176 34.99265683 47.18981394 37.82871719 49.37013767 47.55964657\n",
            " 46.33101958 42.81661187 48.06459358 38.3614902  46.6305236  42.21976466\n",
            " 41.81360728 41.89968062 46.54783556 45.96976282 39.35429332 36.66740777\n",
            " 48.99595806 36.66740777 40.23950472 47.83249534 36.66740777 46.98214719\n",
            " 48.78893973 42.64212679 49.36457142 43.24075807 46.55016212 45.99721565\n",
            " 48.67466858 46.27915736 35.16460346 39.04463129 35.84622559 49.14736605\n",
            " 49.53976669 46.72551617 45.8382739  42.90520701 46.08864608 43.39160688\n",
            " 46.476714   47.24269148 43.9494367  45.521497   47.13380646 45.46331494\n",
            " 45.25795641 49.14404476 46.81565255 30.27477203 48.05139536 46.97164414\n",
            " 37.57835402 42.51678006 49.52947237 38.84025407 39.35609218 36.05554093\n",
            " 38.86965561 45.50521775 49.17472433 48.71877901 40.74072759 49.6091453\n",
            " 44.85790444 36.66740777 44.55624523 45.00475461 44.84280055 48.43695518\n",
            " 46.2099729  37.00206089 46.15650546 48.23978203 47.47748172 44.02451788\n",
            " 46.81414845 45.60165391 35.94615448 46.85531844 40.11985364 31.89041089\n",
            " 33.12994529 47.88915733 44.46605575 45.13108442 46.02778386 44.39707159\n",
            " 40.465116   47.7014857  42.09355526 21.34929108 43.99300459 47.5005011\n",
            " 46.43883847 48.45714553 42.33408196 49.02467863 48.48194988 48.03791668\n",
            " 40.21807445 32.24269784 49.30161233 29.2800672  43.95832029 27.63582786\n",
            " 44.85546882 47.50071765 36.66740777 36.66740777 46.42543263 45.73788163\n",
            " 46.22171237 49.1515235  45.07885067 41.07792033 44.9172939  46.32155989\n",
            " 46.82534437 35.03749995 43.99834164 46.69908279 42.78646388 44.41575938\n",
            " 46.9193972  47.55807916 44.68112583 45.05904118 49.68252175 35.46203742\n",
            " 45.65286545 46.4248797  48.24848895 45.25040385 31.39277213 45.65677513\n",
            " 49.58335378 44.38508621 36.88016303 40.76354413 45.41697843 44.96308982\n",
            " 49.33471341 33.86407084 34.93007815 43.90889905 36.66740777 45.66774731\n",
            " 46.82134375 41.28186212 36.89258727 33.5911629  48.00454638 45.91108969\n",
            " 46.50514771 30.54117338 43.3392713  35.10769306 40.01810981 31.39277213\n",
            " 47.07462557 41.14084958 43.95365183 44.95557281 43.22192321 46.73618227\n",
            " 36.58063842 48.03100627 47.07657441 49.4586082  48.41534825 42.30642652\n",
            " 45.70227939 39.46499799 49.02953529 46.39032054 49.54416443 32.5479691\n",
            " 43.22395849 46.61808509 41.61805021 47.18398633 46.87054416 48.58849421\n",
            " 49.6039067  48.05726385 43.47581689 42.12293595 48.86655475 47.91082333\n",
            " 45.41494249 49.01232    43.2538031  45.64444799 38.75602407 44.91808851\n",
            " 36.66740777 33.2693869  48.83889171 44.22711922 48.64444426 36.66740777\n",
            " 45.09962475 40.94732437 48.65967465 34.10719395 49.38798503 47.99477114\n",
            " 34.40216315 45.33628149 40.05868826 44.96986648 41.0048395  47.00882272\n",
            " 41.75606127 37.40142116 41.37220448 41.64784048 45.24264474 45.5404321\n",
            " 49.38300474 44.57996752 48.48997845 42.14845321 46.55674858 46.00486328\n",
            " 42.62847457 47.36792054 47.9341411  36.66740777 36.66740777 41.0063507\n",
            " 43.08882928 46.03239114 46.26724245 43.12068448 46.98675662 44.97148266\n",
            " 27.56730926 45.75557138 47.52642942 33.71664519 47.26977801 46.43123561\n",
            " 48.91460451 45.94174208 46.99395874 44.15741546 48.5195983  38.14617205\n",
            " 35.94615448 46.76840571 44.92570173 42.34645884 49.35942544 47.21148845\n",
            " 43.58906421 36.60005562 47.2737615  38.86515204 46.69064451 45.5404321\n",
            " 42.89679576 41.65565829 47.96991717 47.83840998 49.4914304  44.7900645\n",
            " 43.88070388 47.46110186 47.94125908 41.51914678 46.82866389 36.92003312\n",
            " 35.22007281 48.1217468  36.35901508 41.92957894 49.15124781 45.67017199\n",
            " 44.76045117 43.40650827 46.55329234 33.58344682 49.34791901 42.91008176\n",
            " 47.09084175 47.9516445  46.53531541 43.55938646 35.5343196  48.03283464\n",
            " 45.31608566 47.22415038 42.34747933 39.64190836 49.09953708 39.6277963\n",
            " 49.21901617 35.56946058 43.89685429 46.08772812 45.97053885 30.47303807\n",
            " 45.96533941 44.7321005  37.81884197 35.28471173 42.55183176 46.77913896\n",
            " 45.94700543 32.28649064 44.58413344 46.63741689 32.87289878 43.41503551\n",
            " 23.67507285 41.13548487 40.45458889 33.60721342 49.41787511 46.99231801\n",
            " 38.8291211  46.67213423 41.77561664 40.19475066 47.47505895 47.95503663\n",
            " 49.10945026 49.17554254 38.46443444 36.09394179 47.48848835 44.70184002\n",
            " 47.58024274 45.2285702  47.53601348 37.71116735 40.7996764  47.16695942\n",
            " 40.85763198 46.97471239 48.10415724 41.54770725 48.54221164 38.73908422\n",
            " 49.42907292 39.12231652 47.24269148 49.2265787  48.47897795 45.6995148\n",
            " 48.19308989 47.32965993 41.21198232 44.52751466 43.46759103 42.26648691\n",
            " 39.43583379 47.01396681 39.91016305 44.55714371 36.66740777 42.95692674\n",
            " 48.93980256 45.69368396 41.90316779 36.66740777 36.66740777 43.74657599\n",
            " 35.5052898  49.10515739 47.72610857 48.75354552 39.47297695 40.29567378\n",
            " 48.36910859 48.9264686  27.46872227 47.24780154 42.21337674 48.02478655\n",
            " 36.03369956 47.28213343 39.24632785 47.60548471 37.3054381  45.47249029\n",
            " 38.72662602 47.89153586 48.48148847 47.92520441 37.53332586 47.73749004\n",
            " 40.16745675 47.54454885 41.90184617 49.13215744 49.38603608 48.91780867\n",
            " 49.62857394 43.81035687 44.99947612 44.39287305 49.3212869  49.16752831\n",
            " 46.76459433 43.04806958 44.76363463 48.63588863 47.37965404 43.42944903\n",
            " 49.28025621 45.86735618 37.91722597 43.54890088 46.92418388 47.62090167\n",
            " 47.46084573 48.44996279 49.00673048 46.15649165 36.18545631 34.45242501\n",
            " 43.8529358  31.28816267 48.22413168 32.79232722 49.5856826  45.68925527\n",
            " 46.13681901 49.43249504 48.09946406 37.07770851 35.27637768 36.47493338\n",
            " 38.61312326 45.40052486 41.65597583 34.77132966 25.61554512 47.88709671\n",
            " 44.70925532 49.16785726 45.5747376  37.81532848 42.16576647 45.18274064\n",
            " 47.74336088 41.58678494 47.91185196 48.31083494 45.80896207 37.04345998\n",
            " 47.00882272 46.14468287 37.45942416 38.64968807 48.65997076 38.9208887\n",
            " 48.68146116 35.2282553  49.59681962 46.79526175 43.60124261 46.8348653\n",
            " 48.12396936 40.73419987 37.85438652 35.51687139 42.48341128 39.30171739\n",
            " 38.76899949 37.87143118 49.69029965 43.84260747 49.41738184 33.76392817\n",
            " 42.49966076 42.25702551 48.56359781 39.0876112  32.6835568  38.72269913\n",
            " 49.39043191 40.99372345 42.24043248 36.36869549 46.6092282  48.29186361\n",
            " 46.04214685 46.57971405 34.81689236 44.16890366 49.73932238 35.2482206\n",
            " 43.47494566 49.50868134 37.83996581 49.50607625 46.00082047 42.43438382\n",
            " 34.48003035 48.3233038  41.96700046 48.97124898 48.30068186 43.21749717\n",
            " 48.62621652 44.5353131  48.98436934 47.91047279 44.3855653  46.42386009\n",
            " 38.53724598 36.66740777 43.2167567  45.62455245 49.10707595 36.66740777\n",
            " 45.54640052 44.96292711 35.87552876 47.24780154 47.37076098 45.06088786\n",
            " 39.89882941 46.41522599 47.52642942 46.74237824 47.86709871 46.37807483\n",
            " 46.19972942 44.3176921  43.50584788 37.96719552 41.0061024  47.72123617\n",
            " 48.16378099 40.0467252  45.13944185 43.42664031 48.7586519  44.61757546\n",
            " 43.23258514 35.89687142 40.4389426  45.69805113 37.49243928 46.27478066\n",
            " 47.67711561 46.18072285 49.26635581 37.54718575 48.811745   46.04233934\n",
            " 48.09136031 36.66740777 47.87944692 47.60327195 48.73433469 47.29143708\n",
            " 43.9254874  43.58296871 48.88722748 47.72417717 40.29800884 40.9307851\n",
            " 46.5659874  39.09072923 35.12262152 48.75105232 48.78767114 40.57590194\n",
            " 42.90197846 38.38354579 49.20247272 39.89721645 42.97692667 48.95595059\n",
            " 43.70234546 34.81795562 49.39339987 47.23633744 45.44730192 48.15173941\n",
            " 45.80781489 40.83870368 34.71040725 37.14795335 40.33016504 47.18425535\n",
            " 46.99171765 38.74221715 36.66740777 46.59194057 31.93284687 41.57688909\n",
            " 36.66740777 38.7043025  49.70993049 47.48327975 47.40235861 44.74229315\n",
            " 47.96312173 42.87854259 41.63101616 48.4485791 ]\n",
            "selection [315 540  62 664 602 462 329  43  67 327] (10,) [21.34929108 23.67507285 25.03827064 25.61554512 27.46872227 27.56730926\n",
            " 27.63582786 27.89024222 29.10243798 29.2800672 ]\n",
            "trainset before adding uncertain samples (470, 10) (470,)\n",
            "trainset after adding uncertain samples (480, 10) (480,)\n",
            "updated train set: (480, 10) (480,) unique(labels): [234 246] [0 1]\n",
            "val set: (822, 10) (822,)\n",
            "\n",
            "Train set: (480, 10)\n",
            "Validation set: (822, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 48\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.370 s \n",
            "\n",
            "Accuracy rate is 81.105991 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.89      0.87       321\n",
            "           1       0.65      0.59      0.62       113\n",
            "\n",
            "    accuracy                           0.81       434\n",
            "   macro avg       0.76      0.74      0.75       434\n",
            "weighted avg       0.81      0.81      0.81       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[285  36]\n",
            " [ 46  67]]\n",
            "--------------------------------\n",
            "val predicted: (822,) [1 1 1 0 1 0 0 0 1 1 0 1 0 1 0 0 0 1 1 1 1 1 1 0 0 0 1 1 0 0 0 1 1 0 0 0 1\n",
            " 1 1 1 0 0 1 1 1 0 1 0 1 1 0 0 1 1 1 1 0 1 0 1 0 1 1 0 0 1 0 0 1 1 1 0 1 0\n",
            " 0 1 1 1 0 0 0 0 1 0 1 0 1 1 1 0 1 0 0 0 0 0 0 0 0 1 0 1 1 0 0 1 1 0 1 1 1\n",
            " 1 0 1 0 1 1 0 0 1 1 0 1 1 1 0 0 1 0 0 0 1 1 1 1 0 1 1 0 1 0 0 1 1 1 1 1 0\n",
            " 0 0 0 0 0 0 1 1 1 0 0 1 0 0 0 0 0 1 1 0 0 0 0 1 0 1 1 0 1 1 0 1 1 0 0 0 0\n",
            " 0 1 0 1 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 0 1 1 0 1 1 0 1 1 0 1 0 1 1 1 1 1\n",
            " 1 0 0 1 1 0 1 1 0 0 1 1 1 0 0 0 0 0 1 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0\n",
            " 1 1 1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 0 0 0 1 1 0 1 0 0 1 0 0 1 0 0 1 0 1 0 0\n",
            " 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 0 1 1 0 1 1 1 0 0 1 0 1 0 1\n",
            " 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 0 1 1 1 1 0 0 0 0 1 1 0 1 1 0 0 1 0 0 1 0\n",
            " 0 1 0 0 1 0 1 1 1 0 1 1 1 1 1 0 1 0 1 1 0 0 0 0 0 0 1 1 1 1 1 0 0 0 1 1 1\n",
            " 0 1 0 1 0 0 0 0 0 0 1 1 0 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 0 0 1\n",
            " 0 1 1 0 0 1 1 0 1 0 1 0 0 1 0 1 0 1 0 1 1 0 1 1 0 1 1 0 1 1 1 1 0 1 1 0 1\n",
            " 1 1 0 0 1 0 1 1 1 1 1 1 0 1 0 0 0 0 1 0 0 0 1 0 1 1 0 1 1 1 0 1 0 0 0 1 0\n",
            " 0 1 0 0 1 0 1 1 1 1 1 0 0 0 1 1 1 1 0 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 1 1 0\n",
            " 1 1 1 1 1 0 1 0 0 1 0 0 1 1 1 0 1 1 1 1 1 1 0 0 1 0 1 1 0 0 1 0 0 1 0 0 1\n",
            " 0 0 1 0 1 0 1 0 0 1 1 1 0 1 0 1 1 1 1 1 0 0 1 0 1 1 1 0 0 1 1 0 0 0 1 0 1\n",
            " 0 1 0 0 1 0 0 1 0 1 1 1 0 0 0 1 1 0 0 1 0 1 0 1 1 0 0 1 0 1 1 0 0 0 1 0 0\n",
            " 1 0 1 1 1 1 0 1 0 1 0 0 0 0 0 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 0 1 0 0\n",
            " 1 0 1 1 1 0 1 0 0 0 0 0 1 0 1 0 1 0 1 1 1 0 0 0 1 0 0 1 1 0 0 1 0 1 1 1 1\n",
            " 1 0 1 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 0 1 0 0 1 0 1 1\n",
            " 0 0 0 0 1 0 1 1 1 0 1 1 1 1 1 1 0 0 0 0 1 0 0 0 1 0 0 1 1 0 1 0 1 1 1 0 1\n",
            " 0 0 1 1 0 1 0 0]\n",
            "probabilities: (822, 2) \n",
            " [1 1 1 0 1 0 0 0 1 1 0 1 0 1 0 0 0 1 1 1 1 1 1 0 0 0 1 1 0 0 0 1 1 0 0 0 1\n",
            " 1 1 1 0 0 1 1 1 0 1 0 1 1 0 0 1 1 1 1 0 1 0 1 0 1 1 0 0 1 0 0 1 1 1 0 1 0\n",
            " 0 1 1 1 0 0 0 0 1 0 1 0 1 1 1 0 1 0 0 0 0 0 0 0 0 1 0 1 1 0 0 1 1 0 1 1 1\n",
            " 1 0 1 0 1 1 0 0 1 1 0 1 1 1 0 0 1 0 0 0 1 1 1 1 0 1 1 0 1 0 0 1 1 1 1 1 0\n",
            " 0 0 0 0 0 0 1 1 1 0 0 1 0 0 0 0 0 1 1 0 0 0 0 1 0 1 1 0 1 1 0 1 1 0 0 0 0\n",
            " 0 1 0 1 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 0 1 1 0 1 1 0 1 1 0 1 0 1 1 1 1 1\n",
            " 1 0 0 1 1 0 1 1 0 0 1 1 1 0 0 0 0 0 1 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0\n",
            " 1 1 1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 0 0 0 1 1 0 1 0 0 1 0 0 1 0 0 1 0 1 0 0\n",
            " 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 0 1 1 0 1 1 1 0 0 1 0 1 0 1\n",
            " 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 0 1 1 1 1 0 0 0 0 1 1 0 1 1 0 0 1 0 0 1 0\n",
            " 0 1 0 0 1 0 1 1 1 0 1 1 1 1 1 0 1 0 1 1 0 0 0 0 0 0 1 1 1 1 1 0 0 0 1 1 1\n",
            " 0 1 0 1 0 0 0 0 0 0 1 1 0 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 0 0 1\n",
            " 0 1 1 0 0 1 1 0 1 0 1 0 0 1 0 1 0 1 0 1 1 0 1 1 0 1 1 0 1 1 1 1 0 1 1 0 1\n",
            " 1 1 0 0 1 0 1 1 1 1 1 1 0 1 0 0 0 0 1 0 0 0 1 0 1 1 0 1 1 1 0 1 0 0 0 1 0\n",
            " 0 1 0 0 1 0 1 1 1 1 1 0 0 0 1 1 1 1 0 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 1 1 0\n",
            " 1 1 1 1 1 0 1 0 0 1 0 0 1 1 1 0 1 1 1 1 1 1 0 0 1 0 1 1 0 0 1 0 0 1 0 0 1\n",
            " 0 0 1 0 1 0 1 0 0 1 1 1 0 1 0 1 1 1 1 1 0 0 1 0 1 1 1 0 0 1 1 0 0 0 1 0 1\n",
            " 0 1 0 0 1 0 0 1 0 1 1 1 0 0 0 1 1 0 0 1 0 1 0 1 1 0 0 1 0 1 1 0 0 0 1 0 0\n",
            " 1 0 1 1 1 1 0 1 0 1 0 0 0 0 0 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 0 1 0 0\n",
            " 1 0 1 1 1 0 1 0 0 0 0 0 1 0 1 0 1 0 1 1 1 0 0 0 1 0 0 1 1 0 0 1 0 1 1 1 1\n",
            " 1 0 1 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 0 1 0 0 1 0 1 1\n",
            " 0 0 0 0 1 0 1 1 1 0 1 1 1 1 1 1 0 0 0 0 1 0 0 0 1 0 0 1 1 0 1 0 1 1 1 0 1\n",
            " 0 0 1 1 0 1 0 0]\n",
            "std (822,) [39.89405072 42.49656866 33.45461878 44.03647213 43.35551225 35.14156202\n",
            " 49.32306028 49.24942176 46.28408771 47.62848483 46.4840909  42.41649511\n",
            " 36.71331769 35.59709712 44.6825135  34.87600599 35.14921631 46.70366744\n",
            " 41.3019194  47.36962569 44.24454184 46.18092689 44.36426408 28.20167286\n",
            " 36.48726301 46.53942309 45.73122564 37.19499186 49.38060838 49.5953825\n",
            " 30.73602593 35.76758893 33.89449556 41.28710861 48.75640332 41.96814784\n",
            " 40.86229996 43.56549508 42.33819722 48.16964268 43.39286338 47.37998296\n",
            " 47.66292808 46.8426826  43.74599631 46.93210797 44.91649853 25.68995921\n",
            " 33.90663906 45.61723093 43.67656585 49.04825974 43.42664553 46.6062376\n",
            " 44.00188775 44.08981156 48.92777847 47.13316525 37.42709907 46.08256425\n",
            " 49.09473377 46.03850546 35.51332953 34.44011259 46.39812706 47.38959357\n",
            " 47.91681414 43.82842385 38.9886007  45.79620032 41.08178858 43.05066325\n",
            " 47.51485283 48.76114772 36.71331769 43.88373881 36.61129337 41.8376621\n",
            " 47.51241167 47.21155432 49.44775184 48.98493203 47.44856358 48.19557335\n",
            " 45.85567446 48.59125497 45.34812607 40.06022527 48.28811841 42.39767748\n",
            " 45.63164961 48.16430055 49.41960048 48.7671561  44.92004893 48.88812791\n",
            " 47.00711873 32.3911984  36.71331769 46.54066186 49.4080855  45.23583192\n",
            " 45.30371527 49.18155668 47.84579876 45.69658645 39.33628726 42.33846165\n",
            " 35.30146376 41.64886578 38.20383069 44.59927187 35.36193724 45.61593119\n",
            " 41.84294683 46.17159518 46.17462275 44.22338821 36.71331769 48.82390823\n",
            " 43.82196261 48.79347427 46.20606797 46.19818141 42.80302433 40.91892442\n",
            " 43.70610304 42.61544229 32.07636099 48.70467786 38.65074277 46.17833645\n",
            " 44.10879942 45.65668479 33.76279554 36.85758931 32.03752405 35.81805241\n",
            " 49.28815177 39.97950331 49.51537397 36.71331769 39.91026455 39.92558013\n",
            " 41.86080266 42.8094457  45.77389996 45.54409795 47.72873248 34.4579801\n",
            " 43.38242117 39.44666276 46.03357058 32.98707016 43.84572066 47.07132683\n",
            " 45.89638732 44.91194521 38.82468933 44.15026805 45.59434616 41.15954593\n",
            " 49.50550981 47.28624834 49.16759982 48.05089307 32.9153985  47.79574122\n",
            " 49.43845615 49.63859655 36.71331769 42.28497227 48.07813468 45.13702667\n",
            " 29.57269455 47.35404522 47.56426542 37.55776708 46.28331492 39.09522716\n",
            " 47.72051866 38.8677091  35.76235043 49.26811107 42.19822742 44.30627482\n",
            " 48.28826516 45.49380122 42.45614406 28.17141853 42.01711851 42.9866292\n",
            " 40.96008209 40.83342209 47.8189219  45.94907017 45.85742314 47.28414027\n",
            " 39.10519116 47.35500328 48.73657422 46.15276367 45.30354326 46.3997764\n",
            " 45.69354629 46.56277325 35.58341587 45.34843571 48.99859054 48.91339307\n",
            " 43.70433703 46.30344407 48.09875645 46.91935963 48.66044318 43.67694986\n",
            " 31.83762381 48.2056158  45.33898952 37.65244933 35.93550341 46.48872311\n",
            " 40.49755862 49.28760611 48.36027689 45.83922957 40.9720346  47.39895418\n",
            " 30.23351706 46.44682478 43.19726867 43.17868261 44.70531302 45.3771525\n",
            " 43.98461842 39.60267242 36.71331769 49.0556265  36.71331769 40.70303823\n",
            " 46.97895696 36.71331769 46.71084511 48.87552599 42.57669787 49.02617095\n",
            " 43.24248338 47.10260442 46.67941818 48.40838733 45.07874193 41.93550677\n",
            " 42.17567832 37.65828967 49.20329617 49.43444354 46.77883214 44.75790524\n",
            " 37.80782218 45.74938092 43.6524491  46.31167967 46.2661863  43.21485339\n",
            " 45.5252473  46.03311859 45.23540476 44.85595095 49.09473377 45.42836827\n",
            " 31.08314918 47.83575106 47.74029502 37.10962433 42.57085853 49.3910199\n",
            " 44.31770727 41.85646312 37.3562993  36.77534082 45.60984707 49.01260896\n",
            " 48.78914008 39.00772521 49.19839942 40.59435362 36.71331769 43.64089677\n",
            " 45.98071375 45.26298243 47.79258191 45.92452625 38.9405099  46.00542287\n",
            " 48.08315757 47.91957413 43.24075276 46.72475344 46.51958972 35.02655881\n",
            " 46.50060315 41.36945186 29.13775425 33.23194824 47.9681646  44.86145443\n",
            " 46.09595254 44.1018963  43.75105501 40.66670765 47.42849077 42.6959459\n",
            " 42.73001294 46.79591645 46.75600872 48.41256636 41.28874359 48.83921823\n",
            " 48.18550319 48.43070406 36.27584926 31.40374898 49.28907527 45.03399143\n",
            " 44.55761103 47.22942333 36.71331769 36.71331769 45.21009582 45.59595417\n",
            " 46.70602858 49.17491336 42.88348074 41.85074345 45.29008983 45.22546184\n",
            " 47.14855583 35.73254205 43.37410363 46.67354105 41.56825603 45.26088445\n",
            " 47.67917853 46.77038378 43.81597355 43.08992975 49.44640348 26.12980771\n",
            " 45.22761634 47.88758417 48.50890006 44.91861839 35.97711232 43.70347269\n",
            " 49.31119169 44.03784384 36.11673085 41.14662435 45.48248477 43.15745696\n",
            " 49.24985038 27.68786095 25.41656127 43.49730151 36.71331769 44.89564357\n",
            " 45.11732891 41.04689951 32.04252373 31.54085831 47.45208935 47.43032041\n",
            " 45.59945593 39.60380491 43.12692657 27.26102631 38.9216312  35.97711232\n",
            " 46.88190847 41.47797656 45.55315421 45.39019562 44.76081669 47.04331722\n",
            " 36.83961496 47.86666619 43.68346689 49.372373   47.33368351 41.52538759\n",
            " 46.46065394 42.95808953 49.05832857 44.68877058 49.4492001  32.99999047\n",
            " 40.53184784 45.76281003 42.66260382 46.92977199 47.33326113 48.2911935\n",
            " 49.48758416 47.73313484 42.86698793 40.68393938 48.65013704 49.05384926\n",
            " 45.14142518 48.73232974 43.63041165 46.22031667 38.98093753 43.01291469\n",
            " 36.71331769 39.03034508 48.96856735 44.22951859 48.75009966 36.71331769\n",
            " 43.21502119 40.04276354 48.79742876 33.74246386 49.27376498 48.93872936\n",
            " 34.96580016 45.68812164 41.35857331 44.90972999 38.22273579 47.13944487\n",
            " 41.03409776 38.00634697 40.95307792 40.77197149 42.07063732 45.54515778\n",
            " 49.46799904 42.82970595 48.31272035 41.19085853 47.07117499 47.04500714\n",
            " 43.95381703 46.82342238 47.76895726 36.71331769 36.71331769 39.7074638\n",
            " 43.86428426 45.08983353 46.20757722 43.38400962 47.36092654 45.50481018\n",
            " 46.73772903 47.54895603 38.04524992 46.608083   46.33077412 48.88506617\n",
            " 45.65760697 45.16303046 43.45379116 46.65562148 35.1202292  35.02655881\n",
            " 46.78794659 44.68307208 38.18310286 49.16480187 46.27093561 42.10019749\n",
            " 35.20491571 47.46911412 36.01390865 44.35152115 45.54515778 43.91334007\n",
            " 40.18939953 47.92863682 46.93716169 49.44510154 42.69452862 42.68228524\n",
            " 46.48559765 48.39621737 40.71347162 47.42767333 41.03241956 34.22503102\n",
            " 47.79500138 37.85047579 41.3894668  48.9758643  46.21433459 45.60000421\n",
            " 41.77304557 47.3061224  37.38603357 49.03907745 42.31518751 45.32540339\n",
            " 47.90793701 46.18846343 43.65883342 38.99236685 47.982324   45.64359998\n",
            " 45.87667365 38.9439413  37.7617707  48.30061805 39.72632856 49.17517403\n",
            " 32.14149378 45.23244363 44.38134467 44.00400605 35.66650958 45.89113917\n",
            " 43.36049504 43.03418816 36.664719   40.66544237 46.66699721 45.5773306\n",
            " 34.18904537 45.08819654 46.84259629 29.96335513 43.98066726 40.86364746\n",
            " 38.79688932 36.88449058 49.26611906 44.934953   36.6098547  46.6195464\n",
            " 41.04674495 39.80586207 46.55544529 46.281855   49.38159888 49.05376991\n",
            " 38.28820845 37.33106506 46.27704919 46.54972191 47.36666455 45.42147021\n",
            " 47.78505936 40.52005838 38.04301518 45.37297073 35.37341416 47.42078255\n",
            " 47.66689201 39.5440537  47.88567119 38.05176854 49.452871   39.29220618\n",
            " 46.2661863  48.96492289 48.63687018 44.5577517  47.48468534 46.76251577\n",
            " 35.66352054 44.73829927 44.21733083 40.72131127 35.88222433 47.23190916\n",
            " 40.08096781 43.79462132 36.71331769 42.6264027  48.53765478 45.54127195\n",
            " 42.59464759 36.71331769 36.71331769 43.51620086 34.33568307 48.55496438\n",
            " 47.59221293 47.7046691  40.56467693 41.72561178 48.47016806 48.69659531\n",
            " 47.07906745 44.23266029 48.07201219 32.47038368 46.99456849 38.88577987\n",
            " 47.78890396 38.04094165 45.62584214 38.95031191 47.59912397 48.35441493\n",
            " 46.05015246 37.16075244 47.43845677 32.51092213 46.81584622 45.27512083\n",
            " 49.02950292 49.13853045 48.69305366 49.00743474 43.62102975 44.17498199\n",
            " 44.01773159 49.27588937 48.9933386  45.13414021 42.51646093 43.21306235\n",
            " 48.67829192 47.42743884 43.35816121 49.32957345 44.31561434 39.46234381\n",
            " 44.82813612 47.44636027 48.12871942 47.38587737 48.83423301 48.43972174\n",
            " 46.00125517 38.63106131 31.94949356 44.22345647 28.17670575 48.53575082\n",
            " 34.30472434 49.32438267 43.67447278 45.65406896 48.93612553 46.85849049\n",
            " 41.00842633 33.57809418 35.99702108 39.39570966 45.32333045 43.02822078\n",
            " 36.14742667 47.82935821 45.16519745 48.8011942  46.18019628 29.26345978\n",
            " 42.44069855 46.29144318 47.3423158  42.07031366 48.31212784 48.14959351\n",
            " 45.3580606  38.39901819 47.13944487 44.44322641 35.44732473 40.7766589\n",
            " 47.41221384 40.08812512 48.43597822 33.34827936 49.34216511 47.60970036\n",
            " 45.14182045 47.7666467  47.08144632 43.63726702 37.82462642 38.40595566\n",
            " 41.72544275 38.51754569 35.85130311 42.05986718 49.48568361 42.93405625\n",
            " 49.14702539 32.51468185 41.25613595 44.12281953 48.31118331 42.40090665\n",
            " 30.11097647 36.88966445 49.04541663 42.54378294 40.80584736 35.93159203\n",
            " 46.88208684 48.30225489 46.18203664 46.43673912 37.29648103 43.47461965\n",
            " 49.57750973 34.14061405 45.00855053 49.13952    33.67422213 49.09536003\n",
            " 46.04249424 41.59056798 33.53898849 48.59120613 42.07077917 48.68041584\n",
            " 47.98515694 39.87959589 48.22324526 43.14330567 49.04872763 46.85447306\n",
            " 42.38665228 45.96305548 36.9109863  36.71331769 44.22968725 45.22479073\n",
            " 49.14022988 36.71331769 43.02198701 44.50676386 35.59709712 47.07906745\n",
            " 47.75216479 43.4207447  42.9195808  45.60898723 47.54895603 46.75097266\n",
            " 47.31190091 46.51122504 46.14587465 44.91984465 44.19888156 36.97318242\n",
            " 41.10992615 47.07650188 48.17160927 40.54501657 45.90764601 41.9169559\n",
            " 48.64965712 43.73690059 43.3143097  35.28574055 41.33776305 45.54785782\n",
            " 34.97106964 45.66096247 48.1812339  45.52633242 49.14928249 36.63930705\n",
            " 48.66079313 45.67437322 47.42577909 36.71331769 47.67473772 46.91032507\n",
            " 49.02675053 47.20479844 42.7920265  43.47350095 49.00534845 47.26978262\n",
            " 42.10066624 42.15559981 45.1286456  37.68837134 36.25882046 48.6363755\n",
            " 49.06141748 36.55175493 42.74095906 42.22975376 49.03150367 38.79391588\n",
            " 41.67651708 48.77426969 42.47425926 32.79843522 49.13017173 45.22831381\n",
            " 43.35600093 48.11223652 46.52114743 41.8114156  31.78918054 36.32877466\n",
            " 37.60768635 47.6380793  47.34191765 38.71390229 36.71331769 46.380981\n",
            " 29.01845532 41.54288022 36.71331769 39.2497421  49.70474485 47.23498208\n",
            " 47.90098444 43.8315006  47.24687556 45.50804518 39.57756453 48.474509  ]\n",
            "selection [362  47 347 375 361 189 640  23 810 302] (10,) [25.41656127 25.68995921 26.12980771 27.26102631 27.68786095 28.17141853\n",
            " 28.17670575 28.20167286 29.01845532 29.13775425]\n",
            "trainset before adding uncertain samples (480, 10) (480,)\n",
            "trainset after adding uncertain samples (490, 10) (490,)\n",
            "updated train set: (490, 10) (490,) unique(labels): [238 252] [0 1]\n",
            "val set: (812, 10) (812,)\n",
            "\n",
            "Train set: (490, 10)\n",
            "Validation set: (812, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 49\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.394 s \n",
            "\n",
            "Accuracy rate is 80.875576 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.88      0.87       321\n",
            "           1       0.64      0.59      0.62       113\n",
            "\n",
            "    accuracy                           0.81       434\n",
            "   macro avg       0.75      0.74      0.75       434\n",
            "weighted avg       0.80      0.81      0.81       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[284  37]\n",
            " [ 46  67]]\n",
            "--------------------------------\n",
            "val predicted: (812,) [1 1 1 0 1 0 0 0 1 1 0 1 0 1 0 0 0 1 1 1 1 1 1 0 0 1 1 0 0 0 1 1 0 0 0 1 1\n",
            " 1 1 0 0 1 1 1 0 1 1 1 0 0 1 1 1 1 0 1 0 1 0 1 1 0 0 1 0 0 1 1 1 0 1 0 0 1\n",
            " 1 1 0 0 0 0 1 0 1 0 1 1 1 0 1 0 0 0 0 0 0 0 0 1 0 1 1 0 0 1 1 0 1 1 1 1 0\n",
            " 1 0 1 1 0 0 1 1 0 1 1 1 0 0 1 0 0 0 1 1 1 1 0 1 1 0 1 0 0 1 1 1 1 1 0 0 0\n",
            " 0 0 0 0 1 1 1 0 0 1 0 0 0 0 0 1 1 0 0 0 0 1 0 1 1 0 1 1 0 1 1 0 0 0 0 0 1\n",
            " 0 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 0 1 1 0 1 1 0 1 1 0 1 0 1 1 1 1 1 1 0 0\n",
            " 1 1 0 1 1 0 0 1 1 1 0 0 0 0 0 1 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 1 1\n",
            " 1 1 1 1 1 1 0 1 0 1 0 0 1 0 0 0 0 1 1 0 1 0 0 1 0 0 1 0 0 1 0 1 0 0 1 1 1\n",
            " 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 0 1 1 0 1 1 1 0 0 1 0 1 0 1 1 1 1 0\n",
            " 1 1 0 1 1 1 1 1 1 0 1 0 1 1 1 1 0 0 0 0 1 1 0 0 0 1 0 0 1 0 0 1 0 0 1 1 1\n",
            " 1 0 1 1 1 1 1 0 1 0 1 1 0 0 0 0 0 0 1 1 1 1 1 0 0 0 1 1 1 0 1 0 1 0 0 0 0\n",
            " 0 0 1 1 0 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 0 0 1 0 1 1 0 0 1 1 0\n",
            " 1 0 1 0 0 1 0 1 0 1 0 1 1 0 1 1 0 1 1 0 1 1 1 1 0 1 1 0 1 1 1 0 0 1 0 1 1\n",
            " 1 1 1 1 0 1 0 0 0 0 1 0 0 0 1 0 1 1 0 1 1 1 0 1 0 0 0 1 0 0 1 0 0 1 0 1 1\n",
            " 1 1 1 0 0 0 1 1 1 1 0 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0\n",
            " 0 1 0 0 1 1 1 0 1 1 1 1 1 1 0 0 1 0 1 1 0 0 1 0 0 1 0 0 1 0 0 1 0 1 0 1 0\n",
            " 0 1 1 1 0 1 0 1 1 1 1 1 0 0 1 0 1 1 1 0 0 1 1 0 0 0 1 0 1 0 1 0 0 1 0 0 1\n",
            " 0 1 1 0 0 0 1 1 0 0 1 0 1 0 1 1 0 0 1 0 1 1 0 0 0 1 0 0 1 0 1 1 1 1 0 1 0\n",
            " 1 0 0 0 0 0 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 0 1 0 0 1 0 1 1 1 0 1 0 0\n",
            " 0 0 0 1 0 1 0 1 0 1 1 1 0 0 0 1 0 0 1 1 0 0 1 0 1 1 1 1 1 0 1 1 0 0 1 1 1\n",
            " 0 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 0 1 0 0 1 0 1 1 0 0 0 0 1 0 1 1 1\n",
            " 0 1 1 1 1 1 1 0 0 0 0 1 0 0 0 1 0 0 1 1 0 1 0 1 1 0 1 0 0 1 1 0 1 0 0]\n",
            "probabilities: (812, 2) \n",
            " [1 1 1 0 1 0 0 0 1 1 0 1 0 1 0 0 0 1 1 1 1 1 1 0 0 1 1 0 0 0 1 1 0 0 0 1 1\n",
            " 1 1 0 0 1 1 1 0 1 1 1 0 0 1 1 1 1 0 1 0 1 0 1 1 0 0 1 0 0 1 1 1 0 1 0 0 1\n",
            " 1 1 0 0 0 0 1 0 1 0 1 1 1 0 1 0 0 0 0 0 0 0 0 1 0 1 1 0 0 1 1 0 1 1 1 1 0\n",
            " 1 0 1 1 0 0 1 1 0 1 1 1 0 0 1 0 0 0 1 1 1 1 0 1 1 0 1 0 0 1 1 1 1 1 0 0 0\n",
            " 0 0 0 0 1 1 1 0 0 1 0 0 0 0 0 1 1 0 0 0 0 1 0 1 1 0 1 1 0 1 1 0 0 0 0 0 1\n",
            " 0 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 0 1 1 0 1 1 0 1 1 0 1 0 1 1 1 1 1 1 0 0\n",
            " 1 1 0 1 1 0 0 1 1 1 0 0 0 0 0 1 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 1 1\n",
            " 1 1 1 1 1 1 0 1 0 1 0 0 1 0 0 0 0 1 1 0 1 0 0 1 0 0 1 0 0 1 0 1 0 0 1 1 1\n",
            " 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 0 1 1 0 1 1 1 0 0 1 0 1 0 1 1 1 1 0\n",
            " 1 1 0 1 1 1 1 1 1 0 1 0 1 1 1 1 0 0 0 0 1 1 0 0 0 1 0 0 1 0 0 1 0 0 1 1 1\n",
            " 1 0 1 1 1 1 1 0 1 0 1 1 0 0 0 0 0 0 1 1 1 1 1 0 0 0 1 1 1 0 1 0 1 0 0 0 0\n",
            " 0 0 1 1 0 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 0 0 1 0 1 1 0 0 1 1 0\n",
            " 1 0 1 0 0 1 0 1 0 1 0 1 1 0 1 1 0 1 1 0 1 1 1 1 0 1 1 0 1 1 1 0 0 1 0 1 1\n",
            " 1 1 1 1 0 1 0 0 0 0 1 0 0 0 1 0 1 1 0 1 1 1 0 1 0 0 0 1 0 0 1 0 0 1 0 1 1\n",
            " 1 1 1 0 0 0 1 1 1 1 0 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0\n",
            " 0 1 0 0 1 1 1 0 1 1 1 1 1 1 0 0 1 0 1 1 0 0 1 0 0 1 0 0 1 0 0 1 0 1 0 1 0\n",
            " 0 1 1 1 0 1 0 1 1 1 1 1 0 0 1 0 1 1 1 0 0 1 1 0 0 0 1 0 1 0 1 0 0 1 0 0 1\n",
            " 0 1 1 0 0 0 1 1 0 0 1 0 1 0 1 1 0 0 1 0 1 1 0 0 0 1 0 0 1 0 1 1 1 1 0 1 0\n",
            " 1 0 0 0 0 0 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 0 1 0 0 1 0 1 1 1 0 1 0 0\n",
            " 0 0 0 1 0 1 0 1 0 1 1 1 0 0 0 1 0 0 1 1 0 0 1 0 1 1 1 1 1 0 1 1 0 0 1 1 1\n",
            " 0 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 0 1 0 0 1 0 1 1 0 0 0 0 1 0 1 1 1\n",
            " 0 1 1 1 1 1 1 0 0 0 0 1 0 0 0 1 0 0 1 1 0 1 0 1 1 0 1 0 0 1 1 0 1 0 0]\n",
            "std (812,) [37.27077032 41.5685122  38.54480381 42.66161096 44.49387252 33.36471757\n",
            " 49.12988388 48.69017065 47.52128965 48.75126781 47.14949532 40.04948878\n",
            " 35.93970833 34.73868367 45.25655023 36.41334782 37.23823354 47.32364647\n",
            " 42.72468025 46.79154873 47.41218862 46.51451478 42.82776434 34.26643214\n",
            " 46.54416982 47.22654839 38.55302357 49.42421063 49.58267126 33.51993704\n",
            " 38.34712325 30.06724179 40.95210467 48.30640421 40.76555877 40.82178625\n",
            " 43.83018422 42.76168038 47.47740425 43.77210241 47.42384642 48.99280189\n",
            " 48.63209397 44.78720169 46.19612682 47.226218   34.71109025 46.75755275\n",
            " 43.15848854 49.19465332 42.35346326 46.65574001 43.76627396 44.06863787\n",
            " 48.90545778 46.8454165  38.45819895 46.39849018 49.13758735 46.9490669\n",
            " 38.77481721 32.44037666 45.8644063  47.52032314 48.7323415  43.46489766\n",
            " 44.42032406 46.79234176 42.68402838 43.12898843 47.37970835 49.04984677\n",
            " 35.93970833 45.61985833 38.03006633 42.65274399 47.47591279 46.84713682\n",
            " 49.2568331  49.06819316 47.23682088 48.27579555 47.79625495 48.58248157\n",
            " 46.0074825  37.26091604 48.513472   45.47863498 46.46594735 47.94158706\n",
            " 49.35727728 49.13689042 45.2607981  48.64317884 46.19158885 36.64250648\n",
            " 35.93970833 47.32709247 49.15806497 45.58956872 44.48713506 48.99643509\n",
            " 48.34215049 44.83787375 34.35937889 41.52727567 26.91022499 43.04110152\n",
            " 36.96276712 43.59792459 36.42730382 46.50341744 41.99647377 47.18257835\n",
            " 46.57674004 45.03052619 35.93970833 48.95961562 43.83088498 48.86668143\n",
            " 46.26617902 46.43791516 44.22505387 41.85951346 44.33306354 42.0394802\n",
            " 30.83557602 48.76993    38.67854221 47.17769588 43.21335657 46.48273486\n",
            " 31.2348504  41.72260149 29.07181467 36.79186208 49.26449929 37.6888357\n",
            " 49.37381384 35.93970833 38.26072563 39.93367561 41.893399   46.04378484\n",
            " 46.80690222 47.40556479 46.96527384 22.81983387 43.78377568 38.12528435\n",
            " 45.57674028 34.00188336 45.83156469 47.44734601 46.39124057 38.48979844\n",
            " 38.85254635 42.41122126 46.3820558  44.18052762 49.4891519  46.00502407\n",
            " 48.99149776 47.84133906 32.09087717 46.63802064 49.25764691 49.48991078\n",
            " 35.93970833 42.62697634 47.47196251 45.95654527 29.08548663 47.20259885\n",
            " 48.20181912 39.82167937 47.11940413 40.18553773 47.8700408  38.65633428\n",
            " 34.5913638  49.40657139 41.11111422 45.87276564 48.16771505 45.5050464\n",
            " 42.27517915 42.89123401 43.7050351  43.08281677 39.693444   47.52612439\n",
            " 43.89549293 45.67447338 46.29546546 42.45602688 46.68274185 48.43963306\n",
            " 46.25002049 41.55510926 45.96475051 44.00043323 46.16338909 38.14572271\n",
            " 47.99796177 49.15510112 49.01693709 43.49414275 44.70425467 47.49058371\n",
            " 46.20018878 48.37787954 42.85954659 34.5705634  48.61733828 45.40850385\n",
            " 39.52923113 34.43394402 47.96294133 41.3737984  49.15255088 48.44219731\n",
            " 46.80136042 40.66100097 48.32731872 41.40018023 46.6242459  39.97469703\n",
            " 42.90585862 46.16023572 46.22095232 47.70116325 32.67577145 35.93970833\n",
            " 48.9352066  35.93970833 42.02858878 47.57085836 35.93970833 47.43057927\n",
            " 47.79317364 41.41530814 49.14339634 43.91786861 47.0862386  46.51844634\n",
            " 48.566741   43.94376974 40.00089201 42.61084213 33.12229573 49.32711537\n",
            " 49.29814289 47.90593711 45.73687098 39.58988459 46.39735565 43.63556986\n",
            " 44.93044738 46.34132833 44.35027504 45.38573427 46.38536577 45.86463023\n",
            " 41.37405436 49.13758735 46.44486957 29.39767258 47.60041988 46.37630122\n",
            " 33.74764634 40.61759995 49.2616769  43.35191403 40.28331005 27.96818061\n",
            " 37.75937787 43.11026943 49.10014453 49.29235527 37.55987707 49.2274977\n",
            " 45.42835839 35.93970833 41.42434098 47.57938209 45.64481643 47.87764708\n",
            " 46.01492273 28.25879912 46.37893538 48.41024802 46.47136134 43.58167717\n",
            " 46.08305107 45.13550331 36.8604604  46.50961624 37.82880784 38.30783551\n",
            " 48.09889241 43.30240091 45.39458754 47.11028685 42.93892614 39.90194546\n",
            " 47.31490489 42.23751794 47.10867923 47.60052915 46.56249683 48.22374252\n",
            " 41.29922925 49.29875577 47.8327671  47.88631118 35.71007898 31.17406576\n",
            " 48.75930551 43.71476925 46.53332269 46.63409685 35.93970833 35.93970833\n",
            " 46.62246569 45.16162506 46.30379371 48.98252242 46.78179201 42.76565221\n",
            " 45.64660211 45.31702432 47.46317378 35.62453757 43.85667614 45.05698249\n",
            " 43.15692105 45.23680509 47.32446921 47.22700149 43.89155824 45.82982632\n",
            " 49.34952073 45.35152665 47.81297668 48.28109637 45.71885112 33.41227009\n",
            " 45.77769954 49.29280873 44.17608471 38.26945589 39.2911308  45.21802479\n",
            " 45.58726357 48.40271134 39.32819116 35.93970833 44.3844838  45.85439432\n",
            " 41.68753111 35.56058987 33.01390046 47.16949762 47.73312355 44.92337678\n",
            " 38.38676925 44.84553997 41.82639552 33.41227009 46.74458531 42.78793502\n",
            " 45.22659152 45.13982131 46.876258   47.36915254 40.31728571 47.84307339\n",
            " 45.68851875 49.02754575 47.20202954 44.8859655  45.75752021 43.68006006\n",
            " 49.05157412 45.51940553 49.32652394 29.86680049 43.08832391 45.17923483\n",
            " 41.61463537 47.4948929  46.73999297 48.54018924 49.48136804 47.51281391\n",
            " 42.40745709 43.29087024 48.73305174 49.1895489  45.2874938  48.89306684\n",
            " 43.45281524 46.38939823 38.90627941 44.69116033 35.93970833 36.60582043\n",
            " 48.4784939  43.67189682 48.86696731 35.93970833 43.66797024 38.89645544\n",
            " 47.55771381 33.5569774  48.93290485 48.89438627 36.71599225 46.27884601\n",
            " 42.7644074  45.03274322 37.82632941 47.20150319 40.95644639 36.21722416\n",
            " 41.85979352 41.95578243 45.57516843 45.2743633  49.49001892 42.65015593\n",
            " 48.28409096 41.08737557 46.54152577 47.84954692 40.38483599 47.79577981\n",
            " 47.73923145 35.93970833 35.93970833 39.64633457 42.77929764 44.17403646\n",
            " 45.70684698 38.43069261 47.16040126 47.3441948  46.94623538 47.23812933\n",
            " 37.55437338 46.36655172 46.16436123 49.02538697 47.12418187 48.26220896\n",
            " 41.55639479 45.5075211  41.4123071  36.8604604  47.56847278 44.00168427\n",
            " 44.34262086 49.30470926 46.93231747 44.90165006 37.55058891 46.57235634\n",
            " 39.35423294 45.42298629 45.2743633  44.40406762 39.20572614 47.6422359\n",
            " 48.81953778 49.42940531 45.12759859 44.05045625 47.61358653 48.22893075\n",
            " 39.02037503 47.64950088 43.28709233 28.54447556 47.94831594 38.01417991\n",
            " 42.62918749 49.27947763 45.95554402 45.23356483 43.85544247 46.72568036\n",
            " 33.99660957 48.75828332 42.84826372 46.569487   46.82719385 46.48320924\n",
            " 45.29632779 39.80555816 47.71082319 45.27182934 47.75616306 38.48190837\n",
            " 40.50486103 48.86260373 38.82609816 49.13815209 33.44521182 45.67503243\n",
            " 44.4470053  43.7979674  37.11363482 46.08460643 42.75401074 40.37253127\n",
            " 34.61518042 45.07450206 45.83812249 45.88031013 37.97686919 44.5026564\n",
            " 45.78477142 30.14804118 44.21575926 43.19764796 39.6736269  34.39770973\n",
            " 49.13007802 47.14439501 38.17677667 46.68321018 41.22290136 39.98263458\n",
            " 46.94671441 48.12174803 49.02296038 48.79743221 39.90784164 35.156393\n",
            " 48.02946413 46.46578359 46.15131461 44.43394613 47.95671691 35.61465088\n",
            " 36.12826908 47.16365104 39.25952312 48.75953478 47.86300201 37.3372211\n",
            " 47.46551072 35.85262838 49.43987101 39.21858339 46.34132833 49.19836195\n",
            " 48.32445164 46.56272191 48.62036629 47.40944599 38.47432296 44.51083088\n",
            " 43.40616974 40.50293192 40.17106123 48.23892708 37.6725972  43.73468451\n",
            " 35.93970833 44.88991467 48.67219427 45.89428088 40.26817616 35.93970833\n",
            " 35.93970833 45.76869851 33.32806857 48.63898691 47.59647666 46.4810966\n",
            " 39.17254288 42.25660429 48.19991113 48.76485484 46.55911954 43.74709231\n",
            " 47.68054537 31.64265885 47.60133859 36.82768762 47.79589711 38.36293852\n",
            " 46.01307773 39.27546373 47.93247619 48.62858334 47.06505403 36.85761264\n",
            " 47.72992712 37.85175344 47.68990796 44.96325838 49.07323065 49.01108617\n",
            " 48.82747027 49.21879111 44.02793376 44.9535859  45.43656075 49.39656459\n",
            " 49.18211897 46.79935067 42.22191515 43.76773927 49.01269583 46.46405865\n",
            " 45.08748308 49.1694656  42.74739637 42.70028251 45.75135422 44.649447\n",
            " 47.10194631 46.99952918 48.59631413 48.66985228 45.35070325 39.26454009\n",
            " 33.16385004 44.03845334 48.66080029 38.84487292 48.83091141 45.01317647\n",
            " 46.28760597 49.05427406 47.08101331 40.63092412 35.91643194 32.00810511\n",
            " 38.63426441 43.08413947 42.28310517 42.65828127 47.03907142 45.33904146\n",
            " 48.37997009 46.98734638 40.63466845 40.60655599 47.04745674 47.66603544\n",
            " 44.7408221  47.36558353 48.78362285 46.08526039 37.88023203 47.20150319\n",
            " 45.90721688 41.86508348 41.29531839 47.74932902 40.35123307 48.46537985\n",
            " 31.66086137 49.41149815 47.88250135 44.66442348 45.49295588 47.56517453\n",
            " 44.62721631 38.69459098 36.64105949 39.89386207 38.8813037  42.77278587\n",
            " 41.33306278 49.40828244 44.1760424  49.09813292 35.90219129 40.71207471\n",
            " 41.31997818 48.34139039 40.56526969 33.22584778 34.92027083 49.21446199\n",
            " 42.75522389 41.00289193 34.30686557 46.33033156 47.84628121 44.94684448\n",
            " 45.15433134 41.74899724 43.01213094 49.4007801  32.06139003 44.3677047\n",
            " 49.1632838  37.5402713  48.98836969 42.88634239 43.47821049 32.29973184\n",
            " 48.80452798 41.45472633 48.64609943 48.42371704 40.89840739 48.5847713\n",
            " 43.7080422  48.90182335 46.12107385 44.62501358 46.85864902 39.25888863\n",
            " 35.93970833 44.75490968 44.51457251 49.06780614 35.93970833 44.86487614\n",
            " 44.99670349 34.73868367 46.55911954 46.56537448 43.44481926 44.67136329\n",
            " 45.36792039 47.23812933 46.80059672 47.73085282 44.48630107 46.2663365\n",
            " 44.19048976 44.47895284 33.13314523 40.63768172 47.29159582 48.16783965\n",
            " 41.69961373 45.4767653  43.36495522 48.8689834  43.21541619 41.74851586\n",
            " 36.68594581 39.02712873 45.85546487 34.67775682 46.92718084 48.08198549\n",
            " 44.78173819 48.94732809 37.37674301 48.58925826 45.50250208 48.14206209\n",
            " 35.93970833 47.17498471 48.11893507 48.91004411 48.65077693 47.33401291\n",
            " 45.32792108 48.38174455 47.59561279 41.29057845 45.5008754  44.43271694\n",
            " 40.9459644  35.02636113 48.68000646 48.50076497 35.27169726 43.60377564\n",
            " 42.37894634 48.99249182 37.82501496 42.42779607 48.91136012 45.28302576\n",
            " 24.7278052  49.05218013 47.81699392 42.66154287 47.53780898 44.70711649\n",
            " 40.99799863 34.30589324 34.99054691 37.88769967 47.64726752 46.56478604\n",
            " 38.88895532 35.93970833 47.19612952 43.63608247 35.93970833 39.53707943\n",
            " 49.58010875 46.90298447 48.04766235 40.86838053 47.03301839 44.28317685\n",
            " 37.98379057 47.99510004]\n",
            "selection [147 786 106 275 289 483 134 172 267 387] (10,) [22.81983387 24.7278052  26.91022499 27.96818061 28.25879912 28.54447556\n",
            " 29.07181467 29.08548663 29.39767258 29.86680049]\n",
            "trainset before adding uncertain samples (490, 10) (490,)\n",
            "trainset after adding uncertain samples (500, 10) (500,)\n",
            "updated train set: (500, 10) (500,) unique(labels): [243 257] [0 1]\n",
            "val set: (802, 10) (802,)\n",
            "\n",
            "Train set: (500, 10)\n",
            "Validation set: (802, 10)\n",
            "Test set: (434, 10)\n",
            "training GBDC...\n",
            "--------------------------------\n",
            "Iteration: 50\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 1.356 s \n",
            "\n",
            "Accuracy rate is 81.336406 \n",
            "Classification report for GradientBoostingClassifier(learning_rate=0.01, n_estimators=1200,\n",
            "                           random_state=3, subsample=0.5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.89      0.88       321\n",
            "           1       0.66      0.58      0.62       113\n",
            "\n",
            "    accuracy                           0.81       434\n",
            "   macro avg       0.76      0.74      0.75       434\n",
            "weighted avg       0.81      0.81      0.81       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[287  34]\n",
            " [ 47  66]]\n",
            "--------------------------------\n",
            "final active learning accuracies [73.73271889400922, 77.18894009216591, 77.18894009216591, 76.72811059907833, 71.19815668202764, 76.49769585253456, 77.88018433179722, 78.11059907834101, 77.88018433179722, 77.88018433179722, 79.03225806451613, 79.03225806451613, 79.72350230414746, 78.57142857142857, 79.26267281105991, 79.26267281105991, 75.34562211981567, 73.50230414746544, 74.42396313364056, 73.963133640553, 74.19354838709677, 73.963133640553, 74.19354838709677, 74.42396313364056, 75.80645161290323, 75.80645161290323, 74.88479262672811, 74.65437788018433, 74.65437788018433, 75.34562211981567, 75.80645161290323, 80.87557603686636, 80.18433179723502, 80.64516129032258, 80.87557603686636, 81.10599078341014, 81.5668202764977, 81.5668202764977, 81.10599078341014, 81.33640552995391, 81.5668202764977, 82.7188940092166, 82.25806451612904, 82.25806451612904, 81.79723502304147, 80.4147465437788, 80.87557603686636, 81.10599078341014, 80.87557603686636, 81.33640552995391]\n",
            "saved /Users/wenxuanhuang/Documents/Repo/ML-for-COVID-19-dataset/Results/Active-learning-experiment-20.pkl /Users/wenxuanhuang/Documents/Repo/ML-for-COVID-19-dataset ['Decision_tree.ipynb', 'dec_git.png', 'Logit_default_f10.pdf', 'Logistic.ipynb', 'SVC.ipynb', 'RF_f5e50_featureimp.pdf', 'log_al.png', 'dec_git.pdf', '.DS_Store', 'log_git.png', 'svm_git.png', 'Logistic_Scikit.ipynb', 'knn_git.pdf', 'knn_git.png', 'rf_al.png', 'Best classifier_RF_f5e50.pdf', 'KNN.ipynb', 'GBDC.ipynb', 'rf_git.png', 'README.md', 'all_training.csv', 'Results', 'svm_al.png', 'Log_ROC.png', 'Logit_default_f7(p_removal).pdf', 'Active_learning.ipynb', 'Random_forest.ipynb', 'Model_select.ipynb', 'gdbc_git.png', '.git', '.vscode', 'Untitled', 'RF_f5e50_modelselect.pdf', 'Logit_default_f8(std_removal).pdf']\n",
            "{\n",
            "  \"GDBCModel\": {\n",
            "    \"EntropySelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          65.2073732718894,\n",
            "          76.95852534562212,\n",
            "          75.11520737327189,\n",
            "          70.04608294930875,\n",
            "          72.35023041474655,\n",
            "          71.42857142857143,\n",
            "          77.41935483870968,\n",
            "          76.26728110599078,\n",
            "          77.41935483870968,\n",
            "          77.88018433179722,\n",
            "          78.57142857142857,\n",
            "          73.963133640553,\n",
            "          79.49308755760369,\n",
            "          79.03225806451613,\n",
            "          79.49308755760369,\n",
            "          79.26267281105991,\n",
            "          78.3410138248848,\n",
            "          78.57142857142857,\n",
            "          79.03225806451613,\n",
            "          80.18433179723502,\n",
            "          79.95391705069125,\n",
            "          80.18433179723502,\n",
            "          78.80184331797236,\n",
            "          79.49308755760369,\n",
            "          79.72350230414746,\n",
            "          80.18433179723502,\n",
            "          79.95391705069125,\n",
            "          81.5668202764977,\n",
            "          81.79723502304147,\n",
            "          81.5668202764977,\n",
            "          81.33640552995391,\n",
            "          80.64516129032258,\n",
            "          80.4147465437788,\n",
            "          81.10599078341014,\n",
            "          79.49308755760369,\n",
            "          80.64516129032258,\n",
            "          80.87557603686636,\n",
            "          80.87557603686636,\n",
            "          79.49308755760369,\n",
            "          80.18433179723502,\n",
            "          79.72350230414746,\n",
            "          79.95391705069125,\n",
            "          78.80184331797236,\n",
            "          79.72350230414746,\n",
            "          79.49308755760369,\n",
            "          80.4147465437788,\n",
            "          79.49308755760369,\n",
            "          80.4147465437788,\n",
            "          79.72350230414746,\n",
            "          79.95391705069125\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          77.41935483870968,\n",
            "          79.03225806451613,\n",
            "          80.64516129032258,\n",
            "          80.18433179723502\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          70.04608294930875,\n",
            "          76.49769585253456,\n",
            "          79.03225806451613,\n",
            "          78.57142857142857,\n",
            "          77.64976958525345,\n",
            "          78.80184331797236,\n",
            "          78.80184331797236,\n",
            "          77.41935483870968,\n",
            "          77.88018433179722,\n",
            "          77.64976958525345,\n",
            "          79.03225806451613,\n",
            "          77.88018433179722,\n",
            "          78.80184331797236,\n",
            "          78.80184331797236,\n",
            "          79.26267281105991,\n",
            "          79.72350230414746,\n",
            "          79.03225806451613,\n",
            "          79.72350230414746,\n",
            "          80.4147465437788,\n",
            "          80.87557603686636\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          78.57142857142857,\n",
            "          80.4147465437788\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          75.34562211981567,\n",
            "          80.64516129032258,\n",
            "          79.95391705069125,\n",
            "          79.03225806451613,\n",
            "          80.64516129032258,\n",
            "          80.18433179723502,\n",
            "          79.95391705069125,\n",
            "          79.49308755760369,\n",
            "          79.72350230414746,\n",
            "          79.49308755760369\n",
            "        ]\n",
            "      ]\n",
            "    },\n",
            "    \"MarginSamplingSelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          49.07834101382488,\n",
            "          63.133640552995395,\n",
            "          72.58064516129032,\n",
            "          68.89400921658986,\n",
            "          72.58064516129032,\n",
            "          76.036866359447,\n",
            "          75.34562211981567,\n",
            "          74.19354838709677,\n",
            "          74.65437788018433,\n",
            "          73.73271889400922,\n",
            "          75.11520737327189,\n",
            "          70.50691244239631,\n",
            "          75.57603686635944,\n",
            "          75.34562211981567,\n",
            "          75.11520737327189,\n",
            "          75.80645161290323,\n",
            "          76.72811059907833,\n",
            "          76.49769585253456,\n",
            "          77.41935483870968,\n",
            "          77.18894009216591,\n",
            "          77.41935483870968,\n",
            "          76.95852534562212,\n",
            "          78.80184331797236,\n",
            "          78.3410138248848,\n",
            "          78.57142857142857,\n",
            "          79.72350230414746,\n",
            "          79.72350230414746,\n",
            "          79.26267281105991,\n",
            "          79.49308755760369,\n",
            "          79.49308755760369,\n",
            "          79.26267281105991,\n",
            "          78.57142857142857,\n",
            "          79.03225806451613,\n",
            "          79.49308755760369,\n",
            "          79.95391705069125,\n",
            "          79.95391705069125,\n",
            "          80.18433179723502,\n",
            "          79.95391705069125,\n",
            "          80.64516129032258,\n",
            "          79.49308755760369,\n",
            "          78.57142857142857,\n",
            "          78.80184331797236,\n",
            "          78.57142857142857,\n",
            "          79.03225806451613,\n",
            "          79.26267281105991,\n",
            "          78.57142857142857,\n",
            "          79.26267281105991,\n",
            "          78.80184331797236,\n",
            "          79.26267281105991,\n",
            "          79.49308755760369\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          76.95852534562212,\n",
            "          78.80184331797236,\n",
            "          79.03225806451613,\n",
            "          81.10599078341014\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          74.65437788018433,\n",
            "          69.81566820276498,\n",
            "          80.18433179723502,\n",
            "          72.11981566820278,\n",
            "          72.81105990783409,\n",
            "          73.73271889400922,\n",
            "          73.50230414746544,\n",
            "          78.57142857142857,\n",
            "          78.57142857142857,\n",
            "          81.10599078341014,\n",
            "          80.64516129032258,\n",
            "          78.80184331797236,\n",
            "          79.26267281105991,\n",
            "          80.18433179723502,\n",
            "          79.72350230414746,\n",
            "          79.26267281105991,\n",
            "          79.95391705069125,\n",
            "          79.72350230414746,\n",
            "          79.95391705069125,\n",
            "          79.72350230414746\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          76.26728110599078,\n",
            "          79.26267281105991\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          78.11059907834101,\n",
            "          78.11059907834101,\n",
            "          78.57142857142857,\n",
            "          78.57142857142857,\n",
            "          80.4147465437788,\n",
            "          80.18433179723502,\n",
            "          79.95391705069125,\n",
            "          79.72350230414746,\n",
            "          79.49308755760369,\n",
            "          78.80184331797236\n",
            "        ]\n",
            "      ]\n",
            "    },\n",
            "    \"MinStdSelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          73.73271889400922,\n",
            "          77.18894009216591,\n",
            "          77.18894009216591,\n",
            "          76.72811059907833,\n",
            "          71.19815668202764,\n",
            "          76.49769585253456,\n",
            "          77.88018433179722,\n",
            "          78.11059907834101,\n",
            "          77.88018433179722,\n",
            "          77.88018433179722,\n",
            "          79.03225806451613,\n",
            "          79.03225806451613,\n",
            "          79.72350230414746,\n",
            "          78.57142857142857,\n",
            "          79.26267281105991,\n",
            "          79.26267281105991,\n",
            "          75.34562211981567,\n",
            "          73.50230414746544,\n",
            "          74.42396313364056,\n",
            "          73.963133640553,\n",
            "          74.19354838709677,\n",
            "          73.963133640553,\n",
            "          74.19354838709677,\n",
            "          74.42396313364056,\n",
            "          75.80645161290323,\n",
            "          75.80645161290323,\n",
            "          74.88479262672811,\n",
            "          74.65437788018433,\n",
            "          74.65437788018433,\n",
            "          75.34562211981567,\n",
            "          75.80645161290323,\n",
            "          80.87557603686636,\n",
            "          80.18433179723502,\n",
            "          80.64516129032258,\n",
            "          80.87557603686636,\n",
            "          81.10599078341014,\n",
            "          81.5668202764977,\n",
            "          81.5668202764977,\n",
            "          81.10599078341014,\n",
            "          81.33640552995391,\n",
            "          81.5668202764977,\n",
            "          82.7188940092166,\n",
            "          82.25806451612904,\n",
            "          82.25806451612904,\n",
            "          81.79723502304147,\n",
            "          80.4147465437788,\n",
            "          80.87557603686636,\n",
            "          81.10599078341014,\n",
            "          80.87557603686636,\n",
            "          81.33640552995391\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          78.3410138248848,\n",
            "          76.036866359447,\n",
            "          80.18433179723502,\n",
            "          79.72350230414746\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          77.64976958525345,\n",
            "          77.88018433179722,\n",
            "          73.04147465437788,\n",
            "          74.19354838709677,\n",
            "          80.64516129032258,\n",
            "          80.18433179723502,\n",
            "          79.72350230414746,\n",
            "          80.87557603686636,\n",
            "          81.33640552995391,\n",
            "          80.87557603686636,\n",
            "          79.49308755760369,\n",
            "          80.18433179723502,\n",
            "          80.87557603686636,\n",
            "          80.87557603686636,\n",
            "          80.87557603686636,\n",
            "          80.87557603686636,\n",
            "          81.33640552995391,\n",
            "          81.33640552995391,\n",
            "          80.18433179723502,\n",
            "          80.4147465437788\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          75.11520737327189,\n",
            "          79.26267281105991\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          79.95391705069125,\n",
            "          76.95852534562212,\n",
            "          80.18433179723502,\n",
            "          79.49308755760369,\n",
            "          79.26267281105991,\n",
            "          79.72350230414746,\n",
            "          79.95391705069125,\n",
            "          79.72350230414746,\n",
            "          79.72350230414746,\n",
            "          79.72350230414746\n",
            "        ]\n",
            "      ]\n",
            "    },\n",
            "    \"RandomSelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          63.36405529953917,\n",
            "          70.73732718894009,\n",
            "          61.29032258064516,\n",
            "          63.594470046082954,\n",
            "          74.65437788018433,\n",
            "          75.80645161290323,\n",
            "          76.49769585253456,\n",
            "          76.49769585253456,\n",
            "          77.41935483870968,\n",
            "          76.72811059907833,\n",
            "          78.3410138248848,\n",
            "          78.80184331797236,\n",
            "          77.41935483870968,\n",
            "          79.49308755760369,\n",
            "          77.64976958525345,\n",
            "          76.95852534562212,\n",
            "          77.18894009216591,\n",
            "          76.95852534562212,\n",
            "          77.64976958525345,\n",
            "          78.11059907834101,\n",
            "          78.11059907834101,\n",
            "          77.64976958525345,\n",
            "          77.64976958525345,\n",
            "          78.3410138248848,\n",
            "          78.57142857142857,\n",
            "          77.64976958525345,\n",
            "          77.64976958525345,\n",
            "          77.41935483870968,\n",
            "          77.88018433179722,\n",
            "          77.88018433179722,\n",
            "          77.88018433179722,\n",
            "          78.11059907834101,\n",
            "          77.64976958525345,\n",
            "          78.3410138248848,\n",
            "          78.80184331797236,\n",
            "          79.26267281105991,\n",
            "          78.57142857142857,\n",
            "          77.88018433179722,\n",
            "          77.64976958525345,\n",
            "          77.64976958525345,\n",
            "          78.11059907834101,\n",
            "          79.72350230414746,\n",
            "          79.72350230414746,\n",
            "          79.49308755760369,\n",
            "          79.03225806451613,\n",
            "          79.72350230414746,\n",
            "          78.80184331797236,\n",
            "          78.57142857142857,\n",
            "          79.49308755760369,\n",
            "          79.26267281105991\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          72.58064516129032,\n",
            "          72.58064516129032,\n",
            "          76.036866359447,\n",
            "          76.26728110599078\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          72.35023041474655,\n",
            "          72.11981566820278,\n",
            "          71.88940092165899,\n",
            "          73.04147465437788,\n",
            "          72.81105990783409,\n",
            "          75.11520737327189,\n",
            "          73.50230414746544,\n",
            "          76.036866359447,\n",
            "          76.26728110599078,\n",
            "          76.49769585253456,\n",
            "          76.72811059907833,\n",
            "          77.18894009216591,\n",
            "          76.72811059907833,\n",
            "          78.11059907834101,\n",
            "          78.3410138248848,\n",
            "          77.64976958525345,\n",
            "          79.72350230414746,\n",
            "          79.95391705069125,\n",
            "          80.18433179723502,\n",
            "          80.87557603686636\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          78.3410138248848,\n",
            "          79.95391705069125\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          69.35483870967742,\n",
            "          76.72811059907833,\n",
            "          78.3410138248848,\n",
            "          78.57142857142857,\n",
            "          78.80184331797236,\n",
            "          79.95391705069125,\n",
            "          79.26267281105991,\n",
            "          79.03225806451613,\n",
            "          79.03225806451613,\n",
            "          78.80184331797236\n",
            "        ]\n",
            "      ]\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "---------------------------- FINISHED ---------------------------\n",
            "\n",
            "Count = 21, using model = KnnModel, selection_function = RandomSelection, k = 250, iteration = 0.\n",
            "\n",
            "initial random chosen samples (250,)\n",
            "initial train set: (250, 10) (250,) unique(labels): [118 132] [0 1]\n",
            "Val set: (1052, 10) (1052,) (250,)\n",
            "\n",
            "Train set: (250, 10)\n",
            "Validation set: (1052, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.067 s \n",
            "\n",
            "Accuracy rate is 76.036866 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.85      0.84       321\n",
            "           1       0.54      0.50      0.52       113\n",
            "\n",
            "    accuracy                           0.76       434\n",
            "   macro avg       0.69      0.68      0.68       434\n",
            "weighted avg       0.76      0.76      0.76       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[273  48]\n",
            " [ 56  57]]\n",
            "--------------------------------\n",
            "val predicted: (1052,) [0 1 0 ... 0 0 0]\n",
            "probabilities: (1052, 2) \n",
            " [0 1 0 ... 0 0 0]\n",
            "uniques chosen: 250 <= should be equal to: 250\n",
            "trainset before adding uncertain samples (250, 10) (250,)\n",
            "trainset after adding uncertain samples (500, 10) (500,)\n",
            "updated train set: (500, 10) (500,) unique(labels): [226 274] [0 1]\n",
            "val set: (802, 10) (802,)\n",
            "\n",
            "Train set: (500, 10)\n",
            "Validation set: (802, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.055 s \n",
            "\n",
            "Accuracy rate is 77.649770 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.87      0.85       321\n",
            "           1       0.58      0.50      0.54       113\n",
            "\n",
            "    accuracy                           0.78       434\n",
            "   macro avg       0.71      0.69      0.70       434\n",
            "weighted avg       0.77      0.78      0.77       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[280  41]\n",
            " [ 56  57]]\n",
            "--------------------------------\n",
            "final active learning accuracies [76.036866359447, 77.64976958525345]\n",
            "saved /Users/wenxuanhuang/Documents/Repo/ML-for-COVID-19-dataset/Results/Active-learning-experiment-21.pkl /Users/wenxuanhuang/Documents/Repo/ML-for-COVID-19-dataset ['Decision_tree.ipynb', 'dec_git.png', 'Logit_default_f10.pdf', 'Logistic.ipynb', 'SVC.ipynb', 'RF_f5e50_featureimp.pdf', 'log_al.png', 'dec_git.pdf', '.DS_Store', 'log_git.png', 'svm_git.png', 'Logistic_Scikit.ipynb', 'knn_git.pdf', 'knn_git.png', 'rf_al.png', 'Best classifier_RF_f5e50.pdf', 'KNN.ipynb', 'GBDC.ipynb', 'rf_git.png', 'README.md', 'all_training.csv', 'Results', 'svm_al.png', 'Log_ROC.png', 'Logit_default_f7(p_removal).pdf', 'Active_learning.ipynb', 'Random_forest.ipynb', 'Model_select.ipynb', 'gdbc_git.png', '.git', '.vscode', 'Untitled', 'RF_f5e50_modelselect.pdf', 'Logit_default_f8(std_removal).pdf']\n",
            "\n",
            "---------------------------- FINISHED ---------------------------\n",
            "\n",
            "Count = 22, using model = KnnModel, selection_function = RandomSelection, k = 125, iteration = 0.\n",
            "\n",
            "initial random chosen samples (125,)\n",
            "initial train set: (125, 10) (125,) unique(labels): [56 69] [0 1]\n",
            "Val set: (1177, 10) (1177,) (125,)\n",
            "\n",
            "Train set: (125, 10)\n",
            "Validation set: (1177, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.075 s \n",
            "\n",
            "Accuracy rate is 76.036866 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.83      0.84       321\n",
            "           1       0.54      0.55      0.54       113\n",
            "\n",
            "    accuracy                           0.76       434\n",
            "   macro avg       0.69      0.69      0.69       434\n",
            "weighted avg       0.76      0.76      0.76       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[268  53]\n",
            " [ 51  62]]\n",
            "--------------------------------\n",
            "val predicted: (1177,) [0 1 1 ... 0 0 1]\n",
            "probabilities: (1177, 2) \n",
            " [0 1 1 ... 0 0 1]\n",
            "uniques chosen: 125 <= should be equal to: 125\n",
            "trainset before adding uncertain samples (125, 10) (125,)\n",
            "trainset after adding uncertain samples (250, 10) (250,)\n",
            "updated train set: (250, 10) (250,) unique(labels): [121 129] [0 1]\n",
            "val set: (1052, 10) (1052,)\n",
            "\n",
            "Train set: (250, 10)\n",
            "Validation set: (1052, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.068 s \n",
            "\n",
            "Accuracy rate is 77.188940 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.86      0.85       321\n",
            "           1       0.57      0.52      0.54       113\n",
            "\n",
            "    accuracy                           0.77       434\n",
            "   macro avg       0.70      0.69      0.70       434\n",
            "weighted avg       0.77      0.77      0.77       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[276  45]\n",
            " [ 54  59]]\n",
            "--------------------------------\n",
            "val predicted: (1052,) [0 1 0 ... 0 0 1]\n",
            "probabilities: (1052, 2) \n",
            " [0 1 0 ... 0 0 1]\n",
            "uniques chosen: 125 <= should be equal to: 125\n",
            "trainset before adding uncertain samples (250, 10) (250,)\n",
            "trainset after adding uncertain samples (375, 10) (375,)\n",
            "updated train set: (375, 10) (375,) unique(labels): [174 201] [0 1]\n",
            "val set: (927, 10) (927,)\n",
            "\n",
            "Train set: (375, 10)\n",
            "Validation set: (927, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 3\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.067 s \n",
            "\n",
            "Accuracy rate is 78.110599 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.87      0.85       321\n",
            "           1       0.59      0.53      0.56       113\n",
            "\n",
            "    accuracy                           0.78       434\n",
            "   macro avg       0.71      0.70      0.71       434\n",
            "weighted avg       0.77      0.78      0.78       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[279  42]\n",
            " [ 53  60]]\n",
            "--------------------------------\n",
            "val predicted: (927,) [0 1 0 0 1 0 0 1 1 0 0 0 0 1 1 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 0 1 0 0 0 1\n",
            " 1 1 1 0 0 0 1 1 1 1 1 0 0 0 1 1 0 1 1 1 1 1 1 1 0 0 0 1 0 1 0 0 0 1 0 0 0\n",
            " 0 1 1 1 1 1 0 0 0 1 1 0 0 0 0 0 0 1 0 1 1 1 0 1 0 1 1 0 0 0 0 0 0 1 0 1 1\n",
            " 1 0 0 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 0 1 1 0 0 1 1 0 1 0 1 0 1 0 0 0 0 0 1\n",
            " 1 1 0 1 1 1 1 0 1 1 1 0 1 0 1 0 0 0 1 0 0 1 0 0 1 1 1 1 0 0 0 0 0 1 1 0 1\n",
            " 1 0 1 1 0 1 1 1 1 0 0 1 1 1 0 1 0 1 0 1 1 1 1 1 1 1 1 0 1 1 0 1 1 0 1 1 0\n",
            " 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 0 1 1 0 1 0 0 1 1 1 1 0 0 0 0 1 0 1 0 1\n",
            " 1 0 0 0 0 1 0 1 0 1 0 0 0 1 0 0 0 0 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0 1 1 0 0\n",
            " 0 1 1 1 0 0 1 1 1 1 0 0 0 1 0 0 1 0 1 1 1 0 0 1 1 1 1 0 1 1 0 1 1 1 0 1 0\n",
            " 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 0 0 1 1 0 1 0 1 1 0 0 1 0 1 0 0 1 0 1 1 1\n",
            " 1 0 1 0 1 0 1 0 0 1 0 1 0 1 1 1 1 0 1 0 1 0 1 1 0 0 0 1 1 0 0 1 0 0 1 0 0\n",
            " 0 0 0 1 0 0 0 0 1 1 1 1 0 0 1 0 1 1 1 1 1 0 1 1 1 0 0 1 0 0 0 1 1 1 1 1 1\n",
            " 1 0 1 1 0 0 0 0 1 0 0 1 0 1 1 0 1 0 1 0 0 1 1 1 1 0 0 1 0 1 0 1 1 1 1 0 1\n",
            " 1 0 0 1 0 1 1 1 1 1 1 0 1 1 0 1 0 1 0 1 0 0 0 1 0 1 0 1 0 1 1 0 0 0 1 1 1\n",
            " 1 1 1 1 1 0 0 0 1 1 1 1 0 1 1 1 0 1 0 0 0 0 0 1 1 1 0 0 1 0 1 0 1 1 1 1 0\n",
            " 1 1 1 0 1 0 1 1 0 1 0 0 1 0 1 0 0 0 1 0 1 1 1 1 0 1 0 0 0 1 1 1 1 1 0 1 1\n",
            " 1 0 0 1 1 1 0 1 0 1 1 1 1 1 0 1 0 1 1 1 1 1 0 1 0 0 1 1 0 0 1 1 0 1 0 1 1\n",
            " 1 1 0 0 0 0 0 0 1 1 0 0 1 0 1 1 1 0 0 0 1 0 0 0 1 0 1 0 1 1 1 0 1 1 1 0 0\n",
            " 1 1 1 1 0 0 0 1 0 1 0 0 1 0 0 1 1 1 1 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 1 0\n",
            " 1 0 1 0 0 1 0 1 0 0 1 0 1 0 0 0 1 1 0 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 0 0 0\n",
            " 1 0 1 0 1 1 1 1 0 1 0 0 1 0 1 0 0 0 1 0 1 1 1 1 1 1 1 0 1 0 0 1 0 0 1 1 1\n",
            " 1 1 1 0 0 0 1 0 0 1 1 1 1 0 1 1 0 1 0 0 0 0 0 0 1 0 1 0 0 1 1 1 0 1 1 1 0\n",
            " 1 1 1 1 0 0 1 1 0 0 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 0 1 0 1 1 0 0 1\n",
            " 1 1 1 1 1 0 1 0 1 1 0 1 0 0 0 1 1 0 0 0 0 0 0 1 1 0 0 0 1 1 1 1 0 0 1 1 0\n",
            " 0 0 0 0 0 1 1 0 1 0 1 1 0 1 1 0 1 1 0 1 0 0 1 1 1 1 1 0 1 1 0 1 0 1 1 1 0\n",
            " 0 1]\n",
            "probabilities: (927, 2) \n",
            " [0 1 0 0 1 0 0 1 1 0 0 0 0 1 1 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 0 1 0 0 0 1\n",
            " 1 1 1 0 0 0 1 1 1 1 1 0 0 0 1 1 0 1 1 1 1 1 1 1 0 0 0 1 0 1 0 0 0 1 0 0 0\n",
            " 0 1 1 1 1 1 0 0 0 1 1 0 0 0 0 0 0 1 0 1 1 1 0 1 0 1 1 0 0 0 0 0 0 1 0 1 1\n",
            " 1 0 0 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 0 1 1 0 0 1 1 0 1 0 1 0 1 0 0 0 0 0 1\n",
            " 1 1 0 1 1 1 1 0 1 1 1 0 1 0 1 0 0 0 1 0 0 1 0 0 1 1 1 1 0 0 0 0 0 1 1 0 1\n",
            " 1 0 1 1 0 1 1 1 1 0 0 1 1 1 0 1 0 1 0 1 1 1 1 1 1 1 1 0 1 1 0 1 1 0 1 1 0\n",
            " 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 0 1 1 0 1 0 0 1 1 1 1 0 0 0 0 1 0 1 0 1\n",
            " 1 0 0 0 0 1 0 1 0 1 0 0 0 1 0 0 0 0 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0 1 1 0 0\n",
            " 0 1 1 1 0 0 1 1 1 1 0 0 0 1 0 0 1 0 1 1 1 0 0 1 1 1 1 0 1 1 0 1 1 1 0 1 0\n",
            " 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 0 0 1 1 0 1 0 1 1 0 0 1 0 1 0 0 1 0 1 1 1\n",
            " 1 0 1 0 1 0 1 0 0 1 0 1 0 1 1 1 1 0 1 0 1 0 1 1 0 0 0 1 1 0 0 1 0 0 1 0 0\n",
            " 0 0 0 1 0 0 0 0 1 1 1 1 0 0 1 0 1 1 1 1 1 0 1 1 1 0 0 1 0 0 0 1 1 1 1 1 1\n",
            " 1 0 1 1 0 0 0 0 1 0 0 1 0 1 1 0 1 0 1 0 0 1 1 1 1 0 0 1 0 1 0 1 1 1 1 0 1\n",
            " 1 0 0 1 0 1 1 1 1 1 1 0 1 1 0 1 0 1 0 1 0 0 0 1 0 1 0 1 0 1 1 0 0 0 1 1 1\n",
            " 1 1 1 1 1 0 0 0 1 1 1 1 0 1 1 1 0 1 0 0 0 0 0 1 1 1 0 0 1 0 1 0 1 1 1 1 0\n",
            " 1 1 1 0 1 0 1 1 0 1 0 0 1 0 1 0 0 0 1 0 1 1 1 1 0 1 0 0 0 1 1 1 1 1 0 1 1\n",
            " 1 0 0 1 1 1 0 1 0 1 1 1 1 1 0 1 0 1 1 1 1 1 0 1 0 0 1 1 0 0 1 1 0 1 0 1 1\n",
            " 1 1 0 0 0 0 0 0 1 1 0 0 1 0 1 1 1 0 0 0 1 0 0 0 1 0 1 0 1 1 1 0 1 1 1 0 0\n",
            " 1 1 1 1 0 0 0 1 0 1 0 0 1 0 0 1 1 1 1 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 1 0\n",
            " 1 0 1 0 0 1 0 1 0 0 1 0 1 0 0 0 1 1 0 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 0 0 0\n",
            " 1 0 1 0 1 1 1 1 0 1 0 0 1 0 1 0 0 0 1 0 1 1 1 1 1 1 1 0 1 0 0 1 0 0 1 1 1\n",
            " 1 1 1 0 0 0 1 0 0 1 1 1 1 0 1 1 0 1 0 0 0 0 0 0 1 0 1 0 0 1 1 1 0 1 1 1 0\n",
            " 1 1 1 1 0 0 1 1 0 0 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 0 1 0 1 1 0 0 1\n",
            " 1 1 1 1 1 0 1 0 1 1 0 1 0 0 0 1 1 0 0 0 0 0 0 1 1 0 0 0 1 1 1 1 0 0 1 1 0\n",
            " 0 0 0 0 0 1 1 0 1 0 1 1 0 1 1 0 1 1 0 1 0 0 1 1 1 1 1 0 1 1 0 1 0 1 1 1 0\n",
            " 0 1]\n",
            "uniques chosen: 125 <= should be equal to: 125\n",
            "trainset before adding uncertain samples (375, 10) (375,)\n",
            "trainset after adding uncertain samples (500, 10) (500,)\n",
            "updated train set: (500, 10) (500,) unique(labels): [221 279] [0 1]\n",
            "val set: (802, 10) (802,)\n",
            "\n",
            "Train set: (500, 10)\n",
            "Validation set: (802, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 4\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.071 s \n",
            "\n",
            "Accuracy rate is 78.341014 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.86      0.85       321\n",
            "           1       0.59      0.58      0.58       113\n",
            "\n",
            "    accuracy                           0.78       434\n",
            "   macro avg       0.72      0.72      0.72       434\n",
            "weighted avg       0.78      0.78      0.78       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[275  46]\n",
            " [ 48  65]]\n",
            "--------------------------------\n",
            "final active learning accuracies [76.036866359447, 77.18894009216591, 78.11059907834101, 78.3410138248848]\n",
            "saved /Users/wenxuanhuang/Documents/Repo/ML-for-COVID-19-dataset/Results/Active-learning-experiment-22.pkl /Users/wenxuanhuang/Documents/Repo/ML-for-COVID-19-dataset ['Decision_tree.ipynb', 'dec_git.png', 'Logit_default_f10.pdf', 'Logistic.ipynb', 'SVC.ipynb', 'RF_f5e50_featureimp.pdf', 'log_al.png', 'dec_git.pdf', '.DS_Store', 'log_git.png', 'svm_git.png', 'Logistic_Scikit.ipynb', 'knn_git.pdf', 'knn_git.png', 'rf_al.png', 'Best classifier_RF_f5e50.pdf', 'KNN.ipynb', 'GBDC.ipynb', 'rf_git.png', 'README.md', 'all_training.csv', 'Results', 'svm_al.png', 'Log_ROC.png', 'Logit_default_f7(p_removal).pdf', 'Active_learning.ipynb', 'Random_forest.ipynb', 'Model_select.ipynb', 'gdbc_git.png', '.git', '.vscode', 'Untitled', 'RF_f5e50_modelselect.pdf', 'Logit_default_f8(std_removal).pdf']\n",
            "\n",
            "---------------------------- FINISHED ---------------------------\n",
            "\n",
            "Count = 23, using model = KnnModel, selection_function = RandomSelection, k = 50, iteration = 0.\n",
            "\n",
            "initial random chosen samples (50,)\n",
            "initial train set: (50, 10) (50,) unique(labels): [29 21] [0 1]\n",
            "Val set: (1252, 10) (1252,) (50,)\n",
            "\n",
            "Train set: (50, 10)\n",
            "Validation set: (1252, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.064 s \n",
            "\n",
            "Accuracy rate is 78.110599 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.97      0.87       321\n",
            "           1       0.74      0.25      0.37       113\n",
            "\n",
            "    accuracy                           0.78       434\n",
            "   macro avg       0.76      0.61      0.62       434\n",
            "weighted avg       0.77      0.78      0.74       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[311  10]\n",
            " [ 85  28]]\n",
            "--------------------------------\n",
            "val predicted: (1252,) [0 1 0 ... 0 0 0]\n",
            "probabilities: (1252, 2) \n",
            " [0 1 0 ... 0 0 0]\n",
            "uniques chosen: 50 <= should be equal to: 50\n",
            "trainset before adding uncertain samples (50, 10) (50,)\n",
            "trainset after adding uncertain samples (100, 10) (100,)\n",
            "updated train set: (100, 10) (100,) unique(labels): [51 49] [0 1]\n",
            "val set: (1202, 10) (1202,)\n",
            "\n",
            "Train set: (100, 10)\n",
            "Validation set: (1202, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.073 s \n",
            "\n",
            "Accuracy rate is 77.880184 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.88      0.86       321\n",
            "           1       0.59      0.48      0.53       113\n",
            "\n",
            "    accuracy                           0.78       434\n",
            "   macro avg       0.71      0.68      0.69       434\n",
            "weighted avg       0.77      0.78      0.77       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[284  37]\n",
            " [ 59  54]]\n",
            "--------------------------------\n",
            "val predicted: (1202,) [0 1 0 ... 0 0 0]\n",
            "probabilities: (1202, 2) \n",
            " [0 1 0 ... 0 0 0]\n",
            "uniques chosen: 50 <= should be equal to: 50\n",
            "trainset before adding uncertain samples (100, 10) (100,)\n",
            "trainset after adding uncertain samples (150, 10) (150,)\n",
            "updated train set: (150, 10) (150,) unique(labels): [77 73] [0 1]\n",
            "val set: (1152, 10) (1152,)\n",
            "\n",
            "Train set: (150, 10)\n",
            "Validation set: (1152, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 3\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.069 s \n",
            "\n",
            "Accuracy rate is 76.958525 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.88      0.85       321\n",
            "           1       0.57      0.47      0.51       113\n",
            "\n",
            "    accuracy                           0.77       434\n",
            "   macro avg       0.70      0.67      0.68       434\n",
            "weighted avg       0.76      0.77      0.76       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[281  40]\n",
            " [ 60  53]]\n",
            "--------------------------------\n",
            "val predicted: (1152,) [0 1 0 ... 0 0 0]\n",
            "probabilities: (1152, 2) \n",
            " [0 1 0 ... 0 0 0]\n",
            "uniques chosen: 50 <= should be equal to: 50\n",
            "trainset before adding uncertain samples (150, 10) (150,)\n",
            "trainset after adding uncertain samples (200, 10) (200,)\n",
            "updated train set: (200, 10) (200,) unique(labels): [101  99] [0 1]\n",
            "val set: (1102, 10) (1102,)\n",
            "\n",
            "Train set: (200, 10)\n",
            "Validation set: (1102, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 4\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.077 s \n",
            "\n",
            "Accuracy rate is 77.188940 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.87      0.85       321\n",
            "           1       0.57      0.49      0.53       113\n",
            "\n",
            "    accuracy                           0.77       434\n",
            "   macro avg       0.70      0.68      0.69       434\n",
            "weighted avg       0.76      0.77      0.77       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[280  41]\n",
            " [ 58  55]]\n",
            "--------------------------------\n",
            "val predicted: (1102,) [0 1 0 ... 0 0 0]\n",
            "probabilities: (1102, 2) \n",
            " [0 1 0 ... 0 0 0]\n",
            "uniques chosen: 50 <= should be equal to: 50\n",
            "trainset before adding uncertain samples (200, 10) (200,)\n",
            "trainset after adding uncertain samples (250, 10) (250,)\n",
            "updated train set: (250, 10) (250,) unique(labels): [125 125] [0 1]\n",
            "val set: (1052, 10) (1052,)\n",
            "\n",
            "Train set: (250, 10)\n",
            "Validation set: (1052, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 5\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.079 s \n",
            "\n",
            "Accuracy rate is 76.497696 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.87      0.85       321\n",
            "           1       0.56      0.46      0.50       113\n",
            "\n",
            "    accuracy                           0.76       434\n",
            "   macro avg       0.69      0.67      0.68       434\n",
            "weighted avg       0.75      0.76      0.76       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[280  41]\n",
            " [ 61  52]]\n",
            "--------------------------------\n",
            "val predicted: (1052,) [0 1 0 ... 0 0 0]\n",
            "probabilities: (1052, 2) \n",
            " [0 1 0 ... 0 0 0]\n",
            "uniques chosen: 50 <= should be equal to: 50\n",
            "trainset before adding uncertain samples (250, 10) (250,)\n",
            "trainset after adding uncertain samples (300, 10) (300,)\n",
            "updated train set: (300, 10) (300,) unique(labels): [152 148] [0 1]\n",
            "val set: (1002, 10) (1002,)\n",
            "\n",
            "Train set: (300, 10)\n",
            "Validation set: (1002, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 6\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.076 s \n",
            "\n",
            "Accuracy rate is 76.958525 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.88      0.85       321\n",
            "           1       0.57      0.47      0.51       113\n",
            "\n",
            "    accuracy                           0.77       434\n",
            "   macro avg       0.70      0.67      0.68       434\n",
            "weighted avg       0.76      0.77      0.76       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[281  40]\n",
            " [ 60  53]]\n",
            "--------------------------------\n",
            "val predicted: (1002,) [0 1 0 ... 0 0 1]\n",
            "probabilities: (1002, 2) \n",
            " [0 1 0 ... 0 0 1]\n",
            "uniques chosen: 50 <= should be equal to: 50\n",
            "trainset before adding uncertain samples (300, 10) (300,)\n",
            "trainset after adding uncertain samples (350, 10) (350,)\n",
            "updated train set: (350, 10) (350,) unique(labels): [179 171] [0 1]\n",
            "val set: (952, 10) (952,)\n",
            "\n",
            "Train set: (350, 10)\n",
            "Validation set: (952, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 7\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.084 s \n",
            "\n",
            "Accuracy rate is 76.958525 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.87      0.85       321\n",
            "           1       0.57      0.49      0.52       113\n",
            "\n",
            "    accuracy                           0.77       434\n",
            "   macro avg       0.70      0.68      0.69       434\n",
            "weighted avg       0.76      0.77      0.76       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[279  42]\n",
            " [ 58  55]]\n",
            "--------------------------------\n",
            "val predicted: (952,) [0 1 0 1 0 0 1 1 0 0 1 0 0 1 1 1 0 1 0 1 0 0 1 0 1 1 0 1 0 1 1 1 1 1 1 1 0\n",
            " 1 1 0 0 1 0 1 0 0 0 1 1 1 1 1 1 1 0 0 1 1 1 1 0 0 0 1 1 0 1 1 1 1 1 1 1 1\n",
            " 0 0 1 1 0 0 1 0 1 1 0 1 0 0 1 0 0 0 1 0 0 1 1 0 1 0 0 0 1 1 1 0 0 0 0 0 1\n",
            " 0 0 1 0 1 1 1 0 1 0 1 1 1 0 0 0 1 0 1 0 1 1 0 0 0 0 0 1 1 1 0 0 1 1 1 1 0\n",
            " 1 1 1 0 0 1 1 1 1 0 1 0 0 0 0 1 1 1 1 0 1 1 1 0 0 0 0 1 1 0 1 1 0 0 0 0 0\n",
            " 0 0 1 1 1 1 0 1 0 0 0 0 1 1 0 0 0 0 0 1 0 1 0 0 1 1 0 1 1 1 0 0 1 0 0 1 0\n",
            " 1 1 0 0 1 1 1 1 0 1 0 0 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 0 1 1 1 0 0 1 1 0\n",
            " 1 0 0 1 0 1 1 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 1 1\n",
            " 1 0 1 1 0 1 1 0 1 1 0 0 1 0 0 0 1 1 0 1 1 1 0 0 1 1 0 0 1 1 0 1 1 0 1 0 1\n",
            " 0 0 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 1 1 0 0 1 0 1 1 0 0 1 1 0 0 0\n",
            " 1 0 0 0 1 1 1 0 1 1 0 1 0 1 0 1 0 1 1 0 1 1 1 1 1 0 1 0 1 0 0 1 0 0 0 1 1\n",
            " 0 0 0 1 0 0 1 0 0 0 0 1 1 0 0 1 0 0 1 0 1 1 1 1 0 0 0 0 1 1 0 0 0 0 1 1 1\n",
            " 0 0 0 1 1 1 0 0 0 0 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 0 0 0 1 0 1 1 0 1 1 0 1\n",
            " 1 1 0 0 0 0 1 1 0 0 1 1 1 1 1 1 1 0 1 1 0 0 1 1 0 0 1 0 1 0 0 1 1 0 1 0 1\n",
            " 0 0 0 0 0 1 1 0 1 1 0 1 1 0 1 0 0 1 1 1 1 1 0 1 1 1 1 1 1 1 0 0 1 0 1 0 1\n",
            " 1 1 0 0 1 1 0 1 0 0 0 1 1 0 1 0 0 0 1 0 1 0 1 1 1 1 0 1 0 1 0 0 1 1 0 0 1\n",
            " 0 1 0 0 0 1 0 1 1 1 0 0 1 0 1 0 0 1 1 1 0 1 0 1 1 1 0 1 1 1 0 0 1 0 1 1 1\n",
            " 1 1 1 1 1 0 1 1 1 1 0 0 1 1 1 0 1 0 1 1 1 0 1 1 0 0 0 0 1 0 1 0 0 0 1 0 1\n",
            " 0 0 1 1 0 0 1 1 0 0 1 0 0 1 1 0 1 1 0 0 0 1 1 1 1 0 0 1 0 1 1 1 0 1 1 1 1\n",
            " 1 0 0 0 1 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 1 1 0 1 0 0 0 1 0 0 0 0 0 0 1 1 0\n",
            " 0 0 0 0 1 1 0 0 1 0 1 0 1 1 1 1 0 0 1 0 0 1 1 0 0 0 0 1 1 1 0 0 1 0 0 0 0\n",
            " 0 1 1 0 1 1 1 1 1 0 1 1 1 0 1 0 0 0 1 1 0 1 1 1 1 1 0 0 0 1 0 0 1 1 1 1 1\n",
            " 0 0 0 0 0 0 1 0 0 1 0 1 0 1 0 1 1 1 0 0 1 0 1 0 1 1 1 0 0 0 0 1 1 1 1 1 1\n",
            " 0 0 1 0 1 1 1 1 1 1 1 1 1 0 1 0 1 1 0 0 1 1 1 1 1 1 1 1 1 0 1 0 0 1 0 1 1\n",
            " 0 1 0 0 0 0 0 0 1 1 0 1 0 1 1 1 1 1 1 1 1 0 1 1 0 0 1 0 0 1 1 1 1 0 1 1 0\n",
            " 1 1 0 0 1 0 1 1 1 1 0 0 1 1 0 0 0 1 1 0 1 1 1 0 0 0 1]\n",
            "probabilities: (952, 2) \n",
            " [0 1 0 1 0 0 1 1 0 0 1 0 0 1 1 1 0 1 0 1 0 0 1 0 1 1 0 1 0 1 1 1 1 1 1 1 0\n",
            " 1 1 0 0 1 0 1 0 0 0 1 1 1 1 1 1 1 0 0 1 1 1 1 0 0 0 1 1 0 1 1 1 1 1 1 1 1\n",
            " 0 0 1 1 0 0 1 0 1 1 0 1 0 0 1 0 0 0 1 0 0 1 1 0 1 0 0 0 1 1 1 0 0 0 0 0 1\n",
            " 0 0 1 0 1 1 1 0 1 0 1 1 1 0 0 0 1 0 1 0 1 1 0 0 0 0 0 1 1 1 0 0 1 1 1 1 0\n",
            " 1 1 1 0 0 1 1 1 1 0 1 0 0 0 0 1 1 1 1 0 1 1 1 0 0 0 0 1 1 0 1 1 0 0 0 0 0\n",
            " 0 0 1 1 1 1 0 1 0 0 0 0 1 1 0 0 0 0 0 1 0 1 0 0 1 1 0 1 1 1 0 0 1 0 0 1 0\n",
            " 1 1 0 0 1 1 1 1 0 1 0 0 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 0 1 1 1 0 0 1 1 0\n",
            " 1 0 0 1 0 1 1 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 1 1\n",
            " 1 0 1 1 0 1 1 0 1 1 0 0 1 0 0 0 1 1 0 1 1 1 0 0 1 1 0 0 1 1 0 1 1 0 1 0 1\n",
            " 0 0 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 1 1 0 0 1 0 1 1 0 0 1 1 0 0 0\n",
            " 1 0 0 0 1 1 1 0 1 1 0 1 0 1 0 1 0 1 1 0 1 1 1 1 1 0 1 0 1 0 0 1 0 0 0 1 1\n",
            " 0 0 0 1 0 0 1 0 0 0 0 1 1 0 0 1 0 0 1 0 1 1 1 1 0 0 0 0 1 1 0 0 0 0 1 1 1\n",
            " 0 0 0 1 1 1 0 0 0 0 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 0 0 0 1 0 1 1 0 1 1 0 1\n",
            " 1 1 0 0 0 0 1 1 0 0 1 1 1 1 1 1 1 0 1 1 0 0 1 1 0 0 1 0 1 0 0 1 1 0 1 0 1\n",
            " 0 0 0 0 0 1 1 0 1 1 0 1 1 0 1 0 0 1 1 1 1 1 0 1 1 1 1 1 1 1 0 0 1 0 1 0 1\n",
            " 1 1 0 0 1 1 0 1 0 0 0 1 1 0 1 0 0 0 1 0 1 0 1 1 1 1 0 1 0 1 0 0 1 1 0 0 1\n",
            " 0 1 0 0 0 1 0 1 1 1 0 0 1 0 1 0 0 1 1 1 0 1 0 1 1 1 0 1 1 1 0 0 1 0 1 1 1\n",
            " 1 1 1 1 1 0 1 1 1 1 0 0 1 1 1 0 1 0 1 1 1 0 1 1 0 0 0 0 1 0 1 0 0 0 1 0 1\n",
            " 0 0 1 1 0 0 1 1 0 0 1 0 0 1 1 0 1 1 0 0 0 1 1 1 1 0 0 1 0 1 1 1 0 1 1 1 1\n",
            " 1 0 0 0 1 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 1 1 0 1 0 0 0 1 0 0 0 0 0 0 1 1 0\n",
            " 0 0 0 0 1 1 0 0 1 0 1 0 1 1 1 1 0 0 1 0 0 1 1 0 0 0 0 1 1 1 0 0 1 0 0 0 0\n",
            " 0 1 1 0 1 1 1 1 1 0 1 1 1 0 1 0 0 0 1 1 0 1 1 1 1 1 0 0 0 1 0 0 1 1 1 1 1\n",
            " 0 0 0 0 0 0 1 0 0 1 0 1 0 1 0 1 1 1 0 0 1 0 1 0 1 1 1 0 0 0 0 1 1 1 1 1 1\n",
            " 0 0 1 0 1 1 1 1 1 1 1 1 1 0 1 0 1 1 0 0 1 1 1 1 1 1 1 1 1 0 1 0 0 1 0 1 1\n",
            " 0 1 0 0 0 0 0 0 1 1 0 1 0 1 1 1 1 1 1 1 1 0 1 1 0 0 1 0 0 1 1 1 1 0 1 1 0\n",
            " 1 1 0 0 1 0 1 1 1 1 0 0 1 1 0 0 0 1 1 0 1 1 1 0 0 0 1]\n",
            "uniques chosen: 50 <= should be equal to: 50\n",
            "trainset before adding uncertain samples (350, 10) (350,)\n",
            "trainset after adding uncertain samples (400, 10) (400,)\n",
            "updated train set: (400, 10) (400,) unique(labels): [196 204] [0 1]\n",
            "val set: (902, 10) (902,)\n",
            "\n",
            "Train set: (400, 10)\n",
            "Validation set: (902, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 8\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.062 s \n",
            "\n",
            "Accuracy rate is 78.110599 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86       321\n",
            "           1       0.59      0.51      0.55       113\n",
            "\n",
            "    accuracy                           0.78       434\n",
            "   macro avg       0.71      0.69      0.70       434\n",
            "weighted avg       0.77      0.78      0.78       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[281  40]\n",
            " [ 55  58]]\n",
            "--------------------------------\n",
            "val predicted: (902,) [0 1 0 1 1 1 1 0 0 1 0 0 1 1 0 1 0 1 0 0 1 0 1 0 1 0 1 1 1 1 1 1 0 1 1 0 0\n",
            " 1 0 1 0 0 0 1 1 1 1 1 1 1 0 1 1 1 1 0 0 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 0 0\n",
            " 1 0 1 1 0 1 0 0 1 0 0 0 1 0 0 1 1 0 1 0 0 1 1 1 0 0 0 0 1 0 0 1 0 1 1 1 0\n",
            " 1 0 1 1 0 0 0 1 0 0 1 1 0 0 0 0 0 1 1 1 0 0 1 1 1 1 1 1 1 0 0 1 1 1 1 0 1\n",
            " 0 0 0 0 1 1 1 1 1 1 0 1 0 0 1 1 0 1 1 0 1 0 1 0 0 0 1 1 1 1 0 0 0 0 1 1 0\n",
            " 0 1 0 0 1 0 1 0 0 1 1 0 1 1 0 0 1 0 0 1 0 1 0 1 1 1 1 1 0 1 0 1 0 1 1 1 1\n",
            " 1 0 1 1 1 0 1 1 1 1 1 1 1 1 0 0 1 1 0 1 0 0 1 0 1 1 0 0 0 1 0 0 0 1 0 1 0\n",
            " 0 0 1 0 1 0 0 0 1 0 0 0 0 0 1 1 0 1 1 0 1 1 0 1 1 0 0 1 0 0 0 1 0 1 1 1 0\n",
            " 0 1 1 0 0 1 1 0 1 1 0 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 1 1\n",
            " 0 0 1 1 1 1 0 0 1 1 0 0 0 1 0 0 0 1 1 1 0 1 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1\n",
            " 1 0 1 0 1 0 0 0 0 0 0 1 1 0 0 0 1 0 0 1 0 0 0 0 1 1 0 0 1 0 0 1 0 1 0 1 1\n",
            " 0 0 0 0 1 1 0 0 0 0 1 1 1 0 0 0 1 1 0 0 0 0 1 0 1 0 0 1 0 1 0 0 0 1 0 0 1\n",
            " 1 1 0 1 1 0 1 1 1 0 0 0 1 1 1 1 0 1 1 1 1 1 1 0 1 1 0 1 1 0 0 1 0 1 0 0 1\n",
            " 1 0 1 0 1 0 1 0 0 0 1 1 0 1 0 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1\n",
            " 0 1 1 1 0 1 1 1 0 1 0 0 0 1 1 1 1 0 0 0 1 0 1 0 1 1 1 1 0 1 0 1 0 0 1 1 0\n",
            " 0 1 1 0 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 0 1 0 1 1 1 0 1 1 1 0 1 0 1 1 0 1\n",
            " 1 1 1 0 1 1 1 1 0 0 1 1 1 1 1 0 1 1 1 0 1 1 0 0 0 0 1 0 1 0 0 0 1 0 1 0 0\n",
            " 1 0 0 1 1 0 0 0 0 1 1 0 1 1 0 0 0 1 1 1 1 0 0 1 0 1 1 1 0 1 1 1 1 1 0 0 1\n",
            " 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 1 1 0 1 1 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 1 0\n",
            " 0 1 0 1 0 1 1 1 1 0 0 1 0 0 1 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 1 1 0 1 1 0\n",
            " 1 1 0 1 1 1 0 1 0 0 0 1 1 0 1 1 1 1 1 0 0 0 1 1 0 1 1 1 1 1 0 0 0 0 0 0 1\n",
            " 0 0 1 0 1 0 1 1 1 1 0 0 1 0 1 0 1 1 1 0 0 0 0 1 1 1 1 1 0 0 1 0 1 1 1 0 1\n",
            " 1 1 1 1 0 1 0 1 1 0 0 1 1 1 1 1 1 1 1 0 1 0 0 1 0 1 0 1 0 0 1 0 0 0 1 1 0\n",
            " 1 0 1 1 1 1 1 1 0 1 1 0 1 0 0 0 1 1 1 1 0 0 1 0 1 1 0 0 1 0 1 1 1 1 0 0 1\n",
            " 1 0 0 0 1 1 0 1 1 1 0 0 0 1]\n",
            "probabilities: (902, 2) \n",
            " [0 1 0 1 1 1 1 0 0 1 0 0 1 1 0 1 0 1 0 0 1 0 1 0 1 0 1 1 1 1 1 1 0 1 1 0 0\n",
            " 1 0 1 0 0 0 1 1 1 1 1 1 1 0 1 1 1 1 0 0 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 0 0\n",
            " 1 0 1 1 0 1 0 0 1 0 0 0 1 0 0 1 1 0 1 0 0 1 1 1 0 0 0 0 1 0 0 1 0 1 1 1 0\n",
            " 1 0 1 1 0 0 0 1 0 0 1 1 0 0 0 0 0 1 1 1 0 0 1 1 1 1 1 1 1 0 0 1 1 1 1 0 1\n",
            " 0 0 0 0 1 1 1 1 1 1 0 1 0 0 1 1 0 1 1 0 1 0 1 0 0 0 1 1 1 1 0 0 0 0 1 1 0\n",
            " 0 1 0 0 1 0 1 0 0 1 1 0 1 1 0 0 1 0 0 1 0 1 0 1 1 1 1 1 0 1 0 1 0 1 1 1 1\n",
            " 1 0 1 1 1 0 1 1 1 1 1 1 1 1 0 0 1 1 0 1 0 0 1 0 1 1 0 0 0 1 0 0 0 1 0 1 0\n",
            " 0 0 1 0 1 0 0 0 1 0 0 0 0 0 1 1 0 1 1 0 1 1 0 1 1 0 0 1 0 0 0 1 0 1 1 1 0\n",
            " 0 1 1 0 0 1 1 0 1 1 0 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 1 1\n",
            " 0 0 1 1 1 1 0 0 1 1 0 0 0 1 0 0 0 1 1 1 0 1 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1\n",
            " 1 0 1 0 1 0 0 0 0 0 0 1 1 0 0 0 1 0 0 1 0 0 0 0 1 1 0 0 1 0 0 1 0 1 0 1 1\n",
            " 0 0 0 0 1 1 0 0 0 0 1 1 1 0 0 0 1 1 0 0 0 0 1 0 1 0 0 1 0 1 0 0 0 1 0 0 1\n",
            " 1 1 0 1 1 0 1 1 1 0 0 0 1 1 1 1 0 1 1 1 1 1 1 0 1 1 0 1 1 0 0 1 0 1 0 0 1\n",
            " 1 0 1 0 1 0 1 0 0 0 1 1 0 1 0 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1\n",
            " 0 1 1 1 0 1 1 1 0 1 0 0 0 1 1 1 1 0 0 0 1 0 1 0 1 1 1 1 0 1 0 1 0 0 1 1 0\n",
            " 0 1 1 0 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 0 1 0 1 1 1 0 1 1 1 0 1 0 1 1 0 1\n",
            " 1 1 1 0 1 1 1 1 0 0 1 1 1 1 1 0 1 1 1 0 1 1 0 0 0 0 1 0 1 0 0 0 1 0 1 0 0\n",
            " 1 0 0 1 1 0 0 0 0 1 1 0 1 1 0 0 0 1 1 1 1 0 0 1 0 1 1 1 0 1 1 1 1 1 0 0 1\n",
            " 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 1 1 0 1 1 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 1 0\n",
            " 0 1 0 1 0 1 1 1 1 0 0 1 0 0 1 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 1 1 0 1 1 0\n",
            " 1 1 0 1 1 1 0 1 0 0 0 1 1 0 1 1 1 1 1 0 0 0 1 1 0 1 1 1 1 1 0 0 0 0 0 0 1\n",
            " 0 0 1 0 1 0 1 1 1 1 0 0 1 0 1 0 1 1 1 0 0 0 0 1 1 1 1 1 0 0 1 0 1 1 1 0 1\n",
            " 1 1 1 1 0 1 0 1 1 0 0 1 1 1 1 1 1 1 1 0 1 0 0 1 0 1 0 1 0 0 1 0 0 0 1 1 0\n",
            " 1 0 1 1 1 1 1 1 0 1 1 0 1 0 0 0 1 1 1 1 0 0 1 0 1 1 0 0 1 0 1 1 1 1 0 0 1\n",
            " 1 0 0 0 1 1 0 1 1 1 0 0 0 1]\n",
            "uniques chosen: 50 <= should be equal to: 50\n",
            "trainset before adding uncertain samples (400, 10) (400,)\n",
            "trainset after adding uncertain samples (450, 10) (450,)\n",
            "updated train set: (450, 10) (450,) unique(labels): [223 227] [0 1]\n",
            "val set: (852, 10) (852,)\n",
            "\n",
            "Train set: (450, 10)\n",
            "Validation set: (852, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 9\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.069 s \n",
            "\n",
            "Accuracy rate is 77.419355 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.88      0.85       321\n",
            "           1       0.58      0.48      0.52       113\n",
            "\n",
            "    accuracy                           0.77       434\n",
            "   macro avg       0.70      0.68      0.69       434\n",
            "weighted avg       0.76      0.77      0.77       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[282  39]\n",
            " [ 59  54]]\n",
            "--------------------------------\n",
            "val predicted: (852,) [0 1 0 1 0 0 1 0 0 1 1 0 1 0 1 0 0 1 0 1 0 1 0 1 1 1 1 0 1 1 0 0 1 0 1 0 0\n",
            " 0 1 0 1 1 1 1 1 0 1 1 1 1 0 0 1 1 0 1 1 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1 0 0\n",
            " 1 0 0 0 1 0 0 1 1 0 1 0 0 1 1 1 0 0 0 0 0 0 1 0 1 1 1 0 1 0 1 1 0 0 0 1 0\n",
            " 1 1 1 0 1 1 1 1 1 0 0 1 1 1 1 1 1 1 0 1 1 1 1 0 1 0 0 0 0 1 1 1 1 1 1 0 1\n",
            " 0 0 1 1 0 1 1 0 1 0 1 0 0 0 1 1 1 0 0 1 0 0 1 1 0 0 1 0 0 1 0 1 0 0 1 1 0\n",
            " 1 0 0 0 0 0 1 0 1 0 1 1 1 1 0 1 0 1 0 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1\n",
            " 0 0 1 1 0 1 0 0 1 0 1 1 0 0 0 1 0 0 0 1 0 0 0 0 1 1 0 0 0 1 0 0 0 0 1 1 1\n",
            " 0 1 1 0 1 1 0 1 1 0 1 0 0 1 0 1 0 1 0 0 1 1 0 0 1 1 0 1 1 1 1 0 0 0 0 1 0\n",
            " 1 1 1 1 1 1 1 1 1 0 1 1 1 0 0 1 1 0 0 1 0 1 1 0 0 1 1 0 0 0 1 0 0 0 1 1 1\n",
            " 0 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 0 1 0 1 0 0 0 0 0 0 1 1 0 0 1 0 1 0 0 0 0\n",
            " 1 1 0 0 1 0 1 0 1 1 1 1 0 0 1 1 1 0 0 0 0 1 1 1 0 0 0 1 1 0 0 0 1 0 1 0 0\n",
            " 1 0 1 0 0 1 0 1 1 1 0 1 0 0 1 1 1 0 0 0 1 1 1 1 0 1 1 1 1 1 1 0 1 1 0 1 1\n",
            " 0 0 1 0 1 0 0 1 1 0 1 0 1 0 1 0 0 0 1 1 0 1 0 1 1 0 0 0 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 0 0 1 0 0 0 1 1 1 0 1 1 1 0 1 0 0 0 0 1 1 1 0 0 0 1 0 1 0 1 1 1 0 1\n",
            " 0 1 0 0 1 1 0 0 1 1 0 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 0 1 0 1 1 1 0 1 1 1\n",
            " 0 1 0 1 0 0 1 1 1 1 0 1 1 1 1 0 0 1 1 1 1 1 0 1 1 1 0 1 1 0 0 0 0 1 1 0 0\n",
            " 0 0 1 0 0 1 0 0 1 0 0 0 1 1 0 1 1 0 0 1 1 1 0 0 1 0 1 1 1 0 1 1 1 1 1 0 0\n",
            " 1 0 1 1 0 1 0 0 1 0 1 0 0 0 0 0 1 0 0 1 1 0 0 1 0 0 0 1 0 1 1 0 0 0 0 0 1\n",
            " 0 0 1 0 1 0 1 1 1 1 0 0 1 0 0 1 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 1 0 1 1 0\n",
            " 1 1 0 1 1 1 0 1 1 0 0 1 0 1 1 1 1 0 0 0 1 1 0 1 1 1 1 1 0 0 0 0 0 1 0 0 1\n",
            " 0 1 0 1 1 1 1 0 1 0 1 0 1 1 1 1 0 0 0 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 0\n",
            " 1 0 1 1 0 0 1 1 1 1 1 1 0 1 0 0 1 0 1 0 1 0 0 1 0 0 0 1 1 1 0 1 0 1 1 0 0\n",
            " 1 1 0 1 0 0 0 1 1 1 1 0 1 0 1 1 0 0 1 0 1 1 1 0 0 1 1 0 0 0 1 1 1 1 0 0 0\n",
            " 1]\n",
            "probabilities: (852, 2) \n",
            " [0 1 0 1 0 0 1 0 0 1 1 0 1 0 1 0 0 1 0 1 0 1 0 1 1 1 1 0 1 1 0 0 1 0 1 0 0\n",
            " 0 1 0 1 1 1 1 1 0 1 1 1 1 0 0 1 1 0 1 1 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1 0 0\n",
            " 1 0 0 0 1 0 0 1 1 0 1 0 0 1 1 1 0 0 0 0 0 0 1 0 1 1 1 0 1 0 1 1 0 0 0 1 0\n",
            " 1 1 1 0 1 1 1 1 1 0 0 1 1 1 1 1 1 1 0 1 1 1 1 0 1 0 0 0 0 1 1 1 1 1 1 0 1\n",
            " 0 0 1 1 0 1 1 0 1 0 1 0 0 0 1 1 1 0 0 1 0 0 1 1 0 0 1 0 0 1 0 1 0 0 1 1 0\n",
            " 1 0 0 0 0 0 1 0 1 0 1 1 1 1 0 1 0 1 0 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1\n",
            " 0 0 1 1 0 1 0 0 1 0 1 1 0 0 0 1 0 0 0 1 0 0 0 0 1 1 0 0 0 1 0 0 0 0 1 1 1\n",
            " 0 1 1 0 1 1 0 1 1 0 1 0 0 1 0 1 0 1 0 0 1 1 0 0 1 1 0 1 1 1 1 0 0 0 0 1 0\n",
            " 1 1 1 1 1 1 1 1 1 0 1 1 1 0 0 1 1 0 0 1 0 1 1 0 0 1 1 0 0 0 1 0 0 0 1 1 1\n",
            " 0 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 0 1 0 1 0 0 0 0 0 0 1 1 0 0 1 0 1 0 0 0 0\n",
            " 1 1 0 0 1 0 1 0 1 1 1 1 0 0 1 1 1 0 0 0 0 1 1 1 0 0 0 1 1 0 0 0 1 0 1 0 0\n",
            " 1 0 1 0 0 1 0 1 1 1 0 1 0 0 1 1 1 0 0 0 1 1 1 1 0 1 1 1 1 1 1 0 1 1 0 1 1\n",
            " 0 0 1 0 1 0 0 1 1 0 1 0 1 0 1 0 0 0 1 1 0 1 0 1 1 0 0 0 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 0 0 1 0 0 0 1 1 1 0 1 1 1 0 1 0 0 0 0 1 1 1 0 0 0 1 0 1 0 1 1 1 0 1\n",
            " 0 1 0 0 1 1 0 0 1 1 0 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 0 1 0 1 1 1 0 1 1 1\n",
            " 0 1 0 1 0 0 1 1 1 1 0 1 1 1 1 0 0 1 1 1 1 1 0 1 1 1 0 1 1 0 0 0 0 1 1 0 0\n",
            " 0 0 1 0 0 1 0 0 1 0 0 0 1 1 0 1 1 0 0 1 1 1 0 0 1 0 1 1 1 0 1 1 1 1 1 0 0\n",
            " 1 0 1 1 0 1 0 0 1 0 1 0 0 0 0 0 1 0 0 1 1 0 0 1 0 0 0 1 0 1 1 0 0 0 0 0 1\n",
            " 0 0 1 0 1 0 1 1 1 1 0 0 1 0 0 1 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 1 0 1 1 0\n",
            " 1 1 0 1 1 1 0 1 1 0 0 1 0 1 1 1 1 0 0 0 1 1 0 1 1 1 1 1 0 0 0 0 0 1 0 0 1\n",
            " 0 1 0 1 1 1 1 0 1 0 1 0 1 1 1 1 0 0 0 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 0\n",
            " 1 0 1 1 0 0 1 1 1 1 1 1 0 1 0 0 1 0 1 0 1 0 0 1 0 0 0 1 1 1 0 1 0 1 1 0 0\n",
            " 1 1 0 1 0 0 0 1 1 1 1 0 1 0 1 1 0 0 1 0 1 1 1 0 0 1 1 0 0 0 1 1 1 1 0 0 0\n",
            " 1]\n",
            "uniques chosen: 50 <= should be equal to: 50\n",
            "trainset before adding uncertain samples (450, 10) (450,)\n",
            "trainset after adding uncertain samples (500, 10) (500,)\n",
            "updated train set: (500, 10) (500,) unique(labels): [249 251] [0 1]\n",
            "val set: (802, 10) (802,)\n",
            "\n",
            "Train set: (500, 10)\n",
            "Validation set: (802, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 10\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.100 s \n",
            "\n",
            "Accuracy rate is 78.571429 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.90      0.86       321\n",
            "           1       0.62      0.46      0.53       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.72      0.68      0.69       434\n",
            "weighted avg       0.77      0.79      0.77       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[289  32]\n",
            " [ 61  52]]\n",
            "--------------------------------\n",
            "final active learning accuracies [78.11059907834101, 77.88018433179722, 76.95852534562212, 77.18894009216591, 76.49769585253456, 76.95852534562212, 76.95852534562212, 78.11059907834101, 77.41935483870968, 78.57142857142857]\n",
            "saved /Users/wenxuanhuang/Documents/Repo/ML-for-COVID-19-dataset/Results/Active-learning-experiment-23.pkl /Users/wenxuanhuang/Documents/Repo/ML-for-COVID-19-dataset ['Decision_tree.ipynb', 'dec_git.png', 'Logit_default_f10.pdf', 'Logistic.ipynb', 'SVC.ipynb', 'RF_f5e50_featureimp.pdf', 'log_al.png', 'dec_git.pdf', '.DS_Store', 'log_git.png', 'svm_git.png', 'Logistic_Scikit.ipynb', 'knn_git.pdf', 'knn_git.png', 'rf_al.png', 'Best classifier_RF_f5e50.pdf', 'KNN.ipynb', 'GBDC.ipynb', 'rf_git.png', 'README.md', 'all_training.csv', 'Results', 'svm_al.png', 'Log_ROC.png', 'Logit_default_f7(p_removal).pdf', 'Active_learning.ipynb', 'Random_forest.ipynb', 'Model_select.ipynb', 'gdbc_git.png', '.git', '.vscode', 'Untitled', 'RF_f5e50_modelselect.pdf', 'Logit_default_f8(std_removal).pdf']\n",
            "\n",
            "---------------------------- FINISHED ---------------------------\n",
            "\n",
            "Count = 24, using model = KnnModel, selection_function = RandomSelection, k = 25, iteration = 0.\n",
            "\n",
            "initial random chosen samples (25,)\n",
            "initial train set: (25, 10) (25,) unique(labels): [ 9 16] [0 1]\n",
            "Val set: (1277, 10) (1277,) (25,)\n",
            "\n",
            "Train set: (25, 10)\n",
            "Validation set: (1277, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.077 s \n",
            "\n",
            "Accuracy rate is 71.889401 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.76      0.80       321\n",
            "           1       0.47      0.61      0.53       113\n",
            "\n",
            "    accuracy                           0.72       434\n",
            "   macro avg       0.66      0.68      0.67       434\n",
            "weighted avg       0.75      0.72      0.73       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[243  78]\n",
            " [ 44  69]]\n",
            "--------------------------------\n",
            "val predicted: (1277,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1277, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "uniques chosen: 25 <= should be equal to: 25\n",
            "trainset before adding uncertain samples (25, 10) (25,)\n",
            "trainset after adding uncertain samples (50, 10) (50,)\n",
            "updated train set: (50, 10) (50,) unique(labels): [23 27] [0 1]\n",
            "val set: (1252, 10) (1252,)\n",
            "\n",
            "Train set: (50, 10)\n",
            "Validation set: (1252, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.065 s \n",
            "\n",
            "Accuracy rate is 77.419355 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.86      0.85       321\n",
            "           1       0.57      0.54      0.55       113\n",
            "\n",
            "    accuracy                           0.77       434\n",
            "   macro avg       0.71      0.70      0.70       434\n",
            "weighted avg       0.77      0.77      0.77       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[275  46]\n",
            " [ 52  61]]\n",
            "--------------------------------\n",
            "val predicted: (1252,) [0 1 0 ... 0 0 0]\n",
            "probabilities: (1252, 2) \n",
            " [0 1 0 ... 0 0 0]\n",
            "uniques chosen: 25 <= should be equal to: 25\n",
            "trainset before adding uncertain samples (50, 10) (50,)\n",
            "trainset after adding uncertain samples (75, 10) (75,)\n",
            "updated train set: (75, 10) (75,) unique(labels): [35 40] [0 1]\n",
            "val set: (1227, 10) (1227,)\n",
            "\n",
            "Train set: (75, 10)\n",
            "Validation set: (1227, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 3\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.089 s \n",
            "\n",
            "Accuracy rate is 74.193548 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.81      0.82       321\n",
            "           1       0.50      0.56      0.53       113\n",
            "\n",
            "    accuracy                           0.74       434\n",
            "   macro avg       0.67      0.68      0.68       434\n",
            "weighted avg       0.75      0.74      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[259  62]\n",
            " [ 50  63]]\n",
            "--------------------------------\n",
            "val predicted: (1227,) [0 0 1 ... 0 0 1]\n",
            "probabilities: (1227, 2) \n",
            " [0 0 1 ... 0 0 1]\n",
            "uniques chosen: 25 <= should be equal to: 25\n",
            "trainset before adding uncertain samples (75, 10) (75,)\n",
            "trainset after adding uncertain samples (100, 10) (100,)\n",
            "updated train set: (100, 10) (100,) unique(labels): [47 53] [0 1]\n",
            "val set: (1202, 10) (1202,)\n",
            "\n",
            "Train set: (100, 10)\n",
            "Validation set: (1202, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 4\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.073 s \n",
            "\n",
            "Accuracy rate is 76.267281 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.84      0.84       321\n",
            "           1       0.54      0.55      0.55       113\n",
            "\n",
            "    accuracy                           0.76       434\n",
            "   macro avg       0.69      0.69      0.69       434\n",
            "weighted avg       0.76      0.76      0.76       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[269  52]\n",
            " [ 51  62]]\n",
            "--------------------------------\n",
            "val predicted: (1202,) [0 1 1 ... 0 0 1]\n",
            "probabilities: (1202, 2) \n",
            " [0 1 1 ... 0 0 1]\n",
            "uniques chosen: 25 <= should be equal to: 25\n",
            "trainset before adding uncertain samples (100, 10) (100,)\n",
            "trainset after adding uncertain samples (125, 10) (125,)\n",
            "updated train set: (125, 10) (125,) unique(labels): [61 64] [0 1]\n",
            "val set: (1177, 10) (1177,)\n",
            "\n",
            "Train set: (125, 10)\n",
            "Validation set: (1177, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 5\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.064 s \n",
            "\n",
            "Accuracy rate is 77.419355 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.87      0.85       321\n",
            "           1       0.58      0.50      0.54       113\n",
            "\n",
            "    accuracy                           0.77       434\n",
            "   macro avg       0.70      0.69      0.69       434\n",
            "weighted avg       0.77      0.77      0.77       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[279  42]\n",
            " [ 56  57]]\n",
            "--------------------------------\n",
            "val predicted: (1177,) [0 0 1 ... 0 0 0]\n",
            "probabilities: (1177, 2) \n",
            " [0 0 1 ... 0 0 0]\n",
            "uniques chosen: 25 <= should be equal to: 25\n",
            "trainset before adding uncertain samples (125, 10) (125,)\n",
            "trainset after adding uncertain samples (150, 10) (150,)\n",
            "updated train set: (150, 10) (150,) unique(labels): [70 80] [0 1]\n",
            "val set: (1152, 10) (1152,)\n",
            "\n",
            "Train set: (150, 10)\n",
            "Validation set: (1152, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 6\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.074 s \n",
            "\n",
            "Accuracy rate is 78.110599 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.88      0.86       321\n",
            "           1       0.60      0.50      0.54       113\n",
            "\n",
            "    accuracy                           0.78       434\n",
            "   macro avg       0.71      0.69      0.70       434\n",
            "weighted avg       0.77      0.78      0.77       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[283  38]\n",
            " [ 57  56]]\n",
            "--------------------------------\n",
            "val predicted: (1152,) [0 0 1 ... 0 0 1]\n",
            "probabilities: (1152, 2) \n",
            " [0 0 1 ... 0 0 1]\n",
            "uniques chosen: 25 <= should be equal to: 25\n",
            "trainset before adding uncertain samples (150, 10) (150,)\n",
            "trainset after adding uncertain samples (175, 10) (175,)\n",
            "updated train set: (175, 10) (175,) unique(labels): [84 91] [0 1]\n",
            "val set: (1127, 10) (1127,)\n",
            "\n",
            "Train set: (175, 10)\n",
            "Validation set: (1127, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 7\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.094 s \n",
            "\n",
            "Accuracy rate is 77.649770 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.86      0.85       321\n",
            "           1       0.58      0.53      0.55       113\n",
            "\n",
            "    accuracy                           0.78       434\n",
            "   macro avg       0.71      0.70      0.70       434\n",
            "weighted avg       0.77      0.78      0.77       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[277  44]\n",
            " [ 53  60]]\n",
            "--------------------------------\n",
            "val predicted: (1127,) [0 1 1 ... 0 0 1]\n",
            "probabilities: (1127, 2) \n",
            " [0 1 1 ... 0 0 1]\n",
            "uniques chosen: 25 <= should be equal to: 25\n",
            "trainset before adding uncertain samples (175, 10) (175,)\n",
            "trainset after adding uncertain samples (200, 10) (200,)\n",
            "updated train set: (200, 10) (200,) unique(labels): [ 98 102] [0 1]\n",
            "val set: (1102, 10) (1102,)\n",
            "\n",
            "Train set: (200, 10)\n",
            "Validation set: (1102, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 8\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.072 s \n",
            "\n",
            "Accuracy rate is 78.571429 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86       321\n",
            "           1       0.60      0.52      0.56       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.72      0.70      0.71       434\n",
            "weighted avg       0.78      0.79      0.78       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[282  39]\n",
            " [ 54  59]]\n",
            "--------------------------------\n",
            "val predicted: (1102,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1102, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "uniques chosen: 25 <= should be equal to: 25\n",
            "trainset before adding uncertain samples (200, 10) (200,)\n",
            "trainset after adding uncertain samples (225, 10) (225,)\n",
            "updated train set: (225, 10) (225,) unique(labels): [109 116] [0 1]\n",
            "val set: (1077, 10) (1077,)\n",
            "\n",
            "Train set: (225, 10)\n",
            "Validation set: (1077, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 9\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.071 s \n",
            "\n",
            "Accuracy rate is 78.801843 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86       321\n",
            "           1       0.60      0.54      0.57       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.72      0.71      0.71       434\n",
            "weighted avg       0.78      0.79      0.78       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[281  40]\n",
            " [ 52  61]]\n",
            "--------------------------------\n",
            "val predicted: (1077,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1077, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "uniques chosen: 25 <= should be equal to: 25\n",
            "trainset before adding uncertain samples (225, 10) (225,)\n",
            "trainset after adding uncertain samples (250, 10) (250,)\n",
            "updated train set: (250, 10) (250,) unique(labels): [118 132] [0 1]\n",
            "val set: (1052, 10) (1052,)\n",
            "\n",
            "Train set: (250, 10)\n",
            "Validation set: (1052, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 10\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.059 s \n",
            "\n",
            "Accuracy rate is 78.571429 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86       321\n",
            "           1       0.60      0.53      0.56       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.72      0.70      0.71       434\n",
            "weighted avg       0.78      0.79      0.78       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[281  40]\n",
            " [ 53  60]]\n",
            "--------------------------------\n",
            "val predicted: (1052,) [0 1 1 ... 0 0 1]\n",
            "probabilities: (1052, 2) \n",
            " [0 1 1 ... 0 0 1]\n",
            "uniques chosen: 25 <= should be equal to: 25\n",
            "trainset before adding uncertain samples (250, 10) (250,)\n",
            "trainset after adding uncertain samples (275, 10) (275,)\n",
            "updated train set: (275, 10) (275,) unique(labels): [129 146] [0 1]\n",
            "val set: (1027, 10) (1027,)\n",
            "\n",
            "Train set: (275, 10)\n",
            "Validation set: (1027, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 11\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.084 s \n",
            "\n",
            "Accuracy rate is 78.801843 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86       321\n",
            "           1       0.60      0.54      0.57       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.72      0.71      0.71       434\n",
            "weighted avg       0.78      0.79      0.78       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[281  40]\n",
            " [ 52  61]]\n",
            "--------------------------------\n",
            "val predicted: (1027,) [0 1 1 ... 0 0 1]\n",
            "probabilities: (1027, 2) \n",
            " [0 1 1 ... 0 0 1]\n",
            "uniques chosen: 25 <= should be equal to: 25\n",
            "trainset before adding uncertain samples (275, 10) (275,)\n",
            "trainset after adding uncertain samples (300, 10) (300,)\n",
            "updated train set: (300, 10) (300,) unique(labels): [142 158] [0 1]\n",
            "val set: (1002, 10) (1002,)\n",
            "\n",
            "Train set: (300, 10)\n",
            "Validation set: (1002, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 12\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.083 s \n",
            "\n",
            "Accuracy rate is 77.419355 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.86      0.85       321\n",
            "           1       0.57      0.52      0.55       113\n",
            "\n",
            "    accuracy                           0.77       434\n",
            "   macro avg       0.70      0.69      0.70       434\n",
            "weighted avg       0.77      0.77      0.77       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[277  44]\n",
            " [ 54  59]]\n",
            "--------------------------------\n",
            "val predicted: (1002,) [0 1 1 ... 1 0 0]\n",
            "probabilities: (1002, 2) \n",
            " [0 1 1 ... 1 0 0]\n",
            "uniques chosen: 25 <= should be equal to: 25\n",
            "trainset before adding uncertain samples (300, 10) (300,)\n",
            "trainset after adding uncertain samples (325, 10) (325,)\n",
            "updated train set: (325, 10) (325,) unique(labels): [156 169] [0 1]\n",
            "val set: (977, 10) (977,)\n",
            "\n",
            "Train set: (325, 10)\n",
            "Validation set: (977, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 13\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.064 s \n",
            "\n",
            "Accuracy rate is 77.188940 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.87      0.85       321\n",
            "           1       0.57      0.50      0.53       113\n",
            "\n",
            "    accuracy                           0.77       434\n",
            "   macro avg       0.70      0.68      0.69       434\n",
            "weighted avg       0.76      0.77      0.77       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[279  42]\n",
            " [ 57  56]]\n",
            "--------------------------------\n",
            "val predicted: (977,) [0 1 1 0 1 1 1 0 0 1 1 0 1 1 1 1 0 1 0 1 0 0 1 0 0 0 0 1 1 1 0 1 1 1 0 0 1\n",
            " 0 1 1 0 1 0 0 0 1 1 0 1 1 1 0 0 1 1 1 0 1 0 1 0 0 1 1 1 1 1 0 1 1 1 0 0 1\n",
            " 1 0 0 0 0 1 0 0 1 0 1 1 1 0 1 0 0 1 1 1 0 0 0 0 1 0 0 0 0 1 0 0 1 0 1 1 0\n",
            " 1 0 0 1 0 1 0 0 0 0 1 0 1 0 1 1 0 1 1 0 1 0 0 1 1 0 1 1 1 1 0 1 0 1 0 1 1\n",
            " 0 1 1 1 0 1 0 0 0 0 1 1 1 1 0 1 1 1 1 0 0 1 0 0 1 1 0 1 1 1 1 0 0 1 0 0 0\n",
            " 1 1 1 1 0 1 1 0 0 0 1 0 0 0 1 0 1 0 1 0 1 1 0 1 0 1 1 0 0 0 0 0 0 0 1 1 1\n",
            " 1 0 1 1 0 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 0 0 1 1 1 0 1 1 1 0 0 1 1 1 1 1\n",
            " 1 1 1 0 1 1 1 1 0 0 1 1 1 1 1 0 0 0 0 0 1 0 1 1 0 1 0 0 0 1 0 1 0 0 0 0 1\n",
            " 0 0 0 0 0 0 1 1 1 1 0 1 1 1 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 1 0 1 0 0 1 0\n",
            " 0 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1\n",
            " 1 0 0 1 1 1 0 1 0 0 1 1 0 1 1 1 1 1 1 1 0 0 1 0 1 0 0 1 1 0 0 0 0 1 0 0 1\n",
            " 0 1 0 0 0 1 0 0 1 0 0 0 1 1 0 1 1 0 0 1 0 1 1 0 1 0 1 0 1 1 0 0 0 0 0 1 1\n",
            " 1 1 1 1 1 0 0 0 1 0 1 1 1 0 0 1 0 0 0 1 1 0 0 0 0 0 1 1 0 0 1 0 0 0 1 0 1\n",
            " 0 0 1 1 1 1 0 1 1 1 0 1 0 0 0 1 0 1 1 0 1 0 0 1 1 0 1 1 1 0 1 0 1 1 0 0 0\n",
            " 0 0 1 0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 0 0 1 0 0 1 1 1 1 1\n",
            " 1 0 1 0 0 1 0 1 1 0 0 1 0 1 0 0 1 1 1 0 1 1 1 1 1 0 0 1 1 1 0 1 0 1 0 1 0\n",
            " 0 1 0 1 1 0 1 1 1 0 1 0 1 1 1 1 1 0 1 0 1 0 1 0 1 1 0 1 1 1 1 0 0 1 0 1 1\n",
            " 1 0 1 1 0 1 1 0 0 1 1 1 0 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0 1 0 1 0 1 0 0 0 0\n",
            " 1 1 1 0 0 1 1 0 0 1 1 0 0 0 1 0 1 0 1 1 0 0 1 0 1 0 0 1 1 1 0 1 0 0 1 0 1\n",
            " 0 1 0 1 1 0 1 1 1 1 1 0 0 0 0 0 1 1 1 0 1 0 0 0 1 0 0 1 0 1 0 0 0 0 1 0 1\n",
            " 0 1 0 1 0 0 0 1 0 0 1 1 0 1 1 1 0 0 0 0 1 1 0 0 1 0 0 1 1 1 0 1 0 1 1 0 0\n",
            " 0 1 1 0 1 0 1 1 1 1 0 1 0 0 1 0 0 0 0 0 1 1 0 0 1 1 0 1 1 1 1 0 1 1 1 0 0\n",
            " 0 1 1 0 1 1 1 1 1 0 1 0 0 0 1 0 1 0 1 1 0 1 1 0 1 0 0 0 0 1 0 0 1 0 1 1 1\n",
            " 0 0 1 0 1 1 0 1 1 1 1 1 0 0 0 1 1 1 1 1 1 0 1 1 0 1 1 1 0 0 1 1 0 1 1 0 0\n",
            " 0 1 1 0 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 0 0 0 0 1 1 0 1 0 0 1 0 1 0 1 1 0 1\n",
            " 0 1 0 0 1 1 1 0 1 1 0 1 1 0 1 1 0 0 1 1 1 0 1 0 1 0 1 0 1 1 1 0 1 0 1 1 1\n",
            " 1 0 0 1 0 0 0 1 0 0 1 1 1 0 0]\n",
            "probabilities: (977, 2) \n",
            " [0 1 1 0 1 1 1 0 0 1 1 0 1 1 1 1 0 1 0 1 0 0 1 0 0 0 0 1 1 1 0 1 1 1 0 0 1\n",
            " 0 1 1 0 1 0 0 0 1 1 0 1 1 1 0 0 1 1 1 0 1 0 1 0 0 1 1 1 1 1 0 1 1 1 0 0 1\n",
            " 1 0 0 0 0 1 0 0 1 0 1 1 1 0 1 0 0 1 1 1 0 0 0 0 1 0 0 0 0 1 0 0 1 0 1 1 0\n",
            " 1 0 0 1 0 1 0 0 0 0 1 0 1 0 1 1 0 1 1 0 1 0 0 1 1 0 1 1 1 1 0 1 0 1 0 1 1\n",
            " 0 1 1 1 0 1 0 0 0 0 1 1 1 1 0 1 1 1 1 0 0 1 0 0 1 1 0 1 1 1 1 0 0 1 0 0 0\n",
            " 1 1 1 1 0 1 1 0 0 0 1 0 0 0 1 0 1 0 1 0 1 1 0 1 0 1 1 0 0 0 0 0 0 0 1 1 1\n",
            " 1 0 1 1 0 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 0 0 1 1 1 0 1 1 1 0 0 1 1 1 1 1\n",
            " 1 1 1 0 1 1 1 1 0 0 1 1 1 1 1 0 0 0 0 0 1 0 1 1 0 1 0 0 0 1 0 1 0 0 0 0 1\n",
            " 0 0 0 0 0 0 1 1 1 1 0 1 1 1 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 1 0 1 0 0 1 0\n",
            " 0 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1\n",
            " 1 0 0 1 1 1 0 1 0 0 1 1 0 1 1 1 1 1 1 1 0 0 1 0 1 0 0 1 1 0 0 0 0 1 0 0 1\n",
            " 0 1 0 0 0 1 0 0 1 0 0 0 1 1 0 1 1 0 0 1 0 1 1 0 1 0 1 0 1 1 0 0 0 0 0 1 1\n",
            " 1 1 1 1 1 0 0 0 1 0 1 1 1 0 0 1 0 0 0 1 1 0 0 0 0 0 1 1 0 0 1 0 0 0 1 0 1\n",
            " 0 0 1 1 1 1 0 1 1 1 0 1 0 0 0 1 0 1 1 0 1 0 0 1 1 0 1 1 1 0 1 0 1 1 0 0 0\n",
            " 0 0 1 0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 0 0 1 0 0 1 1 1 1 1\n",
            " 1 0 1 0 0 1 0 1 1 0 0 1 0 1 0 0 1 1 1 0 1 1 1 1 1 0 0 1 1 1 0 1 0 1 0 1 0\n",
            " 0 1 0 1 1 0 1 1 1 0 1 0 1 1 1 1 1 0 1 0 1 0 1 0 1 1 0 1 1 1 1 0 0 1 0 1 1\n",
            " 1 0 1 1 0 1 1 0 0 1 1 1 0 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0 1 0 1 0 1 0 0 0 0\n",
            " 1 1 1 0 0 1 1 0 0 1 1 0 0 0 1 0 1 0 1 1 0 0 1 0 1 0 0 1 1 1 0 1 0 0 1 0 1\n",
            " 0 1 0 1 1 0 1 1 1 1 1 0 0 0 0 0 1 1 1 0 1 0 0 0 1 0 0 1 0 1 0 0 0 0 1 0 1\n",
            " 0 1 0 1 0 0 0 1 0 0 1 1 0 1 1 1 0 0 0 0 1 1 0 0 1 0 0 1 1 1 0 1 0 1 1 0 0\n",
            " 0 1 1 0 1 0 1 1 1 1 0 1 0 0 1 0 0 0 0 0 1 1 0 0 1 1 0 1 1 1 1 0 1 1 1 0 0\n",
            " 0 1 1 0 1 1 1 1 1 0 1 0 0 0 1 0 1 0 1 1 0 1 1 0 1 0 0 0 0 1 0 0 1 0 1 1 1\n",
            " 0 0 1 0 1 1 0 1 1 1 1 1 0 0 0 1 1 1 1 1 1 0 1 1 0 1 1 1 0 0 1 1 0 1 1 0 0\n",
            " 0 1 1 0 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 0 0 0 0 1 1 0 1 0 0 1 0 1 0 1 1 0 1\n",
            " 0 1 0 0 1 1 1 0 1 1 0 1 1 0 1 1 0 0 1 1 1 0 1 0 1 0 1 0 1 1 1 0 1 0 1 1 1\n",
            " 1 0 0 1 0 0 0 1 0 0 1 1 1 0 0]\n",
            "uniques chosen: 25 <= should be equal to: 25\n",
            "trainset before adding uncertain samples (325, 10) (325,)\n",
            "trainset after adding uncertain samples (350, 10) (350,)\n",
            "updated train set: (350, 10) (350,) unique(labels): [166 184] [0 1]\n",
            "val set: (952, 10) (952,)\n",
            "\n",
            "Train set: (350, 10)\n",
            "Validation set: (952, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 14\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.059 s \n",
            "\n",
            "Accuracy rate is 77.880184 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.88      0.85       321\n",
            "           1       0.59      0.50      0.54       113\n",
            "\n",
            "    accuracy                           0.78       434\n",
            "   macro avg       0.71      0.69      0.70       434\n",
            "weighted avg       0.77      0.78      0.77       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[281  40]\n",
            " [ 56  57]]\n",
            "--------------------------------\n",
            "val predicted: (952,) [0 1 0 1 1 1 0 0 1 1 0 1 1 1 1 0 1 0 1 0 0 1 0 0 0 0 1 1 1 0 1 1 1 0 0 1 0\n",
            " 1 1 0 1 0 0 0 1 1 1 1 0 0 0 1 1 1 0 1 0 1 0 0 1 1 1 1 0 0 1 1 1 0 0 1 1 0\n",
            " 0 0 0 1 0 0 1 1 1 1 0 1 0 0 1 1 1 0 0 0 0 1 0 0 0 0 1 0 0 1 0 1 0 1 0 0 1\n",
            " 0 0 0 0 0 0 1 0 1 0 0 1 0 1 1 0 1 0 0 1 1 0 1 1 1 1 0 1 0 1 0 1 1 0 1 1 1\n",
            " 0 1 0 0 0 1 1 1 1 1 0 1 1 1 1 0 0 1 0 0 1 1 0 1 1 1 1 0 0 1 0 0 0 1 1 1 1\n",
            " 0 1 1 0 0 0 1 0 0 0 1 0 1 0 1 0 1 1 0 1 0 1 1 0 0 0 0 0 0 0 1 1 1 1 0 1 1\n",
            " 0 1 1 1 0 0 1 1 0 0 1 1 1 0 0 1 1 1 0 1 1 1 0 0 1 1 1 0 1 1 1 1 0 1 1 1 1\n",
            " 0 0 1 1 1 1 1 0 0 0 0 0 1 0 1 1 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 1 1\n",
            " 1 0 1 1 1 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 1 0 1 0 0 1 0 0 1 1 1 1 1 1 1 0 1\n",
            " 1 1 0 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 0 1 1 0 0 1 1 1 0 1 0 0 1\n",
            " 1 0 1 1 1 1 1 1 1 0 0 1 0 1 0 0 1 1 0 0 0 0 1 0 0 1 0 1 0 0 0 1 0 0 1 0 0\n",
            " 0 1 1 1 1 1 0 1 0 1 1 0 1 0 1 0 1 1 0 0 0 0 0 1 1 1 1 1 1 1 0 0 1 0 1 1 1\n",
            " 0 0 1 0 0 0 1 1 0 0 0 1 0 1 1 0 0 1 0 0 0 1 0 1 0 0 1 1 1 1 0 1 1 1 0 1 0\n",
            " 0 0 1 0 1 1 0 1 0 0 1 1 0 1 1 1 0 1 1 1 0 0 0 0 1 0 1 0 1 0 1 1 1 0 1 0 1\n",
            " 1 1 1 0 1 1 0 1 1 1 1 1 0 0 1 0 0 1 1 1 1 1 1 0 1 0 0 1 0 1 1 0 1 0 1 1 0\n",
            " 1 1 1 0 1 1 1 1 1 0 0 1 1 1 0 1 0 1 0 1 0 0 1 0 1 1 0 1 1 1 0 1 0 1 1 1 1\n",
            " 1 0 1 0 1 0 1 0 1 0 1 1 1 1 0 0 1 0 1 1 0 1 1 0 1 1 0 0 1 1 1 0 1 1 1 1 0\n",
            " 1 1 1 0 0 1 1 1 0 0 1 0 1 0 1 0 0 0 0 1 1 1 0 1 1 1 1 1 0 0 0 1 0 1 0 1 1\n",
            " 0 1 1 0 1 0 1 1 1 0 1 0 1 1 0 1 0 1 0 1 1 1 1 1 1 1 0 0 0 0 0 1 1 1 0 1 0\n",
            " 0 0 1 0 0 1 0 1 0 0 0 0 1 0 1 0 1 0 1 0 0 0 1 0 0 1 1 0 1 1 1 0 0 1 0 1 1\n",
            " 0 0 1 0 0 1 1 1 0 1 0 1 1 0 0 0 1 1 0 1 0 1 1 1 1 0 1 0 0 1 0 1 0 0 0 1 1\n",
            " 0 0 1 1 0 1 1 1 1 0 1 1 1 0 0 0 1 1 0 1 1 1 1 1 0 1 0 0 0 1 0 1 0 1 1 0 1\n",
            " 1 0 1 0 0 0 0 1 0 0 1 0 1 1 1 0 0 1 0 1 1 0 1 1 1 1 1 0 0 0 1 1 1 1 1 1 0\n",
            " 1 1 0 1 1 1 0 0 1 1 0 1 1 0 0 1 1 0 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 0 0 0 0\n",
            " 1 1 0 1 0 0 1 0 1 0 1 1 0 1 0 1 0 0 1 1 1 0 1 1 0 1 1 0 1 1 0 0 1 1 1 0 1\n",
            " 0 1 0 1 0 1 1 1 0 1 0 1 0 1 0 0 1 0 0 0 1 0 1 1 1 0 0]\n",
            "probabilities: (952, 2) \n",
            " [0 1 0 1 1 1 0 0 1 1 0 1 1 1 1 0 1 0 1 0 0 1 0 0 0 0 1 1 1 0 1 1 1 0 0 1 0\n",
            " 1 1 0 1 0 0 0 1 1 1 1 0 0 0 1 1 1 0 1 0 1 0 0 1 1 1 1 0 0 1 1 1 0 0 1 1 0\n",
            " 0 0 0 1 0 0 1 1 1 1 0 1 0 0 1 1 1 0 0 0 0 1 0 0 0 0 1 0 0 1 0 1 0 1 0 0 1\n",
            " 0 0 0 0 0 0 1 0 1 0 0 1 0 1 1 0 1 0 0 1 1 0 1 1 1 1 0 1 0 1 0 1 1 0 1 1 1\n",
            " 0 1 0 0 0 1 1 1 1 1 0 1 1 1 1 0 0 1 0 0 1 1 0 1 1 1 1 0 0 1 0 0 0 1 1 1 1\n",
            " 0 1 1 0 0 0 1 0 0 0 1 0 1 0 1 0 1 1 0 1 0 1 1 0 0 0 0 0 0 0 1 1 1 1 0 1 1\n",
            " 0 1 1 1 0 0 1 1 0 0 1 1 1 0 0 1 1 1 0 1 1 1 0 0 1 1 1 0 1 1 1 1 0 1 1 1 1\n",
            " 0 0 1 1 1 1 1 0 0 0 0 0 1 0 1 1 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 1 1\n",
            " 1 0 1 1 1 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 1 0 1 0 0 1 0 0 1 1 1 1 1 1 1 0 1\n",
            " 1 1 0 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 0 1 1 0 0 1 1 1 0 1 0 0 1\n",
            " 1 0 1 1 1 1 1 1 1 0 0 1 0 1 0 0 1 1 0 0 0 0 1 0 0 1 0 1 0 0 0 1 0 0 1 0 0\n",
            " 0 1 1 1 1 1 0 1 0 1 1 0 1 0 1 0 1 1 0 0 0 0 0 1 1 1 1 1 1 1 0 0 1 0 1 1 1\n",
            " 0 0 1 0 0 0 1 1 0 0 0 1 0 1 1 0 0 1 0 0 0 1 0 1 0 0 1 1 1 1 0 1 1 1 0 1 0\n",
            " 0 0 1 0 1 1 0 1 0 0 1 1 0 1 1 1 0 1 1 1 0 0 0 0 1 0 1 0 1 0 1 1 1 0 1 0 1\n",
            " 1 1 1 0 1 1 0 1 1 1 1 1 0 0 1 0 0 1 1 1 1 1 1 0 1 0 0 1 0 1 1 0 1 0 1 1 0\n",
            " 1 1 1 0 1 1 1 1 1 0 0 1 1 1 0 1 0 1 0 1 0 0 1 0 1 1 0 1 1 1 0 1 0 1 1 1 1\n",
            " 1 0 1 0 1 0 1 0 1 0 1 1 1 1 0 0 1 0 1 1 0 1 1 0 1 1 0 0 1 1 1 0 1 1 1 1 0\n",
            " 1 1 1 0 0 1 1 1 0 0 1 0 1 0 1 0 0 0 0 1 1 1 0 1 1 1 1 1 0 0 0 1 0 1 0 1 1\n",
            " 0 1 1 0 1 0 1 1 1 0 1 0 1 1 0 1 0 1 0 1 1 1 1 1 1 1 0 0 0 0 0 1 1 1 0 1 0\n",
            " 0 0 1 0 0 1 0 1 0 0 0 0 1 0 1 0 1 0 1 0 0 0 1 0 0 1 1 0 1 1 1 0 0 1 0 1 1\n",
            " 0 0 1 0 0 1 1 1 0 1 0 1 1 0 0 0 1 1 0 1 0 1 1 1 1 0 1 0 0 1 0 1 0 0 0 1 1\n",
            " 0 0 1 1 0 1 1 1 1 0 1 1 1 0 0 0 1 1 0 1 1 1 1 1 0 1 0 0 0 1 0 1 0 1 1 0 1\n",
            " 1 0 1 0 0 0 0 1 0 0 1 0 1 1 1 0 0 1 0 1 1 0 1 1 1 1 1 0 0 0 1 1 1 1 1 1 0\n",
            " 1 1 0 1 1 1 0 0 1 1 0 1 1 0 0 1 1 0 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 0 0 0 0\n",
            " 1 1 0 1 0 0 1 0 1 0 1 1 0 1 0 1 0 0 1 1 1 0 1 1 0 1 1 0 1 1 0 0 1 1 1 0 1\n",
            " 0 1 0 1 0 1 1 1 0 1 0 1 0 1 0 0 1 0 0 0 1 0 1 1 1 0 0]\n",
            "uniques chosen: 25 <= should be equal to: 25\n",
            "trainset before adding uncertain samples (350, 10) (350,)\n",
            "trainset after adding uncertain samples (375, 10) (375,)\n",
            "updated train set: (375, 10) (375,) unique(labels): [174 201] [0 1]\n",
            "val set: (927, 10) (927,)\n",
            "\n",
            "Train set: (375, 10)\n",
            "Validation set: (927, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 15\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.076 s \n",
            "\n",
            "Accuracy rate is 78.110599 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86       321\n",
            "           1       0.59      0.51      0.55       113\n",
            "\n",
            "    accuracy                           0.78       434\n",
            "   macro avg       0.71      0.69      0.70       434\n",
            "weighted avg       0.77      0.78      0.78       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[281  40]\n",
            " [ 55  58]]\n",
            "--------------------------------\n",
            "val predicted: (927,) [0 1 0 1 1 1 0 0 1 1 0 1 1 1 1 0 1 0 1 0 0 1 0 0 0 0 1 1 1 0 1 1 1 0 0 1 0\n",
            " 1 1 0 1 0 0 0 1 1 1 1 0 0 0 1 1 1 0 1 0 1 0 0 1 1 1 1 0 0 1 1 1 0 0 1 1 0\n",
            " 0 0 0 1 0 0 1 1 1 1 0 1 0 0 1 1 0 0 0 0 1 0 0 0 0 1 0 0 1 0 1 0 1 0 0 0 0\n",
            " 0 0 0 0 0 1 0 0 1 0 1 1 0 1 0 1 1 0 1 1 1 1 0 1 0 1 0 1 1 0 1 1 1 0 1 0 0\n",
            " 0 1 1 1 1 1 0 1 1 1 0 1 1 0 0 1 1 0 1 1 1 1 0 0 1 0 0 0 1 1 1 1 0 1 0 0 0\n",
            " 0 0 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 0 0 0 0 0 0 1 1 1 1 0 1 1 0 1 1 1 0 0 1\n",
            " 1 0 0 1 1 1 0 0 1 1 1 0 1 1 1 0 0 1 1 1 0 1 1 1 1 0 1 1 1 1 0 0 1 1 1 1 1\n",
            " 0 0 0 0 0 1 0 1 1 0 1 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 1 1 1 1 0 1 1 1 0 1\n",
            " 0 0 1 1 0 0 0 1 1 1 1 1 0 1 0 1 0 0 1 0 0 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 0\n",
            " 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 0 0 1 1 0 1 0 0 1 1 0 1 1 1 1 1 1 0\n",
            " 0 1 0 1 0 0 1 1 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 1 0 0 0 1 1 1 1 0 1 0 1 1 1\n",
            " 0 1 0 1 1 0 0 0 0 0 1 1 1 1 1 1 1 0 0 1 0 1 1 1 0 0 1 0 0 0 1 1 0 0 0 1 0\n",
            " 1 1 0 0 0 0 0 0 1 0 1 0 0 1 1 1 1 0 1 1 1 0 1 1 0 0 1 0 1 1 0 1 0 0 1 1 0\n",
            " 1 1 1 0 1 1 1 0 0 0 0 1 0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 0\n",
            " 0 1 0 0 1 1 1 1 1 1 0 1 0 0 1 0 1 1 0 1 0 1 1 0 1 1 1 0 1 1 1 0 0 1 1 1 0\n",
            " 1 0 1 0 1 0 0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1 0 1 0 1 0 1 0 1 0 1 1 1 1 0 0\n",
            " 1 0 1 1 0 1 1 0 1 1 0 0 1 1 1 0 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0 1 0 1 0 1 0\n",
            " 0 0 1 1 1 0 1 1 1 1 1 0 0 0 1 0 1 0 1 1 1 1 0 1 0 1 1 1 0 1 0 0 1 0 1 0 1\n",
            " 1 1 1 1 1 1 1 1 0 0 0 0 0 1 1 1 0 1 0 0 0 1 0 0 1 0 1 0 0 0 0 1 0 1 0 1 0\n",
            " 1 0 0 0 1 0 0 1 1 0 1 1 1 0 0 1 0 1 1 0 0 1 0 1 1 1 0 1 0 1 1 0 0 0 1 0 1\n",
            " 0 1 1 1 1 0 1 0 0 1 0 1 0 0 0 1 1 0 0 1 1 0 1 1 1 1 0 1 1 1 0 0 0 1 1 0 1\n",
            " 1 1 1 1 0 0 0 1 0 1 0 1 1 0 1 1 0 1 0 0 0 0 1 0 0 1 0 1 1 1 0 0 1 0 1 1 0\n",
            " 1 1 1 1 1 0 0 0 1 1 1 1 1 1 0 1 1 0 1 0 0 1 1 0 1 1 0 1 1 0 1 1 1 1 1 1 1\n",
            " 1 0 1 1 0 1 1 1 0 0 0 0 1 1 0 1 0 0 1 0 1 0 1 1 0 1 0 1 0 0 1 1 1 0 1 1 0\n",
            " 1 1 0 0 1 0 0 1 1 1 0 1 0 1 0 1 0 1 1 1 0 1 0 1 0 0 0 0 1 0 0 0 1 0 1 1 1\n",
            " 0 0]\n",
            "probabilities: (927, 2) \n",
            " [0 1 0 1 1 1 0 0 1 1 0 1 1 1 1 0 1 0 1 0 0 1 0 0 0 0 1 1 1 0 1 1 1 0 0 1 0\n",
            " 1 1 0 1 0 0 0 1 1 1 1 0 0 0 1 1 1 0 1 0 1 0 0 1 1 1 1 0 0 1 1 1 0 0 1 1 0\n",
            " 0 0 0 1 0 0 1 1 1 1 0 1 0 0 1 1 0 0 0 0 1 0 0 0 0 1 0 0 1 0 1 0 1 0 0 0 0\n",
            " 0 0 0 0 0 1 0 0 1 0 1 1 0 1 0 1 1 0 1 1 1 1 0 1 0 1 0 1 1 0 1 1 1 0 1 0 0\n",
            " 0 1 1 1 1 1 0 1 1 1 0 1 1 0 0 1 1 0 1 1 1 1 0 0 1 0 0 0 1 1 1 1 0 1 0 0 0\n",
            " 0 0 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 0 0 0 0 0 0 1 1 1 1 0 1 1 0 1 1 1 0 0 1\n",
            " 1 0 0 1 1 1 0 0 1 1 1 0 1 1 1 0 0 1 1 1 0 1 1 1 1 0 1 1 1 1 0 0 1 1 1 1 1\n",
            " 0 0 0 0 0 1 0 1 1 0 1 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 1 1 1 1 0 1 1 1 0 1\n",
            " 0 0 1 1 0 0 0 1 1 1 1 1 0 1 0 1 0 0 1 0 0 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 0\n",
            " 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 0 0 1 1 0 1 0 0 1 1 0 1 1 1 1 1 1 0\n",
            " 0 1 0 1 0 0 1 1 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 1 0 0 0 1 1 1 1 0 1 0 1 1 1\n",
            " 0 1 0 1 1 0 0 0 0 0 1 1 1 1 1 1 1 0 0 1 0 1 1 1 0 0 1 0 0 0 1 1 0 0 0 1 0\n",
            " 1 1 0 0 0 0 0 0 1 0 1 0 0 1 1 1 1 0 1 1 1 0 1 1 0 0 1 0 1 1 0 1 0 0 1 1 0\n",
            " 1 1 1 0 1 1 1 0 0 0 0 1 0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 0\n",
            " 0 1 0 0 1 1 1 1 1 1 0 1 0 0 1 0 1 1 0 1 0 1 1 0 1 1 1 0 1 1 1 0 0 1 1 1 0\n",
            " 1 0 1 0 1 0 0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1 0 1 0 1 0 1 0 1 0 1 1 1 1 0 0\n",
            " 1 0 1 1 0 1 1 0 1 1 0 0 1 1 1 0 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0 1 0 1 0 1 0\n",
            " 0 0 1 1 1 0 1 1 1 1 1 0 0 0 1 0 1 0 1 1 1 1 0 1 0 1 1 1 0 1 0 0 1 0 1 0 1\n",
            " 1 1 1 1 1 1 1 1 0 0 0 0 0 1 1 1 0 1 0 0 0 1 0 0 1 0 1 0 0 0 0 1 0 1 0 1 0\n",
            " 1 0 0 0 1 0 0 1 1 0 1 1 1 0 0 1 0 1 1 0 0 1 0 1 1 1 0 1 0 1 1 0 0 0 1 0 1\n",
            " 0 1 1 1 1 0 1 0 0 1 0 1 0 0 0 1 1 0 0 1 1 0 1 1 1 1 0 1 1 1 0 0 0 1 1 0 1\n",
            " 1 1 1 1 0 0 0 1 0 1 0 1 1 0 1 1 0 1 0 0 0 0 1 0 0 1 0 1 1 1 0 0 1 0 1 1 0\n",
            " 1 1 1 1 1 0 0 0 1 1 1 1 1 1 0 1 1 0 1 0 0 1 1 0 1 1 0 1 1 0 1 1 1 1 1 1 1\n",
            " 1 0 1 1 0 1 1 1 0 0 0 0 1 1 0 1 0 0 1 0 1 0 1 1 0 1 0 1 0 0 1 1 1 0 1 1 0\n",
            " 1 1 0 0 1 0 0 1 1 1 0 1 0 1 0 1 0 1 1 1 0 1 0 1 0 0 0 0 1 0 0 0 1 0 1 1 1\n",
            " 0 0]\n",
            "uniques chosen: 25 <= should be equal to: 25\n",
            "trainset before adding uncertain samples (375, 10) (375,)\n",
            "trainset after adding uncertain samples (400, 10) (400,)\n",
            "updated train set: (400, 10) (400,) unique(labels): [185 215] [0 1]\n",
            "val set: (902, 10) (902,)\n",
            "\n",
            "Train set: (400, 10)\n",
            "Validation set: (902, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 16\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.073 s \n",
            "\n",
            "Accuracy rate is 78.110599 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.87      0.85       321\n",
            "           1       0.59      0.52      0.55       113\n",
            "\n",
            "    accuracy                           0.78       434\n",
            "   macro avg       0.71      0.70      0.70       434\n",
            "weighted avg       0.77      0.78      0.78       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[280  41]\n",
            " [ 54  59]]\n",
            "--------------------------------\n",
            "val predicted: (902,) [0 1 0 1 1 1 0 0 1 1 0 1 1 1 1 0 0 1 0 0 1 0 0 0 0 1 1 1 0 1 1 1 0 0 1 0 1\n",
            " 1 0 1 0 0 0 1 1 1 1 1 0 0 1 1 1 0 1 0 0 1 1 1 1 0 0 1 1 1 0 0 1 1 0 0 0 0\n",
            " 1 0 0 1 1 1 0 1 0 0 1 1 0 0 0 0 1 0 0 0 0 1 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0\n",
            " 0 1 0 0 1 0 0 1 0 1 0 1 1 0 1 1 1 1 0 1 0 1 0 1 1 0 1 1 1 0 1 0 0 0 1 1 1\n",
            " 1 1 0 1 1 1 0 1 1 0 0 1 1 0 1 1 1 1 0 0 1 0 0 0 1 1 1 1 0 1 1 0 0 0 0 0 0\n",
            " 1 0 1 0 1 0 1 1 0 1 1 1 0 0 0 0 0 0 0 1 1 1 1 0 1 0 1 1 1 0 0 1 1 0 0 1 1\n",
            " 1 0 0 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 1 1 1 1 0 0 0 0 0 1\n",
            " 0 1 1 0 1 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 1 1 1 1 0 1 1 1 0 1 0 0 1 1 0 0\n",
            " 1 1 1 1 1 0 1 0 1 0 0 1 0 0 1 1 1 1 1 1 0 1 1 1 0 1 0 1 0 1 1 1 1 1 1 1 1\n",
            " 1 1 1 0 0 0 1 1 1 1 1 0 0 1 1 0 1 0 0 1 1 0 1 1 1 1 1 1 0 0 1 0 1 0 0 1 1\n",
            " 0 0 0 0 0 0 1 0 1 0 0 1 1 0 0 1 0 0 1 1 1 1 0 1 0 1 1 1 0 1 0 1 1 0 0 0 1\n",
            " 1 1 1 1 1 1 0 1 0 1 1 1 0 0 1 0 0 0 1 1 0 0 0 1 0 1 1 0 0 0 0 0 0 1 0 1 0\n",
            " 0 1 1 1 1 0 1 1 1 0 1 1 0 0 1 1 1 0 1 0 0 1 1 0 1 1 1 0 1 1 1 0 0 0 0 1 0\n",
            " 1 0 1 0 1 1 1 0 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 0 0 1 0 0 1 1 1 1 1 1 0 1 0\n",
            " 0 1 1 1 0 1 0 1 1 0 1 1 1 0 1 1 1 0 0 1 1 1 0 1 0 1 1 0 0 1 0 1 0 1 1 1 0\n",
            " 1 0 1 1 1 1 1 0 1 0 1 0 1 0 1 0 1 1 1 1 0 0 1 0 1 1 0 1 0 1 1 0 0 1 1 1 0\n",
            " 1 1 1 1 0 1 1 1 1 0 1 1 1 0 0 1 0 1 0 1 0 0 0 1 1 1 0 1 1 1 1 1 0 0 0 1 0\n",
            " 1 1 1 1 1 1 0 1 0 1 1 1 0 1 0 0 1 0 1 0 1 1 1 1 1 1 1 1 0 0 0 0 0 1 1 1 0\n",
            " 1 0 0 0 1 0 0 1 0 1 0 0 0 0 1 0 1 0 1 0 0 0 0 1 0 0 1 0 1 1 1 0 0 1 0 1 1\n",
            " 0 0 1 0 1 1 1 0 1 0 1 1 0 0 0 1 1 0 1 1 1 1 0 1 0 0 1 0 1 0 0 0 1 1 0 0 1\n",
            " 1 0 1 1 1 1 0 1 1 1 0 0 0 1 1 0 1 1 1 1 1 0 0 0 1 0 1 0 1 1 0 1 1 0 1 0 0\n",
            " 0 0 1 0 0 1 0 1 1 1 0 0 0 1 1 0 1 1 1 1 1 0 0 0 1 1 1 1 1 1 0 0 1 0 1 0 0\n",
            " 1 0 1 1 0 1 1 0 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 0 0 0 0 1 1 0 1 0 0 1 0 1 0\n",
            " 1 1 0 1 0 1 0 0 1 1 0 1 1 0 1 1 0 0 1 0 0 1 1 0 1 0 1 0 1 0 1 1 1 0 1 1 0\n",
            " 0 0 0 1 0 0 0 1 0 1 1 1 0 0]\n",
            "probabilities: (902, 2) \n",
            " [0 1 0 1 1 1 0 0 1 1 0 1 1 1 1 0 0 1 0 0 1 0 0 0 0 1 1 1 0 1 1 1 0 0 1 0 1\n",
            " 1 0 1 0 0 0 1 1 1 1 1 0 0 1 1 1 0 1 0 0 1 1 1 1 0 0 1 1 1 0 0 1 1 0 0 0 0\n",
            " 1 0 0 1 1 1 0 1 0 0 1 1 0 0 0 0 1 0 0 0 0 1 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0\n",
            " 0 1 0 0 1 0 0 1 0 1 0 1 1 0 1 1 1 1 0 1 0 1 0 1 1 0 1 1 1 0 1 0 0 0 1 1 1\n",
            " 1 1 0 1 1 1 0 1 1 0 0 1 1 0 1 1 1 1 0 0 1 0 0 0 1 1 1 1 0 1 1 0 0 0 0 0 0\n",
            " 1 0 1 0 1 0 1 1 0 1 1 1 0 0 0 0 0 0 0 1 1 1 1 0 1 0 1 1 1 0 0 1 1 0 0 1 1\n",
            " 1 0 0 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 1 1 1 1 0 0 0 0 0 1\n",
            " 0 1 1 0 1 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 1 1 1 1 0 1 1 1 0 1 0 0 1 1 0 0\n",
            " 1 1 1 1 1 0 1 0 1 0 0 1 0 0 1 1 1 1 1 1 0 1 1 1 0 1 0 1 0 1 1 1 1 1 1 1 1\n",
            " 1 1 1 0 0 0 1 1 1 1 1 0 0 1 1 0 1 0 0 1 1 0 1 1 1 1 1 1 0 0 1 0 1 0 0 1 1\n",
            " 0 0 0 0 0 0 1 0 1 0 0 1 1 0 0 1 0 0 1 1 1 1 0 1 0 1 1 1 0 1 0 1 1 0 0 0 1\n",
            " 1 1 1 1 1 1 0 1 0 1 1 1 0 0 1 0 0 0 1 1 0 0 0 1 0 1 1 0 0 0 0 0 0 1 0 1 0\n",
            " 0 1 1 1 1 0 1 1 1 0 1 1 0 0 1 1 1 0 1 0 0 1 1 0 1 1 1 0 1 1 1 0 0 0 0 1 0\n",
            " 1 0 1 0 1 1 1 0 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 0 0 1 0 0 1 1 1 1 1 1 0 1 0\n",
            " 0 1 1 1 0 1 0 1 1 0 1 1 1 0 1 1 1 0 0 1 1 1 0 1 0 1 1 0 0 1 0 1 0 1 1 1 0\n",
            " 1 0 1 1 1 1 1 0 1 0 1 0 1 0 1 0 1 1 1 1 0 0 1 0 1 1 0 1 0 1 1 0 0 1 1 1 0\n",
            " 1 1 1 1 0 1 1 1 1 0 1 1 1 0 0 1 0 1 0 1 0 0 0 1 1 1 0 1 1 1 1 1 0 0 0 1 0\n",
            " 1 1 1 1 1 1 0 1 0 1 1 1 0 1 0 0 1 0 1 0 1 1 1 1 1 1 1 1 0 0 0 0 0 1 1 1 0\n",
            " 1 0 0 0 1 0 0 1 0 1 0 0 0 0 1 0 1 0 1 0 0 0 0 1 0 0 1 0 1 1 1 0 0 1 0 1 1\n",
            " 0 0 1 0 1 1 1 0 1 0 1 1 0 0 0 1 1 0 1 1 1 1 0 1 0 0 1 0 1 0 0 0 1 1 0 0 1\n",
            " 1 0 1 1 1 1 0 1 1 1 0 0 0 1 1 0 1 1 1 1 1 0 0 0 1 0 1 0 1 1 0 1 1 0 1 0 0\n",
            " 0 0 1 0 0 1 0 1 1 1 0 0 0 1 1 0 1 1 1 1 1 0 0 0 1 1 1 1 1 1 0 0 1 0 1 0 0\n",
            " 1 0 1 1 0 1 1 0 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 0 0 0 0 1 1 0 1 0 0 1 0 1 0\n",
            " 1 1 0 1 0 1 0 0 1 1 0 1 1 0 1 1 0 0 1 0 0 1 1 0 1 0 1 0 1 0 1 1 1 0 1 1 0\n",
            " 0 0 0 1 0 0 0 1 0 1 1 1 0 0]\n",
            "uniques chosen: 25 <= should be equal to: 25\n",
            "trainset before adding uncertain samples (400, 10) (400,)\n",
            "trainset after adding uncertain samples (425, 10) (425,)\n",
            "updated train set: (425, 10) (425,) unique(labels): [196 229] [0 1]\n",
            "val set: (877, 10) (877,)\n",
            "\n",
            "Train set: (425, 10)\n",
            "Validation set: (877, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 17\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.098 s \n",
            "\n",
            "Accuracy rate is 77.419355 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.86      0.85       321\n",
            "           1       0.57      0.52      0.55       113\n",
            "\n",
            "    accuracy                           0.77       434\n",
            "   macro avg       0.70      0.69      0.70       434\n",
            "weighted avg       0.77      0.77      0.77       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[277  44]\n",
            " [ 54  59]]\n",
            "--------------------------------\n",
            "val predicted: (877,) [0 1 0 1 1 1 0 0 1 1 0 1 1 1 1 0 0 1 0 0 1 0 0 0 0 1 1 1 0 1 1 1 0 0 1 0 1\n",
            " 1 0 1 0 0 0 1 1 1 1 1 0 0 1 1 1 0 1 0 0 1 1 1 1 0 0 1 1 1 0 0 1 1 0 0 0 0\n",
            " 1 0 0 1 1 1 0 1 0 0 1 1 0 0 0 0 1 0 0 0 0 1 0 0 1 0 1 1 1 0 0 1 0 0 0 0 0\n",
            " 0 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 1 0 1 0 1 0 1 1 0 1 1 1 0 1 0 0 0 1 1 1 1\n",
            " 1 0 1 1 1 0 0 1 0 0 1 1 0 1 1 1 1 0 0 1 0 0 0 1 1 1 0 0 1 1 0 0 0 0 0 0 1\n",
            " 0 1 0 1 0 1 0 1 1 1 0 0 0 0 0 0 0 1 1 1 1 0 1 0 1 1 1 0 0 1 1 0 0 1 1 1 0\n",
            " 0 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 1 1 1 1 0 0 0 0 1 0 1 1\n",
            " 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 1 1 1 1 0 1 1 1 0 1 0 0 1 1 0 0 1 1 1 1 1\n",
            " 0 1 0 1 0 0 1 0 0 1 1 1 1 1 1 0 1 1 1 0 1 0 1 0 1 1 1 1 1 1 1 1 1 1 0 0 0\n",
            " 1 1 1 1 1 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 0 0 1 0 1 0 1 1 1 0 0 0 0 1 0 1\n",
            " 0 0 1 1 0 0 1 0 0 1 1 1 1 0 1 0 1 1 1 0 1 0 1 1 1 0 0 1 1 1 1 1 1 1 0 1 0\n",
            " 1 1 1 0 0 1 0 0 0 1 1 0 0 0 1 0 1 1 0 0 0 0 0 0 1 0 1 0 0 1 1 1 1 0 1 1 1\n",
            " 0 1 0 0 0 1 1 1 0 1 0 0 1 1 0 1 1 1 0 1 1 1 0 0 0 0 1 0 1 0 1 0 1 1 1 0 1\n",
            " 0 1 1 1 1 0 1 1 0 1 1 1 1 0 0 1 0 0 1 1 1 1 1 1 0 1 0 0 1 1 1 0 1 0 1 1 0\n",
            " 1 1 1 0 1 1 1 0 1 1 1 0 1 0 1 1 0 0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1 0 1 0 1\n",
            " 1 0 1 0 1 1 0 0 1 0 1 1 0 1 0 1 0 0 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 0 0 1\n",
            " 0 1 0 1 0 0 0 1 1 1 0 0 1 1 1 1 0 0 0 1 0 1 1 1 1 1 1 0 1 0 1 1 1 0 1 1 1\n",
            " 0 1 0 1 1 1 1 1 1 1 0 0 0 0 0 1 1 1 0 1 0 0 0 1 0 0 1 0 1 0 0 0 0 1 0 1 0\n",
            " 1 0 0 0 0 1 0 0 1 0 1 1 0 0 1 0 1 1 0 0 1 0 1 1 1 0 1 0 1 1 0 0 0 1 1 0 1\n",
            " 1 1 1 0 1 0 0 1 0 0 0 0 1 1 0 1 1 0 1 1 1 1 1 1 1 1 0 0 0 1 1 0 1 1 1 0 1\n",
            " 0 0 0 1 0 1 0 1 1 0 1 1 0 1 0 0 0 0 1 0 0 1 0 1 1 1 0 0 0 1 1 0 1 1 1 1 1\n",
            " 0 0 0 1 1 1 1 1 1 0 0 1 0 1 0 0 1 0 1 0 1 1 0 1 1 1 1 1 1 1 1 0 1 1 0 1 1\n",
            " 1 0 0 0 0 1 1 0 1 0 0 1 0 1 0 1 1 0 1 0 1 0 0 1 1 0 1 1 0 1 1 0 1 0 0 1 1\n",
            " 0 1 0 1 1 0 1 1 0 1 1 1 0 0 0 1 0 0 0 1 0 1 1 1 0 0]\n",
            "probabilities: (877, 2) \n",
            " [0 1 0 1 1 1 0 0 1 1 0 1 1 1 1 0 0 1 0 0 1 0 0 0 0 1 1 1 0 1 1 1 0 0 1 0 1\n",
            " 1 0 1 0 0 0 1 1 1 1 1 0 0 1 1 1 0 1 0 0 1 1 1 1 0 0 1 1 1 0 0 1 1 0 0 0 0\n",
            " 1 0 0 1 1 1 0 1 0 0 1 1 0 0 0 0 1 0 0 0 0 1 0 0 1 0 1 1 1 0 0 1 0 0 0 0 0\n",
            " 0 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 1 0 1 0 1 0 1 1 0 1 1 1 0 1 0 0 0 1 1 1 1\n",
            " 1 0 1 1 1 0 0 1 0 0 1 1 0 1 1 1 1 0 0 1 0 0 0 1 1 1 0 0 1 1 0 0 0 0 0 0 1\n",
            " 0 1 0 1 0 1 0 1 1 1 0 0 0 0 0 0 0 1 1 1 1 0 1 0 1 1 1 0 0 1 1 0 0 1 1 1 0\n",
            " 0 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 1 1 1 1 0 0 0 0 1 0 1 1\n",
            " 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 1 1 1 1 0 1 1 1 0 1 0 0 1 1 0 0 1 1 1 1 1\n",
            " 0 1 0 1 0 0 1 0 0 1 1 1 1 1 1 0 1 1 1 0 1 0 1 0 1 1 1 1 1 1 1 1 1 1 0 0 0\n",
            " 1 1 1 1 1 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 0 0 1 0 1 0 1 1 1 0 0 0 0 1 0 1\n",
            " 0 0 1 1 0 0 1 0 0 1 1 1 1 0 1 0 1 1 1 0 1 0 1 1 1 0 0 1 1 1 1 1 1 1 0 1 0\n",
            " 1 1 1 0 0 1 0 0 0 1 1 0 0 0 1 0 1 1 0 0 0 0 0 0 1 0 1 0 0 1 1 1 1 0 1 1 1\n",
            " 0 1 0 0 0 1 1 1 0 1 0 0 1 1 0 1 1 1 0 1 1 1 0 0 0 0 1 0 1 0 1 0 1 1 1 0 1\n",
            " 0 1 1 1 1 0 1 1 0 1 1 1 1 0 0 1 0 0 1 1 1 1 1 1 0 1 0 0 1 1 1 0 1 0 1 1 0\n",
            " 1 1 1 0 1 1 1 0 1 1 1 0 1 0 1 1 0 0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1 0 1 0 1\n",
            " 1 0 1 0 1 1 0 0 1 0 1 1 0 1 0 1 0 0 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 0 0 1\n",
            " 0 1 0 1 0 0 0 1 1 1 0 0 1 1 1 1 0 0 0 1 0 1 1 1 1 1 1 0 1 0 1 1 1 0 1 1 1\n",
            " 0 1 0 1 1 1 1 1 1 1 0 0 0 0 0 1 1 1 0 1 0 0 0 1 0 0 1 0 1 0 0 0 0 1 0 1 0\n",
            " 1 0 0 0 0 1 0 0 1 0 1 1 0 0 1 0 1 1 0 0 1 0 1 1 1 0 1 0 1 1 0 0 0 1 1 0 1\n",
            " 1 1 1 0 1 0 0 1 0 0 0 0 1 1 0 1 1 0 1 1 1 1 1 1 1 1 0 0 0 1 1 0 1 1 1 0 1\n",
            " 0 0 0 1 0 1 0 1 1 0 1 1 0 1 0 0 0 0 1 0 0 1 0 1 1 1 0 0 0 1 1 0 1 1 1 1 1\n",
            " 0 0 0 1 1 1 1 1 1 0 0 1 0 1 0 0 1 0 1 0 1 1 0 1 1 1 1 1 1 1 1 0 1 1 0 1 1\n",
            " 1 0 0 0 0 1 1 0 1 0 0 1 0 1 0 1 1 0 1 0 1 0 0 1 1 0 1 1 0 1 1 0 1 0 0 1 1\n",
            " 0 1 0 1 1 0 1 1 0 1 1 1 0 0 0 1 0 0 0 1 0 1 1 1 0 0]\n",
            "uniques chosen: 25 <= should be equal to: 25\n",
            "trainset before adding uncertain samples (425, 10) (425,)\n",
            "trainset after adding uncertain samples (450, 10) (450,)\n",
            "updated train set: (450, 10) (450,) unique(labels): [213 237] [0 1]\n",
            "val set: (852, 10) (852,)\n",
            "\n",
            "Train set: (450, 10)\n",
            "Validation set: (852, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 18\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.062 s \n",
            "\n",
            "Accuracy rate is 79.032258 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86       321\n",
            "           1       0.61      0.54      0.57       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.73      0.71      0.72       434\n",
            "weighted avg       0.78      0.79      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[282  39]\n",
            " [ 52  61]]\n",
            "--------------------------------\n",
            "val predicted: (852,) [0 1 0 1 1 1 0 1 0 1 1 1 1 0 0 1 0 0 1 0 0 0 0 1 1 1 0 1 1 1 0 0 1 0 0 1 0\n",
            " 1 0 0 1 1 1 1 1 0 0 1 1 1 0 1 0 0 1 1 1 1 0 1 1 1 0 0 1 1 0 0 0 0 1 0 0 1\n",
            " 1 1 0 1 0 0 1 1 0 0 0 0 1 0 0 0 0 1 0 0 1 0 1 1 0 0 1 0 0 0 0 0 0 1 0 0 1\n",
            " 0 1 0 0 0 1 1 0 1 1 1 1 0 0 1 0 1 1 0 1 1 1 0 1 0 0 0 1 1 1 1 0 1 1 1 0 0\n",
            " 1 0 0 1 1 0 1 1 1 1 0 0 1 0 0 0 1 1 1 0 0 1 0 0 0 0 0 0 1 1 0 1 0 1 0 1 0\n",
            " 1 1 1 0 0 0 0 0 0 0 1 1 1 1 0 1 0 1 1 1 0 0 1 1 0 0 1 1 1 0 0 1 1 1 0 1 1\n",
            " 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 1 1 1 1 0 0 0 0 1 0 1 1 0 0 0 0 0 1 0 0\n",
            " 0 1 1 0 0 0 0 0 1 1 1 1 0 1 1 1 0 1 0 0 1 1 0 0 1 1 1 1 1 0 1 0 1 0 0 1 0\n",
            " 0 1 1 1 1 1 1 0 1 1 1 0 1 0 1 0 0 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 0 0 1\n",
            " 1 1 0 0 1 0 1 1 1 1 1 1 0 0 1 0 1 0 1 1 1 0 0 0 0 1 0 1 0 0 0 1 0 0 1 0 0\n",
            " 1 1 1 1 0 1 0 1 1 1 0 1 0 1 1 1 0 0 1 1 1 1 1 1 1 0 1 0 1 1 1 0 1 0 0 0 1\n",
            " 1 0 0 0 1 0 1 1 0 0 0 0 0 0 1 0 1 0 0 1 1 1 1 0 1 1 1 0 1 0 0 0 1 1 1 0 1\n",
            " 0 0 1 1 0 1 1 1 0 1 1 1 0 0 0 0 1 0 1 0 1 0 1 1 1 0 1 1 1 1 1 0 1 1 0 1 1\n",
            " 1 1 0 0 1 0 1 1 1 1 1 1 0 1 0 0 1 1 1 0 1 0 1 1 0 1 1 1 0 1 1 1 0 1 1 1 0\n",
            " 1 0 1 1 0 0 1 0 0 1 1 1 1 0 1 1 1 1 1 0 1 0 1 1 0 1 0 1 1 0 0 1 0 1 1 0 1\n",
            " 0 1 0 0 0 1 1 1 1 0 1 1 1 1 0 1 1 1 0 0 1 0 1 0 1 0 0 0 1 1 1 0 0 1 1 1 1\n",
            " 0 0 1 0 1 1 0 1 1 1 0 1 0 1 1 1 0 1 0 1 0 1 0 1 1 1 1 1 1 1 0 0 0 0 1 1 1\n",
            " 0 1 0 0 0 1 0 0 1 0 1 0 0 0 0 1 0 1 0 1 0 0 0 0 1 0 0 1 0 1 1 0 0 1 0 1 1\n",
            " 0 0 1 0 1 1 1 0 1 0 1 1 0 0 0 1 1 0 1 1 1 1 0 1 0 0 0 0 0 1 1 1 1 1 0 1 1\n",
            " 1 1 1 1 1 0 0 0 1 1 0 1 1 1 0 1 0 0 0 1 0 1 0 1 1 0 1 1 0 1 0 0 0 0 1 0 0\n",
            " 1 0 1 1 1 0 0 0 1 1 0 1 1 1 1 1 0 0 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 1 1 0\n",
            " 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 0 0 0 0 1 1 1 0 0 1 0 1 0 1 1 0 1 0 1 0 0 1\n",
            " 1 0 1 1 0 1 1 0 1 0 0 1 0 0 1 0 1 1 0 1 1 0 1 1 1 0 0 1 0 0 0 1 0 1 1 1 0\n",
            " 0]\n",
            "probabilities: (852, 2) \n",
            " [0 1 0 1 1 1 0 1 0 1 1 1 1 0 0 1 0 0 1 0 0 0 0 1 1 1 0 1 1 1 0 0 1 0 0 1 0\n",
            " 1 0 0 1 1 1 1 1 0 0 1 1 1 0 1 0 0 1 1 1 1 0 1 1 1 0 0 1 1 0 0 0 0 1 0 0 1\n",
            " 1 1 0 1 0 0 1 1 0 0 0 0 1 0 0 0 0 1 0 0 1 0 1 1 0 0 1 0 0 0 0 0 0 1 0 0 1\n",
            " 0 1 0 0 0 1 1 0 1 1 1 1 0 0 1 0 1 1 0 1 1 1 0 1 0 0 0 1 1 1 1 0 1 1 1 0 0\n",
            " 1 0 0 1 1 0 1 1 1 1 0 0 1 0 0 0 1 1 1 0 0 1 0 0 0 0 0 0 1 1 0 1 0 1 0 1 0\n",
            " 1 1 1 0 0 0 0 0 0 0 1 1 1 1 0 1 0 1 1 1 0 0 1 1 0 0 1 1 1 0 0 1 1 1 0 1 1\n",
            " 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 1 1 1 1 0 0 0 0 1 0 1 1 0 0 0 0 0 1 0 0\n",
            " 0 1 1 0 0 0 0 0 1 1 1 1 0 1 1 1 0 1 0 0 1 1 0 0 1 1 1 1 1 0 1 0 1 0 0 1 0\n",
            " 0 1 1 1 1 1 1 0 1 1 1 0 1 0 1 0 0 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 0 0 1\n",
            " 1 1 0 0 1 0 1 1 1 1 1 1 0 0 1 0 1 0 1 1 1 0 0 0 0 1 0 1 0 0 0 1 0 0 1 0 0\n",
            " 1 1 1 1 0 1 0 1 1 1 0 1 0 1 1 1 0 0 1 1 1 1 1 1 1 0 1 0 1 1 1 0 1 0 0 0 1\n",
            " 1 0 0 0 1 0 1 1 0 0 0 0 0 0 1 0 1 0 0 1 1 1 1 0 1 1 1 0 1 0 0 0 1 1 1 0 1\n",
            " 0 0 1 1 0 1 1 1 0 1 1 1 0 0 0 0 1 0 1 0 1 0 1 1 1 0 1 1 1 1 1 0 1 1 0 1 1\n",
            " 1 1 0 0 1 0 1 1 1 1 1 1 0 1 0 0 1 1 1 0 1 0 1 1 0 1 1 1 0 1 1 1 0 1 1 1 0\n",
            " 1 0 1 1 0 0 1 0 0 1 1 1 1 0 1 1 1 1 1 0 1 0 1 1 0 1 0 1 1 0 0 1 0 1 1 0 1\n",
            " 0 1 0 0 0 1 1 1 1 0 1 1 1 1 0 1 1 1 0 0 1 0 1 0 1 0 0 0 1 1 1 0 0 1 1 1 1\n",
            " 0 0 1 0 1 1 0 1 1 1 0 1 0 1 1 1 0 1 0 1 0 1 0 1 1 1 1 1 1 1 0 0 0 0 1 1 1\n",
            " 0 1 0 0 0 1 0 0 1 0 1 0 0 0 0 1 0 1 0 1 0 0 0 0 1 0 0 1 0 1 1 0 0 1 0 1 1\n",
            " 0 0 1 0 1 1 1 0 1 0 1 1 0 0 0 1 1 0 1 1 1 1 0 1 0 0 0 0 0 1 1 1 1 1 0 1 1\n",
            " 1 1 1 1 1 0 0 0 1 1 0 1 1 1 0 1 0 0 0 1 0 1 0 1 1 0 1 1 0 1 0 0 0 0 1 0 0\n",
            " 1 0 1 1 1 0 0 0 1 1 0 1 1 1 1 1 0 0 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 1 1 0\n",
            " 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 0 0 0 0 1 1 1 0 0 1 0 1 0 1 1 0 1 0 1 0 0 1\n",
            " 1 0 1 1 0 1 1 0 1 0 0 1 0 0 1 0 1 1 0 1 1 0 1 1 1 0 0 1 0 0 0 1 0 1 1 1 0\n",
            " 0]\n",
            "uniques chosen: 25 <= should be equal to: 25\n",
            "trainset before adding uncertain samples (450, 10) (450,)\n",
            "trainset after adding uncertain samples (475, 10) (475,)\n",
            "updated train set: (475, 10) (475,) unique(labels): [223 252] [0 1]\n",
            "val set: (827, 10) (827,)\n",
            "\n",
            "Train set: (475, 10)\n",
            "Validation set: (827, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 19\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.061 s \n",
            "\n",
            "Accuracy rate is 78.571429 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86       321\n",
            "           1       0.60      0.52      0.56       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.72      0.70      0.71       434\n",
            "weighted avg       0.78      0.79      0.78       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[282  39]\n",
            " [ 54  59]]\n",
            "--------------------------------\n",
            "val predicted: (827,) [0 1 0 1 0 1 0 1 0 1 1 1 1 0 0 1 0 0 1 0 0 0 0 1 1 1 0 1 0 1 0 0 1 0 0 1 0\n",
            " 1 0 1 1 1 1 1 0 0 1 1 1 0 1 0 0 1 1 1 1 0 1 1 1 0 0 1 1 0 0 0 0 1 0 0 1 1\n",
            " 1 0 1 0 0 1 1 0 0 0 0 1 0 0 0 0 1 0 0 1 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 0 1\n",
            " 0 0 0 1 0 1 1 1 1 0 0 1 0 1 1 0 1 1 0 0 1 0 0 0 1 1 1 0 1 1 1 0 0 1 0 0 1\n",
            " 1 0 1 1 1 1 0 0 1 0 0 0 1 1 1 0 0 1 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 1 1 1 0\n",
            " 0 0 0 0 0 0 1 1 1 1 0 1 0 1 1 1 0 0 1 1 0 0 1 1 1 0 0 1 1 0 1 1 1 0 1 1 1\n",
            " 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 0 0 0 0 1 0 1 1 0 0 0 0 0 1 0 0 0 1 1 0 0 0\n",
            " 0 0 1 1 1 1 0 1 1 1 0 1 0 0 1 1 1 0 1 1 1 1 1 0 1 0 1 0 0 1 0 0 1 1 1 1 1\n",
            " 0 1 1 1 0 1 0 1 0 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1\n",
            " 1 1 1 1 1 0 0 1 0 1 0 1 1 1 0 0 0 0 1 0 1 0 0 0 1 0 0 1 1 0 1 1 1 1 0 1 0\n",
            " 1 1 1 0 1 0 1 1 1 0 0 1 1 1 1 1 1 0 1 0 1 1 1 0 1 0 0 0 1 1 0 0 0 1 0 1 1\n",
            " 0 0 0 0 0 0 1 0 1 0 0 1 1 1 1 1 1 1 0 1 0 0 0 1 1 1 0 1 0 0 1 1 0 1 1 1 0\n",
            " 1 1 1 0 0 0 1 0 1 0 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 0 1 0 1 1 1 1 1 1 0\n",
            " 1 0 0 1 1 1 0 1 1 1 0 1 1 1 0 1 1 1 0 1 1 1 0 1 0 1 1 0 0 1 0 0 1 1 1 1 0\n",
            " 1 1 1 1 1 1 0 1 1 0 1 0 1 1 0 0 1 0 1 1 0 1 0 1 0 1 1 1 1 1 1 0 1 1 1 1 0\n",
            " 1 1 1 0 0 1 0 1 0 1 0 0 0 1 1 1 0 0 1 1 1 1 0 0 1 0 1 1 0 1 0 1 0 1 0 1 1\n",
            " 1 0 1 0 1 0 1 0 1 1 1 1 1 1 0 0 0 0 1 1 1 0 1 0 0 0 1 0 0 1 0 1 0 0 1 0 1\n",
            " 0 0 0 1 0 0 0 0 1 0 0 1 0 1 1 0 0 1 0 0 1 0 1 1 1 0 1 0 1 1 0 0 0 1 1 0 1\n",
            " 1 1 1 0 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 0 1 1 0 1 0 0 0 1 0\n",
            " 1 0 1 1 0 1 0 1 0 0 0 0 1 0 0 1 0 1 1 1 0 0 0 1 1 0 1 1 1 1 1 0 0 1 1 1 1\n",
            " 1 1 0 1 0 1 0 0 1 0 1 0 1 1 0 1 1 1 1 1 1 1 0 1 1 0 1 1 1 0 0 0 0 1 1 1 0\n",
            " 0 1 0 1 0 1 1 0 1 0 1 0 0 1 1 1 1 0 1 0 1 0 0 1 0 0 1 0 1 1 0 1 1 0 1 1 1\n",
            " 0 0 1 1 0 0 1 0 1 1 1 0 0]\n",
            "probabilities: (827, 2) \n",
            " [0 1 0 1 0 1 0 1 0 1 1 1 1 0 0 1 0 0 1 0 0 0 0 1 1 1 0 1 0 1 0 0 1 0 0 1 0\n",
            " 1 0 1 1 1 1 1 0 0 1 1 1 0 1 0 0 1 1 1 1 0 1 1 1 0 0 1 1 0 0 0 0 1 0 0 1 1\n",
            " 1 0 1 0 0 1 1 0 0 0 0 1 0 0 0 0 1 0 0 1 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 0 1\n",
            " 0 0 0 1 0 1 1 1 1 0 0 1 0 1 1 0 1 1 0 0 1 0 0 0 1 1 1 0 1 1 1 0 0 1 0 0 1\n",
            " 1 0 1 1 1 1 0 0 1 0 0 0 1 1 1 0 0 1 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 1 1 1 0\n",
            " 0 0 0 0 0 0 1 1 1 1 0 1 0 1 1 1 0 0 1 1 0 0 1 1 1 0 0 1 1 0 1 1 1 0 1 1 1\n",
            " 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 0 0 0 0 1 0 1 1 0 0 0 0 0 1 0 0 0 1 1 0 0 0\n",
            " 0 0 1 1 1 1 0 1 1 1 0 1 0 0 1 1 1 0 1 1 1 1 1 0 1 0 1 0 0 1 0 0 1 1 1 1 1\n",
            " 0 1 1 1 0 1 0 1 0 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1\n",
            " 1 1 1 1 1 0 0 1 0 1 0 1 1 1 0 0 0 0 1 0 1 0 0 0 1 0 0 1 1 0 1 1 1 1 0 1 0\n",
            " 1 1 1 0 1 0 1 1 1 0 0 1 1 1 1 1 1 0 1 0 1 1 1 0 1 0 0 0 1 1 0 0 0 1 0 1 1\n",
            " 0 0 0 0 0 0 1 0 1 0 0 1 1 1 1 1 1 1 0 1 0 0 0 1 1 1 0 1 0 0 1 1 0 1 1 1 0\n",
            " 1 1 1 0 0 0 1 0 1 0 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 0 1 0 1 1 1 1 1 1 0\n",
            " 1 0 0 1 1 1 0 1 1 1 0 1 1 1 0 1 1 1 0 1 1 1 0 1 0 1 1 0 0 1 0 0 1 1 1 1 0\n",
            " 1 1 1 1 1 1 0 1 1 0 1 0 1 1 0 0 1 0 1 1 0 1 0 1 0 1 1 1 1 1 1 0 1 1 1 1 0\n",
            " 1 1 1 0 0 1 0 1 0 1 0 0 0 1 1 1 0 0 1 1 1 1 0 0 1 0 1 1 0 1 0 1 0 1 0 1 1\n",
            " 1 0 1 0 1 0 1 0 1 1 1 1 1 1 0 0 0 0 1 1 1 0 1 0 0 0 1 0 0 1 0 1 0 0 1 0 1\n",
            " 0 0 0 1 0 0 0 0 1 0 0 1 0 1 1 0 0 1 0 0 1 0 1 1 1 0 1 0 1 1 0 0 0 1 1 0 1\n",
            " 1 1 1 0 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 0 1 1 0 1 0 0 0 1 0\n",
            " 1 0 1 1 0 1 0 1 0 0 0 0 1 0 0 1 0 1 1 1 0 0 0 1 1 0 1 1 1 1 1 0 0 1 1 1 1\n",
            " 1 1 0 1 0 1 0 0 1 0 1 0 1 1 0 1 1 1 1 1 1 1 0 1 1 0 1 1 1 0 0 0 0 1 1 1 0\n",
            " 0 1 0 1 0 1 1 0 1 0 1 0 0 1 1 1 1 0 1 0 1 0 0 1 0 0 1 0 1 1 0 1 1 0 1 1 1\n",
            " 0 0 1 1 0 0 1 0 1 1 1 0 0]\n",
            "uniques chosen: 25 <= should be equal to: 25\n",
            "trainset before adding uncertain samples (475, 10) (475,)\n",
            "trainset after adding uncertain samples (500, 10) (500,)\n",
            "updated train set: (500, 10) (500,) unique(labels): [237 263] [0 1]\n",
            "val set: (802, 10) (802,)\n",
            "\n",
            "Train set: (500, 10)\n",
            "Validation set: (802, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 20\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.052 s \n",
            "\n",
            "Accuracy rate is 79.262673 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.88      0.86       321\n",
            "           1       0.61      0.56      0.58       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.73      0.72      0.72       434\n",
            "weighted avg       0.79      0.79      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[281  40]\n",
            " [ 50  63]]\n",
            "--------------------------------\n",
            "final active learning accuracies [71.88940092165899, 77.41935483870968, 74.19354838709677, 76.26728110599078, 77.41935483870968, 78.11059907834101, 77.64976958525345, 78.57142857142857, 78.80184331797236, 78.57142857142857, 78.80184331797236, 77.41935483870968, 77.18894009216591, 77.88018433179722, 78.11059907834101, 78.11059907834101, 77.41935483870968, 79.03225806451613, 78.57142857142857, 79.26267281105991]\n",
            "saved /Users/wenxuanhuang/Documents/Repo/ML-for-COVID-19-dataset/Results/Active-learning-experiment-24.pkl /Users/wenxuanhuang/Documents/Repo/ML-for-COVID-19-dataset ['Decision_tree.ipynb', 'dec_git.png', 'Logit_default_f10.pdf', 'Logistic.ipynb', 'SVC.ipynb', 'RF_f5e50_featureimp.pdf', 'log_al.png', 'dec_git.pdf', '.DS_Store', 'log_git.png', 'svm_git.png', 'Logistic_Scikit.ipynb', 'knn_git.pdf', 'knn_git.png', 'rf_al.png', 'Best classifier_RF_f5e50.pdf', 'KNN.ipynb', 'GBDC.ipynb', 'rf_git.png', 'README.md', 'all_training.csv', 'Results', 'svm_al.png', 'Log_ROC.png', 'Logit_default_f7(p_removal).pdf', 'Active_learning.ipynb', 'Random_forest.ipynb', 'Model_select.ipynb', 'gdbc_git.png', '.git', '.vscode', 'Untitled', 'RF_f5e50_modelselect.pdf', 'Logit_default_f8(std_removal).pdf']\n",
            "\n",
            "---------------------------- FINISHED ---------------------------\n",
            "\n",
            "Count = 25, using model = KnnModel, selection_function = RandomSelection, k = 10, iteration = 0.\n",
            "\n",
            "initial random chosen samples (10,)\n",
            "initial train set: (10, 10) (10,) unique(labels): [2 8] [0 1]\n",
            "Val set: (1292, 10) (1292,) (10,)\n",
            "\n",
            "Train set: (10, 10)\n",
            "Validation set: (1292, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.084 s \n",
            "\n",
            "Accuracy rate is 26.036866 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       321\n",
            "           1       0.26      1.00      0.41       113\n",
            "\n",
            "    accuracy                           0.26       434\n",
            "   macro avg       0.13      0.50      0.21       434\n",
            "weighted avg       0.07      0.26      0.11       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[  0 321]\n",
            " [  0 113]]\n",
            "--------------------------------\n",
            "val predicted: (1292,) [1 1 1 ... 1 1 1]\n",
            "probabilities: (1292, 2) \n",
            " [1 1 1 ... 1 1 1]\n",
            "uniques chosen: 10 <= should be equal to: 10\n",
            "trainset before adding uncertain samples (10, 10) (10,)\n",
            "trainset after adding uncertain samples (20, 10) (20,)\n",
            "updated train set: (20, 10) (20,) unique(labels): [ 8 12] [0 1]\n",
            "val set: (1282, 10) (1282,)\n",
            "\n",
            "Train set: (20, 10)\n",
            "Validation set: (1282, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.075 s \n",
            "\n",
            "Accuracy rate is 63.594470 \n",
            "/Users/wenxuanhuang/Library/Python/3.8/lib/python/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/Users/wenxuanhuang/Library/Python/3.8/lib/python/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/Users/wenxuanhuang/Library/Python/3.8/lib/python/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.66      0.73       321\n",
            "           1       0.37      0.57      0.45       113\n",
            "\n",
            "    accuracy                           0.64       434\n",
            "   macro avg       0.59      0.61      0.59       434\n",
            "weighted avg       0.70      0.64      0.66       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[212 109]\n",
            " [ 49  64]]\n",
            "--------------------------------\n",
            "val predicted: (1282,) [1 1 1 ... 0 0 0]\n",
            "probabilities: (1282, 2) \n",
            " [1 1 1 ... 0 0 0]\n",
            "uniques chosen: 10 <= should be equal to: 10\n",
            "trainset before adding uncertain samples (20, 10) (20,)\n",
            "trainset after adding uncertain samples (30, 10) (30,)\n",
            "updated train set: (30, 10) (30,) unique(labels): [15 15] [0 1]\n",
            "val set: (1272, 10) (1272,)\n",
            "\n",
            "Train set: (30, 10)\n",
            "Validation set: (1272, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 3\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.089 s \n",
            "\n",
            "Accuracy rate is 72.580645 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.88      0.83       321\n",
            "           1       0.46      0.30      0.36       113\n",
            "\n",
            "    accuracy                           0.73       434\n",
            "   macro avg       0.62      0.59      0.59       434\n",
            "weighted avg       0.70      0.73      0.71       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[281  40]\n",
            " [ 79  34]]\n",
            "--------------------------------\n",
            "val predicted: (1272,) [0 0 0 ... 0 0 0]\n",
            "probabilities: (1272, 2) \n",
            " [0 0 0 ... 0 0 0]\n",
            "uniques chosen: 10 <= should be equal to: 10\n",
            "trainset before adding uncertain samples (30, 10) (30,)\n",
            "trainset after adding uncertain samples (40, 10) (40,)\n",
            "updated train set: (40, 10) (40,) unique(labels): [19 21] [0 1]\n",
            "val set: (1262, 10) (1262,)\n",
            "\n",
            "Train set: (40, 10)\n",
            "Validation set: (1262, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 4\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.087 s \n",
            "\n",
            "Accuracy rate is 75.806452 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.92      0.85       321\n",
            "           1       0.56      0.31      0.40       113\n",
            "\n",
            "    accuracy                           0.76       434\n",
            "   macro avg       0.68      0.61      0.62       434\n",
            "weighted avg       0.73      0.76      0.73       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[294  27]\n",
            " [ 78  35]]\n",
            "--------------------------------\n",
            "val predicted: (1262,) [0 1 0 ... 0 0 0]\n",
            "probabilities: (1262, 2) \n",
            " [0 1 0 ... 0 0 0]\n",
            "uniques chosen: 10 <= should be equal to: 10\n",
            "trainset before adding uncertain samples (40, 10) (40,)\n",
            "trainset after adding uncertain samples (50, 10) (50,)\n",
            "updated train set: (50, 10) (50,) unique(labels): [22 28] [0 1]\n",
            "val set: (1252, 10) (1252,)\n",
            "\n",
            "Train set: (50, 10)\n",
            "Validation set: (1252, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 5\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.067 s \n",
            "\n",
            "Accuracy rate is 73.732719 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.85      0.83       321\n",
            "           1       0.49      0.42      0.45       113\n",
            "\n",
            "    accuracy                           0.74       434\n",
            "   macro avg       0.65      0.63      0.64       434\n",
            "weighted avg       0.72      0.74      0.73       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[273  48]\n",
            " [ 66  47]]\n",
            "--------------------------------\n",
            "val predicted: (1252,) [0 1 0 ... 0 0 0]\n",
            "probabilities: (1252, 2) \n",
            " [0 1 0 ... 0 0 0]\n",
            "uniques chosen: 10 <= should be equal to: 10\n",
            "trainset before adding uncertain samples (50, 10) (50,)\n",
            "trainset after adding uncertain samples (60, 10) (60,)\n",
            "updated train set: (60, 10) (60,) unique(labels): [28 32] [0 1]\n",
            "val set: (1242, 10) (1242,)\n",
            "\n",
            "Train set: (60, 10)\n",
            "Validation set: (1242, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 6\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.064 s \n",
            "\n",
            "Accuracy rate is 75.806452 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.86      0.84       321\n",
            "           1       0.54      0.48      0.51       113\n",
            "\n",
            "    accuracy                           0.76       434\n",
            "   macro avg       0.68      0.67      0.67       434\n",
            "weighted avg       0.75      0.76      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[275  46]\n",
            " [ 59  54]]\n",
            "--------------------------------\n",
            "val predicted: (1242,) [0 1 0 ... 0 0 0]\n",
            "probabilities: (1242, 2) \n",
            " [0 1 0 ... 0 0 0]\n",
            "uniques chosen: 10 <= should be equal to: 10\n",
            "trainset before adding uncertain samples (60, 10) (60,)\n",
            "trainset after adding uncertain samples (70, 10) (70,)\n",
            "updated train set: (70, 10) (70,) unique(labels): [35 35] [0 1]\n",
            "val set: (1232, 10) (1232,)\n",
            "\n",
            "Train set: (70, 10)\n",
            "Validation set: (1232, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 7\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.074 s \n",
            "\n",
            "Accuracy rate is 76.267281 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.88      0.85       321\n",
            "           1       0.56      0.42      0.48       113\n",
            "\n",
            "    accuracy                           0.76       434\n",
            "   macro avg       0.69      0.65      0.66       434\n",
            "weighted avg       0.75      0.76      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[284  37]\n",
            " [ 66  47]]\n",
            "--------------------------------\n",
            "val predicted: (1232,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1232, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "uniques chosen: 10 <= should be equal to: 10\n",
            "trainset before adding uncertain samples (70, 10) (70,)\n",
            "trainset after adding uncertain samples (80, 10) (80,)\n",
            "updated train set: (80, 10) (80,) unique(labels): [38 42] [0 1]\n",
            "val set: (1222, 10) (1222,)\n",
            "\n",
            "Train set: (80, 10)\n",
            "Validation set: (1222, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 8\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.061 s \n",
            "\n",
            "Accuracy rate is 76.036866 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.86      0.84       321\n",
            "           1       0.55      0.48      0.51       113\n",
            "\n",
            "    accuracy                           0.76       434\n",
            "   macro avg       0.68      0.67      0.68       434\n",
            "weighted avg       0.75      0.76      0.76       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[276  45]\n",
            " [ 59  54]]\n",
            "--------------------------------\n",
            "val predicted: (1222,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1222, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "uniques chosen: 10 <= should be equal to: 10\n",
            "trainset before adding uncertain samples (80, 10) (80,)\n",
            "trainset after adding uncertain samples (90, 10) (90,)\n",
            "updated train set: (90, 10) (90,) unique(labels): [42 48] [0 1]\n",
            "val set: (1212, 10) (1212,)\n",
            "\n",
            "Train set: (90, 10)\n",
            "Validation set: (1212, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 9\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.063 s \n",
            "\n",
            "Accuracy rate is 76.728111 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.86      0.85       321\n",
            "           1       0.56      0.50      0.53       113\n",
            "\n",
            "    accuracy                           0.77       434\n",
            "   macro avg       0.70      0.68      0.69       434\n",
            "weighted avg       0.76      0.77      0.76       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[276  45]\n",
            " [ 56  57]]\n",
            "--------------------------------\n",
            "val predicted: (1212,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1212, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "uniques chosen: 10 <= should be equal to: 10\n",
            "trainset before adding uncertain samples (90, 10) (90,)\n",
            "trainset after adding uncertain samples (100, 10) (100,)\n",
            "updated train set: (100, 10) (100,) unique(labels): [45 55] [0 1]\n",
            "val set: (1202, 10) (1202,)\n",
            "\n",
            "Train set: (100, 10)\n",
            "Validation set: (1202, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 10\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.069 s \n",
            "\n",
            "Accuracy rate is 77.188940 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.86      0.85       321\n",
            "           1       0.57      0.52      0.54       113\n",
            "\n",
            "    accuracy                           0.77       434\n",
            "   macro avg       0.70      0.69      0.70       434\n",
            "weighted avg       0.77      0.77      0.77       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[276  45]\n",
            " [ 54  59]]\n",
            "--------------------------------\n",
            "val predicted: (1202,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1202, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "uniques chosen: 10 <= should be equal to: 10\n",
            "trainset before adding uncertain samples (100, 10) (100,)\n",
            "trainset after adding uncertain samples (110, 10) (110,)\n",
            "updated train set: (110, 10) (110,) unique(labels): [47 63] [0 1]\n",
            "val set: (1192, 10) (1192,)\n",
            "\n",
            "Train set: (110, 10)\n",
            "Validation set: (1192, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 11\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.064 s \n",
            "\n",
            "Accuracy rate is 76.497696 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.84      0.84       321\n",
            "           1       0.55      0.55      0.55       113\n",
            "\n",
            "    accuracy                           0.76       434\n",
            "   macro avg       0.69      0.69      0.69       434\n",
            "weighted avg       0.76      0.76      0.76       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[270  51]\n",
            " [ 51  62]]\n",
            "--------------------------------\n",
            "val predicted: (1192,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1192, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "uniques chosen: 10 <= should be equal to: 10\n",
            "trainset before adding uncertain samples (110, 10) (110,)\n",
            "trainset after adding uncertain samples (120, 10) (120,)\n",
            "updated train set: (120, 10) (120,) unique(labels): [50 70] [0 1]\n",
            "val set: (1182, 10) (1182,)\n",
            "\n",
            "Train set: (120, 10)\n",
            "Validation set: (1182, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 12\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.070 s \n",
            "\n",
            "Accuracy rate is 74.884793 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.82      0.83       321\n",
            "           1       0.52      0.54      0.53       113\n",
            "\n",
            "    accuracy                           0.75       434\n",
            "   macro avg       0.68      0.68      0.68       434\n",
            "weighted avg       0.75      0.75      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[264  57]\n",
            " [ 52  61]]\n",
            "--------------------------------\n",
            "val predicted: (1182,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1182, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "uniques chosen: 10 <= should be equal to: 10\n",
            "trainset before adding uncertain samples (120, 10) (120,)\n",
            "trainset after adding uncertain samples (130, 10) (130,)\n",
            "updated train set: (130, 10) (130,) unique(labels): [54 76] [0 1]\n",
            "val set: (1172, 10) (1172,)\n",
            "\n",
            "Train set: (130, 10)\n",
            "Validation set: (1172, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 13\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.066 s \n",
            "\n",
            "Accuracy rate is 77.419355 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.85      0.85       321\n",
            "           1       0.57      0.55      0.56       113\n",
            "\n",
            "    accuracy                           0.77       434\n",
            "   macro avg       0.71      0.70      0.70       434\n",
            "weighted avg       0.77      0.77      0.77       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[274  47]\n",
            " [ 51  62]]\n",
            "--------------------------------\n",
            "val predicted: (1172,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1172, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "uniques chosen: 10 <= should be equal to: 10\n",
            "trainset before adding uncertain samples (130, 10) (130,)\n",
            "trainset after adding uncertain samples (140, 10) (140,)\n",
            "updated train set: (140, 10) (140,) unique(labels): [59 81] [0 1]\n",
            "val set: (1162, 10) (1162,)\n",
            "\n",
            "Train set: (140, 10)\n",
            "Validation set: (1162, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 14\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.066 s \n",
            "\n",
            "Accuracy rate is 76.497696 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.83      0.84       321\n",
            "           1       0.55      0.57      0.56       113\n",
            "\n",
            "    accuracy                           0.76       434\n",
            "   macro avg       0.70      0.70      0.70       434\n",
            "weighted avg       0.77      0.76      0.77       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[268  53]\n",
            " [ 49  64]]\n",
            "--------------------------------\n",
            "val predicted: (1162,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1162, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "uniques chosen: 10 <= should be equal to: 10\n",
            "trainset before adding uncertain samples (140, 10) (140,)\n",
            "trainset after adding uncertain samples (150, 10) (150,)\n",
            "updated train set: (150, 10) (150,) unique(labels): [64 86] [0 1]\n",
            "val set: (1152, 10) (1152,)\n",
            "\n",
            "Train set: (150, 10)\n",
            "Validation set: (1152, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 15\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.077 s \n",
            "\n",
            "Accuracy rate is 76.958525 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.83      0.84       321\n",
            "           1       0.55      0.58      0.57       113\n",
            "\n",
            "    accuracy                           0.77       434\n",
            "   macro avg       0.70      0.71      0.71       434\n",
            "weighted avg       0.77      0.77      0.77       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[268  53]\n",
            " [ 47  66]]\n",
            "--------------------------------\n",
            "val predicted: (1152,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1152, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "uniques chosen: 10 <= should be equal to: 10\n",
            "trainset before adding uncertain samples (150, 10) (150,)\n",
            "trainset after adding uncertain samples (160, 10) (160,)\n",
            "updated train set: (160, 10) (160,) unique(labels): [67 93] [0 1]\n",
            "val set: (1142, 10) (1142,)\n",
            "\n",
            "Train set: (160, 10)\n",
            "Validation set: (1142, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 16\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.061 s \n",
            "\n",
            "Accuracy rate is 76.728111 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.83      0.84       321\n",
            "           1       0.55      0.59      0.57       113\n",
            "\n",
            "    accuracy                           0.77       434\n",
            "   macro avg       0.70      0.71      0.71       434\n",
            "weighted avg       0.77      0.77      0.77       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[266  55]\n",
            " [ 46  67]]\n",
            "--------------------------------\n",
            "val predicted: (1142,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1142, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "uniques chosen: 10 <= should be equal to: 10\n",
            "trainset before adding uncertain samples (160, 10) (160,)\n",
            "trainset after adding uncertain samples (170, 10) (170,)\n",
            "updated train set: (170, 10) (170,) unique(labels): [71 99] [0 1]\n",
            "val set: (1132, 10) (1132,)\n",
            "\n",
            "Train set: (170, 10)\n",
            "Validation set: (1132, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 17\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.092 s \n",
            "\n",
            "Accuracy rate is 78.110599 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.84      0.85       321\n",
            "           1       0.57      0.61      0.59       113\n",
            "\n",
            "    accuracy                           0.78       434\n",
            "   macro avg       0.72      0.73      0.72       434\n",
            "weighted avg       0.79      0.78      0.78       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[270  51]\n",
            " [ 44  69]]\n",
            "--------------------------------\n",
            "val predicted: (1132,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1132, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "uniques chosen: 10 <= should be equal to: 10\n",
            "trainset before adding uncertain samples (170, 10) (170,)\n",
            "trainset after adding uncertain samples (180, 10) (180,)\n",
            "updated train set: (180, 10) (180,) unique(labels): [ 76 104] [0 1]\n",
            "val set: (1122, 10) (1122,)\n",
            "\n",
            "Train set: (180, 10)\n",
            "Validation set: (1122, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 18\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.072 s \n",
            "\n",
            "Accuracy rate is 77.649770 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.84      0.85       321\n",
            "           1       0.57      0.59      0.58       113\n",
            "\n",
            "    accuracy                           0.78       434\n",
            "   macro avg       0.71      0.72      0.71       434\n",
            "weighted avg       0.78      0.78      0.78       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[270  51]\n",
            " [ 46  67]]\n",
            "--------------------------------\n",
            "val predicted: (1122,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1122, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "uniques chosen: 10 <= should be equal to: 10\n",
            "trainset before adding uncertain samples (180, 10) (180,)\n",
            "trainset after adding uncertain samples (190, 10) (190,)\n",
            "updated train set: (190, 10) (190,) unique(labels): [ 81 109] [0 1]\n",
            "val set: (1112, 10) (1112,)\n",
            "\n",
            "Train set: (190, 10)\n",
            "Validation set: (1112, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 19\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.073 s \n",
            "\n",
            "Accuracy rate is 78.341014 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.84      0.85       321\n",
            "           1       0.58      0.61      0.59       113\n",
            "\n",
            "    accuracy                           0.78       434\n",
            "   macro avg       0.72      0.73      0.72       434\n",
            "weighted avg       0.79      0.78      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[271  50]\n",
            " [ 44  69]]\n",
            "--------------------------------\n",
            "val predicted: (1112,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1112, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "uniques chosen: 10 <= should be equal to: 10\n",
            "trainset before adding uncertain samples (190, 10) (190,)\n",
            "trainset after adding uncertain samples (200, 10) (200,)\n",
            "updated train set: (200, 10) (200,) unique(labels): [ 86 114] [0 1]\n",
            "val set: (1102, 10) (1102,)\n",
            "\n",
            "Train set: (200, 10)\n",
            "Validation set: (1102, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 20\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.130 s \n",
            "\n",
            "Accuracy rate is 77.188940 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.85      0.85       321\n",
            "           1       0.56      0.55      0.56       113\n",
            "\n",
            "    accuracy                           0.77       434\n",
            "   macro avg       0.70      0.70      0.70       434\n",
            "weighted avg       0.77      0.77      0.77       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[273  48]\n",
            " [ 51  62]]\n",
            "--------------------------------\n",
            "val predicted: (1102,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1102, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "uniques chosen: 10 <= should be equal to: 10\n",
            "trainset before adding uncertain samples (200, 10) (200,)\n",
            "trainset after adding uncertain samples (210, 10) (210,)\n",
            "updated train set: (210, 10) (210,) unique(labels): [ 89 121] [0 1]\n",
            "val set: (1092, 10) (1092,)\n",
            "\n",
            "Train set: (210, 10)\n",
            "Validation set: (1092, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 21\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.086 s \n",
            "\n",
            "Accuracy rate is 78.341014 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.85      0.85       321\n",
            "           1       0.58      0.59      0.59       113\n",
            "\n",
            "    accuracy                           0.78       434\n",
            "   macro avg       0.72      0.72      0.72       434\n",
            "weighted avg       0.78      0.78      0.78       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[273  48]\n",
            " [ 46  67]]\n",
            "--------------------------------\n",
            "val predicted: (1092,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1092, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "uniques chosen: 10 <= should be equal to: 10\n",
            "trainset before adding uncertain samples (210, 10) (210,)\n",
            "trainset after adding uncertain samples (220, 10) (220,)\n",
            "updated train set: (220, 10) (220,) unique(labels): [ 92 128] [0 1]\n",
            "val set: (1082, 10) (1082,)\n",
            "\n",
            "Train set: (220, 10)\n",
            "Validation set: (1082, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 22\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.086 s \n",
            "\n",
            "Accuracy rate is 78.571429 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.86      0.86       321\n",
            "           1       0.59      0.58      0.59       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.72      0.72      0.72       434\n",
            "weighted avg       0.79      0.79      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[275  46]\n",
            " [ 47  66]]\n",
            "--------------------------------\n",
            "val predicted: (1082,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1082, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "uniques chosen: 10 <= should be equal to: 10\n",
            "trainset before adding uncertain samples (220, 10) (220,)\n",
            "trainset after adding uncertain samples (230, 10) (230,)\n",
            "updated train set: (230, 10) (230,) unique(labels): [ 97 133] [0 1]\n",
            "val set: (1072, 10) (1072,)\n",
            "\n",
            "Train set: (230, 10)\n",
            "Validation set: (1072, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 23\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.088 s \n",
            "\n",
            "Accuracy rate is 79.262673 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.87      0.86       321\n",
            "           1       0.61      0.58      0.59       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.73      0.73      0.73       434\n",
            "weighted avg       0.79      0.79      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[278  43]\n",
            " [ 47  66]]\n",
            "--------------------------------\n",
            "val predicted: (1072,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1072, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "uniques chosen: 10 <= should be equal to: 10\n",
            "trainset before adding uncertain samples (230, 10) (230,)\n",
            "trainset after adding uncertain samples (240, 10) (240,)\n",
            "updated train set: (240, 10) (240,) unique(labels): [103 137] [0 1]\n",
            "val set: (1062, 10) (1062,)\n",
            "\n",
            "Train set: (240, 10)\n",
            "Validation set: (1062, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 24\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.078 s \n",
            "\n",
            "Accuracy rate is 78.801843 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.87      0.86       321\n",
            "           1       0.60      0.55      0.57       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.72      0.71      0.72       434\n",
            "weighted avg       0.78      0.79      0.78       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[280  41]\n",
            " [ 51  62]]\n",
            "--------------------------------\n",
            "val predicted: (1062,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1062, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "uniques chosen: 10 <= should be equal to: 10\n",
            "trainset before adding uncertain samples (240, 10) (240,)\n",
            "trainset after adding uncertain samples (250, 10) (250,)\n",
            "updated train set: (250, 10) (250,) unique(labels): [106 144] [0 1]\n",
            "val set: (1052, 10) (1052,)\n",
            "\n",
            "Train set: (250, 10)\n",
            "Validation set: (1052, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 25\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.071 s \n",
            "\n",
            "Accuracy rate is 78.110599 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.87      0.85       321\n",
            "           1       0.59      0.54      0.56       113\n",
            "\n",
            "    accuracy                           0.78       434\n",
            "   macro avg       0.71      0.70      0.71       434\n",
            "weighted avg       0.78      0.78      0.78       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[278  43]\n",
            " [ 52  61]]\n",
            "--------------------------------\n",
            "val predicted: (1052,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1052, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "uniques chosen: 10 <= should be equal to: 10\n",
            "trainset before adding uncertain samples (250, 10) (250,)\n",
            "trainset after adding uncertain samples (260, 10) (260,)\n",
            "updated train set: (260, 10) (260,) unique(labels): [110 150] [0 1]\n",
            "val set: (1042, 10) (1042,)\n",
            "\n",
            "Train set: (260, 10)\n",
            "Validation set: (1042, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 26\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.076 s \n",
            "\n",
            "Accuracy rate is 77.880184 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.86      0.85       321\n",
            "           1       0.58      0.55      0.56       113\n",
            "\n",
            "    accuracy                           0.78       434\n",
            "   macro avg       0.71      0.70      0.71       434\n",
            "weighted avg       0.78      0.78      0.78       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[276  45]\n",
            " [ 51  62]]\n",
            "--------------------------------\n",
            "val predicted: (1042,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1042, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "uniques chosen: 10 <= should be equal to: 10\n",
            "trainset before adding uncertain samples (260, 10) (260,)\n",
            "trainset after adding uncertain samples (270, 10) (270,)\n",
            "updated train set: (270, 10) (270,) unique(labels): [115 155] [0 1]\n",
            "val set: (1032, 10) (1032,)\n",
            "\n",
            "Train set: (270, 10)\n",
            "Validation set: (1032, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 27\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.069 s \n",
            "\n",
            "Accuracy rate is 77.649770 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.86      0.85       321\n",
            "           1       0.57      0.55      0.56       113\n",
            "\n",
            "    accuracy                           0.78       434\n",
            "   macro avg       0.71      0.70      0.71       434\n",
            "weighted avg       0.77      0.78      0.77       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[275  46]\n",
            " [ 51  62]]\n",
            "--------------------------------\n",
            "val predicted: (1032,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1032, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "uniques chosen: 10 <= should be equal to: 10\n",
            "trainset before adding uncertain samples (270, 10) (270,)\n",
            "trainset after adding uncertain samples (280, 10) (280,)\n",
            "updated train set: (280, 10) (280,) unique(labels): [121 159] [0 1]\n",
            "val set: (1022, 10) (1022,)\n",
            "\n",
            "Train set: (280, 10)\n",
            "Validation set: (1022, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 28\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.154 s \n",
            "\n",
            "Accuracy rate is 77.649770 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.86      0.85       321\n",
            "           1       0.58      0.53      0.55       113\n",
            "\n",
            "    accuracy                           0.78       434\n",
            "   macro avg       0.71      0.70      0.70       434\n",
            "weighted avg       0.77      0.78      0.77       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[277  44]\n",
            " [ 53  60]]\n",
            "--------------------------------\n",
            "val predicted: (1022,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1022, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "uniques chosen: 10 <= should be equal to: 10\n",
            "trainset before adding uncertain samples (280, 10) (280,)\n",
            "trainset after adding uncertain samples (290, 10) (290,)\n",
            "updated train set: (290, 10) (290,) unique(labels): [124 166] [0 1]\n",
            "val set: (1012, 10) (1012,)\n",
            "\n",
            "Train set: (290, 10)\n",
            "Validation set: (1012, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 29\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.156 s \n",
            "\n",
            "Accuracy rate is 77.188940 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.86      0.85       321\n",
            "           1       0.57      0.52      0.54       113\n",
            "\n",
            "    accuracy                           0.77       434\n",
            "   macro avg       0.70      0.69      0.70       434\n",
            "weighted avg       0.77      0.77      0.77       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[276  45]\n",
            " [ 54  59]]\n",
            "--------------------------------\n",
            "val predicted: (1012,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1012, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "uniques chosen: 10 <= should be equal to: 10\n",
            "trainset before adding uncertain samples (290, 10) (290,)\n",
            "trainset after adding uncertain samples (300, 10) (300,)\n",
            "updated train set: (300, 10) (300,) unique(labels): [127 173] [0 1]\n",
            "val set: (1002, 10) (1002,)\n",
            "\n",
            "Train set: (300, 10)\n",
            "Validation set: (1002, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 30\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.088 s \n",
            "\n",
            "Accuracy rate is 76.958525 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.85      0.85       321\n",
            "           1       0.56      0.53      0.55       113\n",
            "\n",
            "    accuracy                           0.77       434\n",
            "   macro avg       0.70      0.69      0.70       434\n",
            "weighted avg       0.77      0.77      0.77       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[274  47]\n",
            " [ 53  60]]\n",
            "--------------------------------\n",
            "val predicted: (1002,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1002, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "uniques chosen: 10 <= should be equal to: 10\n",
            "trainset before adding uncertain samples (300, 10) (300,)\n",
            "trainset after adding uncertain samples (310, 10) (310,)\n",
            "updated train set: (310, 10) (310,) unique(labels): [131 179] [0 1]\n",
            "val set: (992, 10) (992,)\n",
            "\n",
            "Train set: (310, 10)\n",
            "Validation set: (992, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 31\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.082 s \n",
            "\n",
            "Accuracy rate is 77.188940 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.86      0.85       321\n",
            "           1       0.57      0.53      0.55       113\n",
            "\n",
            "    accuracy                           0.77       434\n",
            "   macro avg       0.70      0.69      0.70       434\n",
            "weighted avg       0.77      0.77      0.77       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[275  46]\n",
            " [ 53  60]]\n",
            "--------------------------------\n",
            "val predicted: (992,) [0 1 1 1 0 1 0 0 1 1 1 0 1 0 1 0 1 0 1 0 0 1 0 1 0 1 0 1 1 0 1 1 1 1 1 0 0\n",
            " 0 0 0 1 1 0 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1\n",
            " 0 0 1 1 0 1 0 0 0 1 0 0 1 1 0 1 1 1 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 1 1\n",
            " 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 1 1 0 1 0 0 1 1 0 1 1 1 0 1 1 1 1 1 1 0 1 1\n",
            " 0 0 0 1 0 1 1 1 1 0 0 0 0 1 1 1 1 0 1 1 1 1 1 0 0 1 1 0 1 1 1 0 0 0 0 1 0\n",
            " 0 0 1 0 1 1 1 1 0 0 0 0 1 1 0 0 0 1 0 1 0 1 0 1 0 1 1 0 1 1 1 0 0 0 0 0 1\n",
            " 1 0 1 1 0 1 1 0 1 1 1 1 0 0 1 0 1 1 1 1 0 1 1 0 1 1 1 0 1 1 0 1 1 0 1 0 1\n",
            " 1 1 1 1 0 0 1 1 0 1 0 0 1 1 1 1 1 0 0 0 0 0 0 1 0 1 0 0 0 0 1 1 0 1 0 0 0\n",
            " 1 0 0 0 0 0 0 1 1 1 1 0 1 1 0 0 1 0 1 0 0 1 0 0 0 1 1 1 1 1 0 1 1 1 1 0 1\n",
            " 0 1 0 1 0 1 1 0 0 1 1 0 1 0 1 1 0 1 1 0 0 1 1 1 1 1 1 1 1 0 0 1 1 1 0 0 0\n",
            " 1 1 0 0 0 1 1 0 0 1 0 0 0 1 0 1 0 1 1 1 0 1 0 1 0 1 0 1 1 1 1 0 1 1 0 0 0\n",
            " 1 1 1 0 1 1 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 1 1 0 0 1 1 0 1 1 1 1 1 0\n",
            " 0 1 0 1 1 1 0 1 0 1 0 1 1 0 0 0 0 0 1 1 1 1 0 0 0 1 0 1 1 1 0 0 0 0 0 0 1\n",
            " 0 0 0 1 0 1 1 0 1 0 0 0 1 1 1 1 1 1 0 0 1 1 1 1 0 1 0 1 0 0 0 0 1 0 1 1 1\n",
            " 0 1 1 1 0 0 1 1 0 0 0 0 1 0 0 1 0 1 0 1 1 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1 1\n",
            " 1 1 1 0 0 1 1 0 1 1 1 1 1 1 1 0 0 0 0 1 1 1 0 0 0 0 1 0 1 1 1 0 1 1 1 1 0\n",
            " 1 0 0 1 1 0 1 0 0 1 0 1 0 1 0 0 1 0 0 0 1 1 1 0 0 1 1 0 0 0 0 1 0 1 1 0 1\n",
            " 1 0 0 1 1 0 1 1 0 1 1 0 1 0 1 1 0 1 1 0 0 0 0 1 0 1 1 1 1 1 0 0 1 1 1 0 0\n",
            " 1 1 1 1 0 1 0 1 0 0 1 1 0 1 0 0 0 0 1 0 1 1 0 0 0 0 1 0 1 0 1 0 0 1 0 1 0\n",
            " 0 0 1 0 0 1 1 1 1 0 0 0 1 1 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 1\n",
            " 1 1 0 0 0 1 1 0 0 1 0 1 0 0 1 0 0 0 1 1 0 1 1 0 0 0 1 0 0 0 1 0 0 1 1 0 0\n",
            " 0 0 1 1 0 0 1 0 1 1 1 0 0 1 0 1 1 0 0 0 1 0 0 1 1 1 1 0 1 0 1 0 0 0 0 1 1\n",
            " 1 0 1 1 1 0 1 0 0 0 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 0 0 0 0 1 1 0 1 0 0 0 0\n",
            " 0 0 0 0 1 1 0 0 1 1 0 0 1 0 1 1 0 1 1 0 1 0 0 0 0 1 0 1 1 1 0 1 1 0 1 1 1\n",
            " 0 1 1 1 0 1 1 0 1 0 1 0 1 1 0 1 0 1 1 0 0 0 1 1 1 1 0 1 0 1 1 0 1 0 0 0 0\n",
            " 1 0 0 1 0 0 1 0 1 0 1 0 1 1 1 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 0 0 1 0 0\n",
            " 1 0 1 1 0 0 1 0 1 1 0 1 0 0 0 1 1 1 0 0 1 1 0 0 1 1 1 0 0 0]\n",
            "probabilities: (992, 2) \n",
            " [0 1 1 1 0 1 0 0 1 1 1 0 1 0 1 0 1 0 1 0 0 1 0 1 0 1 0 1 1 0 1 1 1 1 1 0 0\n",
            " 0 0 0 1 1 0 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1\n",
            " 0 0 1 1 0 1 0 0 0 1 0 0 1 1 0 1 1 1 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 1 1\n",
            " 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 1 1 0 1 0 0 1 1 0 1 1 1 0 1 1 1 1 1 1 0 1 1\n",
            " 0 0 0 1 0 1 1 1 1 0 0 0 0 1 1 1 1 0 1 1 1 1 1 0 0 1 1 0 1 1 1 0 0 0 0 1 0\n",
            " 0 0 1 0 1 1 1 1 0 0 0 0 1 1 0 0 0 1 0 1 0 1 0 1 0 1 1 0 1 1 1 0 0 0 0 0 1\n",
            " 1 0 1 1 0 1 1 0 1 1 1 1 0 0 1 0 1 1 1 1 0 1 1 0 1 1 1 0 1 1 0 1 1 0 1 0 1\n",
            " 1 1 1 1 0 0 1 1 0 1 0 0 1 1 1 1 1 0 0 0 0 0 0 1 0 1 0 0 0 0 1 1 0 1 0 0 0\n",
            " 1 0 0 0 0 0 0 1 1 1 1 0 1 1 0 0 1 0 1 0 0 1 0 0 0 1 1 1 1 1 0 1 1 1 1 0 1\n",
            " 0 1 0 1 0 1 1 0 0 1 1 0 1 0 1 1 0 1 1 0 0 1 1 1 1 1 1 1 1 0 0 1 1 1 0 0 0\n",
            " 1 1 0 0 0 1 1 0 0 1 0 0 0 1 0 1 0 1 1 1 0 1 0 1 0 1 0 1 1 1 1 0 1 1 0 0 0\n",
            " 1 1 1 0 1 1 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 1 1 0 0 1 1 0 1 1 1 1 1 0\n",
            " 0 1 0 1 1 1 0 1 0 1 0 1 1 0 0 0 0 0 1 1 1 1 0 0 0 1 0 1 1 1 0 0 0 0 0 0 1\n",
            " 0 0 0 1 0 1 1 0 1 0 0 0 1 1 1 1 1 1 0 0 1 1 1 1 0 1 0 1 0 0 0 0 1 0 1 1 1\n",
            " 0 1 1 1 0 0 1 1 0 0 0 0 1 0 0 1 0 1 0 1 1 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1 1\n",
            " 1 1 1 0 0 1 1 0 1 1 1 1 1 1 1 0 0 0 0 1 1 1 0 0 0 0 1 0 1 1 1 0 1 1 1 1 0\n",
            " 1 0 0 1 1 0 1 0 0 1 0 1 0 1 0 0 1 0 0 0 1 1 1 0 0 1 1 0 0 0 0 1 0 1 1 0 1\n",
            " 1 0 0 1 1 0 1 1 0 1 1 0 1 0 1 1 0 1 1 0 0 0 0 1 0 1 1 1 1 1 0 0 1 1 1 0 0\n",
            " 1 1 1 1 0 1 0 1 0 0 1 1 0 1 0 0 0 0 1 0 1 1 0 0 0 0 1 0 1 0 1 0 0 1 0 1 0\n",
            " 0 0 1 0 0 1 1 1 1 0 0 0 1 1 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 1\n",
            " 1 1 0 0 0 1 1 0 0 1 0 1 0 0 1 0 0 0 1 1 0 1 1 0 0 0 1 0 0 0 1 0 0 1 1 0 0\n",
            " 0 0 1 1 0 0 1 0 1 1 1 0 0 1 0 1 1 0 0 0 1 0 0 1 1 1 1 0 1 0 1 0 0 0 0 1 1\n",
            " 1 0 1 1 1 0 1 0 0 0 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 0 0 0 0 1 1 0 1 0 0 0 0\n",
            " 0 0 0 0 1 1 0 0 1 1 0 0 1 0 1 1 0 1 1 0 1 0 0 0 0 1 0 1 1 1 0 1 1 0 1 1 1\n",
            " 0 1 1 1 0 1 1 0 1 0 1 0 1 1 0 1 0 1 1 0 0 0 1 1 1 1 0 1 0 1 1 0 1 0 0 0 0\n",
            " 1 0 0 1 0 0 1 0 1 0 1 0 1 1 1 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 0 0 1 0 0\n",
            " 1 0 1 1 0 0 1 0 1 1 0 1 0 0 0 1 1 1 0 0 1 1 0 0 1 1 1 0 0 0]\n",
            "uniques chosen: 10 <= should be equal to: 10\n",
            "trainset before adding uncertain samples (310, 10) (310,)\n",
            "trainset after adding uncertain samples (320, 10) (320,)\n",
            "updated train set: (320, 10) (320,) unique(labels): [136 184] [0 1]\n",
            "val set: (982, 10) (982,)\n",
            "\n",
            "Train set: (320, 10)\n",
            "Validation set: (982, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 32\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.067 s \n",
            "\n",
            "Accuracy rate is 77.188940 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.86      0.85       321\n",
            "           1       0.57      0.52      0.54       113\n",
            "\n",
            "    accuracy                           0.77       434\n",
            "   macro avg       0.70      0.69      0.70       434\n",
            "weighted avg       0.77      0.77      0.77       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[276  45]\n",
            " [ 54  59]]\n",
            "--------------------------------\n",
            "val predicted: (982,) [0 1 1 1 0 1 0 0 1 1 1 0 1 0 1 0 1 0 1 0 0 1 0 1 0 1 0 1 1 0 1 1 1 1 1 0 0\n",
            " 0 0 0 1 1 0 0 1 1 1 0 1 1 0 1 0 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 0 1 1\n",
            " 0 0 1 1 0 1 0 0 0 1 0 0 1 1 0 1 1 1 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 1 1\n",
            " 0 0 0 1 0 1 0 0 0 0 0 0 1 0 1 1 1 0 1 0 0 1 1 0 0 1 1 0 1 1 1 1 1 1 0 1 1\n",
            " 0 0 0 1 0 1 1 1 1 0 0 0 0 1 1 1 1 0 1 1 1 1 1 0 0 1 1 0 1 1 1 0 0 0 0 1 0\n",
            " 0 0 1 0 1 1 1 1 0 0 0 0 1 1 0 0 1 0 1 0 1 0 1 0 1 1 0 1 1 1 0 0 0 0 0 1 1\n",
            " 0 1 1 0 1 1 0 1 1 1 1 0 0 1 0 1 1 1 1 0 1 1 0 1 1 1 0 1 1 0 1 1 1 0 1 1 1\n",
            " 1 1 0 0 1 1 0 1 0 0 1 1 1 1 1 0 0 0 0 0 0 1 0 1 0 0 0 0 1 1 0 1 0 0 1 0 0\n",
            " 0 0 0 0 1 1 1 1 0 1 1 0 0 1 0 1 0 0 1 0 0 0 1 1 1 1 1 0 1 1 1 1 0 1 0 1 0\n",
            " 1 0 1 1 0 0 1 1 0 1 0 1 1 0 1 1 0 0 1 1 1 1 1 1 1 0 0 1 1 1 0 0 0 1 1 0 0\n",
            " 0 1 1 0 0 1 0 0 0 1 0 1 0 1 1 1 0 1 0 1 0 1 0 1 1 1 1 0 1 1 0 0 0 1 1 1 0\n",
            " 1 1 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 1 1 0 0 1 1 0 1 1 1 1 1 0 0 1 0 1 1\n",
            " 1 0 1 0 1 0 1 1 0 0 0 0 0 1 1 1 1 0 0 0 1 0 1 1 1 0 0 0 0 0 0 1 0 0 0 1 0\n",
            " 1 1 0 1 0 0 0 1 1 1 1 1 1 0 0 1 1 1 1 0 1 0 1 0 0 0 0 1 0 1 1 0 0 1 1 0 0\n",
            " 1 1 0 0 0 0 1 0 0 1 0 1 0 1 1 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1\n",
            " 0 1 1 1 1 1 1 1 0 0 0 0 1 1 1 0 0 0 0 1 0 1 1 1 0 1 1 1 1 0 1 0 0 1 1 0 1\n",
            " 0 0 1 0 1 0 1 0 0 1 0 0 0 1 1 1 0 0 1 1 0 0 0 0 1 0 1 1 0 1 1 0 0 1 1 0 1\n",
            " 1 0 1 1 0 1 0 1 1 0 1 1 0 0 0 0 1 0 1 1 1 1 1 0 0 0 1 1 0 0 1 1 1 1 0 1 0\n",
            " 1 1 0 1 1 0 1 0 0 0 0 1 0 1 1 0 0 0 0 1 0 1 0 1 0 0 1 0 1 0 0 0 1 0 0 1 1\n",
            " 1 1 0 0 0 1 1 1 1 0 1 0 0 1 0 0 1 1 1 1 1 1 0 0 0 0 0 0 0 1 1 1 0 0 0 1 1\n",
            " 0 0 1 0 1 0 0 1 0 0 0 1 1 0 1 1 0 0 0 1 0 0 0 1 0 0 1 1 0 0 0 0 1 1 0 0 1\n",
            " 0 1 1 1 0 0 1 0 1 1 0 0 0 1 0 0 1 1 1 1 0 1 0 1 0 0 0 0 1 1 1 0 1 1 1 0 1\n",
            " 0 0 0 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 1 1 0 0\n",
            " 1 1 0 0 1 0 1 1 0 1 1 0 1 0 0 0 0 1 0 1 1 0 1 1 0 1 1 1 0 1 1 1 0 1 1 0 1\n",
            " 0 1 0 1 1 0 1 0 1 0 0 0 1 1 1 1 0 1 0 1 1 0 1 0 0 0 0 1 0 0 1 0 0 1 0 1 0\n",
            " 1 0 1 1 1 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 0 0 1 0 0 1 0 1 1 0 0 1 0 1 1\n",
            " 0 1 0 0 0 1 1 1 0 0 1 1 0 0 1 1 1 0 0 0]\n",
            "probabilities: (982, 2) \n",
            " [0 1 1 1 0 1 0 0 1 1 1 0 1 0 1 0 1 0 1 0 0 1 0 1 0 1 0 1 1 0 1 1 1 1 1 0 0\n",
            " 0 0 0 1 1 0 0 1 1 1 0 1 1 0 1 0 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 0 1 1\n",
            " 0 0 1 1 0 1 0 0 0 1 0 0 1 1 0 1 1 1 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 1 1\n",
            " 0 0 0 1 0 1 0 0 0 0 0 0 1 0 1 1 1 0 1 0 0 1 1 0 0 1 1 0 1 1 1 1 1 1 0 1 1\n",
            " 0 0 0 1 0 1 1 1 1 0 0 0 0 1 1 1 1 0 1 1 1 1 1 0 0 1 1 0 1 1 1 0 0 0 0 1 0\n",
            " 0 0 1 0 1 1 1 1 0 0 0 0 1 1 0 0 1 0 1 0 1 0 1 0 1 1 0 1 1 1 0 0 0 0 0 1 1\n",
            " 0 1 1 0 1 1 0 1 1 1 1 0 0 1 0 1 1 1 1 0 1 1 0 1 1 1 0 1 1 0 1 1 1 0 1 1 1\n",
            " 1 1 0 0 1 1 0 1 0 0 1 1 1 1 1 0 0 0 0 0 0 1 0 1 0 0 0 0 1 1 0 1 0 0 1 0 0\n",
            " 0 0 0 0 1 1 1 1 0 1 1 0 0 1 0 1 0 0 1 0 0 0 1 1 1 1 1 0 1 1 1 1 0 1 0 1 0\n",
            " 1 0 1 1 0 0 1 1 0 1 0 1 1 0 1 1 0 0 1 1 1 1 1 1 1 0 0 1 1 1 0 0 0 1 1 0 0\n",
            " 0 1 1 0 0 1 0 0 0 1 0 1 0 1 1 1 0 1 0 1 0 1 0 1 1 1 1 0 1 1 0 0 0 1 1 1 0\n",
            " 1 1 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 1 1 0 0 1 1 0 1 1 1 1 1 0 0 1 0 1 1\n",
            " 1 0 1 0 1 0 1 1 0 0 0 0 0 1 1 1 1 0 0 0 1 0 1 1 1 0 0 0 0 0 0 1 0 0 0 1 0\n",
            " 1 1 0 1 0 0 0 1 1 1 1 1 1 0 0 1 1 1 1 0 1 0 1 0 0 0 0 1 0 1 1 0 0 1 1 0 0\n",
            " 1 1 0 0 0 0 1 0 0 1 0 1 0 1 1 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1\n",
            " 0 1 1 1 1 1 1 1 0 0 0 0 1 1 1 0 0 0 0 1 0 1 1 1 0 1 1 1 1 0 1 0 0 1 1 0 1\n",
            " 0 0 1 0 1 0 1 0 0 1 0 0 0 1 1 1 0 0 1 1 0 0 0 0 1 0 1 1 0 1 1 0 0 1 1 0 1\n",
            " 1 0 1 1 0 1 0 1 1 0 1 1 0 0 0 0 1 0 1 1 1 1 1 0 0 0 1 1 0 0 1 1 1 1 0 1 0\n",
            " 1 1 0 1 1 0 1 0 0 0 0 1 0 1 1 0 0 0 0 1 0 1 0 1 0 0 1 0 1 0 0 0 1 0 0 1 1\n",
            " 1 1 0 0 0 1 1 1 1 0 1 0 0 1 0 0 1 1 1 1 1 1 0 0 0 0 0 0 0 1 1 1 0 0 0 1 1\n",
            " 0 0 1 0 1 0 0 1 0 0 0 1 1 0 1 1 0 0 0 1 0 0 0 1 0 0 1 1 0 0 0 0 1 1 0 0 1\n",
            " 0 1 1 1 0 0 1 0 1 1 0 0 0 1 0 0 1 1 1 1 0 1 0 1 0 0 0 0 1 1 1 0 1 1 1 0 1\n",
            " 0 0 0 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 1 1 0 0\n",
            " 1 1 0 0 1 0 1 1 0 1 1 0 1 0 0 0 0 1 0 1 1 0 1 1 0 1 1 1 0 1 1 1 0 1 1 0 1\n",
            " 0 1 0 1 1 0 1 0 1 0 0 0 1 1 1 1 0 1 0 1 1 0 1 0 0 0 0 1 0 0 1 0 0 1 0 1 0\n",
            " 1 0 1 1 1 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 0 0 1 0 0 1 0 1 1 0 0 1 0 1 1\n",
            " 0 1 0 0 0 1 1 1 0 0 1 1 0 0 1 1 1 0 0 0]\n",
            "uniques chosen: 10 <= should be equal to: 10\n",
            "trainset before adding uncertain samples (320, 10) (320,)\n",
            "trainset after adding uncertain samples (330, 10) (330,)\n",
            "updated train set: (330, 10) (330,) unique(labels): [142 188] [0 1]\n",
            "val set: (972, 10) (972,)\n",
            "\n",
            "Train set: (330, 10)\n",
            "Validation set: (972, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 33\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.082 s \n",
            "\n",
            "Accuracy rate is 76.958525 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.86      0.85       321\n",
            "           1       0.56      0.51      0.54       113\n",
            "\n",
            "    accuracy                           0.77       434\n",
            "   macro avg       0.70      0.69      0.69       434\n",
            "weighted avg       0.76      0.77      0.77       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[276  45]\n",
            " [ 55  58]]\n",
            "--------------------------------\n",
            "val predicted: (972,) [0 1 1 1 0 1 0 0 1 1 1 0 1 0 1 0 1 0 1 0 0 1 0 1 0 1 0 1 1 0 1 1 1 1 1 0 0\n",
            " 0 0 0 1 1 0 0 1 1 1 0 1 1 0 1 0 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 0 1 1\n",
            " 0 0 1 1 0 1 0 0 0 1 0 0 1 1 0 1 1 1 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 1 1\n",
            " 0 0 0 1 0 1 0 0 0 0 0 0 1 0 1 1 1 0 1 1 0 1 1 0 1 1 1 0 1 1 1 1 1 1 0 1 1\n",
            " 0 0 0 1 0 1 1 1 1 0 0 0 0 1 1 1 1 0 1 1 1 1 1 0 0 1 1 0 1 1 1 0 0 0 0 1 0\n",
            " 0 0 1 0 1 1 1 1 0 0 0 0 1 1 0 0 1 0 1 0 1 0 1 0 1 0 1 1 1 0 0 0 0 0 1 1 0\n",
            " 1 1 0 1 0 1 1 1 1 0 0 1 0 1 1 1 1 0 1 1 0 1 1 1 0 1 1 0 1 1 1 0 1 1 1 1 1\n",
            " 0 0 1 1 0 1 0 0 1 1 1 1 1 0 0 0 0 0 0 1 0 1 0 0 0 0 1 1 0 1 0 0 1 0 0 0 0\n",
            " 0 0 1 1 1 1 0 1 1 0 0 1 0 1 0 0 1 0 0 0 0 1 1 1 1 0 1 1 1 1 0 1 0 1 0 1 0\n",
            " 1 1 0 0 1 1 0 1 0 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0 1 1 1 0 0 0 1 1 0 0 1 1 1\n",
            " 0 0 1 0 0 0 1 0 1 0 1 1 1 0 1 0 1 0 1 1 1 1 1 0 1 1 0 0 0 1 1 1 0 1 1 0 0\n",
            " 0 0 0 1 0 0 1 1 1 0 0 0 0 0 0 1 1 0 0 1 1 0 1 1 1 1 1 0 0 1 0 1 1 1 0 1 0\n",
            " 1 0 1 1 0 0 0 0 0 1 1 1 1 0 0 0 1 0 1 1 1 0 0 0 0 0 1 0 0 0 1 0 1 1 0 1 0\n",
            " 0 0 1 1 1 1 1 1 0 0 1 1 1 1 0 1 0 1 0 0 0 0 1 0 1 1 0 0 1 1 0 0 1 1 0 0 0\n",
            " 0 1 0 0 1 0 1 0 1 1 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1\n",
            " 1 1 1 0 0 0 0 1 1 1 0 0 0 0 1 0 1 1 1 0 1 1 1 1 0 1 0 0 1 1 0 1 0 0 1 0 1\n",
            " 0 1 0 0 1 0 0 1 1 1 0 0 1 1 0 0 0 0 1 0 1 1 0 1 1 0 0 1 1 0 1 1 0 1 1 0 1\n",
            " 0 1 0 1 1 0 0 0 0 1 0 1 1 1 1 1 0 0 1 1 1 0 0 1 1 1 1 0 1 0 1 1 0 1 1 0 1\n",
            " 0 0 0 0 0 1 1 0 0 0 0 1 0 1 0 1 0 0 1 0 1 0 0 0 1 0 0 1 1 1 1 0 0 0 1 1 1\n",
            " 1 0 1 0 0 1 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 1 1 1 0 0 0 1 1 0 0 1 0 1 0 0 1\n",
            " 0 0 0 1 1 0 1 1 0 0 0 1 0 0 0 1 0 0 1 1 0 0 0 0 1 1 0 0 1 0 1 1 1 0 0 1 0\n",
            " 1 1 0 0 0 1 0 0 1 1 1 1 0 1 0 1 0 0 0 0 0 1 1 0 1 1 1 0 1 0 0 0 0 0 0 1 1\n",
            " 1 1 1 1 0 1 0 0 0 1 0 0 0 0 1 1 1 0 1 0 0 0 0 1 1 0 0 1 1 0 0 1 0 1 1 0 1\n",
            " 1 0 1 0 0 0 0 1 0 1 1 0 1 1 0 1 1 1 0 1 1 1 0 1 1 0 1 1 1 0 1 1 0 1 0 1 0\n",
            " 0 0 1 1 1 1 0 1 0 1 1 0 1 0 0 0 0 1 0 0 1 0 0 1 0 1 0 1 0 1 1 1 1 0 0 0 1\n",
            " 1 0 0 1 0 0 1 1 1 0 0 0 0 0 1 0 0 1 0 1 1 0 0 1 0 1 1 0 1 0 0 0 1 1 1 0 0\n",
            " 1 1 0 0 1 1 1 0 0 0]\n",
            "probabilities: (972, 2) \n",
            " [0 1 1 1 0 1 0 0 1 1 1 0 1 0 1 0 1 0 1 0 0 1 0 1 0 1 0 1 1 0 1 1 1 1 1 0 0\n",
            " 0 0 0 1 1 0 0 1 1 1 0 1 1 0 1 0 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 0 1 1\n",
            " 0 0 1 1 0 1 0 0 0 1 0 0 1 1 0 1 1 1 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 1 1\n",
            " 0 0 0 1 0 1 0 0 0 0 0 0 1 0 1 1 1 0 1 1 0 1 1 0 1 1 1 0 1 1 1 1 1 1 0 1 1\n",
            " 0 0 0 1 0 1 1 1 1 0 0 0 0 1 1 1 1 0 1 1 1 1 1 0 0 1 1 0 1 1 1 0 0 0 0 1 0\n",
            " 0 0 1 0 1 1 1 1 0 0 0 0 1 1 0 0 1 0 1 0 1 0 1 0 1 0 1 1 1 0 0 0 0 0 1 1 0\n",
            " 1 1 0 1 0 1 1 1 1 0 0 1 0 1 1 1 1 0 1 1 0 1 1 1 0 1 1 0 1 1 1 0 1 1 1 1 1\n",
            " 0 0 1 1 0 1 0 0 1 1 1 1 1 0 0 0 0 0 0 1 0 1 0 0 0 0 1 1 0 1 0 0 1 0 0 0 0\n",
            " 0 0 1 1 1 1 0 1 1 0 0 1 0 1 0 0 1 0 0 0 0 1 1 1 1 0 1 1 1 1 0 1 0 1 0 1 0\n",
            " 1 1 0 0 1 1 0 1 0 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0 1 1 1 0 0 0 1 1 0 0 1 1 1\n",
            " 0 0 1 0 0 0 1 0 1 0 1 1 1 0 1 0 1 0 1 1 1 1 1 0 1 1 0 0 0 1 1 1 0 1 1 0 0\n",
            " 0 0 0 1 0 0 1 1 1 0 0 0 0 0 0 1 1 0 0 1 1 0 1 1 1 1 1 0 0 1 0 1 1 1 0 1 0\n",
            " 1 0 1 1 0 0 0 0 0 1 1 1 1 0 0 0 1 0 1 1 1 0 0 0 0 0 1 0 0 0 1 0 1 1 0 1 0\n",
            " 0 0 1 1 1 1 1 1 0 0 1 1 1 1 0 1 0 1 0 0 0 0 1 0 1 1 0 0 1 1 0 0 1 1 0 0 0\n",
            " 0 1 0 0 1 0 1 0 1 1 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1\n",
            " 1 1 1 0 0 0 0 1 1 1 0 0 0 0 1 0 1 1 1 0 1 1 1 1 0 1 0 0 1 1 0 1 0 0 1 0 1\n",
            " 0 1 0 0 1 0 0 1 1 1 0 0 1 1 0 0 0 0 1 0 1 1 0 1 1 0 0 1 1 0 1 1 0 1 1 0 1\n",
            " 0 1 0 1 1 0 0 0 0 1 0 1 1 1 1 1 0 0 1 1 1 0 0 1 1 1 1 0 1 0 1 1 0 1 1 0 1\n",
            " 0 0 0 0 0 1 1 0 0 0 0 1 0 1 0 1 0 0 1 0 1 0 0 0 1 0 0 1 1 1 1 0 0 0 1 1 1\n",
            " 1 0 1 0 0 1 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 1 1 1 0 0 0 1 1 0 0 1 0 1 0 0 1\n",
            " 0 0 0 1 1 0 1 1 0 0 0 1 0 0 0 1 0 0 1 1 0 0 0 0 1 1 0 0 1 0 1 1 1 0 0 1 0\n",
            " 1 1 0 0 0 1 0 0 1 1 1 1 0 1 0 1 0 0 0 0 0 1 1 0 1 1 1 0 1 0 0 0 0 0 0 1 1\n",
            " 1 1 1 1 0 1 0 0 0 1 0 0 0 0 1 1 1 0 1 0 0 0 0 1 1 0 0 1 1 0 0 1 0 1 1 0 1\n",
            " 1 0 1 0 0 0 0 1 0 1 1 0 1 1 0 1 1 1 0 1 1 1 0 1 1 0 1 1 1 0 1 1 0 1 0 1 0\n",
            " 0 0 1 1 1 1 0 1 0 1 1 0 1 0 0 0 0 1 0 0 1 0 0 1 0 1 0 1 0 1 1 1 1 0 0 0 1\n",
            " 1 0 0 1 0 0 1 1 1 0 0 0 0 0 1 0 0 1 0 1 1 0 0 1 0 1 1 0 1 0 0 0 1 1 1 0 0\n",
            " 1 1 0 0 1 1 1 0 0 0]\n",
            "uniques chosen: 10 <= should be equal to: 10\n",
            "trainset before adding uncertain samples (330, 10) (330,)\n",
            "trainset after adding uncertain samples (340, 10) (340,)\n",
            "updated train set: (340, 10) (340,) unique(labels): [146 194] [0 1]\n",
            "val set: (962, 10) (962,)\n",
            "\n",
            "Train set: (340, 10)\n",
            "Validation set: (962, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 34\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.088 s \n",
            "\n",
            "Accuracy rate is 77.419355 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.85      0.85       321\n",
            "           1       0.57      0.55      0.56       113\n",
            "\n",
            "    accuracy                           0.77       434\n",
            "   macro avg       0.71      0.70      0.70       434\n",
            "weighted avg       0.77      0.77      0.77       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[274  47]\n",
            " [ 51  62]]\n",
            "--------------------------------\n",
            "val predicted: (962,) [0 1 1 1 0 1 0 0 1 1 1 0 1 0 1 1 1 0 1 0 0 1 0 1 0 1 0 1 1 0 1 1 1 1 1 0 0\n",
            " 0 0 1 1 0 0 1 1 1 0 1 1 0 1 0 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 0 1 1 0\n",
            " 0 1 1 0 1 0 0 0 1 0 0 1 1 0 1 1 1 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 1 1 0\n",
            " 0 0 1 0 1 0 0 0 0 0 0 1 0 1 1 1 0 1 1 0 1 1 0 0 1 1 0 1 1 1 1 1 1 0 1 1 0\n",
            " 0 0 1 0 1 1 1 1 0 0 0 0 1 1 1 1 0 1 1 1 1 1 0 0 1 1 0 1 1 1 0 0 0 0 1 0 0\n",
            " 0 1 0 1 1 1 1 0 0 0 0 1 1 0 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 1 1 0 1 1\n",
            " 0 1 0 1 1 1 1 0 1 0 1 1 1 1 0 1 1 0 1 1 1 0 1 1 0 1 1 1 0 1 1 1 1 1 0 0 1\n",
            " 1 0 1 0 0 1 1 1 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 1 1 0 1 0 0 1 0 0 0 0 0 0 1\n",
            " 1 1 1 0 1 1 0 0 1 0 1 0 0 1 0 0 0 0 1 1 1 1 0 1 1 1 1 0 0 1 0 1 0 1 0 0 1\n",
            " 1 0 1 0 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0 1 1 1 0 0 0 1 1 0 0 1 1 1 0 0 1 0 0\n",
            " 0 1 0 1 0 1 1 1 0 1 0 1 0 1 1 1 1 1 0 1 1 0 0 0 1 1 1 0 1 1 0 0 0 0 0 1 0\n",
            " 0 1 1 1 0 0 0 0 0 0 1 1 1 0 1 1 0 1 1 1 1 1 0 0 1 0 1 1 1 0 1 0 1 0 1 1 0\n",
            " 0 0 0 0 1 1 1 1 0 0 0 1 0 1 1 1 0 0 0 0 0 1 0 0 0 1 0 1 1 0 1 0 0 0 1 1 1\n",
            " 1 1 1 0 0 1 1 1 1 0 1 0 1 0 0 0 0 1 0 1 1 0 1 1 1 0 0 1 1 0 0 0 0 1 0 0 1\n",
            " 0 1 0 1 1 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 0 0 0 0\n",
            " 1 1 1 0 0 0 0 1 0 1 1 1 0 1 1 1 1 0 1 0 0 1 1 0 1 0 0 1 0 1 0 1 0 0 1 0 0\n",
            " 1 1 1 0 0 1 1 0 0 0 0 1 0 1 1 0 1 1 0 0 1 1 0 1 1 0 1 1 0 1 0 1 0 1 1 0 0\n",
            " 0 0 1 0 1 1 1 1 1 0 0 1 1 1 0 0 1 1 1 1 0 1 0 1 0 0 0 1 0 1 0 0 0 0 0 1 1\n",
            " 0 0 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 0 0 1 1 1 1 0 0 0 1 1 1 1 0 1 0 0 1 0\n",
            " 0 1 1 1 1 1 1 0 0 0 0 0 0 0 1 1 1 0 0 0 1 1 0 0 1 0 1 0 0 1 0 0 0 1 1 0 1\n",
            " 1 0 0 1 1 0 0 1 0 0 1 1 0 0 0 0 1 1 0 0 1 0 1 1 1 0 0 1 0 1 1 0 0 0 1 0 0\n",
            " 1 1 1 1 0 1 0 1 0 0 0 0 1 1 0 1 1 1 0 1 0 0 0 0 0 0 1 1 1 1 1 1 0 1 0 0 0\n",
            " 1 0 0 0 0 1 0 1 0 1 0 1 0 0 1 1 0 0 1 1 0 0 1 0 1 1 0 1 1 0 1 0 0 0 0 1 0\n",
            " 1 1 0 1 1 0 1 1 1 0 1 1 1 0 1 1 0 1 1 1 0 1 1 0 1 1 0 0 0 1 1 1 1 0 1 0 1\n",
            " 1 0 1 0 0 0 0 1 0 0 1 0 0 1 0 1 0 1 0 1 1 1 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0\n",
            " 0 0 0 0 1 0 0 1 0 1 1 0 0 1 0 1 1 0 1 0 0 0 1 1 1 0 0 1 1 0 0 1 1 1 0 0 0]\n",
            "probabilities: (962, 2) \n",
            " [0 1 1 1 0 1 0 0 1 1 1 0 1 0 1 1 1 0 1 0 0 1 0 1 0 1 0 1 1 0 1 1 1 1 1 0 0\n",
            " 0 0 1 1 0 0 1 1 1 0 1 1 0 1 0 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 0 1 1 0\n",
            " 0 1 1 0 1 0 0 0 1 0 0 1 1 0 1 1 1 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 1 1 0\n",
            " 0 0 1 0 1 0 0 0 0 0 0 1 0 1 1 1 0 1 1 0 1 1 0 0 1 1 0 1 1 1 1 1 1 0 1 1 0\n",
            " 0 0 1 0 1 1 1 1 0 0 0 0 1 1 1 1 0 1 1 1 1 1 0 0 1 1 0 1 1 1 0 0 0 0 1 0 0\n",
            " 0 1 0 1 1 1 1 0 0 0 0 1 1 0 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 1 1 0 1 1\n",
            " 0 1 0 1 1 1 1 0 1 0 1 1 1 1 0 1 1 0 1 1 1 0 1 1 0 1 1 1 0 1 1 1 1 1 0 0 1\n",
            " 1 0 1 0 0 1 1 1 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 1 1 0 1 0 0 1 0 0 0 0 0 0 1\n",
            " 1 1 1 0 1 1 0 0 1 0 1 0 0 1 0 0 0 0 1 1 1 1 0 1 1 1 1 0 0 1 0 1 0 1 0 0 1\n",
            " 1 0 1 0 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0 1 1 1 0 0 0 1 1 0 0 1 1 1 0 0 1 0 0\n",
            " 0 1 0 1 0 1 1 1 0 1 0 1 0 1 1 1 1 1 0 1 1 0 0 0 1 1 1 0 1 1 0 0 0 0 0 1 0\n",
            " 0 1 1 1 0 0 0 0 0 0 1 1 1 0 1 1 0 1 1 1 1 1 0 0 1 0 1 1 1 0 1 0 1 0 1 1 0\n",
            " 0 0 0 0 1 1 1 1 0 0 0 1 0 1 1 1 0 0 0 0 0 1 0 0 0 1 0 1 1 0 1 0 0 0 1 1 1\n",
            " 1 1 1 0 0 1 1 1 1 0 1 0 1 0 0 0 0 1 0 1 1 0 1 1 1 0 0 1 1 0 0 0 0 1 0 0 1\n",
            " 0 1 0 1 1 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 0 0 0 0\n",
            " 1 1 1 0 0 0 0 1 0 1 1 1 0 1 1 1 1 0 1 0 0 1 1 0 1 0 0 1 0 1 0 1 0 0 1 0 0\n",
            " 1 1 1 0 0 1 1 0 0 0 0 1 0 1 1 0 1 1 0 0 1 1 0 1 1 0 1 1 0 1 0 1 0 1 1 0 0\n",
            " 0 0 1 0 1 1 1 1 1 0 0 1 1 1 0 0 1 1 1 1 0 1 0 1 0 0 0 1 0 1 0 0 0 0 0 1 1\n",
            " 0 0 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 0 0 1 1 1 1 0 0 0 1 1 1 1 0 1 0 0 1 0\n",
            " 0 1 1 1 1 1 1 0 0 0 0 0 0 0 1 1 1 0 0 0 1 1 0 0 1 0 1 0 0 1 0 0 0 1 1 0 1\n",
            " 1 0 0 1 1 0 0 1 0 0 1 1 0 0 0 0 1 1 0 0 1 0 1 1 1 0 0 1 0 1 1 0 0 0 1 0 0\n",
            " 1 1 1 1 0 1 0 1 0 0 0 0 1 1 0 1 1 1 0 1 0 0 0 0 0 0 1 1 1 1 1 1 0 1 0 0 0\n",
            " 1 0 0 0 0 1 0 1 0 1 0 1 0 0 1 1 0 0 1 1 0 0 1 0 1 1 0 1 1 0 1 0 0 0 0 1 0\n",
            " 1 1 0 1 1 0 1 1 1 0 1 1 1 0 1 1 0 1 1 1 0 1 1 0 1 1 0 0 0 1 1 1 1 0 1 0 1\n",
            " 1 0 1 0 0 0 0 1 0 0 1 0 0 1 0 1 0 1 0 1 1 1 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0\n",
            " 0 0 0 0 1 0 0 1 0 1 1 0 0 1 0 1 1 0 1 0 0 0 1 1 1 0 0 1 1 0 0 1 1 1 0 0 0]\n",
            "uniques chosen: 10 <= should be equal to: 10\n",
            "trainset before adding uncertain samples (340, 10) (340,)\n",
            "trainset after adding uncertain samples (350, 10) (350,)\n",
            "updated train set: (350, 10) (350,) unique(labels): [153 197] [0 1]\n",
            "val set: (952, 10) (952,)\n",
            "\n",
            "Train set: (350, 10)\n",
            "Validation set: (952, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 35\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.078 s \n",
            "\n",
            "Accuracy rate is 79.032258 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.87      0.86       321\n",
            "           1       0.61      0.56      0.58       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.73      0.71      0.72       434\n",
            "weighted avg       0.79      0.79      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[280  41]\n",
            " [ 50  63]]\n",
            "--------------------------------\n",
            "val predicted: (952,) [0 1 1 1 0 1 0 0 1 1 1 0 1 0 1 1 1 0 1 0 0 1 0 1 0 1 0 1 1 0 1 1 1 1 1 0 0\n",
            " 0 0 1 1 0 1 1 1 0 1 1 0 1 0 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0\n",
            " 1 1 0 1 0 0 0 1 0 0 1 1 0 1 1 1 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0\n",
            " 0 1 0 1 0 0 0 0 0 0 1 0 1 1 1 0 1 1 0 1 1 0 0 1 0 1 1 1 1 1 1 0 1 1 0 1 0\n",
            " 1 0 1 1 1 1 0 0 0 0 1 1 1 1 0 1 1 1 1 1 0 0 1 0 0 0 1 1 0 0 0 0 1 0 0 0 1\n",
            " 0 1 1 1 1 0 0 0 0 1 1 0 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 1 1 0 1 1 0 1\n",
            " 0 1 1 1 1 0 1 0 1 1 1 1 0 1 1 0 1 1 1 0 1 1 0 1 1 1 0 1 1 1 1 1 0 0 1 1 0\n",
            " 1 0 0 1 1 1 0 1 0 0 0 0 0 1 0 1 0 1 0 0 1 1 0 1 0 1 0 0 0 0 0 0 1 1 1 1 0\n",
            " 1 1 0 0 1 0 1 0 0 1 0 0 0 0 1 1 1 1 0 1 1 1 1 0 0 1 0 1 1 1 0 0 1 1 0 1 0\n",
            " 1 0 1 1 0 0 1 1 1 1 1 1 1 0 0 1 1 1 0 0 0 1 1 0 0 1 1 1 0 0 1 0 0 0 1 0 1\n",
            " 0 1 1 1 0 1 0 1 0 1 1 1 1 1 0 1 1 0 0 0 1 1 1 0 1 1 0 0 0 0 0 1 0 0 1 1 1\n",
            " 0 0 0 0 0 0 1 0 0 0 1 1 0 1 1 1 1 1 0 0 1 0 1 1 1 0 1 0 1 0 1 1 0 0 0 0 0\n",
            " 1 1 1 1 0 0 0 1 0 0 1 1 0 0 0 0 0 1 0 0 0 1 0 1 1 0 1 0 0 0 1 1 1 1 1 1 0\n",
            " 0 1 1 1 1 0 1 0 1 0 0 0 0 1 0 1 1 0 1 1 1 0 0 1 1 0 0 0 0 1 0 0 1 0 1 0 1\n",
            " 1 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 0 0 0 0 1 1 1 0\n",
            " 0 0 0 1 0 1 1 1 0 1 1 1 1 0 1 0 0 1 1 0 1 0 0 1 0 1 0 1 0 0 1 0 0 1 1 1 0\n",
            " 0 1 1 0 0 0 0 1 0 1 1 0 1 1 0 0 1 1 0 1 1 0 1 1 0 1 0 1 0 1 1 0 0 0 1 0 1\n",
            " 1 1 1 1 0 0 1 1 1 0 0 1 1 1 1 0 1 0 0 0 0 1 0 1 0 0 0 0 0 1 1 0 0 0 0 1 0\n",
            " 1 0 1 0 0 1 1 1 0 0 1 1 0 0 1 1 1 1 0 0 0 1 1 1 1 0 1 0 0 1 0 1 1 1 1 1 1\n",
            " 1 0 0 0 0 0 0 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 0 1 0 0 0 1 1 0 1 1 0 0 1 1 0\n",
            " 0 1 0 0 1 1 0 0 0 0 1 1 0 0 1 0 1 1 1 0 0 1 0 1 1 0 0 0 1 0 0 1 1 1 1 0 0\n",
            " 0 1 0 0 0 0 1 1 0 1 1 1 0 1 0 0 0 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 0 0 0 1 0\n",
            " 1 0 1 0 0 0 0 1 1 0 0 1 1 0 0 1 0 1 1 0 1 1 0 1 0 0 0 0 1 0 1 1 0 1 1 0 1\n",
            " 1 1 0 1 1 1 0 1 1 0 1 1 1 0 1 1 0 1 1 0 0 1 1 1 1 0 1 0 1 1 0 1 0 0 0 0 0\n",
            " 0 1 0 0 1 0 1 0 1 0 1 1 1 1 0 0 0 1 1 0 0 1 0 0 1 0 1 0 0 0 0 0 1 0 0 1 0\n",
            " 1 1 0 0 1 0 1 0 1 0 0 0 1 1 1 0 0 1 1 0 0 1 1 1 0 0 0]\n",
            "probabilities: (952, 2) \n",
            " [0 1 1 1 0 1 0 0 1 1 1 0 1 0 1 1 1 0 1 0 0 1 0 1 0 1 0 1 1 0 1 1 1 1 1 0 0\n",
            " 0 0 1 1 0 1 1 1 0 1 1 0 1 0 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0\n",
            " 1 1 0 1 0 0 0 1 0 0 1 1 0 1 1 1 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0\n",
            " 0 1 0 1 0 0 0 0 0 0 1 0 1 1 1 0 1 1 0 1 1 0 0 1 0 1 1 1 1 1 1 0 1 1 0 1 0\n",
            " 1 0 1 1 1 1 0 0 0 0 1 1 1 1 0 1 1 1 1 1 0 0 1 0 0 0 1 1 0 0 0 0 1 0 0 0 1\n",
            " 0 1 1 1 1 0 0 0 0 1 1 0 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 1 1 0 1 1 0 1\n",
            " 0 1 1 1 1 0 1 0 1 1 1 1 0 1 1 0 1 1 1 0 1 1 0 1 1 1 0 1 1 1 1 1 0 0 1 1 0\n",
            " 1 0 0 1 1 1 0 1 0 0 0 0 0 1 0 1 0 1 0 0 1 1 0 1 0 1 0 0 0 0 0 0 1 1 1 1 0\n",
            " 1 1 0 0 1 0 1 0 0 1 0 0 0 0 1 1 1 1 0 1 1 1 1 0 0 1 0 1 1 1 0 0 1 1 0 1 0\n",
            " 1 0 1 1 0 0 1 1 1 1 1 1 1 0 0 1 1 1 0 0 0 1 1 0 0 1 1 1 0 0 1 0 0 0 1 0 1\n",
            " 0 1 1 1 0 1 0 1 0 1 1 1 1 1 0 1 1 0 0 0 1 1 1 0 1 1 0 0 0 0 0 1 0 0 1 1 1\n",
            " 0 0 0 0 0 0 1 0 0 0 1 1 0 1 1 1 1 1 0 0 1 0 1 1 1 0 1 0 1 0 1 1 0 0 0 0 0\n",
            " 1 1 1 1 0 0 0 1 0 0 1 1 0 0 0 0 0 1 0 0 0 1 0 1 1 0 1 0 0 0 1 1 1 1 1 1 0\n",
            " 0 1 1 1 1 0 1 0 1 0 0 0 0 1 0 1 1 0 1 1 1 0 0 1 1 0 0 0 0 1 0 0 1 0 1 0 1\n",
            " 1 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 0 0 0 0 1 1 1 0\n",
            " 0 0 0 1 0 1 1 1 0 1 1 1 1 0 1 0 0 1 1 0 1 0 0 1 0 1 0 1 0 0 1 0 0 1 1 1 0\n",
            " 0 1 1 0 0 0 0 1 0 1 1 0 1 1 0 0 1 1 0 1 1 0 1 1 0 1 0 1 0 1 1 0 0 0 1 0 1\n",
            " 1 1 1 1 0 0 1 1 1 0 0 1 1 1 1 0 1 0 0 0 0 1 0 1 0 0 0 0 0 1 1 0 0 0 0 1 0\n",
            " 1 0 1 0 0 1 1 1 0 0 1 1 0 0 1 1 1 1 0 0 0 1 1 1 1 0 1 0 0 1 0 1 1 1 1 1 1\n",
            " 1 0 0 0 0 0 0 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 0 1 0 0 0 1 1 0 1 1 0 0 1 1 0\n",
            " 0 1 0 0 1 1 0 0 0 0 1 1 0 0 1 0 1 1 1 0 0 1 0 1 1 0 0 0 1 0 0 1 1 1 1 0 0\n",
            " 0 1 0 0 0 0 1 1 0 1 1 1 0 1 0 0 0 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 0 0 0 1 0\n",
            " 1 0 1 0 0 0 0 1 1 0 0 1 1 0 0 1 0 1 1 0 1 1 0 1 0 0 0 0 1 0 1 1 0 1 1 0 1\n",
            " 1 1 0 1 1 1 0 1 1 0 1 1 1 0 1 1 0 1 1 0 0 1 1 1 1 0 1 0 1 1 0 1 0 0 0 0 0\n",
            " 0 1 0 0 1 0 1 0 1 0 1 1 1 1 0 0 0 1 1 0 0 1 0 0 1 0 1 0 0 0 0 0 1 0 0 1 0\n",
            " 1 1 0 0 1 0 1 0 1 0 0 0 1 1 1 0 0 1 1 0 0 1 1 1 0 0 0]\n",
            "uniques chosen: 10 <= should be equal to: 10\n",
            "trainset before adding uncertain samples (350, 10) (350,)\n",
            "trainset after adding uncertain samples (360, 10) (360,)\n",
            "updated train set: (360, 10) (360,) unique(labels): [158 202] [0 1]\n",
            "val set: (942, 10) (942,)\n",
            "\n",
            "Train set: (360, 10)\n",
            "Validation set: (942, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 36\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.068 s \n",
            "\n",
            "Accuracy rate is 78.571429 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.87      0.86       321\n",
            "           1       0.60      0.55      0.57       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.72      0.71      0.71       434\n",
            "weighted avg       0.78      0.79      0.78       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[279  42]\n",
            " [ 51  62]]\n",
            "--------------------------------\n",
            "val predicted: (942,) [0 1 1 1 0 1 0 0 1 1 1 0 1 0 1 1 0 1 0 0 1 0 1 0 1 0 1 1 0 1 1 1 1 1 0 0 0\n",
            " 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1\n",
            " 1 0 1 0 0 0 1 0 0 1 1 0 1 1 1 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0\n",
            " 1 0 1 0 0 0 0 0 0 1 0 1 1 1 0 1 1 0 1 1 0 0 1 0 1 1 1 1 1 1 0 1 1 1 0 1 0\n",
            " 1 1 1 1 0 0 0 0 1 1 1 1 0 1 1 1 1 1 0 0 1 0 0 0 1 1 0 0 0 1 0 0 0 1 0 1 1\n",
            " 1 1 0 0 0 0 1 1 0 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 1 1 0 1 1 0 1 0 1 1\n",
            " 1 1 0 1 0 1 1 1 1 0 1 1 0 1 1 1 0 1 1 0 1 1 1 0 1 1 1 1 0 0 1 1 0 1 0 0 1\n",
            " 1 1 0 1 0 0 0 0 0 1 0 1 0 1 0 0 1 1 0 1 0 1 0 0 0 0 0 0 1 1 1 1 0 1 1 0 0\n",
            " 1 0 1 0 0 1 0 0 0 0 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1 0 0 1 1 0 1 0 1 0 1 1 0\n",
            " 0 1 1 1 1 1 1 1 0 0 1 1 1 0 0 0 1 1 0 0 1 1 1 0 0 1 0 0 0 0 1 0 1 1 1 0 1\n",
            " 1 0 1 1 1 1 1 0 1 1 0 0 0 1 1 1 0 1 1 0 0 0 0 1 0 0 1 1 1 0 0 0 0 0 0 1 0\n",
            " 0 0 1 1 0 1 1 1 1 1 0 0 1 0 1 1 1 0 1 0 1 0 1 1 0 0 0 0 0 1 1 1 1 0 0 0 1\n",
            " 0 0 1 1 0 0 0 0 0 1 0 0 0 1 0 1 1 0 1 0 0 0 1 1 1 1 1 1 0 0 1 1 1 1 0 1 0\n",
            " 1 0 0 0 0 1 0 1 1 0 1 1 1 0 0 1 1 0 0 0 0 1 0 0 1 0 1 0 1 1 0 1 1 0 0 1 0\n",
            " 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 0 0 0 0 1 1 1 0 0 0 0 1 0 1 1 1\n",
            " 0 1 1 1 1 1 0 0 1 1 0 1 0 0 1 0 1 0 1 0 0 1 0 0 1 1 1 0 0 1 1 0 0 0 0 1 0\n",
            " 1 1 0 1 1 0 1 1 0 1 1 0 1 1 0 1 0 1 0 1 1 0 0 0 1 0 1 1 1 1 1 0 0 1 1 1 0\n",
            " 0 1 1 1 1 0 1 0 0 0 0 1 0 1 0 0 0 0 0 1 1 0 0 0 0 1 0 1 0 1 0 0 1 1 1 0 0\n",
            " 1 1 0 0 1 1 1 1 0 0 0 1 1 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 1 1\n",
            " 1 0 0 0 0 1 0 0 1 0 1 0 0 1 0 0 0 1 1 0 1 1 0 0 1 1 0 0 1 0 0 1 1 0 0 0 0\n",
            " 1 1 0 0 1 0 1 1 1 0 0 1 0 1 1 0 0 0 1 0 0 1 1 1 1 0 0 0 1 0 0 0 0 1 1 0 1\n",
            " 1 1 0 1 0 0 0 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 0 0 0 1 0 1 0 1 0 0 0 0 1 1 0\n",
            " 0 1 1 0 0 1 0 1 1 0 1 1 0 1 0 0 0 0 1 0 1 1 0 1 1 0 1 1 1 0 1 1 1 0 1 1 0\n",
            " 1 1 1 0 1 1 0 1 1 0 0 1 1 1 1 0 1 0 1 1 0 1 0 0 0 0 0 0 1 0 0 1 0 1 0 1 0\n",
            " 0 1 1 1 0 0 0 1 1 0 0 1 0 0 1 0 1 0 0 0 0 0 1 0 0 1 0 1 1 0 0 1 0 1 0 1 0\n",
            " 0 0 1 1 1 0 0 1 1 0 0 1 1 1 0 0 0]\n",
            "probabilities: (942, 2) \n",
            " [0 1 1 1 0 1 0 0 1 1 1 0 1 0 1 1 0 1 0 0 1 0 1 0 1 0 1 1 0 1 1 1 1 1 0 0 0\n",
            " 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1\n",
            " 1 0 1 0 0 0 1 0 0 1 1 0 1 1 1 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0\n",
            " 1 0 1 0 0 0 0 0 0 1 0 1 1 1 0 1 1 0 1 1 0 0 1 0 1 1 1 1 1 1 0 1 1 1 0 1 0\n",
            " 1 1 1 1 0 0 0 0 1 1 1 1 0 1 1 1 1 1 0 0 1 0 0 0 1 1 0 0 0 1 0 0 0 1 0 1 1\n",
            " 1 1 0 0 0 0 1 1 0 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 1 1 0 1 1 0 1 0 1 1\n",
            " 1 1 0 1 0 1 1 1 1 0 1 1 0 1 1 1 0 1 1 0 1 1 1 0 1 1 1 1 0 0 1 1 0 1 0 0 1\n",
            " 1 1 0 1 0 0 0 0 0 1 0 1 0 1 0 0 1 1 0 1 0 1 0 0 0 0 0 0 1 1 1 1 0 1 1 0 0\n",
            " 1 0 1 0 0 1 0 0 0 0 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1 0 0 1 1 0 1 0 1 0 1 1 0\n",
            " 0 1 1 1 1 1 1 1 0 0 1 1 1 0 0 0 1 1 0 0 1 1 1 0 0 1 0 0 0 0 1 0 1 1 1 0 1\n",
            " 1 0 1 1 1 1 1 0 1 1 0 0 0 1 1 1 0 1 1 0 0 0 0 1 0 0 1 1 1 0 0 0 0 0 0 1 0\n",
            " 0 0 1 1 0 1 1 1 1 1 0 0 1 0 1 1 1 0 1 0 1 0 1 1 0 0 0 0 0 1 1 1 1 0 0 0 1\n",
            " 0 0 1 1 0 0 0 0 0 1 0 0 0 1 0 1 1 0 1 0 0 0 1 1 1 1 1 1 0 0 1 1 1 1 0 1 0\n",
            " 1 0 0 0 0 1 0 1 1 0 1 1 1 0 0 1 1 0 0 0 0 1 0 0 1 0 1 0 1 1 0 1 1 0 0 1 0\n",
            " 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 0 0 0 0 1 1 1 0 0 0 0 1 0 1 1 1\n",
            " 0 1 1 1 1 1 0 0 1 1 0 1 0 0 1 0 1 0 1 0 0 1 0 0 1 1 1 0 0 1 1 0 0 0 0 1 0\n",
            " 1 1 0 1 1 0 1 1 0 1 1 0 1 1 0 1 0 1 0 1 1 0 0 0 1 0 1 1 1 1 1 0 0 1 1 1 0\n",
            " 0 1 1 1 1 0 1 0 0 0 0 1 0 1 0 0 0 0 0 1 1 0 0 0 0 1 0 1 0 1 0 0 1 1 1 0 0\n",
            " 1 1 0 0 1 1 1 1 0 0 0 1 1 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 1 1\n",
            " 1 0 0 0 0 1 0 0 1 0 1 0 0 1 0 0 0 1 1 0 1 1 0 0 1 1 0 0 1 0 0 1 1 0 0 0 0\n",
            " 1 1 0 0 1 0 1 1 1 0 0 1 0 1 1 0 0 0 1 0 0 1 1 1 1 0 0 0 1 0 0 0 0 1 1 0 1\n",
            " 1 1 0 1 0 0 0 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 0 0 0 1 0 1 0 1 0 0 0 0 1 1 0\n",
            " 0 1 1 0 0 1 0 1 1 0 1 1 0 1 0 0 0 0 1 0 1 1 0 1 1 0 1 1 1 0 1 1 1 0 1 1 0\n",
            " 1 1 1 0 1 1 0 1 1 0 0 1 1 1 1 0 1 0 1 1 0 1 0 0 0 0 0 0 1 0 0 1 0 1 0 1 0\n",
            " 0 1 1 1 0 0 0 1 1 0 0 1 0 0 1 0 1 0 0 0 0 0 1 0 0 1 0 1 1 0 0 1 0 1 0 1 0\n",
            " 0 0 1 1 1 0 0 1 1 0 0 1 1 1 0 0 0]\n",
            "uniques chosen: 10 <= should be equal to: 10\n",
            "trainset before adding uncertain samples (360, 10) (360,)\n",
            "trainset after adding uncertain samples (370, 10) (370,)\n",
            "updated train set: (370, 10) (370,) unique(labels): [163 207] [0 1]\n",
            "val set: (932, 10) (932,)\n",
            "\n",
            "Train set: (370, 10)\n",
            "Validation set: (932, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 37\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.109 s \n",
            "\n",
            "Accuracy rate is 78.801843 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.87      0.86       321\n",
            "           1       0.60      0.55      0.57       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.72      0.71      0.72       434\n",
            "weighted avg       0.78      0.79      0.78       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[280  41]\n",
            " [ 51  62]]\n",
            "--------------------------------\n",
            "val predicted: (932,) [0 1 1 1 0 1 0 0 1 1 1 0 1 0 0 1 0 1 0 0 1 0 0 0 1 0 1 1 0 1 1 1 1 1 0 0 0\n",
            " 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1\n",
            " 1 0 1 0 0 0 1 0 0 1 1 0 1 1 1 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0\n",
            " 1 0 1 0 0 0 0 0 0 1 0 1 1 1 0 0 1 0 1 1 0 0 1 0 1 1 1 1 1 0 1 1 1 0 1 0 1\n",
            " 1 1 1 0 0 0 0 1 1 0 1 0 1 1 1 1 1 0 0 1 0 0 0 1 1 0 0 0 1 0 0 0 1 0 1 1 1\n",
            " 1 0 0 0 0 1 1 0 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 1 0 1 1 0 1 0 1 1 1\n",
            " 1 0 1 0 1 1 1 1 0 1 1 0 1 1 1 0 1 1 0 1 1 1 0 1 1 1 1 0 0 1 1 0 1 0 0 1 1\n",
            " 1 0 1 0 0 0 0 0 1 0 1 0 1 0 0 1 1 0 1 0 1 0 0 0 0 0 0 1 1 1 1 0 1 1 0 0 1\n",
            " 0 1 0 0 1 0 0 0 0 1 1 1 1 1 1 1 1 0 0 1 0 1 0 1 0 0 1 1 0 1 0 1 0 1 1 0 0\n",
            " 1 1 1 1 1 1 1 0 0 1 1 1 0 0 0 1 1 0 0 1 1 1 0 0 1 0 0 0 0 1 0 1 1 1 0 1 1\n",
            " 0 1 1 1 1 1 0 1 1 0 0 0 1 1 1 0 1 0 0 0 0 1 0 0 1 1 1 0 0 0 0 0 0 1 0 0 0\n",
            " 1 1 0 1 1 1 1 0 0 1 0 1 1 1 0 1 0 1 0 1 1 0 0 0 0 0 1 1 1 1 0 0 0 1 0 0 1\n",
            " 1 0 0 0 0 0 1 0 0 0 1 0 1 1 0 1 0 0 0 1 1 1 1 1 1 0 0 1 1 1 1 0 1 0 1 0 0\n",
            " 0 0 1 0 1 1 0 1 1 1 0 0 1 1 0 0 0 0 1 0 0 1 0 1 0 1 1 0 1 1 0 0 1 0 1 1 1\n",
            " 1 0 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 0 0 0 0 1 1 1 0 0 0 0 1 0 1 1 1 0 1 1 1\n",
            " 1 1 0 0 1 1 0 1 0 0 1 0 1 0 1 0 0 1 0 0 1 1 0 0 1 1 0 0 0 0 1 0 1 1 0 1 1\n",
            " 0 1 1 0 1 1 0 1 1 0 1 0 1 0 1 1 0 0 0 1 0 1 1 1 1 1 0 0 1 1 1 0 0 1 1 1 1\n",
            " 0 1 0 0 0 0 1 0 1 0 0 0 0 0 1 1 0 0 0 0 1 0 1 0 1 0 0 1 0 1 0 0 0 1 0 0 1\n",
            " 1 1 1 0 0 0 1 1 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0 1\n",
            " 0 0 1 0 1 0 0 1 0 0 0 1 1 0 1 1 0 0 1 1 0 0 1 0 0 1 1 0 0 0 0 1 1 0 0 1 0\n",
            " 1 1 1 0 0 1 0 1 1 0 0 0 1 0 0 1 1 1 1 0 0 0 1 0 0 0 0 1 1 0 1 1 1 1 0 0 0\n",
            " 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 0 0 0 1 0 1 0 1 0 0 0 0 1 1 0 0 1 1 0 0 1 0\n",
            " 1 1 0 1 1 0 1 0 0 0 0 1 0 1 0 1 1 0 1 1 1 0 1 1 1 0 1 1 0 1 1 0 1 1 0 1 1\n",
            " 0 0 1 1 1 1 0 1 0 1 1 0 1 0 0 0 0 0 0 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 0 1 1\n",
            " 0 1 1 0 0 1 0 1 0 0 0 0 0 1 0 0 1 0 1 1 0 0 1 0 1 0 1 0 0 0 1 1 1 0 0 1 1\n",
            " 0 0 1 1 1 0 0]\n",
            "probabilities: (932, 2) \n",
            " [0 1 1 1 0 1 0 0 1 1 1 0 1 0 0 1 0 1 0 0 1 0 0 0 1 0 1 1 0 1 1 1 1 1 0 0 0\n",
            " 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1\n",
            " 1 0 1 0 0 0 1 0 0 1 1 0 1 1 1 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0\n",
            " 1 0 1 0 0 0 0 0 0 1 0 1 1 1 0 0 1 0 1 1 0 0 1 0 1 1 1 1 1 0 1 1 1 0 1 0 1\n",
            " 1 1 1 0 0 0 0 1 1 0 1 0 1 1 1 1 1 0 0 1 0 0 0 1 1 0 0 0 1 0 0 0 1 0 1 1 1\n",
            " 1 0 0 0 0 1 1 0 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 1 0 1 1 0 1 0 1 1 1\n",
            " 1 0 1 0 1 1 1 1 0 1 1 0 1 1 1 0 1 1 0 1 1 1 0 1 1 1 1 0 0 1 1 0 1 0 0 1 1\n",
            " 1 0 1 0 0 0 0 0 1 0 1 0 1 0 0 1 1 0 1 0 1 0 0 0 0 0 0 1 1 1 1 0 1 1 0 0 1\n",
            " 0 1 0 0 1 0 0 0 0 1 1 1 1 1 1 1 1 0 0 1 0 1 0 1 0 0 1 1 0 1 0 1 0 1 1 0 0\n",
            " 1 1 1 1 1 1 1 0 0 1 1 1 0 0 0 1 1 0 0 1 1 1 0 0 1 0 0 0 0 1 0 1 1 1 0 1 1\n",
            " 0 1 1 1 1 1 0 1 1 0 0 0 1 1 1 0 1 0 0 0 0 1 0 0 1 1 1 0 0 0 0 0 0 1 0 0 0\n",
            " 1 1 0 1 1 1 1 0 0 1 0 1 1 1 0 1 0 1 0 1 1 0 0 0 0 0 1 1 1 1 0 0 0 1 0 0 1\n",
            " 1 0 0 0 0 0 1 0 0 0 1 0 1 1 0 1 0 0 0 1 1 1 1 1 1 0 0 1 1 1 1 0 1 0 1 0 0\n",
            " 0 0 1 0 1 1 0 1 1 1 0 0 1 1 0 0 0 0 1 0 0 1 0 1 0 1 1 0 1 1 0 0 1 0 1 1 1\n",
            " 1 0 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 0 0 0 0 1 1 1 0 0 0 0 1 0 1 1 1 0 1 1 1\n",
            " 1 1 0 0 1 1 0 1 0 0 1 0 1 0 1 0 0 1 0 0 1 1 0 0 1 1 0 0 0 0 1 0 1 1 0 1 1\n",
            " 0 1 1 0 1 1 0 1 1 0 1 0 1 0 1 1 0 0 0 1 0 1 1 1 1 1 0 0 1 1 1 0 0 1 1 1 1\n",
            " 0 1 0 0 0 0 1 0 1 0 0 0 0 0 1 1 0 0 0 0 1 0 1 0 1 0 0 1 0 1 0 0 0 1 0 0 1\n",
            " 1 1 1 0 0 0 1 1 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0 1\n",
            " 0 0 1 0 1 0 0 1 0 0 0 1 1 0 1 1 0 0 1 1 0 0 1 0 0 1 1 0 0 0 0 1 1 0 0 1 0\n",
            " 1 1 1 0 0 1 0 1 1 0 0 0 1 0 0 1 1 1 1 0 0 0 1 0 0 0 0 1 1 0 1 1 1 1 0 0 0\n",
            " 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 0 0 0 1 0 1 0 1 0 0 0 0 1 1 0 0 1 1 0 0 1 0\n",
            " 1 1 0 1 1 0 1 0 0 0 0 1 0 1 0 1 1 0 1 1 1 0 1 1 1 0 1 1 0 1 1 0 1 1 0 1 1\n",
            " 0 0 1 1 1 1 0 1 0 1 1 0 1 0 0 0 0 0 0 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 0 1 1\n",
            " 0 1 1 0 0 1 0 1 0 0 0 0 0 1 0 0 1 0 1 1 0 0 1 0 1 0 1 0 0 0 1 1 1 0 0 1 1\n",
            " 0 0 1 1 1 0 0]\n",
            "uniques chosen: 10 <= should be equal to: 10\n",
            "trainset before adding uncertain samples (370, 10) (370,)\n",
            "trainset after adding uncertain samples (380, 10) (380,)\n",
            "updated train set: (380, 10) (380,) unique(labels): [168 212] [0 1]\n",
            "val set: (922, 10) (922,)\n",
            "\n",
            "Train set: (380, 10)\n",
            "Validation set: (922, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 38\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.090 s \n",
            "\n",
            "Accuracy rate is 78.341014 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.87      0.86       321\n",
            "           1       0.59      0.55      0.57       113\n",
            "\n",
            "    accuracy                           0.78       434\n",
            "   macro avg       0.72      0.71      0.71       434\n",
            "weighted avg       0.78      0.78      0.78       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[278  43]\n",
            " [ 51  62]]\n",
            "--------------------------------\n",
            "val predicted: (922,) [0 1 1 1 0 1 0 0 1 1 1 0 1 0 0 1 0 1 0 0 1 0 0 0 1 0 1 1 0 1 1 1 1 1 0 0 0\n",
            " 0 1 1 0 1 1 1 0 1 1 0 1 0 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1\n",
            " 1 0 1 0 0 0 1 0 1 1 0 1 1 1 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 1 0\n",
            " 1 0 0 0 0 0 0 1 0 1 1 1 0 0 1 0 1 1 0 0 0 0 1 1 1 1 1 0 1 1 0 0 1 0 1 1 1\n",
            " 1 0 0 0 0 1 1 0 1 0 1 1 1 1 1 0 0 1 1 0 1 1 1 0 0 0 1 0 0 0 1 0 1 1 1 1 0\n",
            " 0 0 0 1 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 1 0 1 1 0 0 1 1 1 1 0 1 0\n",
            " 1 1 1 1 0 1 1 0 1 1 1 0 1 1 0 1 1 1 0 1 1 1 1 0 0 1 1 0 1 0 0 1 1 1 0 1 0\n",
            " 0 0 0 0 1 0 1 0 1 0 0 1 1 0 1 0 1 0 0 0 0 0 0 1 1 1 1 0 1 1 0 0 1 0 1 0 0\n",
            " 1 0 0 0 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1 0 0 1 1 0 1 0 1 0 1 1 0 0 1 1 1 1\n",
            " 1 1 1 0 0 1 1 1 0 0 0 1 1 0 0 1 1 1 0 0 1 0 0 0 0 1 0 1 1 1 0 1 1 0 1 1 1\n",
            " 1 1 0 1 1 0 0 0 1 1 1 0 1 1 0 0 0 1 0 0 1 1 1 0 0 0 0 0 0 1 0 0 0 1 1 0 1\n",
            " 1 1 1 0 0 1 0 1 1 1 0 1 0 1 0 1 1 0 0 0 0 0 1 1 1 1 0 0 0 1 0 0 1 1 0 0 0\n",
            " 0 0 1 0 0 1 0 1 1 0 1 0 0 0 1 1 1 1 1 1 0 0 1 1 1 1 0 1 0 1 0 0 0 0 1 0 1\n",
            " 0 0 1 1 1 0 0 1 1 0 0 0 0 1 0 0 1 0 1 0 1 1 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1\n",
            " 1 1 1 0 1 1 1 1 0 1 1 1 0 0 0 0 0 1 1 0 0 0 0 1 0 1 1 1 0 1 1 1 1 1 0 0 1\n",
            " 1 0 1 0 0 0 1 0 1 0 0 1 0 0 1 1 0 0 1 1 0 0 0 0 1 0 1 1 0 1 1 0 1 1 0 1 1\n",
            " 0 1 1 0 1 0 1 0 1 1 0 0 1 0 1 1 1 1 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 0 1 0\n",
            " 1 0 0 0 0 0 1 1 0 0 0 0 1 0 1 0 1 0 0 1 0 1 0 0 0 1 0 0 1 1 1 1 0 0 0 1 1\n",
            " 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 1 0 1 0 0 1\n",
            " 0 0 0 1 1 0 1 1 0 0 1 1 0 0 1 0 0 1 1 0 0 0 0 1 1 0 0 1 0 1 1 1 0 0 1 0 1\n",
            " 1 0 0 0 1 0 0 1 1 1 1 0 0 0 1 0 0 0 0 1 1 0 1 1 1 1 0 0 0 0 0 0 1 1 1 1 1\n",
            " 1 0 1 0 0 0 1 0 0 0 1 1 1 0 0 0 0 0 0 1 1 0 0 1 1 0 0 1 0 1 1 0 1 1 0 1 0\n",
            " 0 0 0 1 0 1 0 1 1 0 1 1 1 0 1 1 1 0 1 1 0 1 1 0 1 1 0 1 1 0 1 1 1 1 1 0 1\n",
            " 0 1 1 0 1 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 1 1 1 0 0 0 1 1 0 1 1 0 0 1 1 1 0\n",
            " 0 0 0 0 1 0 0 1 0 1 1 0 0 1 0 1 0 1 0 0 0 1 1 1 0 0 1 1 0 1 1 1 0 0]\n",
            "probabilities: (922, 2) \n",
            " [0 1 1 1 0 1 0 0 1 1 1 0 1 0 0 1 0 1 0 0 1 0 0 0 1 0 1 1 0 1 1 1 1 1 0 0 0\n",
            " 0 1 1 0 1 1 1 0 1 1 0 1 0 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1\n",
            " 1 0 1 0 0 0 1 0 1 1 0 1 1 1 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 1 0\n",
            " 1 0 0 0 0 0 0 1 0 1 1 1 0 0 1 0 1 1 0 0 0 0 1 1 1 1 1 0 1 1 0 0 1 0 1 1 1\n",
            " 1 0 0 0 0 1 1 0 1 0 1 1 1 1 1 0 0 1 1 0 1 1 1 0 0 0 1 0 0 0 1 0 1 1 1 1 0\n",
            " 0 0 0 1 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 1 0 1 1 0 0 1 1 1 1 0 1 0\n",
            " 1 1 1 1 0 1 1 0 1 1 1 0 1 1 0 1 1 1 0 1 1 1 1 0 0 1 1 0 1 0 0 1 1 1 0 1 0\n",
            " 0 0 0 0 1 0 1 0 1 0 0 1 1 0 1 0 1 0 0 0 0 0 0 1 1 1 1 0 1 1 0 0 1 0 1 0 0\n",
            " 1 0 0 0 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1 0 0 1 1 0 1 0 1 0 1 1 0 0 1 1 1 1\n",
            " 1 1 1 0 0 1 1 1 0 0 0 1 1 0 0 1 1 1 0 0 1 0 0 0 0 1 0 1 1 1 0 1 1 0 1 1 1\n",
            " 1 1 0 1 1 0 0 0 1 1 1 0 1 1 0 0 0 1 0 0 1 1 1 0 0 0 0 0 0 1 0 0 0 1 1 0 1\n",
            " 1 1 1 0 0 1 0 1 1 1 0 1 0 1 0 1 1 0 0 0 0 0 1 1 1 1 0 0 0 1 0 0 1 1 0 0 0\n",
            " 0 0 1 0 0 1 0 1 1 0 1 0 0 0 1 1 1 1 1 1 0 0 1 1 1 1 0 1 0 1 0 0 0 0 1 0 1\n",
            " 0 0 1 1 1 0 0 1 1 0 0 0 0 1 0 0 1 0 1 0 1 1 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1\n",
            " 1 1 1 0 1 1 1 1 0 1 1 1 0 0 0 0 0 1 1 0 0 0 0 1 0 1 1 1 0 1 1 1 1 1 0 0 1\n",
            " 1 0 1 0 0 0 1 0 1 0 0 1 0 0 1 1 0 0 1 1 0 0 0 0 1 0 1 1 0 1 1 0 1 1 0 1 1\n",
            " 0 1 1 0 1 0 1 0 1 1 0 0 1 0 1 1 1 1 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 0 1 0\n",
            " 1 0 0 0 0 0 1 1 0 0 0 0 1 0 1 0 1 0 0 1 0 1 0 0 0 1 0 0 1 1 1 1 0 0 0 1 1\n",
            " 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 1 0 1 0 0 1\n",
            " 0 0 0 1 1 0 1 1 0 0 1 1 0 0 1 0 0 1 1 0 0 0 0 1 1 0 0 1 0 1 1 1 0 0 1 0 1\n",
            " 1 0 0 0 1 0 0 1 1 1 1 0 0 0 1 0 0 0 0 1 1 0 1 1 1 1 0 0 0 0 0 0 1 1 1 1 1\n",
            " 1 0 1 0 0 0 1 0 0 0 1 1 1 0 0 0 0 0 0 1 1 0 0 1 1 0 0 1 0 1 1 0 1 1 0 1 0\n",
            " 0 0 0 1 0 1 0 1 1 0 1 1 1 0 1 1 1 0 1 1 0 1 1 0 1 1 0 1 1 0 1 1 1 1 1 0 1\n",
            " 0 1 1 0 1 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 1 1 1 0 0 0 1 1 0 1 1 0 0 1 1 1 0\n",
            " 0 0 0 0 1 0 0 1 0 1 1 0 0 1 0 1 0 1 0 0 0 1 1 1 0 0 1 1 0 1 1 1 0 0]\n",
            "uniques chosen: 10 <= should be equal to: 10\n",
            "trainset before adding uncertain samples (380, 10) (380,)\n",
            "trainset after adding uncertain samples (390, 10) (390,)\n",
            "updated train set: (390, 10) (390,) unique(labels): [171 219] [0 1]\n",
            "val set: (912, 10) (912,)\n",
            "\n",
            "Train set: (390, 10)\n",
            "Validation set: (912, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 39\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.082 s \n",
            "\n",
            "Accuracy rate is 77.880184 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.87      0.85       321\n",
            "           1       0.58      0.52      0.55       113\n",
            "\n",
            "    accuracy                           0.78       434\n",
            "   macro avg       0.71      0.70      0.70       434\n",
            "weighted avg       0.77      0.78      0.77       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[279  42]\n",
            " [ 54  59]]\n",
            "--------------------------------\n",
            "val predicted: (912,) [0 1 1 1 0 1 0 0 1 1 1 0 1 0 0 1 0 1 0 0 1 0 0 0 1 0 1 1 0 1 1 1 1 1 0 0 0\n",
            " 0 1 1 0 1 1 1 0 1 1 0 1 0 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1\n",
            " 1 0 1 0 0 0 1 0 1 1 0 1 1 1 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 1 0\n",
            " 1 0 0 0 0 0 0 1 0 1 1 1 0 0 1 0 1 1 0 0 0 0 1 1 1 1 1 0 1 1 0 0 1 0 1 1 1\n",
            " 1 0 0 0 0 1 1 0 1 0 1 1 1 1 1 0 0 1 1 0 1 1 1 0 0 0 1 0 0 0 1 0 1 1 1 1 0\n",
            " 0 0 0 1 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 1 1 0 1 1 0 1 1 1 1 0 1 0 1\n",
            " 1 1 1 0 1 1 0 1 1 1 0 1 1 0 1 1 0 1 1 1 1 0 0 1 1 0 1 0 0 1 1 1 0 1 0 0 0\n",
            " 0 0 1 0 1 0 1 0 0 1 1 0 1 0 1 0 0 0 0 0 0 1 1 0 1 1 0 0 1 0 1 0 0 1 0 0 0\n",
            " 0 1 1 1 1 1 1 1 1 0 0 1 0 1 0 1 0 0 1 1 0 1 0 1 0 1 1 0 0 1 1 1 1 1 1 1 0\n",
            " 0 1 1 1 0 0 0 1 1 0 0 1 1 1 0 0 1 0 1 0 0 1 1 1 1 0 1 1 0 1 1 1 1 1 0 1 1\n",
            " 0 0 0 1 1 1 0 1 0 0 0 0 1 0 1 1 1 1 0 0 0 0 0 0 1 0 0 0 1 1 0 1 1 1 1 0 0\n",
            " 1 0 1 1 1 0 1 0 1 0 1 1 0 0 0 0 0 1 1 1 1 0 0 0 1 0 0 1 1 0 0 0 0 0 1 0 0\n",
            " 1 0 1 1 0 1 0 0 1 1 1 1 1 1 0 0 1 1 1 0 1 0 1 0 0 0 0 1 0 1 0 0 1 1 1 0 0\n",
            " 1 1 0 0 0 0 1 0 0 1 0 1 0 1 1 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1\n",
            " 1 0 1 1 1 0 0 0 0 0 0 1 0 0 0 0 1 0 1 1 1 0 1 1 1 1 1 0 0 1 1 0 1 0 0 0 1\n",
            " 0 1 0 0 1 0 0 1 1 0 0 1 1 1 0 0 0 1 0 1 1 0 1 1 0 1 1 0 1 1 0 1 1 0 1 0 1\n",
            " 0 1 1 0 0 1 1 1 1 1 1 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 0 1 0 1 0 0 0 0 0 1\n",
            " 1 0 0 0 0 1 0 1 0 1 0 0 1 1 1 0 0 0 1 0 0 1 1 1 1 0 0 0 1 1 1 1 0 1 0 0 1\n",
            " 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 1 0 1 0 0 1 0 0 0 1 1 0 1\n",
            " 1 0 0 1 1 0 0 1 0 0 1 1 0 0 0 0 1 1 0 0 1 0 1 1 1 0 0 1 0 1 1 0 0 0 1 0 0\n",
            " 1 1 1 1 0 0 0 1 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1\n",
            " 0 0 0 1 1 1 0 1 0 1 0 0 1 1 0 0 1 1 0 0 1 0 1 1 0 1 1 0 1 0 0 0 0 1 0 1 0\n",
            " 1 1 0 1 1 1 1 1 1 0 1 1 0 1 1 0 1 1 0 1 1 0 1 1 1 0 1 0 1 1 0 1 0 0 0 0 0\n",
            " 0 0 1 1 0 1 0 1 0 0 1 1 1 0 0 0 1 1 0 1 1 0 0 1 1 1 0 0 0 0 0 1 0 0 1 0 1\n",
            " 1 0 0 1 0 1 0 1 0 0 0 1 1 1 0 0 1 1 0 1 1 1 0 0]\n",
            "probabilities: (912, 2) \n",
            " [0 1 1 1 0 1 0 0 1 1 1 0 1 0 0 1 0 1 0 0 1 0 0 0 1 0 1 1 0 1 1 1 1 1 0 0 0\n",
            " 0 1 1 0 1 1 1 0 1 1 0 1 0 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1\n",
            " 1 0 1 0 0 0 1 0 1 1 0 1 1 1 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 1 0\n",
            " 1 0 0 0 0 0 0 1 0 1 1 1 0 0 1 0 1 1 0 0 0 0 1 1 1 1 1 0 1 1 0 0 1 0 1 1 1\n",
            " 1 0 0 0 0 1 1 0 1 0 1 1 1 1 1 0 0 1 1 0 1 1 1 0 0 0 1 0 0 0 1 0 1 1 1 1 0\n",
            " 0 0 0 1 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 1 1 0 1 1 0 1 1 1 1 0 1 0 1\n",
            " 1 1 1 0 1 1 0 1 1 1 0 1 1 0 1 1 0 1 1 1 1 0 0 1 1 0 1 0 0 1 1 1 0 1 0 0 0\n",
            " 0 0 1 0 1 0 1 0 0 1 1 0 1 0 1 0 0 0 0 0 0 1 1 0 1 1 0 0 1 0 1 0 0 1 0 0 0\n",
            " 0 1 1 1 1 1 1 1 1 0 0 1 0 1 0 1 0 0 1 1 0 1 0 1 0 1 1 0 0 1 1 1 1 1 1 1 0\n",
            " 0 1 1 1 0 0 0 1 1 0 0 1 1 1 0 0 1 0 1 0 0 1 1 1 1 0 1 1 0 1 1 1 1 1 0 1 1\n",
            " 0 0 0 1 1 1 0 1 0 0 0 0 1 0 1 1 1 1 0 0 0 0 0 0 1 0 0 0 1 1 0 1 1 1 1 0 0\n",
            " 1 0 1 1 1 0 1 0 1 0 1 1 0 0 0 0 0 1 1 1 1 0 0 0 1 0 0 1 1 0 0 0 0 0 1 0 0\n",
            " 1 0 1 1 0 1 0 0 1 1 1 1 1 1 0 0 1 1 1 0 1 0 1 0 0 0 0 1 0 1 0 0 1 1 1 0 0\n",
            " 1 1 0 0 0 0 1 0 0 1 0 1 0 1 1 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1\n",
            " 1 0 1 1 1 0 0 0 0 0 0 1 0 0 0 0 1 0 1 1 1 0 1 1 1 1 1 0 0 1 1 0 1 0 0 0 1\n",
            " 0 1 0 0 1 0 0 1 1 0 0 1 1 1 0 0 0 1 0 1 1 0 1 1 0 1 1 0 1 1 0 1 1 0 1 0 1\n",
            " 0 1 1 0 0 1 1 1 1 1 1 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 0 1 0 1 0 0 0 0 0 1\n",
            " 1 0 0 0 0 1 0 1 0 1 0 0 1 1 1 0 0 0 1 0 0 1 1 1 1 0 0 0 1 1 1 1 0 1 0 0 1\n",
            " 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 1 0 1 0 0 1 0 0 0 1 1 0 1\n",
            " 1 0 0 1 1 0 0 1 0 0 1 1 0 0 0 0 1 1 0 0 1 0 1 1 1 0 0 1 0 1 1 0 0 0 1 0 0\n",
            " 1 1 1 1 0 0 0 1 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1\n",
            " 0 0 0 1 1 1 0 1 0 1 0 0 1 1 0 0 1 1 0 0 1 0 1 1 0 1 1 0 1 0 0 0 0 1 0 1 0\n",
            " 1 1 0 1 1 1 1 1 1 0 1 1 0 1 1 0 1 1 0 1 1 0 1 1 1 0 1 0 1 1 0 1 0 0 0 0 0\n",
            " 0 0 1 1 0 1 0 1 0 0 1 1 1 0 0 0 1 1 0 1 1 0 0 1 1 1 0 0 0 0 0 1 0 0 1 0 1\n",
            " 1 0 0 1 0 1 0 1 0 0 0 1 1 1 0 0 1 1 0 1 1 1 0 0]\n",
            "uniques chosen: 10 <= should be equal to: 10\n",
            "trainset before adding uncertain samples (390, 10) (390,)\n",
            "trainset after adding uncertain samples (400, 10) (400,)\n",
            "updated train set: (400, 10) (400,) unique(labels): [175 225] [0 1]\n",
            "val set: (902, 10) (902,)\n",
            "\n",
            "Train set: (400, 10)\n",
            "Validation set: (902, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 40\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.059 s \n",
            "\n",
            "Accuracy rate is 77.880184 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.87      0.85       321\n",
            "           1       0.59      0.51      0.55       113\n",
            "\n",
            "    accuracy                           0.78       434\n",
            "   macro avg       0.71      0.69      0.70       434\n",
            "weighted avg       0.77      0.78      0.77       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[280  41]\n",
            " [ 55  58]]\n",
            "--------------------------------\n",
            "val predicted: (902,) [0 1 1 1 0 1 0 0 1 1 0 1 0 0 1 0 1 0 0 1 0 0 0 1 0 1 1 0 1 1 1 1 1 0 0 0 0\n",
            " 1 1 0 1 1 1 0 1 1 0 1 0 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 1\n",
            " 0 0 0 1 0 1 1 0 1 1 1 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 1 0 1 0 0\n",
            " 0 0 0 1 0 1 1 1 0 0 1 0 1 1 0 0 1 0 1 1 1 1 1 0 1 1 1 0 1 0 1 0 1 1 0 0 0\n",
            " 0 1 1 0 1 0 1 1 1 1 1 0 0 1 1 0 0 1 1 0 0 0 1 0 0 0 1 0 1 1 1 1 0 0 0 0 1\n",
            " 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 1 0 0 0 1 1 0 1 1 0 1 1 1 1 0 1 0 1 1 1 1 0\n",
            " 1 1 0 1 1 1 0 1 1 0 1 1 0 1 1 1 1 0 0 1 1 0 1 0 0 1 1 1 0 1 0 0 0 0 0 1 0\n",
            " 1 0 1 0 0 1 1 0 1 0 1 0 0 0 0 0 0 1 1 0 1 1 0 0 1 0 1 0 0 1 0 0 0 0 1 1 1\n",
            " 1 1 1 1 1 0 0 1 0 1 1 1 0 0 1 1 0 1 0 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0 1 1 1\n",
            " 0 0 0 1 1 0 0 1 1 1 0 0 1 0 0 0 0 1 1 1 1 0 1 1 0 1 1 1 1 1 0 1 1 0 0 0 1\n",
            " 1 1 0 1 0 0 0 1 0 1 1 1 1 0 0 0 0 0 0 1 0 0 0 0 1 0 1 1 1 1 0 0 1 0 1 1 0\n",
            " 1 0 1 0 1 1 0 0 0 0 0 1 1 1 1 0 0 0 1 0 0 1 1 0 0 0 0 0 1 0 0 1 0 1 1 0 1\n",
            " 0 0 1 1 1 1 1 1 0 0 1 1 1 0 1 0 1 0 0 0 0 1 0 1 0 0 1 1 1 0 0 1 1 0 0 0 1\n",
            " 0 0 1 0 1 0 1 1 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 0 0\n",
            " 0 0 1 0 1 0 0 0 0 1 0 1 1 1 0 1 1 1 1 1 0 0 1 1 0 1 0 0 0 1 0 1 0 0 1 0 0\n",
            " 1 1 0 0 1 1 0 0 0 0 1 0 1 1 0 1 1 0 1 1 0 1 1 0 1 1 0 1 0 1 0 1 1 0 0 1 0\n",
            " 1 1 1 1 1 0 0 1 1 1 0 0 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 0 0 1 1 0 0 0 0 1 0\n",
            " 1 0 1 0 0 1 0 1 0 0 0 1 0 0 1 1 0 0 0 0 1 1 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1\n",
            " 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 1 0 1 0 0 1 0 0 0 1 1 0 1 1 0 0 1 1 0 0 1 0\n",
            " 0 1 1 0 0 0 0 1 1 0 0 1 0 1 1 1 0 0 1 0 1 1 0 0 0 1 0 0 1 1 1 1 0 0 0 1 0\n",
            " 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 0 0 0 1 1 1 0 1 0\n",
            " 0 0 0 1 1 0 0 1 1 0 0 1 0 1 1 0 1 1 0 1 0 0 0 0 1 0 1 1 1 1 0 1 1 1 1 1 1\n",
            " 0 1 1 0 1 1 0 1 1 0 1 1 0 1 1 1 0 1 0 1 1 0 1 0 0 0 0 0 0 0 1 0 1 0 1 0 0\n",
            " 1 1 1 0 0 0 1 1 0 1 1 0 0 1 1 1 0 0 0 0 0 1 0 0 1 0 1 1 0 0 1 0 1 0 1 0 0\n",
            " 0 1 1 1 0 0 1 1 0 1 1 1 0 0]\n",
            "probabilities: (902, 2) \n",
            " [0 1 1 1 0 1 0 0 1 1 0 1 0 0 1 0 1 0 0 1 0 0 0 1 0 1 1 0 1 1 1 1 1 0 0 0 0\n",
            " 1 1 0 1 1 1 0 1 1 0 1 0 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 1\n",
            " 0 0 0 1 0 1 1 0 1 1 1 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 1 0 1 0 0\n",
            " 0 0 0 1 0 1 1 1 0 0 1 0 1 1 0 0 1 0 1 1 1 1 1 0 1 1 1 0 1 0 1 0 1 1 0 0 0\n",
            " 0 1 1 0 1 0 1 1 1 1 1 0 0 1 1 0 0 1 1 0 0 0 1 0 0 0 1 0 1 1 1 1 0 0 0 0 1\n",
            " 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 1 0 0 0 1 1 0 1 1 0 1 1 1 1 0 1 0 1 1 1 1 0\n",
            " 1 1 0 1 1 1 0 1 1 0 1 1 0 1 1 1 1 0 0 1 1 0 1 0 0 1 1 1 0 1 0 0 0 0 0 1 0\n",
            " 1 0 1 0 0 1 1 0 1 0 1 0 0 0 0 0 0 1 1 0 1 1 0 0 1 0 1 0 0 1 0 0 0 0 1 1 1\n",
            " 1 1 1 1 1 0 0 1 0 1 1 1 0 0 1 1 0 1 0 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0 1 1 1\n",
            " 0 0 0 1 1 0 0 1 1 1 0 0 1 0 0 0 0 1 1 1 1 0 1 1 0 1 1 1 1 1 0 1 1 0 0 0 1\n",
            " 1 1 0 1 0 0 0 1 0 1 1 1 1 0 0 0 0 0 0 1 0 0 0 0 1 0 1 1 1 1 0 0 1 0 1 1 0\n",
            " 1 0 1 0 1 1 0 0 0 0 0 1 1 1 1 0 0 0 1 0 0 1 1 0 0 0 0 0 1 0 0 1 0 1 1 0 1\n",
            " 0 0 1 1 1 1 1 1 0 0 1 1 1 0 1 0 1 0 0 0 0 1 0 1 0 0 1 1 1 0 0 1 1 0 0 0 1\n",
            " 0 0 1 0 1 0 1 1 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 0 0\n",
            " 0 0 1 0 1 0 0 0 0 1 0 1 1 1 0 1 1 1 1 1 0 0 1 1 0 1 0 0 0 1 0 1 0 0 1 0 0\n",
            " 1 1 0 0 1 1 0 0 0 0 1 0 1 1 0 1 1 0 1 1 0 1 1 0 1 1 0 1 0 1 0 1 1 0 0 1 0\n",
            " 1 1 1 1 1 0 0 1 1 1 0 0 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 0 0 1 1 0 0 0 0 1 0\n",
            " 1 0 1 0 0 1 0 1 0 0 0 1 0 0 1 1 0 0 0 0 1 1 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1\n",
            " 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 1 0 1 0 0 1 0 0 0 1 1 0 1 1 0 0 1 1 0 0 1 0\n",
            " 0 1 1 0 0 0 0 1 1 0 0 1 0 1 1 1 0 0 1 0 1 1 0 0 0 1 0 0 1 1 1 1 0 0 0 1 0\n",
            " 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 0 0 0 1 1 1 0 1 0\n",
            " 0 0 0 1 1 0 0 1 1 0 0 1 0 1 1 0 1 1 0 1 0 0 0 0 1 0 1 1 1 1 0 1 1 1 1 1 1\n",
            " 0 1 1 0 1 1 0 1 1 0 1 1 0 1 1 1 0 1 0 1 1 0 1 0 0 0 0 0 0 0 1 0 1 0 1 0 0\n",
            " 1 1 1 0 0 0 1 1 0 1 1 0 0 1 1 1 0 0 0 0 0 1 0 0 1 0 1 1 0 0 1 0 1 0 1 0 0\n",
            " 0 1 1 1 0 0 1 1 0 1 1 1 0 0]\n",
            "uniques chosen: 10 <= should be equal to: 10\n",
            "trainset before adding uncertain samples (400, 10) (400,)\n",
            "trainset after adding uncertain samples (410, 10) (410,)\n",
            "updated train set: (410, 10) (410,) unique(labels): [178 232] [0 1]\n",
            "val set: (892, 10) (892,)\n",
            "\n",
            "Train set: (410, 10)\n",
            "Validation set: (892, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 41\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.070 s \n",
            "\n",
            "Accuracy rate is 78.571429 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.87      0.86       321\n",
            "           1       0.60      0.54      0.57       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.72      0.71      0.71       434\n",
            "weighted avg       0.78      0.79      0.78       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[280  41]\n",
            " [ 52  61]]\n",
            "--------------------------------\n",
            "val predicted: (892,) [0 1 1 1 0 1 0 0 1 1 0 1 0 1 1 0 1 0 0 1 0 0 0 1 0 1 1 0 1 1 1 1 1 0 0 0 0\n",
            " 1 1 0 1 1 1 0 1 1 0 1 0 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 1\n",
            " 0 0 0 1 0 1 1 0 1 1 1 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 1 0 1 0 0\n",
            " 0 0 0 1 0 1 1 1 0 0 1 0 1 1 0 0 1 0 1 1 1 1 1 0 1 1 1 0 1 0 1 0 1 1 0 0 0\n",
            " 0 1 1 1 1 0 1 1 1 1 1 0 0 1 1 0 1 1 1 0 0 0 1 0 0 0 1 0 1 1 1 1 0 0 0 0 1\n",
            " 1 0 1 0 0 1 0 1 0 0 1 1 1 0 1 0 0 0 1 1 0 1 1 0 1 1 1 1 0 1 0 1 1 1 1 0 1\n",
            " 1 0 1 1 1 0 1 1 0 1 1 0 1 1 1 1 0 0 1 1 0 1 0 0 1 1 1 0 1 0 0 0 0 1 1 0 1\n",
            " 0 1 0 0 1 1 0 1 0 1 0 0 0 0 0 0 1 1 0 1 1 0 0 1 0 1 0 0 1 0 0 0 1 1 1 1 1\n",
            " 1 1 1 0 0 1 0 1 1 1 0 0 1 1 0 1 0 1 0 1 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 0 0\n",
            " 0 1 1 0 1 1 1 0 0 1 0 0 0 0 1 1 1 1 0 1 1 0 1 1 1 1 1 0 1 1 0 0 0 1 1 1 0\n",
            " 1 0 0 0 1 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 0 1 1 1 1 0 0 1 0 1 1 0 1 0 1 0\n",
            " 1 1 0 0 0 0 0 1 1 1 1 0 0 0 1 0 0 1 1 0 0 0 0 1 0 0 1 0 1 1 0 1 0 0 1 1 1\n",
            " 1 1 1 0 0 1 1 1 0 1 0 1 0 0 0 1 0 1 0 0 1 1 1 0 0 1 1 0 0 0 1 0 0 1 0 1 0\n",
            " 1 1 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 0 0 0 0 1 0 1 0\n",
            " 0 0 0 1 0 1 1 1 0 1 1 1 1 1 0 0 1 1 0 1 0 0 0 1 0 1 0 0 1 0 0 1 1 0 0 1 1\n",
            " 1 0 0 0 1 0 1 1 0 1 1 0 1 1 0 1 1 0 1 1 0 1 0 1 0 1 1 0 0 1 0 1 1 1 1 1 0\n",
            " 0 1 1 1 0 0 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 0 0 1 1 0 0 0 0 1 0 1 0 1 0 0 1\n",
            " 0 1 0 0 1 0 0 1 1 0 0 0 0 1 1 1 1 0 1 0 0 1 0 1 1 1 1 1 1 0 0 0 0 0 0 0 1\n",
            " 1 0 0 0 1 0 0 1 0 1 0 0 1 0 0 0 1 1 0 1 1 0 0 1 1 0 0 1 0 0 1 1 0 0 0 0 1\n",
            " 1 0 0 1 0 1 1 1 0 0 1 0 1 1 0 0 0 1 0 0 1 1 1 1 0 0 0 1 0 0 0 1 1 1 1 1 1\n",
            " 1 1 0 0 0 0 0 0 1 1 1 1 1 0 1 0 0 0 1 0 0 0 1 1 1 0 1 0 0 0 0 1 1 0 1 1 1\n",
            " 0 0 1 0 1 1 0 1 1 0 1 0 0 0 0 1 0 1 0 1 1 1 1 1 1 1 1 0 1 1 0 1 1 0 1 1 0\n",
            " 1 1 0 1 1 1 0 1 0 1 1 0 1 0 0 0 0 0 0 1 1 0 1 0 1 0 0 1 1 1 0 0 0 1 1 0 1\n",
            " 1 0 0 1 1 1 0 0 0 0 0 1 0 0 1 0 1 1 0 0 1 0 1 0 1 0 0 0 1 1 1 0 0 1 1 0 1\n",
            " 1 1 0 0]\n",
            "probabilities: (892, 2) \n",
            " [0 1 1 1 0 1 0 0 1 1 0 1 0 1 1 0 1 0 0 1 0 0 0 1 0 1 1 0 1 1 1 1 1 0 0 0 0\n",
            " 1 1 0 1 1 1 0 1 1 0 1 0 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 1\n",
            " 0 0 0 1 0 1 1 0 1 1 1 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 1 0 1 0 0\n",
            " 0 0 0 1 0 1 1 1 0 0 1 0 1 1 0 0 1 0 1 1 1 1 1 0 1 1 1 0 1 0 1 0 1 1 0 0 0\n",
            " 0 1 1 1 1 0 1 1 1 1 1 0 0 1 1 0 1 1 1 0 0 0 1 0 0 0 1 0 1 1 1 1 0 0 0 0 1\n",
            " 1 0 1 0 0 1 0 1 0 0 1 1 1 0 1 0 0 0 1 1 0 1 1 0 1 1 1 1 0 1 0 1 1 1 1 0 1\n",
            " 1 0 1 1 1 0 1 1 0 1 1 0 1 1 1 1 0 0 1 1 0 1 0 0 1 1 1 0 1 0 0 0 0 1 1 0 1\n",
            " 0 1 0 0 1 1 0 1 0 1 0 0 0 0 0 0 1 1 0 1 1 0 0 1 0 1 0 0 1 0 0 0 1 1 1 1 1\n",
            " 1 1 1 0 0 1 0 1 1 1 0 0 1 1 0 1 0 1 0 1 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 0 0\n",
            " 0 1 1 0 1 1 1 0 0 1 0 0 0 0 1 1 1 1 0 1 1 0 1 1 1 1 1 0 1 1 0 0 0 1 1 1 0\n",
            " 1 0 0 0 1 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 0 1 1 1 1 0 0 1 0 1 1 0 1 0 1 0\n",
            " 1 1 0 0 0 0 0 1 1 1 1 0 0 0 1 0 0 1 1 0 0 0 0 1 0 0 1 0 1 1 0 1 0 0 1 1 1\n",
            " 1 1 1 0 0 1 1 1 0 1 0 1 0 0 0 1 0 1 0 0 1 1 1 0 0 1 1 0 0 0 1 0 0 1 0 1 0\n",
            " 1 1 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 0 0 0 0 1 0 1 0\n",
            " 0 0 0 1 0 1 1 1 0 1 1 1 1 1 0 0 1 1 0 1 0 0 0 1 0 1 0 0 1 0 0 1 1 0 0 1 1\n",
            " 1 0 0 0 1 0 1 1 0 1 1 0 1 1 0 1 1 0 1 1 0 1 0 1 0 1 1 0 0 1 0 1 1 1 1 1 0\n",
            " 0 1 1 1 0 0 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 0 0 1 1 0 0 0 0 1 0 1 0 1 0 0 1\n",
            " 0 1 0 0 1 0 0 1 1 0 0 0 0 1 1 1 1 0 1 0 0 1 0 1 1 1 1 1 1 0 0 0 0 0 0 0 1\n",
            " 1 0 0 0 1 0 0 1 0 1 0 0 1 0 0 0 1 1 0 1 1 0 0 1 1 0 0 1 0 0 1 1 0 0 0 0 1\n",
            " 1 0 0 1 0 1 1 1 0 0 1 0 1 1 0 0 0 1 0 0 1 1 1 1 0 0 0 1 0 0 0 1 1 1 1 1 1\n",
            " 1 1 0 0 0 0 0 0 1 1 1 1 1 0 1 0 0 0 1 0 0 0 1 1 1 0 1 0 0 0 0 1 1 0 1 1 1\n",
            " 0 0 1 0 1 1 0 1 1 0 1 0 0 0 0 1 0 1 0 1 1 1 1 1 1 1 1 0 1 1 0 1 1 0 1 1 0\n",
            " 1 1 0 1 1 1 0 1 0 1 1 0 1 0 0 0 0 0 0 1 1 0 1 0 1 0 0 1 1 1 0 0 0 1 1 0 1\n",
            " 1 0 0 1 1 1 0 0 0 0 0 1 0 0 1 0 1 1 0 0 1 0 1 0 1 0 0 0 1 1 1 0 0 1 1 0 1\n",
            " 1 1 0 0]\n",
            "uniques chosen: 10 <= should be equal to: 10\n",
            "trainset before adding uncertain samples (410, 10) (410,)\n",
            "trainset after adding uncertain samples (420, 10) (420,)\n",
            "updated train set: (420, 10) (420,) unique(labels): [184 236] [0 1]\n",
            "val set: (882, 10) (882,)\n",
            "\n",
            "Train set: (420, 10)\n",
            "Validation set: (882, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 42\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.060 s \n",
            "\n",
            "Accuracy rate is 78.801843 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.87      0.86       321\n",
            "           1       0.60      0.55      0.57       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.72      0.71      0.72       434\n",
            "weighted avg       0.78      0.79      0.78       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[280  41]\n",
            " [ 51  62]]\n",
            "--------------------------------\n",
            "val predicted: (882,) [0 1 1 1 0 1 0 0 1 1 0 1 0 1 1 0 1 0 0 1 0 0 0 1 0 1 1 0 1 1 1 1 1 0 0 0 0\n",
            " 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 1 0\n",
            " 0 0 1 0 1 1 0 1 1 1 0 0 0 1 1 1 0 0 0 0 0 0 1 0 0 0 1 1 0 0 1 0 1 0 0 0 0\n",
            " 0 1 0 1 1 1 0 0 1 0 1 1 0 0 0 0 1 1 1 1 1 0 1 1 1 1 0 1 0 1 1 0 0 0 0 1 1\n",
            " 1 1 0 1 1 1 1 1 0 0 1 1 0 1 1 1 0 0 0 1 0 0 0 1 0 1 1 1 1 0 0 0 0 1 1 0 0\n",
            " 0 1 0 1 0 1 1 1 0 1 0 0 0 1 1 0 1 1 0 1 1 1 1 0 1 0 1 1 1 1 0 1 1 0 1 1 1\n",
            " 0 1 1 0 1 1 0 1 1 1 1 0 0 1 1 0 1 0 0 1 1 1 0 1 0 0 0 0 1 1 0 1 0 1 0 0 1\n",
            " 1 0 1 0 1 0 0 0 0 0 0 1 1 0 1 1 0 0 1 0 1 0 0 1 1 0 0 1 1 1 1 1 1 1 1 0 0\n",
            " 1 0 1 0 1 0 0 1 1 0 1 0 1 0 1 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 0 0 0 1 1 0 1\n",
            " 1 1 0 0 1 0 0 0 0 1 1 1 1 0 1 1 0 1 1 1 1 1 0 1 1 0 0 0 1 1 1 0 0 0 0 0 1\n",
            " 0 1 1 1 0 0 0 0 0 0 0 0 0 0 1 0 1 1 1 1 0 0 1 0 1 1 0 1 0 1 0 1 1 0 0 0 0\n",
            " 0 1 1 1 1 0 0 0 1 0 0 1 1 0 0 0 0 1 0 0 1 0 1 1 0 1 0 0 1 1 1 1 1 1 0 0 1\n",
            " 1 1 0 1 0 1 0 0 0 1 0 1 0 0 1 1 1 0 0 1 1 0 0 0 1 0 0 1 0 1 0 1 1 0 1 1 0\n",
            " 0 1 0 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 0 0 0 0 1 0 1 0 0 0 0 1 0 1\n",
            " 1 1 0 1 1 1 1 1 0 0 1 1 0 1 0 0 0 1 0 1 0 0 1 0 0 1 1 0 0 1 1 1 0 0 0 1 0\n",
            " 1 1 0 1 1 0 1 1 0 1 1 0 1 1 0 1 0 1 0 1 1 0 0 1 0 1 1 1 1 1 0 0 1 1 1 0 0\n",
            " 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 0 0 1 1 0 0 0 0 1 0 1 0 1 0 0 1 0 1 0 1 0 0\n",
            " 1 1 1 0 0 0 1 1 1 1 0 1 0 0 1 0 1 1 1 1 1 1 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0\n",
            " 1 0 1 0 0 1 0 0 0 1 1 0 1 1 0 0 1 1 0 0 1 0 0 1 1 0 0 0 1 1 0 0 1 0 1 1 1\n",
            " 0 0 1 0 1 1 0 0 0 1 0 0 1 1 1 1 0 0 0 1 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 1\n",
            " 1 1 1 1 0 1 0 0 0 1 0 0 0 1 1 1 0 1 0 0 0 0 1 1 0 1 1 1 0 0 1 0 1 1 0 1 1\n",
            " 0 1 0 0 0 0 1 0 1 0 1 1 1 1 1 1 1 0 1 1 0 1 1 0 1 1 0 1 1 0 1 1 1 0 1 0 1\n",
            " 1 0 1 0 0 0 0 0 0 1 1 0 1 0 1 0 0 1 1 1 0 0 0 1 1 0 1 1 0 0 1 1 1 0 0 0 0\n",
            " 0 1 0 0 1 0 1 1 0 0 1 0 1 0 1 0 0 0 1 1 1 0 0 1 1 0 1 1 1 0 0]\n",
            "probabilities: (882, 2) \n",
            " [0 1 1 1 0 1 0 0 1 1 0 1 0 1 1 0 1 0 0 1 0 0 0 1 0 1 1 0 1 1 1 1 1 0 0 0 0\n",
            " 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 1 0\n",
            " 0 0 1 0 1 1 0 1 1 1 0 0 0 1 1 1 0 0 0 0 0 0 1 0 0 0 1 1 0 0 1 0 1 0 0 0 0\n",
            " 0 1 0 1 1 1 0 0 1 0 1 1 0 0 0 0 1 1 1 1 1 0 1 1 1 1 0 1 0 1 1 0 0 0 0 1 1\n",
            " 1 1 0 1 1 1 1 1 0 0 1 1 0 1 1 1 0 0 0 1 0 0 0 1 0 1 1 1 1 0 0 0 0 1 1 0 0\n",
            " 0 1 0 1 0 1 1 1 0 1 0 0 0 1 1 0 1 1 0 1 1 1 1 0 1 0 1 1 1 1 0 1 1 0 1 1 1\n",
            " 0 1 1 0 1 1 0 1 1 1 1 0 0 1 1 0 1 0 0 1 1 1 0 1 0 0 0 0 1 1 0 1 0 1 0 0 1\n",
            " 1 0 1 0 1 0 0 0 0 0 0 1 1 0 1 1 0 0 1 0 1 0 0 1 1 0 0 1 1 1 1 1 1 1 1 0 0\n",
            " 1 0 1 0 1 0 0 1 1 0 1 0 1 0 1 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 0 0 0 1 1 0 1\n",
            " 1 1 0 0 1 0 0 0 0 1 1 1 1 0 1 1 0 1 1 1 1 1 0 1 1 0 0 0 1 1 1 0 0 0 0 0 1\n",
            " 0 1 1 1 0 0 0 0 0 0 0 0 0 0 1 0 1 1 1 1 0 0 1 0 1 1 0 1 0 1 0 1 1 0 0 0 0\n",
            " 0 1 1 1 1 0 0 0 1 0 0 1 1 0 0 0 0 1 0 0 1 0 1 1 0 1 0 0 1 1 1 1 1 1 0 0 1\n",
            " 1 1 0 1 0 1 0 0 0 1 0 1 0 0 1 1 1 0 0 1 1 0 0 0 1 0 0 1 0 1 0 1 1 0 1 1 0\n",
            " 0 1 0 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 0 0 0 0 1 0 1 0 0 0 0 1 0 1\n",
            " 1 1 0 1 1 1 1 1 0 0 1 1 0 1 0 0 0 1 0 1 0 0 1 0 0 1 1 0 0 1 1 1 0 0 0 1 0\n",
            " 1 1 0 1 1 0 1 1 0 1 1 0 1 1 0 1 0 1 0 1 1 0 0 1 0 1 1 1 1 1 0 0 1 1 1 0 0\n",
            " 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 0 0 1 1 0 0 0 0 1 0 1 0 1 0 0 1 0 1 0 1 0 0\n",
            " 1 1 1 0 0 0 1 1 1 1 0 1 0 0 1 0 1 1 1 1 1 1 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0\n",
            " 1 0 1 0 0 1 0 0 0 1 1 0 1 1 0 0 1 1 0 0 1 0 0 1 1 0 0 0 1 1 0 0 1 0 1 1 1\n",
            " 0 0 1 0 1 1 0 0 0 1 0 0 1 1 1 1 0 0 0 1 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 1\n",
            " 1 1 1 1 0 1 0 0 0 1 0 0 0 1 1 1 0 1 0 0 0 0 1 1 0 1 1 1 0 0 1 0 1 1 0 1 1\n",
            " 0 1 0 0 0 0 1 0 1 0 1 1 1 1 1 1 1 0 1 1 0 1 1 0 1 1 0 1 1 0 1 1 1 0 1 0 1\n",
            " 1 0 1 0 0 0 0 0 0 1 1 0 1 0 1 0 0 1 1 1 0 0 0 1 1 0 1 1 0 0 1 1 1 0 0 0 0\n",
            " 0 1 0 0 1 0 1 1 0 0 1 0 1 0 1 0 0 0 1 1 1 0 0 1 1 0 1 1 1 0 0]\n",
            "uniques chosen: 10 <= should be equal to: 10\n",
            "trainset before adding uncertain samples (420, 10) (420,)\n",
            "trainset after adding uncertain samples (430, 10) (430,)\n",
            "updated train set: (430, 10) (430,) unique(labels): [190 240] [0 1]\n",
            "val set: (872, 10) (872,)\n",
            "\n",
            "Train set: (430, 10)\n",
            "Validation set: (872, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 43\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.073 s \n",
            "\n",
            "Accuracy rate is 78.801843 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86       321\n",
            "           1       0.60      0.54      0.57       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.72      0.71      0.71       434\n",
            "weighted avg       0.78      0.79      0.78       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[281  40]\n",
            " [ 52  61]]\n",
            "--------------------------------\n",
            "val predicted: (872,) [0 1 1 1 0 1 1 0 1 1 0 1 0 1 1 0 1 0 0 1 0 0 0 1 0 1 1 0 1 1 1 1 1 0 0 0 0\n",
            " 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 1 0\n",
            " 0 0 1 0 1 1 0 1 1 1 0 0 0 1 1 1 0 0 0 0 0 1 0 0 0 1 1 0 0 1 0 1 0 0 0 0 0\n",
            " 1 0 1 1 1 0 0 1 0 1 1 0 0 1 0 1 1 1 1 1 0 1 1 1 1 0 1 0 1 0 0 0 0 1 1 0 1\n",
            " 0 1 1 1 1 1 0 0 1 1 0 0 1 1 0 0 0 1 0 0 1 0 1 1 1 1 0 0 0 0 1 1 0 0 0 1 0\n",
            " 1 0 1 1 1 0 1 0 0 0 1 1 0 1 1 0 1 1 1 1 0 1 0 1 1 1 1 0 1 1 0 1 1 1 0 1 1\n",
            " 0 1 1 0 1 1 1 1 0 0 1 1 0 1 0 0 1 1 1 0 1 0 0 0 0 1 1 0 1 0 1 0 0 1 1 0 1\n",
            " 0 1 0 0 0 0 0 0 1 1 0 1 1 0 0 1 0 1 0 0 1 1 0 0 1 1 1 1 1 1 1 1 0 0 1 0 1\n",
            " 1 1 0 0 1 1 0 1 0 1 0 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 0 0 0 1 1 0 1 1 1 0 0\n",
            " 1 0 1 0 0 1 1 1 1 0 1 1 0 1 1 1 1 1 0 1 1 0 0 0 1 1 1 0 0 0 0 0 1 0 1 1 1\n",
            " 0 0 0 0 0 0 0 0 0 0 1 0 1 1 1 1 0 0 1 0 1 1 0 1 0 1 0 1 1 0 0 0 0 0 1 1 1\n",
            " 1 0 0 0 1 0 0 1 1 0 0 0 1 0 0 1 0 1 1 0 1 0 0 1 1 1 1 1 1 0 0 1 1 1 0 1 0\n",
            " 1 0 0 0 1 0 1 0 0 1 1 1 0 0 1 1 0 0 0 1 0 0 1 0 1 0 1 1 0 1 1 0 0 1 0 1 1\n",
            " 1 1 0 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 0 0 0 0 1 1 0 0 0 0 1 0 1 1 1 0 1 1 1\n",
            " 1 1 0 0 1 1 0 1 0 0 0 1 0 1 0 0 1 0 0 1 1 0 0 1 1 1 0 0 0 1 0 1 1 0 1 1 0\n",
            " 1 1 0 1 1 0 1 1 0 0 1 0 1 1 0 0 1 0 1 1 1 1 1 0 0 1 1 1 0 0 1 1 1 0 1 0 1\n",
            " 0 0 1 0 1 1 0 0 0 0 1 1 1 0 0 0 1 1 1 0 1 0 0 1 1 1 0 1 0 0 1 1 1 0 0 0 1\n",
            " 1 1 1 0 1 0 0 1 0 1 1 1 1 1 1 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 1 0 1 0 0 1 0\n",
            " 0 0 1 0 0 1 1 0 0 1 1 0 0 1 0 0 1 1 0 0 0 1 1 0 0 1 0 1 1 1 0 0 1 0 1 1 0\n",
            " 0 1 0 0 1 1 1 1 0 0 0 1 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 1 1 1 1 1 0 1 0 0\n",
            " 0 1 0 0 1 1 1 0 1 0 0 0 0 1 1 0 1 1 1 0 0 1 0 1 1 0 1 1 0 1 0 0 0 0 1 0 1\n",
            " 1 1 1 1 1 1 1 1 0 1 1 0 1 1 0 1 1 0 1 1 0 1 1 1 0 1 0 1 1 0 1 0 0 0 0 0 1\n",
            " 1 0 1 0 1 0 0 1 1 1 0 0 0 1 1 0 1 1 0 0 1 1 1 0 0 0 0 0 0 0 0 1 0 1 1 0 0\n",
            " 1 0 1 0 1 1 0 0 1 1 1 0 0 1 1 0 1 1 1 0 0]\n",
            "probabilities: (872, 2) \n",
            " [0 1 1 1 0 1 1 0 1 1 0 1 0 1 1 0 1 0 0 1 0 0 0 1 0 1 1 0 1 1 1 1 1 0 0 0 0\n",
            " 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 1 0\n",
            " 0 0 1 0 1 1 0 1 1 1 0 0 0 1 1 1 0 0 0 0 0 1 0 0 0 1 1 0 0 1 0 1 0 0 0 0 0\n",
            " 1 0 1 1 1 0 0 1 0 1 1 0 0 1 0 1 1 1 1 1 0 1 1 1 1 0 1 0 1 0 0 0 0 1 1 0 1\n",
            " 0 1 1 1 1 1 0 0 1 1 0 0 1 1 0 0 0 1 0 0 1 0 1 1 1 1 0 0 0 0 1 1 0 0 0 1 0\n",
            " 1 0 1 1 1 0 1 0 0 0 1 1 0 1 1 0 1 1 1 1 0 1 0 1 1 1 1 0 1 1 0 1 1 1 0 1 1\n",
            " 0 1 1 0 1 1 1 1 0 0 1 1 0 1 0 0 1 1 1 0 1 0 0 0 0 1 1 0 1 0 1 0 0 1 1 0 1\n",
            " 0 1 0 0 0 0 0 0 1 1 0 1 1 0 0 1 0 1 0 0 1 1 0 0 1 1 1 1 1 1 1 1 0 0 1 0 1\n",
            " 1 1 0 0 1 1 0 1 0 1 0 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 0 0 0 1 1 0 1 1 1 0 0\n",
            " 1 0 1 0 0 1 1 1 1 0 1 1 0 1 1 1 1 1 0 1 1 0 0 0 1 1 1 0 0 0 0 0 1 0 1 1 1\n",
            " 0 0 0 0 0 0 0 0 0 0 1 0 1 1 1 1 0 0 1 0 1 1 0 1 0 1 0 1 1 0 0 0 0 0 1 1 1\n",
            " 1 0 0 0 1 0 0 1 1 0 0 0 1 0 0 1 0 1 1 0 1 0 0 1 1 1 1 1 1 0 0 1 1 1 0 1 0\n",
            " 1 0 0 0 1 0 1 0 0 1 1 1 0 0 1 1 0 0 0 1 0 0 1 0 1 0 1 1 0 1 1 0 0 1 0 1 1\n",
            " 1 1 0 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 0 0 0 0 1 1 0 0 0 0 1 0 1 1 1 0 1 1 1\n",
            " 1 1 0 0 1 1 0 1 0 0 0 1 0 1 0 0 1 0 0 1 1 0 0 1 1 1 0 0 0 1 0 1 1 0 1 1 0\n",
            " 1 1 0 1 1 0 1 1 0 0 1 0 1 1 0 0 1 0 1 1 1 1 1 0 0 1 1 1 0 0 1 1 1 0 1 0 1\n",
            " 0 0 1 0 1 1 0 0 0 0 1 1 1 0 0 0 1 1 1 0 1 0 0 1 1 1 0 1 0 0 1 1 1 0 0 0 1\n",
            " 1 1 1 0 1 0 0 1 0 1 1 1 1 1 1 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 1 0 1 0 0 1 0\n",
            " 0 0 1 0 0 1 1 0 0 1 1 0 0 1 0 0 1 1 0 0 0 1 1 0 0 1 0 1 1 1 0 0 1 0 1 1 0\n",
            " 0 1 0 0 1 1 1 1 0 0 0 1 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 1 1 1 1 1 0 1 0 0\n",
            " 0 1 0 0 1 1 1 0 1 0 0 0 0 1 1 0 1 1 1 0 0 1 0 1 1 0 1 1 0 1 0 0 0 0 1 0 1\n",
            " 1 1 1 1 1 1 1 1 0 1 1 0 1 1 0 1 1 0 1 1 0 1 1 1 0 1 0 1 1 0 1 0 0 0 0 0 1\n",
            " 1 0 1 0 1 0 0 1 1 1 0 0 0 1 1 0 1 1 0 0 1 1 1 0 0 0 0 0 0 0 0 1 0 1 1 0 0\n",
            " 1 0 1 0 1 1 0 0 1 1 1 0 0 1 1 0 1 1 1 0 0]\n",
            "uniques chosen: 10 <= should be equal to: 10\n",
            "trainset before adding uncertain samples (430, 10) (430,)\n",
            "trainset after adding uncertain samples (440, 10) (440,)\n",
            "updated train set: (440, 10) (440,) unique(labels): [195 245] [0 1]\n",
            "val set: (862, 10) (862,)\n",
            "\n",
            "Train set: (440, 10)\n",
            "Validation set: (862, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 44\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.065 s \n",
            "\n",
            "Accuracy rate is 78.110599 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.87      0.85       321\n",
            "           1       0.59      0.52      0.55       113\n",
            "\n",
            "    accuracy                           0.78       434\n",
            "   macro avg       0.71      0.70      0.70       434\n",
            "weighted avg       0.77      0.78      0.78       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[280  41]\n",
            " [ 54  59]]\n",
            "--------------------------------\n",
            "val predicted: (862,) [0 1 1 1 0 1 1 0 1 1 0 1 0 1 1 0 1 0 0 1 0 0 0 1 0 1 1 0 1 1 1 1 1 0 0 0 0\n",
            " 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 1 0\n",
            " 0 0 1 0 1 1 0 1 1 1 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 1 1 0 0 1 0 1 0 0 0 0 0\n",
            " 1 0 1 1 1 0 0 1 0 1 1 0 0 0 1 1 1 1 1 0 1 1 1 1 0 1 0 1 0 0 0 0 1 1 1 1 0\n",
            " 1 1 1 1 1 0 0 1 1 0 1 1 1 0 0 1 0 0 1 0 1 1 1 0 0 0 0 1 1 0 0 0 1 0 1 0 1\n",
            " 1 1 0 1 0 0 0 1 1 0 1 1 0 1 1 1 1 0 1 0 1 1 1 1 0 1 1 0 1 1 1 0 1 1 0 1 1\n",
            " 0 1 1 1 1 0 0 1 1 0 1 0 0 1 1 1 0 1 0 0 0 0 1 1 0 1 0 1 0 0 1 1 0 1 0 1 0\n",
            " 0 0 0 0 1 1 0 1 1 0 1 0 1 0 0 1 1 0 0 1 1 1 1 1 0 1 1 0 0 1 0 1 1 1 0 0 1\n",
            " 1 0 1 0 1 0 1 1 0 1 1 1 1 1 1 1 0 0 1 1 1 0 0 0 1 0 1 1 1 0 0 1 0 0 0 0 1\n",
            " 1 1 1 0 1 1 0 1 1 1 1 1 0 1 1 0 0 0 1 1 1 0 1 0 0 1 0 1 1 1 0 0 0 1 0 0 0\n",
            " 0 0 0 1 0 1 1 1 1 0 0 1 0 1 1 0 1 0 1 0 1 1 0 0 0 0 0 1 1 1 0 0 0 0 1 0 0\n",
            " 1 1 0 0 0 1 0 0 1 0 1 1 0 1 0 0 1 1 1 1 1 0 0 1 1 1 0 1 0 1 0 0 0 1 0 1 0\n",
            " 0 1 1 1 0 0 1 1 0 0 0 1 0 0 1 0 1 0 1 1 0 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1\n",
            " 1 0 1 1 1 1 0 1 1 1 0 0 0 0 1 1 0 0 0 0 1 0 1 1 1 0 1 1 1 1 1 0 0 1 1 0 1\n",
            " 0 0 0 1 0 1 0 0 1 0 0 1 1 0 0 1 1 1 0 0 0 1 0 1 0 1 1 0 1 1 0 1 1 0 1 1 0\n",
            " 0 1 0 1 1 0 0 1 0 1 1 1 1 1 0 0 1 1 1 0 0 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 0\n",
            " 0 1 1 1 0 0 0 1 1 1 0 1 0 0 1 1 1 0 1 0 0 1 1 1 0 0 0 1 1 1 1 0 1 0 0 1 0\n",
            " 1 1 1 1 1 1 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 1 0 1 0 0 1 0 0 0 1 0 0 1 0 0 1\n",
            " 1 0 0 1 0 0 1 1 0 0 0 1 1 0 0 1 0 1 1 1 0 0 1 0 1 1 0 0 0 0 0 1 1 1 1 0 0\n",
            " 0 1 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 1 1 1 1 1 0 1 0 0 0 1 0 0 1 1 1 0 1 0\n",
            " 0 0 0 1 1 0 1 1 1 0 0 1 0 1 1 0 1 1 0 1 0 0 0 0 1 0 1 1 1 1 1 1 1 1 1 0 1\n",
            " 1 0 1 1 0 1 1 0 1 1 0 1 1 1 0 1 0 1 1 0 1 0 0 0 0 0 0 1 0 1 0 1 0 0 1 1 1\n",
            " 0 0 0 1 1 0 1 1 0 0 1 1 1 0 0 0 0 0 1 0 0 1 0 1 1 0 0 1 0 1 0 1 0 0 0 1 1\n",
            " 1 0 0 1 1 0 1 1 1 0 0]\n",
            "probabilities: (862, 2) \n",
            " [0 1 1 1 0 1 1 0 1 1 0 1 0 1 1 0 1 0 0 1 0 0 0 1 0 1 1 0 1 1 1 1 1 0 0 0 0\n",
            " 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 1 0\n",
            " 0 0 1 0 1 1 0 1 1 1 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 1 1 0 0 1 0 1 0 0 0 0 0\n",
            " 1 0 1 1 1 0 0 1 0 1 1 0 0 0 1 1 1 1 1 0 1 1 1 1 0 1 0 1 0 0 0 0 1 1 1 1 0\n",
            " 1 1 1 1 1 0 0 1 1 0 1 1 1 0 0 1 0 0 1 0 1 1 1 0 0 0 0 1 1 0 0 0 1 0 1 0 1\n",
            " 1 1 0 1 0 0 0 1 1 0 1 1 0 1 1 1 1 0 1 0 1 1 1 1 0 1 1 0 1 1 1 0 1 1 0 1 1\n",
            " 0 1 1 1 1 0 0 1 1 0 1 0 0 1 1 1 0 1 0 0 0 0 1 1 0 1 0 1 0 0 1 1 0 1 0 1 0\n",
            " 0 0 0 0 1 1 0 1 1 0 1 0 1 0 0 1 1 0 0 1 1 1 1 1 0 1 1 0 0 1 0 1 1 1 0 0 1\n",
            " 1 0 1 0 1 0 1 1 0 1 1 1 1 1 1 1 0 0 1 1 1 0 0 0 1 0 1 1 1 0 0 1 0 0 0 0 1\n",
            " 1 1 1 0 1 1 0 1 1 1 1 1 0 1 1 0 0 0 1 1 1 0 1 0 0 1 0 1 1 1 0 0 0 1 0 0 0\n",
            " 0 0 0 1 0 1 1 1 1 0 0 1 0 1 1 0 1 0 1 0 1 1 0 0 0 0 0 1 1 1 0 0 0 0 1 0 0\n",
            " 1 1 0 0 0 1 0 0 1 0 1 1 0 1 0 0 1 1 1 1 1 0 0 1 1 1 0 1 0 1 0 0 0 1 0 1 0\n",
            " 0 1 1 1 0 0 1 1 0 0 0 1 0 0 1 0 1 0 1 1 0 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1\n",
            " 1 0 1 1 1 1 0 1 1 1 0 0 0 0 1 1 0 0 0 0 1 0 1 1 1 0 1 1 1 1 1 0 0 1 1 0 1\n",
            " 0 0 0 1 0 1 0 0 1 0 0 1 1 0 0 1 1 1 0 0 0 1 0 1 0 1 1 0 1 1 0 1 1 0 1 1 0\n",
            " 0 1 0 1 1 0 0 1 0 1 1 1 1 1 0 0 1 1 1 0 0 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 0\n",
            " 0 1 1 1 0 0 0 1 1 1 0 1 0 0 1 1 1 0 1 0 0 1 1 1 0 0 0 1 1 1 1 0 1 0 0 1 0\n",
            " 1 1 1 1 1 1 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 1 0 1 0 0 1 0 0 0 1 0 0 1 0 0 1\n",
            " 1 0 0 1 0 0 1 1 0 0 0 1 1 0 0 1 0 1 1 1 0 0 1 0 1 1 0 0 0 0 0 1 1 1 1 0 0\n",
            " 0 1 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 1 1 1 1 1 0 1 0 0 0 1 0 0 1 1 1 0 1 0\n",
            " 0 0 0 1 1 0 1 1 1 0 0 1 0 1 1 0 1 1 0 1 0 0 0 0 1 0 1 1 1 1 1 1 1 1 1 0 1\n",
            " 1 0 1 1 0 1 1 0 1 1 0 1 1 1 0 1 0 1 1 0 1 0 0 0 0 0 0 1 0 1 0 1 0 0 1 1 1\n",
            " 0 0 0 1 1 0 1 1 0 0 1 1 1 0 0 0 0 0 1 0 0 1 0 1 1 0 0 1 0 1 0 1 0 0 0 1 1\n",
            " 1 0 0 1 1 0 1 1 1 0 0]\n",
            "uniques chosen: 10 <= should be equal to: 10\n",
            "trainset before adding uncertain samples (440, 10) (440,)\n",
            "trainset after adding uncertain samples (450, 10) (450,)\n",
            "updated train set: (450, 10) (450,) unique(labels): [203 247] [0 1]\n",
            "val set: (852, 10) (852,)\n",
            "\n",
            "Train set: (450, 10)\n",
            "Validation set: (852, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 45\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.060 s \n",
            "\n",
            "Accuracy rate is 78.801843 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86       321\n",
            "           1       0.61      0.53      0.57       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.72      0.70      0.71       434\n",
            "weighted avg       0.78      0.79      0.78       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[282  39]\n",
            " [ 53  60]]\n",
            "--------------------------------\n",
            "val predicted: (852,) [0 1 1 1 0 1 0 1 1 0 1 0 1 1 0 1 0 0 1 0 0 0 1 0 1 1 0 1 1 1 1 1 0 0 0 0 1\n",
            " 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 1 0 0\n",
            " 0 1 0 1 1 0 1 1 1 0 0 0 1 1 1 0 0 0 0 0 1 0 0 0 1 1 0 0 1 0 1 0 0 0 0 0 1\n",
            " 0 1 1 1 0 0 1 0 1 1 0 0 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1 0 0 0 0 1 1 1 1 0 1\n",
            " 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 0 0 1 0 1 1 1 0 0 0 0 1 1 0 0 0 1 0 1 0 1 1\n",
            " 1 0 1 0 0 0 1 1 0 1 1 0 1 1 1 1 0 1 0 1 1 1 1 0 1 1 0 1 1 1 0 1 1 0 1 1 0\n",
            " 1 1 1 1 0 0 1 1 0 1 0 0 1 1 1 0 1 0 0 0 0 1 1 0 1 0 1 0 0 1 1 0 1 0 1 0 0\n",
            " 0 0 0 1 1 0 1 1 0 1 0 1 0 0 1 0 0 0 1 1 1 1 1 0 1 1 0 0 1 0 1 1 1 0 0 1 1\n",
            " 0 1 1 0 1 0 1 1 1 1 1 1 1 0 0 1 1 1 0 0 0 1 0 1 1 1 0 0 1 0 1 0 0 1 1 1 1\n",
            " 0 1 1 0 1 1 1 1 1 0 1 1 0 0 0 1 1 1 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0\n",
            " 1 0 1 1 1 1 0 0 1 0 1 1 0 1 0 1 0 1 1 0 0 0 0 0 1 1 1 0 0 0 0 1 0 0 1 1 0\n",
            " 0 0 1 0 0 1 0 1 1 0 1 0 0 1 1 1 1 1 0 0 1 1 1 0 1 0 1 1 0 0 1 0 1 0 0 1 1\n",
            " 1 0 0 1 1 0 0 1 0 0 1 0 1 0 1 1 0 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1\n",
            " 1 1 0 1 1 1 0 0 0 0 1 1 0 0 0 0 1 0 1 1 1 0 1 1 1 1 1 0 0 1 1 0 1 0 0 0 1\n",
            " 0 1 0 0 1 0 0 1 1 0 0 1 1 1 0 0 0 1 0 1 0 1 1 0 1 1 0 1 1 0 1 1 0 0 1 0 1\n",
            " 1 0 0 1 0 1 1 1 1 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 0 0 1 0 0 0 0 0 1 1 1 0\n",
            " 0 0 1 1 1 0 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 0 1 1 1 1 0 1 0 0 1 0 1 1 1 1 1\n",
            " 1 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 1 0 1 0 0 1 0 0 0 1 0 0 1 0 0 1 0 0 0 1 0\n",
            " 0 1 1 0 0 0 1 1 0 0 1 1 1 1 0 0 1 0 1 1 0 1 0 0 1 1 1 1 0 0 0 1 0 0 0 0 1\n",
            " 1 1 1 1 1 1 1 0 0 0 0 1 1 1 1 1 0 1 0 0 0 1 0 0 1 1 1 0 1 0 0 0 0 1 1 0 1\n",
            " 1 1 0 0 1 0 1 1 0 1 1 0 1 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 0 1 1 0\n",
            " 1 1 0 1 1 1 0 1 0 1 1 0 1 0 0 0 0 0 1 1 0 1 0 0 1 1 1 0 0 0 1 1 0 1 1 0 0\n",
            " 1 1 1 0 0 0 0 0 0 0 0 1 0 1 1 0 0 1 0 1 0 1 0 0 0 1 1 1 0 0 1 1 0 1 1 1 0\n",
            " 0]\n",
            "probabilities: (852, 2) \n",
            " [0 1 1 1 0 1 0 1 1 0 1 0 1 1 0 1 0 0 1 0 0 0 1 0 1 1 0 1 1 1 1 1 0 0 0 0 1\n",
            " 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 1 0 0\n",
            " 0 1 0 1 1 0 1 1 1 0 0 0 1 1 1 0 0 0 0 0 1 0 0 0 1 1 0 0 1 0 1 0 0 0 0 0 1\n",
            " 0 1 1 1 0 0 1 0 1 1 0 0 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1 0 0 0 0 1 1 1 1 0 1\n",
            " 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 0 0 1 0 1 1 1 0 0 0 0 1 1 0 0 0 1 0 1 0 1 1\n",
            " 1 0 1 0 0 0 1 1 0 1 1 0 1 1 1 1 0 1 0 1 1 1 1 0 1 1 0 1 1 1 0 1 1 0 1 1 0\n",
            " 1 1 1 1 0 0 1 1 0 1 0 0 1 1 1 0 1 0 0 0 0 1 1 0 1 0 1 0 0 1 1 0 1 0 1 0 0\n",
            " 0 0 0 1 1 0 1 1 0 1 0 1 0 0 1 0 0 0 1 1 1 1 1 0 1 1 0 0 1 0 1 1 1 0 0 1 1\n",
            " 0 1 1 0 1 0 1 1 1 1 1 1 1 0 0 1 1 1 0 0 0 1 0 1 1 1 0 0 1 0 1 0 0 1 1 1 1\n",
            " 0 1 1 0 1 1 1 1 1 0 1 1 0 0 0 1 1 1 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0\n",
            " 1 0 1 1 1 1 0 0 1 0 1 1 0 1 0 1 0 1 1 0 0 0 0 0 1 1 1 0 0 0 0 1 0 0 1 1 0\n",
            " 0 0 1 0 0 1 0 1 1 0 1 0 0 1 1 1 1 1 0 0 1 1 1 0 1 0 1 1 0 0 1 0 1 0 0 1 1\n",
            " 1 0 0 1 1 0 0 1 0 0 1 0 1 0 1 1 0 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1\n",
            " 1 1 0 1 1 1 0 0 0 0 1 1 0 0 0 0 1 0 1 1 1 0 1 1 1 1 1 0 0 1 1 0 1 0 0 0 1\n",
            " 0 1 0 0 1 0 0 1 1 0 0 1 1 1 0 0 0 1 0 1 0 1 1 0 1 1 0 1 1 0 1 1 0 0 1 0 1\n",
            " 1 0 0 1 0 1 1 1 1 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 0 0 1 0 0 0 0 0 1 1 1 0\n",
            " 0 0 1 1 1 0 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 0 1 1 1 1 0 1 0 0 1 0 1 1 1 1 1\n",
            " 1 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 1 0 1 0 0 1 0 0 0 1 0 0 1 0 0 1 0 0 0 1 0\n",
            " 0 1 1 0 0 0 1 1 0 0 1 1 1 1 0 0 1 0 1 1 0 1 0 0 1 1 1 1 0 0 0 1 0 0 0 0 1\n",
            " 1 1 1 1 1 1 1 0 0 0 0 1 1 1 1 1 0 1 0 0 0 1 0 0 1 1 1 0 1 0 0 0 0 1 1 0 1\n",
            " 1 1 0 0 1 0 1 1 0 1 1 0 1 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 0 1 1 0\n",
            " 1 1 0 1 1 1 0 1 0 1 1 0 1 0 0 0 0 0 1 1 0 1 0 0 1 1 1 0 0 0 1 1 0 1 1 0 0\n",
            " 1 1 1 0 0 0 0 0 0 0 0 1 0 1 1 0 0 1 0 1 0 1 0 0 0 1 1 1 0 0 1 1 0 1 1 1 0\n",
            " 0]\n",
            "uniques chosen: 10 <= should be equal to: 10\n",
            "trainset before adding uncertain samples (450, 10) (450,)\n",
            "trainset after adding uncertain samples (460, 10) (460,)\n",
            "updated train set: (460, 10) (460,) unique(labels): [206 254] [0 1]\n",
            "val set: (842, 10) (842,)\n",
            "\n",
            "Train set: (460, 10)\n",
            "Validation set: (842, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 46\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.074 s \n",
            "\n",
            "Accuracy rate is 78.801843 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.87      0.86       321\n",
            "           1       0.60      0.55      0.57       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.72      0.71      0.72       434\n",
            "weighted avg       0.78      0.79      0.78       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[280  41]\n",
            " [ 51  62]]\n",
            "--------------------------------\n",
            "val predicted: (842,) [0 1 1 0 1 0 1 1 0 1 0 1 1 0 1 0 1 0 0 0 1 0 1 1 0 1 1 1 1 1 0 0 0 0 1 0 1\n",
            " 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 1 0 0 0 1 0\n",
            " 1 1 0 1 1 1 0 0 0 1 1 1 0 0 0 0 0 1 0 0 0 1 1 0 0 1 0 1 0 0 0 0 0 1 0 1 1\n",
            " 1 0 0 1 0 1 1 0 0 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1 0 0 0 0 1 1 1 1 0 1 1 1 1\n",
            " 1 0 0 1 1 0 0 1 1 0 0 1 0 0 1 0 1 1 1 0 0 0 0 1 1 0 0 0 1 0 1 0 1 1 1 0 1\n",
            " 0 0 0 1 1 0 1 1 0 1 1 1 1 0 1 0 1 1 1 1 0 1 1 0 1 1 1 0 1 1 0 1 1 0 1 1 1\n",
            " 1 0 0 1 1 0 1 0 0 1 1 1 0 1 0 0 0 0 1 1 0 1 0 1 0 0 1 1 0 1 0 1 0 0 0 0 0\n",
            " 1 1 0 1 1 1 0 1 0 0 1 0 0 0 1 1 1 1 1 0 1 1 0 0 1 0 1 1 1 0 0 1 1 0 1 1 0\n",
            " 1 0 1 1 1 1 1 1 1 0 0 1 1 1 0 0 0 1 0 1 1 1 0 0 1 0 1 0 0 1 1 1 1 0 1 1 0\n",
            " 1 1 1 1 1 0 1 1 0 0 0 1 1 1 0 0 0 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0 1 0 1 1\n",
            " 1 1 0 0 1 0 1 1 0 1 0 1 0 1 0 0 0 0 0 1 1 1 0 0 0 0 1 0 0 1 1 0 0 0 1 0 0\n",
            " 1 0 1 1 0 1 0 0 1 1 1 1 1 0 0 1 1 1 0 1 0 1 0 0 0 1 0 1 1 0 1 1 1 0 0 1 1\n",
            " 0 0 1 0 0 1 0 1 0 1 1 0 1 1 0 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1\n",
            " 0 0 0 0 1 1 0 0 0 0 1 0 1 1 1 0 1 1 1 1 1 0 0 1 1 0 1 0 0 0 1 0 1 0 0 1 0\n",
            " 0 1 1 0 0 1 1 1 0 0 0 1 0 0 1 1 0 1 1 0 1 1 0 1 1 0 0 1 0 1 1 0 0 1 0 1 1\n",
            " 1 1 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 1 1 1 0 1\n",
            " 0 0 1 0 1 0 1 0 0 1 1 1 0 0 0 1 1 1 1 0 1 0 0 1 0 1 1 1 1 1 1 0 0 0 0 0 0\n",
            " 0 1 1 0 0 0 1 0 0 1 0 1 0 0 1 0 0 0 1 0 0 1 0 0 1 0 0 0 1 0 0 1 1 0 0 0 1\n",
            " 1 0 0 1 1 1 1 0 0 1 0 1 1 0 1 0 0 1 1 1 1 0 0 0 1 0 0 0 0 1 1 1 1 1 1 1 1\n",
            " 0 0 0 0 1 1 1 1 1 0 1 0 0 0 1 0 0 1 1 1 0 1 0 0 0 0 1 1 0 1 1 1 0 0 1 0 1\n",
            " 1 0 1 1 0 1 0 0 0 0 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 0 1 1 0 1 1 0 1 1 1 0 1\n",
            " 0 1 1 0 1 0 0 0 0 1 1 0 1 0 0 1 1 0 0 0 1 1 0 1 1 0 0 1 1 1 0 0 0 0 0 0 0\n",
            " 0 1 0 1 1 0 0 1 0 1 0 1 0 0 0 1 1 1 0 0 1 1 0 1 1 1 0 0]\n",
            "probabilities: (842, 2) \n",
            " [0 1 1 0 1 0 1 1 0 1 0 1 1 0 1 0 1 0 0 0 1 0 1 1 0 1 1 1 1 1 0 0 0 0 1 0 1\n",
            " 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 1 0 0 0 1 0\n",
            " 1 1 0 1 1 1 0 0 0 1 1 1 0 0 0 0 0 1 0 0 0 1 1 0 0 1 0 1 0 0 0 0 0 1 0 1 1\n",
            " 1 0 0 1 0 1 1 0 0 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1 0 0 0 0 1 1 1 1 0 1 1 1 1\n",
            " 1 0 0 1 1 0 0 1 1 0 0 1 0 0 1 0 1 1 1 0 0 0 0 1 1 0 0 0 1 0 1 0 1 1 1 0 1\n",
            " 0 0 0 1 1 0 1 1 0 1 1 1 1 0 1 0 1 1 1 1 0 1 1 0 1 1 1 0 1 1 0 1 1 0 1 1 1\n",
            " 1 0 0 1 1 0 1 0 0 1 1 1 0 1 0 0 0 0 1 1 0 1 0 1 0 0 1 1 0 1 0 1 0 0 0 0 0\n",
            " 1 1 0 1 1 1 0 1 0 0 1 0 0 0 1 1 1 1 1 0 1 1 0 0 1 0 1 1 1 0 0 1 1 0 1 1 0\n",
            " 1 0 1 1 1 1 1 1 1 0 0 1 1 1 0 0 0 1 0 1 1 1 0 0 1 0 1 0 0 1 1 1 1 0 1 1 0\n",
            " 1 1 1 1 1 0 1 1 0 0 0 1 1 1 0 0 0 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0 1 0 1 1\n",
            " 1 1 0 0 1 0 1 1 0 1 0 1 0 1 0 0 0 0 0 1 1 1 0 0 0 0 1 0 0 1 1 0 0 0 1 0 0\n",
            " 1 0 1 1 0 1 0 0 1 1 1 1 1 0 0 1 1 1 0 1 0 1 0 0 0 1 0 1 1 0 1 1 1 0 0 1 1\n",
            " 0 0 1 0 0 1 0 1 0 1 1 0 1 1 0 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1\n",
            " 0 0 0 0 1 1 0 0 0 0 1 0 1 1 1 0 1 1 1 1 1 0 0 1 1 0 1 0 0 0 1 0 1 0 0 1 0\n",
            " 0 1 1 0 0 1 1 1 0 0 0 1 0 0 1 1 0 1 1 0 1 1 0 1 1 0 0 1 0 1 1 0 0 1 0 1 1\n",
            " 1 1 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 1 1 1 0 1\n",
            " 0 0 1 0 1 0 1 0 0 1 1 1 0 0 0 1 1 1 1 0 1 0 0 1 0 1 1 1 1 1 1 0 0 0 0 0 0\n",
            " 0 1 1 0 0 0 1 0 0 1 0 1 0 0 1 0 0 0 1 0 0 1 0 0 1 0 0 0 1 0 0 1 1 0 0 0 1\n",
            " 1 0 0 1 1 1 1 0 0 1 0 1 1 0 1 0 0 1 1 1 1 0 0 0 1 0 0 0 0 1 1 1 1 1 1 1 1\n",
            " 0 0 0 0 1 1 1 1 1 0 1 0 0 0 1 0 0 1 1 1 0 1 0 0 0 0 1 1 0 1 1 1 0 0 1 0 1\n",
            " 1 0 1 1 0 1 0 0 0 0 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 0 1 1 0 1 1 0 1 1 1 0 1\n",
            " 0 1 1 0 1 0 0 0 0 1 1 0 1 0 0 1 1 0 0 0 1 1 0 1 1 0 0 1 1 1 0 0 0 0 0 0 0\n",
            " 0 1 0 1 1 0 0 1 0 1 0 1 0 0 0 1 1 1 0 0 1 1 0 1 1 1 0 0]\n",
            "uniques chosen: 10 <= should be equal to: 10\n",
            "trainset before adding uncertain samples (460, 10) (460,)\n",
            "trainset after adding uncertain samples (470, 10) (470,)\n",
            "updated train set: (470, 10) (470,) unique(labels): [213 257] [0 1]\n",
            "val set: (832, 10) (832,)\n",
            "\n",
            "Train set: (470, 10)\n",
            "Validation set: (832, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 47\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.064 s \n",
            "\n",
            "Accuracy rate is 79.032258 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.88      0.86       321\n",
            "           1       0.61      0.55      0.58       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.73      0.71      0.72       434\n",
            "weighted avg       0.78      0.79      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[281  40]\n",
            " [ 51  62]]\n",
            "--------------------------------\n",
            "val predicted: (832,) [0 1 1 0 1 0 1 1 0 1 0 1 1 0 1 0 1 0 0 0 1 0 1 1 0 1 1 1 1 1 0 0 0 0 1 0 1\n",
            " 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 0 1 1 0 0 1 1 1 0 0 0 1 0 1\n",
            " 1 0 1 1 1 0 0 0 1 1 0 0 0 0 0 1 0 0 0 1 1 0 0 1 0 1 0 0 0 0 0 1 0 1 1 1 0\n",
            " 0 1 0 1 1 0 0 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1 0 0 0 0 1 1 1 1 0 1 1 1 1 1 0\n",
            " 0 1 1 0 0 1 1 0 0 1 0 0 1 0 1 1 1 0 0 0 0 1 1 0 0 0 1 0 1 0 1 1 1 0 1 0 0\n",
            " 0 1 1 0 1 1 0 1 1 1 1 0 1 0 1 1 1 1 0 1 1 0 1 1 1 0 1 1 0 1 1 0 1 1 1 1 0\n",
            " 0 1 1 0 1 0 0 1 1 0 1 0 0 0 0 0 1 0 1 0 1 0 0 1 0 1 0 1 0 0 0 0 0 1 1 0 1\n",
            " 1 1 0 1 0 0 1 0 0 0 1 1 1 1 1 0 1 1 0 0 1 0 1 1 1 0 0 1 1 0 1 1 0 1 0 1 1\n",
            " 1 1 1 1 1 0 0 1 1 1 0 0 0 1 0 1 1 1 0 0 1 0 1 0 0 1 1 1 1 0 1 1 0 1 1 1 1\n",
            " 1 0 1 1 0 0 0 1 1 1 0 1 0 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0 1 0 1 1 1 1 0 0\n",
            " 1 0 1 1 1 0 1 0 1 0 0 0 0 0 1 1 1 0 0 0 0 1 0 0 1 1 0 0 0 1 0 0 1 0 1 1 0\n",
            " 1 0 0 1 1 1 1 1 0 0 1 1 1 0 0 1 0 0 0 1 0 1 1 0 1 1 1 0 0 1 1 0 0 1 0 0 1\n",
            " 0 1 0 1 1 0 1 1 0 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 0 0 0 1 1\n",
            " 0 0 0 0 1 0 1 1 1 0 1 1 1 1 1 0 0 1 1 0 1 0 0 0 1 0 1 0 0 1 0 0 1 1 0 0 1\n",
            " 1 1 0 0 0 1 0 0 1 1 0 1 1 0 1 0 1 1 0 0 1 0 1 1 0 0 1 0 1 1 1 1 0 0 1 1 1\n",
            " 0 0 1 1 1 0 1 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 1 1 1 0 1 0 0 1 1 0 1 0 0\n",
            " 1 1 1 0 0 0 1 1 1 1 0 1 0 0 1 0 1 1 1 1 1 1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 1\n",
            " 0 1 0 0 1 0 0 0 1 0 0 1 0 0 1 0 0 0 1 0 0 1 1 0 0 0 1 1 0 0 1 1 1 1 0 0 1\n",
            " 0 1 1 0 1 0 0 1 1 1 1 0 0 0 1 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 1 1 1 1 1 0\n",
            " 1 0 0 0 1 0 0 1 1 1 0 1 0 0 0 0 1 1 0 1 1 1 0 0 1 0 1 1 0 1 1 0 1 0 0 0 0\n",
            " 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 0 1 1 0 1 1 0 1 1 1 0 1 0 1 1 0 1 0 0 0 0 1\n",
            " 1 0 1 0 0 1 1 0 0 0 1 1 0 1 1 0 0 1 1 1 0 0 0 0 0 1 0 0 1 0 1 1 0 0 1 0 1\n",
            " 1 1 0 0 0 1 1 1 0 0 1 1 0 1 1 1 0 0]\n",
            "probabilities: (832, 2) \n",
            " [0 1 1 0 1 0 1 1 0 1 0 1 1 0 1 0 1 0 0 0 1 0 1 1 0 1 1 1 1 1 0 0 0 0 1 0 1\n",
            " 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 0 1 1 0 0 1 1 1 0 0 0 1 0 1\n",
            " 1 0 1 1 1 0 0 0 1 1 0 0 0 0 0 1 0 0 0 1 1 0 0 1 0 1 0 0 0 0 0 1 0 1 1 1 0\n",
            " 0 1 0 1 1 0 0 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1 0 0 0 0 1 1 1 1 0 1 1 1 1 1 0\n",
            " 0 1 1 0 0 1 1 0 0 1 0 0 1 0 1 1 1 0 0 0 0 1 1 0 0 0 1 0 1 0 1 1 1 0 1 0 0\n",
            " 0 1 1 0 1 1 0 1 1 1 1 0 1 0 1 1 1 1 0 1 1 0 1 1 1 0 1 1 0 1 1 0 1 1 1 1 0\n",
            " 0 1 1 0 1 0 0 1 1 0 1 0 0 0 0 0 1 0 1 0 1 0 0 1 0 1 0 1 0 0 0 0 0 1 1 0 1\n",
            " 1 1 0 1 0 0 1 0 0 0 1 1 1 1 1 0 1 1 0 0 1 0 1 1 1 0 0 1 1 0 1 1 0 1 0 1 1\n",
            " 1 1 1 1 1 0 0 1 1 1 0 0 0 1 0 1 1 1 0 0 1 0 1 0 0 1 1 1 1 0 1 1 0 1 1 1 1\n",
            " 1 0 1 1 0 0 0 1 1 1 0 1 0 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0 1 0 1 1 1 1 0 0\n",
            " 1 0 1 1 1 0 1 0 1 0 0 0 0 0 1 1 1 0 0 0 0 1 0 0 1 1 0 0 0 1 0 0 1 0 1 1 0\n",
            " 1 0 0 1 1 1 1 1 0 0 1 1 1 0 0 1 0 0 0 1 0 1 1 0 1 1 1 0 0 1 1 0 0 1 0 0 1\n",
            " 0 1 0 1 1 0 1 1 0 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 0 0 0 1 1\n",
            " 0 0 0 0 1 0 1 1 1 0 1 1 1 1 1 0 0 1 1 0 1 0 0 0 1 0 1 0 0 1 0 0 1 1 0 0 1\n",
            " 1 1 0 0 0 1 0 0 1 1 0 1 1 0 1 0 1 1 0 0 1 0 1 1 0 0 1 0 1 1 1 1 0 0 1 1 1\n",
            " 0 0 1 1 1 0 1 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 1 1 1 0 1 0 0 1 1 0 1 0 0\n",
            " 1 1 1 0 0 0 1 1 1 1 0 1 0 0 1 0 1 1 1 1 1 1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 1\n",
            " 0 1 0 0 1 0 0 0 1 0 0 1 0 0 1 0 0 0 1 0 0 1 1 0 0 0 1 1 0 0 1 1 1 1 0 0 1\n",
            " 0 1 1 0 1 0 0 1 1 1 1 0 0 0 1 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 1 1 1 1 1 0\n",
            " 1 0 0 0 1 0 0 1 1 1 0 1 0 0 0 0 1 1 0 1 1 1 0 0 1 0 1 1 0 1 1 0 1 0 0 0 0\n",
            " 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 0 1 1 0 1 1 0 1 1 1 0 1 0 1 1 0 1 0 0 0 0 1\n",
            " 1 0 1 0 0 1 1 0 0 0 1 1 0 1 1 0 0 1 1 1 0 0 0 0 0 1 0 0 1 0 1 1 0 0 1 0 1\n",
            " 1 1 0 0 0 1 1 1 0 0 1 1 0 1 1 1 0 0]\n",
            "uniques chosen: 10 <= should be equal to: 10\n",
            "trainset before adding uncertain samples (470, 10) (470,)\n",
            "trainset after adding uncertain samples (480, 10) (480,)\n",
            "updated train set: (480, 10) (480,) unique(labels): [218 262] [0 1]\n",
            "val set: (822, 10) (822,)\n",
            "\n",
            "Train set: (480, 10)\n",
            "Validation set: (822, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 48\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.092 s \n",
            "\n",
            "Accuracy rate is 78.571429 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.87      0.86       321\n",
            "           1       0.60      0.54      0.57       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.72      0.71      0.71       434\n",
            "weighted avg       0.78      0.79      0.78       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[280  41]\n",
            " [ 52  61]]\n",
            "--------------------------------\n",
            "val predicted: (822,) [0 1 1 0 1 0 1 1 0 1 0 1 1 0 1 0 1 0 0 0 1 0 1 1 0 1 1 1 1 1 0 0 0 0 1 0 1\n",
            " 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 0 1 1 0 0 1 1 1 0 0 0 1 0 1\n",
            " 1 0 1 1 1 0 0 0 1 1 0 0 0 0 0 1 0 0 1 1 0 0 1 0 1 0 0 0 0 0 1 0 1 1 1 0 0\n",
            " 1 0 1 1 0 0 0 1 1 1 1 0 1 1 1 1 0 1 1 1 0 0 0 0 1 1 1 1 0 1 1 1 1 1 0 0 1\n",
            " 1 0 0 1 1 0 0 1 0 0 1 0 1 1 1 0 0 0 0 1 1 0 0 0 1 0 1 0 1 1 0 1 0 0 0 1 1\n",
            " 0 1 1 0 1 1 1 1 0 1 0 1 1 1 1 0 1 1 0 1 1 1 0 1 1 0 1 1 0 1 1 1 1 0 0 1 1\n",
            " 0 1 0 0 1 1 0 1 0 0 0 0 0 1 0 1 0 1 0 0 1 0 1 0 1 0 0 0 0 0 1 1 0 1 1 1 0\n",
            " 1 0 0 1 0 0 0 1 1 1 1 1 0 1 1 0 0 1 0 1 1 1 0 0 1 1 0 1 1 0 1 0 1 1 1 1 1\n",
            " 1 1 0 0 1 1 1 0 0 0 1 0 1 1 1 0 0 1 0 1 0 1 1 1 0 1 1 0 1 1 1 1 1 0 1 1 0\n",
            " 0 0 1 1 1 0 1 0 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0 1 0 1 1 1 1 0 0 1 0 1 1 1\n",
            " 0 1 0 1 0 0 0 0 0 1 1 1 0 0 0 0 1 0 0 1 1 0 0 0 1 0 0 1 0 1 1 0 1 0 0 1 1\n",
            " 1 1 0 0 1 1 1 0 0 1 1 0 0 1 0 1 1 0 1 1 1 0 0 1 1 0 0 1 0 0 1 0 1 0 1 1 0\n",
            " 1 1 0 0 1 0 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 0 0 0 1 1 0 0 0 0 1 0\n",
            " 1 1 1 0 1 1 1 1 1 0 0 1 1 0 1 0 0 0 0 0 1 0 0 1 0 1 1 0 0 1 1 1 0 0 0 1 0\n",
            " 0 1 1 0 1 1 0 1 0 1 1 0 0 1 0 1 1 0 0 1 0 1 1 1 1 0 0 1 1 1 0 0 1 1 1 0 1\n",
            " 0 0 0 0 0 1 1 0 0 0 0 1 1 1 0 0 0 1 1 1 0 1 0 0 1 1 0 1 0 0 1 1 1 0 0 0 1\n",
            " 1 1 1 0 1 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 1 1 0 0 1 0 1 0 1 0 0 0 0 0 1 0\n",
            " 0 1 0 0 1 0 0 0 1 0 0 1 1 0 0 0 1 1 0 0 1 1 1 1 0 0 1 0 1 1 0 0 0 0 1 1 1\n",
            " 1 0 0 0 1 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 1 1 1 1 1 0 1 0 0 0 1 0 0 1 1 1\n",
            " 0 1 0 0 0 0 1 1 0 1 1 1 0 0 1 0 1 1 0 1 1 0 1 0 0 0 0 1 1 1 1 1 1 1 1 1 0\n",
            " 1 1 0 1 1 0 0 1 0 1 1 0 1 1 1 0 1 0 1 1 0 1 0 0 0 0 1 1 0 1 0 0 1 1 0 0 0\n",
            " 1 1 0 1 1 0 0 1 1 1 0 0 0 0 0 1 0 0 1 0 1 1 0 0 1 0 1 1 1 0 0 0 1 1 1 0 0\n",
            " 1 1 0 1 1 1 0 0]\n",
            "probabilities: (822, 2) \n",
            " [0 1 1 0 1 0 1 1 0 1 0 1 1 0 1 0 1 0 0 0 1 0 1 1 0 1 1 1 1 1 0 0 0 0 1 0 1\n",
            " 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 0 1 1 0 0 1 1 1 0 0 0 1 0 1\n",
            " 1 0 1 1 1 0 0 0 1 1 0 0 0 0 0 1 0 0 1 1 0 0 1 0 1 0 0 0 0 0 1 0 1 1 1 0 0\n",
            " 1 0 1 1 0 0 0 1 1 1 1 0 1 1 1 1 0 1 1 1 0 0 0 0 1 1 1 1 0 1 1 1 1 1 0 0 1\n",
            " 1 0 0 1 1 0 0 1 0 0 1 0 1 1 1 0 0 0 0 1 1 0 0 0 1 0 1 0 1 1 0 1 0 0 0 1 1\n",
            " 0 1 1 0 1 1 1 1 0 1 0 1 1 1 1 0 1 1 0 1 1 1 0 1 1 0 1 1 0 1 1 1 1 0 0 1 1\n",
            " 0 1 0 0 1 1 0 1 0 0 0 0 0 1 0 1 0 1 0 0 1 0 1 0 1 0 0 0 0 0 1 1 0 1 1 1 0\n",
            " 1 0 0 1 0 0 0 1 1 1 1 1 0 1 1 0 0 1 0 1 1 1 0 0 1 1 0 1 1 0 1 0 1 1 1 1 1\n",
            " 1 1 0 0 1 1 1 0 0 0 1 0 1 1 1 0 0 1 0 1 0 1 1 1 0 1 1 0 1 1 1 1 1 0 1 1 0\n",
            " 0 0 1 1 1 0 1 0 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0 1 0 1 1 1 1 0 0 1 0 1 1 1\n",
            " 0 1 0 1 0 0 0 0 0 1 1 1 0 0 0 0 1 0 0 1 1 0 0 0 1 0 0 1 0 1 1 0 1 0 0 1 1\n",
            " 1 1 0 0 1 1 1 0 0 1 1 0 0 1 0 1 1 0 1 1 1 0 0 1 1 0 0 1 0 0 1 0 1 0 1 1 0\n",
            " 1 1 0 0 1 0 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 0 0 0 1 1 0 0 0 0 1 0\n",
            " 1 1 1 0 1 1 1 1 1 0 0 1 1 0 1 0 0 0 0 0 1 0 0 1 0 1 1 0 0 1 1 1 0 0 0 1 0\n",
            " 0 1 1 0 1 1 0 1 0 1 1 0 0 1 0 1 1 0 0 1 0 1 1 1 1 0 0 1 1 1 0 0 1 1 1 0 1\n",
            " 0 0 0 0 0 1 1 0 0 0 0 1 1 1 0 0 0 1 1 1 0 1 0 0 1 1 0 1 0 0 1 1 1 0 0 0 1\n",
            " 1 1 1 0 1 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 1 1 0 0 1 0 1 0 1 0 0 0 0 0 1 0\n",
            " 0 1 0 0 1 0 0 0 1 0 0 1 1 0 0 0 1 1 0 0 1 1 1 1 0 0 1 0 1 1 0 0 0 0 1 1 1\n",
            " 1 0 0 0 1 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 1 1 1 1 1 0 1 0 0 0 1 0 0 1 1 1\n",
            " 0 1 0 0 0 0 1 1 0 1 1 1 0 0 1 0 1 1 0 1 1 0 1 0 0 0 0 1 1 1 1 1 1 1 1 1 0\n",
            " 1 1 0 1 1 0 0 1 0 1 1 0 1 1 1 0 1 0 1 1 0 1 0 0 0 0 1 1 0 1 0 0 1 1 0 0 0\n",
            " 1 1 0 1 1 0 0 1 1 1 0 0 0 0 0 1 0 0 1 0 1 1 0 0 1 0 1 1 1 0 0 0 1 1 1 0 0\n",
            " 1 1 0 1 1 1 0 0]\n",
            "uniques chosen: 10 <= should be equal to: 10\n",
            "trainset before adding uncertain samples (480, 10) (480,)\n",
            "trainset after adding uncertain samples (490, 10) (490,)\n",
            "updated train set: (490, 10) (490,) unique(labels): [222 268] [0 1]\n",
            "val set: (812, 10) (812,)\n",
            "\n",
            "Train set: (490, 10)\n",
            "Validation set: (812, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 49\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.062 s \n",
            "\n",
            "Accuracy rate is 78.571429 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.87      0.86       321\n",
            "           1       0.60      0.54      0.57       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.72      0.71      0.71       434\n",
            "weighted avg       0.78      0.79      0.78       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[280  41]\n",
            " [ 52  61]]\n",
            "--------------------------------\n",
            "val predicted: (812,) [0 1 1 0 1 0 1 1 0 1 0 1 1 1 0 1 0 0 0 1 0 1 1 0 1 1 1 1 1 0 0 0 0 1 0 1 1\n",
            " 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 0 1 1 0 0 1 1 1 0 0 0 1 0 1 1\n",
            " 0 1 1 1 0 0 0 1 0 0 0 0 0 1 0 0 1 1 0 0 1 0 1 0 0 0 0 0 1 0 1 1 1 0 1 1 0\n",
            " 1 1 0 0 0 1 1 1 1 0 1 1 1 1 0 1 1 1 0 0 0 0 1 1 1 1 0 1 1 1 1 0 0 1 1 0 0\n",
            " 1 1 0 0 1 0 0 1 0 1 1 1 0 0 0 0 1 1 0 0 0 1 0 1 0 1 1 0 1 0 0 0 1 1 0 1 0\n",
            " 1 1 1 1 0 1 0 1 1 1 1 0 1 1 0 1 1 1 0 1 1 0 1 1 0 1 1 1 1 0 0 1 1 0 1 0 0\n",
            " 1 1 0 1 0 0 0 0 0 1 0 1 0 1 0 0 1 0 1 0 1 0 0 0 0 0 1 1 0 1 1 1 0 1 0 0 1\n",
            " 0 0 0 1 1 1 1 1 0 1 1 0 0 1 0 1 1 1 0 0 1 1 0 1 1 0 1 0 1 1 1 1 1 1 1 0 0\n",
            " 1 1 1 0 0 0 0 1 1 1 0 0 1 0 1 0 1 1 1 0 1 1 0 1 1 1 1 1 0 1 1 0 0 0 1 1 1\n",
            " 0 1 0 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0 1 0 1 1 1 1 0 0 1 0 1 1 1 0 1 0 0 0\n",
            " 0 0 0 1 1 1 1 0 0 0 1 0 0 1 1 0 0 0 1 0 0 1 0 1 1 0 1 0 0 1 1 1 1 0 0 1 1\n",
            " 1 0 0 1 1 0 0 1 0 1 1 0 1 1 1 0 0 1 1 0 0 1 0 0 0 1 0 1 1 0 1 1 0 0 1 0 1\n",
            " 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 0 0 0 1 1 0 0 0 0 1 0 1 1 1 0 1 1 1\n",
            " 1 1 0 0 1 1 0 1 0 0 0 0 0 1 0 0 1 0 1 1 0 0 1 1 1 0 0 0 1 0 0 1 1 0 1 1 0\n",
            " 1 0 1 1 0 0 1 0 1 1 0 0 1 0 1 1 1 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 0 0 1 1\n",
            " 0 0 0 0 1 1 0 0 0 1 1 1 0 1 0 0 1 1 0 1 0 0 1 1 1 0 0 0 1 1 1 1 0 1 0 0 1\n",
            " 1 1 1 1 1 1 0 0 0 0 0 0 0 1 1 0 0 1 0 1 0 1 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0\n",
            " 1 0 0 1 1 0 0 0 1 1 0 0 1 1 1 1 0 0 1 0 1 1 0 0 0 1 1 1 1 0 0 0 1 0 0 0 0\n",
            " 0 1 1 1 1 1 1 1 0 0 0 0 1 1 1 1 1 0 1 0 0 0 1 0 0 1 1 1 1 0 0 0 0 1 1 0 1\n",
            " 1 1 0 0 1 0 1 1 0 1 1 0 1 0 0 0 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 1 0 1\n",
            " 1 0 1 1 1 0 1 0 1 1 0 1 0 0 0 0 1 1 0 1 0 0 1 1 0 0 0 1 1 0 1 1 0 0 1 1 1\n",
            " 0 0 0 0 0 1 0 0 1 0 1 1 0 0 1 0 1 1 1 0 0 0 1 1 1 0 0 1 1 0 1 1 1 0 0]\n",
            "probabilities: (812, 2) \n",
            " [0 1 1 0 1 0 1 1 0 1 0 1 1 1 0 1 0 0 0 1 0 1 1 0 1 1 1 1 1 0 0 0 0 1 0 1 1\n",
            " 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 0 1 1 0 0 1 1 1 0 0 0 1 0 1 1\n",
            " 0 1 1 1 0 0 0 1 0 0 0 0 0 1 0 0 1 1 0 0 1 0 1 0 0 0 0 0 1 0 1 1 1 0 1 1 0\n",
            " 1 1 0 0 0 1 1 1 1 0 1 1 1 1 0 1 1 1 0 0 0 0 1 1 1 1 0 1 1 1 1 0 0 1 1 0 0\n",
            " 1 1 0 0 1 0 0 1 0 1 1 1 0 0 0 0 1 1 0 0 0 1 0 1 0 1 1 0 1 0 0 0 1 1 0 1 0\n",
            " 1 1 1 1 0 1 0 1 1 1 1 0 1 1 0 1 1 1 0 1 1 0 1 1 0 1 1 1 1 0 0 1 1 0 1 0 0\n",
            " 1 1 0 1 0 0 0 0 0 1 0 1 0 1 0 0 1 0 1 0 1 0 0 0 0 0 1 1 0 1 1 1 0 1 0 0 1\n",
            " 0 0 0 1 1 1 1 1 0 1 1 0 0 1 0 1 1 1 0 0 1 1 0 1 1 0 1 0 1 1 1 1 1 1 1 0 0\n",
            " 1 1 1 0 0 0 0 1 1 1 0 0 1 0 1 0 1 1 1 0 1 1 0 1 1 1 1 1 0 1 1 0 0 0 1 1 1\n",
            " 0 1 0 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0 1 0 1 1 1 1 0 0 1 0 1 1 1 0 1 0 0 0\n",
            " 0 0 0 1 1 1 1 0 0 0 1 0 0 1 1 0 0 0 1 0 0 1 0 1 1 0 1 0 0 1 1 1 1 0 0 1 1\n",
            " 1 0 0 1 1 0 0 1 0 1 1 0 1 1 1 0 0 1 1 0 0 1 0 0 0 1 0 1 1 0 1 1 0 0 1 0 1\n",
            " 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 0 0 0 1 1 0 0 0 0 1 0 1 1 1 0 1 1 1\n",
            " 1 1 0 0 1 1 0 1 0 0 0 0 0 1 0 0 1 0 1 1 0 0 1 1 1 0 0 0 1 0 0 1 1 0 1 1 0\n",
            " 1 0 1 1 0 0 1 0 1 1 0 0 1 0 1 1 1 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 0 0 1 1\n",
            " 0 0 0 0 1 1 0 0 0 1 1 1 0 1 0 0 1 1 0 1 0 0 1 1 1 0 0 0 1 1 1 1 0 1 0 0 1\n",
            " 1 1 1 1 1 1 0 0 0 0 0 0 0 1 1 0 0 1 0 1 0 1 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0\n",
            " 1 0 0 1 1 0 0 0 1 1 0 0 1 1 1 1 0 0 1 0 1 1 0 0 0 1 1 1 1 0 0 0 1 0 0 0 0\n",
            " 0 1 1 1 1 1 1 1 0 0 0 0 1 1 1 1 1 0 1 0 0 0 1 0 0 1 1 1 1 0 0 0 0 1 1 0 1\n",
            " 1 1 0 0 1 0 1 1 0 1 1 0 1 0 0 0 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 1 0 1\n",
            " 1 0 1 1 1 0 1 0 1 1 0 1 0 0 0 0 1 1 0 1 0 0 1 1 0 0 0 1 1 0 1 1 0 0 1 1 1\n",
            " 0 0 0 0 0 1 0 0 1 0 1 1 0 0 1 0 1 1 1 0 0 0 1 1 1 0 0 1 1 0 1 1 1 0 0]\n",
            "uniques chosen: 10 <= should be equal to: 10\n",
            "trainset before adding uncertain samples (490, 10) (490,)\n",
            "trainset after adding uncertain samples (500, 10) (500,)\n",
            "updated train set: (500, 10) (500,) unique(labels): [228 272] [0 1]\n",
            "val set: (802, 10) (802,)\n",
            "\n",
            "Train set: (500, 10)\n",
            "Validation set: (802, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 50\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.067 s \n",
            "\n",
            "Accuracy rate is 78.571429 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86       321\n",
            "           1       0.60      0.53      0.56       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.72      0.70      0.71       434\n",
            "weighted avg       0.78      0.79      0.78       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[281  40]\n",
            " [ 53  60]]\n",
            "--------------------------------\n",
            "final active learning accuracies [26.036866359447004, 63.594470046082954, 72.58064516129032, 75.80645161290323, 73.73271889400922, 75.80645161290323, 76.26728110599078, 76.036866359447, 76.72811059907833, 77.18894009216591, 76.49769585253456, 74.88479262672811, 77.41935483870968, 76.49769585253456, 76.95852534562212, 76.72811059907833, 78.11059907834101, 77.64976958525345, 78.3410138248848, 77.18894009216591, 78.3410138248848, 78.57142857142857, 79.26267281105991, 78.80184331797236, 78.11059907834101, 77.88018433179722, 77.64976958525345, 77.64976958525345, 77.18894009216591, 76.95852534562212, 77.18894009216591, 77.18894009216591, 76.95852534562212, 77.41935483870968, 79.03225806451613, 78.57142857142857, 78.80184331797236, 78.3410138248848, 77.88018433179722, 77.88018433179722, 78.57142857142857, 78.80184331797236, 78.80184331797236, 78.11059907834101, 78.80184331797236, 78.80184331797236, 79.03225806451613, 78.57142857142857, 78.57142857142857, 78.57142857142857]\n",
            "saved /Users/wenxuanhuang/Documents/Repo/ML-for-COVID-19-dataset/Results/Active-learning-experiment-25.pkl /Users/wenxuanhuang/Documents/Repo/ML-for-COVID-19-dataset ['Decision_tree.ipynb', 'dec_git.png', 'Logit_default_f10.pdf', 'Logistic.ipynb', 'SVC.ipynb', 'RF_f5e50_featureimp.pdf', 'log_al.png', 'dec_git.pdf', '.DS_Store', 'log_git.png', 'svm_git.png', 'Logistic_Scikit.ipynb', 'knn_git.pdf', 'knn_git.png', 'rf_al.png', 'Best classifier_RF_f5e50.pdf', 'KNN.ipynb', 'GBDC.ipynb', 'rf_git.png', 'README.md', 'all_training.csv', 'Results', 'svm_al.png', 'Log_ROC.png', 'Logit_default_f7(p_removal).pdf', 'Active_learning.ipynb', 'Random_forest.ipynb', 'Model_select.ipynb', 'gdbc_git.png', '.git', '.vscode', 'Untitled', 'RF_f5e50_modelselect.pdf', 'Logit_default_f8(std_removal).pdf']\n",
            "{\n",
            "  \"GDBCModel\": {\n",
            "    \"EntropySelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          65.2073732718894,\n",
            "          76.95852534562212,\n",
            "          75.11520737327189,\n",
            "          70.04608294930875,\n",
            "          72.35023041474655,\n",
            "          71.42857142857143,\n",
            "          77.41935483870968,\n",
            "          76.26728110599078,\n",
            "          77.41935483870968,\n",
            "          77.88018433179722,\n",
            "          78.57142857142857,\n",
            "          73.963133640553,\n",
            "          79.49308755760369,\n",
            "          79.03225806451613,\n",
            "          79.49308755760369,\n",
            "          79.26267281105991,\n",
            "          78.3410138248848,\n",
            "          78.57142857142857,\n",
            "          79.03225806451613,\n",
            "          80.18433179723502,\n",
            "          79.95391705069125,\n",
            "          80.18433179723502,\n",
            "          78.80184331797236,\n",
            "          79.49308755760369,\n",
            "          79.72350230414746,\n",
            "          80.18433179723502,\n",
            "          79.95391705069125,\n",
            "          81.5668202764977,\n",
            "          81.79723502304147,\n",
            "          81.5668202764977,\n",
            "          81.33640552995391,\n",
            "          80.64516129032258,\n",
            "          80.4147465437788,\n",
            "          81.10599078341014,\n",
            "          79.49308755760369,\n",
            "          80.64516129032258,\n",
            "          80.87557603686636,\n",
            "          80.87557603686636,\n",
            "          79.49308755760369,\n",
            "          80.18433179723502,\n",
            "          79.72350230414746,\n",
            "          79.95391705069125,\n",
            "          78.80184331797236,\n",
            "          79.72350230414746,\n",
            "          79.49308755760369,\n",
            "          80.4147465437788,\n",
            "          79.49308755760369,\n",
            "          80.4147465437788,\n",
            "          79.72350230414746,\n",
            "          79.95391705069125\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          77.41935483870968,\n",
            "          79.03225806451613,\n",
            "          80.64516129032258,\n",
            "          80.18433179723502\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          70.04608294930875,\n",
            "          76.49769585253456,\n",
            "          79.03225806451613,\n",
            "          78.57142857142857,\n",
            "          77.64976958525345,\n",
            "          78.80184331797236,\n",
            "          78.80184331797236,\n",
            "          77.41935483870968,\n",
            "          77.88018433179722,\n",
            "          77.64976958525345,\n",
            "          79.03225806451613,\n",
            "          77.88018433179722,\n",
            "          78.80184331797236,\n",
            "          78.80184331797236,\n",
            "          79.26267281105991,\n",
            "          79.72350230414746,\n",
            "          79.03225806451613,\n",
            "          79.72350230414746,\n",
            "          80.4147465437788,\n",
            "          80.87557603686636\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          78.57142857142857,\n",
            "          80.4147465437788\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          75.34562211981567,\n",
            "          80.64516129032258,\n",
            "          79.95391705069125,\n",
            "          79.03225806451613,\n",
            "          80.64516129032258,\n",
            "          80.18433179723502,\n",
            "          79.95391705069125,\n",
            "          79.49308755760369,\n",
            "          79.72350230414746,\n",
            "          79.49308755760369\n",
            "        ]\n",
            "      ]\n",
            "    },\n",
            "    \"MarginSamplingSelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          49.07834101382488,\n",
            "          63.133640552995395,\n",
            "          72.58064516129032,\n",
            "          68.89400921658986,\n",
            "          72.58064516129032,\n",
            "          76.036866359447,\n",
            "          75.34562211981567,\n",
            "          74.19354838709677,\n",
            "          74.65437788018433,\n",
            "          73.73271889400922,\n",
            "          75.11520737327189,\n",
            "          70.50691244239631,\n",
            "          75.57603686635944,\n",
            "          75.34562211981567,\n",
            "          75.11520737327189,\n",
            "          75.80645161290323,\n",
            "          76.72811059907833,\n",
            "          76.49769585253456,\n",
            "          77.41935483870968,\n",
            "          77.18894009216591,\n",
            "          77.41935483870968,\n",
            "          76.95852534562212,\n",
            "          78.80184331797236,\n",
            "          78.3410138248848,\n",
            "          78.57142857142857,\n",
            "          79.72350230414746,\n",
            "          79.72350230414746,\n",
            "          79.26267281105991,\n",
            "          79.49308755760369,\n",
            "          79.49308755760369,\n",
            "          79.26267281105991,\n",
            "          78.57142857142857,\n",
            "          79.03225806451613,\n",
            "          79.49308755760369,\n",
            "          79.95391705069125,\n",
            "          79.95391705069125,\n",
            "          80.18433179723502,\n",
            "          79.95391705069125,\n",
            "          80.64516129032258,\n",
            "          79.49308755760369,\n",
            "          78.57142857142857,\n",
            "          78.80184331797236,\n",
            "          78.57142857142857,\n",
            "          79.03225806451613,\n",
            "          79.26267281105991,\n",
            "          78.57142857142857,\n",
            "          79.26267281105991,\n",
            "          78.80184331797236,\n",
            "          79.26267281105991,\n",
            "          79.49308755760369\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          76.95852534562212,\n",
            "          78.80184331797236,\n",
            "          79.03225806451613,\n",
            "          81.10599078341014\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          74.65437788018433,\n",
            "          69.81566820276498,\n",
            "          80.18433179723502,\n",
            "          72.11981566820278,\n",
            "          72.81105990783409,\n",
            "          73.73271889400922,\n",
            "          73.50230414746544,\n",
            "          78.57142857142857,\n",
            "          78.57142857142857,\n",
            "          81.10599078341014,\n",
            "          80.64516129032258,\n",
            "          78.80184331797236,\n",
            "          79.26267281105991,\n",
            "          80.18433179723502,\n",
            "          79.72350230414746,\n",
            "          79.26267281105991,\n",
            "          79.95391705069125,\n",
            "          79.72350230414746,\n",
            "          79.95391705069125,\n",
            "          79.72350230414746\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          76.26728110599078,\n",
            "          79.26267281105991\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          78.11059907834101,\n",
            "          78.11059907834101,\n",
            "          78.57142857142857,\n",
            "          78.57142857142857,\n",
            "          80.4147465437788,\n",
            "          80.18433179723502,\n",
            "          79.95391705069125,\n",
            "          79.72350230414746,\n",
            "          79.49308755760369,\n",
            "          78.80184331797236\n",
            "        ]\n",
            "      ]\n",
            "    },\n",
            "    \"MinStdSelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          73.73271889400922,\n",
            "          77.18894009216591,\n",
            "          77.18894009216591,\n",
            "          76.72811059907833,\n",
            "          71.19815668202764,\n",
            "          76.49769585253456,\n",
            "          77.88018433179722,\n",
            "          78.11059907834101,\n",
            "          77.88018433179722,\n",
            "          77.88018433179722,\n",
            "          79.03225806451613,\n",
            "          79.03225806451613,\n",
            "          79.72350230414746,\n",
            "          78.57142857142857,\n",
            "          79.26267281105991,\n",
            "          79.26267281105991,\n",
            "          75.34562211981567,\n",
            "          73.50230414746544,\n",
            "          74.42396313364056,\n",
            "          73.963133640553,\n",
            "          74.19354838709677,\n",
            "          73.963133640553,\n",
            "          74.19354838709677,\n",
            "          74.42396313364056,\n",
            "          75.80645161290323,\n",
            "          75.80645161290323,\n",
            "          74.88479262672811,\n",
            "          74.65437788018433,\n",
            "          74.65437788018433,\n",
            "          75.34562211981567,\n",
            "          75.80645161290323,\n",
            "          80.87557603686636,\n",
            "          80.18433179723502,\n",
            "          80.64516129032258,\n",
            "          80.87557603686636,\n",
            "          81.10599078341014,\n",
            "          81.5668202764977,\n",
            "          81.5668202764977,\n",
            "          81.10599078341014,\n",
            "          81.33640552995391,\n",
            "          81.5668202764977,\n",
            "          82.7188940092166,\n",
            "          82.25806451612904,\n",
            "          82.25806451612904,\n",
            "          81.79723502304147,\n",
            "          80.4147465437788,\n",
            "          80.87557603686636,\n",
            "          81.10599078341014,\n",
            "          80.87557603686636,\n",
            "          81.33640552995391\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          78.3410138248848,\n",
            "          76.036866359447,\n",
            "          80.18433179723502,\n",
            "          79.72350230414746\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          77.64976958525345,\n",
            "          77.88018433179722,\n",
            "          73.04147465437788,\n",
            "          74.19354838709677,\n",
            "          80.64516129032258,\n",
            "          80.18433179723502,\n",
            "          79.72350230414746,\n",
            "          80.87557603686636,\n",
            "          81.33640552995391,\n",
            "          80.87557603686636,\n",
            "          79.49308755760369,\n",
            "          80.18433179723502,\n",
            "          80.87557603686636,\n",
            "          80.87557603686636,\n",
            "          80.87557603686636,\n",
            "          80.87557603686636,\n",
            "          81.33640552995391,\n",
            "          81.33640552995391,\n",
            "          80.18433179723502,\n",
            "          80.4147465437788\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          75.11520737327189,\n",
            "          79.26267281105991\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          79.95391705069125,\n",
            "          76.95852534562212,\n",
            "          80.18433179723502,\n",
            "          79.49308755760369,\n",
            "          79.26267281105991,\n",
            "          79.72350230414746,\n",
            "          79.95391705069125,\n",
            "          79.72350230414746,\n",
            "          79.72350230414746,\n",
            "          79.72350230414746\n",
            "        ]\n",
            "      ]\n",
            "    },\n",
            "    \"RandomSelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          63.36405529953917,\n",
            "          70.73732718894009,\n",
            "          61.29032258064516,\n",
            "          63.594470046082954,\n",
            "          74.65437788018433,\n",
            "          75.80645161290323,\n",
            "          76.49769585253456,\n",
            "          76.49769585253456,\n",
            "          77.41935483870968,\n",
            "          76.72811059907833,\n",
            "          78.3410138248848,\n",
            "          78.80184331797236,\n",
            "          77.41935483870968,\n",
            "          79.49308755760369,\n",
            "          77.64976958525345,\n",
            "          76.95852534562212,\n",
            "          77.18894009216591,\n",
            "          76.95852534562212,\n",
            "          77.64976958525345,\n",
            "          78.11059907834101,\n",
            "          78.11059907834101,\n",
            "          77.64976958525345,\n",
            "          77.64976958525345,\n",
            "          78.3410138248848,\n",
            "          78.57142857142857,\n",
            "          77.64976958525345,\n",
            "          77.64976958525345,\n",
            "          77.41935483870968,\n",
            "          77.88018433179722,\n",
            "          77.88018433179722,\n",
            "          77.88018433179722,\n",
            "          78.11059907834101,\n",
            "          77.64976958525345,\n",
            "          78.3410138248848,\n",
            "          78.80184331797236,\n",
            "          79.26267281105991,\n",
            "          78.57142857142857,\n",
            "          77.88018433179722,\n",
            "          77.64976958525345,\n",
            "          77.64976958525345,\n",
            "          78.11059907834101,\n",
            "          79.72350230414746,\n",
            "          79.72350230414746,\n",
            "          79.49308755760369,\n",
            "          79.03225806451613,\n",
            "          79.72350230414746,\n",
            "          78.80184331797236,\n",
            "          78.57142857142857,\n",
            "          79.49308755760369,\n",
            "          79.26267281105991\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          72.58064516129032,\n",
            "          72.58064516129032,\n",
            "          76.036866359447,\n",
            "          76.26728110599078\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          72.35023041474655,\n",
            "          72.11981566820278,\n",
            "          71.88940092165899,\n",
            "          73.04147465437788,\n",
            "          72.81105990783409,\n",
            "          75.11520737327189,\n",
            "          73.50230414746544,\n",
            "          76.036866359447,\n",
            "          76.26728110599078,\n",
            "          76.49769585253456,\n",
            "          76.72811059907833,\n",
            "          77.18894009216591,\n",
            "          76.72811059907833,\n",
            "          78.11059907834101,\n",
            "          78.3410138248848,\n",
            "          77.64976958525345,\n",
            "          79.72350230414746,\n",
            "          79.95391705069125,\n",
            "          80.18433179723502,\n",
            "          80.87557603686636\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          78.3410138248848,\n",
            "          79.95391705069125\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          69.35483870967742,\n",
            "          76.72811059907833,\n",
            "          78.3410138248848,\n",
            "          78.57142857142857,\n",
            "          78.80184331797236,\n",
            "          79.95391705069125,\n",
            "          79.26267281105991,\n",
            "          79.03225806451613,\n",
            "          79.03225806451613,\n",
            "          78.80184331797236\n",
            "        ]\n",
            "      ]\n",
            "    }\n",
            "  },\n",
            "  \"KnnModel\": {\n",
            "    \"RandomSelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          26.036866359447004,\n",
            "          63.594470046082954,\n",
            "          72.58064516129032,\n",
            "          75.80645161290323,\n",
            "          73.73271889400922,\n",
            "          75.80645161290323,\n",
            "          76.26728110599078,\n",
            "          76.036866359447,\n",
            "          76.72811059907833,\n",
            "          77.18894009216591,\n",
            "          76.49769585253456,\n",
            "          74.88479262672811,\n",
            "          77.41935483870968,\n",
            "          76.49769585253456,\n",
            "          76.95852534562212,\n",
            "          76.72811059907833,\n",
            "          78.11059907834101,\n",
            "          77.64976958525345,\n",
            "          78.3410138248848,\n",
            "          77.18894009216591,\n",
            "          78.3410138248848,\n",
            "          78.57142857142857,\n",
            "          79.26267281105991,\n",
            "          78.80184331797236,\n",
            "          78.11059907834101,\n",
            "          77.88018433179722,\n",
            "          77.64976958525345,\n",
            "          77.64976958525345,\n",
            "          77.18894009216591,\n",
            "          76.95852534562212,\n",
            "          77.18894009216591,\n",
            "          77.18894009216591,\n",
            "          76.95852534562212,\n",
            "          77.41935483870968,\n",
            "          79.03225806451613,\n",
            "          78.57142857142857,\n",
            "          78.80184331797236,\n",
            "          78.3410138248848,\n",
            "          77.88018433179722,\n",
            "          77.88018433179722,\n",
            "          78.57142857142857,\n",
            "          78.80184331797236,\n",
            "          78.80184331797236,\n",
            "          78.11059907834101,\n",
            "          78.80184331797236,\n",
            "          78.80184331797236,\n",
            "          79.03225806451613,\n",
            "          78.57142857142857,\n",
            "          78.57142857142857,\n",
            "          78.57142857142857\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          76.036866359447,\n",
            "          77.18894009216591,\n",
            "          78.11059907834101,\n",
            "          78.3410138248848\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          71.88940092165899,\n",
            "          77.41935483870968,\n",
            "          74.19354838709677,\n",
            "          76.26728110599078,\n",
            "          77.41935483870968,\n",
            "          78.11059907834101,\n",
            "          77.64976958525345,\n",
            "          78.57142857142857,\n",
            "          78.80184331797236,\n",
            "          78.57142857142857,\n",
            "          78.80184331797236,\n",
            "          77.41935483870968,\n",
            "          77.18894009216591,\n",
            "          77.88018433179722,\n",
            "          78.11059907834101,\n",
            "          78.11059907834101,\n",
            "          77.41935483870968,\n",
            "          79.03225806451613,\n",
            "          78.57142857142857,\n",
            "          79.26267281105991\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          76.036866359447,\n",
            "          77.64976958525345\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          78.11059907834101,\n",
            "          77.88018433179722,\n",
            "          76.95852534562212,\n",
            "          77.18894009216591,\n",
            "          76.49769585253456,\n",
            "          76.95852534562212,\n",
            "          76.95852534562212,\n",
            "          78.11059907834101,\n",
            "          77.41935483870968,\n",
            "          78.57142857142857\n",
            "        ]\n",
            "      ]\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "---------------------------- FINISHED ---------------------------\n",
            "\n",
            "Count = 26, using model = KnnModel, selection_function = MarginSamplingSelection, k = 250, iteration = 0.\n",
            "\n",
            "initial random chosen samples (250,)\n",
            "initial train set: (250, 10) (250,) unique(labels): [119 131] [0 1]\n",
            "Val set: (1052, 10) (1052,) (250,)\n",
            "\n",
            "Train set: (250, 10)\n",
            "Validation set: (1052, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.066 s \n",
            "\n",
            "Accuracy rate is 77.880184 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.88      0.85       321\n",
            "           1       0.59      0.50      0.54       113\n",
            "\n",
            "    accuracy                           0.78       434\n",
            "   macro avg       0.71      0.69      0.70       434\n",
            "weighted avg       0.77      0.78      0.77       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[282  39]\n",
            " [ 57  56]]\n",
            "--------------------------------\n",
            "val predicted: (1052,) [0 1 1 ... 1 0 1]\n",
            "probabilities: (1052, 2) \n",
            " [0 1 1 ... 1 0 1]\n",
            "trainset before adding uncertain samples (250, 10) (250,)\n",
            "trainset after adding uncertain samples (500, 10) (500,)\n",
            "updated train set: (500, 10) (500,) unique(labels): [250 250] [0 1]\n",
            "val set: (802, 10) (802,)\n",
            "\n",
            "Train set: (500, 10)\n",
            "Validation set: (802, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.074 s \n",
            "\n",
            "Accuracy rate is 80.184332 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.89      0.87       321\n",
            "           1       0.64      0.54      0.59       113\n",
            "\n",
            "    accuracy                           0.80       434\n",
            "   macro avg       0.74      0.72      0.73       434\n",
            "weighted avg       0.79      0.80      0.80       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[287  34]\n",
            " [ 52  61]]\n",
            "--------------------------------\n",
            "final active learning accuracies [77.88018433179722, 80.18433179723502]\n",
            "saved /Users/wenxuanhuang/Documents/Repo/ML-for-COVID-19-dataset/Results/Active-learning-experiment-26.pkl /Users/wenxuanhuang/Documents/Repo/ML-for-COVID-19-dataset ['Decision_tree.ipynb', 'dec_git.png', 'Logit_default_f10.pdf', 'Logistic.ipynb', 'SVC.ipynb', 'RF_f5e50_featureimp.pdf', 'log_al.png', 'dec_git.pdf', '.DS_Store', 'log_git.png', 'svm_git.png', 'Logistic_Scikit.ipynb', 'knn_git.pdf', 'knn_git.png', 'rf_al.png', 'Best classifier_RF_f5e50.pdf', 'KNN.ipynb', 'GBDC.ipynb', 'rf_git.png', 'README.md', 'all_training.csv', 'Results', 'svm_al.png', 'Log_ROC.png', 'Logit_default_f7(p_removal).pdf', 'Active_learning.ipynb', 'Random_forest.ipynb', 'Model_select.ipynb', 'gdbc_git.png', '.git', '.vscode', 'Untitled', 'RF_f5e50_modelselect.pdf', 'Logit_default_f8(std_removal).pdf']\n",
            "\n",
            "---------------------------- FINISHED ---------------------------\n",
            "\n",
            "Count = 27, using model = KnnModel, selection_function = MarginSamplingSelection, k = 125, iteration = 0.\n",
            "\n",
            "initial random chosen samples (125,)\n",
            "initial train set: (125, 10) (125,) unique(labels): [57 68] [0 1]\n",
            "Val set: (1177, 10) (1177,) (125,)\n",
            "\n",
            "Train set: (125, 10)\n",
            "Validation set: (1177, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.066 s \n",
            "\n",
            "Accuracy rate is 77.188940 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.88      0.85       321\n",
            "           1       0.57      0.48      0.52       113\n",
            "\n",
            "    accuracy                           0.77       434\n",
            "   macro avg       0.70      0.68      0.69       434\n",
            "weighted avg       0.76      0.77      0.76       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[281  40]\n",
            " [ 59  54]]\n",
            "--------------------------------\n",
            "val predicted: (1177,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1177, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "trainset before adding uncertain samples (125, 10) (125,)\n",
            "trainset after adding uncertain samples (250, 10) (250,)\n",
            "updated train set: (250, 10) (250,) unique(labels): [127 123] [0 1]\n",
            "val set: (1052, 10) (1052,)\n",
            "\n",
            "Train set: (250, 10)\n",
            "Validation set: (1052, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.076 s \n",
            "\n",
            "Accuracy rate is 77.649770 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.89      0.86       321\n",
            "           1       0.60      0.44      0.51       113\n",
            "\n",
            "    accuracy                           0.78       434\n",
            "   macro avg       0.71      0.67      0.68       434\n",
            "weighted avg       0.76      0.78      0.76       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[287  34]\n",
            " [ 63  50]]\n",
            "--------------------------------\n",
            "val predicted: (1052,) [0 0 1 ... 0 0 0]\n",
            "probabilities: (1052, 2) \n",
            " [0 0 1 ... 0 0 0]\n",
            "trainset before adding uncertain samples (250, 10) (250,)\n",
            "trainset after adding uncertain samples (375, 10) (375,)\n",
            "updated train set: (375, 10) (375,) unique(labels): [188 187] [0 1]\n",
            "val set: (927, 10) (927,)\n",
            "\n",
            "Train set: (375, 10)\n",
            "Validation set: (927, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 3\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.062 s \n",
            "\n",
            "Accuracy rate is 78.571429 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86       321\n",
            "           1       0.61      0.50      0.55       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.72      0.69      0.71       434\n",
            "weighted avg       0.78      0.79      0.78       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[284  37]\n",
            " [ 56  57]]\n",
            "--------------------------------\n",
            "val predicted: (927,) [0 1 0 1 1 0 0 0 0 1 1 1 0 1 0 0 0 0 0 1 0 1 0 1 1 1 0 1 1 0 0 1 1 0 0 1 0\n",
            " 1 1 0 1 1 1 1 1 0 0 1 1 0 0 1 0 0 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 1 0 1 0 0\n",
            " 1 0 0 1 1 1 1 0 1 0 0 0 1 1 1 0 0 0 0 1 0 1 0 0 0 1 0 0 1 0 1 1 1 1 0 0 1\n",
            " 0 1 0 0 0 0 1 0 1 0 1 1 0 0 1 0 0 1 0 1 1 1 1 1 1 0 1 1 0 1 1 0 1 0 1 0 0\n",
            " 0 0 1 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 0 0 1 0 0 0 1 0 1 1 1 0 0 0 0 1 1 1\n",
            " 0 0 0 1 0 1 1 0 0 1 0 1 0 0 0 0 1 0 1 1 1 1 1 1 1 1 0 0 0 1 1 0 1 0 1 1 1\n",
            " 1 0 1 1 0 1 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0 1 1 0 1 1 0 0 1 1 1 1 1 1 0 0 0\n",
            " 0 1 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 1 1 1 0 0 1 1 0 1 0 1 1 1 0 0 0 1\n",
            " 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 1 1 0 1 1 0 1 1 0 1 1 0 1 1 0 1 1 1 1 1 1 1\n",
            " 1 0 1 1 0 0 0 1 1 1 0 0 1 0 0 1 0 1 1 0 0 1 1 0 1 0 1 1 0 0 1 1 1 0 1 1 0\n",
            " 1 0 1 1 1 0 1 0 0 1 0 1 1 1 0 1 1 0 0 1 1 0 0 1 0 0 1 0 0 0 1 0 1 0 1 0 1\n",
            " 1 1 1 0 1 0 1 1 0 1 0 1 0 1 1 0 0 0 0 0 0 1 1 1 1 0 0 1 0 0 0 1 1 1 1 0 0\n",
            " 1 0 0 0 0 0 0 1 1 0 0 0 0 1 1 1 0 0 0 0 0 1 1 1 0 1 0 0 1 1 1 1 1 0 1 1 1\n",
            " 1 1 1 0 1 1 0 0 1 1 1 0 1 1 1 0 0 1 1 1 0 1 0 1 0 0 0 1 0 1 0 1 0 1 1 0 1\n",
            " 1 0 1 1 0 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 0 1 0 0\n",
            " 0 1 0 1 0 0 1 0 1 0 1 1 1 1 0 1 1 1 1 1 1 0 1 0 0 1 0 0 0 0 0 0 1 0 1 1 1\n",
            " 1 1 0 1 1 0 1 0 1 0 1 1 0 1 1 0 1 0 1 0 0 1 1 1 1 1 0 0 1 0 1 1 1 1 1 0 1\n",
            " 1 1 0 0 1 1 0 1 1 0 1 1 1 1 0 1 0 0 1 0 1 1 0 1 1 0 1 0 1 1 0 0 1 0 0 1 0\n",
            " 0 0 1 0 1 1 0 1 0 0 1 0 1 0 1 1 1 1 1 0 0 0 0 0 0 0 1 1 1 0 1 0 0 1 0 0 1\n",
            " 1 0 1 0 1 0 1 0 1 1 1 0 0 1 1 1 0 0 1 1 0 0 1 0 1 1 1 1 0 0 1 0 0 1 1 0 0\n",
            " 0 1 0 0 0 1 1 1 0 1 0 0 0 1 1 0 1 1 1 1 0 0 1 0 0 1 0 1 1 1 1 1 1 0 0 0 0\n",
            " 0 1 0 0 1 1 1 1 0 1 0 0 0 0 0 1 0 0 1 1 1 0 1 1 0 0 1 1 0 0 1 0 0 1 1 1 1\n",
            " 1 1 1 0 0 1 1 1 0 0 1 1 1 1 0 1 1 1 1 0 1 1 1 0 1 1 1 0 0 1 1 1 1 1 1 0 1\n",
            " 0 0 1 1 0 1 0 0 0 1 1 1 0 1 0 0 0 1 0 1 1 1 0 1 0 1 0 1 0 1 1 1 1 0 0 1 0\n",
            " 1 1 0 1 0 0 1 1 0 1 0 1 0 1 0 0 1 1 1 1 0 0 1 0 0 1 1 0 1 1 1 0 1 0 1 1 0\n",
            " 0 0]\n",
            "probabilities: (927, 2) \n",
            " [0 1 0 1 1 0 0 0 0 1 1 1 0 1 0 0 0 0 0 1 0 1 0 1 1 1 0 1 1 0 0 1 1 0 0 1 0\n",
            " 1 1 0 1 1 1 1 1 0 0 1 1 0 0 1 0 0 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 1 0 1 0 0\n",
            " 1 0 0 1 1 1 1 0 1 0 0 0 1 1 1 0 0 0 0 1 0 1 0 0 0 1 0 0 1 0 1 1 1 1 0 0 1\n",
            " 0 1 0 0 0 0 1 0 1 0 1 1 0 0 1 0 0 1 0 1 1 1 1 1 1 0 1 1 0 1 1 0 1 0 1 0 0\n",
            " 0 0 1 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 0 0 1 0 0 0 1 0 1 1 1 0 0 0 0 1 1 1\n",
            " 0 0 0 1 0 1 1 0 0 1 0 1 0 0 0 0 1 0 1 1 1 1 1 1 1 1 0 0 0 1 1 0 1 0 1 1 1\n",
            " 1 0 1 1 0 1 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0 1 1 0 1 1 0 0 1 1 1 1 1 1 0 0 0\n",
            " 0 1 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 1 1 1 0 0 1 1 0 1 0 1 1 1 0 0 0 1\n",
            " 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 1 1 0 1 1 0 1 1 0 1 1 0 1 1 0 1 1 1 1 1 1 1\n",
            " 1 0 1 1 0 0 0 1 1 1 0 0 1 0 0 1 0 1 1 0 0 1 1 0 1 0 1 1 0 0 1 1 1 0 1 1 0\n",
            " 1 0 1 1 1 0 1 0 0 1 0 1 1 1 0 1 1 0 0 1 1 0 0 1 0 0 1 0 0 0 1 0 1 0 1 0 1\n",
            " 1 1 1 0 1 0 1 1 0 1 0 1 0 1 1 0 0 0 0 0 0 1 1 1 1 0 0 1 0 0 0 1 1 1 1 0 0\n",
            " 1 0 0 0 0 0 0 1 1 0 0 0 0 1 1 1 0 0 0 0 0 1 1 1 0 1 0 0 1 1 1 1 1 0 1 1 1\n",
            " 1 1 1 0 1 1 0 0 1 1 1 0 1 1 1 0 0 1 1 1 0 1 0 1 0 0 0 1 0 1 0 1 0 1 1 0 1\n",
            " 1 0 1 1 0 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 0 1 0 0\n",
            " 0 1 0 1 0 0 1 0 1 0 1 1 1 1 0 1 1 1 1 1 1 0 1 0 0 1 0 0 0 0 0 0 1 0 1 1 1\n",
            " 1 1 0 1 1 0 1 0 1 0 1 1 0 1 1 0 1 0 1 0 0 1 1 1 1 1 0 0 1 0 1 1 1 1 1 0 1\n",
            " 1 1 0 0 1 1 0 1 1 0 1 1 1 1 0 1 0 0 1 0 1 1 0 1 1 0 1 0 1 1 0 0 1 0 0 1 0\n",
            " 0 0 1 0 1 1 0 1 0 0 1 0 1 0 1 1 1 1 1 0 0 0 0 0 0 0 1 1 1 0 1 0 0 1 0 0 1\n",
            " 1 0 1 0 1 0 1 0 1 1 1 0 0 1 1 1 0 0 1 1 0 0 1 0 1 1 1 1 0 0 1 0 0 1 1 0 0\n",
            " 0 1 0 0 0 1 1 1 0 1 0 0 0 1 1 0 1 1 1 1 0 0 1 0 0 1 0 1 1 1 1 1 1 0 0 0 0\n",
            " 0 1 0 0 1 1 1 1 0 1 0 0 0 0 0 1 0 0 1 1 1 0 1 1 0 0 1 1 0 0 1 0 0 1 1 1 1\n",
            " 1 1 1 0 0 1 1 1 0 0 1 1 1 1 0 1 1 1 1 0 1 1 1 0 1 1 1 0 0 1 1 1 1 1 1 0 1\n",
            " 0 0 1 1 0 1 0 0 0 1 1 1 0 1 0 0 0 1 0 1 1 1 0 1 0 1 0 1 0 1 1 1 1 0 0 1 0\n",
            " 1 1 0 1 0 0 1 1 0 1 0 1 0 1 0 0 1 1 1 1 0 0 1 0 0 1 1 0 1 1 1 0 1 0 1 1 0\n",
            " 0 0]\n",
            "trainset before adding uncertain samples (375, 10) (375,)\n",
            "trainset after adding uncertain samples (500, 10) (500,)\n",
            "updated train set: (500, 10) (500,) unique(labels): [249 251] [0 1]\n",
            "val set: (802, 10) (802,)\n",
            "\n",
            "Train set: (500, 10)\n",
            "Validation set: (802, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 4\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.060 s \n",
            "\n",
            "Accuracy rate is 79.723502 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.89      0.87       321\n",
            "           1       0.63      0.54      0.58       113\n",
            "\n",
            "    accuracy                           0.80       434\n",
            "   macro avg       0.74      0.71      0.72       434\n",
            "weighted avg       0.79      0.80      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[285  36]\n",
            " [ 52  61]]\n",
            "--------------------------------\n",
            "final active learning accuracies [77.18894009216591, 77.64976958525345, 78.57142857142857, 79.72350230414746]\n",
            "saved /Users/wenxuanhuang/Documents/Repo/ML-for-COVID-19-dataset/Results/Active-learning-experiment-27.pkl /Users/wenxuanhuang/Documents/Repo/ML-for-COVID-19-dataset ['Decision_tree.ipynb', 'dec_git.png', 'Logit_default_f10.pdf', 'Logistic.ipynb', 'SVC.ipynb', 'RF_f5e50_featureimp.pdf', 'log_al.png', 'dec_git.pdf', '.DS_Store', 'log_git.png', 'svm_git.png', 'Logistic_Scikit.ipynb', 'knn_git.pdf', 'knn_git.png', 'rf_al.png', 'Best classifier_RF_f5e50.pdf', 'KNN.ipynb', 'GBDC.ipynb', 'rf_git.png', 'README.md', 'all_training.csv', 'Results', 'svm_al.png', 'Log_ROC.png', 'Logit_default_f7(p_removal).pdf', 'Active_learning.ipynb', 'Random_forest.ipynb', 'Model_select.ipynb', 'gdbc_git.png', '.git', '.vscode', 'Untitled', 'RF_f5e50_modelselect.pdf', 'Logit_default_f8(std_removal).pdf']\n",
            "\n",
            "---------------------------- FINISHED ---------------------------\n",
            "\n",
            "Count = 28, using model = KnnModel, selection_function = MarginSamplingSelection, k = 50, iteration = 0.\n",
            "\n",
            "initial random chosen samples (50,)\n",
            "initial train set: (50, 10) (50,) unique(labels): [24 26] [0 1]\n",
            "Val set: (1252, 10) (1252,) (50,)\n",
            "\n",
            "Train set: (50, 10)\n",
            "Validation set: (1252, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.095 s \n",
            "\n",
            "Accuracy rate is 79.723502 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.89      0.87       321\n",
            "           1       0.63      0.52      0.57       113\n",
            "\n",
            "    accuracy                           0.80       434\n",
            "   macro avg       0.74      0.71      0.72       434\n",
            "weighted avg       0.79      0.80      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[287  34]\n",
            " [ 54  59]]\n",
            "--------------------------------\n",
            "val predicted: (1252,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1252, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "trainset before adding uncertain samples (50, 10) (50,)\n",
            "trainset after adding uncertain samples (100, 10) (100,)\n",
            "updated train set: (100, 10) (100,) unique(labels): [44 56] [0 1]\n",
            "val set: (1202, 10) (1202,)\n",
            "\n",
            "Train set: (100, 10)\n",
            "Validation set: (1202, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.071 s \n",
            "\n",
            "Accuracy rate is 75.115207 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.83      0.83       321\n",
            "           1       0.52      0.51      0.52       113\n",
            "\n",
            "    accuracy                           0.75       434\n",
            "   macro avg       0.68      0.67      0.68       434\n",
            "weighted avg       0.75      0.75      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[268  53]\n",
            " [ 55  58]]\n",
            "--------------------------------\n",
            "val predicted: (1202,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1202, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "trainset before adding uncertain samples (100, 10) (100,)\n",
            "trainset after adding uncertain samples (150, 10) (150,)\n",
            "updated train set: (150, 10) (150,) unique(labels): [80 70] [0 1]\n",
            "val set: (1152, 10) (1152,)\n",
            "\n",
            "Train set: (150, 10)\n",
            "Validation set: (1152, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 3\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.075 s \n",
            "\n",
            "Accuracy rate is 78.801843 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86       321\n",
            "           1       0.61      0.51      0.56       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.72      0.70      0.71       434\n",
            "weighted avg       0.78      0.79      0.78       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[284  37]\n",
            " [ 55  58]]\n",
            "--------------------------------\n",
            "val predicted: (1152,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1152, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "trainset before adding uncertain samples (150, 10) (150,)\n",
            "trainset after adding uncertain samples (200, 10) (200,)\n",
            "updated train set: (200, 10) (200,) unique(labels): [102  98] [0 1]\n",
            "val set: (1102, 10) (1102,)\n",
            "\n",
            "Train set: (200, 10)\n",
            "Validation set: (1102, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 4\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.093 s \n",
            "\n",
            "Accuracy rate is 79.262673 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.89      0.86       321\n",
            "           1       0.63      0.50      0.56       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.73      0.70      0.71       434\n",
            "weighted avg       0.78      0.79      0.78       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[287  34]\n",
            " [ 56  57]]\n",
            "--------------------------------\n",
            "val predicted: (1102,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1102, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "trainset before adding uncertain samples (200, 10) (200,)\n",
            "trainset after adding uncertain samples (250, 10) (250,)\n",
            "updated train set: (250, 10) (250,) unique(labels): [126 124] [0 1]\n",
            "val set: (1052, 10) (1052,)\n",
            "\n",
            "Train set: (250, 10)\n",
            "Validation set: (1052, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 5\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.072 s \n",
            "\n",
            "Accuracy rate is 80.645161 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.91      0.87       321\n",
            "           1       0.67      0.51      0.58       113\n",
            "\n",
            "    accuracy                           0.81       434\n",
            "   macro avg       0.75      0.71      0.73       434\n",
            "weighted avg       0.80      0.81      0.80       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[292  29]\n",
            " [ 55  58]]\n",
            "--------------------------------\n",
            "val predicted: (1052,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1052, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "trainset before adding uncertain samples (250, 10) (250,)\n",
            "trainset after adding uncertain samples (300, 10) (300,)\n",
            "updated train set: (300, 10) (300,) unique(labels): [149 151] [0 1]\n",
            "val set: (1002, 10) (1002,)\n",
            "\n",
            "Train set: (300, 10)\n",
            "Validation set: (1002, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 6\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.064 s \n",
            "\n",
            "Accuracy rate is 79.493088 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.89      0.87       321\n",
            "           1       0.63      0.51      0.57       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.73      0.70      0.72       434\n",
            "weighted avg       0.78      0.79      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[287  34]\n",
            " [ 55  58]]\n",
            "--------------------------------\n",
            "val predicted: (1002,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1002, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "trainset before adding uncertain samples (300, 10) (300,)\n",
            "trainset after adding uncertain samples (350, 10) (350,)\n",
            "updated train set: (350, 10) (350,) unique(labels): [187 163] [0 1]\n",
            "val set: (952, 10) (952,)\n",
            "\n",
            "Train set: (350, 10)\n",
            "Validation set: (952, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 7\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.066 s \n",
            "\n",
            "Accuracy rate is 78.110599 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.88      0.86       321\n",
            "           1       0.60      0.50      0.54       113\n",
            "\n",
            "    accuracy                           0.78       434\n",
            "   macro avg       0.71      0.69      0.70       434\n",
            "weighted avg       0.77      0.78      0.77       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[283  38]\n",
            " [ 57  56]]\n",
            "--------------------------------\n",
            "val predicted: (952,) [0 1 1 0 0 1 1 0 0 1 0 1 1 1 1 0 1 1 0 0 0 1 0 0 1 1 1 1 1 1 0 0 1 1 0 0 0\n",
            " 0 1 0 1 0 0 1 1 0 1 1 1 0 1 1 1 1 1 0 1 0 0 1 1 0 0 1 1 1 1 1 1 0 1 1 0 1\n",
            " 1 0 0 0 0 0 1 0 1 1 0 1 1 0 1 0 1 1 0 0 0 0 1 1 0 0 1 0 0 1 0 1 0 1 1 0 1\n",
            " 0 0 1 0 0 1 0 0 0 1 0 1 1 0 1 0 1 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 1 1 0 1 1\n",
            " 1 0 0 1 0 0 0 0 0 1 1 0 1 1 1 1 1 0 1 0 1 1 1 0 0 1 1 1 0 0 0 0 0 0 1 0 1\n",
            " 0 0 0 0 0 1 0 0 1 0 0 1 1 1 1 0 1 0 0 1 1 0 0 1 0 0 1 1 0 1 1 1 1 0 1 1 1\n",
            " 1 1 1 0 0 1 1 0 0 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 0 1 1 1 0 0 0 1 1 0 1 1 0\n",
            " 0 0 1 0 1 1 1 1 0 0 0 0 1 0 0 0 1 0 1 0 1 0 1 0 0 1 0 0 0 0 0 0 1 1 1 1 0\n",
            " 1 1 1 1 1 0 1 0 1 0 1 0 1 0 0 0 1 1 1 0 0 1 1 1 0 1 0 1 0 0 1 1 1 1 1 0 0\n",
            " 1 1 1 1 0 1 0 1 1 0 1 0 1 1 0 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 1 0 0 0 1 1 0\n",
            " 0 1 1 0 1 0 0 1 1 1 0 1 0 0 1 1 1 0 1 0 1 1 1 1 0 1 1 0 1 0 1 1 0 1 1 0 0\n",
            " 1 0 1 1 0 1 0 0 0 1 0 0 1 1 0 1 0 1 1 0 0 1 0 1 1 0 1 1 0 0 1 1 1 1 0 1 0\n",
            " 1 0 1 1 0 0 0 0 0 1 1 1 1 1 1 1 0 0 1 0 1 1 0 1 0 1 0 0 1 1 0 0 1 1 0 0 0\n",
            " 0 0 1 1 1 0 1 0 0 0 1 1 1 0 1 1 1 1 1 1 1 0 1 1 0 0 1 0 1 0 1 0 1 1 1 1 1\n",
            " 1 1 0 1 1 0 0 0 1 0 1 0 1 0 1 1 0 1 1 1 1 0 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1\n",
            " 1 1 0 0 1 0 1 1 1 1 1 1 1 1 1 0 1 0 0 0 1 1 0 0 1 0 1 1 0 1 1 1 0 1 1 1 0\n",
            " 1 1 1 1 0 0 1 0 0 1 0 1 0 1 1 1 1 1 0 1 0 1 0 1 1 0 1 1 0 1 0 1 1 0 1 0 0\n",
            " 1 1 1 1 1 1 0 0 0 1 0 1 1 1 1 1 1 0 1 1 0 0 1 0 0 1 1 1 1 1 1 1 1 0 1 1 1\n",
            " 0 0 1 0 1 1 0 1 1 1 0 1 0 1 1 1 0 1 1 0 0 1 1 0 1 1 1 0 1 0 1 1 0 0 1 0 1\n",
            " 0 1 1 1 1 1 1 0 0 0 0 0 1 0 1 1 1 0 1 0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 0 0\n",
            " 1 0 0 1 1 0 1 1 0 0 0 1 1 0 0 1 0 1 0 1 1 1 0 0 1 0 0 1 0 0 1 0 1 0 1 0 1\n",
            " 0 1 1 1 0 0 1 0 0 0 0 1 1 1 1 1 1 0 0 1 0 1 0 0 1 1 1 1 1 1 1 0 0 0 0 1 0\n",
            " 0 1 1 1 1 0 1 0 0 0 0 0 1 0 1 1 0 1 1 0 0 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1\n",
            " 1 1 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 0 0 1 1 1 0 1 1 1 1 1 0 1 1 0 1 1 0 0 0\n",
            " 1 1 0 1 0 0 0 1 0 1 1 0 1 0 1 0 0 0 1 1 1 1 1 0 0 1 0 1 0 1 0 0 1 0 0 0 1\n",
            " 0 0 1 0 1 1 1 0 0 0 0 1 1 1 0 1 0 0 0 1 1 0 1 1 1 0 0]\n",
            "probabilities: (952, 2) \n",
            " [0 1 1 0 0 1 1 0 0 1 0 1 1 1 1 0 1 1 0 0 0 1 0 0 1 1 1 1 1 1 0 0 1 1 0 0 0\n",
            " 0 1 0 1 0 0 1 1 0 1 1 1 0 1 1 1 1 1 0 1 0 0 1 1 0 0 1 1 1 1 1 1 0 1 1 0 1\n",
            " 1 0 0 0 0 0 1 0 1 1 0 1 1 0 1 0 1 1 0 0 0 0 1 1 0 0 1 0 0 1 0 1 0 1 1 0 1\n",
            " 0 0 1 0 0 1 0 0 0 1 0 1 1 0 1 0 1 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 1 1 0 1 1\n",
            " 1 0 0 1 0 0 0 0 0 1 1 0 1 1 1 1 1 0 1 0 1 1 1 0 0 1 1 1 0 0 0 0 0 0 1 0 1\n",
            " 0 0 0 0 0 1 0 0 1 0 0 1 1 1 1 0 1 0 0 1 1 0 0 1 0 0 1 1 0 1 1 1 1 0 1 1 1\n",
            " 1 1 1 0 0 1 1 0 0 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 0 1 1 1 0 0 0 1 1 0 1 1 0\n",
            " 0 0 1 0 1 1 1 1 0 0 0 0 1 0 0 0 1 0 1 0 1 0 1 0 0 1 0 0 0 0 0 0 1 1 1 1 0\n",
            " 1 1 1 1 1 0 1 0 1 0 1 0 1 0 0 0 1 1 1 0 0 1 1 1 0 1 0 1 0 0 1 1 1 1 1 0 0\n",
            " 1 1 1 1 0 1 0 1 1 0 1 0 1 1 0 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 1 0 0 0 1 1 0\n",
            " 0 1 1 0 1 0 0 1 1 1 0 1 0 0 1 1 1 0 1 0 1 1 1 1 0 1 1 0 1 0 1 1 0 1 1 0 0\n",
            " 1 0 1 1 0 1 0 0 0 1 0 0 1 1 0 1 0 1 1 0 0 1 0 1 1 0 1 1 0 0 1 1 1 1 0 1 0\n",
            " 1 0 1 1 0 0 0 0 0 1 1 1 1 1 1 1 0 0 1 0 1 1 0 1 0 1 0 0 1 1 0 0 1 1 0 0 0\n",
            " 0 0 1 1 1 0 1 0 0 0 1 1 1 0 1 1 1 1 1 1 1 0 1 1 0 0 1 0 1 0 1 0 1 1 1 1 1\n",
            " 1 1 0 1 1 0 0 0 1 0 1 0 1 0 1 1 0 1 1 1 1 0 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1\n",
            " 1 1 0 0 1 0 1 1 1 1 1 1 1 1 1 0 1 0 0 0 1 1 0 0 1 0 1 1 0 1 1 1 0 1 1 1 0\n",
            " 1 1 1 1 0 0 1 0 0 1 0 1 0 1 1 1 1 1 0 1 0 1 0 1 1 0 1 1 0 1 0 1 1 0 1 0 0\n",
            " 1 1 1 1 1 1 0 0 0 1 0 1 1 1 1 1 1 0 1 1 0 0 1 0 0 1 1 1 1 1 1 1 1 0 1 1 1\n",
            " 0 0 1 0 1 1 0 1 1 1 0 1 0 1 1 1 0 1 1 0 0 1 1 0 1 1 1 0 1 0 1 1 0 0 1 0 1\n",
            " 0 1 1 1 1 1 1 0 0 0 0 0 1 0 1 1 1 0 1 0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 0 0\n",
            " 1 0 0 1 1 0 1 1 0 0 0 1 1 0 0 1 0 1 0 1 1 1 0 0 1 0 0 1 0 0 1 0 1 0 1 0 1\n",
            " 0 1 1 1 0 0 1 0 0 0 0 1 1 1 1 1 1 0 0 1 0 1 0 0 1 1 1 1 1 1 1 0 0 0 0 1 0\n",
            " 0 1 1 1 1 0 1 0 0 0 0 0 1 0 1 1 0 1 1 0 0 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1\n",
            " 1 1 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 0 0 1 1 1 0 1 1 1 1 1 0 1 1 0 1 1 0 0 0\n",
            " 1 1 0 1 0 0 0 1 0 1 1 0 1 0 1 0 0 0 1 1 1 1 1 0 0 1 0 1 0 1 0 0 1 0 0 0 1\n",
            " 0 0 1 0 1 1 1 0 0 0 0 1 1 1 0 1 0 0 0 1 1 0 1 1 1 0 0]\n",
            "trainset before adding uncertain samples (350, 10) (350,)\n",
            "trainset after adding uncertain samples (400, 10) (400,)\n",
            "updated train set: (400, 10) (400,) unique(labels): [209 191] [0 1]\n",
            "val set: (902, 10) (902,)\n",
            "\n",
            "Train set: (400, 10)\n",
            "Validation set: (902, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 8\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.066 s \n",
            "\n",
            "Accuracy rate is 78.571429 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.86      0.86       321\n",
            "           1       0.59      0.58      0.59       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.72      0.72      0.72       434\n",
            "weighted avg       0.79      0.79      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[275  46]\n",
            " [ 47  66]]\n",
            "--------------------------------\n",
            "val predicted: (902,) [0 1 1 0 0 1 1 0 0 1 0 1 1 1 1 0 1 1 0 0 0 1 0 1 1 1 1 0 1 0 0 1 1 0 0 0 0\n",
            " 1 0 1 0 0 1 1 0 1 1 1 0 1 1 1 1 1 0 1 0 0 1 1 0 0 1 1 1 1 1 1 0 1 1 0 1 1\n",
            " 0 0 0 0 1 0 1 1 0 1 1 0 0 1 1 0 0 0 0 1 1 0 0 1 0 0 1 0 1 0 1 1 0 1 0 0 1\n",
            " 0 0 1 0 0 0 1 0 1 1 0 1 0 1 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 1 1 0 1 1 1 0 0\n",
            " 1 0 0 0 0 1 1 1 1 1 1 1 0 1 0 1 1 0 1 1 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0\n",
            " 1 0 0 1 1 1 1 0 1 0 0 1 1 0 0 1 0 0 1 1 0 1 1 1 0 0 1 1 1 1 1 1 0 0 1 1 0\n",
            " 0 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 0 1 1 0 0 1 1 0 1 1 0 0 0 1 0 1 1 1 1 0 0\n",
            " 0 0 1 0 0 0 1 0 1 0 1 0 1 0 0 1 0 0 0 0 0 1 1 1 1 0 1 1 1 1 1 0 1 0 1 0 1\n",
            " 0 1 0 0 1 1 1 0 1 1 0 1 1 0 0 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 0 1 0 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 0 1 1 1 0 0 1 1 1 0 1 0 0 1 1 1 0 1 0 1 1 1\n",
            " 1 1 1 1 0 1 0 1 1 0 1 1 0 1 0 1 1 1 0 0 1 0 1 1 1 0 1 0 1 1 0 0 1 0 1 1 0\n",
            " 1 1 0 0 1 1 1 1 0 1 0 1 0 1 1 0 0 0 0 0 1 1 1 1 1 0 1 0 0 1 1 1 0 1 0 1 0\n",
            " 1 0 0 0 1 1 0 0 0 1 1 1 1 0 1 0 0 1 1 0 1 1 1 1 1 1 1 0 1 1 0 0 1 0 1 0 1\n",
            " 0 1 1 1 1 1 1 1 0 1 1 0 0 0 1 0 1 0 1 0 1 1 0 1 1 1 1 0 0 1 1 1 1 1 0 1 1\n",
            " 1 1 1 1 1 1 1 0 0 1 0 1 1 1 1 1 1 1 1 1 0 1 0 0 0 1 1 0 0 1 0 1 1 0 1 1 1\n",
            " 0 1 1 1 1 1 1 1 0 0 1 0 0 1 0 1 0 1 1 1 1 1 0 1 0 1 1 1 0 1 1 0 1 0 1 1 0\n",
            " 1 0 0 1 1 1 1 1 1 0 0 0 1 0 1 1 1 1 1 0 0 1 1 0 0 1 0 0 1 1 1 1 1 1 1 1 0\n",
            " 1 1 1 0 0 1 0 1 1 0 1 1 1 0 1 0 1 1 1 0 1 1 0 0 1 1 0 1 1 1 1 0 1 1 0 0 1\n",
            " 0 1 0 1 1 1 1 0 0 0 0 0 1 0 1 1 1 0 1 0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 0 0\n",
            " 1 0 0 1 1 0 1 1 0 0 0 1 1 0 0 1 0 1 0 1 1 1 0 0 1 0 0 1 0 0 0 0 1 0 0 0 1\n",
            " 0 1 1 1 0 0 1 0 0 0 0 1 1 1 1 1 1 0 0 1 0 1 0 1 1 1 1 1 1 1 0 0 0 0 1 0 0\n",
            " 1 1 1 1 0 1 0 0 0 0 0 1 0 1 1 0 1 1 0 0 1 0 1 1 1 1 0 1 0 1 1 1 1 1 1 1 0\n",
            " 0 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 0 1 1 0 1 1 0 0 0 1 1 0 1 0 0\n",
            " 0 1 0 1 0 1 0 1 0 1 1 1 1 1 0 0 1 0 1 0 0 0 0 1 0 0 1 0 0 1 0 1 1 1 0 0 1\n",
            " 1 1 0 1 0 0 1 1 0 1 1 1 0 0]\n",
            "probabilities: (902, 2) \n",
            " [0 1 1 0 0 1 1 0 0 1 0 1 1 1 1 0 1 1 0 0 0 1 0 1 1 1 1 0 1 0 0 1 1 0 0 0 0\n",
            " 1 0 1 0 0 1 1 0 1 1 1 0 1 1 1 1 1 0 1 0 0 1 1 0 0 1 1 1 1 1 1 0 1 1 0 1 1\n",
            " 0 0 0 0 1 0 1 1 0 1 1 0 0 1 1 0 0 0 0 1 1 0 0 1 0 0 1 0 1 0 1 1 0 1 0 0 1\n",
            " 0 0 1 0 0 0 1 0 1 1 0 1 0 1 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 1 1 0 1 1 1 0 0\n",
            " 1 0 0 0 0 1 1 1 1 1 1 1 0 1 0 1 1 0 1 1 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0\n",
            " 1 0 0 1 1 1 1 0 1 0 0 1 1 0 0 1 0 0 1 1 0 1 1 1 0 0 1 1 1 1 1 1 0 0 1 1 0\n",
            " 0 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 0 1 1 0 0 1 1 0 1 1 0 0 0 1 0 1 1 1 1 0 0\n",
            " 0 0 1 0 0 0 1 0 1 0 1 0 1 0 0 1 0 0 0 0 0 1 1 1 1 0 1 1 1 1 1 0 1 0 1 0 1\n",
            " 0 1 0 0 1 1 1 0 1 1 0 1 1 0 0 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 0 1 0 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 0 1 1 1 0 0 1 1 1 0 1 0 0 1 1 1 0 1 0 1 1 1\n",
            " 1 1 1 1 0 1 0 1 1 0 1 1 0 1 0 1 1 1 0 0 1 0 1 1 1 0 1 0 1 1 0 0 1 0 1 1 0\n",
            " 1 1 0 0 1 1 1 1 0 1 0 1 0 1 1 0 0 0 0 0 1 1 1 1 1 0 1 0 0 1 1 1 0 1 0 1 0\n",
            " 1 0 0 0 1 1 0 0 0 1 1 1 1 0 1 0 0 1 1 0 1 1 1 1 1 1 1 0 1 1 0 0 1 0 1 0 1\n",
            " 0 1 1 1 1 1 1 1 0 1 1 0 0 0 1 0 1 0 1 0 1 1 0 1 1 1 1 0 0 1 1 1 1 1 0 1 1\n",
            " 1 1 1 1 1 1 1 0 0 1 0 1 1 1 1 1 1 1 1 1 0 1 0 0 0 1 1 0 0 1 0 1 1 0 1 1 1\n",
            " 0 1 1 1 1 1 1 1 0 0 1 0 0 1 0 1 0 1 1 1 1 1 0 1 0 1 1 1 0 1 1 0 1 0 1 1 0\n",
            " 1 0 0 1 1 1 1 1 1 0 0 0 1 0 1 1 1 1 1 0 0 1 1 0 0 1 0 0 1 1 1 1 1 1 1 1 0\n",
            " 1 1 1 0 0 1 0 1 1 0 1 1 1 0 1 0 1 1 1 0 1 1 0 0 1 1 0 1 1 1 1 0 1 1 0 0 1\n",
            " 0 1 0 1 1 1 1 0 0 0 0 0 1 0 1 1 1 0 1 0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 0 0\n",
            " 1 0 0 1 1 0 1 1 0 0 0 1 1 0 0 1 0 1 0 1 1 1 0 0 1 0 0 1 0 0 0 0 1 0 0 0 1\n",
            " 0 1 1 1 0 0 1 0 0 0 0 1 1 1 1 1 1 0 0 1 0 1 0 1 1 1 1 1 1 1 0 0 0 0 1 0 0\n",
            " 1 1 1 1 0 1 0 0 0 0 0 1 0 1 1 0 1 1 0 0 1 0 1 1 1 1 0 1 0 1 1 1 1 1 1 1 0\n",
            " 0 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 0 1 1 0 1 1 0 0 0 1 1 0 1 0 0\n",
            " 0 1 0 1 0 1 0 1 0 1 1 1 1 1 0 0 1 0 1 0 0 0 0 1 0 0 1 0 0 1 0 1 1 1 0 0 1\n",
            " 1 1 0 1 0 0 1 1 0 1 1 1 0 0]\n",
            "trainset before adding uncertain samples (400, 10) (400,)\n",
            "trainset after adding uncertain samples (450, 10) (450,)\n",
            "updated train set: (450, 10) (450,) unique(labels): [230 220] [0 1]\n",
            "val set: (852, 10) (852,)\n",
            "\n",
            "Train set: (450, 10)\n",
            "Validation set: (852, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 9\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.055 s \n",
            "\n",
            "Accuracy rate is 77.880184 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.85      0.85       321\n",
            "           1       0.57      0.58      0.58       113\n",
            "\n",
            "    accuracy                           0.78       434\n",
            "   macro avg       0.71      0.72      0.71       434\n",
            "weighted avg       0.78      0.78      0.78       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[272  49]\n",
            " [ 47  66]]\n",
            "--------------------------------\n",
            "val predicted: (852,) [0 1 1 0 0 1 1 0 0 1 0 1 1 1 1 0 1 1 0 0 0 1 0 1 1 1 1 1 0 0 1 1 0 0 0 0 1\n",
            " 0 1 0 0 1 1 0 1 1 1 0 1 1 1 1 1 0 1 0 0 1 1 0 0 1 1 1 1 1 1 0 1 1 0 1 1 0\n",
            " 0 0 0 1 0 1 1 0 1 1 0 0 1 0 0 0 1 1 0 0 1 0 0 1 0 1 1 1 1 0 0 1 0 0 1 0 0\n",
            " 0 1 0 1 1 0 1 0 1 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 1 1 0 1 1 1 0 1 0 0 0 0 1\n",
            " 1 1 1 1 1 1 0 1 0 1 1 0 1 1 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 1 0 0 1 1 1\n",
            " 1 0 1 0 1 1 0 0 0 0 1 0 1 1 1 1 1 1 1 0 1 0 0 1 1 0 0 1 1 1 1 1 0 1 1 1 1\n",
            " 1 0 1 1 1 1 1 0 0 1 1 0 1 1 0 0 1 0 1 1 1 1 0 0 0 0 1 0 0 0 1 0 1 0 0 0 1\n",
            " 0 0 1 0 0 0 0 1 1 1 1 0 1 1 1 1 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 1 1 0 1 1 0\n",
            " 0 1 1 1 0 0 1 1 1 1 1 0 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 0 1 1\n",
            " 1 0 1 1 1 0 1 0 0 1 1 1 0 1 0 1 1 1 1 0 1 1 0 1 0 1 1 0 1 1 0 1 1 1 1 1 0\n",
            " 0 1 0 1 0 1 0 1 0 1 1 0 1 0 1 1 0 1 1 0 0 1 1 1 1 0 1 0 1 0 1 1 0 0 0 0 0\n",
            " 1 1 1 1 1 1 0 0 1 1 1 0 1 0 1 0 1 0 0 1 1 0 0 0 0 1 1 1 0 1 0 0 1 1 0 1 1\n",
            " 1 1 1 1 1 0 1 1 0 0 1 0 1 0 1 0 1 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 1 1 0 1\n",
            " 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 0 0 0 1 1\n",
            " 0 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0 1 0 0 1 0 1 1 1 1 1 1 0 1 0 1 1 1 0 1\n",
            " 1 0 1 0 1 1 0 1 0 0 1 1 1 1 1 1 0 0 0 1 0 1 1 1 1 1 0 1 1 0 1 0 0 1 1 1 1\n",
            " 1 1 1 1 0 1 1 1 0 0 1 0 1 1 0 1 1 0 1 0 1 1 1 0 0 1 0 0 1 1 0 1 1 1 1 0 1\n",
            " 1 0 0 1 0 1 1 1 1 1 0 0 0 0 0 1 0 1 1 1 1 0 0 0 1 1 0 0 0 1 0 1 1 1 1 0 0\n",
            " 1 0 0 1 1 0 1 1 0 0 1 1 0 0 1 0 1 0 1 1 1 0 0 1 0 0 1 0 0 0 1 0 1 0 1 0 1\n",
            " 1 1 0 0 1 0 0 0 0 1 1 1 1 1 1 0 0 1 0 1 0 1 1 1 1 1 1 1 0 0 1 0 1 1 0 1 0\n",
            " 0 0 1 0 1 1 0 1 1 0 0 1 0 1 1 0 0 1 1 1 1 0 1 1 0 0 1 1 1 1 1 0 1 1 1 1 1\n",
            " 0 1 1 1 0 1 1 1 1 1 0 1 1 0 1 1 1 0 0 1 1 0 1 0 0 0 1 0 1 0 1 0 1 0 1 1 1\n",
            " 1 1 0 0 1 0 1 0 0 0 1 0 0 1 0 0 1 0 1 1 1 0 0 1 1 1 0 1 0 0 1 1 0 1 1 1 0\n",
            " 0]\n",
            "probabilities: (852, 2) \n",
            " [0 1 1 0 0 1 1 0 0 1 0 1 1 1 1 0 1 1 0 0 0 1 0 1 1 1 1 1 0 0 1 1 0 0 0 0 1\n",
            " 0 1 0 0 1 1 0 1 1 1 0 1 1 1 1 1 0 1 0 0 1 1 0 0 1 1 1 1 1 1 0 1 1 0 1 1 0\n",
            " 0 0 0 1 0 1 1 0 1 1 0 0 1 0 0 0 1 1 0 0 1 0 0 1 0 1 1 1 1 0 0 1 0 0 1 0 0\n",
            " 0 1 0 1 1 0 1 0 1 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 1 1 0 1 1 1 0 1 0 0 0 0 1\n",
            " 1 1 1 1 1 1 0 1 0 1 1 0 1 1 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 1 0 0 1 1 1\n",
            " 1 0 1 0 1 1 0 0 0 0 1 0 1 1 1 1 1 1 1 0 1 0 0 1 1 0 0 1 1 1 1 1 0 1 1 1 1\n",
            " 1 0 1 1 1 1 1 0 0 1 1 0 1 1 0 0 1 0 1 1 1 1 0 0 0 0 1 0 0 0 1 0 1 0 0 0 1\n",
            " 0 0 1 0 0 0 0 1 1 1 1 0 1 1 1 1 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 1 1 0 1 1 0\n",
            " 0 1 1 1 0 0 1 1 1 1 1 0 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 0 1 1\n",
            " 1 0 1 1 1 0 1 0 0 1 1 1 0 1 0 1 1 1 1 0 1 1 0 1 0 1 1 0 1 1 0 1 1 1 1 1 0\n",
            " 0 1 0 1 0 1 0 1 0 1 1 0 1 0 1 1 0 1 1 0 0 1 1 1 1 0 1 0 1 0 1 1 0 0 0 0 0\n",
            " 1 1 1 1 1 1 0 0 1 1 1 0 1 0 1 0 1 0 0 1 1 0 0 0 0 1 1 1 0 1 0 0 1 1 0 1 1\n",
            " 1 1 1 1 1 0 1 1 0 0 1 0 1 0 1 0 1 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 1 1 0 1\n",
            " 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 0 0 0 1 1\n",
            " 0 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0 1 0 0 1 0 1 1 1 1 1 1 0 1 0 1 1 1 0 1\n",
            " 1 0 1 0 1 1 0 1 0 0 1 1 1 1 1 1 0 0 0 1 0 1 1 1 1 1 0 1 1 0 1 0 0 1 1 1 1\n",
            " 1 1 1 1 0 1 1 1 0 0 1 0 1 1 0 1 1 0 1 0 1 1 1 0 0 1 0 0 1 1 0 1 1 1 1 0 1\n",
            " 1 0 0 1 0 1 1 1 1 1 0 0 0 0 0 1 0 1 1 1 1 0 0 0 1 1 0 0 0 1 0 1 1 1 1 0 0\n",
            " 1 0 0 1 1 0 1 1 0 0 1 1 0 0 1 0 1 0 1 1 1 0 0 1 0 0 1 0 0 0 1 0 1 0 1 0 1\n",
            " 1 1 0 0 1 0 0 0 0 1 1 1 1 1 1 0 0 1 0 1 0 1 1 1 1 1 1 1 0 0 1 0 1 1 0 1 0\n",
            " 0 0 1 0 1 1 0 1 1 0 0 1 0 1 1 0 0 1 1 1 1 0 1 1 0 0 1 1 1 1 1 0 1 1 1 1 1\n",
            " 0 1 1 1 0 1 1 1 1 1 0 1 1 0 1 1 1 0 0 1 1 0 1 0 0 0 1 0 1 0 1 0 1 0 1 1 1\n",
            " 1 1 0 0 1 0 1 0 0 0 1 0 0 1 0 0 1 0 1 1 1 0 0 1 1 1 0 1 0 0 1 1 0 1 1 1 0\n",
            " 0]\n",
            "trainset before adding uncertain samples (450, 10) (450,)\n",
            "trainset after adding uncertain samples (500, 10) (500,)\n",
            "updated train set: (500, 10) (500,) unique(labels): [258 242] [0 1]\n",
            "val set: (802, 10) (802,)\n",
            "\n",
            "Train set: (500, 10)\n",
            "Validation set: (802, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 10\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.095 s \n",
            "\n",
            "Accuracy rate is 78.341014 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.86      0.85       321\n",
            "           1       0.59      0.58      0.58       113\n",
            "\n",
            "    accuracy                           0.78       434\n",
            "   macro avg       0.72      0.72      0.72       434\n",
            "weighted avg       0.78      0.78      0.78       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[275  46]\n",
            " [ 48  65]]\n",
            "--------------------------------\n",
            "final active learning accuracies [79.72350230414746, 75.11520737327189, 78.80184331797236, 79.26267281105991, 80.64516129032258, 79.49308755760369, 78.11059907834101, 78.57142857142857, 77.88018433179722, 78.3410138248848]\n",
            "saved /Users/wenxuanhuang/Documents/Repo/ML-for-COVID-19-dataset/Results/Active-learning-experiment-28.pkl /Users/wenxuanhuang/Documents/Repo/ML-for-COVID-19-dataset ['Decision_tree.ipynb', 'dec_git.png', 'Logit_default_f10.pdf', 'Logistic.ipynb', 'SVC.ipynb', 'RF_f5e50_featureimp.pdf', 'log_al.png', 'dec_git.pdf', '.DS_Store', 'log_git.png', 'svm_git.png', 'Logistic_Scikit.ipynb', 'knn_git.pdf', 'knn_git.png', 'rf_al.png', 'Best classifier_RF_f5e50.pdf', 'KNN.ipynb', 'GBDC.ipynb', 'rf_git.png', 'README.md', 'all_training.csv', 'Results', 'svm_al.png', 'Log_ROC.png', 'Logit_default_f7(p_removal).pdf', 'Active_learning.ipynb', 'Random_forest.ipynb', 'Model_select.ipynb', 'gdbc_git.png', '.git', '.vscode', 'Untitled', 'RF_f5e50_modelselect.pdf', 'Logit_default_f8(std_removal).pdf']\n",
            "\n",
            "---------------------------- FINISHED ---------------------------\n",
            "\n",
            "Count = 29, using model = KnnModel, selection_function = MarginSamplingSelection, k = 25, iteration = 0.\n",
            "\n",
            "initial random chosen samples (25,)\n",
            "initial train set: (25, 10) (25,) unique(labels): [11 14] [0 1]\n",
            "Val set: (1277, 10) (1277,) (25,)\n",
            "\n",
            "Train set: (25, 10)\n",
            "Validation set: (1277, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.074 s \n",
            "\n",
            "Accuracy rate is 44.009217 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.30      0.44       321\n",
            "           1       0.30      0.83      0.44       113\n",
            "\n",
            "    accuracy                           0.44       434\n",
            "   macro avg       0.57      0.57      0.44       434\n",
            "weighted avg       0.70      0.44      0.44       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 97 224]\n",
            " [ 19  94]]\n",
            "--------------------------------\n",
            "val predicted: (1277,) [0 1 1 ... 0 1 0]\n",
            "probabilities: (1277, 2) \n",
            " [0 1 1 ... 0 1 0]\n",
            "trainset before adding uncertain samples (25, 10) (25,)\n",
            "trainset after adding uncertain samples (50, 10) (50,)\n",
            "updated train set: (50, 10) (50,) unique(labels): [34 16] [0 1]\n",
            "val set: (1252, 10) (1252,)\n",
            "\n",
            "Train set: (50, 10)\n",
            "Validation set: (1252, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.063 s \n",
            "\n",
            "Accuracy rate is 77.880184 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.92      0.86       321\n",
            "           1       0.62      0.39      0.48       113\n",
            "\n",
            "    accuracy                           0.78       434\n",
            "   macro avg       0.71      0.65      0.67       434\n",
            "weighted avg       0.76      0.78      0.76       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[294  27]\n",
            " [ 69  44]]\n",
            "--------------------------------\n",
            "val predicted: (1252,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1252, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "trainset before adding uncertain samples (50, 10) (50,)\n",
            "trainset after adding uncertain samples (75, 10) (75,)\n",
            "updated train set: (75, 10) (75,) unique(labels): [43 32] [0 1]\n",
            "val set: (1227, 10) (1227,)\n",
            "\n",
            "Train set: (75, 10)\n",
            "Validation set: (1227, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 3\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.073 s \n",
            "\n",
            "Accuracy rate is 72.811060 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.78      0.81       321\n",
            "           1       0.48      0.59      0.53       113\n",
            "\n",
            "    accuracy                           0.73       434\n",
            "   macro avg       0.66      0.68      0.67       434\n",
            "weighted avg       0.75      0.73      0.74       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[249  72]\n",
            " [ 46  67]]\n",
            "--------------------------------\n",
            "val predicted: (1227,) [0 1 1 ... 1 0 0]\n",
            "probabilities: (1227, 2) \n",
            " [0 1 1 ... 1 0 0]\n",
            "trainset before adding uncertain samples (75, 10) (75,)\n",
            "trainset after adding uncertain samples (100, 10) (100,)\n",
            "updated train set: (100, 10) (100,) unique(labels): [54 46] [0 1]\n",
            "val set: (1202, 10) (1202,)\n",
            "\n",
            "Train set: (100, 10)\n",
            "Validation set: (1202, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 4\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.063 s \n",
            "\n",
            "Accuracy rate is 80.414747 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.88      0.87       321\n",
            "           1       0.64      0.58      0.60       113\n",
            "\n",
            "    accuracy                           0.80       434\n",
            "   macro avg       0.75      0.73      0.74       434\n",
            "weighted avg       0.80      0.80      0.80       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[284  37]\n",
            " [ 48  65]]\n",
            "--------------------------------\n",
            "val predicted: (1202,) [0 1 1 ... 1 0 0]\n",
            "probabilities: (1202, 2) \n",
            " [0 1 1 ... 1 0 0]\n",
            "trainset before adding uncertain samples (100, 10) (100,)\n",
            "trainset after adding uncertain samples (125, 10) (125,)\n",
            "updated train set: (125, 10) (125,) unique(labels): [72 53] [0 1]\n",
            "val set: (1177, 10) (1177,)\n",
            "\n",
            "Train set: (125, 10)\n",
            "Validation set: (1177, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 5\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.078 s \n",
            "\n",
            "Accuracy rate is 78.801843 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.93      0.87       321\n",
            "           1       0.66      0.39      0.49       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.73      0.66      0.68       434\n",
            "weighted avg       0.77      0.79      0.77       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[298  23]\n",
            " [ 69  44]]\n",
            "--------------------------------\n",
            "val predicted: (1177,) [0 0 0 ... 0 0 0]\n",
            "probabilities: (1177, 2) \n",
            " [0 0 0 ... 0 0 0]\n",
            "trainset before adding uncertain samples (125, 10) (125,)\n",
            "trainset after adding uncertain samples (150, 10) (150,)\n",
            "updated train set: (150, 10) (150,) unique(labels): [82 68] [0 1]\n",
            "val set: (1152, 10) (1152,)\n",
            "\n",
            "Train set: (150, 10)\n",
            "Validation set: (1152, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 6\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.073 s \n",
            "\n",
            "Accuracy rate is 76.728111 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.89      0.85       321\n",
            "           1       0.57      0.42      0.48       113\n",
            "\n",
            "    accuracy                           0.77       434\n",
            "   macro avg       0.69      0.65      0.67       434\n",
            "weighted avg       0.75      0.77      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[286  35]\n",
            " [ 66  47]]\n",
            "--------------------------------\n",
            "val predicted: (1152,) [1 1 1 ... 0 0 0]\n",
            "probabilities: (1152, 2) \n",
            " [1 1 1 ... 0 0 0]\n",
            "trainset before adding uncertain samples (150, 10) (150,)\n",
            "trainset after adding uncertain samples (175, 10) (175,)\n",
            "updated train set: (175, 10) (175,) unique(labels): [93 82] [0 1]\n",
            "val set: (1127, 10) (1127,)\n",
            "\n",
            "Train set: (175, 10)\n",
            "Validation set: (1127, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 7\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.084 s \n",
            "\n",
            "Accuracy rate is 79.262673 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.91      0.87       321\n",
            "           1       0.64      0.47      0.54       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.73      0.69      0.70       434\n",
            "weighted avg       0.78      0.79      0.78       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[291  30]\n",
            " [ 60  53]]\n",
            "--------------------------------\n",
            "val predicted: (1127,) [1 1 1 ... 0 0 0]\n",
            "probabilities: (1127, 2) \n",
            " [1 1 1 ... 0 0 0]\n",
            "trainset before adding uncertain samples (175, 10) (175,)\n",
            "trainset after adding uncertain samples (200, 10) (200,)\n",
            "updated train set: (200, 10) (200,) unique(labels): [104  96] [0 1]\n",
            "val set: (1102, 10) (1102,)\n",
            "\n",
            "Train set: (200, 10)\n",
            "Validation set: (1102, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 8\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.083 s \n",
            "\n",
            "Accuracy rate is 80.184332 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.91      0.87       321\n",
            "           1       0.66      0.50      0.57       113\n",
            "\n",
            "    accuracy                           0.80       434\n",
            "   macro avg       0.75      0.70      0.72       434\n",
            "weighted avg       0.79      0.80      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[292  29]\n",
            " [ 57  56]]\n",
            "--------------------------------\n",
            "val predicted: (1102,) [1 1 1 ... 0 0 0]\n",
            "probabilities: (1102, 2) \n",
            " [1 1 1 ... 0 0 0]\n",
            "trainset before adding uncertain samples (200, 10) (200,)\n",
            "trainset after adding uncertain samples (225, 10) (225,)\n",
            "updated train set: (225, 10) (225,) unique(labels): [118 107] [0 1]\n",
            "val set: (1077, 10) (1077,)\n",
            "\n",
            "Train set: (225, 10)\n",
            "Validation set: (1077, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 9\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.060 s \n",
            "\n",
            "Accuracy rate is 78.801843 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.89      0.86       321\n",
            "           1       0.62      0.50      0.55       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.72      0.69      0.71       434\n",
            "weighted avg       0.78      0.79      0.78       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[286  35]\n",
            " [ 57  56]]\n",
            "--------------------------------\n",
            "val predicted: (1077,) [1 1 1 ... 0 0 0]\n",
            "probabilities: (1077, 2) \n",
            " [1 1 1 ... 0 0 0]\n",
            "trainset before adding uncertain samples (225, 10) (225,)\n",
            "trainset after adding uncertain samples (250, 10) (250,)\n",
            "updated train set: (250, 10) (250,) unique(labels): [136 114] [0 1]\n",
            "val set: (1052, 10) (1052,)\n",
            "\n",
            "Train set: (250, 10)\n",
            "Validation set: (1052, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 10\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.082 s \n",
            "\n",
            "Accuracy rate is 79.032258 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.91      0.86       321\n",
            "           1       0.63      0.46      0.53       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.73      0.68      0.70       434\n",
            "weighted avg       0.78      0.79      0.78       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[291  30]\n",
            " [ 61  52]]\n",
            "--------------------------------\n",
            "val predicted: (1052,) [1 1 1 ... 0 0 0]\n",
            "probabilities: (1052, 2) \n",
            " [1 1 1 ... 0 0 0]\n",
            "trainset before adding uncertain samples (250, 10) (250,)\n",
            "trainset after adding uncertain samples (275, 10) (275,)\n",
            "updated train set: (275, 10) (275,) unique(labels): [146 129] [0 1]\n",
            "val set: (1027, 10) (1027,)\n",
            "\n",
            "Train set: (275, 10)\n",
            "Validation set: (1027, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 11\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.057 s \n",
            "\n",
            "Accuracy rate is 79.723502 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.90      0.87       321\n",
            "           1       0.64      0.50      0.56       113\n",
            "\n",
            "    accuracy                           0.80       434\n",
            "   macro avg       0.74      0.70      0.72       434\n",
            "weighted avg       0.79      0.80      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[289  32]\n",
            " [ 56  57]]\n",
            "--------------------------------\n",
            "val predicted: (1027,) [1 1 1 ... 0 0 0]\n",
            "probabilities: (1027, 2) \n",
            " [1 1 1 ... 0 0 0]\n",
            "trainset before adding uncertain samples (275, 10) (275,)\n",
            "trainset after adding uncertain samples (300, 10) (300,)\n",
            "updated train set: (300, 10) (300,) unique(labels): [156 144] [0 1]\n",
            "val set: (1002, 10) (1002,)\n",
            "\n",
            "Train set: (300, 10)\n",
            "Validation set: (1002, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 12\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.071 s \n",
            "\n",
            "Accuracy rate is 79.493088 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.89      0.87       321\n",
            "           1       0.63      0.51      0.57       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.73      0.70      0.72       434\n",
            "weighted avg       0.78      0.79      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[287  34]\n",
            " [ 55  58]]\n",
            "--------------------------------\n",
            "val predicted: (1002,) [1 1 1 ... 0 0 0]\n",
            "probabilities: (1002, 2) \n",
            " [1 1 1 ... 0 0 0]\n",
            "trainset before adding uncertain samples (300, 10) (300,)\n",
            "trainset after adding uncertain samples (325, 10) (325,)\n",
            "updated train set: (325, 10) (325,) unique(labels): [169 156] [0 1]\n",
            "val set: (977, 10) (977,)\n",
            "\n",
            "Train set: (325, 10)\n",
            "Validation set: (977, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 13\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.078 s \n",
            "\n",
            "Accuracy rate is 79.262673 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.89      0.86       321\n",
            "           1       0.63      0.50      0.56       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.73      0.70      0.71       434\n",
            "weighted avg       0.78      0.79      0.78       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[287  34]\n",
            " [ 56  57]]\n",
            "--------------------------------\n",
            "val predicted: (977,) [1 1 1 0 1 0 0 0 1 1 0 0 1 0 1 0 0 1 1 1 0 1 0 1 0 0 0 0 1 0 0 1 0 1 1 0 1\n",
            " 1 1 0 1 1 0 0 0 1 0 1 0 0 1 1 1 0 1 1 1 1 0 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1\n",
            " 1 1 0 1 1 1 0 0 1 1 0 0 1 0 0 1 0 1 1 1 1 1 0 1 0 0 0 1 1 0 0 0 0 0 1 0 1\n",
            " 0 0 0 1 0 0 1 0 1 1 0 1 0 1 0 0 1 0 0 0 0 1 0 1 0 1 1 1 0 1 0 0 1 1 0 1 0\n",
            " 1 1 1 1 1 0 1 0 1 1 0 0 1 1 0 1 1 1 1 1 0 0 1 0 1 0 1 1 1 0 1 0 0 1 0 1 1\n",
            " 0 0 0 0 0 0 0 1 1 1 0 1 0 0 0 0 0 1 1 0 0 0 0 1 1 0 1 1 0 1 1 1 0 0 0 0 0\n",
            " 0 1 1 0 1 1 0 1 1 1 1 1 1 1 0 0 0 1 1 0 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 0\n",
            " 0 1 1 1 0 1 0 1 1 1 1 1 1 0 0 0 1 1 0 1 1 0 0 0 1 1 1 1 1 0 0 0 0 0 1 0 1\n",
            " 1 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 1 1 1 1 1 1 1 0 0 1 1 0 1 0 1 0 1 0 1 1 1\n",
            " 0 1 1 0 1 0 1 0 1 1 0 1 1 1 1 1 1 0 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1\n",
            " 0 0 0 1 1 1 1 0 1 1 0 1 0 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 0 1 1 0 1 1 0 1 0\n",
            " 1 1 1 1 1 0 0 0 0 0 1 1 0 0 1 0 0 1 0 0 0 1 1 0 1 1 0 0 0 1 0 1 1 1 0 0 1\n",
            " 1 1 0 1 0 1 0 1 0 1 1 1 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 1 1 0 1 0 1 0 0 1\n",
            " 0 0 1 0 0 0 0 0 1 1 0 0 0 1 1 1 0 1 0 0 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 0 0\n",
            " 1 0 1 0 1 1 1 1 1 1 1 0 1 1 0 0 0 0 1 0 1 1 0 1 0 1 1 1 1 0 0 1 1 1 1 0 1\n",
            " 1 0 1 1 1 1 1 1 0 0 0 0 0 1 1 1 1 1 1 1 1 0 1 0 0 0 1 0 0 0 1 0 1 0 1 1 1\n",
            " 0 1 1 1 1 1 1 0 0 1 0 0 1 0 0 1 0 1 0 1 1 0 1 1 0 1 0 1 1 0 1 1 1 1 1 1 0\n",
            " 1 0 1 0 0 1 1 1 1 1 0 1 0 1 1 0 1 1 0 0 1 0 1 1 1 0 1 1 1 1 1 0 1 1 1 0 1\n",
            " 1 0 1 0 1 1 0 1 0 1 1 1 0 0 1 0 0 0 1 0 0 1 0 0 0 1 0 0 1 0 0 1 0 1 0 0 1\n",
            " 0 1 0 1 1 1 1 0 1 0 0 0 0 0 0 1 0 1 1 1 0 1 0 0 1 0 0 1 0 1 0 0 0 1 0 1 1\n",
            " 1 0 0 1 0 0 0 1 0 0 1 1 1 1 0 0 0 0 1 1 0 0 1 0 1 1 1 0 1 0 0 1 0 0 0 0 0\n",
            " 0 1 1 0 1 1 1 1 0 1 0 1 0 1 0 0 0 1 1 1 1 1 1 0 1 0 0 1 0 1 1 1 0 0 0 0 0\n",
            " 1 0 0 1 0 1 1 1 0 0 0 0 0 1 0 1 0 1 0 1 1 0 0 1 0 1 0 0 0 1 1 0 1 0 0 1 0\n",
            " 1 1 0 1 1 1 0 1 1 1 0 0 1 1 1 1 0 1 1 1 0 1 0 1 1 1 0 1 1 1 0 0 1 1 1 1 1\n",
            " 1 1 1 1 0 1 1 1 1 0 1 1 0 0 1 0 1 1 1 0 0 0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1\n",
            " 1 0 0 1 1 0 1 1 0 0 0 1 1 0 0 0 1 0 1 1 0 0 1 1 0 1 1 1 0 0 1 0 0 1 1 1 0\n",
            " 0 1 0 1 0 0 1 0 0 1 1 1 0 0 0]\n",
            "probabilities: (977, 2) \n",
            " [1 1 1 0 1 0 0 0 1 1 0 0 1 0 1 0 0 1 1 1 0 1 0 1 0 0 0 0 1 0 0 1 0 1 1 0 1\n",
            " 1 1 0 1 1 0 0 0 1 0 1 0 0 1 1 1 0 1 1 1 1 0 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1\n",
            " 1 1 0 1 1 1 0 0 1 1 0 0 1 0 0 1 0 1 1 1 1 1 0 1 0 0 0 1 1 0 0 0 0 0 1 0 1\n",
            " 0 0 0 1 0 0 1 0 1 1 0 1 0 1 0 0 1 0 0 0 0 1 0 1 0 1 1 1 0 1 0 0 1 1 0 1 0\n",
            " 1 1 1 1 1 0 1 0 1 1 0 0 1 1 0 1 1 1 1 1 0 0 1 0 1 0 1 1 1 0 1 0 0 1 0 1 1\n",
            " 0 0 0 0 0 0 0 1 1 1 0 1 0 0 0 0 0 1 1 0 0 0 0 1 1 0 1 1 0 1 1 1 0 0 0 0 0\n",
            " 0 1 1 0 1 1 0 1 1 1 1 1 1 1 0 0 0 1 1 0 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 0\n",
            " 0 1 1 1 0 1 0 1 1 1 1 1 1 0 0 0 1 1 0 1 1 0 0 0 1 1 1 1 1 0 0 0 0 0 1 0 1\n",
            " 1 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 1 1 1 1 1 1 1 0 0 1 1 0 1 0 1 0 1 0 1 1 1\n",
            " 0 1 1 0 1 0 1 0 1 1 0 1 1 1 1 1 1 0 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1\n",
            " 0 0 0 1 1 1 1 0 1 1 0 1 0 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 0 1 1 0 1 1 0 1 0\n",
            " 1 1 1 1 1 0 0 0 0 0 1 1 0 0 1 0 0 1 0 0 0 1 1 0 1 1 0 0 0 1 0 1 1 1 0 0 1\n",
            " 1 1 0 1 0 1 0 1 0 1 1 1 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 1 1 0 1 0 1 0 0 1\n",
            " 0 0 1 0 0 0 0 0 1 1 0 0 0 1 1 1 0 1 0 0 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 0 0\n",
            " 1 0 1 0 1 1 1 1 1 1 1 0 1 1 0 0 0 0 1 0 1 1 0 1 0 1 1 1 1 0 0 1 1 1 1 0 1\n",
            " 1 0 1 1 1 1 1 1 0 0 0 0 0 1 1 1 1 1 1 1 1 0 1 0 0 0 1 0 0 0 1 0 1 0 1 1 1\n",
            " 0 1 1 1 1 1 1 0 0 1 0 0 1 0 0 1 0 1 0 1 1 0 1 1 0 1 0 1 1 0 1 1 1 1 1 1 0\n",
            " 1 0 1 0 0 1 1 1 1 1 0 1 0 1 1 0 1 1 0 0 1 0 1 1 1 0 1 1 1 1 1 0 1 1 1 0 1\n",
            " 1 0 1 0 1 1 0 1 0 1 1 1 0 0 1 0 0 0 1 0 0 1 0 0 0 1 0 0 1 0 0 1 0 1 0 0 1\n",
            " 0 1 0 1 1 1 1 0 1 0 0 0 0 0 0 1 0 1 1 1 0 1 0 0 1 0 0 1 0 1 0 0 0 1 0 1 1\n",
            " 1 0 0 1 0 0 0 1 0 0 1 1 1 1 0 0 0 0 1 1 0 0 1 0 1 1 1 0 1 0 0 1 0 0 0 0 0\n",
            " 0 1 1 0 1 1 1 1 0 1 0 1 0 1 0 0 0 1 1 1 1 1 1 0 1 0 0 1 0 1 1 1 0 0 0 0 0\n",
            " 1 0 0 1 0 1 1 1 0 0 0 0 0 1 0 1 0 1 0 1 1 0 0 1 0 1 0 0 0 1 1 0 1 0 0 1 0\n",
            " 1 1 0 1 1 1 0 1 1 1 0 0 1 1 1 1 0 1 1 1 0 1 0 1 1 1 0 1 1 1 0 0 1 1 1 1 1\n",
            " 1 1 1 1 0 1 1 1 1 0 1 1 0 0 1 0 1 1 1 0 0 0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1\n",
            " 1 0 0 1 1 0 1 1 0 0 0 1 1 0 0 0 1 0 1 1 0 0 1 1 0 1 1 1 0 0 1 0 0 1 1 1 0\n",
            " 0 1 0 1 0 0 1 0 0 1 1 1 0 0 0]\n",
            "trainset before adding uncertain samples (325, 10) (325,)\n",
            "trainset after adding uncertain samples (350, 10) (350,)\n",
            "updated train set: (350, 10) (350,) unique(labels): [179 171] [0 1]\n",
            "val set: (952, 10) (952,)\n",
            "\n",
            "Train set: (350, 10)\n",
            "Validation set: (952, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 14\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.095 s \n",
            "\n",
            "Accuracy rate is 78.110599 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86       321\n",
            "           1       0.59      0.51      0.55       113\n",
            "\n",
            "    accuracy                           0.78       434\n",
            "   macro avg       0.71      0.69      0.70       434\n",
            "weighted avg       0.77      0.78      0.78       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[281  40]\n",
            " [ 55  58]]\n",
            "--------------------------------\n",
            "val predicted: (952,) [1 1 1 0 0 0 1 1 0 0 1 0 1 0 1 1 1 0 1 0 1 0 0 0 1 0 0 1 0 1 1 0 1 1 1 0 1\n",
            " 1 0 0 0 1 0 1 0 0 1 1 1 0 1 1 1 1 0 1 1 1 1 0 1 0 1 0 0 1 1 1 1 1 1 1 0 1\n",
            " 1 1 0 0 1 1 0 0 1 0 1 0 1 1 1 1 1 0 1 0 0 0 1 1 0 0 0 0 0 1 0 1 0 0 0 1 0\n",
            " 0 1 0 1 1 0 1 0 1 0 0 1 0 0 0 1 0 1 0 0 1 1 0 1 0 0 1 1 0 1 0 1 1 1 1 1 0\n",
            " 1 0 1 1 0 0 1 1 0 1 1 1 1 1 0 0 1 0 1 0 1 1 1 0 1 0 0 1 0 1 1 0 0 0 0 0 0\n",
            " 0 1 1 1 0 1 0 0 0 0 0 1 1 0 0 0 0 1 1 0 1 1 0 1 0 1 0 0 0 0 0 0 1 1 0 1 1\n",
            " 0 1 1 1 1 1 1 1 0 0 0 1 1 0 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 0 0 1 1 1 0 1\n",
            " 1 1 1 1 1 1 0 0 1 1 0 1 1 0 0 0 1 1 1 1 1 0 0 0 0 1 0 1 1 0 1 0 0 1 0 0 0\n",
            " 0 1 0 0 0 0 0 1 1 1 1 1 1 1 1 0 1 1 0 1 0 1 0 1 0 1 1 1 0 1 1 0 1 0 1 0 1\n",
            " 1 0 1 1 1 1 1 1 0 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 0 0 1 1 1 1 0 1\n",
            " 1 0 1 0 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 0 1 1 0 1 1 0 1 0 1 1 1 1 1 0 0 0 0\n",
            " 0 1 1 0 0 1 0 0 1 0 0 0 1 1 0 1 1 0 0 0 1 1 1 1 0 0 1 1 1 1 0 1 0 1 0 1 1\n",
            " 1 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 1 1 0 1 0 1 0 0 1 0 0 1 0 0 0 0 0 1 1 0\n",
            " 0 0 1 1 1 0 1 0 0 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 0 0 1 0 1 0 1 1 1 1 1 1 1\n",
            " 0 1 1 0 0 0 1 0 1 1 0 1 0 1 1 1 1 0 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0 0 0\n",
            " 0 1 1 1 1 1 1 1 1 0 1 0 0 0 1 0 0 0 1 0 1 0 1 1 1 0 1 1 1 1 1 1 0 0 1 0 0\n",
            " 1 0 0 1 0 1 0 1 1 0 1 1 0 1 0 1 1 0 1 1 1 1 1 1 0 1 0 1 0 0 1 1 1 1 1 0 1\n",
            " 1 1 0 1 1 0 0 1 0 1 1 1 0 1 1 1 1 1 0 1 1 1 0 1 1 0 1 0 1 1 0 1 0 1 1 1 0\n",
            " 0 1 0 0 0 1 0 0 1 0 0 0 1 0 0 1 0 1 0 1 0 0 1 0 1 0 1 1 1 1 1 0 0 0 0 0 0\n",
            " 1 0 1 1 1 0 1 0 0 1 0 0 1 0 1 0 0 0 1 0 1 1 1 0 1 0 0 0 1 0 0 1 1 1 1 0 0\n",
            " 0 0 1 1 0 0 1 0 1 1 1 0 1 0 0 1 0 0 1 1 0 1 1 1 1 0 1 0 1 0 1 0 0 0 1 1 1\n",
            " 1 1 1 0 1 0 0 1 0 1 1 1 0 0 0 0 0 1 0 0 1 0 1 1 1 0 0 0 0 0 1 0 1 0 1 0 1\n",
            " 1 0 0 1 0 1 0 0 1 1 0 0 0 0 1 0 1 1 1 1 1 1 0 1 1 1 0 0 1 1 1 1 0 1 1 1 0\n",
            " 1 0 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 0 1 0 1 1 1 1 0 1 1 0 0 1 0 1 1 1 0 0 0\n",
            " 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1 1 0 1 1 0 1 1 0 0 0 1 1 0 0 0 1 0 1 1 0 0 1\n",
            " 1 0 1 1 1 0 1 0 0 1 0 1 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0]\n",
            "probabilities: (952, 2) \n",
            " [1 1 1 0 0 0 1 1 0 0 1 0 1 0 1 1 1 0 1 0 1 0 0 0 1 0 0 1 0 1 1 0 1 1 1 0 1\n",
            " 1 0 0 0 1 0 1 0 0 1 1 1 0 1 1 1 1 0 1 1 1 1 0 1 0 1 0 0 1 1 1 1 1 1 1 0 1\n",
            " 1 1 0 0 1 1 0 0 1 0 1 0 1 1 1 1 1 0 1 0 0 0 1 1 0 0 0 0 0 1 0 1 0 0 0 1 0\n",
            " 0 1 0 1 1 0 1 0 1 0 0 1 0 0 0 1 0 1 0 0 1 1 0 1 0 0 1 1 0 1 0 1 1 1 1 1 0\n",
            " 1 0 1 1 0 0 1 1 0 1 1 1 1 1 0 0 1 0 1 0 1 1 1 0 1 0 0 1 0 1 1 0 0 0 0 0 0\n",
            " 0 1 1 1 0 1 0 0 0 0 0 1 1 0 0 0 0 1 1 0 1 1 0 1 0 1 0 0 0 0 0 0 1 1 0 1 1\n",
            " 0 1 1 1 1 1 1 1 0 0 0 1 1 0 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 0 0 1 1 1 0 1\n",
            " 1 1 1 1 1 1 0 0 1 1 0 1 1 0 0 0 1 1 1 1 1 0 0 0 0 1 0 1 1 0 1 0 0 1 0 0 0\n",
            " 0 1 0 0 0 0 0 1 1 1 1 1 1 1 1 0 1 1 0 1 0 1 0 1 0 1 1 1 0 1 1 0 1 0 1 0 1\n",
            " 1 0 1 1 1 1 1 1 0 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 0 0 1 1 1 1 0 1\n",
            " 1 0 1 0 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 0 1 1 0 1 1 0 1 0 1 1 1 1 1 0 0 0 0\n",
            " 0 1 1 0 0 1 0 0 1 0 0 0 1 1 0 1 1 0 0 0 1 1 1 1 0 0 1 1 1 1 0 1 0 1 0 1 1\n",
            " 1 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 1 1 0 1 0 1 0 0 1 0 0 1 0 0 0 0 0 1 1 0\n",
            " 0 0 1 1 1 0 1 0 0 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 0 0 1 0 1 0 1 1 1 1 1 1 1\n",
            " 0 1 1 0 0 0 1 0 1 1 0 1 0 1 1 1 1 0 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0 0 0\n",
            " 0 1 1 1 1 1 1 1 1 0 1 0 0 0 1 0 0 0 1 0 1 0 1 1 1 0 1 1 1 1 1 1 0 0 1 0 0\n",
            " 1 0 0 1 0 1 0 1 1 0 1 1 0 1 0 1 1 0 1 1 1 1 1 1 0 1 0 1 0 0 1 1 1 1 1 0 1\n",
            " 1 1 0 1 1 0 0 1 0 1 1 1 0 1 1 1 1 1 0 1 1 1 0 1 1 0 1 0 1 1 0 1 0 1 1 1 0\n",
            " 0 1 0 0 0 1 0 0 1 0 0 0 1 0 0 1 0 1 0 1 0 0 1 0 1 0 1 1 1 1 1 0 0 0 0 0 0\n",
            " 1 0 1 1 1 0 1 0 0 1 0 0 1 0 1 0 0 0 1 0 1 1 1 0 1 0 0 0 1 0 0 1 1 1 1 0 0\n",
            " 0 0 1 1 0 0 1 0 1 1 1 0 1 0 0 1 0 0 1 1 0 1 1 1 1 0 1 0 1 0 1 0 0 0 1 1 1\n",
            " 1 1 1 0 1 0 0 1 0 1 1 1 0 0 0 0 0 1 0 0 1 0 1 1 1 0 0 0 0 0 1 0 1 0 1 0 1\n",
            " 1 0 0 1 0 1 0 0 1 1 0 0 0 0 1 0 1 1 1 1 1 1 0 1 1 1 0 0 1 1 1 1 0 1 1 1 0\n",
            " 1 0 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 0 1 0 1 1 1 1 0 1 1 0 0 1 0 1 1 1 0 0 0\n",
            " 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1 1 0 1 1 0 1 1 0 0 0 1 1 0 0 0 1 0 1 1 0 0 1\n",
            " 1 0 1 1 1 0 1 0 0 1 0 1 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0]\n",
            "trainset before adding uncertain samples (350, 10) (350,)\n",
            "trainset after adding uncertain samples (375, 10) (375,)\n",
            "updated train set: (375, 10) (375,) unique(labels): [189 186] [0 1]\n",
            "val set: (927, 10) (927,)\n",
            "\n",
            "Train set: (375, 10)\n",
            "Validation set: (927, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 15\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.061 s \n",
            "\n",
            "Accuracy rate is 78.341014 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.86      0.85       321\n",
            "           1       0.59      0.56      0.57       113\n",
            "\n",
            "    accuracy                           0.78       434\n",
            "   macro avg       0.72      0.71      0.71       434\n",
            "weighted avg       0.78      0.78      0.78       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[277  44]\n",
            " [ 50  63]]\n",
            "--------------------------------\n",
            "val predicted: (927,) [1 1 0 0 0 1 1 0 0 1 0 1 0 1 1 1 0 1 0 1 0 0 0 1 0 0 1 0 1 1 0 1 1 1 0 1 1\n",
            " 0 0 0 1 0 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 0 1 1 0 0 1 1 1 1 1 1 1 0 1 1 1 0\n",
            " 0 1 1 0 0 1 0 1 0 1 1 1 1 1 0 1 0 0 0 1 1 0 0 0 0 0 1 0 1 0 0 0 1 0 0 1 0\n",
            " 1 1 0 1 0 1 0 0 1 0 0 0 1 0 1 1 1 0 1 0 0 1 1 0 1 0 1 1 1 1 1 0 1 0 1 1 0\n",
            " 0 1 1 0 1 1 1 1 1 0 0 1 0 1 0 1 1 1 0 1 0 0 1 0 1 1 0 0 0 0 0 0 0 1 1 1 0\n",
            " 1 0 0 0 0 0 1 1 0 0 0 0 1 1 0 1 1 0 1 1 0 0 0 0 0 0 1 1 0 1 1 1 1 1 1 1 1\n",
            " 1 0 0 0 1 1 0 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 0 0 1 1 1 0 1 1 1 1 1 1 1 0\n",
            " 0 1 1 0 1 1 0 0 0 1 1 1 1 1 0 0 0 1 0 1 1 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 1\n",
            " 1 1 1 1 1 1 0 1 1 0 1 0 1 1 1 1 1 0 1 1 0 1 0 1 0 1 1 0 1 1 1 1 1 1 0 1 1\n",
            " 0 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 0 0 1 1 1 1 0 1 1 0 1 0 1 0 1 1 1 1 0\n",
            " 1 1 0 1 1 1 1 1 0 1 1 0 1 1 0 1 0 1 1 1 1 1 0 0 0 0 0 1 1 0 0 1 0 0 1 0 0\n",
            " 0 1 1 0 1 1 0 0 0 1 1 1 1 0 0 1 1 1 1 0 1 0 1 0 1 1 1 0 0 0 0 0 0 1 1 1 1\n",
            " 1 1 1 0 0 0 1 1 0 1 0 1 0 0 1 0 0 1 0 0 0 0 1 1 0 0 0 1 1 1 0 1 0 0 1 1 1\n",
            " 1 0 1 1 1 1 1 1 1 0 1 1 0 0 1 0 1 1 1 1 1 1 1 0 1 1 0 0 1 0 1 1 0 1 0 1 1\n",
            " 1 1 0 0 1 1 1 1 0 1 1 1 1 1 1 1 1 0 0 0 0 0 1 1 1 1 1 1 1 1 0 1 0 0 0 1 0\n",
            " 0 0 1 0 1 0 1 1 1 0 1 1 1 1 1 1 0 0 1 0 0 1 0 0 1 0 1 0 1 1 0 1 1 0 1 0 1\n",
            " 1 0 1 1 1 1 1 1 0 1 0 1 0 0 1 1 1 1 1 0 1 1 1 0 1 1 0 0 1 0 1 1 1 0 1 1 1\n",
            " 1 1 0 1 1 1 0 1 1 0 1 0 1 1 0 1 0 1 1 1 0 1 0 0 0 1 0 0 1 0 0 0 1 0 0 1 1\n",
            " 0 1 0 0 1 0 1 0 1 1 1 1 1 0 0 0 0 0 1 0 1 1 1 0 1 0 1 0 0 1 0 1 0 0 1 0 1\n",
            " 1 1 0 1 0 0 0 1 0 0 1 1 1 1 0 0 0 0 1 1 0 0 1 0 1 1 1 0 1 0 0 1 0 0 1 1 0\n",
            " 1 1 1 1 0 1 0 1 0 1 0 0 0 1 1 1 1 1 1 0 1 0 0 1 0 1 1 1 0 0 0 0 1 0 0 1 0\n",
            " 1 1 1 0 0 0 0 0 1 0 1 0 1 0 1 1 0 0 1 0 1 0 0 1 1 0 0 0 1 0 1 1 0 1 1 1 0\n",
            " 1 1 1 0 0 1 1 1 1 0 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 0 1 1 1 1\n",
            " 0 1 1 0 0 1 0 1 1 1 0 0 0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1 1 0 1 1 0 1 1 0 0\n",
            " 0 1 1 0 0 0 1 0 1 1 0 0 1 1 0 1 1 1 0 1 0 0 1 1 0 0 1 1 0 0 1 0 0 1 1 1 0\n",
            " 0 0]\n",
            "probabilities: (927, 2) \n",
            " [1 1 0 0 0 1 1 0 0 1 0 1 0 1 1 1 0 1 0 1 0 0 0 1 0 0 1 0 1 1 0 1 1 1 0 1 1\n",
            " 0 0 0 1 0 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 0 1 1 0 0 1 1 1 1 1 1 1 0 1 1 1 0\n",
            " 0 1 1 0 0 1 0 1 0 1 1 1 1 1 0 1 0 0 0 1 1 0 0 0 0 0 1 0 1 0 0 0 1 0 0 1 0\n",
            " 1 1 0 1 0 1 0 0 1 0 0 0 1 0 1 1 1 0 1 0 0 1 1 0 1 0 1 1 1 1 1 0 1 0 1 1 0\n",
            " 0 1 1 0 1 1 1 1 1 0 0 1 0 1 0 1 1 1 0 1 0 0 1 0 1 1 0 0 0 0 0 0 0 1 1 1 0\n",
            " 1 0 0 0 0 0 1 1 0 0 0 0 1 1 0 1 1 0 1 1 0 0 0 0 0 0 1 1 0 1 1 1 1 1 1 1 1\n",
            " 1 0 0 0 1 1 0 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 0 0 1 1 1 0 1 1 1 1 1 1 1 0\n",
            " 0 1 1 0 1 1 0 0 0 1 1 1 1 1 0 0 0 1 0 1 1 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 1\n",
            " 1 1 1 1 1 1 0 1 1 0 1 0 1 1 1 1 1 0 1 1 0 1 0 1 0 1 1 0 1 1 1 1 1 1 0 1 1\n",
            " 0 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 0 0 1 1 1 1 0 1 1 0 1 0 1 0 1 1 1 1 0\n",
            " 1 1 0 1 1 1 1 1 0 1 1 0 1 1 0 1 0 1 1 1 1 1 0 0 0 0 0 1 1 0 0 1 0 0 1 0 0\n",
            " 0 1 1 0 1 1 0 0 0 1 1 1 1 0 0 1 1 1 1 0 1 0 1 0 1 1 1 0 0 0 0 0 0 1 1 1 1\n",
            " 1 1 1 0 0 0 1 1 0 1 0 1 0 0 1 0 0 1 0 0 0 0 1 1 0 0 0 1 1 1 0 1 0 0 1 1 1\n",
            " 1 0 1 1 1 1 1 1 1 0 1 1 0 0 1 0 1 1 1 1 1 1 1 0 1 1 0 0 1 0 1 1 0 1 0 1 1\n",
            " 1 1 0 0 1 1 1 1 0 1 1 1 1 1 1 1 1 0 0 0 0 0 1 1 1 1 1 1 1 1 0 1 0 0 0 1 0\n",
            " 0 0 1 0 1 0 1 1 1 0 1 1 1 1 1 1 0 0 1 0 0 1 0 0 1 0 1 0 1 1 0 1 1 0 1 0 1\n",
            " 1 0 1 1 1 1 1 1 0 1 0 1 0 0 1 1 1 1 1 0 1 1 1 0 1 1 0 0 1 0 1 1 1 0 1 1 1\n",
            " 1 1 0 1 1 1 0 1 1 0 1 0 1 1 0 1 0 1 1 1 0 1 0 0 0 1 0 0 1 0 0 0 1 0 0 1 1\n",
            " 0 1 0 0 1 0 1 0 1 1 1 1 1 0 0 0 0 0 1 0 1 1 1 0 1 0 1 0 0 1 0 1 0 0 1 0 1\n",
            " 1 1 0 1 0 0 0 1 0 0 1 1 1 1 0 0 0 0 1 1 0 0 1 0 1 1 1 0 1 0 0 1 0 0 1 1 0\n",
            " 1 1 1 1 0 1 0 1 0 1 0 0 0 1 1 1 1 1 1 0 1 0 0 1 0 1 1 1 0 0 0 0 1 0 0 1 0\n",
            " 1 1 1 0 0 0 0 0 1 0 1 0 1 0 1 1 0 0 1 0 1 0 0 1 1 0 0 0 1 0 1 1 0 1 1 1 0\n",
            " 1 1 1 0 0 1 1 1 1 0 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 0 1 1 1 1\n",
            " 0 1 1 0 0 1 0 1 1 1 0 0 0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1 1 0 1 1 0 1 1 0 0\n",
            " 0 1 1 0 0 0 1 0 1 1 0 0 1 1 0 1 1 1 0 1 0 0 1 1 0 0 1 1 0 0 1 0 0 1 1 1 0\n",
            " 0 0]\n",
            "trainset before adding uncertain samples (375, 10) (375,)\n",
            "trainset after adding uncertain samples (400, 10) (400,)\n",
            "updated train set: (400, 10) (400,) unique(labels): [204 196] [0 1]\n",
            "val set: (902, 10) (902,)\n",
            "\n",
            "Train set: (400, 10)\n",
            "Validation set: (902, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 16\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.066 s \n",
            "\n",
            "Accuracy rate is 80.414747 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.89      0.87       321\n",
            "           1       0.64      0.57      0.60       113\n",
            "\n",
            "    accuracy                           0.80       434\n",
            "   macro avg       0.75      0.73      0.74       434\n",
            "weighted avg       0.80      0.80      0.80       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[285  36]\n",
            " [ 49  64]]\n",
            "--------------------------------\n",
            "val predicted: (902,) [1 1 0 0 1 1 0 0 1 0 1 0 1 1 1 0 1 0 1 0 0 1 0 0 1 0 1 1 0 1 1 1 0 1 1 0 0\n",
            " 0 1 0 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 0 1 1 0 0 1 1 1 1 1 1 1 0 0 1 1 0 0 1\n",
            " 1 0 0 1 1 0 1 1 1 1 1 0 0 0 0 1 1 0 0 0 0 0 1 0 1 0 0 0 1 0 0 1 0 1 1 1 0\n",
            " 1 0 0 1 0 0 0 1 1 1 1 0 1 0 1 1 1 0 1 1 1 1 1 0 1 0 1 1 0 0 1 1 0 1 1 1 1\n",
            " 1 0 0 1 0 1 0 1 1 1 0 1 0 0 1 0 1 1 0 0 0 0 0 0 0 1 1 1 0 1 0 0 0 0 0 1 1\n",
            " 0 0 0 0 1 1 0 1 1 0 1 1 0 0 0 0 0 1 1 0 1 1 1 1 1 1 1 1 0 0 0 0 1 1 0 1 0\n",
            " 1 1 1 1 1 0 1 1 0 1 1 1 1 1 0 0 1 1 1 0 1 1 1 1 1 1 1 0 0 1 1 0 1 1 0 0 0\n",
            " 1 1 1 1 1 0 0 0 0 0 1 1 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 1 1 1 1 1 1 0 1 0 1\n",
            " 0 1 1 1 1 1 0 1 1 0 1 0 1 0 1 1 0 1 1 1 1 1 1 0 1 1 0 0 1 1 1 1 1 1 1 1 1\n",
            " 1 1 0 1 1 1 0 0 0 1 1 1 1 0 1 1 0 1 0 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 0 1 1\n",
            " 0 1 1 0 1 0 1 1 1 1 1 0 0 0 0 0 1 1 0 0 1 0 0 1 0 0 1 1 0 1 1 0 0 1 1 1 1\n",
            " 0 0 1 1 0 1 0 1 0 1 0 1 1 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 1 1 0 1 0 1 0\n",
            " 0 1 0 0 1 0 0 0 0 1 1 0 0 1 1 1 0 1 0 0 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 0 0\n",
            " 1 0 1 1 1 1 1 1 1 0 1 1 0 0 1 0 1 1 0 1 0 1 1 1 1 0 0 1 1 1 1 0 1 1 1 1 1\n",
            " 1 1 1 0 0 0 0 0 1 1 1 1 1 1 1 1 0 1 0 0 0 1 0 0 0 1 0 1 0 1 1 1 0 1 1 1 1\n",
            " 1 1 0 0 1 0 0 1 0 0 1 0 1 0 1 1 0 1 1 0 1 0 1 1 0 1 1 1 1 1 1 0 1 0 1 0 1\n",
            " 1 1 1 1 0 1 1 1 1 1 0 1 0 1 1 0 1 1 1 1 1 0 1 1 1 0 1 1 0 1 0 1 1 1 0 1 1\n",
            " 1 0 1 0 0 0 1 0 0 1 0 0 0 1 0 0 1 1 0 1 0 0 1 0 1 0 1 1 1 1 1 0 0 0 0 1 0\n",
            " 1 1 1 0 1 0 1 0 0 1 0 1 0 0 1 0 1 1 1 0 1 0 0 0 1 0 0 1 1 1 1 0 0 0 0 1 1\n",
            " 0 0 1 0 1 1 1 0 1 0 0 1 0 0 1 1 0 1 1 1 1 0 1 0 1 0 1 0 0 0 1 1 1 1 1 1 0\n",
            " 1 0 0 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 1 1 0 0 0 0 0 1 0 1 0 1 0 1 1 0 1 0 1\n",
            " 1 1 1 0 0 0 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 1 0 1 1 1 0 1 0 1 1 1 1 1 1 0\n",
            " 0 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 0 0 1 0 1 1 1 0 0 0 1 0 1 0 1 1 1 0 1 0\n",
            " 1 1 1 1 1 1 0 1 1 0 1 1 0 0 0 1 1 0 0 0 1 0 1 1 0 0 1 1 1 1 1 0 1 0 0 1 1\n",
            " 0 0 1 1 0 0 1 0 1 1 1 0 0 0]\n",
            "probabilities: (902, 2) \n",
            " [1 1 0 0 1 1 0 0 1 0 1 0 1 1 1 0 1 0 1 0 0 1 0 0 1 0 1 1 0 1 1 1 0 1 1 0 0\n",
            " 0 1 0 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 0 1 1 0 0 1 1 1 1 1 1 1 0 0 1 1 0 0 1\n",
            " 1 0 0 1 1 0 1 1 1 1 1 0 0 0 0 1 1 0 0 0 0 0 1 0 1 0 0 0 1 0 0 1 0 1 1 1 0\n",
            " 1 0 0 1 0 0 0 1 1 1 1 0 1 0 1 1 1 0 1 1 1 1 1 0 1 0 1 1 0 0 1 1 0 1 1 1 1\n",
            " 1 0 0 1 0 1 0 1 1 1 0 1 0 0 1 0 1 1 0 0 0 0 0 0 0 1 1 1 0 1 0 0 0 0 0 1 1\n",
            " 0 0 0 0 1 1 0 1 1 0 1 1 0 0 0 0 0 1 1 0 1 1 1 1 1 1 1 1 0 0 0 0 1 1 0 1 0\n",
            " 1 1 1 1 1 0 1 1 0 1 1 1 1 1 0 0 1 1 1 0 1 1 1 1 1 1 1 0 0 1 1 0 1 1 0 0 0\n",
            " 1 1 1 1 1 0 0 0 0 0 1 1 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 1 1 1 1 1 1 0 1 0 1\n",
            " 0 1 1 1 1 1 0 1 1 0 1 0 1 0 1 1 0 1 1 1 1 1 1 0 1 1 0 0 1 1 1 1 1 1 1 1 1\n",
            " 1 1 0 1 1 1 0 0 0 1 1 1 1 0 1 1 0 1 0 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 0 1 1\n",
            " 0 1 1 0 1 0 1 1 1 1 1 0 0 0 0 0 1 1 0 0 1 0 0 1 0 0 1 1 0 1 1 0 0 1 1 1 1\n",
            " 0 0 1 1 0 1 0 1 0 1 0 1 1 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 1 1 0 1 0 1 0\n",
            " 0 1 0 0 1 0 0 0 0 1 1 0 0 1 1 1 0 1 0 0 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 0 0\n",
            " 1 0 1 1 1 1 1 1 1 0 1 1 0 0 1 0 1 1 0 1 0 1 1 1 1 0 0 1 1 1 1 0 1 1 1 1 1\n",
            " 1 1 1 0 0 0 0 0 1 1 1 1 1 1 1 1 0 1 0 0 0 1 0 0 0 1 0 1 0 1 1 1 0 1 1 1 1\n",
            " 1 1 0 0 1 0 0 1 0 0 1 0 1 0 1 1 0 1 1 0 1 0 1 1 0 1 1 1 1 1 1 0 1 0 1 0 1\n",
            " 1 1 1 1 0 1 1 1 1 1 0 1 0 1 1 0 1 1 1 1 1 0 1 1 1 0 1 1 0 1 0 1 1 1 0 1 1\n",
            " 1 0 1 0 0 0 1 0 0 1 0 0 0 1 0 0 1 1 0 1 0 0 1 0 1 0 1 1 1 1 1 0 0 0 0 1 0\n",
            " 1 1 1 0 1 0 1 0 0 1 0 1 0 0 1 0 1 1 1 0 1 0 0 0 1 0 0 1 1 1 1 0 0 0 0 1 1\n",
            " 0 0 1 0 1 1 1 0 1 0 0 1 0 0 1 1 0 1 1 1 1 0 1 0 1 0 1 0 0 0 1 1 1 1 1 1 0\n",
            " 1 0 0 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 1 1 0 0 0 0 0 1 0 1 0 1 0 1 1 0 1 0 1\n",
            " 1 1 1 0 0 0 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 1 0 1 1 1 0 1 0 1 1 1 1 1 1 0\n",
            " 0 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 0 0 1 0 1 1 1 0 0 0 1 0 1 0 1 1 1 0 1 0\n",
            " 1 1 1 1 1 1 0 1 1 0 1 1 0 0 0 1 1 0 0 0 1 0 1 1 0 0 1 1 1 1 1 0 1 0 0 1 1\n",
            " 0 0 1 1 0 0 1 0 1 1 1 0 0 0]\n",
            "trainset before adding uncertain samples (400, 10) (400,)\n",
            "trainset after adding uncertain samples (425, 10) (425,)\n",
            "updated train set: (425, 10) (425,) unique(labels): [216 209] [0 1]\n",
            "val set: (877, 10) (877,)\n",
            "\n",
            "Train set: (425, 10)\n",
            "Validation set: (877, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 17\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.056 s \n",
            "\n",
            "Accuracy rate is 80.645161 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.89      0.87       321\n",
            "           1       0.65      0.57      0.60       113\n",
            "\n",
            "    accuracy                           0.81       434\n",
            "   macro avg       0.75      0.73      0.74       434\n",
            "weighted avg       0.80      0.81      0.80       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[286  35]\n",
            " [ 49  64]]\n",
            "--------------------------------\n",
            "val predicted: (877,) [1 1 0 0 1 1 0 0 1 0 1 0 1 1 1 0 1 0 1 0 0 1 0 0 1 0 1 1 0 1 1 1 0 1 1 0 0\n",
            " 0 1 0 1 0 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 1 1 1 0 1 0 1 1 0 1 1 0 0\n",
            " 1 1 0 1 1 1 1 1 0 0 0 0 1 1 0 0 0 0 0 1 0 1 0 0 0 1 0 0 1 0 1 1 1 0 1 0 0\n",
            " 1 0 0 0 1 1 1 1 0 1 0 1 1 1 0 1 1 1 1 1 0 1 0 1 1 0 1 1 0 1 1 1 1 1 0 0 1\n",
            " 0 1 0 1 1 1 0 1 0 0 1 0 1 1 0 0 0 0 0 0 0 1 1 0 1 0 0 0 1 1 0 0 0 1 1 0 1\n",
            " 1 0 1 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 1 0 1 1 0 1 1\n",
            " 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0 1 1 0 1 1 0 0 0 1 1 1 1 1 0 0 0 0 1 1 1\n",
            " 0 0 1 0 0 0 0 1 0 0 0 0 0 1 1 1 1 1 1 0 1 0 1 0 1 1 1 1 1 0 1 1 0 1 0 1 0\n",
            " 1 1 0 1 1 1 1 1 1 0 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 0 0 1 1 1 1 0\n",
            " 1 1 0 1 0 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 0 1 1 0 1 1 0 1 0 1 1 1 1 1 0 0 0\n",
            " 0 0 1 1 0 0 1 0 0 1 0 0 1 1 0 1 1 0 0 1 1 1 1 0 0 1 1 1 0 1 0 1 0 1 1 0 0\n",
            " 0 0 0 0 1 1 1 1 1 1 1 0 0 0 1 1 0 1 0 1 0 0 1 0 0 1 0 0 0 0 1 1 0 0 1 1 1\n",
            " 0 1 0 0 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 0 0 1 0 1 1 1 1 1 1 1 0 1 1 0 0 1 0\n",
            " 1 1 0 1 0 1 1 1 1 0 0 1 1 1 1 0 1 1 1 1 1 1 1 1 0 0 0 0 0 1 1 1 1 1 1 1 1\n",
            " 0 1 0 0 0 1 0 0 0 1 0 1 0 1 1 1 0 1 1 1 1 1 1 0 0 1 0 0 1 0 0 1 0 1 0 1 1\n",
            " 0 1 1 0 1 0 1 1 0 1 1 1 1 1 1 0 1 0 1 0 1 1 1 1 1 0 1 1 1 1 1 0 1 0 1 1 0\n",
            " 1 0 1 1 1 0 1 1 1 0 1 1 0 1 0 1 1 1 0 1 1 1 0 1 0 0 0 1 0 0 1 0 0 1 0 0 1\n",
            " 1 0 1 0 0 1 0 1 0 1 1 1 1 1 0 0 0 1 1 1 1 0 1 0 0 0 1 0 1 0 0 1 0 1 1 1 0\n",
            " 1 0 0 0 1 0 0 1 1 1 1 0 0 0 1 1 0 0 1 0 1 1 1 0 1 0 0 1 0 0 1 1 0 1 1 1 1\n",
            " 0 1 0 1 0 0 0 0 1 1 1 1 1 1 0 1 0 0 1 1 1 1 0 0 0 1 0 0 1 1 1 1 0 0 0 0 0\n",
            " 1 0 1 0 1 0 1 1 0 1 0 1 0 1 1 0 0 0 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 1 0 1\n",
            " 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 0 0 1 1 1 1 0 1 1 0 0 1 0 1 1 1 0\n",
            " 0 0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1 1 0 1 1 0 1 1 0 0 0 1 1 0 0 0 1 0 1 1 0\n",
            " 0 1 1 1 1 1 0 1 0 0 1 1 0 0 1 1 0 0 1 0 1 1 1 0 0 0]\n",
            "probabilities: (877, 2) \n",
            " [1 1 0 0 1 1 0 0 1 0 1 0 1 1 1 0 1 0 1 0 0 1 0 0 1 0 1 1 0 1 1 1 0 1 1 0 0\n",
            " 0 1 0 1 0 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 1 1 1 0 1 0 1 1 0 1 1 0 0\n",
            " 1 1 0 1 1 1 1 1 0 0 0 0 1 1 0 0 0 0 0 1 0 1 0 0 0 1 0 0 1 0 1 1 1 0 1 0 0\n",
            " 1 0 0 0 1 1 1 1 0 1 0 1 1 1 0 1 1 1 1 1 0 1 0 1 1 0 1 1 0 1 1 1 1 1 0 0 1\n",
            " 0 1 0 1 1 1 0 1 0 0 1 0 1 1 0 0 0 0 0 0 0 1 1 0 1 0 0 0 1 1 0 0 0 1 1 0 1\n",
            " 1 0 1 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 1 0 1 1 0 1 1\n",
            " 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0 1 1 0 1 1 0 0 0 1 1 1 1 1 0 0 0 0 1 1 1\n",
            " 0 0 1 0 0 0 0 1 0 0 0 0 0 1 1 1 1 1 1 0 1 0 1 0 1 1 1 1 1 0 1 1 0 1 0 1 0\n",
            " 1 1 0 1 1 1 1 1 1 0 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 0 0 1 1 1 1 0\n",
            " 1 1 0 1 0 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 0 1 1 0 1 1 0 1 0 1 1 1 1 1 0 0 0\n",
            " 0 0 1 1 0 0 1 0 0 1 0 0 1 1 0 1 1 0 0 1 1 1 1 0 0 1 1 1 0 1 0 1 0 1 1 0 0\n",
            " 0 0 0 0 1 1 1 1 1 1 1 0 0 0 1 1 0 1 0 1 0 0 1 0 0 1 0 0 0 0 1 1 0 0 1 1 1\n",
            " 0 1 0 0 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 0 0 1 0 1 1 1 1 1 1 1 0 1 1 0 0 1 0\n",
            " 1 1 0 1 0 1 1 1 1 0 0 1 1 1 1 0 1 1 1 1 1 1 1 1 0 0 0 0 0 1 1 1 1 1 1 1 1\n",
            " 0 1 0 0 0 1 0 0 0 1 0 1 0 1 1 1 0 1 1 1 1 1 1 0 0 1 0 0 1 0 0 1 0 1 0 1 1\n",
            " 0 1 1 0 1 0 1 1 0 1 1 1 1 1 1 0 1 0 1 0 1 1 1 1 1 0 1 1 1 1 1 0 1 0 1 1 0\n",
            " 1 0 1 1 1 0 1 1 1 0 1 1 0 1 0 1 1 1 0 1 1 1 0 1 0 0 0 1 0 0 1 0 0 1 0 0 1\n",
            " 1 0 1 0 0 1 0 1 0 1 1 1 1 1 0 0 0 1 1 1 1 0 1 0 0 0 1 0 1 0 0 1 0 1 1 1 0\n",
            " 1 0 0 0 1 0 0 1 1 1 1 0 0 0 1 1 0 0 1 0 1 1 1 0 1 0 0 1 0 0 1 1 0 1 1 1 1\n",
            " 0 1 0 1 0 0 0 0 1 1 1 1 1 1 0 1 0 0 1 1 1 1 0 0 0 1 0 0 1 1 1 1 0 0 0 0 0\n",
            " 1 0 1 0 1 0 1 1 0 1 0 1 0 1 1 0 0 0 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 1 0 1\n",
            " 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 0 0 1 1 1 1 0 1 1 0 0 1 0 1 1 1 0\n",
            " 0 0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1 1 0 1 1 0 1 1 0 0 0 1 1 0 0 0 1 0 1 1 0\n",
            " 0 1 1 1 1 1 0 1 0 0 1 1 0 0 1 1 0 0 1 0 1 1 1 0 0 0]\n",
            "trainset before adding uncertain samples (425, 10) (425,)\n",
            "trainset after adding uncertain samples (450, 10) (450,)\n",
            "updated train set: (450, 10) (450,) unique(labels): [232 218] [0 1]\n",
            "val set: (852, 10) (852,)\n",
            "\n",
            "Train set: (450, 10)\n",
            "Validation set: (852, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 18\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.066 s \n",
            "\n",
            "Accuracy rate is 81.105991 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.89      0.88       321\n",
            "           1       0.66      0.58      0.61       113\n",
            "\n",
            "    accuracy                           0.81       434\n",
            "   macro avg       0.76      0.73      0.74       434\n",
            "weighted avg       0.80      0.81      0.81       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[287  34]\n",
            " [ 48  65]]\n",
            "--------------------------------\n",
            "val predicted: (852,) [1 1 0 0 1 1 0 0 1 0 1 0 1 1 1 0 1 0 1 0 0 1 0 0 1 0 1 1 0 1 1 1 0 1 1 0 0\n",
            " 0 1 0 1 0 1 1 1 0 1 1 1 1 1 1 1 0 1 1 0 0 1 1 1 1 1 1 0 1 1 0 1 1 0 0 1 1\n",
            " 0 1 1 1 1 1 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 1 0 0 1 0 1 1 1 0 1 0 0 1 0 0 0\n",
            " 1 1 1 1 0 1 0 1 1 1 0 1 1 1 1 1 0 1 0 1 1 1 1 0 1 1 1 1 0 0 1 0 1 0 1 1 1\n",
            " 0 1 0 0 1 0 1 1 0 0 0 0 0 0 0 1 1 0 1 0 0 0 1 0 0 0 0 1 1 0 1 1 0 1 1 0 0\n",
            " 0 0 0 1 1 1 1 1 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 0 1 1\n",
            " 1 0 1 1 1 1 1 1 1 0 0 1 1 0 1 1 0 0 0 1 1 1 1 1 0 0 0 0 1 1 1 0 0 1 0 0 0\n",
            " 0 1 0 0 0 0 0 1 1 1 1 1 1 0 1 0 1 0 1 1 1 1 1 0 1 1 0 1 0 1 0 1 1 0 1 1 1\n",
            " 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 0 0 1 1 1 1 1 1 0 1 0 1 0 1\n",
            " 1 1 1 0 1 1 0 1 1 1 1 1 0 1 1 0 1 1 0 1 0 1 1 1 1 1 0 0 0 0 0 1 1 0 0 1 0\n",
            " 0 1 0 0 1 1 0 1 1 0 0 1 1 1 1 0 0 1 1 1 0 1 0 1 0 1 1 0 0 0 0 0 0 1 1 1 1\n",
            " 1 1 1 0 0 0 1 1 0 1 0 1 0 0 1 0 0 1 0 0 0 0 1 1 0 1 1 0 1 0 0 1 1 1 1 0 1\n",
            " 1 1 1 1 1 1 0 1 1 0 0 1 0 1 1 1 1 1 1 1 0 1 1 0 1 0 1 1 0 1 0 1 1 1 1 0 1\n",
            " 1 1 1 0 1 1 1 1 1 1 1 1 0 0 0 0 0 1 1 1 1 1 1 1 1 0 1 0 0 0 1 0 0 0 1 0 1\n",
            " 0 1 1 1 0 1 1 1 1 1 0 1 0 0 1 0 0 1 1 0 1 1 0 1 1 0 1 0 1 1 0 1 1 1 1 1 1\n",
            " 0 1 0 1 0 1 1 1 1 1 0 1 1 1 1 1 0 1 0 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 1 1\n",
            " 1 0 1 1 1 0 1 0 0 1 0 0 1 0 1 0 0 1 1 0 1 0 0 1 0 1 0 1 1 1 1 1 0 0 0 1 1\n",
            " 1 1 0 1 0 0 0 1 0 1 0 0 1 0 1 1 1 0 1 0 0 0 1 0 0 1 1 1 1 0 0 0 1 1 0 0 1\n",
            " 0 1 1 1 0 1 0 0 1 0 0 1 1 1 1 1 1 0 1 0 1 0 0 0 1 1 1 1 1 1 0 1 0 0 1 1 1\n",
            " 1 0 0 0 1 0 0 1 1 1 1 0 0 0 0 0 1 0 1 0 1 0 1 1 0 1 0 1 0 1 1 0 0 1 0 1 1\n",
            " 1 1 1 0 1 1 1 0 0 1 1 1 1 0 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 0 1\n",
            " 1 1 1 0 1 0 0 0 1 0 1 1 1 0 0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1 1 0 1 1 0 1 1\n",
            " 0 0 0 1 1 0 0 0 1 0 1 1 0 0 1 1 1 1 1 0 1 0 0 1 1 0 1 1 0 0 1 0 1 1 1 0 0\n",
            " 0]\n",
            "probabilities: (852, 2) \n",
            " [1 1 0 0 1 1 0 0 1 0 1 0 1 1 1 0 1 0 1 0 0 1 0 0 1 0 1 1 0 1 1 1 0 1 1 0 0\n",
            " 0 1 0 1 0 1 1 1 0 1 1 1 1 1 1 1 0 1 1 0 0 1 1 1 1 1 1 0 1 1 0 1 1 0 0 1 1\n",
            " 0 1 1 1 1 1 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 1 0 0 1 0 1 1 1 0 1 0 0 1 0 0 0\n",
            " 1 1 1 1 0 1 0 1 1 1 0 1 1 1 1 1 0 1 0 1 1 1 1 0 1 1 1 1 0 0 1 0 1 0 1 1 1\n",
            " 0 1 0 0 1 0 1 1 0 0 0 0 0 0 0 1 1 0 1 0 0 0 1 0 0 0 0 1 1 0 1 1 0 1 1 0 0\n",
            " 0 0 0 1 1 1 1 1 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 0 1 1\n",
            " 1 0 1 1 1 1 1 1 1 0 0 1 1 0 1 1 0 0 0 1 1 1 1 1 0 0 0 0 1 1 1 0 0 1 0 0 0\n",
            " 0 1 0 0 0 0 0 1 1 1 1 1 1 0 1 0 1 0 1 1 1 1 1 0 1 1 0 1 0 1 0 1 1 0 1 1 1\n",
            " 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 0 0 1 1 1 1 1 1 0 1 0 1 0 1\n",
            " 1 1 1 0 1 1 0 1 1 1 1 1 0 1 1 0 1 1 0 1 0 1 1 1 1 1 0 0 0 0 0 1 1 0 0 1 0\n",
            " 0 1 0 0 1 1 0 1 1 0 0 1 1 1 1 0 0 1 1 1 0 1 0 1 0 1 1 0 0 0 0 0 0 1 1 1 1\n",
            " 1 1 1 0 0 0 1 1 0 1 0 1 0 0 1 0 0 1 0 0 0 0 1 1 0 1 1 0 1 0 0 1 1 1 1 0 1\n",
            " 1 1 1 1 1 1 0 1 1 0 0 1 0 1 1 1 1 1 1 1 0 1 1 0 1 0 1 1 0 1 0 1 1 1 1 0 1\n",
            " 1 1 1 0 1 1 1 1 1 1 1 1 0 0 0 0 0 1 1 1 1 1 1 1 1 0 1 0 0 0 1 0 0 0 1 0 1\n",
            " 0 1 1 1 0 1 1 1 1 1 0 1 0 0 1 0 0 1 1 0 1 1 0 1 1 0 1 0 1 1 0 1 1 1 1 1 1\n",
            " 0 1 0 1 0 1 1 1 1 1 0 1 1 1 1 1 0 1 0 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 1 1\n",
            " 1 0 1 1 1 0 1 0 0 1 0 0 1 0 1 0 0 1 1 0 1 0 0 1 0 1 0 1 1 1 1 1 0 0 0 1 1\n",
            " 1 1 0 1 0 0 0 1 0 1 0 0 1 0 1 1 1 0 1 0 0 0 1 0 0 1 1 1 1 0 0 0 1 1 0 0 1\n",
            " 0 1 1 1 0 1 0 0 1 0 0 1 1 1 1 1 1 0 1 0 1 0 0 0 1 1 1 1 1 1 0 1 0 0 1 1 1\n",
            " 1 0 0 0 1 0 0 1 1 1 1 0 0 0 0 0 1 0 1 0 1 0 1 1 0 1 0 1 0 1 1 0 0 1 0 1 1\n",
            " 1 1 1 0 1 1 1 0 0 1 1 1 1 0 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 0 1\n",
            " 1 1 1 0 1 0 0 0 1 0 1 1 1 0 0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1 1 0 1 1 0 1 1\n",
            " 0 0 0 1 1 0 0 0 1 0 1 1 0 0 1 1 1 1 1 0 1 0 0 1 1 0 1 1 0 0 1 0 1 1 1 0 0\n",
            " 0]\n",
            "trainset before adding uncertain samples (450, 10) (450,)\n",
            "trainset after adding uncertain samples (475, 10) (475,)\n",
            "updated train set: (475, 10) (475,) unique(labels): [246 229] [0 1]\n",
            "val set: (827, 10) (827,)\n",
            "\n",
            "Train set: (475, 10)\n",
            "Validation set: (827, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 19\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.056 s \n",
            "\n",
            "Accuracy rate is 80.184332 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.89      0.87       321\n",
            "           1       0.64      0.56      0.59       113\n",
            "\n",
            "    accuracy                           0.80       434\n",
            "   macro avg       0.74      0.72      0.73       434\n",
            "weighted avg       0.79      0.80      0.80       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[285  36]\n",
            " [ 50  63]]\n",
            "--------------------------------\n",
            "val predicted: (827,) [1 1 0 0 1 1 0 0 1 0 0 0 1 1 1 0 1 0 1 0 0 1 0 0 1 0 1 1 0 1 1 1 0 1 1 0 0\n",
            " 0 1 0 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 1 1 1 1 0 1 1 0 1 1 0 0 1 1 0\n",
            " 1 1 1 1 1 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 1 0 0 1 0 1 1 1 0 1 0 0 1 0 0 0 1\n",
            " 1 1 1 0 1 0 1 1 1 0 1 1 1 1 1 0 1 0 1 1 1 1 0 1 1 1 1 0 0 1 0 1 0 1 1 1 0\n",
            " 1 0 0 1 0 1 1 0 0 0 0 0 0 0 1 1 0 1 0 0 0 1 0 0 0 1 1 0 1 1 0 1 0 0 0 0 1\n",
            " 1 1 1 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1\n",
            " 1 1 1 0 0 1 1 0 1 1 0 0 0 1 1 1 1 1 0 0 0 0 1 1 1 0 0 1 0 0 0 0 1 0 0 0 0\n",
            " 0 1 1 1 1 1 1 0 1 0 1 0 1 1 1 1 1 0 1 1 0 1 0 1 0 1 1 0 1 1 1 1 1 1 0 1 1\n",
            " 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 0 0 1 1 1 1 1 1 0 1 0 1 0 1 1 1 1 0 1 1\n",
            " 0 1 1 1 1 1 0 1 1 0 1 1 0 1 0 1 1 1 1 1 0 0 0 0 1 1 0 1 0 0 1 0 0 1 1 1 0\n",
            " 0 1 1 1 1 0 1 1 1 0 1 0 1 0 1 1 0 0 0 0 0 1 1 1 1 1 1 0 0 0 1 1 0 1 0 1 0\n",
            " 0 0 0 1 0 0 0 0 1 1 0 1 1 0 1 0 0 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 0 0 1 0 1\n",
            " 1 1 1 1 1 1 0 1 1 0 1 0 1 1 0 1 0 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 0 0 0\n",
            " 0 0 1 1 1 1 1 1 1 1 1 0 0 0 1 0 1 0 1 0 1 1 1 0 1 1 1 1 1 0 1 0 0 1 0 0 1\n",
            " 1 0 1 1 0 1 1 0 1 0 1 1 0 1 1 1 1 1 1 0 1 0 1 0 1 1 1 1 1 0 1 1 1 1 1 0 1\n",
            " 0 1 1 1 1 1 1 0 1 1 1 1 1 0 1 0 1 1 1 0 1 1 1 1 0 0 1 0 0 1 0 1 0 0 1 1 0\n",
            " 1 0 0 1 0 1 0 1 1 1 1 1 0 0 0 1 1 1 1 0 1 0 0 0 1 0 1 0 0 1 0 1 1 1 0 1 0\n",
            " 0 0 1 0 0 1 1 1 1 0 0 0 1 1 0 0 1 0 1 1 1 0 1 0 0 1 0 0 1 1 1 1 1 1 0 1 0\n",
            " 1 0 0 0 1 1 1 1 1 1 0 1 0 0 1 1 1 1 0 0 0 1 0 0 1 1 1 1 0 0 0 0 0 1 0 1 0\n",
            " 1 0 1 1 0 1 0 1 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1 0 0 1 1 1 1 0 1 1 1 0 1 0 1\n",
            " 1 1 1 1 1 0 0 1 1 1 1 1 1 1 0 1 1 1 1 0 1 0 0 1 0 1 1 1 0 0 1 0 1 0 1 1 1\n",
            " 0 1 0 1 1 1 1 1 1 0 1 1 0 1 1 0 0 0 1 1 0 0 1 1 1 0 1 1 1 1 1 0 1 0 0 1 1\n",
            " 0 1 1 0 0 1 0 1 1 1 0 0 0]\n",
            "probabilities: (827, 2) \n",
            " [1 1 0 0 1 1 0 0 1 0 0 0 1 1 1 0 1 0 1 0 0 1 0 0 1 0 1 1 0 1 1 1 0 1 1 0 0\n",
            " 0 1 0 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 1 1 1 1 0 1 1 0 1 1 0 0 1 1 0\n",
            " 1 1 1 1 1 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 1 0 0 1 0 1 1 1 0 1 0 0 1 0 0 0 1\n",
            " 1 1 1 0 1 0 1 1 1 0 1 1 1 1 1 0 1 0 1 1 1 1 0 1 1 1 1 0 0 1 0 1 0 1 1 1 0\n",
            " 1 0 0 1 0 1 1 0 0 0 0 0 0 0 1 1 0 1 0 0 0 1 0 0 0 1 1 0 1 1 0 1 0 0 0 0 1\n",
            " 1 1 1 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1\n",
            " 1 1 1 0 0 1 1 0 1 1 0 0 0 1 1 1 1 1 0 0 0 0 1 1 1 0 0 1 0 0 0 0 1 0 0 0 0\n",
            " 0 1 1 1 1 1 1 0 1 0 1 0 1 1 1 1 1 0 1 1 0 1 0 1 0 1 1 0 1 1 1 1 1 1 0 1 1\n",
            " 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 0 0 1 1 1 1 1 1 0 1 0 1 0 1 1 1 1 0 1 1\n",
            " 0 1 1 1 1 1 0 1 1 0 1 1 0 1 0 1 1 1 1 1 0 0 0 0 1 1 0 1 0 0 1 0 0 1 1 1 0\n",
            " 0 1 1 1 1 0 1 1 1 0 1 0 1 0 1 1 0 0 0 0 0 1 1 1 1 1 1 0 0 0 1 1 0 1 0 1 0\n",
            " 0 0 0 1 0 0 0 0 1 1 0 1 1 0 1 0 0 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 0 0 1 0 1\n",
            " 1 1 1 1 1 1 0 1 1 0 1 0 1 1 0 1 0 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 0 0 0\n",
            " 0 0 1 1 1 1 1 1 1 1 1 0 0 0 1 0 1 0 1 0 1 1 1 0 1 1 1 1 1 0 1 0 0 1 0 0 1\n",
            " 1 0 1 1 0 1 1 0 1 0 1 1 0 1 1 1 1 1 1 0 1 0 1 0 1 1 1 1 1 0 1 1 1 1 1 0 1\n",
            " 0 1 1 1 1 1 1 0 1 1 1 1 1 0 1 0 1 1 1 0 1 1 1 1 0 0 1 0 0 1 0 1 0 0 1 1 0\n",
            " 1 0 0 1 0 1 0 1 1 1 1 1 0 0 0 1 1 1 1 0 1 0 0 0 1 0 1 0 0 1 0 1 1 1 0 1 0\n",
            " 0 0 1 0 0 1 1 1 1 0 0 0 1 1 0 0 1 0 1 1 1 0 1 0 0 1 0 0 1 1 1 1 1 1 0 1 0\n",
            " 1 0 0 0 1 1 1 1 1 1 0 1 0 0 1 1 1 1 0 0 0 1 0 0 1 1 1 1 0 0 0 0 0 1 0 1 0\n",
            " 1 0 1 1 0 1 0 1 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1 0 0 1 1 1 1 0 1 1 1 0 1 0 1\n",
            " 1 1 1 1 1 0 0 1 1 1 1 1 1 1 0 1 1 1 1 0 1 0 0 1 0 1 1 1 0 0 1 0 1 0 1 1 1\n",
            " 0 1 0 1 1 1 1 1 1 0 1 1 0 1 1 0 0 0 1 1 0 0 1 1 1 0 1 1 1 1 1 0 1 0 0 1 1\n",
            " 0 1 1 0 0 1 0 1 1 1 0 0 0]\n",
            "trainset before adding uncertain samples (475, 10) (475,)\n",
            "trainset after adding uncertain samples (500, 10) (500,)\n",
            "updated train set: (500, 10) (500,) unique(labels): [263 237] [0 1]\n",
            "val set: (802, 10) (802,)\n",
            "\n",
            "Train set: (500, 10)\n",
            "Validation set: (802, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 20\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.065 s \n",
            "\n",
            "Accuracy rate is 79.723502 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.88      0.87       321\n",
            "           1       0.62      0.56      0.59       113\n",
            "\n",
            "    accuracy                           0.80       434\n",
            "   macro avg       0.74      0.72      0.73       434\n",
            "weighted avg       0.79      0.80      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[283  38]\n",
            " [ 50  63]]\n",
            "--------------------------------\n",
            "final active learning accuracies [44.00921658986175, 77.88018433179722, 72.81105990783409, 80.4147465437788, 78.80184331797236, 76.72811059907833, 79.26267281105991, 80.18433179723502, 78.80184331797236, 79.03225806451613, 79.72350230414746, 79.49308755760369, 79.26267281105991, 78.11059907834101, 78.3410138248848, 80.4147465437788, 80.64516129032258, 81.10599078341014, 80.18433179723502, 79.72350230414746]\n",
            "saved /Users/wenxuanhuang/Documents/Repo/ML-for-COVID-19-dataset/Results/Active-learning-experiment-29.pkl /Users/wenxuanhuang/Documents/Repo/ML-for-COVID-19-dataset ['Decision_tree.ipynb', 'dec_git.png', 'Logit_default_f10.pdf', 'Logistic.ipynb', 'SVC.ipynb', 'RF_f5e50_featureimp.pdf', 'log_al.png', 'dec_git.pdf', '.DS_Store', 'log_git.png', 'svm_git.png', 'Logistic_Scikit.ipynb', 'knn_git.pdf', 'knn_git.png', 'rf_al.png', 'Best classifier_RF_f5e50.pdf', 'KNN.ipynb', 'GBDC.ipynb', 'rf_git.png', 'README.md', 'all_training.csv', 'Results', 'svm_al.png', 'Log_ROC.png', 'Logit_default_f7(p_removal).pdf', 'Active_learning.ipynb', 'Random_forest.ipynb', 'Model_select.ipynb', 'gdbc_git.png', '.git', '.vscode', 'Untitled', 'RF_f5e50_modelselect.pdf', 'Logit_default_f8(std_removal).pdf']\n",
            "\n",
            "---------------------------- FINISHED ---------------------------\n",
            "\n",
            "Count = 30, using model = KnnModel, selection_function = MarginSamplingSelection, k = 10, iteration = 0.\n",
            "\n",
            "initial random chosen samples (10,)\n",
            "initial train set: (10, 10) (10,) unique(labels): [4 6] [0 1]\n",
            "Val set: (1292, 10) (1292,) (10,)\n",
            "\n",
            "Train set: (10, 10)\n",
            "Validation set: (1292, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.076 s \n",
            "\n",
            "Accuracy rate is 26.036866 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       321\n",
            "           1       0.26      1.00      0.41       113\n",
            "\n",
            "    accuracy                           0.26       434\n",
            "   macro avg       0.13      0.50      0.21       434\n",
            "weighted avg       0.07      0.26      0.11       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[  0 321]\n",
            " [  0 113]]\n",
            "--------------------------------\n",
            "val predicted: (1292,) [1 1 1 ... 1 1 1]\n",
            "probabilities: (1292, 2) \n",
            " [1 1 1 ... 1 1 1]\n",
            "trainset before adding uncertain samples (10, 10) (10,)\n",
            "trainset after adding uncertain samples (20, 10) (20,)\n",
            "updated train set: (20, 10) (20,) unique(labels): [ 9 11] [0 1]\n",
            "val set: (1282, 10) (1282,)\n",
            "\n",
            "Train set: (20, 10)\n",
            "Validation set: (1282, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "/Users/wenxuanhuang/Library/Python/3.8/lib/python/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/Users/wenxuanhuang/Library/Python/3.8/lib/python/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/Users/wenxuanhuang/Library/Python/3.8/lib/python/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.076 s \n",
            "\n",
            "Accuracy rate is 71.428571 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.77      0.80       321\n",
            "           1       0.46      0.55      0.50       113\n",
            "\n",
            "    accuracy                           0.71       434\n",
            "   macro avg       0.64      0.66      0.65       434\n",
            "weighted avg       0.73      0.71      0.72       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[248  73]\n",
            " [ 51  62]]\n",
            "--------------------------------\n",
            "val predicted: (1282,) [1 1 1 ... 0 0 0]\n",
            "probabilities: (1282, 2) \n",
            " [1 1 1 ... 0 0 0]\n",
            "trainset before adding uncertain samples (20, 10) (20,)\n",
            "trainset after adding uncertain samples (30, 10) (30,)\n",
            "updated train set: (30, 10) (30,) unique(labels): [19 11] [0 1]\n",
            "val set: (1272, 10) (1272,)\n",
            "\n",
            "Train set: (30, 10)\n",
            "Validation set: (1272, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 3\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.085 s \n",
            "\n",
            "Accuracy rate is 76.036866 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.98      0.86       321\n",
            "           1       0.74      0.12      0.21       113\n",
            "\n",
            "    accuracy                           0.76       434\n",
            "   macro avg       0.75      0.55      0.54       434\n",
            "weighted avg       0.76      0.76      0.69       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[316   5]\n",
            " [ 99  14]]\n",
            "--------------------------------\n",
            "val predicted: (1272,) [0 0 0 ... 0 0 0]\n",
            "probabilities: (1272, 2) \n",
            " [0 0 0 ... 0 0 0]\n",
            "trainset before adding uncertain samples (30, 10) (30,)\n",
            "trainset after adding uncertain samples (40, 10) (40,)\n",
            "updated train set: (40, 10) (40,) unique(labels): [21 19] [0 1]\n",
            "val set: (1262, 10) (1262,)\n",
            "\n",
            "Train set: (40, 10)\n",
            "Validation set: (1262, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 4\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.072 s \n",
            "\n",
            "Accuracy rate is 78.341014 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.93      0.86       321\n",
            "           1       0.66      0.35      0.46       113\n",
            "\n",
            "    accuracy                           0.78       434\n",
            "   macro avg       0.73      0.64      0.66       434\n",
            "weighted avg       0.77      0.78      0.76       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[300  21]\n",
            " [ 73  40]]\n",
            "--------------------------------\n",
            "val predicted: (1262,) [1 1 0 ... 0 0 0]\n",
            "probabilities: (1262, 2) \n",
            " [1 1 0 ... 0 0 0]\n",
            "trainset before adding uncertain samples (40, 10) (40,)\n",
            "trainset after adding uncertain samples (50, 10) (50,)\n",
            "updated train set: (50, 10) (50,) unique(labels): [25 25] [0 1]\n",
            "val set: (1252, 10) (1252,)\n",
            "\n",
            "Train set: (50, 10)\n",
            "Validation set: (1252, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 5\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.070 s \n",
            "\n",
            "Accuracy rate is 78.571429 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.92      0.86       321\n",
            "           1       0.64      0.40      0.49       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.73      0.66      0.68       434\n",
            "weighted avg       0.77      0.79      0.77       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[296  25]\n",
            " [ 68  45]]\n",
            "--------------------------------\n",
            "val predicted: (1252,) [1 0 0 ... 0 0 0]\n",
            "probabilities: (1252, 2) \n",
            " [1 0 0 ... 0 0 0]\n",
            "trainset before adding uncertain samples (50, 10) (50,)\n",
            "trainset after adding uncertain samples (60, 10) (60,)\n",
            "updated train set: (60, 10) (60,) unique(labels): [25 35] [0 1]\n",
            "val set: (1242, 10) (1242,)\n",
            "\n",
            "Train set: (60, 10)\n",
            "Validation set: (1242, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 6\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.073 s \n",
            "\n",
            "Accuracy rate is 77.649770 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.87      0.85       321\n",
            "           1       0.58      0.52      0.55       113\n",
            "\n",
            "    accuracy                           0.78       434\n",
            "   macro avg       0.71      0.69      0.70       434\n",
            "weighted avg       0.77      0.78      0.77       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[278  43]\n",
            " [ 54  59]]\n",
            "--------------------------------\n",
            "val predicted: (1242,) [1 0 0 ... 0 0 0]\n",
            "probabilities: (1242, 2) \n",
            " [1 0 0 ... 0 0 0]\n",
            "trainset before adding uncertain samples (60, 10) (60,)\n",
            "trainset after adding uncertain samples (70, 10) (70,)\n",
            "updated train set: (70, 10) (70,) unique(labels): [31 39] [0 1]\n",
            "val set: (1232, 10) (1232,)\n",
            "\n",
            "Train set: (70, 10)\n",
            "Validation set: (1232, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 7\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.101 s \n",
            "\n",
            "Accuracy rate is 76.728111 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.87      0.85       321\n",
            "           1       0.56      0.49      0.52       113\n",
            "\n",
            "    accuracy                           0.77       434\n",
            "   macro avg       0.69      0.68      0.68       434\n",
            "weighted avg       0.76      0.77      0.76       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[278  43]\n",
            " [ 58  55]]\n",
            "--------------------------------\n",
            "val predicted: (1232,) [1 0 0 ... 0 0 0]\n",
            "probabilities: (1232, 2) \n",
            " [1 0 0 ... 0 0 0]\n",
            "trainset before adding uncertain samples (70, 10) (70,)\n",
            "trainset after adding uncertain samples (80, 10) (80,)\n",
            "updated train set: (80, 10) (80,) unique(labels): [37 43] [0 1]\n",
            "val set: (1222, 10) (1222,)\n",
            "\n",
            "Train set: (80, 10)\n",
            "Validation set: (1222, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 8\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.063 s \n",
            "\n",
            "Accuracy rate is 77.419355 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.88      0.85       321\n",
            "           1       0.58      0.49      0.53       113\n",
            "\n",
            "    accuracy                           0.77       434\n",
            "   macro avg       0.70      0.68      0.69       434\n",
            "weighted avg       0.76      0.77      0.77       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[281  40]\n",
            " [ 58  55]]\n",
            "--------------------------------\n",
            "val predicted: (1222,) [1 0 0 ... 0 0 0]\n",
            "probabilities: (1222, 2) \n",
            " [1 0 0 ... 0 0 0]\n",
            "trainset before adding uncertain samples (80, 10) (80,)\n",
            "trainset after adding uncertain samples (90, 10) (90,)\n",
            "updated train set: (90, 10) (90,) unique(labels): [43 47] [0 1]\n",
            "val set: (1212, 10) (1212,)\n",
            "\n",
            "Train set: (90, 10)\n",
            "Validation set: (1212, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 9\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.072 s \n",
            "\n",
            "Accuracy rate is 79.032258 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.90      0.86       321\n",
            "           1       0.63      0.47      0.54       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.73      0.69      0.70       434\n",
            "weighted avg       0.78      0.79      0.78       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[290  31]\n",
            " [ 60  53]]\n",
            "--------------------------------\n",
            "val predicted: (1212,) [1 0 0 ... 0 0 0]\n",
            "probabilities: (1212, 2) \n",
            " [1 0 0 ... 0 0 0]\n",
            "trainset before adding uncertain samples (90, 10) (90,)\n",
            "trainset after adding uncertain samples (100, 10) (100,)\n",
            "updated train set: (100, 10) (100,) unique(labels): [48 52] [0 1]\n",
            "val set: (1202, 10) (1202,)\n",
            "\n",
            "Train set: (100, 10)\n",
            "Validation set: (1202, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 10\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.074 s \n",
            "\n",
            "Accuracy rate is 78.110599 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.88      0.86       321\n",
            "           1       0.60      0.49      0.54       113\n",
            "\n",
            "    accuracy                           0.78       434\n",
            "   macro avg       0.71      0.69      0.70       434\n",
            "weighted avg       0.77      0.78      0.77       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[284  37]\n",
            " [ 58  55]]\n",
            "--------------------------------\n",
            "val predicted: (1202,) [1 0 0 ... 0 0 0]\n",
            "probabilities: (1202, 2) \n",
            " [1 0 0 ... 0 0 0]\n",
            "trainset before adding uncertain samples (100, 10) (100,)\n",
            "trainset after adding uncertain samples (110, 10) (110,)\n",
            "updated train set: (110, 10) (110,) unique(labels): [55 55] [0 1]\n",
            "val set: (1192, 10) (1192,)\n",
            "\n",
            "Train set: (110, 10)\n",
            "Validation set: (1192, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 11\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.068 s \n",
            "\n",
            "Accuracy rate is 76.958525 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.88      0.85       321\n",
            "           1       0.57      0.44      0.50       113\n",
            "\n",
            "    accuracy                           0.77       434\n",
            "   macro avg       0.70      0.66      0.68       434\n",
            "weighted avg       0.75      0.77      0.76       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[284  37]\n",
            " [ 63  50]]\n",
            "--------------------------------\n",
            "val predicted: (1192,) [1 0 0 ... 0 0 0]\n",
            "probabilities: (1192, 2) \n",
            " [1 0 0 ... 0 0 0]\n",
            "trainset before adding uncertain samples (110, 10) (110,)\n",
            "trainset after adding uncertain samples (120, 10) (120,)\n",
            "updated train set: (120, 10) (120,) unique(labels): [60 60] [0 1]\n",
            "val set: (1182, 10) (1182,)\n",
            "\n",
            "Train set: (120, 10)\n",
            "Validation set: (1182, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 12\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.060 s \n",
            "\n",
            "Accuracy rate is 78.571429 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.90      0.86       321\n",
            "           1       0.62      0.47      0.53       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.72      0.68      0.70       434\n",
            "weighted avg       0.77      0.79      0.78       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[288  33]\n",
            " [ 60  53]]\n",
            "--------------------------------\n",
            "val predicted: (1182,) [1 0 0 ... 0 0 0]\n",
            "probabilities: (1182, 2) \n",
            " [1 0 0 ... 0 0 0]\n",
            "trainset before adding uncertain samples (120, 10) (120,)\n",
            "trainset after adding uncertain samples (130, 10) (130,)\n",
            "updated train set: (130, 10) (130,) unique(labels): [69 61] [0 1]\n",
            "val set: (1172, 10) (1172,)\n",
            "\n",
            "Train set: (130, 10)\n",
            "Validation set: (1172, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 13\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.105 s \n",
            "\n",
            "Accuracy rate is 77.880184 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.90      0.86       321\n",
            "           1       0.60      0.44      0.51       113\n",
            "\n",
            "    accuracy                           0.78       434\n",
            "   macro avg       0.71      0.67      0.68       434\n",
            "weighted avg       0.76      0.78      0.77       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[288  33]\n",
            " [ 63  50]]\n",
            "--------------------------------\n",
            "val predicted: (1172,) [1 0 0 ... 0 0 0]\n",
            "probabilities: (1172, 2) \n",
            " [1 0 0 ... 0 0 0]\n",
            "trainset before adding uncertain samples (130, 10) (130,)\n",
            "trainset after adding uncertain samples (140, 10) (140,)\n",
            "updated train set: (140, 10) (140,) unique(labels): [74 66] [0 1]\n",
            "val set: (1162, 10) (1162,)\n",
            "\n",
            "Train set: (140, 10)\n",
            "Validation set: (1162, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 14\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.069 s \n",
            "\n",
            "Accuracy rate is 79.262673 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.91      0.87       321\n",
            "           1       0.64      0.46      0.54       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.73      0.68      0.70       434\n",
            "weighted avg       0.78      0.79      0.78       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[292  29]\n",
            " [ 61  52]]\n",
            "--------------------------------\n",
            "val predicted: (1162,) [1 0 0 ... 0 0 0]\n",
            "probabilities: (1162, 2) \n",
            " [1 0 0 ... 0 0 0]\n",
            "trainset before adding uncertain samples (140, 10) (140,)\n",
            "trainset after adding uncertain samples (150, 10) (150,)\n",
            "updated train set: (150, 10) (150,) unique(labels): [79 71] [0 1]\n",
            "val set: (1152, 10) (1152,)\n",
            "\n",
            "Train set: (150, 10)\n",
            "Validation set: (1152, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 15\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.074 s \n",
            "\n",
            "Accuracy rate is 79.262673 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.91      0.87       321\n",
            "           1       0.64      0.46      0.54       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.73      0.68      0.70       434\n",
            "weighted avg       0.78      0.79      0.78       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[292  29]\n",
            " [ 61  52]]\n",
            "--------------------------------\n",
            "val predicted: (1152,) [1 0 0 ... 0 0 0]\n",
            "probabilities: (1152, 2) \n",
            " [1 0 0 ... 0 0 0]\n",
            "trainset before adding uncertain samples (150, 10) (150,)\n",
            "trainset after adding uncertain samples (160, 10) (160,)\n",
            "updated train set: (160, 10) (160,) unique(labels): [85 75] [0 1]\n",
            "val set: (1142, 10) (1142,)\n",
            "\n",
            "Train set: (160, 10)\n",
            "Validation set: (1142, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 16\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.065 s \n",
            "\n",
            "Accuracy rate is 79.723502 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.91      0.87       321\n",
            "           1       0.65      0.48      0.55       113\n",
            "\n",
            "    accuracy                           0.80       434\n",
            "   macro avg       0.74      0.69      0.71       434\n",
            "weighted avg       0.78      0.80      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[292  29]\n",
            " [ 59  54]]\n",
            "--------------------------------\n",
            "val predicted: (1142,) [1 0 0 ... 0 0 0]\n",
            "probabilities: (1142, 2) \n",
            " [1 0 0 ... 0 0 0]\n",
            "trainset before adding uncertain samples (160, 10) (160,)\n",
            "trainset after adding uncertain samples (170, 10) (170,)\n",
            "updated train set: (170, 10) (170,) unique(labels): [88 82] [0 1]\n",
            "val set: (1132, 10) (1132,)\n",
            "\n",
            "Train set: (170, 10)\n",
            "Validation set: (1132, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 17\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.064 s \n",
            "\n",
            "Accuracy rate is 80.645161 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.91      0.87       321\n",
            "           1       0.67      0.50      0.58       113\n",
            "\n",
            "    accuracy                           0.81       434\n",
            "   macro avg       0.76      0.71      0.73       434\n",
            "weighted avg       0.80      0.81      0.80       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[293  28]\n",
            " [ 56  57]]\n",
            "--------------------------------\n",
            "val predicted: (1132,) [1 1 0 ... 0 0 0]\n",
            "probabilities: (1132, 2) \n",
            " [1 1 0 ... 0 0 0]\n",
            "trainset before adding uncertain samples (170, 10) (170,)\n",
            "trainset after adding uncertain samples (180, 10) (180,)\n",
            "updated train set: (180, 10) (180,) unique(labels): [93 87] [0 1]\n",
            "val set: (1122, 10) (1122,)\n",
            "\n",
            "Train set: (180, 10)\n",
            "Validation set: (1122, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 18\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.072 s \n",
            "\n",
            "Accuracy rate is 81.105991 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.92      0.88       321\n",
            "           1       0.69      0.50      0.58       113\n",
            "\n",
            "    accuracy                           0.81       434\n",
            "   macro avg       0.76      0.71      0.73       434\n",
            "weighted avg       0.80      0.81      0.80       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[295  26]\n",
            " [ 56  57]]\n",
            "--------------------------------\n",
            "val predicted: (1122,) [1 1 0 ... 0 0 0]\n",
            "probabilities: (1122, 2) \n",
            " [1 1 0 ... 0 0 0]\n",
            "trainset before adding uncertain samples (180, 10) (180,)\n",
            "trainset after adding uncertain samples (190, 10) (190,)\n",
            "updated train set: (190, 10) (190,) unique(labels): [96 94] [0 1]\n",
            "val set: (1112, 10) (1112,)\n",
            "\n",
            "Train set: (190, 10)\n",
            "Validation set: (1112, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 19\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.061 s \n",
            "\n",
            "Accuracy rate is 78.801843 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.89      0.86       321\n",
            "           1       0.61      0.50      0.55       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.72      0.70      0.71       434\n",
            "weighted avg       0.78      0.79      0.78       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[285  36]\n",
            " [ 56  57]]\n",
            "--------------------------------\n",
            "val predicted: (1112,) [1 1 0 ... 0 0 0]\n",
            "probabilities: (1112, 2) \n",
            " [1 1 0 ... 0 0 0]\n",
            "trainset before adding uncertain samples (190, 10) (190,)\n",
            "trainset after adding uncertain samples (200, 10) (200,)\n",
            "updated train set: (200, 10) (200,) unique(labels): [100 100] [0 1]\n",
            "val set: (1102, 10) (1102,)\n",
            "\n",
            "Train set: (200, 10)\n",
            "Validation set: (1102, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 20\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.071 s \n",
            "\n",
            "Accuracy rate is 78.341014 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.90      0.86       321\n",
            "           1       0.61      0.46      0.53       113\n",
            "\n",
            "    accuracy                           0.78       434\n",
            "   macro avg       0.72      0.68      0.69       434\n",
            "weighted avg       0.77      0.78      0.77       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[288  33]\n",
            " [ 61  52]]\n",
            "--------------------------------\n",
            "val predicted: (1102,) [1 1 0 ... 0 0 0]\n",
            "probabilities: (1102, 2) \n",
            " [1 1 0 ... 0 0 0]\n",
            "trainset before adding uncertain samples (200, 10) (200,)\n",
            "trainset after adding uncertain samples (210, 10) (210,)\n",
            "updated train set: (210, 10) (210,) unique(labels): [106 104] [0 1]\n",
            "val set: (1092, 10) (1092,)\n",
            "\n",
            "Train set: (210, 10)\n",
            "Validation set: (1092, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 21\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.069 s \n",
            "\n",
            "Accuracy rate is 80.184332 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.91      0.87       321\n",
            "           1       0.66      0.49      0.56       113\n",
            "\n",
            "    accuracy                           0.80       434\n",
            "   macro avg       0.75      0.70      0.72       434\n",
            "weighted avg       0.79      0.80      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[293  28]\n",
            " [ 58  55]]\n",
            "--------------------------------\n",
            "val predicted: (1092,) [1 1 1 ... 0 0 0]\n",
            "probabilities: (1092, 2) \n",
            " [1 1 1 ... 0 0 0]\n",
            "trainset before adding uncertain samples (210, 10) (210,)\n",
            "trainset after adding uncertain samples (220, 10) (220,)\n",
            "updated train set: (220, 10) (220,) unique(labels): [112 108] [0 1]\n",
            "val set: (1082, 10) (1082,)\n",
            "\n",
            "Train set: (220, 10)\n",
            "Validation set: (1082, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 22\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.081 s \n",
            "\n",
            "Accuracy rate is 79.493088 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.91      0.87       321\n",
            "           1       0.65      0.46      0.54       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.74      0.69      0.70       434\n",
            "weighted avg       0.78      0.79      0.78       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[293  28]\n",
            " [ 61  52]]\n",
            "--------------------------------\n",
            "val predicted: (1082,) [1 1 1 ... 0 0 0]\n",
            "probabilities: (1082, 2) \n",
            " [1 1 1 ... 0 0 0]\n",
            "trainset before adding uncertain samples (220, 10) (220,)\n",
            "trainset after adding uncertain samples (230, 10) (230,)\n",
            "updated train set: (230, 10) (230,) unique(labels): [116 114] [0 1]\n",
            "val set: (1072, 10) (1072,)\n",
            "\n",
            "Train set: (230, 10)\n",
            "Validation set: (1072, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 23\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.076 s \n",
            "\n",
            "Accuracy rate is 80.875576 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.93      0.88       321\n",
            "           1       0.69      0.48      0.57       113\n",
            "\n",
            "    accuracy                           0.81       434\n",
            "   macro avg       0.76      0.70      0.72       434\n",
            "weighted avg       0.80      0.81      0.80       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[297  24]\n",
            " [ 59  54]]\n",
            "--------------------------------\n",
            "val predicted: (1072,) [1 1 1 ... 0 0 0]\n",
            "probabilities: (1072, 2) \n",
            " [1 1 1 ... 0 0 0]\n",
            "trainset before adding uncertain samples (230, 10) (230,)\n",
            "trainset after adding uncertain samples (240, 10) (240,)\n",
            "updated train set: (240, 10) (240,) unique(labels): [120 120] [0 1]\n",
            "val set: (1062, 10) (1062,)\n",
            "\n",
            "Train set: (240, 10)\n",
            "Validation set: (1062, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 24\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.064 s \n",
            "\n",
            "Accuracy rate is 80.414747 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.93      0.87       321\n",
            "           1       0.68      0.46      0.55       113\n",
            "\n",
            "    accuracy                           0.80       434\n",
            "   macro avg       0.76      0.69      0.71       434\n",
            "weighted avg       0.79      0.80      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[297  24]\n",
            " [ 61  52]]\n",
            "--------------------------------\n",
            "val predicted: (1062,) [1 1 1 ... 0 0 0]\n",
            "probabilities: (1062, 2) \n",
            " [1 1 1 ... 0 0 0]\n",
            "trainset before adding uncertain samples (240, 10) (240,)\n",
            "trainset after adding uncertain samples (250, 10) (250,)\n",
            "updated train set: (250, 10) (250,) unique(labels): [125 125] [0 1]\n",
            "val set: (1052, 10) (1052,)\n",
            "\n",
            "Train set: (250, 10)\n",
            "Validation set: (1052, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 25\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.120 s \n",
            "\n",
            "Accuracy rate is 80.645161 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.93      0.88       321\n",
            "           1       0.69      0.46      0.55       113\n",
            "\n",
            "    accuracy                           0.81       434\n",
            "   macro avg       0.76      0.69      0.71       434\n",
            "weighted avg       0.79      0.81      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[298  23]\n",
            " [ 61  52]]\n",
            "--------------------------------\n",
            "val predicted: (1052,) [1 0 1 ... 0 0 0]\n",
            "probabilities: (1052, 2) \n",
            " [1 0 1 ... 0 0 0]\n",
            "trainset before adding uncertain samples (250, 10) (250,)\n",
            "trainset after adding uncertain samples (260, 10) (260,)\n",
            "updated train set: (260, 10) (260,) unique(labels): [131 129] [0 1]\n",
            "val set: (1042, 10) (1042,)\n",
            "\n",
            "Train set: (260, 10)\n",
            "Validation set: (1042, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 26\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.102 s \n",
            "\n",
            "Accuracy rate is 80.645161 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.93      0.88       321\n",
            "           1       0.69      0.46      0.55       113\n",
            "\n",
            "    accuracy                           0.81       434\n",
            "   macro avg       0.76      0.69      0.71       434\n",
            "weighted avg       0.79      0.81      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[298  23]\n",
            " [ 61  52]]\n",
            "--------------------------------\n",
            "val predicted: (1042,) [1 0 0 ... 0 0 0]\n",
            "probabilities: (1042, 2) \n",
            " [1 0 0 ... 0 0 0]\n",
            "trainset before adding uncertain samples (260, 10) (260,)\n",
            "trainset after adding uncertain samples (270, 10) (270,)\n",
            "updated train set: (270, 10) (270,) unique(labels): [136 134] [0 1]\n",
            "val set: (1032, 10) (1032,)\n",
            "\n",
            "Train set: (270, 10)\n",
            "Validation set: (1032, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 27\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.076 s \n",
            "\n",
            "Accuracy rate is 80.184332 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.92      0.87       321\n",
            "           1       0.68      0.46      0.55       113\n",
            "\n",
            "    accuracy                           0.80       434\n",
            "   macro avg       0.75      0.69      0.71       434\n",
            "weighted avg       0.79      0.80      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[296  25]\n",
            " [ 61  52]]\n",
            "--------------------------------\n",
            "val predicted: (1032,) [1 0 0 ... 0 0 0]\n",
            "probabilities: (1032, 2) \n",
            " [1 0 0 ... 0 0 0]\n",
            "trainset before adding uncertain samples (270, 10) (270,)\n",
            "trainset after adding uncertain samples (280, 10) (280,)\n",
            "updated train set: (280, 10) (280,) unique(labels): [140 140] [0 1]\n",
            "val set: (1022, 10) (1022,)\n",
            "\n",
            "Train set: (280, 10)\n",
            "Validation set: (1022, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 28\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.073 s \n",
            "\n",
            "Accuracy rate is 79.723502 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.92      0.87       321\n",
            "           1       0.66      0.45      0.54       113\n",
            "\n",
            "    accuracy                           0.80       434\n",
            "   macro avg       0.74      0.69      0.70       434\n",
            "weighted avg       0.78      0.80      0.78       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[295  26]\n",
            " [ 62  51]]\n",
            "--------------------------------\n",
            "val predicted: (1022,) [1 0 0 ... 0 0 0]\n",
            "probabilities: (1022, 2) \n",
            " [1 0 0 ... 0 0 0]\n",
            "trainset before adding uncertain samples (280, 10) (280,)\n",
            "trainset after adding uncertain samples (290, 10) (290,)\n",
            "updated train set: (290, 10) (290,) unique(labels): [145 145] [0 1]\n",
            "val set: (1012, 10) (1012,)\n",
            "\n",
            "Train set: (290, 10)\n",
            "Validation set: (1012, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 29\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.190 s \n",
            "\n",
            "Accuracy rate is 80.184332 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.91      0.87       321\n",
            "           1       0.66      0.50      0.57       113\n",
            "\n",
            "    accuracy                           0.80       434\n",
            "   macro avg       0.75      0.71      0.72       434\n",
            "weighted avg       0.79      0.80      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[291  30]\n",
            " [ 56  57]]\n",
            "--------------------------------\n",
            "val predicted: (1012,) [1 0 0 ... 0 0 0]\n",
            "probabilities: (1012, 2) \n",
            " [1 0 0 ... 0 0 0]\n",
            "trainset before adding uncertain samples (290, 10) (290,)\n",
            "trainset after adding uncertain samples (300, 10) (300,)\n",
            "updated train set: (300, 10) (300,) unique(labels): [149 151] [0 1]\n",
            "val set: (1002, 10) (1002,)\n",
            "\n",
            "Train set: (300, 10)\n",
            "Validation set: (1002, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 30\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.094 s \n",
            "\n",
            "Accuracy rate is 80.184332 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.91      0.87       321\n",
            "           1       0.66      0.50      0.57       113\n",
            "\n",
            "    accuracy                           0.80       434\n",
            "   macro avg       0.75      0.71      0.72       434\n",
            "weighted avg       0.79      0.80      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[291  30]\n",
            " [ 56  57]]\n",
            "--------------------------------\n",
            "val predicted: (1002,) [1 0 0 ... 0 0 0]\n",
            "probabilities: (1002, 2) \n",
            " [1 0 0 ... 0 0 0]\n",
            "trainset before adding uncertain samples (300, 10) (300,)\n",
            "trainset after adding uncertain samples (310, 10) (310,)\n",
            "updated train set: (310, 10) (310,) unique(labels): [153 157] [0 1]\n",
            "val set: (992, 10) (992,)\n",
            "\n",
            "Train set: (310, 10)\n",
            "Validation set: (992, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 31\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.091 s \n",
            "\n",
            "Accuracy rate is 80.184332 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.90      0.87       321\n",
            "           1       0.65      0.51      0.57       113\n",
            "\n",
            "    accuracy                           0.80       434\n",
            "   macro avg       0.75      0.71      0.72       434\n",
            "weighted avg       0.79      0.80      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[290  31]\n",
            " [ 55  58]]\n",
            "--------------------------------\n",
            "val predicted: (992,) [1 0 0 1 0 0 0 1 1 0 0 1 0 0 0 0 1 1 1 1 0 1 0 1 0 0 1 0 0 1 1 1 1 0 1 1 1\n",
            " 0 0 1 1 0 0 0 0 1 0 1 0 0 0 1 0 1 1 1 1 1 1 1 1 0 1 0 1 0 0 1 1 1 1 1 1 0\n",
            " 1 0 1 1 0 0 0 0 0 0 0 1 1 0 1 1 1 0 1 0 0 1 1 1 0 0 0 1 0 1 0 0 0 1 0 0 1\n",
            " 0 1 1 1 0 1 0 1 0 1 0 1 0 0 0 0 0 0 1 1 1 1 1 0 0 0 1 1 0 1 0 1 1 1 1 1 1\n",
            " 0 1 0 1 0 0 1 1 0 1 1 1 1 0 1 0 1 0 0 0 1 1 0 1 1 0 1 1 1 0 1 1 0 0 1 1 0\n",
            " 1 1 1 0 0 1 0 0 0 1 0 0 1 1 1 0 0 1 0 0 0 0 0 1 1 1 0 1 1 0 0 0 0 1 0 1 1\n",
            " 0 0 1 1 0 0 0 0 0 0 1 1 1 0 1 1 1 0 0 1 0 0 1 1 1 0 1 1 0 1 1 0 1 0 1 1 0\n",
            " 1 1 1 1 1 1 1 0 1 1 0 1 1 0 0 0 1 1 1 1 1 1 0 0 1 0 1 1 0 0 1 0 1 0 1 0 1\n",
            " 0 0 0 1 0 0 0 0 0 1 1 1 1 1 1 1 0 1 1 0 1 0 1 0 1 0 1 0 0 0 0 1 1 1 0 0 1\n",
            " 0 1 0 1 0 0 0 1 1 1 0 0 1 1 1 1 0 1 0 1 1 0 0 1 1 1 0 1 1 1 1 1 1 1 1 0 1\n",
            " 1 0 1 1 1 0 0 0 1 1 0 0 1 1 0 1 1 0 1 1 0 1 0 1 0 1 0 0 1 1 1 1 0 1 1 0 1\n",
            " 0 1 0 1 1 0 1 0 1 1 0 0 1 0 1 1 1 0 1 1 0 0 0 0 1 1 0 0 0 1 0 0 1 0 0 1 0\n",
            " 1 0 1 1 0 0 1 0 1 0 1 1 0 0 1 1 1 1 1 0 1 0 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1\n",
            " 0 0 0 1 0 1 0 1 0 0 1 0 0 0 1 1 0 0 0 0 1 1 0 0 0 0 1 1 0 1 0 0 1 1 1 0 1\n",
            " 1 1 1 1 1 0 1 1 0 0 0 1 0 1 0 0 1 0 0 1 1 1 0 0 1 1 0 1 1 1 0 0 0 0 1 0 1\n",
            " 0 1 1 0 1 1 0 1 1 0 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1 0 1 1 1 1\n",
            " 0 1 0 0 0 0 0 1 0 1 0 1 0 1 1 0 1 1 1 1 1 0 0 1 0 1 1 0 0 1 0 1 0 0 1 0 0\n",
            " 1 1 1 1 1 1 0 1 1 1 0 1 0 1 1 0 1 1 0 1 1 0 1 1 0 1 1 0 0 1 0 1 1 1 1 1 0\n",
            " 0 1 0 1 1 1 1 1 0 1 1 0 0 0 1 1 1 1 1 1 0 1 1 1 1 0 0 0 1 1 1 0 1 0 0 1 1\n",
            " 1 0 1 1 0 0 1 0 0 1 0 1 0 1 0 0 1 1 1 1 0 0 1 0 1 1 1 1 0 0 0 0 1 1 1 1 0\n",
            " 1 0 1 0 1 0 1 1 0 0 0 1 0 0 1 1 1 0 0 0 1 0 0 1 1 1 1 1 0 0 0 0 1 1 0 0 1\n",
            " 0 1 0 1 1 0 0 1 0 1 1 0 0 0 1 0 0 1 0 1 1 1 1 0 1 0 1 0 0 0 0 0 1 0 0 1 1\n",
            " 1 1 1 0 1 1 0 1 0 0 0 1 0 1 1 1 1 1 1 1 0 0 0 0 0 0 1 0 1 1 1 1 1 0 1 0 0\n",
            " 0 0 0 0 1 0 0 1 0 1 1 0 1 1 0 0 0 1 1 0 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1 0 0\n",
            " 1 1 1 1 1 1 0 1 0 1 1 1 0 0 1 1 1 0 1 1 1 1 1 1 1 0 0 1 1 0 0 1 1 0 1 0 0\n",
            " 0 1 0 1 1 0 1 0 0 0 1 1 0 1 1 0 1 0 1 0 1 1 1 1 1 1 0 0 1 0 1 0 0 1 0 0 0\n",
            " 0 1 1 0 0 1 1 1 1 0 1 0 0 1 1 0 1 1 1 0 0 1 0 1 1 1 1 0 0 0]\n",
            "probabilities: (992, 2) \n",
            " [1 0 0 1 0 0 0 1 1 0 0 1 0 0 0 0 1 1 1 1 0 1 0 1 0 0 1 0 0 1 1 1 1 0 1 1 1\n",
            " 0 0 1 1 0 0 0 0 1 0 1 0 0 0 1 0 1 1 1 1 1 1 1 1 0 1 0 1 0 0 1 1 1 1 1 1 0\n",
            " 1 0 1 1 0 0 0 0 0 0 0 1 1 0 1 1 1 0 1 0 0 1 1 1 0 0 0 1 0 1 0 0 0 1 0 0 1\n",
            " 0 1 1 1 0 1 0 1 0 1 0 1 0 0 0 0 0 0 1 1 1 1 1 0 0 0 1 1 0 1 0 1 1 1 1 1 1\n",
            " 0 1 0 1 0 0 1 1 0 1 1 1 1 0 1 0 1 0 0 0 1 1 0 1 1 0 1 1 1 0 1 1 0 0 1 1 0\n",
            " 1 1 1 0 0 1 0 0 0 1 0 0 1 1 1 0 0 1 0 0 0 0 0 1 1 1 0 1 1 0 0 0 0 1 0 1 1\n",
            " 0 0 1 1 0 0 0 0 0 0 1 1 1 0 1 1 1 0 0 1 0 0 1 1 1 0 1 1 0 1 1 0 1 0 1 1 0\n",
            " 1 1 1 1 1 1 1 0 1 1 0 1 1 0 0 0 1 1 1 1 1 1 0 0 1 0 1 1 0 0 1 0 1 0 1 0 1\n",
            " 0 0 0 1 0 0 0 0 0 1 1 1 1 1 1 1 0 1 1 0 1 0 1 0 1 0 1 0 0 0 0 1 1 1 0 0 1\n",
            " 0 1 0 1 0 0 0 1 1 1 0 0 1 1 1 1 0 1 0 1 1 0 0 1 1 1 0 1 1 1 1 1 1 1 1 0 1\n",
            " 1 0 1 1 1 0 0 0 1 1 0 0 1 1 0 1 1 0 1 1 0 1 0 1 0 1 0 0 1 1 1 1 0 1 1 0 1\n",
            " 0 1 0 1 1 0 1 0 1 1 0 0 1 0 1 1 1 0 1 1 0 0 0 0 1 1 0 0 0 1 0 0 1 0 0 1 0\n",
            " 1 0 1 1 0 0 1 0 1 0 1 1 0 0 1 1 1 1 1 0 1 0 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1\n",
            " 0 0 0 1 0 1 0 1 0 0 1 0 0 0 1 1 0 0 0 0 1 1 0 0 0 0 1 1 0 1 0 0 1 1 1 0 1\n",
            " 1 1 1 1 1 0 1 1 0 0 0 1 0 1 0 0 1 0 0 1 1 1 0 0 1 1 0 1 1 1 0 0 0 0 1 0 1\n",
            " 0 1 1 0 1 1 0 1 1 0 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1 0 1 1 1 1\n",
            " 0 1 0 0 0 0 0 1 0 1 0 1 0 1 1 0 1 1 1 1 1 0 0 1 0 1 1 0 0 1 0 1 0 0 1 0 0\n",
            " 1 1 1 1 1 1 0 1 1 1 0 1 0 1 1 0 1 1 0 1 1 0 1 1 0 1 1 0 0 1 0 1 1 1 1 1 0\n",
            " 0 1 0 1 1 1 1 1 0 1 1 0 0 0 1 1 1 1 1 1 0 1 1 1 1 0 0 0 1 1 1 0 1 0 0 1 1\n",
            " 1 0 1 1 0 0 1 0 0 1 0 1 0 1 0 0 1 1 1 1 0 0 1 0 1 1 1 1 0 0 0 0 1 1 1 1 0\n",
            " 1 0 1 0 1 0 1 1 0 0 0 1 0 0 1 1 1 0 0 0 1 0 0 1 1 1 1 1 0 0 0 0 1 1 0 0 1\n",
            " 0 1 0 1 1 0 0 1 0 1 1 0 0 0 1 0 0 1 0 1 1 1 1 0 1 0 1 0 0 0 0 0 1 0 0 1 1\n",
            " 1 1 1 0 1 1 0 1 0 0 0 1 0 1 1 1 1 1 1 1 0 0 0 0 0 0 1 0 1 1 1 1 1 0 1 0 0\n",
            " 0 0 0 0 1 0 0 1 0 1 1 0 1 1 0 0 0 1 1 0 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1 0 0\n",
            " 1 1 1 1 1 1 0 1 0 1 1 1 0 0 1 1 1 0 1 1 1 1 1 1 1 0 0 1 1 0 0 1 1 0 1 0 0\n",
            " 0 1 0 1 1 0 1 0 0 0 1 1 0 1 1 0 1 0 1 0 1 1 1 1 1 1 0 0 1 0 1 0 0 1 0 0 0\n",
            " 0 1 1 0 0 1 1 1 1 0 1 0 0 1 1 0 1 1 1 0 0 1 0 1 1 1 1 0 0 0]\n",
            "trainset before adding uncertain samples (310, 10) (310,)\n",
            "trainset after adding uncertain samples (320, 10) (320,)\n",
            "updated train set: (320, 10) (320,) unique(labels): [158 162] [0 1]\n",
            "val set: (982, 10) (982,)\n",
            "\n",
            "Train set: (320, 10)\n",
            "Validation set: (982, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 32\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.059 s \n",
            "\n",
            "Accuracy rate is 80.875576 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.91      0.88       321\n",
            "           1       0.67      0.52      0.59       113\n",
            "\n",
            "    accuracy                           0.81       434\n",
            "   macro avg       0.76      0.72      0.73       434\n",
            "weighted avg       0.80      0.81      0.80       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[292  29]\n",
            " [ 54  59]]\n",
            "--------------------------------\n",
            "val predicted: (982,) [1 1 0 0 0 1 1 0 0 1 0 0 0 1 1 1 1 0 1 0 1 0 0 1 0 0 1 1 1 1 0 1 1 1 0 0 1\n",
            " 1 0 0 0 0 1 0 1 0 0 0 1 0 1 1 1 1 1 1 1 1 0 1 0 1 0 0 1 1 1 1 1 1 0 1 0 1\n",
            " 1 0 0 0 0 0 0 0 1 1 0 1 1 1 0 1 0 0 1 1 1 0 0 0 1 0 1 0 0 0 1 0 0 1 0 1 1\n",
            " 1 0 1 0 1 0 1 0 1 0 0 0 0 0 0 1 0 1 1 1 0 0 0 1 1 0 1 0 1 1 1 1 1 1 0 1 0\n",
            " 1 0 0 1 1 0 1 1 1 1 0 1 0 1 0 0 0 1 1 0 1 1 0 1 1 1 0 1 1 0 0 1 1 0 1 1 1\n",
            " 0 0 1 0 0 0 1 0 0 1 1 1 0 0 1 0 0 0 0 0 1 1 1 0 1 1 0 0 0 0 1 0 1 1 0 0 1\n",
            " 1 0 0 0 0 0 1 1 1 0 1 1 1 0 0 1 0 0 1 1 1 0 1 1 0 1 1 0 1 0 1 1 0 1 1 1 1\n",
            " 1 1 1 0 1 1 0 1 1 0 0 0 1 1 1 1 1 1 0 0 1 0 1 1 0 0 1 0 1 0 1 0 1 0 0 0 1\n",
            " 0 0 0 0 0 1 1 1 1 1 1 1 0 1 1 0 1 0 1 0 1 0 1 0 0 0 0 1 1 1 0 0 1 0 1 0 1\n",
            " 0 0 0 1 1 1 0 0 1 1 1 1 0 1 0 1 1 0 0 1 1 1 0 1 1 1 1 1 1 1 1 0 1 0 0 1 1\n",
            " 1 0 0 0 1 1 0 0 1 1 0 1 1 0 1 1 0 1 0 1 0 1 0 0 1 1 1 1 0 1 1 0 1 0 1 0 1\n",
            " 1 0 1 0 1 1 0 0 1 0 1 1 1 0 1 1 0 0 0 0 1 1 0 0 0 1 0 0 1 0 0 1 0 1 0 1 1\n",
            " 0 0 1 0 1 0 1 1 0 0 1 1 1 1 1 0 1 0 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 1\n",
            " 0 1 0 1 0 0 1 0 0 0 1 1 0 0 0 0 1 1 0 0 0 0 1 1 0 1 0 0 1 1 1 0 1 1 1 1 0\n",
            " 1 0 1 1 0 0 0 1 0 1 0 0 1 0 0 1 1 1 0 0 1 1 0 1 1 1 0 0 0 0 1 0 1 0 1 1 0\n",
            " 1 1 0 1 1 0 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1 0 1 1 1 1 0 1 0 0\n",
            " 0 0 1 0 1 0 1 0 1 1 0 1 1 1 1 1 0 1 0 1 1 0 0 1 0 1 0 0 1 0 0 1 1 1 1 1 1\n",
            " 0 1 1 0 0 1 0 1 1 0 1 1 0 1 1 0 1 1 0 1 1 0 0 1 0 1 1 1 1 1 0 0 1 0 1 1 1\n",
            " 1 1 0 1 1 0 0 0 1 1 1 1 1 1 0 1 1 1 1 0 0 0 1 1 1 0 1 0 0 1 1 1 0 1 1 0 0\n",
            " 1 0 0 1 0 1 0 1 0 0 1 1 1 1 0 0 1 0 1 1 1 1 0 0 0 0 1 0 1 1 0 1 0 1 0 1 0\n",
            " 1 1 0 0 1 0 0 1 1 1 0 0 0 1 0 0 1 1 1 0 1 0 0 0 0 1 1 0 0 1 0 1 1 1 0 0 1\n",
            " 0 1 1 0 0 0 1 0 0 1 0 1 1 1 1 0 1 0 1 0 0 0 0 0 1 0 1 1 1 1 1 0 1 1 0 1 0\n",
            " 0 0 1 0 1 1 1 1 1 1 1 0 0 0 0 0 0 1 0 1 1 1 1 1 0 1 0 0 0 0 0 0 1 0 0 1 0\n",
            " 1 1 0 1 1 0 0 0 1 1 0 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 1 0 1 0\n",
            " 1 1 0 0 0 1 1 1 0 1 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 0 0 1 0 1 1 0 1 0 0 0\n",
            " 1 1 0 1 1 0 1 0 1 0 1 1 1 1 1 1 0 0 1 0 1 0 0 1 0 0 0 0 1 1 0 0 1 1 1 1 0\n",
            " 1 0 0 1 1 0 1 1 1 0 0 1 0 1 1 1 1 0 0 0]\n",
            "probabilities: (982, 2) \n",
            " [1 1 0 0 0 1 1 0 0 1 0 0 0 1 1 1 1 0 1 0 1 0 0 1 0 0 1 1 1 1 0 1 1 1 0 0 1\n",
            " 1 0 0 0 0 1 0 1 0 0 0 1 0 1 1 1 1 1 1 1 1 0 1 0 1 0 0 1 1 1 1 1 1 0 1 0 1\n",
            " 1 0 0 0 0 0 0 0 1 1 0 1 1 1 0 1 0 0 1 1 1 0 0 0 1 0 1 0 0 0 1 0 0 1 0 1 1\n",
            " 1 0 1 0 1 0 1 0 1 0 0 0 0 0 0 1 0 1 1 1 0 0 0 1 1 0 1 0 1 1 1 1 1 1 0 1 0\n",
            " 1 0 0 1 1 0 1 1 1 1 0 1 0 1 0 0 0 1 1 0 1 1 0 1 1 1 0 1 1 0 0 1 1 0 1 1 1\n",
            " 0 0 1 0 0 0 1 0 0 1 1 1 0 0 1 0 0 0 0 0 1 1 1 0 1 1 0 0 0 0 1 0 1 1 0 0 1\n",
            " 1 0 0 0 0 0 1 1 1 0 1 1 1 0 0 1 0 0 1 1 1 0 1 1 0 1 1 0 1 0 1 1 0 1 1 1 1\n",
            " 1 1 1 0 1 1 0 1 1 0 0 0 1 1 1 1 1 1 0 0 1 0 1 1 0 0 1 0 1 0 1 0 1 0 0 0 1\n",
            " 0 0 0 0 0 1 1 1 1 1 1 1 0 1 1 0 1 0 1 0 1 0 1 0 0 0 0 1 1 1 0 0 1 0 1 0 1\n",
            " 0 0 0 1 1 1 0 0 1 1 1 1 0 1 0 1 1 0 0 1 1 1 0 1 1 1 1 1 1 1 1 0 1 0 0 1 1\n",
            " 1 0 0 0 1 1 0 0 1 1 0 1 1 0 1 1 0 1 0 1 0 1 0 0 1 1 1 1 0 1 1 0 1 0 1 0 1\n",
            " 1 0 1 0 1 1 0 0 1 0 1 1 1 0 1 1 0 0 0 0 1 1 0 0 0 1 0 0 1 0 0 1 0 1 0 1 1\n",
            " 0 0 1 0 1 0 1 1 0 0 1 1 1 1 1 0 1 0 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 1\n",
            " 0 1 0 1 0 0 1 0 0 0 1 1 0 0 0 0 1 1 0 0 0 0 1 1 0 1 0 0 1 1 1 0 1 1 1 1 0\n",
            " 1 0 1 1 0 0 0 1 0 1 0 0 1 0 0 1 1 1 0 0 1 1 0 1 1 1 0 0 0 0 1 0 1 0 1 1 0\n",
            " 1 1 0 1 1 0 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1 0 1 1 1 1 0 1 0 0\n",
            " 0 0 1 0 1 0 1 0 1 1 0 1 1 1 1 1 0 1 0 1 1 0 0 1 0 1 0 0 1 0 0 1 1 1 1 1 1\n",
            " 0 1 1 0 0 1 0 1 1 0 1 1 0 1 1 0 1 1 0 1 1 0 0 1 0 1 1 1 1 1 0 0 1 0 1 1 1\n",
            " 1 1 0 1 1 0 0 0 1 1 1 1 1 1 0 1 1 1 1 0 0 0 1 1 1 0 1 0 0 1 1 1 0 1 1 0 0\n",
            " 1 0 0 1 0 1 0 1 0 0 1 1 1 1 0 0 1 0 1 1 1 1 0 0 0 0 1 0 1 1 0 1 0 1 0 1 0\n",
            " 1 1 0 0 1 0 0 1 1 1 0 0 0 1 0 0 1 1 1 0 1 0 0 0 0 1 1 0 0 1 0 1 1 1 0 0 1\n",
            " 0 1 1 0 0 0 1 0 0 1 0 1 1 1 1 0 1 0 1 0 0 0 0 0 1 0 1 1 1 1 1 0 1 1 0 1 0\n",
            " 0 0 1 0 1 1 1 1 1 1 1 0 0 0 0 0 0 1 0 1 1 1 1 1 0 1 0 0 0 0 0 0 1 0 0 1 0\n",
            " 1 1 0 1 1 0 0 0 1 1 0 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 1 0 1 0\n",
            " 1 1 0 0 0 1 1 1 0 1 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 0 0 1 0 1 1 0 1 0 0 0\n",
            " 1 1 0 1 1 0 1 0 1 0 1 1 1 1 1 1 0 0 1 0 1 0 0 1 0 0 0 0 1 1 0 0 1 1 1 1 0\n",
            " 1 0 0 1 1 0 1 1 1 0 0 1 0 1 1 1 1 0 0 0]\n",
            "trainset before adding uncertain samples (320, 10) (320,)\n",
            "trainset after adding uncertain samples (330, 10) (330,)\n",
            "updated train set: (330, 10) (330,) unique(labels): [164 166] [0 1]\n",
            "val set: (972, 10) (972,)\n",
            "\n",
            "Train set: (330, 10)\n",
            "Validation set: (972, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 33\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.071 s \n",
            "\n",
            "Accuracy rate is 81.566820 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.91      0.88       321\n",
            "           1       0.68      0.55      0.61       113\n",
            "\n",
            "    accuracy                           0.82       434\n",
            "   macro avg       0.77      0.73      0.74       434\n",
            "weighted avg       0.81      0.82      0.81       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[292  29]\n",
            " [ 51  62]]\n",
            "--------------------------------\n",
            "val predicted: (972,) [1 1 0 0 0 1 1 0 0 0 0 0 0 1 1 1 1 0 1 0 1 0 0 1 0 0 1 1 1 1 0 1 1 1 0 0 1\n",
            " 1 0 0 0 0 1 0 1 0 0 0 1 0 1 1 1 1 1 1 1 1 0 1 0 1 0 0 1 1 1 1 1 1 0 1 0 1\n",
            " 1 0 0 0 0 0 0 0 1 1 0 1 1 1 0 1 0 0 1 1 1 0 0 0 1 0 1 0 0 0 1 0 0 1 0 1 1\n",
            " 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0 1 1 1 1 0 0 0 1 1 0 1 0 1 1 1 1 1 1 0 1 0 1\n",
            " 0 0 1 1 0 1 1 1 1 0 1 0 1 0 0 0 1 1 0 1 1 0 1 1 1 0 1 1 0 0 1 1 0 1 1 1 0\n",
            " 0 1 0 0 0 0 0 0 1 1 1 0 1 0 0 0 0 0 1 1 1 0 1 1 0 0 0 0 1 0 1 1 0 0 1 1 0\n",
            " 0 0 0 0 1 1 1 0 1 1 1 0 0 1 0 0 1 1 1 0 1 1 0 1 1 0 1 0 1 1 0 1 1 1 1 1 1\n",
            " 1 0 1 1 0 1 1 0 0 0 1 1 1 1 1 1 0 0 1 0 1 1 0 0 1 0 1 0 1 0 1 0 0 0 1 0 0\n",
            " 0 0 0 1 1 1 1 1 1 1 0 1 1 0 1 0 1 0 1 0 1 0 0 0 0 1 1 1 0 0 1 0 1 0 1 0 0\n",
            " 0 1 1 1 0 0 1 1 1 1 0 1 0 1 1 0 0 1 1 1 0 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 0\n",
            " 0 0 1 1 0 0 1 1 0 1 1 0 1 1 0 1 0 1 0 1 0 0 1 1 1 1 0 1 1 0 1 0 1 0 1 1 0\n",
            " 1 0 1 1 0 0 1 0 1 1 1 0 1 1 0 0 0 1 1 0 0 0 1 0 0 1 0 0 1 0 1 0 1 1 0 0 1\n",
            " 0 1 1 1 1 0 0 1 1 0 1 1 0 1 0 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 1 0 1 0\n",
            " 1 0 0 0 0 0 0 1 1 0 0 0 0 1 1 0 0 0 0 1 0 0 1 0 0 1 1 1 0 1 1 1 1 1 0 1 1\n",
            " 0 0 0 1 0 1 0 0 1 0 0 1 1 1 0 0 1 1 0 1 1 1 0 0 0 0 1 0 1 0 1 1 0 1 1 0 1\n",
            " 1 0 0 1 0 1 0 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1 0 1 1 1 1 0 1 0 0 0 0 1 0\n",
            " 1 0 1 0 1 1 0 1 1 1 1 1 0 1 0 1 1 0 0 1 0 1 0 0 1 0 0 1 1 1 1 1 1 0 1 1 0\n",
            " 1 0 1 1 0 1 1 0 1 1 0 1 1 0 1 1 0 0 1 0 1 1 1 1 1 0 0 1 0 1 1 1 1 1 0 1 1\n",
            " 0 0 0 1 1 1 1 1 1 0 1 1 1 1 0 0 0 1 1 1 0 1 0 0 1 1 1 0 1 1 0 0 1 0 0 1 0\n",
            " 1 0 1 0 0 1 1 1 1 0 0 1 0 1 1 1 1 0 0 0 0 1 1 1 1 0 1 0 1 0 1 0 1 1 0 0 1\n",
            " 0 0 1 1 1 0 0 0 1 0 0 1 1 1 1 0 0 0 0 1 1 0 0 1 0 1 1 1 0 0 1 0 1 1 0 0 0\n",
            " 1 0 0 1 0 1 1 1 1 0 1 0 1 0 0 0 0 1 0 1 1 1 1 1 0 1 1 0 1 0 0 1 1 1 1 1 1\n",
            " 1 1 0 0 0 0 0 1 0 1 1 1 1 1 0 1 0 0 0 0 0 0 1 0 0 1 0 1 1 0 1 1 0 0 0 1 0\n",
            " 0 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 1 0 1 0 1 1 0 0 0 1 1 1 0 1\n",
            " 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 0 0 1 0 1 1 0 1 0 0 0 1 1 0 1 1 0 1 0 1 0\n",
            " 1 1 1 1 1 1 0 0 1 0 1 0 0 1 0 0 0 0 1 1 0 0 1 1 1 1 0 1 0 0 1 1 0 1 1 1 0\n",
            " 0 1 0 1 1 1 1 0 0 0]\n",
            "probabilities: (972, 2) \n",
            " [1 1 0 0 0 1 1 0 0 0 0 0 0 1 1 1 1 0 1 0 1 0 0 1 0 0 1 1 1 1 0 1 1 1 0 0 1\n",
            " 1 0 0 0 0 1 0 1 0 0 0 1 0 1 1 1 1 1 1 1 1 0 1 0 1 0 0 1 1 1 1 1 1 0 1 0 1\n",
            " 1 0 0 0 0 0 0 0 1 1 0 1 1 1 0 1 0 0 1 1 1 0 0 0 1 0 1 0 0 0 1 0 0 1 0 1 1\n",
            " 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0 1 1 1 1 0 0 0 1 1 0 1 0 1 1 1 1 1 1 0 1 0 1\n",
            " 0 0 1 1 0 1 1 1 1 0 1 0 1 0 0 0 1 1 0 1 1 0 1 1 1 0 1 1 0 0 1 1 0 1 1 1 0\n",
            " 0 1 0 0 0 0 0 0 1 1 1 0 1 0 0 0 0 0 1 1 1 0 1 1 0 0 0 0 1 0 1 1 0 0 1 1 0\n",
            " 0 0 0 0 1 1 1 0 1 1 1 0 0 1 0 0 1 1 1 0 1 1 0 1 1 0 1 0 1 1 0 1 1 1 1 1 1\n",
            " 1 0 1 1 0 1 1 0 0 0 1 1 1 1 1 1 0 0 1 0 1 1 0 0 1 0 1 0 1 0 1 0 0 0 1 0 0\n",
            " 0 0 0 1 1 1 1 1 1 1 0 1 1 0 1 0 1 0 1 0 1 0 0 0 0 1 1 1 0 0 1 0 1 0 1 0 0\n",
            " 0 1 1 1 0 0 1 1 1 1 0 1 0 1 1 0 0 1 1 1 0 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 0\n",
            " 0 0 1 1 0 0 1 1 0 1 1 0 1 1 0 1 0 1 0 1 0 0 1 1 1 1 0 1 1 0 1 0 1 0 1 1 0\n",
            " 1 0 1 1 0 0 1 0 1 1 1 0 1 1 0 0 0 1 1 0 0 0 1 0 0 1 0 0 1 0 1 0 1 1 0 0 1\n",
            " 0 1 1 1 1 0 0 1 1 0 1 1 0 1 0 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 1 0 1 0\n",
            " 1 0 0 0 0 0 0 1 1 0 0 0 0 1 1 0 0 0 0 1 0 0 1 0 0 1 1 1 0 1 1 1 1 1 0 1 1\n",
            " 0 0 0 1 0 1 0 0 1 0 0 1 1 1 0 0 1 1 0 1 1 1 0 0 0 0 1 0 1 0 1 1 0 1 1 0 1\n",
            " 1 0 0 1 0 1 0 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1 0 1 1 1 1 0 1 0 0 0 0 1 0\n",
            " 1 0 1 0 1 1 0 1 1 1 1 1 0 1 0 1 1 0 0 1 0 1 0 0 1 0 0 1 1 1 1 1 1 0 1 1 0\n",
            " 1 0 1 1 0 1 1 0 1 1 0 1 1 0 1 1 0 0 1 0 1 1 1 1 1 0 0 1 0 1 1 1 1 1 0 1 1\n",
            " 0 0 0 1 1 1 1 1 1 0 1 1 1 1 0 0 0 1 1 1 0 1 0 0 1 1 1 0 1 1 0 0 1 0 0 1 0\n",
            " 1 0 1 0 0 1 1 1 1 0 0 1 0 1 1 1 1 0 0 0 0 1 1 1 1 0 1 0 1 0 1 0 1 1 0 0 1\n",
            " 0 0 1 1 1 0 0 0 1 0 0 1 1 1 1 0 0 0 0 1 1 0 0 1 0 1 1 1 0 0 1 0 1 1 0 0 0\n",
            " 1 0 0 1 0 1 1 1 1 0 1 0 1 0 0 0 0 1 0 1 1 1 1 1 0 1 1 0 1 0 0 1 1 1 1 1 1\n",
            " 1 1 0 0 0 0 0 1 0 1 1 1 1 1 0 1 0 0 0 0 0 0 1 0 0 1 0 1 1 0 1 1 0 0 0 1 0\n",
            " 0 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 1 0 1 0 1 1 0 0 0 1 1 1 0 1\n",
            " 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 0 0 1 0 1 1 0 1 0 0 0 1 1 0 1 1 0 1 0 1 0\n",
            " 1 1 1 1 1 1 0 0 1 0 1 0 0 1 0 0 0 0 1 1 0 0 1 1 1 1 0 1 0 0 1 1 0 1 1 1 0\n",
            " 0 1 0 1 1 1 1 0 0 0]\n",
            "trainset before adding uncertain samples (330, 10) (330,)\n",
            "trainset after adding uncertain samples (340, 10) (340,)\n",
            "updated train set: (340, 10) (340,) unique(labels): [169 171] [0 1]\n",
            "val set: (962, 10) (962,)\n",
            "\n",
            "Train set: (340, 10)\n",
            "Validation set: (962, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 34\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.064 s \n",
            "\n",
            "Accuracy rate is 80.645161 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.91      0.87       321\n",
            "           1       0.67      0.50      0.58       113\n",
            "\n",
            "    accuracy                           0.81       434\n",
            "   macro avg       0.76      0.71      0.73       434\n",
            "weighted avg       0.80      0.81      0.80       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[293  28]\n",
            " [ 56  57]]\n",
            "--------------------------------\n",
            "val predicted: (962,) [1 1 0 0 0 1 1 0 0 0 0 0 0 1 1 1 1 0 1 0 1 0 0 1 0 0 1 1 1 1 0 1 1 1 0 0 1\n",
            " 1 0 0 0 0 1 0 1 0 0 0 1 0 1 1 1 1 1 1 1 1 0 1 0 1 0 0 1 1 1 1 1 1 0 1 0 1\n",
            " 1 0 0 0 0 0 0 1 1 0 1 1 1 0 1 0 0 1 1 1 0 0 0 1 0 1 0 0 0 1 0 0 1 0 1 1 1\n",
            " 0 1 0 1 0 0 1 0 0 0 0 0 0 1 1 1 1 0 0 0 1 1 0 1 0 1 1 1 1 1 1 0 1 0 1 0 0\n",
            " 1 1 0 1 1 1 1 0 0 0 1 0 0 0 1 1 0 1 1 0 1 1 1 0 1 1 0 0 1 1 0 1 0 1 0 0 0\n",
            " 0 0 0 1 0 0 1 1 1 0 1 0 0 0 0 0 1 1 1 0 1 1 0 0 0 0 1 0 1 1 0 0 1 1 0 0 0\n",
            " 0 0 1 1 1 0 1 1 1 0 0 1 0 0 1 1 1 0 1 1 0 1 1 0 1 0 1 1 0 1 1 1 1 1 1 1 0\n",
            " 1 1 0 1 1 0 0 0 1 1 1 1 1 1 0 0 1 0 1 0 0 0 1 0 1 0 1 0 1 0 0 0 1 0 0 0 0\n",
            " 0 1 1 1 1 1 1 1 0 1 1 0 1 0 1 0 1 0 1 0 0 0 0 1 1 1 0 0 1 0 1 0 1 0 0 0 1\n",
            " 1 1 0 0 1 1 1 1 0 1 0 1 1 0 0 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 0 0 0\n",
            " 1 1 0 0 1 1 0 0 1 0 1 1 0 1 0 1 0 1 0 0 1 1 1 1 0 1 1 0 1 0 1 0 1 1 0 1 0\n",
            " 1 1 0 0 1 0 1 1 1 0 1 1 0 0 0 1 1 0 0 0 1 0 0 1 0 0 1 0 1 0 1 1 0 1 0 1 1\n",
            " 1 1 0 0 1 1 0 1 1 0 1 0 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 1 0 1 0 1 0 0\n",
            " 0 0 0 1 1 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 1 1 1 0 1 1 1 1 1 0 1 1 0 0 0 1 0\n",
            " 1 0 0 1 0 0 1 1 1 0 0 1 1 0 1 1 1 0 0 0 0 1 0 1 0 1 1 0 1 1 0 1 1 0 0 1 1\n",
            " 0 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1 0 1 1 1 1 0 1 0 0 0 0 1 1 0 1 0 1 1 0\n",
            " 1 1 1 1 1 0 1 0 1 1 0 0 1 0 1 0 0 1 0 0 1 1 1 1 1 1 0 1 1 0 1 0 1 1 0 1 1\n",
            " 0 1 1 0 1 1 0 1 1 0 0 1 0 1 1 1 1 1 0 0 1 0 1 1 1 1 1 0 1 1 0 0 0 1 1 1 1\n",
            " 1 1 0 1 1 1 1 0 0 0 1 1 1 0 1 0 0 1 1 1 0 1 1 0 0 1 0 0 1 0 1 0 1 0 0 1 1\n",
            " 1 1 0 0 1 0 1 1 1 1 0 0 0 0 1 0 1 1 0 1 0 1 0 1 0 1 1 0 0 1 0 0 1 1 1 0 0\n",
            " 0 1 0 0 1 1 1 1 0 0 0 0 1 1 0 0 1 0 1 1 1 0 0 1 0 1 1 0 0 0 1 0 0 1 0 1 1\n",
            " 1 1 0 1 0 1 0 0 0 0 1 0 1 1 1 1 1 0 1 1 0 1 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0\n",
            " 1 0 1 1 1 0 1 0 1 0 0 0 0 0 1 0 0 1 0 1 1 0 1 1 0 0 0 1 0 0 1 1 0 0 1 0 1\n",
            " 1 1 1 0 1 1 1 0 0 1 1 1 1 1 1 0 1 0 1 1 0 0 1 1 1 0 1 1 1 1 1 1 1 0 1 1 0\n",
            " 0 1 1 0 1 0 0 0 1 0 1 1 0 1 0 0 0 1 1 0 1 1 0 1 0 1 0 1 1 1 1 1 1 0 0 1 0\n",
            " 1 0 0 1 0 0 0 0 1 1 0 0 1 1 1 1 0 1 0 0 1 1 0 1 1 1 0 0 1 0 0 1 1 1 0 0 0]\n",
            "probabilities: (962, 2) \n",
            " [1 1 0 0 0 1 1 0 0 0 0 0 0 1 1 1 1 0 1 0 1 0 0 1 0 0 1 1 1 1 0 1 1 1 0 0 1\n",
            " 1 0 0 0 0 1 0 1 0 0 0 1 0 1 1 1 1 1 1 1 1 0 1 0 1 0 0 1 1 1 1 1 1 0 1 0 1\n",
            " 1 0 0 0 0 0 0 1 1 0 1 1 1 0 1 0 0 1 1 1 0 0 0 1 0 1 0 0 0 1 0 0 1 0 1 1 1\n",
            " 0 1 0 1 0 0 1 0 0 0 0 0 0 1 1 1 1 0 0 0 1 1 0 1 0 1 1 1 1 1 1 0 1 0 1 0 0\n",
            " 1 1 0 1 1 1 1 0 0 0 1 0 0 0 1 1 0 1 1 0 1 1 1 0 1 1 0 0 1 1 0 1 0 1 0 0 0\n",
            " 0 0 0 1 0 0 1 1 1 0 1 0 0 0 0 0 1 1 1 0 1 1 0 0 0 0 1 0 1 1 0 0 1 1 0 0 0\n",
            " 0 0 1 1 1 0 1 1 1 0 0 1 0 0 1 1 1 0 1 1 0 1 1 0 1 0 1 1 0 1 1 1 1 1 1 1 0\n",
            " 1 1 0 1 1 0 0 0 1 1 1 1 1 1 0 0 1 0 1 0 0 0 1 0 1 0 1 0 1 0 0 0 1 0 0 0 0\n",
            " 0 1 1 1 1 1 1 1 0 1 1 0 1 0 1 0 1 0 1 0 0 0 0 1 1 1 0 0 1 0 1 0 1 0 0 0 1\n",
            " 1 1 0 0 1 1 1 1 0 1 0 1 1 0 0 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 0 0 0\n",
            " 1 1 0 0 1 1 0 0 1 0 1 1 0 1 0 1 0 1 0 0 1 1 1 1 0 1 1 0 1 0 1 0 1 1 0 1 0\n",
            " 1 1 0 0 1 0 1 1 1 0 1 1 0 0 0 1 1 0 0 0 1 0 0 1 0 0 1 0 1 0 1 1 0 1 0 1 1\n",
            " 1 1 0 0 1 1 0 1 1 0 1 0 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 1 0 1 0 1 0 0\n",
            " 0 0 0 1 1 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 1 1 1 0 1 1 1 1 1 0 1 1 0 0 0 1 0\n",
            " 1 0 0 1 0 0 1 1 1 0 0 1 1 0 1 1 1 0 0 0 0 1 0 1 0 1 1 0 1 1 0 1 1 0 0 1 1\n",
            " 0 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1 0 1 1 1 1 0 1 0 0 0 0 1 1 0 1 0 1 1 0\n",
            " 1 1 1 1 1 0 1 0 1 1 0 0 1 0 1 0 0 1 0 0 1 1 1 1 1 1 0 1 1 0 1 0 1 1 0 1 1\n",
            " 0 1 1 0 1 1 0 1 1 0 0 1 0 1 1 1 1 1 0 0 1 0 1 1 1 1 1 0 1 1 0 0 0 1 1 1 1\n",
            " 1 1 0 1 1 1 1 0 0 0 1 1 1 0 1 0 0 1 1 1 0 1 1 0 0 1 0 0 1 0 1 0 1 0 0 1 1\n",
            " 1 1 0 0 1 0 1 1 1 1 0 0 0 0 1 0 1 1 0 1 0 1 0 1 0 1 1 0 0 1 0 0 1 1 1 0 0\n",
            " 0 1 0 0 1 1 1 1 0 0 0 0 1 1 0 0 1 0 1 1 1 0 0 1 0 1 1 0 0 0 1 0 0 1 0 1 1\n",
            " 1 1 0 1 0 1 0 0 0 0 1 0 1 1 1 1 1 0 1 1 0 1 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0\n",
            " 1 0 1 1 1 0 1 0 1 0 0 0 0 0 1 0 0 1 0 1 1 0 1 1 0 0 0 1 0 0 1 1 0 0 1 0 1\n",
            " 1 1 1 0 1 1 1 0 0 1 1 1 1 1 1 0 1 0 1 1 0 0 1 1 1 0 1 1 1 1 1 1 1 0 1 1 0\n",
            " 0 1 1 0 1 0 0 0 1 0 1 1 0 1 0 0 0 1 1 0 1 1 0 1 0 1 0 1 1 1 1 1 1 0 0 1 0\n",
            " 1 0 0 1 0 0 0 0 1 1 0 0 1 1 1 1 0 1 0 0 1 1 0 1 1 1 0 0 1 0 0 1 1 1 0 0 0]\n",
            "trainset before adding uncertain samples (340, 10) (340,)\n",
            "trainset after adding uncertain samples (350, 10) (350,)\n",
            "updated train set: (350, 10) (350,) unique(labels): [170 180] [0 1]\n",
            "val set: (952, 10) (952,)\n",
            "\n",
            "Train set: (350, 10)\n",
            "Validation set: (952, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 35\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.064 s \n",
            "\n",
            "Accuracy rate is 80.875576 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.90      0.87       321\n",
            "           1       0.66      0.54      0.60       113\n",
            "\n",
            "    accuracy                           0.81       434\n",
            "   macro avg       0.76      0.72      0.73       434\n",
            "weighted avg       0.80      0.81      0.80       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[290  31]\n",
            " [ 52  61]]\n",
            "--------------------------------\n",
            "val predicted: (952,) [1 1 0 0 0 1 1 0 0 0 0 0 1 1 1 1 0 1 0 1 0 0 1 0 0 1 1 1 1 0 1 1 1 0 0 1 1\n",
            " 0 0 0 0 1 0 1 0 0 0 1 0 1 1 1 1 1 1 1 1 0 1 0 1 0 0 1 1 1 1 1 1 0 1 0 1 1\n",
            " 0 0 0 0 0 0 1 1 0 1 1 1 0 1 0 0 1 1 1 0 0 0 1 0 1 0 0 0 1 0 0 1 0 1 1 1 0\n",
            " 1 0 1 0 0 1 0 0 0 0 0 0 1 1 1 1 0 0 0 1 1 0 1 0 1 1 1 1 1 1 0 1 0 1 0 0 1\n",
            " 1 0 1 1 1 1 0 0 0 1 0 0 0 1 1 0 1 1 0 1 1 1 0 1 1 0 0 1 1 0 1 1 1 0 0 0 0\n",
            " 0 1 0 0 1 1 1 0 1 0 0 0 0 0 1 1 1 0 1 1 0 0 0 0 1 0 1 1 0 0 1 1 0 0 0 0 0\n",
            " 1 1 1 0 1 1 1 0 0 1 0 0 1 1 1 0 1 1 0 1 1 0 1 0 1 1 0 1 1 1 1 1 1 1 0 1 1\n",
            " 0 1 1 0 0 0 1 1 1 1 1 1 0 0 1 0 1 0 0 1 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 1 1\n",
            " 1 1 1 1 1 0 1 1 0 1 0 1 0 1 0 1 0 0 0 1 1 1 0 0 1 0 1 0 1 0 0 0 1 1 1 0 0\n",
            " 1 1 1 1 0 1 0 1 1 0 0 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 0 0 0 1 1 0 1\n",
            " 1 0 1 0 1 1 0 1 0 1 0 1 0 0 1 1 1 1 0 1 1 0 1 0 1 0 1 1 0 1 0 1 1 0 0 1 0\n",
            " 1 1 1 0 1 1 0 0 0 1 1 0 0 0 1 0 0 1 0 0 1 0 1 0 1 1 0 1 0 1 1 1 1 0 0 1 1\n",
            " 1 1 0 1 0 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 1 0 1 0 1 0 0 0 0 0 1 1 0 0\n",
            " 0 0 1 1 0 0 0 0 1 0 1 0 0 1 1 1 0 1 1 1 1 1 0 1 1 0 0 0 1 0 1 0 0 1 0 0 1\n",
            " 1 1 0 0 1 1 0 1 1 1 0 0 0 0 1 0 1 0 1 1 0 1 1 0 1 1 0 0 1 1 0 1 1 1 1 1 1\n",
            " 1 1 1 1 0 0 1 0 1 1 1 0 1 1 1 1 0 1 0 0 0 0 1 1 0 1 0 1 1 0 1 1 1 1 1 0 1\n",
            " 0 1 1 0 0 1 0 1 0 0 1 0 0 1 1 1 1 1 1 0 1 1 0 1 0 1 1 0 1 1 0 1 1 0 1 1 0\n",
            " 1 1 0 0 1 0 1 1 1 1 1 0 0 1 0 1 1 1 1 1 0 1 1 0 0 0 1 1 1 1 1 1 0 1 1 1 1\n",
            " 0 0 0 1 1 1 0 1 0 0 1 1 1 0 1 1 0 0 1 0 0 1 0 1 0 1 0 0 1 1 1 1 0 0 1 0 1\n",
            " 1 1 1 0 0 0 0 1 1 1 0 1 0 1 0 1 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1 0 0 1 1 1 1\n",
            " 0 0 0 0 1 1 0 0 1 0 1 1 1 0 0 1 0 1 1 0 0 0 1 0 0 1 0 1 1 1 1 0 1 0 1 0 0\n",
            " 0 0 1 0 1 1 1 1 1 0 1 1 0 1 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 1 0 1 1 1 1 0 1\n",
            " 0 0 0 0 0 1 0 0 1 0 1 1 0 1 1 0 0 0 1 0 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1 0 0\n",
            " 1 1 1 1 1 1 0 1 0 1 1 0 0 1 1 1 0 1 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 0 0 1\n",
            " 0 1 1 0 1 0 0 0 1 1 0 1 1 0 1 0 1 0 1 1 1 1 1 1 0 0 1 0 1 0 0 1 0 0 0 0 1\n",
            " 1 0 0 1 1 1 1 0 1 0 0 1 1 0 1 1 1 0 0 1 0 1 1 1 0 0 0]\n",
            "probabilities: (952, 2) \n",
            " [1 1 0 0 0 1 1 0 0 0 0 0 1 1 1 1 0 1 0 1 0 0 1 0 0 1 1 1 1 0 1 1 1 0 0 1 1\n",
            " 0 0 0 0 1 0 1 0 0 0 1 0 1 1 1 1 1 1 1 1 0 1 0 1 0 0 1 1 1 1 1 1 0 1 0 1 1\n",
            " 0 0 0 0 0 0 1 1 0 1 1 1 0 1 0 0 1 1 1 0 0 0 1 0 1 0 0 0 1 0 0 1 0 1 1 1 0\n",
            " 1 0 1 0 0 1 0 0 0 0 0 0 1 1 1 1 0 0 0 1 1 0 1 0 1 1 1 1 1 1 0 1 0 1 0 0 1\n",
            " 1 0 1 1 1 1 0 0 0 1 0 0 0 1 1 0 1 1 0 1 1 1 0 1 1 0 0 1 1 0 1 1 1 0 0 0 0\n",
            " 0 1 0 0 1 1 1 0 1 0 0 0 0 0 1 1 1 0 1 1 0 0 0 0 1 0 1 1 0 0 1 1 0 0 0 0 0\n",
            " 1 1 1 0 1 1 1 0 0 1 0 0 1 1 1 0 1 1 0 1 1 0 1 0 1 1 0 1 1 1 1 1 1 1 0 1 1\n",
            " 0 1 1 0 0 0 1 1 1 1 1 1 0 0 1 0 1 0 0 1 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 1 1\n",
            " 1 1 1 1 1 0 1 1 0 1 0 1 0 1 0 1 0 0 0 1 1 1 0 0 1 0 1 0 1 0 0 0 1 1 1 0 0\n",
            " 1 1 1 1 0 1 0 1 1 0 0 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 0 0 0 1 1 0 1\n",
            " 1 0 1 0 1 1 0 1 0 1 0 1 0 0 1 1 1 1 0 1 1 0 1 0 1 0 1 1 0 1 0 1 1 0 0 1 0\n",
            " 1 1 1 0 1 1 0 0 0 1 1 0 0 0 1 0 0 1 0 0 1 0 1 0 1 1 0 1 0 1 1 1 1 0 0 1 1\n",
            " 1 1 0 1 0 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 1 0 1 0 1 0 0 0 0 0 1 1 0 0\n",
            " 0 0 1 1 0 0 0 0 1 0 1 0 0 1 1 1 0 1 1 1 1 1 0 1 1 0 0 0 1 0 1 0 0 1 0 0 1\n",
            " 1 1 0 0 1 1 0 1 1 1 0 0 0 0 1 0 1 0 1 1 0 1 1 0 1 1 0 0 1 1 0 1 1 1 1 1 1\n",
            " 1 1 1 1 0 0 1 0 1 1 1 0 1 1 1 1 0 1 0 0 0 0 1 1 0 1 0 1 1 0 1 1 1 1 1 0 1\n",
            " 0 1 1 0 0 1 0 1 0 0 1 0 0 1 1 1 1 1 1 0 1 1 0 1 0 1 1 0 1 1 0 1 1 0 1 1 0\n",
            " 1 1 0 0 1 0 1 1 1 1 1 0 0 1 0 1 1 1 1 1 0 1 1 0 0 0 1 1 1 1 1 1 0 1 1 1 1\n",
            " 0 0 0 1 1 1 0 1 0 0 1 1 1 0 1 1 0 0 1 0 0 1 0 1 0 1 0 0 1 1 1 1 0 0 1 0 1\n",
            " 1 1 1 0 0 0 0 1 1 1 0 1 0 1 0 1 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1 0 0 1 1 1 1\n",
            " 0 0 0 0 1 1 0 0 1 0 1 1 1 0 0 1 0 1 1 0 0 0 1 0 0 1 0 1 1 1 1 0 1 0 1 0 0\n",
            " 0 0 1 0 1 1 1 1 1 0 1 1 0 1 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 1 0 1 1 1 1 0 1\n",
            " 0 0 0 0 0 1 0 0 1 0 1 1 0 1 1 0 0 0 1 0 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1 0 0\n",
            " 1 1 1 1 1 1 0 1 0 1 1 0 0 1 1 1 0 1 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 0 0 1\n",
            " 0 1 1 0 1 0 0 0 1 1 0 1 1 0 1 0 1 0 1 1 1 1 1 1 0 0 1 0 1 0 0 1 0 0 0 0 1\n",
            " 1 0 0 1 1 1 1 0 1 0 0 1 1 0 1 1 1 0 0 1 0 1 1 1 0 0 0]\n",
            "trainset before adding uncertain samples (350, 10) (350,)\n",
            "trainset after adding uncertain samples (360, 10) (360,)\n",
            "updated train set: (360, 10) (360,) unique(labels): [177 183] [0 1]\n",
            "val set: (942, 10) (942,)\n",
            "\n",
            "Train set: (360, 10)\n",
            "Validation set: (942, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 36\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.062 s \n",
            "\n",
            "Accuracy rate is 81.566820 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.91      0.88       321\n",
            "           1       0.68      0.56      0.61       113\n",
            "\n",
            "    accuracy                           0.82       434\n",
            "   macro avg       0.77      0.73      0.75       434\n",
            "weighted avg       0.81      0.82      0.81       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[291  30]\n",
            " [ 50  63]]\n",
            "--------------------------------\n",
            "val predicted: (942,) [1 1 0 1 1 0 0 0 0 0 1 1 1 1 0 1 0 1 0 0 1 0 0 1 1 1 1 0 1 1 1 0 0 1 1 0 0\n",
            " 0 0 1 0 1 0 0 0 1 0 1 1 1 1 1 1 1 1 0 1 0 1 0 0 1 1 1 1 1 1 0 1 0 1 1 0 0\n",
            " 0 0 0 0 1 1 0 1 1 1 0 1 0 0 1 1 1 0 0 0 1 0 1 0 0 0 1 0 0 1 0 1 1 1 0 1 0\n",
            " 1 0 0 1 0 0 0 0 0 0 1 1 1 1 0 0 0 1 1 0 1 0 1 1 1 1 1 1 0 1 0 1 0 0 1 1 0\n",
            " 1 1 1 1 0 0 1 0 0 0 1 1 0 1 1 0 1 1 1 0 1 1 0 0 1 1 0 1 1 1 0 0 0 0 0 1 0\n",
            " 0 1 1 1 0 1 0 0 0 0 0 1 1 1 0 1 1 0 0 0 0 1 0 1 1 0 0 1 1 0 0 0 0 0 1 1 1\n",
            " 0 1 1 1 0 0 1 0 0 1 1 1 0 1 1 0 1 1 0 1 0 1 1 0 1 1 1 1 1 1 1 0 1 1 0 1 1\n",
            " 0 0 0 1 1 1 1 1 0 0 1 0 1 0 0 1 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 1 1 1 1 1 1\n",
            " 1 0 1 1 0 1 0 1 0 1 0 1 0 0 0 1 1 1 0 0 1 0 1 0 1 0 0 0 1 1 1 0 0 1 1 1 1\n",
            " 0 1 0 1 1 0 0 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 0 0 0 1 1 0 1 1 0 1 0\n",
            " 1 1 0 1 0 1 0 1 0 0 1 1 1 1 0 1 1 0 1 0 1 0 1 1 0 1 0 1 1 0 0 1 0 1 1 1 0\n",
            " 1 1 0 0 0 1 1 0 0 0 1 0 0 1 0 0 1 0 1 0 1 1 0 1 0 1 1 1 1 0 0 1 1 1 1 0 1\n",
            " 0 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 1 0 1 0 1 0 0 0 1 1 0 0 0 0 1 1 0 0\n",
            " 0 0 1 0 1 0 0 1 1 1 0 1 1 1 1 1 0 1 1 0 0 0 1 0 1 0 0 1 0 0 1 1 1 0 0 1 1\n",
            " 0 1 0 1 0 0 0 1 0 1 0 1 1 0 1 1 0 1 1 0 0 1 1 0 1 1 1 1 1 1 1 1 1 1 0 0 1\n",
            " 0 1 1 1 0 1 1 1 1 0 1 0 0 0 0 1 1 0 1 0 1 1 0 1 1 1 1 1 0 1 0 1 1 0 0 1 0\n",
            " 1 0 0 1 0 0 1 1 1 1 1 1 0 1 1 0 1 0 1 1 0 1 1 0 1 1 0 1 1 0 1 1 0 0 1 0 1\n",
            " 1 1 1 1 0 0 1 0 1 1 1 1 1 0 1 1 0 0 0 1 1 1 1 1 1 0 1 1 1 1 0 0 0 1 1 1 0\n",
            " 1 0 0 1 1 1 0 1 1 0 0 1 0 0 1 0 1 0 1 0 0 1 1 1 1 0 0 1 0 1 1 1 1 0 0 0 0\n",
            " 1 1 1 0 1 0 1 0 1 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1 0 0 1 1 1 1 0 0 0 0 1 1 0\n",
            " 0 1 0 1 1 1 0 1 0 1 1 0 0 0 1 0 0 1 0 1 1 1 1 0 1 0 1 0 0 0 0 1 0 1 1 1 1\n",
            " 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 1 0 1 1 1 1 0 1 0 0 0 0 0 1 0 0 1\n",
            " 0 1 1 0 1 1 0 0 0 1 0 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 1 0 1 0\n",
            " 1 1 0 0 1 1 1 0 1 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 0 0 1 0 1 1 0 1 0 0 0 1\n",
            " 1 0 1 1 0 1 0 1 0 1 1 1 1 1 1 0 1 0 1 0 0 1 0 0 0 0 1 1 0 0 1 1 1 1 0 1 0\n",
            " 0 1 1 0 1 1 1 0 0 1 0 1 1 1 0 0 0]\n",
            "probabilities: (942, 2) \n",
            " [1 1 0 1 1 0 0 0 0 0 1 1 1 1 0 1 0 1 0 0 1 0 0 1 1 1 1 0 1 1 1 0 0 1 1 0 0\n",
            " 0 0 1 0 1 0 0 0 1 0 1 1 1 1 1 1 1 1 0 1 0 1 0 0 1 1 1 1 1 1 0 1 0 1 1 0 0\n",
            " 0 0 0 0 1 1 0 1 1 1 0 1 0 0 1 1 1 0 0 0 1 0 1 0 0 0 1 0 0 1 0 1 1 1 0 1 0\n",
            " 1 0 0 1 0 0 0 0 0 0 1 1 1 1 0 0 0 1 1 0 1 0 1 1 1 1 1 1 0 1 0 1 0 0 1 1 0\n",
            " 1 1 1 1 0 0 1 0 0 0 1 1 0 1 1 0 1 1 1 0 1 1 0 0 1 1 0 1 1 1 0 0 0 0 0 1 0\n",
            " 0 1 1 1 0 1 0 0 0 0 0 1 1 1 0 1 1 0 0 0 0 1 0 1 1 0 0 1 1 0 0 0 0 0 1 1 1\n",
            " 0 1 1 1 0 0 1 0 0 1 1 1 0 1 1 0 1 1 0 1 0 1 1 0 1 1 1 1 1 1 1 0 1 1 0 1 1\n",
            " 0 0 0 1 1 1 1 1 0 0 1 0 1 0 0 1 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 1 1 1 1 1 1\n",
            " 1 0 1 1 0 1 0 1 0 1 0 1 0 0 0 1 1 1 0 0 1 0 1 0 1 0 0 0 1 1 1 0 0 1 1 1 1\n",
            " 0 1 0 1 1 0 0 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 0 0 0 1 1 0 1 1 0 1 0\n",
            " 1 1 0 1 0 1 0 1 0 0 1 1 1 1 0 1 1 0 1 0 1 0 1 1 0 1 0 1 1 0 0 1 0 1 1 1 0\n",
            " 1 1 0 0 0 1 1 0 0 0 1 0 0 1 0 0 1 0 1 0 1 1 0 1 0 1 1 1 1 0 0 1 1 1 1 0 1\n",
            " 0 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 1 0 1 0 1 0 0 0 1 1 0 0 0 0 1 1 0 0\n",
            " 0 0 1 0 1 0 0 1 1 1 0 1 1 1 1 1 0 1 1 0 0 0 1 0 1 0 0 1 0 0 1 1 1 0 0 1 1\n",
            " 0 1 0 1 0 0 0 1 0 1 0 1 1 0 1 1 0 1 1 0 0 1 1 0 1 1 1 1 1 1 1 1 1 1 0 0 1\n",
            " 0 1 1 1 0 1 1 1 1 0 1 0 0 0 0 1 1 0 1 0 1 1 0 1 1 1 1 1 0 1 0 1 1 0 0 1 0\n",
            " 1 0 0 1 0 0 1 1 1 1 1 1 0 1 1 0 1 0 1 1 0 1 1 0 1 1 0 1 1 0 1 1 0 0 1 0 1\n",
            " 1 1 1 1 0 0 1 0 1 1 1 1 1 0 1 1 0 0 0 1 1 1 1 1 1 0 1 1 1 1 0 0 0 1 1 1 0\n",
            " 1 0 0 1 1 1 0 1 1 0 0 1 0 0 1 0 1 0 1 0 0 1 1 1 1 0 0 1 0 1 1 1 1 0 0 0 0\n",
            " 1 1 1 0 1 0 1 0 1 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1 0 0 1 1 1 1 0 0 0 0 1 1 0\n",
            " 0 1 0 1 1 1 0 1 0 1 1 0 0 0 1 0 0 1 0 1 1 1 1 0 1 0 1 0 0 0 0 1 0 1 1 1 1\n",
            " 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 1 0 1 1 1 1 0 1 0 0 0 0 0 1 0 0 1\n",
            " 0 1 1 0 1 1 0 0 0 1 0 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 1 0 1 0\n",
            " 1 1 0 0 1 1 1 0 1 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 0 0 1 0 1 1 0 1 0 0 0 1\n",
            " 1 0 1 1 0 1 0 1 0 1 1 1 1 1 1 0 1 0 1 0 0 1 0 0 0 0 1 1 0 0 1 1 1 1 0 1 0\n",
            " 0 1 1 0 1 1 1 0 0 1 0 1 1 1 0 0 0]\n",
            "trainset before adding uncertain samples (360, 10) (360,)\n",
            "trainset after adding uncertain samples (370, 10) (370,)\n",
            "updated train set: (370, 10) (370,) unique(labels): [183 187] [0 1]\n",
            "val set: (932, 10) (932,)\n",
            "\n",
            "Train set: (370, 10)\n",
            "Validation set: (932, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 37\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.066 s \n",
            "\n",
            "Accuracy rate is 81.797235 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.91      0.88       321\n",
            "           1       0.68      0.57      0.62       113\n",
            "\n",
            "    accuracy                           0.82       434\n",
            "   macro avg       0.77      0.74      0.75       434\n",
            "weighted avg       0.81      0.82      0.81       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[291  30]\n",
            " [ 49  64]]\n",
            "--------------------------------\n",
            "val predicted: (932,) [1 1 0 1 1 0 0 0 0 0 1 1 1 1 0 1 0 1 0 0 1 0 0 1 1 1 1 0 1 1 1 0 0 1 1 0 0\n",
            " 0 0 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 0 1 0 0 1 1 1 1 1 1 0 1 0 1 1 0 0 0\n",
            " 0 0 0 1 1 0 1 1 1 0 1 0 0 1 1 1 0 0 0 1 0 1 0 0 0 1 0 0 1 0 1 1 1 0 1 0 1\n",
            " 0 0 1 0 0 0 0 0 1 1 1 1 0 1 0 1 1 0 1 0 1 1 1 1 1 1 0 1 0 1 0 0 1 1 0 1 1\n",
            " 1 1 0 0 1 0 0 0 1 1 0 1 1 0 1 1 1 0 1 1 0 0 1 1 0 1 1 1 0 0 0 0 0 1 0 0 1\n",
            " 1 1 0 1 0 0 0 0 1 1 1 0 1 1 0 0 0 0 1 0 1 1 0 0 1 1 0 0 0 0 0 1 1 1 0 1 1\n",
            " 1 0 0 1 0 0 1 1 1 0 1 1 0 1 1 0 1 0 1 1 0 1 1 1 1 1 1 1 1 0 1 1 0 0 0 1 1\n",
            " 1 1 1 0 0 1 0 1 0 0 1 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 1 1 1 1 1 1 1 0 1 1 0\n",
            " 1 0 1 0 1 0 1 0 0 0 1 1 1 0 0 1 0 1 0 1 0 0 0 1 1 1 0 0 1 1 1 1 0 1 0 1 1\n",
            " 0 0 1 0 1 0 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 0 0 0 1 1 0 1 1 0 0 0 1 1 0 1 0\n",
            " 1 0 1 0 0 1 1 1 1 0 1 1 0 1 1 0 1 1 0 1 0 1 1 0 0 1 0 1 1 1 0 1 1 0 0 0 1\n",
            " 1 0 0 0 1 0 0 1 0 0 1 0 1 0 1 1 0 1 0 1 1 1 1 0 0 1 1 1 1 0 1 0 1 1 0 0 0\n",
            " 0 0 0 0 0 1 1 1 1 1 0 0 0 1 0 1 0 1 0 0 1 1 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0\n",
            " 1 1 1 0 1 1 1 1 1 0 1 1 0 0 0 1 0 1 0 0 1 0 0 1 1 1 0 0 1 1 0 1 1 0 0 0 1\n",
            " 0 1 0 1 1 0 1 1 0 1 1 0 0 1 1 0 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1 0 1 1 1\n",
            " 1 0 1 0 0 0 0 1 1 0 1 0 1 1 0 1 1 1 1 1 0 1 0 1 1 0 0 1 0 1 0 0 1 0 0 1 1\n",
            " 1 1 1 1 0 1 1 0 1 0 1 1 0 1 1 0 1 1 0 1 1 0 1 1 0 0 1 0 1 1 1 1 1 0 0 1 0\n",
            " 1 1 1 1 1 0 1 1 0 0 0 1 1 1 1 1 1 0 1 1 1 0 0 0 1 1 1 0 1 0 0 1 1 0 1 1 0\n",
            " 0 1 0 0 1 0 1 0 1 0 0 1 1 1 1 0 0 1 0 1 1 1 1 0 0 0 0 1 1 1 0 1 0 1 0 1 0\n",
            " 1 1 0 0 1 0 0 1 1 1 0 0 0 1 0 0 1 1 1 1 0 0 0 0 1 1 0 0 1 0 1 1 1 0 1 0 1\n",
            " 1 0 0 0 1 0 0 1 0 1 1 1 1 0 1 0 1 0 0 0 0 1 0 1 1 1 1 1 1 1 0 1 0 0 1 1 1\n",
            " 1 1 1 1 1 0 0 0 0 0 1 0 1 1 1 1 0 1 0 0 0 0 0 1 0 0 1 0 1 1 0 1 1 0 0 0 1\n",
            " 0 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 1 0 1 0 1 1 0 0 1 1 1 0 1 1\n",
            " 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 0 0 1 0 1 1 0 1 0 0 0 1 1 0 1 1 0 1 0 1 0 1\n",
            " 1 1 1 1 1 0 1 0 1 0 0 1 0 0 0 0 1 1 0 0 1 1 1 1 0 1 0 0 1 1 0 1 1 1 0 0 1\n",
            " 0 1 1 1 0 0 0]\n",
            "probabilities: (932, 2) \n",
            " [1 1 0 1 1 0 0 0 0 0 1 1 1 1 0 1 0 1 0 0 1 0 0 1 1 1 1 0 1 1 1 0 0 1 1 0 0\n",
            " 0 0 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 0 1 0 0 1 1 1 1 1 1 0 1 0 1 1 0 0 0\n",
            " 0 0 0 1 1 0 1 1 1 0 1 0 0 1 1 1 0 0 0 1 0 1 0 0 0 1 0 0 1 0 1 1 1 0 1 0 1\n",
            " 0 0 1 0 0 0 0 0 1 1 1 1 0 1 0 1 1 0 1 0 1 1 1 1 1 1 0 1 0 1 0 0 1 1 0 1 1\n",
            " 1 1 0 0 1 0 0 0 1 1 0 1 1 0 1 1 1 0 1 1 0 0 1 1 0 1 1 1 0 0 0 0 0 1 0 0 1\n",
            " 1 1 0 1 0 0 0 0 1 1 1 0 1 1 0 0 0 0 1 0 1 1 0 0 1 1 0 0 0 0 0 1 1 1 0 1 1\n",
            " 1 0 0 1 0 0 1 1 1 0 1 1 0 1 1 0 1 0 1 1 0 1 1 1 1 1 1 1 1 0 1 1 0 0 0 1 1\n",
            " 1 1 1 0 0 1 0 1 0 0 1 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 1 1 1 1 1 1 1 0 1 1 0\n",
            " 1 0 1 0 1 0 1 0 0 0 1 1 1 0 0 1 0 1 0 1 0 0 0 1 1 1 0 0 1 1 1 1 0 1 0 1 1\n",
            " 0 0 1 0 1 0 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 0 0 0 1 1 0 1 1 0 0 0 1 1 0 1 0\n",
            " 1 0 1 0 0 1 1 1 1 0 1 1 0 1 1 0 1 1 0 1 0 1 1 0 0 1 0 1 1 1 0 1 1 0 0 0 1\n",
            " 1 0 0 0 1 0 0 1 0 0 1 0 1 0 1 1 0 1 0 1 1 1 1 0 0 1 1 1 1 0 1 0 1 1 0 0 0\n",
            " 0 0 0 0 0 1 1 1 1 1 0 0 0 1 0 1 0 1 0 0 1 1 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0\n",
            " 1 1 1 0 1 1 1 1 1 0 1 1 0 0 0 1 0 1 0 0 1 0 0 1 1 1 0 0 1 1 0 1 1 0 0 0 1\n",
            " 0 1 0 1 1 0 1 1 0 1 1 0 0 1 1 0 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1 0 1 1 1\n",
            " 1 0 1 0 0 0 0 1 1 0 1 0 1 1 0 1 1 1 1 1 0 1 0 1 1 0 0 1 0 1 0 0 1 0 0 1 1\n",
            " 1 1 1 1 0 1 1 0 1 0 1 1 0 1 1 0 1 1 0 1 1 0 1 1 0 0 1 0 1 1 1 1 1 0 0 1 0\n",
            " 1 1 1 1 1 0 1 1 0 0 0 1 1 1 1 1 1 0 1 1 1 0 0 0 1 1 1 0 1 0 0 1 1 0 1 1 0\n",
            " 0 1 0 0 1 0 1 0 1 0 0 1 1 1 1 0 0 1 0 1 1 1 1 0 0 0 0 1 1 1 0 1 0 1 0 1 0\n",
            " 1 1 0 0 1 0 0 1 1 1 0 0 0 1 0 0 1 1 1 1 0 0 0 0 1 1 0 0 1 0 1 1 1 0 1 0 1\n",
            " 1 0 0 0 1 0 0 1 0 1 1 1 1 0 1 0 1 0 0 0 0 1 0 1 1 1 1 1 1 1 0 1 0 0 1 1 1\n",
            " 1 1 1 1 1 0 0 0 0 0 1 0 1 1 1 1 0 1 0 0 0 0 0 1 0 0 1 0 1 1 0 1 1 0 0 0 1\n",
            " 0 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 1 0 1 0 1 1 0 0 1 1 1 0 1 1\n",
            " 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 0 0 1 0 1 1 0 1 0 0 0 1 1 0 1 1 0 1 0 1 0 1\n",
            " 1 1 1 1 1 0 1 0 1 0 0 1 0 0 0 0 1 1 0 0 1 1 1 1 0 1 0 0 1 1 0 1 1 1 0 0 1\n",
            " 0 1 1 1 0 0 0]\n",
            "trainset before adding uncertain samples (370, 10) (370,)\n",
            "trainset after adding uncertain samples (380, 10) (380,)\n",
            "updated train set: (380, 10) (380,) unique(labels): [190 190] [0 1]\n",
            "val set: (922, 10) (922,)\n",
            "\n",
            "Train set: (380, 10)\n",
            "Validation set: (922, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 38\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.070 s \n",
            "\n",
            "Accuracy rate is 79.032258 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.89      0.86       321\n",
            "           1       0.62      0.50      0.56       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.73      0.70      0.71       434\n",
            "weighted avg       0.78      0.79      0.78       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[286  35]\n",
            " [ 56  57]]\n",
            "--------------------------------\n",
            "val predicted: (922,) [1 1 0 1 1 0 0 0 0 0 1 1 1 1 0 1 0 1 0 0 1 0 0 1 1 1 1 0 1 1 1 0 0 1 1 0 0\n",
            " 0 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 0 1 0 0 1 1 1 1 1 1 0 1 0 1 1 0 0 0 0\n",
            " 0 0 1 1 0 1 1 0 1 0 0 1 1 1 0 0 0 1 0 1 0 0 0 1 0 0 1 0 1 1 1 0 1 0 1 0 0\n",
            " 1 0 0 0 0 0 1 1 1 1 0 0 0 1 1 0 1 0 1 1 1 1 1 1 0 1 0 1 0 0 1 1 0 1 1 1 1\n",
            " 0 0 1 0 0 0 1 1 0 1 1 0 1 1 1 0 1 1 0 0 1 1 0 1 1 1 0 0 0 0 0 1 0 0 1 1 1\n",
            " 0 1 0 0 0 0 1 1 1 0 0 1 0 0 0 0 1 0 1 1 0 0 1 1 0 0 0 0 0 1 1 1 0 1 1 1 0\n",
            " 0 1 0 0 1 1 1 0 1 1 0 1 1 0 1 0 1 1 0 1 1 1 1 1 1 1 1 0 1 1 0 0 0 1 1 1 1\n",
            " 1 0 0 1 0 1 0 0 1 0 1 0 1 0 1 0 0 0 1 0 1 0 0 0 1 1 1 1 1 1 1 0 1 1 0 1 0\n",
            " 1 0 1 0 1 0 0 0 1 1 1 0 0 1 0 1 1 0 0 0 1 1 1 0 0 1 1 1 1 0 1 0 1 1 0 0 1\n",
            " 1 0 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 0 0 0 1 1 0 1 1 0 0 1 1 0 1 0 1 0 1 0 0\n",
            " 1 1 1 1 0 1 1 0 1 1 0 1 1 0 1 0 1 1 0 0 1 0 1 1 1 0 1 1 0 0 0 1 1 0 0 1 0\n",
            " 0 1 0 0 1 0 1 0 1 1 0 1 0 1 1 1 1 0 0 1 1 1 1 0 1 0 1 1 0 0 0 0 0 0 0 0 1\n",
            " 1 1 1 1 0 0 0 1 0 1 0 1 0 0 1 1 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 1 1 1 0 1 1\n",
            " 1 1 1 0 1 1 0 0 0 1 0 1 0 0 1 0 0 1 1 1 0 0 1 1 0 1 1 0 0 0 1 0 1 0 1 1 0\n",
            " 1 1 0 1 1 0 0 1 1 0 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1 0 1 1 1 1 0 1 0 0 0\n",
            " 0 1 1 0 1 0 1 1 0 1 1 1 1 1 0 1 0 1 1 0 0 1 0 1 0 0 1 0 0 1 1 1 1 1 1 0 1\n",
            " 1 0 1 0 1 1 0 1 1 0 1 1 0 1 1 0 1 1 0 0 1 0 1 1 1 1 1 0 0 1 0 1 1 1 1 1 0\n",
            " 1 1 0 0 0 1 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 1 0 0 1 1 0 1 1 0 1 0 0 1 0 1 0\n",
            " 1 0 0 1 1 1 1 0 0 1 0 1 1 1 1 0 0 0 0 1 1 1 0 1 0 0 0 1 0 1 1 0 0 1 0 0 1\n",
            " 1 1 0 0 0 1 0 0 1 1 1 1 0 0 0 0 1 1 0 0 1 0 1 1 1 0 1 0 1 1 0 0 0 1 0 0 1\n",
            " 0 1 1 1 1 0 1 0 1 0 0 0 0 1 0 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 0 0 0\n",
            " 0 0 1 0 1 1 1 1 0 1 0 0 0 0 0 1 0 0 1 0 1 1 0 1 1 0 0 0 1 1 1 0 0 1 0 1 1\n",
            " 1 1 0 1 1 1 0 0 1 1 1 1 1 1 0 1 0 1 1 0 0 1 1 1 0 1 1 1 1 1 1 1 0 1 1 0 0\n",
            " 1 1 0 1 0 0 0 1 0 1 1 0 1 0 0 0 1 1 0 1 1 0 1 0 1 0 1 1 1 1 1 1 0 1 0 1 0\n",
            " 0 1 0 0 0 0 1 1 0 0 1 1 1 1 0 1 0 0 1 1 0 1 1 1 0 0 1 0 1 1 1 0 0 0]\n",
            "probabilities: (922, 2) \n",
            " [1 1 0 1 1 0 0 0 0 0 1 1 1 1 0 1 0 1 0 0 1 0 0 1 1 1 1 0 1 1 1 0 0 1 1 0 0\n",
            " 0 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 0 1 0 0 1 1 1 1 1 1 0 1 0 1 1 0 0 0 0\n",
            " 0 0 1 1 0 1 1 0 1 0 0 1 1 1 0 0 0 1 0 1 0 0 0 1 0 0 1 0 1 1 1 0 1 0 1 0 0\n",
            " 1 0 0 0 0 0 1 1 1 1 0 0 0 1 1 0 1 0 1 1 1 1 1 1 0 1 0 1 0 0 1 1 0 1 1 1 1\n",
            " 0 0 1 0 0 0 1 1 0 1 1 0 1 1 1 0 1 1 0 0 1 1 0 1 1 1 0 0 0 0 0 1 0 0 1 1 1\n",
            " 0 1 0 0 0 0 1 1 1 0 0 1 0 0 0 0 1 0 1 1 0 0 1 1 0 0 0 0 0 1 1 1 0 1 1 1 0\n",
            " 0 1 0 0 1 1 1 0 1 1 0 1 1 0 1 0 1 1 0 1 1 1 1 1 1 1 1 0 1 1 0 0 0 1 1 1 1\n",
            " 1 0 0 1 0 1 0 0 1 0 1 0 1 0 1 0 0 0 1 0 1 0 0 0 1 1 1 1 1 1 1 0 1 1 0 1 0\n",
            " 1 0 1 0 1 0 0 0 1 1 1 0 0 1 0 1 1 0 0 0 1 1 1 0 0 1 1 1 1 0 1 0 1 1 0 0 1\n",
            " 1 0 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 0 0 0 1 1 0 1 1 0 0 1 1 0 1 0 1 0 1 0 0\n",
            " 1 1 1 1 0 1 1 0 1 1 0 1 1 0 1 0 1 1 0 0 1 0 1 1 1 0 1 1 0 0 0 1 1 0 0 1 0\n",
            " 0 1 0 0 1 0 1 0 1 1 0 1 0 1 1 1 1 0 0 1 1 1 1 0 1 0 1 1 0 0 0 0 0 0 0 0 1\n",
            " 1 1 1 1 0 0 0 1 0 1 0 1 0 0 1 1 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 1 1 1 0 1 1\n",
            " 1 1 1 0 1 1 0 0 0 1 0 1 0 0 1 0 0 1 1 1 0 0 1 1 0 1 1 0 0 0 1 0 1 0 1 1 0\n",
            " 1 1 0 1 1 0 0 1 1 0 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1 0 1 1 1 1 0 1 0 0 0\n",
            " 0 1 1 0 1 0 1 1 0 1 1 1 1 1 0 1 0 1 1 0 0 1 0 1 0 0 1 0 0 1 1 1 1 1 1 0 1\n",
            " 1 0 1 0 1 1 0 1 1 0 1 1 0 1 1 0 1 1 0 0 1 0 1 1 1 1 1 0 0 1 0 1 1 1 1 1 0\n",
            " 1 1 0 0 0 1 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 1 0 0 1 1 0 1 1 0 1 0 0 1 0 1 0\n",
            " 1 0 0 1 1 1 1 0 0 1 0 1 1 1 1 0 0 0 0 1 1 1 0 1 0 0 0 1 0 1 1 0 0 1 0 0 1\n",
            " 1 1 0 0 0 1 0 0 1 1 1 1 0 0 0 0 1 1 0 0 1 0 1 1 1 0 1 0 1 1 0 0 0 1 0 0 1\n",
            " 0 1 1 1 1 0 1 0 1 0 0 0 0 1 0 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 0 0 0\n",
            " 0 0 1 0 1 1 1 1 0 1 0 0 0 0 0 1 0 0 1 0 1 1 0 1 1 0 0 0 1 1 1 0 0 1 0 1 1\n",
            " 1 1 0 1 1 1 0 0 1 1 1 1 1 1 0 1 0 1 1 0 0 1 1 1 0 1 1 1 1 1 1 1 0 1 1 0 0\n",
            " 1 1 0 1 0 0 0 1 0 1 1 0 1 0 0 0 1 1 0 1 1 0 1 0 1 0 1 1 1 1 1 1 0 1 0 1 0\n",
            " 0 1 0 0 0 0 1 1 0 0 1 1 1 1 0 1 0 0 1 1 0 1 1 1 0 0 1 0 1 1 1 0 0 0]\n",
            "trainset before adding uncertain samples (380, 10) (380,)\n",
            "trainset after adding uncertain samples (390, 10) (390,)\n",
            "updated train set: (390, 10) (390,) unique(labels): [196 194] [0 1]\n",
            "val set: (912, 10) (912,)\n",
            "\n",
            "Train set: (390, 10)\n",
            "Validation set: (912, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 39\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.084 s \n",
            "\n",
            "Accuracy rate is 78.341014 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86       321\n",
            "           1       0.60      0.51      0.55       113\n",
            "\n",
            "    accuracy                           0.78       434\n",
            "   macro avg       0.72      0.70      0.70       434\n",
            "weighted avg       0.77      0.78      0.78       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[282  39]\n",
            " [ 55  58]]\n",
            "--------------------------------\n",
            "val predicted: (912,) [1 1 0 1 1 0 0 0 0 0 1 1 1 1 0 1 0 1 0 0 1 0 0 1 1 1 1 0 1 1 1 0 0 1 1 0 0\n",
            " 0 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 0 1 0 0 1 1 1 1 1 1 0 1 0 1 1 0 0 0 0\n",
            " 0 0 1 1 0 1 1 0 1 0 0 1 1 1 0 0 0 1 0 1 0 0 0 1 0 0 1 0 1 1 1 0 0 1 0 0 1\n",
            " 0 0 0 0 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 1 1 0 1 0 1 0 0 1 1 0 1 1 1 1 0 0 1\n",
            " 0 0 0 1 1 0 1 1 0 1 1 1 0 1 1 0 0 1 1 0 1 1 1 0 0 0 0 0 1 0 0 1 1 1 0 1 0\n",
            " 0 0 0 1 1 1 0 1 0 0 0 0 1 0 1 1 0 0 1 1 0 0 0 0 0 1 1 1 0 1 1 1 0 0 1 0 0\n",
            " 1 1 1 0 1 1 0 1 1 0 1 0 1 1 0 1 1 1 1 1 1 1 1 0 1 1 0 0 0 1 1 1 1 1 0 0 1\n",
            " 0 1 0 0 1 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 1 1 1 1 1 1 1 0 1 1 0 1 0 1 0 1 0\n",
            " 1 0 0 0 1 1 1 0 0 1 0 1 1 0 0 0 1 1 1 0 0 1 1 1 1 0 1 0 1 1 0 0 1 1 1 1 1\n",
            " 1 1 1 1 1 0 1 1 1 1 0 0 0 1 1 0 1 0 1 1 0 1 0 1 0 1 0 0 1 1 1 1 0 1 1 0 1\n",
            " 1 0 1 1 0 1 0 1 1 0 1 0 1 1 1 0 1 1 0 0 0 1 1 0 0 1 0 0 1 0 0 1 0 1 0 1 1\n",
            " 0 1 0 1 1 1 1 0 0 1 1 1 1 0 1 0 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 1 0 1\n",
            " 0 1 0 0 1 1 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 1 1 1 0 1 1 1 1 1 0 1 1 0 0 0 1\n",
            " 0 1 0 0 1 0 0 1 1 1 0 0 1 1 0 1 1 0 0 0 1 0 1 0 1 1 0 1 1 0 1 1 0 0 1 1 0\n",
            " 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1 0 1 1 1 1 0 1 0 0 0 0 1 1 0 1 0 1 1 0 1\n",
            " 1 1 1 1 0 1 0 1 1 0 0 1 0 1 0 0 1 0 0 1 1 1 1 1 1 0 1 1 0 1 0 1 1 0 1 1 0\n",
            " 1 1 0 1 1 0 1 1 0 0 1 0 1 1 1 1 1 0 0 1 0 1 1 1 1 1 0 1 1 0 0 0 1 1 1 1 1\n",
            " 1 0 1 1 1 0 0 1 1 1 0 1 0 0 1 1 0 1 1 0 1 0 0 1 0 1 0 1 0 0 1 1 1 1 0 0 1\n",
            " 0 1 1 1 1 0 0 0 0 1 1 1 0 1 0 0 0 1 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1 0 0 1 1\n",
            " 1 1 0 0 0 0 1 1 0 0 1 0 1 1 1 0 1 0 1 1 0 0 0 1 0 0 1 0 1 1 1 1 0 1 0 1 0\n",
            " 0 0 0 1 0 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 1 0 1 1 1 1 0 1\n",
            " 0 0 0 0 0 1 0 0 1 0 1 1 0 1 1 0 0 0 1 1 1 0 0 1 0 1 1 1 1 0 1 1 1 0 0 1 1\n",
            " 1 1 1 1 0 1 0 1 1 0 0 1 1 1 0 1 0 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 0 0 1 0 1\n",
            " 1 0 1 0 0 0 1 1 0 1 1 0 1 0 1 0 1 1 1 1 1 1 0 1 0 1 0 0 1 0 0 0 0 1 1 0 0\n",
            " 1 1 1 1 0 1 0 0 1 1 0 1 1 1 0 0 1 0 1 1 1 0 0 0]\n",
            "probabilities: (912, 2) \n",
            " [1 1 0 1 1 0 0 0 0 0 1 1 1 1 0 1 0 1 0 0 1 0 0 1 1 1 1 0 1 1 1 0 0 1 1 0 0\n",
            " 0 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 0 1 0 0 1 1 1 1 1 1 0 1 0 1 1 0 0 0 0\n",
            " 0 0 1 1 0 1 1 0 1 0 0 1 1 1 0 0 0 1 0 1 0 0 0 1 0 0 1 0 1 1 1 0 0 1 0 0 1\n",
            " 0 0 0 0 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 1 1 0 1 0 1 0 0 1 1 0 1 1 1 1 0 0 1\n",
            " 0 0 0 1 1 0 1 1 0 1 1 1 0 1 1 0 0 1 1 0 1 1 1 0 0 0 0 0 1 0 0 1 1 1 0 1 0\n",
            " 0 0 0 1 1 1 0 1 0 0 0 0 1 0 1 1 0 0 1 1 0 0 0 0 0 1 1 1 0 1 1 1 0 0 1 0 0\n",
            " 1 1 1 0 1 1 0 1 1 0 1 0 1 1 0 1 1 1 1 1 1 1 1 0 1 1 0 0 0 1 1 1 1 1 0 0 1\n",
            " 0 1 0 0 1 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 1 1 1 1 1 1 1 0 1 1 0 1 0 1 0 1 0\n",
            " 1 0 0 0 1 1 1 0 0 1 0 1 1 0 0 0 1 1 1 0 0 1 1 1 1 0 1 0 1 1 0 0 1 1 1 1 1\n",
            " 1 1 1 1 1 0 1 1 1 1 0 0 0 1 1 0 1 0 1 1 0 1 0 1 0 1 0 0 1 1 1 1 0 1 1 0 1\n",
            " 1 0 1 1 0 1 0 1 1 0 1 0 1 1 1 0 1 1 0 0 0 1 1 0 0 1 0 0 1 0 0 1 0 1 0 1 1\n",
            " 0 1 0 1 1 1 1 0 0 1 1 1 1 0 1 0 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 1 0 1\n",
            " 0 1 0 0 1 1 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 1 1 1 0 1 1 1 1 1 0 1 1 0 0 0 1\n",
            " 0 1 0 0 1 0 0 1 1 1 0 0 1 1 0 1 1 0 0 0 1 0 1 0 1 1 0 1 1 0 1 1 0 0 1 1 0\n",
            " 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1 0 1 1 1 1 0 1 0 0 0 0 1 1 0 1 0 1 1 0 1\n",
            " 1 1 1 1 0 1 0 1 1 0 0 1 0 1 0 0 1 0 0 1 1 1 1 1 1 0 1 1 0 1 0 1 1 0 1 1 0\n",
            " 1 1 0 1 1 0 1 1 0 0 1 0 1 1 1 1 1 0 0 1 0 1 1 1 1 1 0 1 1 0 0 0 1 1 1 1 1\n",
            " 1 0 1 1 1 0 0 1 1 1 0 1 0 0 1 1 0 1 1 0 1 0 0 1 0 1 0 1 0 0 1 1 1 1 0 0 1\n",
            " 0 1 1 1 1 0 0 0 0 1 1 1 0 1 0 0 0 1 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1 0 0 1 1\n",
            " 1 1 0 0 0 0 1 1 0 0 1 0 1 1 1 0 1 0 1 1 0 0 0 1 0 0 1 0 1 1 1 1 0 1 0 1 0\n",
            " 0 0 0 1 0 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 1 0 1 1 1 1 0 1\n",
            " 0 0 0 0 0 1 0 0 1 0 1 1 0 1 1 0 0 0 1 1 1 0 0 1 0 1 1 1 1 0 1 1 1 0 0 1 1\n",
            " 1 1 1 1 0 1 0 1 1 0 0 1 1 1 0 1 0 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 0 0 1 0 1\n",
            " 1 0 1 0 0 0 1 1 0 1 1 0 1 0 1 0 1 1 1 1 1 1 0 1 0 1 0 0 1 0 0 0 0 1 1 0 0\n",
            " 1 1 1 1 0 1 0 0 1 1 0 1 1 1 0 0 1 0 1 1 1 0 0 0]\n",
            "trainset before adding uncertain samples (390, 10) (390,)\n",
            "trainset after adding uncertain samples (400, 10) (400,)\n",
            "updated train set: (400, 10) (400,) unique(labels): [201 199] [0 1]\n",
            "val set: (902, 10) (902,)\n",
            "\n",
            "Train set: (400, 10)\n",
            "Validation set: (902, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 40\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.062 s \n",
            "\n",
            "Accuracy rate is 79.032258 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86       321\n",
            "           1       0.61      0.54      0.57       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.73      0.71      0.72       434\n",
            "weighted avg       0.78      0.79      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[282  39]\n",
            " [ 52  61]]\n",
            "--------------------------------\n",
            "val predicted: (902,) [1 1 0 1 1 0 0 0 0 0 1 1 1 1 0 1 0 1 0 0 1 0 0 1 1 1 1 0 1 1 1 0 0 1 1 0 0\n",
            " 0 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 0 1 0 0 1 1 1 1 1 1 0 1 0 1 1 0 0 0 0\n",
            " 0 0 1 1 0 1 1 0 1 0 0 1 1 1 0 0 0 1 0 1 0 0 0 1 0 0 1 0 1 1 1 0 0 1 0 0 1\n",
            " 0 0 0 0 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 1 1 0 1 0 1 0 0 1 1 0 1 1 1 1 0 0 1\n",
            " 0 0 0 1 1 0 1 1 0 1 1 1 0 1 1 0 0 1 1 0 1 1 1 0 0 0 0 0 1 0 0 1 1 1 0 1 0\n",
            " 0 0 0 1 1 0 0 1 0 0 0 0 1 0 1 1 0 0 1 1 0 0 0 0 0 1 1 1 1 1 1 0 0 1 0 0 1\n",
            " 1 1 0 1 1 0 1 1 0 1 0 1 1 0 1 1 1 1 1 1 1 1 0 1 1 0 0 0 1 1 1 1 1 0 0 1 0\n",
            " 1 0 0 1 0 1 0 1 0 1 0 0 0 1 0 0 0 0 1 1 1 1 1 1 1 0 1 1 0 1 0 1 0 1 0 1 0\n",
            " 0 0 1 1 1 0 0 1 0 1 1 0 0 0 1 1 1 0 0 1 1 1 1 0 1 0 1 1 0 0 1 1 1 1 1 1 1\n",
            " 1 1 1 0 1 1 1 1 0 0 0 1 1 0 1 0 1 1 0 1 0 1 0 1 0 0 1 1 1 1 0 1 1 0 1 1 0\n",
            " 1 1 0 1 0 1 1 0 1 0 1 1 1 0 1 1 0 0 1 1 0 0 1 0 0 1 0 0 1 0 1 0 1 1 0 1 0\n",
            " 1 1 1 1 0 0 1 1 1 1 0 1 0 1 1 1 0 0 0 0 0 0 1 1 1 1 1 0 0 0 1 0 1 0 1 0 0\n",
            " 1 1 0 0 0 0 1 1 0 0 0 1 0 1 0 0 1 1 1 0 1 1 1 1 1 0 1 1 0 0 0 1 0 1 0 0 1\n",
            " 0 0 1 1 1 0 0 1 1 0 1 1 0 0 0 1 0 1 0 1 1 0 1 1 0 1 1 0 0 1 1 0 1 1 1 1 1\n",
            " 1 1 1 1 1 0 0 1 0 1 1 1 0 1 1 1 1 0 1 0 0 0 0 1 1 0 1 0 1 1 0 1 1 1 1 1 1\n",
            " 0 1 1 0 0 1 0 1 0 0 1 0 0 1 1 1 1 1 1 0 1 1 0 1 0 1 1 0 1 1 0 1 1 0 1 1 0\n",
            " 1 1 0 0 1 0 1 1 1 1 1 0 0 1 0 1 1 1 1 1 0 1 1 0 0 0 1 1 1 1 1 1 0 1 1 1 0\n",
            " 0 1 1 1 0 1 0 0 1 1 0 1 1 0 1 0 0 1 0 1 0 1 0 1 1 1 1 0 0 1 0 1 1 1 1 0 0\n",
            " 0 0 1 1 1 0 1 0 0 0 1 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1 0 0 1 1 1 1 0 0 0 0 1\n",
            " 1 0 0 1 0 1 1 1 0 1 0 1 1 0 0 0 1 0 0 1 0 1 1 1 1 0 1 0 1 0 0 0 0 1 0 1 1\n",
            " 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 1 0 1 1 1 1 0 1 0 0 0 0 0 1 0 0\n",
            " 1 0 1 1 0 1 1 0 0 1 1 1 0 0 1 0 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 1 0 1 0 1 1\n",
            " 0 0 1 1 1 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 0 0 1 0 1 1 0 1 0 0 0 1 1 0 1\n",
            " 1 0 1 0 1 0 1 1 1 1 1 1 0 1 0 1 0 0 1 0 0 0 0 1 1 0 0 1 1 1 1 0 1 0 0 1 1\n",
            " 0 1 1 1 0 0 1 0 1 1 1 0 0 0]\n",
            "probabilities: (902, 2) \n",
            " [1 1 0 1 1 0 0 0 0 0 1 1 1 1 0 1 0 1 0 0 1 0 0 1 1 1 1 0 1 1 1 0 0 1 1 0 0\n",
            " 0 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 0 1 0 0 1 1 1 1 1 1 0 1 0 1 1 0 0 0 0\n",
            " 0 0 1 1 0 1 1 0 1 0 0 1 1 1 0 0 0 1 0 1 0 0 0 1 0 0 1 0 1 1 1 0 0 1 0 0 1\n",
            " 0 0 0 0 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 1 1 0 1 0 1 0 0 1 1 0 1 1 1 1 0 0 1\n",
            " 0 0 0 1 1 0 1 1 0 1 1 1 0 1 1 0 0 1 1 0 1 1 1 0 0 0 0 0 1 0 0 1 1 1 0 1 0\n",
            " 0 0 0 1 1 0 0 1 0 0 0 0 1 0 1 1 0 0 1 1 0 0 0 0 0 1 1 1 1 1 1 0 0 1 0 0 1\n",
            " 1 1 0 1 1 0 1 1 0 1 0 1 1 0 1 1 1 1 1 1 1 1 0 1 1 0 0 0 1 1 1 1 1 0 0 1 0\n",
            " 1 0 0 1 0 1 0 1 0 1 0 0 0 1 0 0 0 0 1 1 1 1 1 1 1 0 1 1 0 1 0 1 0 1 0 1 0\n",
            " 0 0 1 1 1 0 0 1 0 1 1 0 0 0 1 1 1 0 0 1 1 1 1 0 1 0 1 1 0 0 1 1 1 1 1 1 1\n",
            " 1 1 1 0 1 1 1 1 0 0 0 1 1 0 1 0 1 1 0 1 0 1 0 1 0 0 1 1 1 1 0 1 1 0 1 1 0\n",
            " 1 1 0 1 0 1 1 0 1 0 1 1 1 0 1 1 0 0 1 1 0 0 1 0 0 1 0 0 1 0 1 0 1 1 0 1 0\n",
            " 1 1 1 1 0 0 1 1 1 1 0 1 0 1 1 1 0 0 0 0 0 0 1 1 1 1 1 0 0 0 1 0 1 0 1 0 0\n",
            " 1 1 0 0 0 0 1 1 0 0 0 1 0 1 0 0 1 1 1 0 1 1 1 1 1 0 1 1 0 0 0 1 0 1 0 0 1\n",
            " 0 0 1 1 1 0 0 1 1 0 1 1 0 0 0 1 0 1 0 1 1 0 1 1 0 1 1 0 0 1 1 0 1 1 1 1 1\n",
            " 1 1 1 1 1 0 0 1 0 1 1 1 0 1 1 1 1 0 1 0 0 0 0 1 1 0 1 0 1 1 0 1 1 1 1 1 1\n",
            " 0 1 1 0 0 1 0 1 0 0 1 0 0 1 1 1 1 1 1 0 1 1 0 1 0 1 1 0 1 1 0 1 1 0 1 1 0\n",
            " 1 1 0 0 1 0 1 1 1 1 1 0 0 1 0 1 1 1 1 1 0 1 1 0 0 0 1 1 1 1 1 1 0 1 1 1 0\n",
            " 0 1 1 1 0 1 0 0 1 1 0 1 1 0 1 0 0 1 0 1 0 1 0 1 1 1 1 0 0 1 0 1 1 1 1 0 0\n",
            " 0 0 1 1 1 0 1 0 0 0 1 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1 0 0 1 1 1 1 0 0 0 0 1\n",
            " 1 0 0 1 0 1 1 1 0 1 0 1 1 0 0 0 1 0 0 1 0 1 1 1 1 0 1 0 1 0 0 0 0 1 0 1 1\n",
            " 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 1 0 1 1 1 1 0 1 0 0 0 0 0 1 0 0\n",
            " 1 0 1 1 0 1 1 0 0 1 1 1 0 0 1 0 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 1 0 1 0 1 1\n",
            " 0 0 1 1 1 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 0 0 1 0 1 1 0 1 0 0 0 1 1 0 1\n",
            " 1 0 1 0 1 0 1 1 1 1 1 1 0 1 0 1 0 0 1 0 0 0 0 1 1 0 0 1 1 1 1 0 1 0 0 1 1\n",
            " 0 1 1 1 0 0 1 0 1 1 1 0 0 0]\n",
            "trainset before adding uncertain samples (400, 10) (400,)\n",
            "trainset after adding uncertain samples (410, 10) (410,)\n",
            "updated train set: (410, 10) (410,) unique(labels): [208 202] [0 1]\n",
            "val set: (892, 10) (892,)\n",
            "\n",
            "Train set: (410, 10)\n",
            "Validation set: (892, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 41\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.055 s \n",
            "\n",
            "Accuracy rate is 78.801843 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86       321\n",
            "           1       0.61      0.53      0.57       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.72      0.70      0.71       434\n",
            "weighted avg       0.78      0.79      0.78       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[282  39]\n",
            " [ 53  60]]\n",
            "--------------------------------\n",
            "val predicted: (892,) [1 1 0 1 1 0 0 0 0 0 1 1 1 1 0 1 0 1 0 0 1 0 0 1 1 1 1 0 1 1 1 0 0 1 1 0 0\n",
            " 0 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 0 1 0 0 1 1 1 1 1 1 0 1 0 1 1 0 0 0 0\n",
            " 0 1 1 1 1 0 1 0 0 1 1 1 0 0 0 1 0 1 0 0 0 1 0 0 1 0 1 1 1 0 0 1 0 0 1 0 0\n",
            " 0 0 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 1 1 0 1 0 1 0 0 1 1 0 1 1 1 1 0 0 1 0 0\n",
            " 0 1 1 0 1 1 0 1 1 1 0 1 1 0 0 1 1 0 1 1 1 0 0 0 0 0 1 0 0 1 1 0 1 0 0 0 0\n",
            " 1 1 0 1 0 0 0 0 1 0 1 1 0 0 1 1 0 0 0 0 0 1 1 1 1 1 1 0 0 1 0 0 1 1 1 0 1\n",
            " 1 0 1 1 0 1 0 1 1 0 1 1 1 1 1 1 1 1 0 1 1 0 0 0 1 1 1 1 1 0 0 1 0 1 0 0 1\n",
            " 0 1 0 1 0 1 0 0 0 1 0 0 0 0 1 1 1 1 1 1 1 0 1 1 0 1 0 1 0 1 0 1 0 0 0 1 1\n",
            " 1 0 0 1 0 1 1 0 0 0 1 1 1 0 0 1 1 1 1 0 1 0 1 1 0 0 1 1 1 1 1 1 1 1 1 1 0\n",
            " 1 1 1 1 0 0 0 1 1 0 1 0 1 1 0 1 0 1 0 1 0 0 1 1 1 1 0 1 1 0 1 1 1 1 0 1 0\n",
            " 1 1 0 1 0 1 1 1 0 1 1 0 0 1 1 0 0 1 0 0 1 0 0 1 0 1 0 1 1 0 1 0 1 1 1 1 0\n",
            " 0 1 1 1 1 0 1 0 1 1 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 1 0 1 0 1 0 0 1 1 0 0 0\n",
            " 0 1 1 0 0 0 1 0 1 0 0 1 1 1 0 1 1 1 1 1 0 1 1 0 0 0 1 0 1 0 0 1 0 0 1 1 1\n",
            " 0 0 1 1 0 1 1 0 0 0 1 0 1 0 1 1 0 1 1 0 1 1 0 0 1 1 0 1 1 1 1 1 1 1 1 1 1\n",
            " 0 0 1 0 1 1 1 0 1 1 1 1 1 0 0 0 0 1 1 0 1 1 1 0 1 1 1 1 1 1 0 1 1 0 0 1 0\n",
            " 1 0 0 1 0 0 1 1 1 1 1 1 0 1 1 0 1 0 1 1 0 1 1 0 1 1 0 1 1 0 1 1 0 0 1 0 1\n",
            " 1 1 1 1 0 0 1 0 1 1 1 1 1 0 1 1 0 0 0 1 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 1 0\n",
            " 0 1 1 0 1 1 0 1 0 0 1 0 1 0 1 0 1 1 1 1 0 0 1 0 1 1 1 1 0 0 0 0 1 1 1 0 1\n",
            " 0 0 0 1 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1 0 0 1 1 1 1 0 0 0 0 1 1 0 0 1 0 1 1\n",
            " 1 0 1 0 1 1 0 0 0 1 0 0 1 0 1 1 1 1 0 1 0 1 0 0 0 0 1 0 1 1 1 1 1 1 0 1 0\n",
            " 0 1 1 1 1 1 1 1 1 0 0 0 0 1 0 1 1 1 1 0 1 0 0 0 0 0 1 0 0 1 0 1 1 0 1 1 0\n",
            " 0 1 1 1 0 0 1 0 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 1 0 1 0 1 1 0 1 1 1 0 1 1 1\n",
            " 1 1 1 0 1 1 0 0 1 1 0 1 0 0 0 1 0 1 1 1 0 0 0 1 1 0 1 1 0 1 0 1 0 1 1 1 1\n",
            " 1 1 0 1 0 1 0 0 1 0 0 0 0 1 1 0 0 1 1 1 1 0 1 0 0 1 1 0 1 1 1 0 0 1 0 1 1\n",
            " 1 0 0 0]\n",
            "probabilities: (892, 2) \n",
            " [1 1 0 1 1 0 0 0 0 0 1 1 1 1 0 1 0 1 0 0 1 0 0 1 1 1 1 0 1 1 1 0 0 1 1 0 0\n",
            " 0 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 0 1 0 0 1 1 1 1 1 1 0 1 0 1 1 0 0 0 0\n",
            " 0 1 1 1 1 0 1 0 0 1 1 1 0 0 0 1 0 1 0 0 0 1 0 0 1 0 1 1 1 0 0 1 0 0 1 0 0\n",
            " 0 0 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 1 1 0 1 0 1 0 0 1 1 0 1 1 1 1 0 0 1 0 0\n",
            " 0 1 1 0 1 1 0 1 1 1 0 1 1 0 0 1 1 0 1 1 1 0 0 0 0 0 1 0 0 1 1 0 1 0 0 0 0\n",
            " 1 1 0 1 0 0 0 0 1 0 1 1 0 0 1 1 0 0 0 0 0 1 1 1 1 1 1 0 0 1 0 0 1 1 1 0 1\n",
            " 1 0 1 1 0 1 0 1 1 0 1 1 1 1 1 1 1 1 0 1 1 0 0 0 1 1 1 1 1 0 0 1 0 1 0 0 1\n",
            " 0 1 0 1 0 1 0 0 0 1 0 0 0 0 1 1 1 1 1 1 1 0 1 1 0 1 0 1 0 1 0 1 0 0 0 1 1\n",
            " 1 0 0 1 0 1 1 0 0 0 1 1 1 0 0 1 1 1 1 0 1 0 1 1 0 0 1 1 1 1 1 1 1 1 1 1 0\n",
            " 1 1 1 1 0 0 0 1 1 0 1 0 1 1 0 1 0 1 0 1 0 0 1 1 1 1 0 1 1 0 1 1 1 1 0 1 0\n",
            " 1 1 0 1 0 1 1 1 0 1 1 0 0 1 1 0 0 1 0 0 1 0 0 1 0 1 0 1 1 0 1 0 1 1 1 1 0\n",
            " 0 1 1 1 1 0 1 0 1 1 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 1 0 1 0 1 0 0 1 1 0 0 0\n",
            " 0 1 1 0 0 0 1 0 1 0 0 1 1 1 0 1 1 1 1 1 0 1 1 0 0 0 1 0 1 0 0 1 0 0 1 1 1\n",
            " 0 0 1 1 0 1 1 0 0 0 1 0 1 0 1 1 0 1 1 0 1 1 0 0 1 1 0 1 1 1 1 1 1 1 1 1 1\n",
            " 0 0 1 0 1 1 1 0 1 1 1 1 1 0 0 0 0 1 1 0 1 1 1 0 1 1 1 1 1 1 0 1 1 0 0 1 0\n",
            " 1 0 0 1 0 0 1 1 1 1 1 1 0 1 1 0 1 0 1 1 0 1 1 0 1 1 0 1 1 0 1 1 0 0 1 0 1\n",
            " 1 1 1 1 0 0 1 0 1 1 1 1 1 0 1 1 0 0 0 1 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 1 0\n",
            " 0 1 1 0 1 1 0 1 0 0 1 0 1 0 1 0 1 1 1 1 0 0 1 0 1 1 1 1 0 0 0 0 1 1 1 0 1\n",
            " 0 0 0 1 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1 0 0 1 1 1 1 0 0 0 0 1 1 0 0 1 0 1 1\n",
            " 1 0 1 0 1 1 0 0 0 1 0 0 1 0 1 1 1 1 0 1 0 1 0 0 0 0 1 0 1 1 1 1 1 1 0 1 0\n",
            " 0 1 1 1 1 1 1 1 1 0 0 0 0 1 0 1 1 1 1 0 1 0 0 0 0 0 1 0 0 1 0 1 1 0 1 1 0\n",
            " 0 1 1 1 0 0 1 0 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 1 0 1 0 1 1 0 1 1 1 0 1 1 1\n",
            " 1 1 1 0 1 1 0 0 1 1 0 1 0 0 0 1 0 1 1 1 0 0 0 1 1 0 1 1 0 1 0 1 0 1 1 1 1\n",
            " 1 1 0 1 0 1 0 0 1 0 0 0 0 1 1 0 0 1 1 1 1 0 1 0 0 1 1 0 1 1 1 0 0 1 0 1 1\n",
            " 1 0 0 0]\n",
            "trainset before adding uncertain samples (410, 10) (410,)\n",
            "trainset after adding uncertain samples (420, 10) (420,)\n",
            "updated train set: (420, 10) (420,) unique(labels): [213 207] [0 1]\n",
            "val set: (882, 10) (882,)\n",
            "\n",
            "Train set: (420, 10)\n",
            "Validation set: (882, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 42\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.065 s \n",
            "\n",
            "Accuracy rate is 78.571429 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.87      0.86       321\n",
            "           1       0.60      0.54      0.57       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.72      0.71      0.71       434\n",
            "weighted avg       0.78      0.79      0.78       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[280  41]\n",
            " [ 52  61]]\n",
            "--------------------------------\n",
            "val predicted: (882,) [1 1 0 1 1 0 0 0 0 0 1 1 1 1 0 1 0 1 0 0 1 0 0 1 1 1 1 0 1 1 0 0 1 1 0 0 0\n",
            " 1 0 1 0 0 1 0 1 1 0 1 1 1 1 1 0 1 0 1 0 0 1 1 1 1 1 1 0 1 0 1 1 0 0 0 0 0\n",
            " 1 1 1 1 0 1 0 0 1 1 1 0 0 0 1 0 1 0 0 0 1 0 0 1 0 1 1 1 0 0 1 0 0 1 0 0 0\n",
            " 0 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 1 1 0 1 0 1 0 0 1 1 0 1 1 1 1 0 0 1 0 0 0\n",
            " 1 0 1 1 0 1 1 1 0 1 1 0 0 1 1 0 1 1 1 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 1 1\n",
            " 0 1 0 0 0 0 1 0 1 1 0 0 1 1 0 0 0 0 0 1 1 1 1 1 1 0 0 1 0 0 1 1 1 0 1 1 0\n",
            " 1 1 0 1 0 1 1 0 1 1 1 1 1 1 1 0 1 1 0 0 0 1 1 1 1 1 0 0 1 0 1 0 0 1 0 1 0\n",
            " 1 0 1 0 0 0 1 0 0 0 0 1 1 1 1 1 1 1 0 1 1 0 1 0 1 0 1 0 1 0 0 0 1 1 1 0 0\n",
            " 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 0 1 0 1 1 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1\n",
            " 0 0 0 1 1 0 1 0 1 1 0 1 0 1 0 1 0 0 1 1 1 1 0 1 1 0 1 1 1 1 0 1 0 1 1 0 1\n",
            " 0 1 1 1 0 1 1 0 0 1 1 0 0 1 0 0 1 0 0 1 0 1 0 1 1 0 1 0 1 1 1 1 0 0 1 1 1\n",
            " 1 0 1 0 1 1 0 0 0 0 0 0 1 1 1 1 1 0 0 0 1 0 1 0 1 0 0 1 0 0 0 0 1 1 0 0 1\n",
            " 0 1 0 0 1 1 1 0 1 1 1 1 1 0 1 1 0 0 0 1 0 1 0 0 1 0 0 1 1 1 0 0 1 1 0 1 1\n",
            " 0 0 0 1 0 1 0 1 1 0 1 1 0 1 1 0 0 1 1 0 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1\n",
            " 0 1 1 1 1 1 0 0 0 0 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 0 0 1 0 1 0 0 1 0 0 1 1\n",
            " 1 1 1 1 0 1 1 0 1 0 1 1 0 1 1 0 1 1 0 1 1 0 1 1 0 0 1 0 1 1 1 1 1 0 0 1 0\n",
            " 1 1 0 1 1 0 1 1 0 0 0 1 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 1 0 0 1 1 0 1 1 0 1\n",
            " 0 0 1 0 1 0 1 0 1 1 1 1 0 0 1 0 1 1 1 1 0 0 0 0 1 1 1 0 1 0 0 0 1 0 1 1 0\n",
            " 0 1 0 0 1 1 1 0 0 0 1 0 0 1 1 1 1 0 0 0 0 1 1 0 0 1 0 1 1 1 0 1 0 1 1 0 0\n",
            " 0 1 0 0 1 0 1 1 1 1 0 1 0 1 0 0 0 0 1 0 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1\n",
            " 1 0 0 0 0 1 0 1 1 1 1 0 0 0 0 0 1 0 0 1 0 1 1 0 1 1 0 0 1 1 1 0 0 1 0 1 1\n",
            " 1 1 0 1 1 1 0 0 1 1 1 1 1 1 0 1 0 1 1 0 1 1 1 0 1 1 1 1 1 1 0 1 1 0 0 1 1\n",
            " 0 1 0 0 0 1 0 1 1 1 0 0 0 1 1 0 1 1 0 1 0 1 0 1 1 1 1 1 1 0 1 0 1 0 0 1 0\n",
            " 0 0 0 1 1 0 0 1 1 1 1 0 1 0 0 1 1 0 1 1 0 0 0 1 0 1 1 1 0 0 0]\n",
            "probabilities: (882, 2) \n",
            " [1 1 0 1 1 0 0 0 0 0 1 1 1 1 0 1 0 1 0 0 1 0 0 1 1 1 1 0 1 1 0 0 1 1 0 0 0\n",
            " 1 0 1 0 0 1 0 1 1 0 1 1 1 1 1 0 1 0 1 0 0 1 1 1 1 1 1 0 1 0 1 1 0 0 0 0 0\n",
            " 1 1 1 1 0 1 0 0 1 1 1 0 0 0 1 0 1 0 0 0 1 0 0 1 0 1 1 1 0 0 1 0 0 1 0 0 0\n",
            " 0 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 1 1 0 1 0 1 0 0 1 1 0 1 1 1 1 0 0 1 0 0 0\n",
            " 1 0 1 1 0 1 1 1 0 1 1 0 0 1 1 0 1 1 1 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 1 1\n",
            " 0 1 0 0 0 0 1 0 1 1 0 0 1 1 0 0 0 0 0 1 1 1 1 1 1 0 0 1 0 0 1 1 1 0 1 1 0\n",
            " 1 1 0 1 0 1 1 0 1 1 1 1 1 1 1 0 1 1 0 0 0 1 1 1 1 1 0 0 1 0 1 0 0 1 0 1 0\n",
            " 1 0 1 0 0 0 1 0 0 0 0 1 1 1 1 1 1 1 0 1 1 0 1 0 1 0 1 0 1 0 0 0 1 1 1 0 0\n",
            " 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 0 1 0 1 1 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1\n",
            " 0 0 0 1 1 0 1 0 1 1 0 1 0 1 0 1 0 0 1 1 1 1 0 1 1 0 1 1 1 1 0 1 0 1 1 0 1\n",
            " 0 1 1 1 0 1 1 0 0 1 1 0 0 1 0 0 1 0 0 1 0 1 0 1 1 0 1 0 1 1 1 1 0 0 1 1 1\n",
            " 1 0 1 0 1 1 0 0 0 0 0 0 1 1 1 1 1 0 0 0 1 0 1 0 1 0 0 1 0 0 0 0 1 1 0 0 1\n",
            " 0 1 0 0 1 1 1 0 1 1 1 1 1 0 1 1 0 0 0 1 0 1 0 0 1 0 0 1 1 1 0 0 1 1 0 1 1\n",
            " 0 0 0 1 0 1 0 1 1 0 1 1 0 1 1 0 0 1 1 0 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1\n",
            " 0 1 1 1 1 1 0 0 0 0 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 0 0 1 0 1 0 0 1 0 0 1 1\n",
            " 1 1 1 1 0 1 1 0 1 0 1 1 0 1 1 0 1 1 0 1 1 0 1 1 0 0 1 0 1 1 1 1 1 0 0 1 0\n",
            " 1 1 0 1 1 0 1 1 0 0 0 1 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 1 0 0 1 1 0 1 1 0 1\n",
            " 0 0 1 0 1 0 1 0 1 1 1 1 0 0 1 0 1 1 1 1 0 0 0 0 1 1 1 0 1 0 0 0 1 0 1 1 0\n",
            " 0 1 0 0 1 1 1 0 0 0 1 0 0 1 1 1 1 0 0 0 0 1 1 0 0 1 0 1 1 1 0 1 0 1 1 0 0\n",
            " 0 1 0 0 1 0 1 1 1 1 0 1 0 1 0 0 0 0 1 0 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1\n",
            " 1 0 0 0 0 1 0 1 1 1 1 0 0 0 0 0 1 0 0 1 0 1 1 0 1 1 0 0 1 1 1 0 0 1 0 1 1\n",
            " 1 1 0 1 1 1 0 0 1 1 1 1 1 1 0 1 0 1 1 0 1 1 1 0 1 1 1 1 1 1 0 1 1 0 0 1 1\n",
            " 0 1 0 0 0 1 0 1 1 1 0 0 0 1 1 0 1 1 0 1 0 1 0 1 1 1 1 1 1 0 1 0 1 0 0 1 0\n",
            " 0 0 0 1 1 0 0 1 1 1 1 0 1 0 0 1 1 0 1 1 0 0 0 1 0 1 1 1 0 0 0]\n",
            "trainset before adding uncertain samples (420, 10) (420,)\n",
            "trainset after adding uncertain samples (430, 10) (430,)\n",
            "updated train set: (430, 10) (430,) unique(labels): [218 212] [0 1]\n",
            "val set: (872, 10) (872,)\n",
            "\n",
            "Train set: (430, 10)\n",
            "Validation set: (872, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 43\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.054 s \n",
            "\n",
            "Accuracy rate is 78.341014 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86       321\n",
            "           1       0.60      0.51      0.55       113\n",
            "\n",
            "    accuracy                           0.78       434\n",
            "   macro avg       0.72      0.70      0.70       434\n",
            "weighted avg       0.77      0.78      0.78       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[282  39]\n",
            " [ 55  58]]\n",
            "--------------------------------\n",
            "val predicted: (872,) [1 1 0 1 1 0 0 0 0 0 1 1 1 1 0 1 0 1 0 0 1 0 0 1 1 1 1 0 0 1 0 0 1 1 0 0 1\n",
            " 0 1 0 0 1 0 1 1 1 1 1 1 1 0 1 0 0 0 0 1 1 1 1 1 1 0 1 0 1 1 0 0 0 0 0 1 1\n",
            " 1 1 0 1 0 0 1 1 1 0 0 0 1 0 1 0 0 0 1 0 0 1 0 1 1 1 0 0 1 0 0 1 0 0 0 0 1\n",
            " 1 1 1 0 0 1 1 0 1 0 1 1 1 1 1 1 0 1 0 1 0 0 1 1 0 1 1 1 1 0 0 1 0 0 0 1 0\n",
            " 1 1 0 1 1 1 0 1 1 0 0 1 1 0 1 1 1 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 1 1 0 1 0\n",
            " 0 0 0 1 0 1 1 0 0 1 1 0 0 0 0 0 1 1 1 1 1 1 0 0 1 0 0 1 1 1 0 1 1 0 1 1 0\n",
            " 1 0 1 1 0 1 1 1 1 0 1 1 0 1 1 0 0 0 1 1 1 1 1 0 0 1 0 1 0 0 1 0 1 0 1 0 1\n",
            " 0 0 0 1 0 0 0 0 1 1 1 1 1 1 1 0 1 1 0 1 0 1 0 1 1 0 0 0 1 1 1 0 0 1 0 1 1\n",
            " 0 0 1 1 1 0 0 1 1 1 1 0 1 0 1 1 0 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 0 1 1\n",
            " 0 1 0 1 1 0 1 0 1 0 1 0 0 1 1 1 1 0 1 1 0 1 1 1 1 0 1 0 1 1 0 1 0 1 1 1 0\n",
            " 1 1 0 0 1 1 0 0 1 0 0 1 0 0 1 0 1 0 1 1 0 1 0 1 1 1 1 0 0 1 1 1 1 0 1 0 1\n",
            " 1 0 0 0 0 0 0 1 1 1 1 1 0 0 0 1 0 1 0 1 0 0 1 0 0 0 0 1 1 0 0 1 0 1 0 0 1\n",
            " 1 1 0 1 1 1 1 1 0 1 1 0 0 0 1 0 1 0 0 1 0 0 1 1 1 0 0 1 1 0 1 1 0 0 0 1 0\n",
            " 1 0 1 1 0 0 1 0 1 1 0 0 1 1 0 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1 0 1 1 1 1\n",
            " 1 0 0 0 0 1 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0 0 1 0 1 0 0 1 0 0 1 1 1 1 1 1 0\n",
            " 1 1 0 1 0 1 1 0 1 1 0 1 1 0 1 1 0 1 1 0 0 1 0 1 1 1 1 1 0 0 1 0 1 0 1 1 0\n",
            " 1 1 0 0 1 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 1 0 0 1 1 0 1 1 0 1 0 0 1 0 1 0 1\n",
            " 0 1 1 1 1 0 0 1 0 1 1 1 1 0 0 0 0 1 1 1 0 1 0 0 0 1 0 1 1 0 0 1 0 0 1 1 1\n",
            " 0 0 0 1 0 0 1 1 1 1 0 0 0 0 1 1 0 0 1 0 1 1 1 0 1 0 1 1 0 0 0 1 0 0 1 0 1\n",
            " 1 1 1 0 1 0 1 0 0 0 0 1 0 1 1 1 1 1 1 0 1 0 0 1 0 1 1 1 1 1 1 0 0 0 1 0 1\n",
            " 1 1 1 0 0 0 0 0 1 0 0 1 0 1 1 0 1 1 0 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1 0 0 1\n",
            " 1 1 1 1 1 0 1 0 1 1 0 1 1 1 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 0 0 1 0 1 1\n",
            " 1 0 0 0 1 1 0 1 1 0 1 0 1 0 1 1 1 1 1 1 0 1 0 1 0 0 1 0 0 0 0 1 1 0 0 1 1\n",
            " 1 1 0 1 0 0 1 1 0 1 1 0 0 1 0 1 1 1 0 0 0]\n",
            "probabilities: (872, 2) \n",
            " [1 1 0 1 1 0 0 0 0 0 1 1 1 1 0 1 0 1 0 0 1 0 0 1 1 1 1 0 0 1 0 0 1 1 0 0 1\n",
            " 0 1 0 0 1 0 1 1 1 1 1 1 1 0 1 0 0 0 0 1 1 1 1 1 1 0 1 0 1 1 0 0 0 0 0 1 1\n",
            " 1 1 0 1 0 0 1 1 1 0 0 0 1 0 1 0 0 0 1 0 0 1 0 1 1 1 0 0 1 0 0 1 0 0 0 0 1\n",
            " 1 1 1 0 0 1 1 0 1 0 1 1 1 1 1 1 0 1 0 1 0 0 1 1 0 1 1 1 1 0 0 1 0 0 0 1 0\n",
            " 1 1 0 1 1 1 0 1 1 0 0 1 1 0 1 1 1 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 1 1 0 1 0\n",
            " 0 0 0 1 0 1 1 0 0 1 1 0 0 0 0 0 1 1 1 1 1 1 0 0 1 0 0 1 1 1 0 1 1 0 1 1 0\n",
            " 1 0 1 1 0 1 1 1 1 0 1 1 0 1 1 0 0 0 1 1 1 1 1 0 0 1 0 1 0 0 1 0 1 0 1 0 1\n",
            " 0 0 0 1 0 0 0 0 1 1 1 1 1 1 1 0 1 1 0 1 0 1 0 1 1 0 0 0 1 1 1 0 0 1 0 1 1\n",
            " 0 0 1 1 1 0 0 1 1 1 1 0 1 0 1 1 0 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 0 1 1\n",
            " 0 1 0 1 1 0 1 0 1 0 1 0 0 1 1 1 1 0 1 1 0 1 1 1 1 0 1 0 1 1 0 1 0 1 1 1 0\n",
            " 1 1 0 0 1 1 0 0 1 0 0 1 0 0 1 0 1 0 1 1 0 1 0 1 1 1 1 0 0 1 1 1 1 0 1 0 1\n",
            " 1 0 0 0 0 0 0 1 1 1 1 1 0 0 0 1 0 1 0 1 0 0 1 0 0 0 0 1 1 0 0 1 0 1 0 0 1\n",
            " 1 1 0 1 1 1 1 1 0 1 1 0 0 0 1 0 1 0 0 1 0 0 1 1 1 0 0 1 1 0 1 1 0 0 0 1 0\n",
            " 1 0 1 1 0 0 1 0 1 1 0 0 1 1 0 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1 0 1 1 1 1\n",
            " 1 0 0 0 0 1 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0 0 1 0 1 0 0 1 0 0 1 1 1 1 1 1 0\n",
            " 1 1 0 1 0 1 1 0 1 1 0 1 1 0 1 1 0 1 1 0 0 1 0 1 1 1 1 1 0 0 1 0 1 0 1 1 0\n",
            " 1 1 0 0 1 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 1 0 0 1 1 0 1 1 0 1 0 0 1 0 1 0 1\n",
            " 0 1 1 1 1 0 0 1 0 1 1 1 1 0 0 0 0 1 1 1 0 1 0 0 0 1 0 1 1 0 0 1 0 0 1 1 1\n",
            " 0 0 0 1 0 0 1 1 1 1 0 0 0 0 1 1 0 0 1 0 1 1 1 0 1 0 1 1 0 0 0 1 0 0 1 0 1\n",
            " 1 1 1 0 1 0 1 0 0 0 0 1 0 1 1 1 1 1 1 0 1 0 0 1 0 1 1 1 1 1 1 0 0 0 1 0 1\n",
            " 1 1 1 0 0 0 0 0 1 0 0 1 0 1 1 0 1 1 0 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1 0 0 1\n",
            " 1 1 1 1 1 0 1 0 1 1 0 1 1 1 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 0 0 1 0 1 1\n",
            " 1 0 0 0 1 1 0 1 1 0 1 0 1 0 1 1 1 1 1 1 0 1 0 1 0 0 1 0 0 0 0 1 1 0 0 1 1\n",
            " 1 1 0 1 0 0 1 1 0 1 1 0 0 1 0 1 1 1 0 0 0]\n",
            "trainset before adding uncertain samples (430, 10) (430,)\n",
            "trainset after adding uncertain samples (440, 10) (440,)\n",
            "updated train set: (440, 10) (440,) unique(labels): [220 220] [0 1]\n",
            "val set: (862, 10) (862,)\n",
            "\n",
            "Train set: (440, 10)\n",
            "Validation set: (862, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 44\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.064 s \n",
            "\n",
            "Accuracy rate is 78.341014 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86       321\n",
            "           1       0.60      0.51      0.55       113\n",
            "\n",
            "    accuracy                           0.78       434\n",
            "   macro avg       0.72      0.70      0.70       434\n",
            "weighted avg       0.77      0.78      0.78       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[282  39]\n",
            " [ 55  58]]\n",
            "--------------------------------\n",
            "val predicted: (862,) [1 1 0 1 1 0 0 0 0 0 1 1 1 1 0 1 0 1 0 0 1 0 0 1 1 1 1 0 1 0 0 1 1 0 0 1 0\n",
            " 1 0 0 1 0 1 1 1 1 1 1 1 0 1 0 0 0 1 1 1 1 1 1 0 1 0 1 1 0 0 0 0 0 1 1 1 1\n",
            " 0 1 0 0 1 1 1 0 0 0 1 0 1 0 0 0 1 0 0 1 0 1 1 1 0 0 1 0 0 1 0 0 0 0 1 1 1\n",
            " 0 0 1 1 0 1 0 1 1 1 1 1 1 0 1 0 1 0 0 1 1 0 1 1 1 1 0 0 1 0 0 0 1 0 1 1 0\n",
            " 1 1 1 0 1 0 0 1 1 0 1 1 1 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 1 1 0 1 0 0 0 0 1\n",
            " 0 1 1 0 0 1 1 0 0 0 0 0 1 1 1 1 1 1 0 0 1 0 0 1 1 1 0 0 1 0 1 1 0 1 0 1 1\n",
            " 0 1 1 1 1 1 1 0 1 1 0 0 0 1 1 1 1 1 0 0 1 0 1 0 0 1 0 1 0 1 0 1 0 0 0 1 0\n",
            " 0 0 0 1 1 1 1 1 1 1 0 1 1 0 1 0 1 0 1 1 0 0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1\n",
            " 0 0 1 1 1 1 0 1 0 1 1 0 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 0 1 1 0 1 0 1 1\n",
            " 0 1 0 1 0 1 0 0 1 1 1 1 0 1 1 0 1 1 1 1 0 1 0 1 1 0 1 0 1 1 1 0 1 1 0 0 1\n",
            " 1 0 0 1 0 0 1 0 0 1 0 1 0 1 1 0 1 0 1 1 1 1 0 0 1 1 1 1 0 1 0 1 1 0 0 0 0\n",
            " 0 0 1 1 1 1 1 0 0 0 1 0 1 0 1 0 0 1 0 0 0 0 1 1 0 0 1 0 1 0 0 1 1 1 0 1 1\n",
            " 1 1 1 0 1 1 0 0 0 1 0 1 0 0 1 0 0 1 1 1 0 0 1 1 0 1 1 0 0 0 1 0 1 0 1 1 0\n",
            " 1 0 1 1 0 0 1 1 0 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1 0 1 1 1 1 1 0 0 0 0 1\n",
            " 0 1 1 1 0 1 1 1 1 1 1 1 0 0 1 0 1 0 0 1 0 0 1 1 1 1 1 1 0 1 0 0 1 0 1 1 0\n",
            " 1 1 0 1 1 0 1 1 0 1 1 0 0 1 0 1 1 1 1 1 0 0 1 0 1 1 1 0 1 1 0 0 1 1 1 1 1\n",
            " 1 0 1 1 1 0 0 1 1 1 0 1 0 0 1 1 0 1 1 0 1 0 0 1 0 1 0 1 0 1 1 1 1 0 0 1 0\n",
            " 1 1 1 1 0 0 0 0 1 1 1 0 1 0 0 0 1 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1 0 0 1 1 1\n",
            " 1 0 0 0 0 1 1 0 0 1 0 1 1 1 0 1 0 1 1 0 0 0 1 0 0 1 0 1 1 1 1 0 1 0 1 0 0\n",
            " 0 0 1 0 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 0 0 0 1 0 1 1 1 1 0 0 0 0 0 1 0\n",
            " 0 1 0 1 1 0 1 1 0 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 1 0 1 0 1 1\n",
            " 0 1 1 1 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 0 0 1 0 1 1 1 0 0 0 1 1 0 1 1 0\n",
            " 1 0 1 0 1 1 1 1 1 1 0 1 0 1 0 0 1 0 0 0 0 1 1 0 0 1 1 1 1 0 1 0 0 1 1 0 1\n",
            " 1 0 0 1 0 1 1 1 0 0 0]\n",
            "probabilities: (862, 2) \n",
            " [1 1 0 1 1 0 0 0 0 0 1 1 1 1 0 1 0 1 0 0 1 0 0 1 1 1 1 0 1 0 0 1 1 0 0 1 0\n",
            " 1 0 0 1 0 1 1 1 1 1 1 1 0 1 0 0 0 1 1 1 1 1 1 0 1 0 1 1 0 0 0 0 0 1 1 1 1\n",
            " 0 1 0 0 1 1 1 0 0 0 1 0 1 0 0 0 1 0 0 1 0 1 1 1 0 0 1 0 0 1 0 0 0 0 1 1 1\n",
            " 0 0 1 1 0 1 0 1 1 1 1 1 1 0 1 0 1 0 0 1 1 0 1 1 1 1 0 0 1 0 0 0 1 0 1 1 0\n",
            " 1 1 1 0 1 0 0 1 1 0 1 1 1 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 1 1 0 1 0 0 0 0 1\n",
            " 0 1 1 0 0 1 1 0 0 0 0 0 1 1 1 1 1 1 0 0 1 0 0 1 1 1 0 0 1 0 1 1 0 1 0 1 1\n",
            " 0 1 1 1 1 1 1 0 1 1 0 0 0 1 1 1 1 1 0 0 1 0 1 0 0 1 0 1 0 1 0 1 0 0 0 1 0\n",
            " 0 0 0 1 1 1 1 1 1 1 0 1 1 0 1 0 1 0 1 1 0 0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1\n",
            " 0 0 1 1 1 1 0 1 0 1 1 0 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 0 1 1 0 1 0 1 1\n",
            " 0 1 0 1 0 1 0 0 1 1 1 1 0 1 1 0 1 1 1 1 0 1 0 1 1 0 1 0 1 1 1 0 1 1 0 0 1\n",
            " 1 0 0 1 0 0 1 0 0 1 0 1 0 1 1 0 1 0 1 1 1 1 0 0 1 1 1 1 0 1 0 1 1 0 0 0 0\n",
            " 0 0 1 1 1 1 1 0 0 0 1 0 1 0 1 0 0 1 0 0 0 0 1 1 0 0 1 0 1 0 0 1 1 1 0 1 1\n",
            " 1 1 1 0 1 1 0 0 0 1 0 1 0 0 1 0 0 1 1 1 0 0 1 1 0 1 1 0 0 0 1 0 1 0 1 1 0\n",
            " 1 0 1 1 0 0 1 1 0 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1 0 1 1 1 1 1 0 0 0 0 1\n",
            " 0 1 1 1 0 1 1 1 1 1 1 1 0 0 1 0 1 0 0 1 0 0 1 1 1 1 1 1 0 1 0 0 1 0 1 1 0\n",
            " 1 1 0 1 1 0 1 1 0 1 1 0 0 1 0 1 1 1 1 1 0 0 1 0 1 1 1 0 1 1 0 0 1 1 1 1 1\n",
            " 1 0 1 1 1 0 0 1 1 1 0 1 0 0 1 1 0 1 1 0 1 0 0 1 0 1 0 1 0 1 1 1 1 0 0 1 0\n",
            " 1 1 1 1 0 0 0 0 1 1 1 0 1 0 0 0 1 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1 0 0 1 1 1\n",
            " 1 0 0 0 0 1 1 0 0 1 0 1 1 1 0 1 0 1 1 0 0 0 1 0 0 1 0 1 1 1 1 0 1 0 1 0 0\n",
            " 0 0 1 0 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 0 0 0 1 0 1 1 1 1 0 0 0 0 0 1 0\n",
            " 0 1 0 1 1 0 1 1 0 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 1 0 1 0 1 1\n",
            " 0 1 1 1 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 0 0 1 0 1 1 1 0 0 0 1 1 0 1 1 0\n",
            " 1 0 1 0 1 1 1 1 1 1 0 1 0 1 0 0 1 0 0 0 0 1 1 0 0 1 1 1 1 0 1 0 0 1 1 0 1\n",
            " 1 0 0 1 0 1 1 1 0 0 0]\n",
            "trainset before adding uncertain samples (440, 10) (440,)\n",
            "trainset after adding uncertain samples (450, 10) (450,)\n",
            "updated train set: (450, 10) (450,) unique(labels): [227 223] [0 1]\n",
            "val set: (852, 10) (852,)\n",
            "\n",
            "Train set: (450, 10)\n",
            "Validation set: (852, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 45\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.068 s \n",
            "\n",
            "Accuracy rate is 77.419355 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.87      0.85       321\n",
            "           1       0.58      0.50      0.53       113\n",
            "\n",
            "    accuracy                           0.77       434\n",
            "   macro avg       0.70      0.68      0.69       434\n",
            "weighted avg       0.76      0.77      0.77       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[280  41]\n",
            " [ 57  56]]\n",
            "--------------------------------\n",
            "val predicted: (852,) [1 1 1 1 0 0 0 1 1 1 1 0 1 0 1 0 0 1 0 0 1 1 1 1 0 1 0 0 1 1 0 0 1 0 1 0 0\n",
            " 1 0 1 1 1 1 1 1 1 0 1 0 0 0 1 1 1 1 1 1 0 1 0 1 1 0 0 0 0 0 1 1 1 1 0 1 0\n",
            " 0 1 1 1 0 0 0 1 0 1 0 0 0 1 0 0 1 0 1 1 1 0 0 1 0 0 1 0 0 0 0 1 1 1 0 0 1\n",
            " 1 0 1 0 1 1 1 1 1 1 0 1 0 1 0 0 1 1 0 1 1 1 1 0 0 1 0 0 0 1 0 1 1 0 1 1 1\n",
            " 0 1 0 0 1 1 0 1 1 1 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 1 1 0 1 0 0 0 0 1 0 1 1\n",
            " 0 0 1 1 0 0 0 0 0 1 1 1 1 1 1 0 0 1 0 0 1 1 1 0 1 0 1 1 0 1 0 1 1 0 1 1 1\n",
            " 1 1 1 0 1 1 0 0 0 1 1 1 1 1 0 0 1 0 1 0 0 1 0 1 0 1 0 1 0 0 0 1 0 0 0 0 1\n",
            " 1 1 1 1 1 1 0 1 1 0 1 0 1 0 1 1 0 0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 0 0 1 1 1\n",
            " 1 0 1 0 1 1 0 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 0 1 1 0 1 0 1 1 0 1 0 1 0\n",
            " 1 0 0 1 1 1 1 0 1 1 0 1 1 1 1 0 1 0 1 1 0 1 0 1 1 1 0 1 0 0 1 1 0 0 1 0 0\n",
            " 1 0 0 1 0 1 0 1 1 0 1 0 1 1 1 1 0 0 1 1 1 1 0 1 0 1 1 0 0 0 0 0 0 1 1 1 1\n",
            " 1 0 0 0 1 0 1 0 1 0 0 1 0 0 0 0 1 1 0 0 1 0 1 0 0 1 1 1 0 1 1 1 1 1 0 1 1\n",
            " 0 0 0 1 0 1 0 0 1 0 0 1 1 1 0 0 1 1 0 1 1 0 0 0 1 0 1 0 1 1 0 1 0 1 1 0 0\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1 0 1 1 1 1 1 0 0 0 0 1 0 1 1 1 0 1 1\n",
            " 1 1 1 1 1 0 0 1 0 1 0 0 1 0 0 1 1 1 1 1 1 0 1 0 1 0 1 1 0 1 1 0 1 1 0 1 1\n",
            " 0 1 1 0 0 1 0 1 1 1 1 1 0 0 1 0 1 1 1 0 1 1 0 0 1 1 1 1 1 1 0 1 1 1 0 0 1\n",
            " 1 1 0 1 0 0 1 1 0 1 0 1 0 0 1 0 1 0 1 0 1 1 1 1 0 0 1 0 1 1 1 1 0 0 0 0 1\n",
            " 1 1 0 1 0 0 0 1 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1 0 0 1 1 1 1 0 0 0 0 1 1 0 0\n",
            " 1 0 1 1 1 0 1 0 1 1 0 0 0 1 0 0 1 0 1 1 1 0 0 1 0 1 0 0 0 0 1 0 1 1 1 1 1\n",
            " 1 0 1 0 0 1 1 1 1 1 1 1 0 0 0 1 0 1 1 1 1 0 0 0 0 0 1 0 0 1 0 1 1 0 1 1 0\n",
            " 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 1 0 1 0 1 1 0 1 1 1 1 1 1 1 1\n",
            " 1 0 1 1 0 0 1 1 0 1 0 0 0 1 0 1 1 1 0 0 0 1 1 0 1 1 0 1 0 1 0 1 1 1 1 1 1\n",
            " 0 1 0 1 0 0 1 0 0 0 0 1 1 0 0 1 1 1 1 0 1 0 0 1 1 0 1 1 0 0 1 0 1 1 1 0 0\n",
            " 0]\n",
            "probabilities: (852, 2) \n",
            " [1 1 1 1 0 0 0 1 1 1 1 0 1 0 1 0 0 1 0 0 1 1 1 1 0 1 0 0 1 1 0 0 1 0 1 0 0\n",
            " 1 0 1 1 1 1 1 1 1 0 1 0 0 0 1 1 1 1 1 1 0 1 0 1 1 0 0 0 0 0 1 1 1 1 0 1 0\n",
            " 0 1 1 1 0 0 0 1 0 1 0 0 0 1 0 0 1 0 1 1 1 0 0 1 0 0 1 0 0 0 0 1 1 1 0 0 1\n",
            " 1 0 1 0 1 1 1 1 1 1 0 1 0 1 0 0 1 1 0 1 1 1 1 0 0 1 0 0 0 1 0 1 1 0 1 1 1\n",
            " 0 1 0 0 1 1 0 1 1 1 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 1 1 0 1 0 0 0 0 1 0 1 1\n",
            " 0 0 1 1 0 0 0 0 0 1 1 1 1 1 1 0 0 1 0 0 1 1 1 0 1 0 1 1 0 1 0 1 1 0 1 1 1\n",
            " 1 1 1 0 1 1 0 0 0 1 1 1 1 1 0 0 1 0 1 0 0 1 0 1 0 1 0 1 0 0 0 1 0 0 0 0 1\n",
            " 1 1 1 1 1 1 0 1 1 0 1 0 1 0 1 1 0 0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 0 0 1 1 1\n",
            " 1 0 1 0 1 1 0 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 0 1 1 0 1 0 1 1 0 1 0 1 0\n",
            " 1 0 0 1 1 1 1 0 1 1 0 1 1 1 1 0 1 0 1 1 0 1 0 1 1 1 0 1 0 0 1 1 0 0 1 0 0\n",
            " 1 0 0 1 0 1 0 1 1 0 1 0 1 1 1 1 0 0 1 1 1 1 0 1 0 1 1 0 0 0 0 0 0 1 1 1 1\n",
            " 1 0 0 0 1 0 1 0 1 0 0 1 0 0 0 0 1 1 0 0 1 0 1 0 0 1 1 1 0 1 1 1 1 1 0 1 1\n",
            " 0 0 0 1 0 1 0 0 1 0 0 1 1 1 0 0 1 1 0 1 1 0 0 0 1 0 1 0 1 1 0 1 0 1 1 0 0\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1 0 1 1 1 1 1 0 0 0 0 1 0 1 1 1 0 1 1\n",
            " 1 1 1 1 1 0 0 1 0 1 0 0 1 0 0 1 1 1 1 1 1 0 1 0 1 0 1 1 0 1 1 0 1 1 0 1 1\n",
            " 0 1 1 0 0 1 0 1 1 1 1 1 0 0 1 0 1 1 1 0 1 1 0 0 1 1 1 1 1 1 0 1 1 1 0 0 1\n",
            " 1 1 0 1 0 0 1 1 0 1 0 1 0 0 1 0 1 0 1 0 1 1 1 1 0 0 1 0 1 1 1 1 0 0 0 0 1\n",
            " 1 1 0 1 0 0 0 1 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1 0 0 1 1 1 1 0 0 0 0 1 1 0 0\n",
            " 1 0 1 1 1 0 1 0 1 1 0 0 0 1 0 0 1 0 1 1 1 0 0 1 0 1 0 0 0 0 1 0 1 1 1 1 1\n",
            " 1 0 1 0 0 1 1 1 1 1 1 1 0 0 0 1 0 1 1 1 1 0 0 0 0 0 1 0 0 1 0 1 1 0 1 1 0\n",
            " 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 1 0 1 0 1 1 0 1 1 1 1 1 1 1 1\n",
            " 1 0 1 1 0 0 1 1 0 1 0 0 0 1 0 1 1 1 0 0 0 1 1 0 1 1 0 1 0 1 0 1 1 1 1 1 1\n",
            " 0 1 0 1 0 0 1 0 0 0 0 1 1 0 0 1 1 1 1 0 1 0 0 1 1 0 1 1 0 0 1 0 1 1 1 0 0\n",
            " 0]\n",
            "trainset before adding uncertain samples (450, 10) (450,)\n",
            "trainset after adding uncertain samples (460, 10) (460,)\n",
            "updated train set: (460, 10) (460,) unique(labels): [230 230] [0 1]\n",
            "val set: (842, 10) (842,)\n",
            "\n",
            "Train set: (460, 10)\n",
            "Validation set: (842, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 46\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.063 s \n",
            "\n",
            "Accuracy rate is 78.341014 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86       321\n",
            "           1       0.60      0.52      0.56       113\n",
            "\n",
            "    accuracy                           0.78       434\n",
            "   macro avg       0.72      0.70      0.71       434\n",
            "weighted avg       0.78      0.78      0.78       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[281  40]\n",
            " [ 54  59]]\n",
            "--------------------------------\n",
            "val predicted: (842,) [1 1 1 1 0 0 0 1 1 1 1 0 1 0 1 0 0 1 0 0 1 1 1 1 0 1 0 0 1 1 0 0 1 0 1 0 1\n",
            " 0 1 1 1 1 1 1 1 0 1 0 0 0 1 1 1 1 1 1 0 1 0 1 1 0 0 0 0 0 1 1 1 1 0 1 0 0\n",
            " 1 1 1 0 0 0 1 0 1 0 0 0 1 0 0 1 0 1 1 1 0 1 0 0 1 0 0 0 0 1 1 1 0 0 1 1 0\n",
            " 1 0 1 1 1 1 1 1 0 1 0 1 0 0 1 1 0 1 1 1 1 0 0 1 0 0 0 0 1 1 0 1 1 1 0 1 0\n",
            " 0 1 1 0 1 1 1 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 1 1 0 1 0 0 0 0 1 0 1 1 0 0 1\n",
            " 1 0 0 0 0 0 1 1 1 1 1 1 0 0 1 0 0 1 1 1 0 1 0 1 1 0 1 0 1 1 0 1 1 1 1 1 0\n",
            " 1 1 0 0 0 1 1 1 1 1 0 0 1 0 1 0 0 1 0 1 0 1 0 1 0 0 0 1 0 0 0 0 1 1 1 1 1\n",
            " 1 1 0 1 1 0 1 0 1 0 1 1 0 0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 0 0 1 1 1 1 0 1 0\n",
            " 1 1 0 0 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 0 1 1 0 1 0 1 1 0 1 0 1 0 1 0 0 1 1\n",
            " 1 1 0 1 1 0 1 1 1 1 0 1 0 1 1 0 1 0 1 1 1 0 1 0 0 1 1 0 0 1 0 0 1 0 0 1 0\n",
            " 1 0 1 1 0 0 1 1 1 1 0 0 1 1 1 1 0 1 0 1 1 0 0 0 0 0 0 1 1 1 1 1 0 0 0 1 0\n",
            " 1 0 1 0 0 1 0 0 0 0 1 1 0 0 1 0 1 0 0 1 1 1 0 1 1 1 1 1 0 1 1 0 0 0 1 0 1\n",
            " 0 0 1 0 0 1 1 1 0 0 1 1 0 1 1 0 0 0 1 0 1 0 1 1 0 1 0 1 1 0 0 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 0 0 1 0 1 1 1 0 1 1 1 1 1 0 0 0 0 1 0 1 1 1 0 1 1 1 1 1 1 1 0\n",
            " 0 1 0 1 0 0 1 0 0 1 1 1 1 1 1 0 1 0 1 0 1 1 0 1 1 0 1 1 0 1 1 0 1 1 0 0 1\n",
            " 0 1 1 1 1 0 0 1 0 1 1 1 0 1 1 0 0 1 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 1 0 0 1\n",
            " 1 0 1 0 1 0 0 1 0 1 0 1 0 1 1 1 1 0 0 1 0 1 1 1 1 0 0 0 0 1 1 1 0 1 0 0 1\n",
            " 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1 0 0 1 1 1 1 0 0 0 0 1 1 0 0 1 0 1 1 1 0 1 0\n",
            " 1 1 0 0 0 1 0 0 1 0 1 1 1 0 1 0 1 0 0 0 0 1 0 1 1 1 1 1 1 0 1 0 0 1 1 1 1\n",
            " 1 1 1 0 0 1 0 1 1 1 1 0 0 0 0 0 1 0 0 1 0 1 1 0 1 1 0 0 1 1 0 0 1 0 1 1 1\n",
            " 1 0 1 1 1 0 0 1 1 1 1 1 1 0 1 0 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1\n",
            " 0 0 0 1 0 1 1 1 0 0 0 1 1 0 1 1 0 1 0 1 0 1 1 1 1 1 1 0 1 0 1 0 0 1 0 0 0\n",
            " 0 1 1 0 0 1 1 1 1 0 1 0 0 1 1 0 1 1 0 0 1 0 1 1 1 0 0 0]\n",
            "probabilities: (842, 2) \n",
            " [1 1 1 1 0 0 0 1 1 1 1 0 1 0 1 0 0 1 0 0 1 1 1 1 0 1 0 0 1 1 0 0 1 0 1 0 1\n",
            " 0 1 1 1 1 1 1 1 0 1 0 0 0 1 1 1 1 1 1 0 1 0 1 1 0 0 0 0 0 1 1 1 1 0 1 0 0\n",
            " 1 1 1 0 0 0 1 0 1 0 0 0 1 0 0 1 0 1 1 1 0 1 0 0 1 0 0 0 0 1 1 1 0 0 1 1 0\n",
            " 1 0 1 1 1 1 1 1 0 1 0 1 0 0 1 1 0 1 1 1 1 0 0 1 0 0 0 0 1 1 0 1 1 1 0 1 0\n",
            " 0 1 1 0 1 1 1 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 1 1 0 1 0 0 0 0 1 0 1 1 0 0 1\n",
            " 1 0 0 0 0 0 1 1 1 1 1 1 0 0 1 0 0 1 1 1 0 1 0 1 1 0 1 0 1 1 0 1 1 1 1 1 0\n",
            " 1 1 0 0 0 1 1 1 1 1 0 0 1 0 1 0 0 1 0 1 0 1 0 1 0 0 0 1 0 0 0 0 1 1 1 1 1\n",
            " 1 1 0 1 1 0 1 0 1 0 1 1 0 0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 0 0 1 1 1 1 0 1 0\n",
            " 1 1 0 0 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 0 1 1 0 1 0 1 1 0 1 0 1 0 1 0 0 1 1\n",
            " 1 1 0 1 1 0 1 1 1 1 0 1 0 1 1 0 1 0 1 1 1 0 1 0 0 1 1 0 0 1 0 0 1 0 0 1 0\n",
            " 1 0 1 1 0 0 1 1 1 1 0 0 1 1 1 1 0 1 0 1 1 0 0 0 0 0 0 1 1 1 1 1 0 0 0 1 0\n",
            " 1 0 1 0 0 1 0 0 0 0 1 1 0 0 1 0 1 0 0 1 1 1 0 1 1 1 1 1 0 1 1 0 0 0 1 0 1\n",
            " 0 0 1 0 0 1 1 1 0 0 1 1 0 1 1 0 0 0 1 0 1 0 1 1 0 1 0 1 1 0 0 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 0 0 1 0 1 1 1 0 1 1 1 1 1 0 0 0 0 1 0 1 1 1 0 1 1 1 1 1 1 1 0\n",
            " 0 1 0 1 0 0 1 0 0 1 1 1 1 1 1 0 1 0 1 0 1 1 0 1 1 0 1 1 0 1 1 0 1 1 0 0 1\n",
            " 0 1 1 1 1 0 0 1 0 1 1 1 0 1 1 0 0 1 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 1 0 0 1\n",
            " 1 0 1 0 1 0 0 1 0 1 0 1 0 1 1 1 1 0 0 1 0 1 1 1 1 0 0 0 0 1 1 1 0 1 0 0 1\n",
            " 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1 0 0 1 1 1 1 0 0 0 0 1 1 0 0 1 0 1 1 1 0 1 0\n",
            " 1 1 0 0 0 1 0 0 1 0 1 1 1 0 1 0 1 0 0 0 0 1 0 1 1 1 1 1 1 0 1 0 0 1 1 1 1\n",
            " 1 1 1 0 0 1 0 1 1 1 1 0 0 0 0 0 1 0 0 1 0 1 1 0 1 1 0 0 1 1 0 0 1 0 1 1 1\n",
            " 1 0 1 1 1 0 0 1 1 1 1 1 1 0 1 0 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1\n",
            " 0 0 0 1 0 1 1 1 0 0 0 1 1 0 1 1 0 1 0 1 0 1 1 1 1 1 1 0 1 0 1 0 0 1 0 0 0\n",
            " 0 1 1 0 0 1 1 1 1 0 1 0 0 1 1 0 1 1 0 0 1 0 1 1 1 0 0 0]\n",
            "trainset before adding uncertain samples (460, 10) (460,)\n",
            "trainset after adding uncertain samples (470, 10) (470,)\n",
            "updated train set: (470, 10) (470,) unique(labels): [233 237] [0 1]\n",
            "val set: (832, 10) (832,)\n",
            "\n",
            "Train set: (470, 10)\n",
            "Validation set: (832, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 47\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.070 s \n",
            "\n",
            "Accuracy rate is 77.880184 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.87      0.85       321\n",
            "           1       0.58      0.52      0.55       113\n",
            "\n",
            "    accuracy                           0.78       434\n",
            "   macro avg       0.71      0.70      0.70       434\n",
            "weighted avg       0.77      0.78      0.77       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[279  42]\n",
            " [ 54  59]]\n",
            "--------------------------------\n",
            "val predicted: (832,) [1 1 1 1 0 0 0 1 1 1 1 0 1 0 1 0 0 1 0 1 1 1 0 1 0 0 1 1 0 0 1 0 1 0 1 0 1\n",
            " 1 1 1 1 1 1 0 1 0 0 0 1 1 1 1 1 1 0 1 0 1 1 0 0 0 0 0 1 1 1 1 0 1 0 0 1 1\n",
            " 1 0 0 0 1 0 1 0 0 0 1 0 0 1 0 1 1 1 0 1 0 0 1 0 0 0 0 1 1 1 0 0 1 1 0 1 0\n",
            " 1 1 1 1 1 1 0 1 0 1 0 0 1 1 0 1 1 1 1 0 0 1 0 0 0 0 1 1 0 1 1 1 0 1 0 0 1\n",
            " 1 0 1 1 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 1 0 1 0 0 0 0 1 0 1 1 0 0 1 1 0 0\n",
            " 0 0 0 1 1 1 1 1 1 0 0 1 0 0 1 1 1 0 1 0 1 1 0 1 0 1 1 0 1 1 1 1 1 0 1 1 0\n",
            " 0 0 1 1 1 1 1 0 0 1 0 1 0 0 1 0 1 0 1 0 1 0 0 0 1 0 0 0 0 1 1 1 1 1 1 1 0\n",
            " 1 1 0 1 0 1 0 1 1 0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 0 0 1 1 1 1 0 1 0 1 1 0 0\n",
            " 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 0 1 1 0 1 0 1 1 0 1 0 1 0 1 0 0 1 1 1 1 0 1\n",
            " 1 0 1 1 1 1 0 1 0 1 1 0 1 0 1 1 1 0 1 0 0 1 1 0 0 1 0 0 1 0 0 1 0 1 0 1 1\n",
            " 0 0 1 1 1 1 0 0 1 1 1 1 0 1 0 1 1 0 0 0 0 0 0 1 1 1 1 1 0 0 0 1 0 1 0 1 0\n",
            " 0 1 0 0 0 0 1 1 0 0 1 0 1 0 0 1 1 1 0 1 1 1 1 0 1 1 0 0 0 1 0 1 0 0 1 0 0\n",
            " 1 1 1 0 0 1 1 0 1 1 0 0 0 1 0 1 0 1 1 0 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 0 0 1 0 1 1 1 0 1 1 1 1 1 0 0 0 0 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0 1 0 1 0 0\n",
            " 1 0 0 1 1 1 1 1 1 0 1 0 1 0 1 1 0 1 1 0 1 1 0 1 1 0 1 1 0 0 1 0 1 1 1 1 0\n",
            " 0 1 0 1 1 1 0 1 1 0 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 1 0 0 1 1 0 1 0 1 0 0\n",
            " 1 0 1 0 1 0 1 1 1 1 0 0 1 0 1 1 1 1 0 0 0 1 1 1 0 1 0 1 0 1 1 0 0 1 0 0 1\n",
            " 1 0 0 0 1 0 0 1 1 1 1 0 0 0 0 1 1 0 0 1 0 1 1 1 0 1 0 1 1 0 0 0 1 0 0 1 0\n",
            " 1 1 1 0 1 0 1 0 0 0 0 1 0 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 0 0 1 0 1 1 1\n",
            " 1 0 0 0 0 0 1 0 0 1 0 1 1 0 1 1 0 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1 0 0 1 1 1\n",
            " 1 1 1 0 1 0 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 0 0 1 0 1 1 1 0 0\n",
            " 0 1 1 0 1 1 0 1 0 1 0 1 1 1 1 1 1 0 1 0 1 0 0 1 0 0 0 0 1 1 0 0 1 1 1 1 0\n",
            " 1 0 0 1 1 0 1 1 0 0 1 0 1 1 1 0 0 0]\n",
            "probabilities: (832, 2) \n",
            " [1 1 1 1 0 0 0 1 1 1 1 0 1 0 1 0 0 1 0 1 1 1 0 1 0 0 1 1 0 0 1 0 1 0 1 0 1\n",
            " 1 1 1 1 1 1 0 1 0 0 0 1 1 1 1 1 1 0 1 0 1 1 0 0 0 0 0 1 1 1 1 0 1 0 0 1 1\n",
            " 1 0 0 0 1 0 1 0 0 0 1 0 0 1 0 1 1 1 0 1 0 0 1 0 0 0 0 1 1 1 0 0 1 1 0 1 0\n",
            " 1 1 1 1 1 1 0 1 0 1 0 0 1 1 0 1 1 1 1 0 0 1 0 0 0 0 1 1 0 1 1 1 0 1 0 0 1\n",
            " 1 0 1 1 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 1 0 1 0 0 0 0 1 0 1 1 0 0 1 1 0 0\n",
            " 0 0 0 1 1 1 1 1 1 0 0 1 0 0 1 1 1 0 1 0 1 1 0 1 0 1 1 0 1 1 1 1 1 0 1 1 0\n",
            " 0 0 1 1 1 1 1 0 0 1 0 1 0 0 1 0 1 0 1 0 1 0 0 0 1 0 0 0 0 1 1 1 1 1 1 1 0\n",
            " 1 1 0 1 0 1 0 1 1 0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 0 0 1 1 1 1 0 1 0 1 1 0 0\n",
            " 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 0 1 1 0 1 0 1 1 0 1 0 1 0 1 0 0 1 1 1 1 0 1\n",
            " 1 0 1 1 1 1 0 1 0 1 1 0 1 0 1 1 1 0 1 0 0 1 1 0 0 1 0 0 1 0 0 1 0 1 0 1 1\n",
            " 0 0 1 1 1 1 0 0 1 1 1 1 0 1 0 1 1 0 0 0 0 0 0 1 1 1 1 1 0 0 0 1 0 1 0 1 0\n",
            " 0 1 0 0 0 0 1 1 0 0 1 0 1 0 0 1 1 1 0 1 1 1 1 0 1 1 0 0 0 1 0 1 0 0 1 0 0\n",
            " 1 1 1 0 0 1 1 0 1 1 0 0 0 1 0 1 0 1 1 0 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 0 0 1 0 1 1 1 0 1 1 1 1 1 0 0 0 0 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0 1 0 1 0 0\n",
            " 1 0 0 1 1 1 1 1 1 0 1 0 1 0 1 1 0 1 1 0 1 1 0 1 1 0 1 1 0 0 1 0 1 1 1 1 0\n",
            " 0 1 0 1 1 1 0 1 1 0 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 1 0 0 1 1 0 1 0 1 0 0\n",
            " 1 0 1 0 1 0 1 1 1 1 0 0 1 0 1 1 1 1 0 0 0 1 1 1 0 1 0 1 0 1 1 0 0 1 0 0 1\n",
            " 1 0 0 0 1 0 0 1 1 1 1 0 0 0 0 1 1 0 0 1 0 1 1 1 0 1 0 1 1 0 0 0 1 0 0 1 0\n",
            " 1 1 1 0 1 0 1 0 0 0 0 1 0 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 0 0 1 0 1 1 1\n",
            " 1 0 0 0 0 0 1 0 0 1 0 1 1 0 1 1 0 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1 0 0 1 1 1\n",
            " 1 1 1 0 1 0 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 0 0 1 0 1 1 1 0 0\n",
            " 0 1 1 0 1 1 0 1 0 1 0 1 1 1 1 1 1 0 1 0 1 0 0 1 0 0 0 0 1 1 0 0 1 1 1 1 0\n",
            " 1 0 0 1 1 0 1 1 0 0 1 0 1 1 1 0 0 0]\n",
            "trainset before adding uncertain samples (470, 10) (470,)\n",
            "trainset after adding uncertain samples (480, 10) (480,)\n",
            "updated train set: (480, 10) (480,) unique(labels): [237 243] [0 1]\n",
            "val set: (822, 10) (822,)\n",
            "\n",
            "Train set: (480, 10)\n",
            "Validation set: (822, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 48\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.067 s \n",
            "\n",
            "Accuracy rate is 78.801843 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.87      0.86       321\n",
            "           1       0.60      0.55      0.57       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.72      0.71      0.72       434\n",
            "weighted avg       0.78      0.79      0.78       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[280  41]\n",
            " [ 51  62]]\n",
            "--------------------------------\n",
            "val predicted: (822,) [1 1 1 1 0 0 0 1 1 1 1 0 1 0 1 0 0 1 0 1 1 1 0 1 0 0 1 1 0 0 1 0 1 0 1 1 1\n",
            " 1 1 1 1 1 0 1 0 0 0 1 1 1 1 1 1 0 1 0 1 1 0 0 0 0 0 1 1 1 1 0 1 0 0 1 1 1\n",
            " 0 0 0 1 0 1 0 0 0 1 0 0 1 0 1 1 1 0 1 0 0 1 0 0 0 0 1 1 1 0 0 1 1 0 1 0 1\n",
            " 1 1 1 1 1 0 1 0 1 0 0 1 1 0 1 1 1 0 0 1 0 0 0 0 1 1 0 1 1 1 0 1 0 0 1 1 0\n",
            " 1 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 1 0 0 0 0 1 0 1 1 0 0 1 1 0 0 0 0 0\n",
            " 1 1 1 1 1 1 0 0 1 0 0 1 1 1 0 1 0 1 1 0 1 0 1 1 0 1 1 1 1 1 0 1 1 0 0 0 1\n",
            " 1 1 1 1 0 0 1 0 1 0 0 1 0 1 0 1 0 1 0 0 0 1 0 0 0 0 1 1 1 1 1 1 1 0 1 1 0\n",
            " 1 0 1 0 1 1 0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 0 0 1 1 1 0 1 0 1 1 0 0 1 1 1 1\n",
            " 1 1 1 1 0 1 1 1 1 0 0 0 1 1 0 1 0 1 1 0 1 0 1 0 1 0 0 1 1 1 1 0 1 1 0 1 1\n",
            " 1 1 0 1 0 1 1 0 1 0 1 1 1 0 1 0 0 1 1 0 0 1 0 0 1 0 0 1 0 1 0 1 1 0 0 1 1\n",
            " 1 1 0 0 1 1 1 1 0 1 0 1 1 0 0 0 0 0 1 1 1 1 1 0 0 0 1 1 0 1 0 0 1 0 0 0 0\n",
            " 1 1 0 0 1 0 1 0 0 1 1 1 0 1 1 1 1 0 1 1 0 0 0 1 0 1 0 0 1 0 0 1 1 1 0 0 1\n",
            " 1 0 1 1 0 0 0 1 0 1 0 1 1 0 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1\n",
            " 1 0 1 1 1 1 1 0 0 0 0 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0 1 0 1 0 0 1 0 0 1 1 1\n",
            " 1 1 1 0 1 0 1 0 1 1 0 1 1 0 1 0 1 1 0 1 1 0 0 1 0 1 1 1 1 0 0 1 0 1 1 1 0\n",
            " 1 1 0 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 1 0 0 1 1 0 1 0 1 0 0 1 0 1 0 1 0 1\n",
            " 1 1 1 0 0 1 0 1 1 1 1 0 0 0 1 1 1 0 1 0 0 1 1 0 0 1 0 0 1 1 0 0 0 1 0 0 1\n",
            " 1 1 1 0 0 0 0 1 1 0 0 1 0 1 1 1 0 1 0 1 1 0 0 0 1 0 0 1 0 1 1 1 0 1 0 1 0\n",
            " 0 0 0 1 0 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 0 0 1 0 1 1 1 1 0 0 0 0 0 1 0 0\n",
            " 1 0 1 1 0 1 1 0 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 1 0 1 0 1 1 0\n",
            " 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 0 0 1 0 1 1 1 0 0 0 1 1 0 1 0 1 0 1\n",
            " 0 1 1 1 1 1 1 0 1 0 1 0 0 1 0 0 0 0 1 1 0 0 1 1 1 1 0 1 0 0 1 1 0 1 1 0 0\n",
            " 1 0 1 1 1 0 0 0]\n",
            "probabilities: (822, 2) \n",
            " [1 1 1 1 0 0 0 1 1 1 1 0 1 0 1 0 0 1 0 1 1 1 0 1 0 0 1 1 0 0 1 0 1 0 1 1 1\n",
            " 1 1 1 1 1 0 1 0 0 0 1 1 1 1 1 1 0 1 0 1 1 0 0 0 0 0 1 1 1 1 0 1 0 0 1 1 1\n",
            " 0 0 0 1 0 1 0 0 0 1 0 0 1 0 1 1 1 0 1 0 0 1 0 0 0 0 1 1 1 0 0 1 1 0 1 0 1\n",
            " 1 1 1 1 1 0 1 0 1 0 0 1 1 0 1 1 1 0 0 1 0 0 0 0 1 1 0 1 1 1 0 1 0 0 1 1 0\n",
            " 1 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 1 0 0 0 0 1 0 1 1 0 0 1 1 0 0 0 0 0\n",
            " 1 1 1 1 1 1 0 0 1 0 0 1 1 1 0 1 0 1 1 0 1 0 1 1 0 1 1 1 1 1 0 1 1 0 0 0 1\n",
            " 1 1 1 1 0 0 1 0 1 0 0 1 0 1 0 1 0 1 0 0 0 1 0 0 0 0 1 1 1 1 1 1 1 0 1 1 0\n",
            " 1 0 1 0 1 1 0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 0 0 1 1 1 0 1 0 1 1 0 0 1 1 1 1\n",
            " 1 1 1 1 0 1 1 1 1 0 0 0 1 1 0 1 0 1 1 0 1 0 1 0 1 0 0 1 1 1 1 0 1 1 0 1 1\n",
            " 1 1 0 1 0 1 1 0 1 0 1 1 1 0 1 0 0 1 1 0 0 1 0 0 1 0 0 1 0 1 0 1 1 0 0 1 1\n",
            " 1 1 0 0 1 1 1 1 0 1 0 1 1 0 0 0 0 0 1 1 1 1 1 0 0 0 1 1 0 1 0 0 1 0 0 0 0\n",
            " 1 1 0 0 1 0 1 0 0 1 1 1 0 1 1 1 1 0 1 1 0 0 0 1 0 1 0 0 1 0 0 1 1 1 0 0 1\n",
            " 1 0 1 1 0 0 0 1 0 1 0 1 1 0 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1\n",
            " 1 0 1 1 1 1 1 0 0 0 0 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0 1 0 1 0 0 1 0 0 1 1 1\n",
            " 1 1 1 0 1 0 1 0 1 1 0 1 1 0 1 0 1 1 0 1 1 0 0 1 0 1 1 1 1 0 0 1 0 1 1 1 0\n",
            " 1 1 0 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 1 0 0 1 1 0 1 0 1 0 0 1 0 1 0 1 0 1\n",
            " 1 1 1 0 0 1 0 1 1 1 1 0 0 0 1 1 1 0 1 0 0 1 1 0 0 1 0 0 1 1 0 0 0 1 0 0 1\n",
            " 1 1 1 0 0 0 0 1 1 0 0 1 0 1 1 1 0 1 0 1 1 0 0 0 1 0 0 1 0 1 1 1 0 1 0 1 0\n",
            " 0 0 0 1 0 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 0 0 1 0 1 1 1 1 0 0 0 0 0 1 0 0\n",
            " 1 0 1 1 0 1 1 0 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 1 0 1 0 1 1 0\n",
            " 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 0 0 1 0 1 1 1 0 0 0 1 1 0 1 0 1 0 1\n",
            " 0 1 1 1 1 1 1 0 1 0 1 0 0 1 0 0 0 0 1 1 0 0 1 1 1 1 0 1 0 0 1 1 0 1 1 0 0\n",
            " 1 0 1 1 1 0 0 0]\n",
            "trainset before adding uncertain samples (480, 10) (480,)\n",
            "trainset after adding uncertain samples (490, 10) (490,)\n",
            "updated train set: (490, 10) (490,) unique(labels): [242 248] [0 1]\n",
            "val set: (812, 10) (812,)\n",
            "\n",
            "Train set: (490, 10)\n",
            "Validation set: (812, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 49\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.060 s \n",
            "\n",
            "Accuracy rate is 78.341014 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.87      0.86       321\n",
            "           1       0.59      0.55      0.57       113\n",
            "\n",
            "    accuracy                           0.78       434\n",
            "   macro avg       0.72      0.71      0.71       434\n",
            "weighted avg       0.78      0.78      0.78       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[278  43]\n",
            " [ 51  62]]\n",
            "--------------------------------\n",
            "val predicted: (812,) [1 1 1 1 0 0 0 1 1 1 1 0 1 0 1 0 0 1 0 1 1 1 0 1 0 0 1 1 0 0 1 0 1 0 1 1 1\n",
            " 1 1 1 0 1 0 0 0 1 1 1 1 1 1 0 1 0 1 1 0 0 0 0 0 1 1 1 1 0 1 0 0 1 1 0 0 0\n",
            " 1 0 1 0 0 0 1 0 0 1 0 1 1 1 0 1 0 0 1 0 0 0 0 1 1 1 0 0 1 1 0 1 0 1 1 1 1\n",
            " 1 1 0 1 0 1 0 0 1 1 0 1 1 1 0 0 1 0 0 0 0 1 1 0 1 1 1 0 1 0 0 1 1 0 1 1 1\n",
            " 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 1 0 0 0 0 1 0 1 1 0 0 1 1 0 0 0 0 0 1 1 1\n",
            " 1 1 1 0 0 1 0 0 1 1 1 0 1 0 1 1 0 1 0 1 1 0 1 1 1 1 1 0 1 1 0 0 0 1 1 1 1\n",
            " 1 0 0 1 0 1 0 0 1 0 1 0 1 0 1 0 0 0 1 0 0 0 0 1 1 1 1 1 1 1 0 1 1 0 1 0 1\n",
            " 0 1 1 0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 0 0 1 1 1 0 1 0 1 1 0 0 1 1 1 1 1 1 1\n",
            " 1 0 1 1 1 1 0 0 0 1 1 0 1 0 1 1 0 1 0 0 1 0 0 1 1 1 1 0 1 1 0 1 1 1 1 0 1\n",
            " 0 1 1 0 1 0 1 1 1 0 1 0 0 1 1 0 0 0 1 0 0 1 0 1 0 1 1 0 1 1 1 1 0 0 1 1 1\n",
            " 1 0 1 0 1 1 0 0 0 0 0 1 1 1 1 1 0 0 0 1 1 0 1 0 0 1 0 0 0 0 1 1 0 0 1 0 1\n",
            " 0 0 1 1 1 0 1 1 1 1 0 1 1 0 0 0 1 0 1 0 0 1 0 0 1 1 1 0 0 1 1 0 1 1 0 0 0\n",
            " 1 0 1 0 1 1 0 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1 0 1 1 1 1 1\n",
            " 0 0 0 0 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0 1 0 1 0 0 1 0 0 1 1 1 1 1 0 1 0 1 1\n",
            " 1 0 1 1 0 1 0 1 1 0 1 1 0 0 1 0 1 1 1 1 0 0 1 0 1 1 1 0 1 1 0 0 1 1 1 1 1\n",
            " 0 1 1 1 0 0 1 1 1 0 1 0 0 1 1 0 1 0 1 0 0 1 0 1 0 1 0 1 1 1 1 0 0 1 0 1 1\n",
            " 1 1 0 0 0 1 1 1 0 1 0 0 1 1 0 0 1 0 0 1 1 0 0 0 1 0 0 1 1 1 1 0 0 0 0 1 1\n",
            " 0 0 1 0 1 1 1 0 1 0 1 1 0 0 0 1 0 0 1 0 1 1 1 0 1 0 1 0 0 0 0 1 0 1 1 1 1\n",
            " 1 1 0 1 0 0 1 1 1 1 1 0 0 1 0 1 1 1 1 0 0 0 0 0 1 0 0 1 0 1 1 0 1 1 0 0 1\n",
            " 1 0 0 1 0 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 1 0 1 0 1 1 0 1 1 1 1 1 1 1 1 1 0\n",
            " 1 1 0 0 1 1 0 1 0 0 0 1 0 1 1 1 0 0 0 1 1 0 1 0 1 0 1 0 1 1 1 1 1 1 0 1 0\n",
            " 1 0 0 1 0 0 0 0 1 1 0 0 1 1 1 1 0 1 0 0 1 1 0 1 1 0 0 1 0 1 1 1 0 0 0]\n",
            "probabilities: (812, 2) \n",
            " [1 1 1 1 0 0 0 1 1 1 1 0 1 0 1 0 0 1 0 1 1 1 0 1 0 0 1 1 0 0 1 0 1 0 1 1 1\n",
            " 1 1 1 0 1 0 0 0 1 1 1 1 1 1 0 1 0 1 1 0 0 0 0 0 1 1 1 1 0 1 0 0 1 1 0 0 0\n",
            " 1 0 1 0 0 0 1 0 0 1 0 1 1 1 0 1 0 0 1 0 0 0 0 1 1 1 0 0 1 1 0 1 0 1 1 1 1\n",
            " 1 1 0 1 0 1 0 0 1 1 0 1 1 1 0 0 1 0 0 0 0 1 1 0 1 1 1 0 1 0 0 1 1 0 1 1 1\n",
            " 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 1 0 0 0 0 1 0 1 1 0 0 1 1 0 0 0 0 0 1 1 1\n",
            " 1 1 1 0 0 1 0 0 1 1 1 0 1 0 1 1 0 1 0 1 1 0 1 1 1 1 1 0 1 1 0 0 0 1 1 1 1\n",
            " 1 0 0 1 0 1 0 0 1 0 1 0 1 0 1 0 0 0 1 0 0 0 0 1 1 1 1 1 1 1 0 1 1 0 1 0 1\n",
            " 0 1 1 0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 0 0 1 1 1 0 1 0 1 1 0 0 1 1 1 1 1 1 1\n",
            " 1 0 1 1 1 1 0 0 0 1 1 0 1 0 1 1 0 1 0 0 1 0 0 1 1 1 1 0 1 1 0 1 1 1 1 0 1\n",
            " 0 1 1 0 1 0 1 1 1 0 1 0 0 1 1 0 0 0 1 0 0 1 0 1 0 1 1 0 1 1 1 1 0 0 1 1 1\n",
            " 1 0 1 0 1 1 0 0 0 0 0 1 1 1 1 1 0 0 0 1 1 0 1 0 0 1 0 0 0 0 1 1 0 0 1 0 1\n",
            " 0 0 1 1 1 0 1 1 1 1 0 1 1 0 0 0 1 0 1 0 0 1 0 0 1 1 1 0 0 1 1 0 1 1 0 0 0\n",
            " 1 0 1 0 1 1 0 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1 0 1 1 1 1 1\n",
            " 0 0 0 0 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0 1 0 1 0 0 1 0 0 1 1 1 1 1 0 1 0 1 1\n",
            " 1 0 1 1 0 1 0 1 1 0 1 1 0 0 1 0 1 1 1 1 0 0 1 0 1 1 1 0 1 1 0 0 1 1 1 1 1\n",
            " 0 1 1 1 0 0 1 1 1 0 1 0 0 1 1 0 1 0 1 0 0 1 0 1 0 1 0 1 1 1 1 0 0 1 0 1 1\n",
            " 1 1 0 0 0 1 1 1 0 1 0 0 1 1 0 0 1 0 0 1 1 0 0 0 1 0 0 1 1 1 1 0 0 0 0 1 1\n",
            " 0 0 1 0 1 1 1 0 1 0 1 1 0 0 0 1 0 0 1 0 1 1 1 0 1 0 1 0 0 0 0 1 0 1 1 1 1\n",
            " 1 1 0 1 0 0 1 1 1 1 1 0 0 1 0 1 1 1 1 0 0 0 0 0 1 0 0 1 0 1 1 0 1 1 0 0 1\n",
            " 1 0 0 1 0 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 1 0 1 0 1 1 0 1 1 1 1 1 1 1 1 1 0\n",
            " 1 1 0 0 1 1 0 1 0 0 0 1 0 1 1 1 0 0 0 1 1 0 1 0 1 0 1 0 1 1 1 1 1 1 0 1 0\n",
            " 1 0 0 1 0 0 0 0 1 1 0 0 1 1 1 1 0 1 0 0 1 1 0 1 1 0 0 1 0 1 1 1 0 0 0]\n",
            "trainset before adding uncertain samples (490, 10) (490,)\n",
            "trainset after adding uncertain samples (500, 10) (500,)\n",
            "updated train set: (500, 10) (500,) unique(labels): [249 251] [0 1]\n",
            "val set: (802, 10) (802,)\n",
            "\n",
            "Train set: (500, 10)\n",
            "Validation set: (802, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 50\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.056 s \n",
            "\n",
            "Accuracy rate is 78.110599 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.86      0.85       321\n",
            "           1       0.58      0.55      0.57       113\n",
            "\n",
            "    accuracy                           0.78       434\n",
            "   macro avg       0.71      0.71      0.71       434\n",
            "weighted avg       0.78      0.78      0.78       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[277  44]\n",
            " [ 51  62]]\n",
            "--------------------------------\n",
            "final active learning accuracies [26.036866359447004, 71.42857142857143, 76.036866359447, 78.3410138248848, 78.57142857142857, 77.64976958525345, 76.72811059907833, 77.41935483870968, 79.03225806451613, 78.11059907834101, 76.95852534562212, 78.57142857142857, 77.88018433179722, 79.26267281105991, 79.26267281105991, 79.72350230414746, 80.64516129032258, 81.10599078341014, 78.80184331797236, 78.3410138248848, 80.18433179723502, 79.49308755760369, 80.87557603686636, 80.4147465437788, 80.64516129032258, 80.64516129032258, 80.18433179723502, 79.72350230414746, 80.18433179723502, 80.18433179723502, 80.18433179723502, 80.87557603686636, 81.5668202764977, 80.64516129032258, 80.87557603686636, 81.5668202764977, 81.79723502304147, 79.03225806451613, 78.3410138248848, 79.03225806451613, 78.80184331797236, 78.57142857142857, 78.3410138248848, 78.3410138248848, 77.41935483870968, 78.3410138248848, 77.88018433179722, 78.80184331797236, 78.3410138248848, 78.11059907834101]\n",
            "saved /Users/wenxuanhuang/Documents/Repo/ML-for-COVID-19-dataset/Results/Active-learning-experiment-30.pkl /Users/wenxuanhuang/Documents/Repo/ML-for-COVID-19-dataset ['Decision_tree.ipynb', 'dec_git.png', 'Logit_default_f10.pdf', 'Logistic.ipynb', 'SVC.ipynb', 'RF_f5e50_featureimp.pdf', 'log_al.png', 'dec_git.pdf', '.DS_Store', 'log_git.png', 'svm_git.png', 'Logistic_Scikit.ipynb', 'knn_git.pdf', 'knn_git.png', 'rf_al.png', 'Best classifier_RF_f5e50.pdf', 'KNN.ipynb', 'GBDC.ipynb', 'rf_git.png', 'README.md', 'all_training.csv', 'Results', 'svm_al.png', 'Log_ROC.png', 'Logit_default_f7(p_removal).pdf', 'Active_learning.ipynb', 'Random_forest.ipynb', 'Model_select.ipynb', 'gdbc_git.png', '.git', '.vscode', 'Untitled', 'RF_f5e50_modelselect.pdf', 'Logit_default_f8(std_removal).pdf']\n",
            "{\n",
            "  \"GDBCModel\": {\n",
            "    \"EntropySelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          65.2073732718894,\n",
            "          76.95852534562212,\n",
            "          75.11520737327189,\n",
            "          70.04608294930875,\n",
            "          72.35023041474655,\n",
            "          71.42857142857143,\n",
            "          77.41935483870968,\n",
            "          76.26728110599078,\n",
            "          77.41935483870968,\n",
            "          77.88018433179722,\n",
            "          78.57142857142857,\n",
            "          73.963133640553,\n",
            "          79.49308755760369,\n",
            "          79.03225806451613,\n",
            "          79.49308755760369,\n",
            "          79.26267281105991,\n",
            "          78.3410138248848,\n",
            "          78.57142857142857,\n",
            "          79.03225806451613,\n",
            "          80.18433179723502,\n",
            "          79.95391705069125,\n",
            "          80.18433179723502,\n",
            "          78.80184331797236,\n",
            "          79.49308755760369,\n",
            "          79.72350230414746,\n",
            "          80.18433179723502,\n",
            "          79.95391705069125,\n",
            "          81.5668202764977,\n",
            "          81.79723502304147,\n",
            "          81.5668202764977,\n",
            "          81.33640552995391,\n",
            "          80.64516129032258,\n",
            "          80.4147465437788,\n",
            "          81.10599078341014,\n",
            "          79.49308755760369,\n",
            "          80.64516129032258,\n",
            "          80.87557603686636,\n",
            "          80.87557603686636,\n",
            "          79.49308755760369,\n",
            "          80.18433179723502,\n",
            "          79.72350230414746,\n",
            "          79.95391705069125,\n",
            "          78.80184331797236,\n",
            "          79.72350230414746,\n",
            "          79.49308755760369,\n",
            "          80.4147465437788,\n",
            "          79.49308755760369,\n",
            "          80.4147465437788,\n",
            "          79.72350230414746,\n",
            "          79.95391705069125\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          77.41935483870968,\n",
            "          79.03225806451613,\n",
            "          80.64516129032258,\n",
            "          80.18433179723502\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          70.04608294930875,\n",
            "          76.49769585253456,\n",
            "          79.03225806451613,\n",
            "          78.57142857142857,\n",
            "          77.64976958525345,\n",
            "          78.80184331797236,\n",
            "          78.80184331797236,\n",
            "          77.41935483870968,\n",
            "          77.88018433179722,\n",
            "          77.64976958525345,\n",
            "          79.03225806451613,\n",
            "          77.88018433179722,\n",
            "          78.80184331797236,\n",
            "          78.80184331797236,\n",
            "          79.26267281105991,\n",
            "          79.72350230414746,\n",
            "          79.03225806451613,\n",
            "          79.72350230414746,\n",
            "          80.4147465437788,\n",
            "          80.87557603686636\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          78.57142857142857,\n",
            "          80.4147465437788\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          75.34562211981567,\n",
            "          80.64516129032258,\n",
            "          79.95391705069125,\n",
            "          79.03225806451613,\n",
            "          80.64516129032258,\n",
            "          80.18433179723502,\n",
            "          79.95391705069125,\n",
            "          79.49308755760369,\n",
            "          79.72350230414746,\n",
            "          79.49308755760369\n",
            "        ]\n",
            "      ]\n",
            "    },\n",
            "    \"MarginSamplingSelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          49.07834101382488,\n",
            "          63.133640552995395,\n",
            "          72.58064516129032,\n",
            "          68.89400921658986,\n",
            "          72.58064516129032,\n",
            "          76.036866359447,\n",
            "          75.34562211981567,\n",
            "          74.19354838709677,\n",
            "          74.65437788018433,\n",
            "          73.73271889400922,\n",
            "          75.11520737327189,\n",
            "          70.50691244239631,\n",
            "          75.57603686635944,\n",
            "          75.34562211981567,\n",
            "          75.11520737327189,\n",
            "          75.80645161290323,\n",
            "          76.72811059907833,\n",
            "          76.49769585253456,\n",
            "          77.41935483870968,\n",
            "          77.18894009216591,\n",
            "          77.41935483870968,\n",
            "          76.95852534562212,\n",
            "          78.80184331797236,\n",
            "          78.3410138248848,\n",
            "          78.57142857142857,\n",
            "          79.72350230414746,\n",
            "          79.72350230414746,\n",
            "          79.26267281105991,\n",
            "          79.49308755760369,\n",
            "          79.49308755760369,\n",
            "          79.26267281105991,\n",
            "          78.57142857142857,\n",
            "          79.03225806451613,\n",
            "          79.49308755760369,\n",
            "          79.95391705069125,\n",
            "          79.95391705069125,\n",
            "          80.18433179723502,\n",
            "          79.95391705069125,\n",
            "          80.64516129032258,\n",
            "          79.49308755760369,\n",
            "          78.57142857142857,\n",
            "          78.80184331797236,\n",
            "          78.57142857142857,\n",
            "          79.03225806451613,\n",
            "          79.26267281105991,\n",
            "          78.57142857142857,\n",
            "          79.26267281105991,\n",
            "          78.80184331797236,\n",
            "          79.26267281105991,\n",
            "          79.49308755760369\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          76.95852534562212,\n",
            "          78.80184331797236,\n",
            "          79.03225806451613,\n",
            "          81.10599078341014\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          74.65437788018433,\n",
            "          69.81566820276498,\n",
            "          80.18433179723502,\n",
            "          72.11981566820278,\n",
            "          72.81105990783409,\n",
            "          73.73271889400922,\n",
            "          73.50230414746544,\n",
            "          78.57142857142857,\n",
            "          78.57142857142857,\n",
            "          81.10599078341014,\n",
            "          80.64516129032258,\n",
            "          78.80184331797236,\n",
            "          79.26267281105991,\n",
            "          80.18433179723502,\n",
            "          79.72350230414746,\n",
            "          79.26267281105991,\n",
            "          79.95391705069125,\n",
            "          79.72350230414746,\n",
            "          79.95391705069125,\n",
            "          79.72350230414746\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          76.26728110599078,\n",
            "          79.26267281105991\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          78.11059907834101,\n",
            "          78.11059907834101,\n",
            "          78.57142857142857,\n",
            "          78.57142857142857,\n",
            "          80.4147465437788,\n",
            "          80.18433179723502,\n",
            "          79.95391705069125,\n",
            "          79.72350230414746,\n",
            "          79.49308755760369,\n",
            "          78.80184331797236\n",
            "        ]\n",
            "      ]\n",
            "    },\n",
            "    \"MinStdSelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          73.73271889400922,\n",
            "          77.18894009216591,\n",
            "          77.18894009216591,\n",
            "          76.72811059907833,\n",
            "          71.19815668202764,\n",
            "          76.49769585253456,\n",
            "          77.88018433179722,\n",
            "          78.11059907834101,\n",
            "          77.88018433179722,\n",
            "          77.88018433179722,\n",
            "          79.03225806451613,\n",
            "          79.03225806451613,\n",
            "          79.72350230414746,\n",
            "          78.57142857142857,\n",
            "          79.26267281105991,\n",
            "          79.26267281105991,\n",
            "          75.34562211981567,\n",
            "          73.50230414746544,\n",
            "          74.42396313364056,\n",
            "          73.963133640553,\n",
            "          74.19354838709677,\n",
            "          73.963133640553,\n",
            "          74.19354838709677,\n",
            "          74.42396313364056,\n",
            "          75.80645161290323,\n",
            "          75.80645161290323,\n",
            "          74.88479262672811,\n",
            "          74.65437788018433,\n",
            "          74.65437788018433,\n",
            "          75.34562211981567,\n",
            "          75.80645161290323,\n",
            "          80.87557603686636,\n",
            "          80.18433179723502,\n",
            "          80.64516129032258,\n",
            "          80.87557603686636,\n",
            "          81.10599078341014,\n",
            "          81.5668202764977,\n",
            "          81.5668202764977,\n",
            "          81.10599078341014,\n",
            "          81.33640552995391,\n",
            "          81.5668202764977,\n",
            "          82.7188940092166,\n",
            "          82.25806451612904,\n",
            "          82.25806451612904,\n",
            "          81.79723502304147,\n",
            "          80.4147465437788,\n",
            "          80.87557603686636,\n",
            "          81.10599078341014,\n",
            "          80.87557603686636,\n",
            "          81.33640552995391\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          78.3410138248848,\n",
            "          76.036866359447,\n",
            "          80.18433179723502,\n",
            "          79.72350230414746\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          77.64976958525345,\n",
            "          77.88018433179722,\n",
            "          73.04147465437788,\n",
            "          74.19354838709677,\n",
            "          80.64516129032258,\n",
            "          80.18433179723502,\n",
            "          79.72350230414746,\n",
            "          80.87557603686636,\n",
            "          81.33640552995391,\n",
            "          80.87557603686636,\n",
            "          79.49308755760369,\n",
            "          80.18433179723502,\n",
            "          80.87557603686636,\n",
            "          80.87557603686636,\n",
            "          80.87557603686636,\n",
            "          80.87557603686636,\n",
            "          81.33640552995391,\n",
            "          81.33640552995391,\n",
            "          80.18433179723502,\n",
            "          80.4147465437788\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          75.11520737327189,\n",
            "          79.26267281105991\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          79.95391705069125,\n",
            "          76.95852534562212,\n",
            "          80.18433179723502,\n",
            "          79.49308755760369,\n",
            "          79.26267281105991,\n",
            "          79.72350230414746,\n",
            "          79.95391705069125,\n",
            "          79.72350230414746,\n",
            "          79.72350230414746,\n",
            "          79.72350230414746\n",
            "        ]\n",
            "      ]\n",
            "    },\n",
            "    \"RandomSelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          63.36405529953917,\n",
            "          70.73732718894009,\n",
            "          61.29032258064516,\n",
            "          63.594470046082954,\n",
            "          74.65437788018433,\n",
            "          75.80645161290323,\n",
            "          76.49769585253456,\n",
            "          76.49769585253456,\n",
            "          77.41935483870968,\n",
            "          76.72811059907833,\n",
            "          78.3410138248848,\n",
            "          78.80184331797236,\n",
            "          77.41935483870968,\n",
            "          79.49308755760369,\n",
            "          77.64976958525345,\n",
            "          76.95852534562212,\n",
            "          77.18894009216591,\n",
            "          76.95852534562212,\n",
            "          77.64976958525345,\n",
            "          78.11059907834101,\n",
            "          78.11059907834101,\n",
            "          77.64976958525345,\n",
            "          77.64976958525345,\n",
            "          78.3410138248848,\n",
            "          78.57142857142857,\n",
            "          77.64976958525345,\n",
            "          77.64976958525345,\n",
            "          77.41935483870968,\n",
            "          77.88018433179722,\n",
            "          77.88018433179722,\n",
            "          77.88018433179722,\n",
            "          78.11059907834101,\n",
            "          77.64976958525345,\n",
            "          78.3410138248848,\n",
            "          78.80184331797236,\n",
            "          79.26267281105991,\n",
            "          78.57142857142857,\n",
            "          77.88018433179722,\n",
            "          77.64976958525345,\n",
            "          77.64976958525345,\n",
            "          78.11059907834101,\n",
            "          79.72350230414746,\n",
            "          79.72350230414746,\n",
            "          79.49308755760369,\n",
            "          79.03225806451613,\n",
            "          79.72350230414746,\n",
            "          78.80184331797236,\n",
            "          78.57142857142857,\n",
            "          79.49308755760369,\n",
            "          79.26267281105991\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          72.58064516129032,\n",
            "          72.58064516129032,\n",
            "          76.036866359447,\n",
            "          76.26728110599078\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          72.35023041474655,\n",
            "          72.11981566820278,\n",
            "          71.88940092165899,\n",
            "          73.04147465437788,\n",
            "          72.81105990783409,\n",
            "          75.11520737327189,\n",
            "          73.50230414746544,\n",
            "          76.036866359447,\n",
            "          76.26728110599078,\n",
            "          76.49769585253456,\n",
            "          76.72811059907833,\n",
            "          77.18894009216591,\n",
            "          76.72811059907833,\n",
            "          78.11059907834101,\n",
            "          78.3410138248848,\n",
            "          77.64976958525345,\n",
            "          79.72350230414746,\n",
            "          79.95391705069125,\n",
            "          80.18433179723502,\n",
            "          80.87557603686636\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          78.3410138248848,\n",
            "          79.95391705069125\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          69.35483870967742,\n",
            "          76.72811059907833,\n",
            "          78.3410138248848,\n",
            "          78.57142857142857,\n",
            "          78.80184331797236,\n",
            "          79.95391705069125,\n",
            "          79.26267281105991,\n",
            "          79.03225806451613,\n",
            "          79.03225806451613,\n",
            "          78.80184331797236\n",
            "        ]\n",
            "      ]\n",
            "    }\n",
            "  },\n",
            "  \"KnnModel\": {\n",
            "    \"MarginSamplingSelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          26.036866359447004,\n",
            "          71.42857142857143,\n",
            "          76.036866359447,\n",
            "          78.3410138248848,\n",
            "          78.57142857142857,\n",
            "          77.64976958525345,\n",
            "          76.72811059907833,\n",
            "          77.41935483870968,\n",
            "          79.03225806451613,\n",
            "          78.11059907834101,\n",
            "          76.95852534562212,\n",
            "          78.57142857142857,\n",
            "          77.88018433179722,\n",
            "          79.26267281105991,\n",
            "          79.26267281105991,\n",
            "          79.72350230414746,\n",
            "          80.64516129032258,\n",
            "          81.10599078341014,\n",
            "          78.80184331797236,\n",
            "          78.3410138248848,\n",
            "          80.18433179723502,\n",
            "          79.49308755760369,\n",
            "          80.87557603686636,\n",
            "          80.4147465437788,\n",
            "          80.64516129032258,\n",
            "          80.64516129032258,\n",
            "          80.18433179723502,\n",
            "          79.72350230414746,\n",
            "          80.18433179723502,\n",
            "          80.18433179723502,\n",
            "          80.18433179723502,\n",
            "          80.87557603686636,\n",
            "          81.5668202764977,\n",
            "          80.64516129032258,\n",
            "          80.87557603686636,\n",
            "          81.5668202764977,\n",
            "          81.79723502304147,\n",
            "          79.03225806451613,\n",
            "          78.3410138248848,\n",
            "          79.03225806451613,\n",
            "          78.80184331797236,\n",
            "          78.57142857142857,\n",
            "          78.3410138248848,\n",
            "          78.3410138248848,\n",
            "          77.41935483870968,\n",
            "          78.3410138248848,\n",
            "          77.88018433179722,\n",
            "          78.80184331797236,\n",
            "          78.3410138248848,\n",
            "          78.11059907834101\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          77.18894009216591,\n",
            "          77.64976958525345,\n",
            "          78.57142857142857,\n",
            "          79.72350230414746\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          44.00921658986175,\n",
            "          77.88018433179722,\n",
            "          72.81105990783409,\n",
            "          80.4147465437788,\n",
            "          78.80184331797236,\n",
            "          76.72811059907833,\n",
            "          79.26267281105991,\n",
            "          80.18433179723502,\n",
            "          78.80184331797236,\n",
            "          79.03225806451613,\n",
            "          79.72350230414746,\n",
            "          79.49308755760369,\n",
            "          79.26267281105991,\n",
            "          78.11059907834101,\n",
            "          78.3410138248848,\n",
            "          80.4147465437788,\n",
            "          80.64516129032258,\n",
            "          81.10599078341014,\n",
            "          80.18433179723502,\n",
            "          79.72350230414746\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          77.88018433179722,\n",
            "          80.18433179723502\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          79.72350230414746,\n",
            "          75.11520737327189,\n",
            "          78.80184331797236,\n",
            "          79.26267281105991,\n",
            "          80.64516129032258,\n",
            "          79.49308755760369,\n",
            "          78.11059907834101,\n",
            "          78.57142857142857,\n",
            "          77.88018433179722,\n",
            "          78.3410138248848\n",
            "        ]\n",
            "      ]\n",
            "    },\n",
            "    \"RandomSelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          26.036866359447004,\n",
            "          63.594470046082954,\n",
            "          72.58064516129032,\n",
            "          75.80645161290323,\n",
            "          73.73271889400922,\n",
            "          75.80645161290323,\n",
            "          76.26728110599078,\n",
            "          76.036866359447,\n",
            "          76.72811059907833,\n",
            "          77.18894009216591,\n",
            "          76.49769585253456,\n",
            "          74.88479262672811,\n",
            "          77.41935483870968,\n",
            "          76.49769585253456,\n",
            "          76.95852534562212,\n",
            "          76.72811059907833,\n",
            "          78.11059907834101,\n",
            "          77.64976958525345,\n",
            "          78.3410138248848,\n",
            "          77.18894009216591,\n",
            "          78.3410138248848,\n",
            "          78.57142857142857,\n",
            "          79.26267281105991,\n",
            "          78.80184331797236,\n",
            "          78.11059907834101,\n",
            "          77.88018433179722,\n",
            "          77.64976958525345,\n",
            "          77.64976958525345,\n",
            "          77.18894009216591,\n",
            "          76.95852534562212,\n",
            "          77.18894009216591,\n",
            "          77.18894009216591,\n",
            "          76.95852534562212,\n",
            "          77.41935483870968,\n",
            "          79.03225806451613,\n",
            "          78.57142857142857,\n",
            "          78.80184331797236,\n",
            "          78.3410138248848,\n",
            "          77.88018433179722,\n",
            "          77.88018433179722,\n",
            "          78.57142857142857,\n",
            "          78.80184331797236,\n",
            "          78.80184331797236,\n",
            "          78.11059907834101,\n",
            "          78.80184331797236,\n",
            "          78.80184331797236,\n",
            "          79.03225806451613,\n",
            "          78.57142857142857,\n",
            "          78.57142857142857,\n",
            "          78.57142857142857\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          76.036866359447,\n",
            "          77.18894009216591,\n",
            "          78.11059907834101,\n",
            "          78.3410138248848\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          71.88940092165899,\n",
            "          77.41935483870968,\n",
            "          74.19354838709677,\n",
            "          76.26728110599078,\n",
            "          77.41935483870968,\n",
            "          78.11059907834101,\n",
            "          77.64976958525345,\n",
            "          78.57142857142857,\n",
            "          78.80184331797236,\n",
            "          78.57142857142857,\n",
            "          78.80184331797236,\n",
            "          77.41935483870968,\n",
            "          77.18894009216591,\n",
            "          77.88018433179722,\n",
            "          78.11059907834101,\n",
            "          78.11059907834101,\n",
            "          77.41935483870968,\n",
            "          79.03225806451613,\n",
            "          78.57142857142857,\n",
            "          79.26267281105991\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          76.036866359447,\n",
            "          77.64976958525345\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          78.11059907834101,\n",
            "          77.88018433179722,\n",
            "          76.95852534562212,\n",
            "          77.18894009216591,\n",
            "          76.49769585253456,\n",
            "          76.95852534562212,\n",
            "          76.95852534562212,\n",
            "          78.11059907834101,\n",
            "          77.41935483870968,\n",
            "          78.57142857142857\n",
            "        ]\n",
            "      ]\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "---------------------------- FINISHED ---------------------------\n",
            "\n",
            "Count = 31, using model = KnnModel, selection_function = EntropySelection, k = 250, iteration = 0.\n",
            "\n",
            "initial random chosen samples (250,)\n",
            "initial train set: (250, 10) (250,) unique(labels): [117 133] [0 1]\n",
            "Val set: (1052, 10) (1052,) (250,)\n",
            "\n",
            "Train set: (250, 10)\n",
            "Validation set: (1052, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.087 s \n",
            "\n",
            "Accuracy rate is 77.188940 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.87      0.85       321\n",
            "           1       0.57      0.49      0.53       113\n",
            "\n",
            "    accuracy                           0.77       434\n",
            "   macro avg       0.70      0.68      0.69       434\n",
            "weighted avg       0.76      0.77      0.77       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[280  41]\n",
            " [ 58  55]]\n",
            "--------------------------------\n",
            "val predicted: (1052,) [0 1 1 ... 0 0 1]\n",
            "probabilities: (1052, 2) \n",
            " [0 1 1 ... 0 0 1]\n",
            "trainset before adding uncertain samples (250, 10) (250,)\n",
            "trainset after adding uncertain samples (500, 10) (500,)\n",
            "updated train set: (500, 10) (500,) unique(labels): [262 238] [0 1]\n",
            "val set: (802, 10) (802,)\n",
            "\n",
            "Train set: (500, 10)\n",
            "Validation set: (802, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.065 s \n",
            "\n",
            "Accuracy rate is 77.880184 \n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: divide by zero encountered in log2\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: invalid value encountered in multiply\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.88      0.85       321\n",
            "           1       0.59      0.50      0.54       113\n",
            "\n",
            "    accuracy                           0.78       434\n",
            "   macro avg       0.71      0.69      0.70       434\n",
            "weighted avg       0.77      0.78      0.77       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[281  40]\n",
            " [ 56  57]]\n",
            "--------------------------------\n",
            "final active learning accuracies [77.18894009216591, 77.88018433179722]\n",
            "saved /Users/wenxuanhuang/Documents/Repo/ML-for-COVID-19-dataset/Results/Active-learning-experiment-31.pkl /Users/wenxuanhuang/Documents/Repo/ML-for-COVID-19-dataset ['Decision_tree.ipynb', 'dec_git.png', 'Logit_default_f10.pdf', 'Logistic.ipynb', 'SVC.ipynb', 'RF_f5e50_featureimp.pdf', 'log_al.png', 'dec_git.pdf', '.DS_Store', 'log_git.png', 'svm_git.png', 'Logistic_Scikit.ipynb', 'knn_git.pdf', 'knn_git.png', 'rf_al.png', 'Best classifier_RF_f5e50.pdf', 'KNN.ipynb', 'GBDC.ipynb', 'rf_git.png', 'README.md', 'all_training.csv', 'Results', 'svm_al.png', 'Log_ROC.png', 'Logit_default_f7(p_removal).pdf', 'Active_learning.ipynb', 'Random_forest.ipynb', 'Model_select.ipynb', 'gdbc_git.png', '.git', '.vscode', 'Untitled', 'RF_f5e50_modelselect.pdf', 'Logit_default_f8(std_removal).pdf']\n",
            "\n",
            "---------------------------- FINISHED ---------------------------\n",
            "\n",
            "Count = 32, using model = KnnModel, selection_function = EntropySelection, k = 125, iteration = 0.\n",
            "\n",
            "initial random chosen samples (125,)\n",
            "initial train set: (125, 10) (125,) unique(labels): [70 55] [0 1]\n",
            "Val set: (1177, 10) (1177,) (125,)\n",
            "\n",
            "Train set: (125, 10)\n",
            "Validation set: (1177, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.092 s \n",
            "\n",
            "Accuracy rate is 78.110599 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.91      0.86       321\n",
            "           1       0.62      0.42      0.50       113\n",
            "\n",
            "    accuracy                           0.78       434\n",
            "   macro avg       0.72      0.66      0.68       434\n",
            "weighted avg       0.76      0.78      0.77       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[292  29]\n",
            " [ 66  47]]\n",
            "--------------------------------\n",
            "val predicted: (1177,) [0 0 1 ... 0 0 0]\n",
            "probabilities: (1177, 2) \n",
            " [0 0 1 ... 0 0 0]\n",
            "trainset before adding uncertain samples (125, 10) (125,)\n",
            "trainset after adding uncertain samples (250, 10) (250,)\n",
            "updated train set: (250, 10) (250,) unique(labels): [146 104] [0 1]\n",
            "val set: (1052, 10) (1052,)\n",
            "\n",
            "Train set: (250, 10)\n",
            "Validation set: (1052, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: divide by zero encountered in log2\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: invalid value encountered in multiply\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: divide by zero encountered in log2\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: invalid value encountered in multiply\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.087 s \n",
            "\n",
            "Accuracy rate is 78.110599 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.87      0.85       321\n",
            "           1       0.59      0.54      0.56       113\n",
            "\n",
            "    accuracy                           0.78       434\n",
            "   macro avg       0.71      0.70      0.71       434\n",
            "weighted avg       0.78      0.78      0.78       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[278  43]\n",
            " [ 52  61]]\n",
            "--------------------------------\n",
            "val predicted: (1052,) [0 0 1 ... 0 0 0]\n",
            "probabilities: (1052, 2) \n",
            " [0 0 1 ... 0 0 0]\n",
            "trainset before adding uncertain samples (250, 10) (250,)\n",
            "trainset after adding uncertain samples (375, 10) (375,)\n",
            "updated train set: (375, 10) (375,) unique(labels): [241 134] [0 1]\n",
            "val set: (927, 10) (927,)\n",
            "\n",
            "Train set: (375, 10)\n",
            "Validation set: (927, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 3\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.096 s \n",
            "\n",
            "Accuracy rate is 79.723502 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.91      0.87       321\n",
            "           1       0.65      0.49      0.56       113\n",
            "\n",
            "    accuracy                           0.80       434\n",
            "   macro avg       0.74      0.70      0.71       434\n",
            "weighted avg       0.79      0.80      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[291  30]\n",
            " [ 58  55]]\n",
            "--------------------------------\n",
            "val predicted: (927,) [0 0 0 0 1 1 0 0 1 0 1 0 1 1 1 0 1 0 0 0 0 0 0 0 0 1 0 1 1 1 1 0 0 0 0 1 1\n",
            " 1 0 0 1 1 0 0 0 1 1 1 1 0 0 0 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 1 1 1 1 1 1 1\n",
            " 0 0 1 0 1 1 0 0 1 0 0 1 0 0 1 1 1 1 1 1 1 0 1 1 0 0 0 1 0 1 0 1 0 1 1 1 1\n",
            " 1 0 1 1 1 0 0 0 1 0 1 0 1 1 1 0 1 0 1 1 0 0 0 1 1 1 1 1 1 0 1 1 0 1 1 0 1\n",
            " 1 1 0 0 1 0 0 0 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 0 0 0 1 0 0 1 1 1 1 0\n",
            " 0 0 0 1 0 0 0 1 0 1 1 1 1 1 0 0 1 0 0 1 0 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 0\n",
            " 1 1 1 1 1 0 1 1 0 0 1 1 0 0 1 0 1 1 1 1 0 0 0 1 1 0 1 0 0 0 1 1 1 1 1 0 0\n",
            " 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 1 0 1\n",
            " 1 0 0 0 0 1 1 1 1 0 1 0 1 0 1 0 0 1 1 0 0 1 1 1 1 0 1 1 1 0 1 1 0 0 0 1 1\n",
            " 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 0 1 0 1 1 0 0 1 1 0 1 0 1 0 1 1 1 0 1 1 0 1\n",
            " 1 1 0 1 0 1 0 1 1 0 1 0 0 1 0 1 1 1 1 1 0 0 0 0 1 1 0 0 0 1 0 1 0 0 0 1 0\n",
            " 1 1 0 1 1 0 0 0 1 0 0 1 0 1 1 0 0 1 0 1 1 1 1 0 1 0 1 1 1 0 0 0 0 1 1 1 1\n",
            " 1 0 1 0 0 1 0 1 0 0 1 0 0 1 0 0 1 1 0 0 0 0 0 0 1 1 1 0 0 0 1 1 1 0 0 1 1\n",
            " 1 1 1 1 1 0 1 1 1 0 0 1 1 0 1 1 1 0 1 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1 1 1 0\n",
            " 1 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0 1 0 1 1 0 1 1 1 1 0 1 0 0 1 1 0 0 1 1 0 0\n",
            " 1 0 1 1 0 1 1 1 0 1 0 1 0 0 1 1 0 1 0 0 1 0 1 0 0 1 0 1 1 0 1 1 1 0 0 0 1\n",
            " 1 0 1 1 0 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 0 0 1 0 1 1 0 1 1 1 1 0 1 1 0\n",
            " 0 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1 0 1 1 0 0 1 0 0 0 0 0 1 0 0 1 1 0 0 1 0 1\n",
            " 0 1 0 1 0 1 0 0 0 1 1 1 0 1 1 0 0 1 0 1 1 0 1 1 1 0 0 1 0 1 1 1 1 0 0 1 1\n",
            " 0 1 0 0 1 1 0 1 1 0 1 0 1 1 1 1 0 0 0 0 1 1 0 1 0 1 1 1 1 0 1 0 0 0 1 1 0\n",
            " 1 1 1 1 0 1 0 1 1 0 0 0 0 1 0 1 0 1 0 1 0 1 1 1 0 0 1 0 1 1 1 1 1 1 1 0 1\n",
            " 0 0 0 1 0 0 1 0 1 1 1 1 0 0 0 0 0 1 0 1 1 1 1 0 0 1 0 1 1 0 1 0 1 1 0 0 0\n",
            " 0 1 0 0 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 0 1 1 1 1 0\n",
            " 1 0 1 1 1 0 0 1 0 1 0 0 1 1 1 0 1 0 0 0 1 0 0 1 1 0 0 1 1 0 1 1 1 1 1 0 0\n",
            " 1 0 1 0 0 0 0 0 1 0 0 0 1 0 0 1 0 1 1 1 0 1 1 1 0 1 1 1 0 0 1 1 0 1 1 1 0\n",
            " 0 0]\n",
            "probabilities: (927, 2) \n",
            " [0 0 0 0 1 1 0 0 1 0 1 0 1 1 1 0 1 0 0 0 0 0 0 0 0 1 0 1 1 1 1 0 0 0 0 1 1\n",
            " 1 0 0 1 1 0 0 0 1 1 1 1 0 0 0 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 1 1 1 1 1 1 1\n",
            " 0 0 1 0 1 1 0 0 1 0 0 1 0 0 1 1 1 1 1 1 1 0 1 1 0 0 0 1 0 1 0 1 0 1 1 1 1\n",
            " 1 0 1 1 1 0 0 0 1 0 1 0 1 1 1 0 1 0 1 1 0 0 0 1 1 1 1 1 1 0 1 1 0 1 1 0 1\n",
            " 1 1 0 0 1 0 0 0 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 0 0 0 1 0 0 1 1 1 1 0\n",
            " 0 0 0 1 0 0 0 1 0 1 1 1 1 1 0 0 1 0 0 1 0 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 0\n",
            " 1 1 1 1 1 0 1 1 0 0 1 1 0 0 1 0 1 1 1 1 0 0 0 1 1 0 1 0 0 0 1 1 1 1 1 0 0\n",
            " 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 1 0 1\n",
            " 1 0 0 0 0 1 1 1 1 0 1 0 1 0 1 0 0 1 1 0 0 1 1 1 1 0 1 1 1 0 1 1 0 0 0 1 1\n",
            " 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 0 1 0 1 1 0 0 1 1 0 1 0 1 0 1 1 1 0 1 1 0 1\n",
            " 1 1 0 1 0 1 0 1 1 0 1 0 0 1 0 1 1 1 1 1 0 0 0 0 1 1 0 0 0 1 0 1 0 0 0 1 0\n",
            " 1 1 0 1 1 0 0 0 1 0 0 1 0 1 1 0 0 1 0 1 1 1 1 0 1 0 1 1 1 0 0 0 0 1 1 1 1\n",
            " 1 0 1 0 0 1 0 1 0 0 1 0 0 1 0 0 1 1 0 0 0 0 0 0 1 1 1 0 0 0 1 1 1 0 0 1 1\n",
            " 1 1 1 1 1 0 1 1 1 0 0 1 1 0 1 1 1 0 1 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1 1 1 0\n",
            " 1 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0 1 0 1 1 0 1 1 1 1 0 1 0 0 1 1 0 0 1 1 0 0\n",
            " 1 0 1 1 0 1 1 1 0 1 0 1 0 0 1 1 0 1 0 0 1 0 1 0 0 1 0 1 1 0 1 1 1 0 0 0 1\n",
            " 1 0 1 1 0 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 0 0 1 0 1 1 0 1 1 1 1 0 1 1 0\n",
            " 0 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1 0 1 1 0 0 1 0 0 0 0 0 1 0 0 1 1 0 0 1 0 1\n",
            " 0 1 0 1 0 1 0 0 0 1 1 1 0 1 1 0 0 1 0 1 1 0 1 1 1 0 0 1 0 1 1 1 1 0 0 1 1\n",
            " 0 1 0 0 1 1 0 1 1 0 1 0 1 1 1 1 0 0 0 0 1 1 0 1 0 1 1 1 1 0 1 0 0 0 1 1 0\n",
            " 1 1 1 1 0 1 0 1 1 0 0 0 0 1 0 1 0 1 0 1 0 1 1 1 0 0 1 0 1 1 1 1 1 1 1 0 1\n",
            " 0 0 0 1 0 0 1 0 1 1 1 1 0 0 0 0 0 1 0 1 1 1 1 0 0 1 0 1 1 0 1 0 1 1 0 0 0\n",
            " 0 1 0 0 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 0 1 1 1 1 0\n",
            " 1 0 1 1 1 0 0 1 0 1 0 0 1 1 1 0 1 0 0 0 1 0 0 1 1 0 0 1 1 0 1 1 1 1 1 0 0\n",
            " 1 0 1 0 0 0 0 0 1 0 0 0 1 0 0 1 0 1 1 1 0 1 1 1 0 1 1 1 0 0 1 1 0 1 1 1 0\n",
            " 0 0]\n",
            "trainset before adding uncertain samples (375, 10) (375,)\n",
            "trainset after adding uncertain samples (500, 10) (500,)\n",
            "updated train set: (500, 10) (500,) unique(labels): [300 200] [0 1]\n",
            "val set: (802, 10) (802,)\n",
            "\n",
            "Train set: (500, 10)\n",
            "Validation set: (802, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: divide by zero encountered in log2\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: invalid value encountered in multiply\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "--------------------------------\n",
            "Iteration: 4\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.077 s \n",
            "\n",
            "Accuracy rate is 78.571429 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.89      0.86       321\n",
            "           1       0.61      0.49      0.54       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.72      0.69      0.70       434\n",
            "weighted avg       0.77      0.79      0.78       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[286  35]\n",
            " [ 58  55]]\n",
            "--------------------------------\n",
            "final active learning accuracies [78.11059907834101, 78.11059907834101, 79.72350230414746, 78.57142857142857]\n",
            "saved /Users/wenxuanhuang/Documents/Repo/ML-for-COVID-19-dataset/Results/Active-learning-experiment-32.pkl /Users/wenxuanhuang/Documents/Repo/ML-for-COVID-19-dataset ['Decision_tree.ipynb', 'dec_git.png', 'Logit_default_f10.pdf', 'Logistic.ipynb', 'SVC.ipynb', 'RF_f5e50_featureimp.pdf', 'log_al.png', 'dec_git.pdf', '.DS_Store', 'log_git.png', 'svm_git.png', 'Logistic_Scikit.ipynb', 'knn_git.pdf', 'knn_git.png', 'rf_al.png', 'Best classifier_RF_f5e50.pdf', 'KNN.ipynb', 'GBDC.ipynb', 'rf_git.png', 'README.md', 'all_training.csv', 'Results', 'svm_al.png', 'Log_ROC.png', 'Logit_default_f7(p_removal).pdf', 'Active_learning.ipynb', 'Random_forest.ipynb', 'Model_select.ipynb', 'gdbc_git.png', '.git', '.vscode', 'Untitled', 'RF_f5e50_modelselect.pdf', 'Logit_default_f8(std_removal).pdf']\n",
            "\n",
            "---------------------------- FINISHED ---------------------------\n",
            "\n",
            "Count = 33, using model = KnnModel, selection_function = EntropySelection, k = 50, iteration = 0.\n",
            "\n",
            "initial random chosen samples (50,)\n",
            "initial train set: (50, 10) (50,) unique(labels): [21 29] [0 1]\n",
            "Val set: (1252, 10) (1252,) (50,)\n",
            "\n",
            "Train set: (50, 10)\n",
            "Validation set: (1252, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.116 s \n",
            "\n",
            "Accuracy rate is 79.723502 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.91      0.87       321\n",
            "           1       0.65      0.48      0.55       113\n",
            "\n",
            "    accuracy                           0.80       434\n",
            "   macro avg       0.74      0.69      0.71       434\n",
            "weighted avg       0.78      0.80      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[292  29]\n",
            " [ 59  54]]\n",
            "--------------------------------\n",
            "val predicted: (1252,) [1 1 0 ... 0 0 0]\n",
            "probabilities: (1252, 2) \n",
            " [1 1 0 ... 0 0 0]\n",
            "trainset before adding uncertain samples (50, 10) (50,)\n",
            "trainset after adding uncertain samples (100, 10) (100,)\n",
            "updated train set: (100, 10) (100,) unique(labels): [42 58] [0 1]\n",
            "val set: (1202, 10) (1202,)\n",
            "\n",
            "Train set: (100, 10)\n",
            "Validation set: (1202, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: divide by zero encountered in log2\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: invalid value encountered in multiply\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: divide by zero encountered in log2\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: invalid value encountered in multiply\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.095 s \n",
            "\n",
            "Accuracy rate is 78.801843 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.89      0.86       321\n",
            "           1       0.62      0.50      0.55       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.72      0.69      0.71       434\n",
            "weighted avg       0.78      0.79      0.78       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[286  35]\n",
            " [ 57  56]]\n",
            "--------------------------------\n",
            "val predicted: (1202,) [0 1 0 ... 0 0 0]\n",
            "probabilities: (1202, 2) \n",
            " [0 1 0 ... 0 0 0]\n",
            "trainset before adding uncertain samples (100, 10) (100,)\n",
            "trainset after adding uncertain samples (150, 10) (150,)\n",
            "updated train set: (150, 10) (150,) unique(labels): [69 81] [0 1]\n",
            "val set: (1152, 10) (1152,)\n",
            "\n",
            "Train set: (150, 10)\n",
            "Validation set: (1152, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 3\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.112 s \n",
            "\n",
            "Accuracy rate is 78.801843 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.89      0.86       321\n",
            "           1       0.62      0.50      0.55       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.72      0.69      0.71       434\n",
            "weighted avg       0.78      0.79      0.78       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[286  35]\n",
            " [ 57  56]]\n",
            "--------------------------------\n",
            "val predicted: (1152,) [0 1 0 ... 0 0 0]\n",
            "probabilities: (1152, 2) \n",
            " [0 1 0 ... 0 0 0]\n",
            "trainset before adding uncertain samples (150, 10) (150,)\n",
            "trainset after adding uncertain samples (200, 10) (200,)\n",
            "updated train set: (200, 10) (200,) unique(labels): [ 92 108] [0 1]\n",
            "val set: (1102, 10) (1102,)\n",
            "\n",
            "Train set: (200, 10)\n",
            "Validation set: (1102, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: divide by zero encountered in log2\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: invalid value encountered in multiply\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: divide by zero encountered in log2\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: invalid value encountered in multiply\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "--------------------------------\n",
            "Iteration: 4\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.075 s \n",
            "\n",
            "Accuracy rate is 76.267281 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.86      0.84       321\n",
            "           1       0.55      0.49      0.52       113\n",
            "\n",
            "    accuracy                           0.76       434\n",
            "   macro avg       0.69      0.67      0.68       434\n",
            "weighted avg       0.75      0.76      0.76       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[276  45]\n",
            " [ 58  55]]\n",
            "--------------------------------\n",
            "val predicted: (1102,) [0 1 0 ... 0 0 0]\n",
            "probabilities: (1102, 2) \n",
            " [0 1 0 ... 0 0 0]\n",
            "trainset before adding uncertain samples (200, 10) (200,)\n",
            "trainset after adding uncertain samples (250, 10) (250,)\n",
            "updated train set: (250, 10) (250,) unique(labels): [116 134] [0 1]\n",
            "val set: (1052, 10) (1052,)\n",
            "\n",
            "Train set: (250, 10)\n",
            "Validation set: (1052, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 5\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.097 s \n",
            "\n",
            "Accuracy rate is 76.267281 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.85      0.84       321\n",
            "           1       0.55      0.51      0.53       113\n",
            "\n",
            "    accuracy                           0.76       434\n",
            "   macro avg       0.69      0.68      0.69       434\n",
            "weighted avg       0.76      0.76      0.76       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[273  48]\n",
            " [ 55  58]]\n",
            "--------------------------------\n",
            "val predicted: (1052,) [1 1 0 ... 0 0 0]\n",
            "probabilities: (1052, 2) \n",
            " [1 1 0 ... 0 0 0]\n",
            "trainset before adding uncertain samples (250, 10) (250,)\n",
            "trainset after adding uncertain samples (300, 10) (300,)\n",
            "updated train set: (300, 10) (300,) unique(labels): [142 158] [0 1]\n",
            "val set: (1002, 10) (1002,)\n",
            "\n",
            "Train set: (300, 10)\n",
            "Validation set: (1002, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: divide by zero encountered in log2\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: invalid value encountered in multiply\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: divide by zero encountered in log2\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: invalid value encountered in multiply\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "--------------------------------\n",
            "Iteration: 6\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.083 s \n",
            "\n",
            "Accuracy rate is 77.188940 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.87      0.85       321\n",
            "           1       0.57      0.50      0.54       113\n",
            "\n",
            "    accuracy                           0.77       434\n",
            "   macro avg       0.70      0.69      0.69       434\n",
            "weighted avg       0.76      0.77      0.77       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[278  43]\n",
            " [ 56  57]]\n",
            "--------------------------------\n",
            "val predicted: (1002,) [1 1 0 ... 0 0 0]\n",
            "probabilities: (1002, 2) \n",
            " [1 1 0 ... 0 0 0]\n",
            "trainset before adding uncertain samples (300, 10) (300,)\n",
            "trainset after adding uncertain samples (350, 10) (350,)\n",
            "updated train set: (350, 10) (350,) unique(labels): [163 187] [0 1]\n",
            "val set: (952, 10) (952,)\n",
            "\n",
            "Train set: (350, 10)\n",
            "Validation set: (952, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 7\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.113 s \n",
            "\n",
            "Accuracy rate is 78.801843 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86       321\n",
            "           1       0.61      0.52      0.56       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.72      0.70      0.71       434\n",
            "weighted avg       0.78      0.79      0.78       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[283  38]\n",
            " [ 54  59]]\n",
            "--------------------------------\n",
            "val predicted: (952,) [0 1 0 0 1 0 0 1 1 1 0 1 0 1 0 0 1 1 1 1 0 1 0 0 0 0 0 1 0 1 0 1 1 1 0 1 1\n",
            " 0 1 1 0 0 1 0 0 0 0 0 1 1 0 1 0 1 1 0 1 0 0 0 1 1 1 0 1 0 0 1 1 1 0 0 1 1\n",
            " 1 1 1 1 0 0 1 0 1 0 1 0 0 1 0 0 0 0 0 1 1 1 1 1 1 1 0 1 0 0 0 1 1 0 0 0 0\n",
            " 0 1 0 1 0 1 1 0 0 0 1 0 1 1 1 0 0 1 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 1 1 0\n",
            " 0 0 1 1 1 0 1 1 1 1 1 1 0 0 1 1 0 0 0 1 0 0 1 1 0 0 1 0 0 0 0 0 1 0 1 1 1\n",
            " 1 1 1 1 1 0 1 0 0 1 1 0 1 1 0 1 0 0 1 0 1 0 0 1 0 0 0 0 0 0 1 1 0 0 1 1 0\n",
            " 1 0 1 0 1 1 1 0 0 1 1 1 1 0 0 0 1 0 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 0 1 1\n",
            " 0 1 1 0 0 1 1 1 0 1 0 1 1 1 1 1 1 1 0 0 1 0 0 0 1 0 1 1 1 0 0 0 0 0 0 0 1\n",
            " 0 0 0 0 0 1 0 1 0 1 1 0 0 0 1 0 1 1 0 1 0 0 0 1 1 1 0 1 0 1 0 1 0 1 1 1 0\n",
            " 1 1 0 0 0 1 0 1 0 1 0 1 1 1 0 0 1 1 1 1 0 0 1 0 1 0 1 0 0 0 1 1 1 1 1 1 1\n",
            " 1 0 0 1 0 1 1 1 0 1 1 0 1 1 0 1 1 0 0 1 1 0 1 0 1 0 0 0 1 1 1 1 0 1 0 1 0\n",
            " 1 0 1 0 1 0 1 0 1 1 0 0 1 0 1 1 0 1 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 1 0 1\n",
            " 1 0 0 0 0 0 0 1 1 0 1 0 1 1 0 1 1 0 0 0 0 0 0 1 1 1 0 1 0 0 0 1 1 1 1 0 1\n",
            " 0 0 0 0 1 1 1 1 0 1 0 0 1 1 0 0 0 1 1 0 1 0 0 1 1 1 1 1 1 0 0 1 0 1 0 0 0\n",
            " 1 1 1 0 0 0 1 0 0 0 0 0 0 0 1 1 0 1 1 1 0 1 1 1 1 1 1 0 0 0 0 1 1 0 0 1 1\n",
            " 1 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 0 1 1 1 1 0 0 0 0 0 0 1 1 0 0 0 0 1 0\n",
            " 1 1 0 0 1 0 1 0 1 0 1 1 0 1 0 1 1 0 1 1 1 0 0 1 0 1 0 1 0 1 1 0 0 1 1 1 0\n",
            " 1 1 1 0 1 1 1 1 1 1 0 1 0 1 1 0 0 1 0 1 0 1 0 0 0 0 1 0 1 0 1 1 0 0 0 0 0\n",
            " 1 0 0 1 1 1 0 0 1 0 1 0 1 1 1 0 1 1 1 0 1 0 0 1 1 0 1 0 1 0 0 0 0 0 0 1 1\n",
            " 1 0 1 0 0 0 1 0 0 0 1 0 0 1 0 1 0 1 1 0 1 1 1 0 0 0 1 0 0 0 1 0 0 0 1 0 1\n",
            " 0 1 0 1 1 0 0 0 0 1 1 0 0 1 0 1 0 1 1 0 1 0 1 1 0 1 0 1 0 1 0 1 0 1 1 1 1\n",
            " 1 0 1 0 0 0 1 0 0 1 0 1 1 0 1 1 1 0 0 1 0 0 0 0 0 1 1 1 1 0 1 1 1 0 0 0 0\n",
            " 0 1 0 0 1 0 1 0 0 1 1 0 1 0 1 0 0 0 1 1 0 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 0\n",
            " 1 1 1 0 1 1 0 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 0 0 0 1 1 0 1 0 0 0 1 0 0 1\n",
            " 0 1 0 1 1 1 1 1 0 0 1 1 0 1 1 0 0 0 0 1 0 0 1 1 0 0 1 0 0 1 0 0 0 1 0 0 1\n",
            " 1 0 0 1 0 0 1 0 1 1 0 0 1 0 1 0 0 1 1 0 1 1 1 1 0 0 0]\n",
            "probabilities: (952, 2) \n",
            " [0 1 0 0 1 0 0 1 1 1 0 1 0 1 0 0 1 1 1 1 0 1 0 0 0 0 0 1 0 1 0 1 1 1 0 1 1\n",
            " 0 1 1 0 0 1 0 0 0 0 0 1 1 0 1 0 1 1 0 1 0 0 0 1 1 1 0 1 0 0 1 1 1 0 0 1 1\n",
            " 1 1 1 1 0 0 1 0 1 0 1 0 0 1 0 0 0 0 0 1 1 1 1 1 1 1 0 1 0 0 0 1 1 0 0 0 0\n",
            " 0 1 0 1 0 1 1 0 0 0 1 0 1 1 1 0 0 1 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 1 1 0\n",
            " 0 0 1 1 1 0 1 1 1 1 1 1 0 0 1 1 0 0 0 1 0 0 1 1 0 0 1 0 0 0 0 0 1 0 1 1 1\n",
            " 1 1 1 1 1 0 1 0 0 1 1 0 1 1 0 1 0 0 1 0 1 0 0 1 0 0 0 0 0 0 1 1 0 0 1 1 0\n",
            " 1 0 1 0 1 1 1 0 0 1 1 1 1 0 0 0 1 0 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 0 1 1\n",
            " 0 1 1 0 0 1 1 1 0 1 0 1 1 1 1 1 1 1 0 0 1 0 0 0 1 0 1 1 1 0 0 0 0 0 0 0 1\n",
            " 0 0 0 0 0 1 0 1 0 1 1 0 0 0 1 0 1 1 0 1 0 0 0 1 1 1 0 1 0 1 0 1 0 1 1 1 0\n",
            " 1 1 0 0 0 1 0 1 0 1 0 1 1 1 0 0 1 1 1 1 0 0 1 0 1 0 1 0 0 0 1 1 1 1 1 1 1\n",
            " 1 0 0 1 0 1 1 1 0 1 1 0 1 1 0 1 1 0 0 1 1 0 1 0 1 0 0 0 1 1 1 1 0 1 0 1 0\n",
            " 1 0 1 0 1 0 1 0 1 1 0 0 1 0 1 1 0 1 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 1 0 1\n",
            " 1 0 0 0 0 0 0 1 1 0 1 0 1 1 0 1 1 0 0 0 0 0 0 1 1 1 0 1 0 0 0 1 1 1 1 0 1\n",
            " 0 0 0 0 1 1 1 1 0 1 0 0 1 1 0 0 0 1 1 0 1 0 0 1 1 1 1 1 1 0 0 1 0 1 0 0 0\n",
            " 1 1 1 0 0 0 1 0 0 0 0 0 0 0 1 1 0 1 1 1 0 1 1 1 1 1 1 0 0 0 0 1 1 0 0 1 1\n",
            " 1 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 0 1 1 1 1 0 0 0 0 0 0 1 1 0 0 0 0 1 0\n",
            " 1 1 0 0 1 0 1 0 1 0 1 1 0 1 0 1 1 0 1 1 1 0 0 1 0 1 0 1 0 1 1 0 0 1 1 1 0\n",
            " 1 1 1 0 1 1 1 1 1 1 0 1 0 1 1 0 0 1 0 1 0 1 0 0 0 0 1 0 1 0 1 1 0 0 0 0 0\n",
            " 1 0 0 1 1 1 0 0 1 0 1 0 1 1 1 0 1 1 1 0 1 0 0 1 1 0 1 0 1 0 0 0 0 0 0 1 1\n",
            " 1 0 1 0 0 0 1 0 0 0 1 0 0 1 0 1 0 1 1 0 1 1 1 0 0 0 1 0 0 0 1 0 0 0 1 0 1\n",
            " 0 1 0 1 1 0 0 0 0 1 1 0 0 1 0 1 0 1 1 0 1 0 1 1 0 1 0 1 0 1 0 1 0 1 1 1 1\n",
            " 1 0 1 0 0 0 1 0 0 1 0 1 1 0 1 1 1 0 0 1 0 0 0 0 0 1 1 1 1 0 1 1 1 0 0 0 0\n",
            " 0 1 0 0 1 0 1 0 0 1 1 0 1 0 1 0 0 0 1 1 0 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 0\n",
            " 1 1 1 0 1 1 0 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 0 0 0 1 1 0 1 0 0 0 1 0 0 1\n",
            " 0 1 0 1 1 1 1 1 0 0 1 1 0 1 1 0 0 0 0 1 0 0 1 1 0 0 1 0 0 1 0 0 0 1 0 0 1\n",
            " 1 0 0 1 0 0 1 0 1 1 0 0 1 0 1 0 0 1 1 0 1 1 1 1 0 0 0]\n",
            "trainset before adding uncertain samples (350, 10) (350,)\n",
            "trainset after adding uncertain samples (400, 10) (400,)\n",
            "updated train set: (400, 10) (400,) unique(labels): [176 224] [0 1]\n",
            "val set: (902, 10) (902,)\n",
            "\n",
            "Train set: (400, 10)\n",
            "Validation set: (902, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: divide by zero encountered in log2\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: invalid value encountered in multiply\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: divide by zero encountered in log2\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: invalid value encountered in multiply\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "--------------------------------\n",
            "Iteration: 8\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.142 s \n",
            "\n",
            "Accuracy rate is 77.419355 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.88      0.85       321\n",
            "           1       0.58      0.48      0.52       113\n",
            "\n",
            "    accuracy                           0.77       434\n",
            "   macro avg       0.70      0.68      0.69       434\n",
            "weighted avg       0.76      0.77      0.77       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[282  39]\n",
            " [ 59  54]]\n",
            "--------------------------------\n",
            "val predicted: (902,) [0 1 0 0 1 0 0 0 1 0 1 0 1 0 0 1 1 1 1 0 1 0 0 0 0 1 1 1 0 1 1 1 0 1 1 0 1\n",
            " 0 1 0 0 0 0 1 1 1 0 1 0 1 1 0 1 1 0 0 1 1 1 0 1 0 0 1 1 1 0 1 1 1 1 1 1 1\n",
            " 0 0 1 0 1 0 1 0 0 1 0 0 0 0 0 1 1 1 1 1 1 1 0 1 0 0 0 1 1 0 0 0 0 0 1 0 1\n",
            " 0 1 1 0 0 0 1 0 1 1 0 0 1 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 1 1 0 0 0 1 1 1\n",
            " 0 1 1 1 1 0 0 1 1 0 0 0 1 0 0 1 1 0 0 1 0 0 0 0 0 1 0 1 1 1 1 1 1 1 1 0 1\n",
            " 0 0 1 0 1 0 1 0 0 0 0 1 0 0 1 1 0 0 0 0 0 1 1 0 0 1 1 0 1 0 1 0 1 1 1 0 0\n",
            " 1 1 1 1 0 0 0 1 0 1 1 0 1 1 1 1 0 1 0 0 1 1 1 1 1 0 1 1 0 1 1 0 0 1 1 1 0\n",
            " 1 0 1 1 1 1 1 1 1 0 0 1 0 0 0 1 0 1 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0\n",
            " 1 1 0 0 0 1 1 1 1 0 1 0 0 0 1 1 0 0 0 1 0 1 1 0 1 1 1 0 0 1 0 1 0 1 0 1 1\n",
            " 1 0 0 1 1 1 0 0 1 0 1 0 1 0 0 0 1 1 1 1 1 1 0 0 1 0 1 1 1 0 1 1 0 1 0 1 0\n",
            " 0 1 1 0 1 0 1 0 0 0 1 1 1 1 0 1 0 1 0 0 1 1 1 0 0 1 1 0 0 1 0 0 0 0 0 0 0\n",
            " 0 0 1 0 0 1 0 0 0 0 1 1 0 0 0 0 0 1 0 1 1 0 1 1 0 0 0 0 0 0 1 1 1 0 1 0 0\n",
            " 1 1 1 1 0 1 0 0 0 0 1 1 1 1 0 1 0 0 1 1 0 0 0 1 1 0 1 0 0 1 1 1 1 1 1 0 1\n",
            " 0 1 0 0 0 1 1 1 0 0 0 1 0 0 0 0 0 0 1 0 1 1 0 1 1 1 1 1 1 0 0 0 0 1 1 0 0\n",
            " 1 1 0 0 1 1 0 0 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 0 0 0 1 1 0 0 0 0 1 0 1\n",
            " 1 1 0 1 0 1 0 1 0 1 1 0 1 0 1 1 0 1 1 1 0 0 1 0 1 0 1 0 1 1 0 0 1 1 1 0 1\n",
            " 1 1 1 1 1 1 1 1 1 0 1 0 1 1 0 0 1 0 1 0 1 0 0 0 0 1 0 1 0 1 1 0 0 0 1 0 1\n",
            " 0 0 1 1 1 0 0 1 0 1 0 1 1 1 0 1 1 1 0 1 0 0 1 1 0 1 1 1 0 0 0 0 0 0 1 1 1\n",
            " 0 1 1 0 1 0 0 0 1 0 0 1 0 1 0 1 1 0 0 1 1 0 0 0 1 0 0 0 1 0 0 0 1 0 1 0 1\n",
            " 0 1 1 0 0 0 0 1 1 0 0 1 0 1 0 1 1 0 1 0 1 1 0 0 0 1 0 1 1 1 0 1 1 1 1 0 1\n",
            " 0 0 0 1 0 0 1 0 1 1 0 1 1 0 0 1 0 0 0 0 0 1 0 1 0 1 1 0 0 0 0 0 1 0 0 1 0\n",
            " 1 0 0 1 1 0 1 0 0 0 0 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 0 1 1 1 0 1 0 1 0 1\n",
            " 1 0 1 1 1 1 1 1 1 0 1 1 0 0 0 1 1 0 1 0 0 0 1 0 0 1 0 1 1 1 1 1 1 0 0 1 0\n",
            " 1 1 0 0 0 0 1 0 0 1 1 0 0 1 0 0 1 1 0 0 1 0 1 1 1 0 0 1 0 0 1 1 1 1 0 0 1\n",
            " 1 1 0 0 1 1 0 0 1 1 1 0 0 0]\n",
            "probabilities: (902, 2) \n",
            " [0 1 0 0 1 0 0 0 1 0 1 0 1 0 0 1 1 1 1 0 1 0 0 0 0 1 1 1 0 1 1 1 0 1 1 0 1\n",
            " 0 1 0 0 0 0 1 1 1 0 1 0 1 1 0 1 1 0 0 1 1 1 0 1 0 0 1 1 1 0 1 1 1 1 1 1 1\n",
            " 0 0 1 0 1 0 1 0 0 1 0 0 0 0 0 1 1 1 1 1 1 1 0 1 0 0 0 1 1 0 0 0 0 0 1 0 1\n",
            " 0 1 1 0 0 0 1 0 1 1 0 0 1 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 1 1 0 0 0 1 1 1\n",
            " 0 1 1 1 1 0 0 1 1 0 0 0 1 0 0 1 1 0 0 1 0 0 0 0 0 1 0 1 1 1 1 1 1 1 1 0 1\n",
            " 0 0 1 0 1 0 1 0 0 0 0 1 0 0 1 1 0 0 0 0 0 1 1 0 0 1 1 0 1 0 1 0 1 1 1 0 0\n",
            " 1 1 1 1 0 0 0 1 0 1 1 0 1 1 1 1 0 1 0 0 1 1 1 1 1 0 1 1 0 1 1 0 0 1 1 1 0\n",
            " 1 0 1 1 1 1 1 1 1 0 0 1 0 0 0 1 0 1 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0\n",
            " 1 1 0 0 0 1 1 1 1 0 1 0 0 0 1 1 0 0 0 1 0 1 1 0 1 1 1 0 0 1 0 1 0 1 0 1 1\n",
            " 1 0 0 1 1 1 0 0 1 0 1 0 1 0 0 0 1 1 1 1 1 1 0 0 1 0 1 1 1 0 1 1 0 1 0 1 0\n",
            " 0 1 1 0 1 0 1 0 0 0 1 1 1 1 0 1 0 1 0 0 1 1 1 0 0 1 1 0 0 1 0 0 0 0 0 0 0\n",
            " 0 0 1 0 0 1 0 0 0 0 1 1 0 0 0 0 0 1 0 1 1 0 1 1 0 0 0 0 0 0 1 1 1 0 1 0 0\n",
            " 1 1 1 1 0 1 0 0 0 0 1 1 1 1 0 1 0 0 1 1 0 0 0 1 1 0 1 0 0 1 1 1 1 1 1 0 1\n",
            " 0 1 0 0 0 1 1 1 0 0 0 1 0 0 0 0 0 0 1 0 1 1 0 1 1 1 1 1 1 0 0 0 0 1 1 0 0\n",
            " 1 1 0 0 1 1 0 0 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 0 0 0 1 1 0 0 0 0 1 0 1\n",
            " 1 1 0 1 0 1 0 1 0 1 1 0 1 0 1 1 0 1 1 1 0 0 1 0 1 0 1 0 1 1 0 0 1 1 1 0 1\n",
            " 1 1 1 1 1 1 1 1 1 0 1 0 1 1 0 0 1 0 1 0 1 0 0 0 0 1 0 1 0 1 1 0 0 0 1 0 1\n",
            " 0 0 1 1 1 0 0 1 0 1 0 1 1 1 0 1 1 1 0 1 0 0 1 1 0 1 1 1 0 0 0 0 0 0 1 1 1\n",
            " 0 1 1 0 1 0 0 0 1 0 0 1 0 1 0 1 1 0 0 1 1 0 0 0 1 0 0 0 1 0 0 0 1 0 1 0 1\n",
            " 0 1 1 0 0 0 0 1 1 0 0 1 0 1 0 1 1 0 1 0 1 1 0 0 0 1 0 1 1 1 0 1 1 1 1 0 1\n",
            " 0 0 0 1 0 0 1 0 1 1 0 1 1 0 0 1 0 0 0 0 0 1 0 1 0 1 1 0 0 0 0 0 1 0 0 1 0\n",
            " 1 0 0 1 1 0 1 0 0 0 0 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 0 1 1 1 0 1 0 1 0 1\n",
            " 1 0 1 1 1 1 1 1 1 0 1 1 0 0 0 1 1 0 1 0 0 0 1 0 0 1 0 1 1 1 1 1 1 0 0 1 0\n",
            " 1 1 0 0 0 0 1 0 0 1 1 0 0 1 0 0 1 1 0 0 1 0 1 1 1 0 0 1 0 0 1 1 1 1 0 0 1\n",
            " 1 1 0 0 1 1 0 0 1 1 1 0 0 0]\n",
            "trainset before adding uncertain samples (400, 10) (400,)\n",
            "trainset after adding uncertain samples (450, 10) (450,)\n",
            "updated train set: (450, 10) (450,) unique(labels): [185 265] [0 1]\n",
            "val set: (852, 10) (852,)\n",
            "\n",
            "Train set: (450, 10)\n",
            "Validation set: (852, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 9\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.058 s \n",
            "\n",
            "Accuracy rate is 78.110599 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86       321\n",
            "           1       0.59      0.51      0.55       113\n",
            "\n",
            "    accuracy                           0.78       434\n",
            "   macro avg       0.71      0.69      0.70       434\n",
            "weighted avg       0.77      0.78      0.78       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[281  40]\n",
            " [ 55  58]]\n",
            "--------------------------------\n",
            "val predicted: (852,) [0 1 0 0 1 0 0 0 1 0 1 0 1 0 0 1 1 1 1 0 1 0 0 0 0 1 1 1 0 1 1 1 0 1 1 0 1\n",
            " 0 1 0 0 0 0 1 1 1 0 1 0 1 0 1 1 0 0 1 0 1 0 0 1 1 0 0 1 1 1 0 0 1 0 0 1 0\n",
            " 0 1 0 0 0 0 0 1 1 1 1 1 1 0 0 0 1 1 0 0 0 0 0 1 0 1 0 0 1 0 0 1 1 1 1 0 0\n",
            " 1 0 0 1 0 0 0 0 1 0 1 0 1 0 0 0 0 1 1 0 0 0 1 1 1 0 1 1 0 0 0 0 0 1 0 0 1\n",
            " 1 0 1 1 0 0 0 0 0 1 0 1 1 1 1 1 1 1 1 1 0 0 1 0 1 0 1 0 0 0 0 1 0 1 1 0 0\n",
            " 0 0 0 1 1 0 1 1 1 0 1 0 1 0 1 1 1 0 0 1 1 1 1 0 1 0 1 0 1 1 0 1 1 1 1 0 1\n",
            " 0 0 1 1 1 1 1 0 1 1 0 1 1 0 0 1 1 0 1 1 1 1 1 1 1 0 0 1 0 0 0 1 0 1 1 1 0\n",
            " 0 0 0 0 0 0 1 0 0 1 0 0 1 1 0 1 0 0 0 1 1 1 1 0 1 0 0 0 1 0 0 0 1 0 1 1 0\n",
            " 1 1 1 1 0 1 0 1 0 1 0 1 1 1 0 0 1 1 0 0 1 0 1 0 1 0 0 0 1 1 1 1 1 1 0 0 0\n",
            " 0 1 1 0 0 1 0 1 0 0 1 1 0 1 0 1 0 0 0 1 1 1 1 0 1 0 1 0 0 1 1 1 0 0 1 1 0\n",
            " 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 1 0 0 1 0 1 1 0 1 1 0 0 0 0 0\n",
            " 0 1 1 1 0 0 0 0 1 1 1 1 0 1 0 0 0 0 1 1 1 1 0 1 0 0 1 0 0 0 1 0 1 0 0 1 1\n",
            " 1 1 1 1 0 1 0 1 0 0 0 1 1 1 0 0 0 1 0 0 0 0 0 0 1 0 1 1 0 1 1 1 1 0 0 0 0\n",
            " 1 1 0 0 1 1 0 0 1 1 0 0 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 0 0 1 1 0 0 0 0\n",
            " 1 0 1 1 1 0 0 1 0 0 1 1 0 1 0 1 0 1 1 1 0 0 1 0 1 1 1 0 1 1 0 0 1 1 1 0 1\n",
            " 1 1 1 1 1 1 1 1 1 0 1 0 1 1 0 0 1 0 1 0 1 0 0 0 0 1 0 1 0 1 1 0 0 0 1 0 1\n",
            " 0 0 1 1 1 0 0 1 0 1 0 1 1 0 0 1 1 1 0 1 0 0 1 1 0 1 1 1 0 0 0 0 0 0 1 1 1\n",
            " 0 1 1 0 1 0 0 0 1 0 0 1 0 1 0 1 1 1 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 1 0\n",
            " 0 0 0 1 1 0 0 1 0 1 0 1 1 0 1 0 1 1 0 0 0 1 0 1 1 1 0 1 1 1 1 0 1 0 0 0 1\n",
            " 1 0 0 1 1 0 1 0 0 1 0 0 0 0 0 1 0 1 0 1 1 0 0 0 0 0 0 0 1 0 1 0 0 1 1 0 1\n",
            " 0 1 0 0 0 0 1 1 1 0 1 1 1 1 1 0 1 1 1 0 1 1 1 0 0 1 0 1 1 0 1 1 1 1 1 1 0\n",
            " 1 1 0 0 0 1 0 0 0 1 0 0 1 0 1 1 1 1 1 1 0 0 1 0 1 1 0 0 0 0 1 0 0 1 1 0 0\n",
            " 1 0 0 1 1 0 0 1 0 1 1 1 1 0 1 0 0 1 1 1 0 0 0 1 1 1 0 0 1 1 0 0 1 1 1 0 0\n",
            " 0]\n",
            "probabilities: (852, 2) \n",
            " [0 1 0 0 1 0 0 0 1 0 1 0 1 0 0 1 1 1 1 0 1 0 0 0 0 1 1 1 0 1 1 1 0 1 1 0 1\n",
            " 0 1 0 0 0 0 1 1 1 0 1 0 1 0 1 1 0 0 1 0 1 0 0 1 1 0 0 1 1 1 0 0 1 0 0 1 0\n",
            " 0 1 0 0 0 0 0 1 1 1 1 1 1 0 0 0 1 1 0 0 0 0 0 1 0 1 0 0 1 0 0 1 1 1 1 0 0\n",
            " 1 0 0 1 0 0 0 0 1 0 1 0 1 0 0 0 0 1 1 0 0 0 1 1 1 0 1 1 0 0 0 0 0 1 0 0 1\n",
            " 1 0 1 1 0 0 0 0 0 1 0 1 1 1 1 1 1 1 1 1 0 0 1 0 1 0 1 0 0 0 0 1 0 1 1 0 0\n",
            " 0 0 0 1 1 0 1 1 1 0 1 0 1 0 1 1 1 0 0 1 1 1 1 0 1 0 1 0 1 1 0 1 1 1 1 0 1\n",
            " 0 0 1 1 1 1 1 0 1 1 0 1 1 0 0 1 1 0 1 1 1 1 1 1 1 0 0 1 0 0 0 1 0 1 1 1 0\n",
            " 0 0 0 0 0 0 1 0 0 1 0 0 1 1 0 1 0 0 0 1 1 1 1 0 1 0 0 0 1 0 0 0 1 0 1 1 0\n",
            " 1 1 1 1 0 1 0 1 0 1 0 1 1 1 0 0 1 1 0 0 1 0 1 0 1 0 0 0 1 1 1 1 1 1 0 0 0\n",
            " 0 1 1 0 0 1 0 1 0 0 1 1 0 1 0 1 0 0 0 1 1 1 1 0 1 0 1 0 0 1 1 1 0 0 1 1 0\n",
            " 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 1 0 0 1 0 1 1 0 1 1 0 0 0 0 0\n",
            " 0 1 1 1 0 0 0 0 1 1 1 1 0 1 0 0 0 0 1 1 1 1 0 1 0 0 1 0 0 0 1 0 1 0 0 1 1\n",
            " 1 1 1 1 0 1 0 1 0 0 0 1 1 1 0 0 0 1 0 0 0 0 0 0 1 0 1 1 0 1 1 1 1 0 0 0 0\n",
            " 1 1 0 0 1 1 0 0 1 1 0 0 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 0 0 1 1 0 0 0 0\n",
            " 1 0 1 1 1 0 0 1 0 0 1 1 0 1 0 1 0 1 1 1 0 0 1 0 1 1 1 0 1 1 0 0 1 1 1 0 1\n",
            " 1 1 1 1 1 1 1 1 1 0 1 0 1 1 0 0 1 0 1 0 1 0 0 0 0 1 0 1 0 1 1 0 0 0 1 0 1\n",
            " 0 0 1 1 1 0 0 1 0 1 0 1 1 0 0 1 1 1 0 1 0 0 1 1 0 1 1 1 0 0 0 0 0 0 1 1 1\n",
            " 0 1 1 0 1 0 0 0 1 0 0 1 0 1 0 1 1 1 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 1 0\n",
            " 0 0 0 1 1 0 0 1 0 1 0 1 1 0 1 0 1 1 0 0 0 1 0 1 1 1 0 1 1 1 1 0 1 0 0 0 1\n",
            " 1 0 0 1 1 0 1 0 0 1 0 0 0 0 0 1 0 1 0 1 1 0 0 0 0 0 0 0 1 0 1 0 0 1 1 0 1\n",
            " 0 1 0 0 0 0 1 1 1 0 1 1 1 1 1 0 1 1 1 0 1 1 1 0 0 1 0 1 1 0 1 1 1 1 1 1 0\n",
            " 1 1 0 0 0 1 0 0 0 1 0 0 1 0 1 1 1 1 1 1 0 0 1 0 1 1 0 0 0 0 1 0 0 1 1 0 0\n",
            " 1 0 0 1 1 0 0 1 0 1 1 1 1 0 1 0 0 1 1 1 0 0 0 1 1 1 0 0 1 1 0 0 1 1 1 0 0\n",
            " 0]\n",
            "trainset before adding uncertain samples (450, 10) (450,)\n",
            "trainset after adding uncertain samples (500, 10) (500,)\n",
            "updated train set: (500, 10) (500,) unique(labels): [198 302] [0 1]\n",
            "val set: (802, 10) (802,)\n",
            "\n",
            "Train set: (500, 10)\n",
            "Validation set: (802, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 10\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.061 s \n",
            "\n",
            "Accuracy rate is 77.649770 \n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: divide by zero encountered in log2\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: invalid value encountered in multiply\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.86      0.85       321\n",
            "           1       0.58      0.53      0.55       113\n",
            "\n",
            "    accuracy                           0.78       434\n",
            "   macro avg       0.71      0.70      0.70       434\n",
            "weighted avg       0.77      0.78      0.77       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[277  44]\n",
            " [ 53  60]]\n",
            "--------------------------------\n",
            "final active learning accuracies [79.72350230414746, 78.80184331797236, 78.80184331797236, 76.26728110599078, 76.26728110599078, 77.18894009216591, 78.80184331797236, 77.41935483870968, 78.11059907834101, 77.64976958525345]\n",
            "saved /Users/wenxuanhuang/Documents/Repo/ML-for-COVID-19-dataset/Results/Active-learning-experiment-33.pkl /Users/wenxuanhuang/Documents/Repo/ML-for-COVID-19-dataset ['Decision_tree.ipynb', 'dec_git.png', 'Logit_default_f10.pdf', 'Logistic.ipynb', 'SVC.ipynb', 'RF_f5e50_featureimp.pdf', 'log_al.png', 'dec_git.pdf', '.DS_Store', 'log_git.png', 'svm_git.png', 'Logistic_Scikit.ipynb', 'knn_git.pdf', 'knn_git.png', 'rf_al.png', 'Best classifier_RF_f5e50.pdf', 'KNN.ipynb', 'GBDC.ipynb', 'rf_git.png', 'README.md', 'all_training.csv', 'Results', 'svm_al.png', 'Log_ROC.png', 'Logit_default_f7(p_removal).pdf', 'Active_learning.ipynb', 'Random_forest.ipynb', 'Model_select.ipynb', 'gdbc_git.png', '.git', '.vscode', 'Untitled', 'RF_f5e50_modelselect.pdf', 'Logit_default_f8(std_removal).pdf']\n",
            "\n",
            "---------------------------- FINISHED ---------------------------\n",
            "\n",
            "Count = 34, using model = KnnModel, selection_function = EntropySelection, k = 25, iteration = 0.\n",
            "\n",
            "initial random chosen samples (25,)\n",
            "initial train set: (25, 10) (25,) unique(labels): [13 12] [0 1]\n",
            "Val set: (1277, 10) (1277,) (25,)\n",
            "\n",
            "Train set: (25, 10)\n",
            "Validation set: (1277, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.098 s \n",
            "\n",
            "Accuracy rate is 77.649770 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.88      0.85       321\n",
            "           1       0.59      0.47      0.52       113\n",
            "\n",
            "    accuracy                           0.78       434\n",
            "   macro avg       0.71      0.68      0.69       434\n",
            "weighted avg       0.76      0.78      0.77       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[284  37]\n",
            " [ 60  53]]\n",
            "--------------------------------\n",
            "val predicted: (1277,) [0 1 1 ... 0 0 1]\n",
            "probabilities: (1277, 2) \n",
            " [0 1 1 ... 0 0 1]\n",
            "trainset before adding uncertain samples (25, 10) (25,)\n",
            "trainset after adding uncertain samples (50, 10) (50,)\n",
            "updated train set: (50, 10) (50,) unique(labels): [25 25] [0 1]\n",
            "val set: (1252, 10) (1252,)\n",
            "\n",
            "Train set: (50, 10)\n",
            "Validation set: (1252, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.070 s \n",
            "\n",
            "Accuracy rate is 76.036866 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.87      0.84       321\n",
            "           1       0.55      0.45      0.50       113\n",
            "\n",
            "    accuracy                           0.76       434\n",
            "   macro avg       0.68      0.66      0.67       434\n",
            "weighted avg       0.75      0.76      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[279  42]\n",
            " [ 62  51]]\n",
            "--------------------------------\n",
            "val predicted: (1252,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1252, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "trainset before adding uncertain samples (50, 10) (50,)\n",
            "trainset after adding uncertain samples (75, 10) (75,)\n",
            "updated train set: (75, 10) (75,) unique(labels): [39 36] [0 1]\n",
            "val set: (1227, 10) (1227,)\n",
            "\n",
            "Train set: (75, 10)\n",
            "Validation set: (1227, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 3\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.073 s \n",
            "\n",
            "Accuracy rate is 77.649770 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.90      0.86       321\n",
            "           1       0.60      0.43      0.50       113\n",
            "\n",
            "    accuracy                           0.78       434\n",
            "   macro avg       0.71      0.67      0.68       434\n",
            "weighted avg       0.76      0.78      0.76       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[288  33]\n",
            " [ 64  49]]\n",
            "--------------------------------\n",
            "val predicted: (1227,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1227, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "trainset before adding uncertain samples (75, 10) (75,)\n",
            "trainset after adding uncertain samples (100, 10) (100,)\n",
            "updated train set: (100, 10) (100,) unique(labels): [43 57] [0 1]\n",
            "val set: (1202, 10) (1202,)\n",
            "\n",
            "Train set: (100, 10)\n",
            "Validation set: (1202, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 4\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.066 s \n",
            "\n",
            "Accuracy rate is 77.649770 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.88      0.85       321\n",
            "           1       0.59      0.48      0.53       113\n",
            "\n",
            "    accuracy                           0.78       434\n",
            "   macro avg       0.71      0.68      0.69       434\n",
            "weighted avg       0.76      0.78      0.77       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[283  38]\n",
            " [ 59  54]]\n",
            "--------------------------------\n",
            "val predicted: (1202,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1202, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "trainset before adding uncertain samples (100, 10) (100,)\n",
            "trainset after adding uncertain samples (125, 10) (125,)\n",
            "updated train set: (125, 10) (125,) unique(labels): [45 80] [0 1]\n",
            "val set: (1177, 10) (1177,)\n",
            "\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: divide by zero encountered in log2\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: invalid value encountered in multiply\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: divide by zero encountered in log2\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: invalid value encountered in multiply\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: divide by zero encountered in log2\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: invalid value encountered in multiply\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "Train set: (125, 10)\n",
            "Validation set: (1177, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 5\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.068 s \n",
            "\n",
            "Accuracy rate is 77.188940 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.86      0.85       321\n",
            "           1       0.57      0.53      0.55       113\n",
            "\n",
            "    accuracy                           0.77       434\n",
            "   macro avg       0.70      0.69      0.70       434\n",
            "weighted avg       0.77      0.77      0.77       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[275  46]\n",
            " [ 53  60]]\n",
            "--------------------------------\n",
            "val predicted: (1177,) [0 1 1 ... 0 0 1]\n",
            "probabilities: (1177, 2) \n",
            " [0 1 1 ... 0 0 1]\n",
            "trainset before adding uncertain samples (125, 10) (125,)\n",
            "trainset after adding uncertain samples (150, 10) (150,)\n",
            "updated train set: (150, 10) (150,) unique(labels): [ 48 102] [0 1]\n",
            "val set: (1152, 10) (1152,)\n",
            "\n",
            "Train set: (150, 10)\n",
            "Validation set: (1152, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: divide by zero encountered in log2\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: invalid value encountered in multiply\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: divide by zero encountered in log2\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: invalid value encountered in multiply\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "--------------------------------\n",
            "Iteration: 6\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.110 s \n",
            "\n",
            "Accuracy rate is 77.649770 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.87      0.85       321\n",
            "           1       0.58      0.50      0.54       113\n",
            "\n",
            "    accuracy                           0.78       434\n",
            "   macro avg       0.71      0.69      0.70       434\n",
            "weighted avg       0.77      0.78      0.77       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[280  41]\n",
            " [ 56  57]]\n",
            "--------------------------------\n",
            "val predicted: (1152,) [0 1 1 ... 0 0 1]\n",
            "probabilities: (1152, 2) \n",
            " [0 1 1 ... 0 0 1]\n",
            "trainset before adding uncertain samples (150, 10) (150,)\n",
            "trainset after adding uncertain samples (175, 10) (175,)\n",
            "updated train set: (175, 10) (175,) unique(labels): [ 48 127] [0 1]\n",
            "val set: (1127, 10) (1127,)\n",
            "\n",
            "Train set: (175, 10)\n",
            "Validation set: (1127, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 7\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.069 s \n",
            "\n",
            "Accuracy rate is 77.419355 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.85      0.85       321\n",
            "           1       0.57      0.55      0.56       113\n",
            "\n",
            "    accuracy                           0.77       434\n",
            "   macro avg       0.71      0.70      0.70       434\n",
            "weighted avg       0.77      0.77      0.77       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[274  47]\n",
            " [ 51  62]]\n",
            "--------------------------------\n",
            "val predicted: (1127,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1127, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "trainset before adding uncertain samples (175, 10) (175,)\n",
            "trainset after adding uncertain samples (200, 10) (200,)\n",
            "updated train set: (200, 10) (200,) unique(labels): [ 51 149] [0 1]\n",
            "val set: (1102, 10) (1102,)\n",
            "\n",
            "Train set: (200, 10)\n",
            "Validation set: (1102, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: divide by zero encountered in log2\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: invalid value encountered in multiply\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: divide by zero encountered in log2\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: invalid value encountered in multiply\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "--------------------------------\n",
            "Iteration: 8\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.121 s \n",
            "\n",
            "Accuracy rate is 76.728111 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.84      0.84       321\n",
            "           1       0.55      0.56      0.56       113\n",
            "\n",
            "    accuracy                           0.77       434\n",
            "   macro avg       0.70      0.70      0.70       434\n",
            "weighted avg       0.77      0.77      0.77       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[270  51]\n",
            " [ 50  63]]\n",
            "--------------------------------\n",
            "val predicted: (1102,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1102, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "trainset before adding uncertain samples (200, 10) (200,)\n",
            "trainset after adding uncertain samples (225, 10) (225,)\n",
            "updated train set: (225, 10) (225,) unique(labels): [ 54 171] [0 1]\n",
            "val set: (1077, 10) (1077,)\n",
            "\n",
            "Train set: (225, 10)\n",
            "Validation set: (1077, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 9\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.066 s \n",
            "\n",
            "Accuracy rate is 76.267281 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.83      0.84       321\n",
            "           1       0.54      0.56      0.55       113\n",
            "\n",
            "    accuracy                           0.76       434\n",
            "   macro avg       0.69      0.70      0.69       434\n",
            "weighted avg       0.76      0.76      0.76       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[268  53]\n",
            " [ 50  63]]\n",
            "--------------------------------\n",
            "val predicted: (1077,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1077, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "trainset before adding uncertain samples (225, 10) (225,)\n",
            "trainset after adding uncertain samples (250, 10) (250,)\n",
            "updated train set: (250, 10) (250,) unique(labels): [ 58 192] [0 1]\n",
            "val set: (1052, 10) (1052,)\n",
            "\n",
            "Train set: (250, 10)\n",
            "Validation set: (1052, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: divide by zero encountered in log2\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: invalid value encountered in multiply\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: divide by zero encountered in log2\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: invalid value encountered in multiply\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "--------------------------------\n",
            "Iteration: 10\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.087 s \n",
            "\n",
            "Accuracy rate is 76.497696 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.83      0.84       321\n",
            "           1       0.55      0.58      0.56       113\n",
            "\n",
            "    accuracy                           0.76       434\n",
            "   macro avg       0.70      0.70      0.70       434\n",
            "weighted avg       0.77      0.76      0.77       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[267  54]\n",
            " [ 48  65]]\n",
            "--------------------------------\n",
            "val predicted: (1052,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1052, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "trainset before adding uncertain samples (250, 10) (250,)\n",
            "trainset after adding uncertain samples (275, 10) (275,)\n",
            "updated train set: (275, 10) (275,) unique(labels): [ 60 215] [0 1]\n",
            "val set: (1027, 10) (1027,)\n",
            "\n",
            "Train set: (275, 10)\n",
            "Validation set: (1027, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 11\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.066 s \n",
            "\n",
            "Accuracy rate is 74.654378 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.81      0.82       321\n",
            "           1       0.51      0.58      0.54       113\n",
            "\n",
            "    accuracy                           0.75       434\n",
            "   macro avg       0.68      0.69      0.68       434\n",
            "weighted avg       0.76      0.75      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[259  62]\n",
            " [ 48  65]]\n",
            "--------------------------------\n",
            "val predicted: (1027,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1027, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "trainset before adding uncertain samples (275, 10) (275,)\n",
            "trainset after adding uncertain samples (300, 10) (300,)\n",
            "updated train set: (300, 10) (300,) unique(labels): [ 64 236] [0 1]\n",
            "val set: (1002, 10) (1002,)\n",
            "\n",
            "Train set: (300, 10)\n",
            "Validation set: (1002, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 12\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.066 s \n",
            "\n",
            "Accuracy rate is 74.654378 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.80      0.82       321\n",
            "           1       0.51      0.58      0.55       113\n",
            "\n",
            "    accuracy                           0.75       434\n",
            "   macro avg       0.68      0.69      0.68       434\n",
            "weighted avg       0.76      0.75      0.75       434\n",
            "\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: divide by zero encountered in log2\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: invalid value encountered in multiply\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: divide by zero encountered in log2\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: invalid value encountered in multiply\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: divide by zero encountered in log2\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: invalid value encountered in multiply\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "\n",
            "Confusion matrix:\n",
            "[[258  63]\n",
            " [ 47  66]]\n",
            "--------------------------------\n",
            "val predicted: (1002,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1002, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "trainset before adding uncertain samples (300, 10) (300,)\n",
            "trainset after adding uncertain samples (325, 10) (325,)\n",
            "updated train set: (325, 10) (325,) unique(labels): [ 71 254] [0 1]\n",
            "val set: (977, 10) (977,)\n",
            "\n",
            "Train set: (325, 10)\n",
            "Validation set: (977, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 13\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.072 s \n",
            "\n",
            "Accuracy rate is 74.884793 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.81      0.83       321\n",
            "           1       0.52      0.58      0.55       113\n",
            "\n",
            "    accuracy                           0.75       434\n",
            "   macro avg       0.68      0.70      0.69       434\n",
            "weighted avg       0.76      0.75      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[259  62]\n",
            " [ 47  66]]\n",
            "--------------------------------\n",
            "val predicted: (977,) [0 1 1 0 0 1 0 0 0 1 1 0 0 1 0 1 1 0 1 1 1 1 0 1 0 1 0 0 1 0 1 1 0 1 0 1 1\n",
            " 1 0 1 1 1 1 0 0 1 1 0 0 1 0 0 1 0 1 1 0 0 0 1 1 1 0 1 1 1 1 0 0 0 1 1 1 1\n",
            " 1 1 1 0 1 1 1 0 0 1 1 1 1 1 1 0 1 0 1 0 0 1 0 0 1 1 0 0 1 0 0 0 1 0 0 0 1\n",
            " 0 1 1 1 1 0 1 0 0 0 1 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 1 1 0 0 0 0 1 0 1\n",
            " 0 0 0 0 0 0 0 1 0 1 1 0 0 1 0 0 1 0 0 0 1 1 0 1 1 1 0 0 1 0 1 0 1 1 0 1 1\n",
            " 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 1 1 0 0 0 0 0 1 0 0 1 0 0 1 1 0 0 1 0 0 0 0\n",
            " 1 1 0 1 0 0 0 0 1 0 0 1 0 1 1 0 0 1 1 1 0 0 0 1 0 0 0 1 1 0 1 1 1 1 1 0 1\n",
            " 1 1 1 0 0 1 0 1 1 1 0 1 1 0 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0\n",
            " 0 0 1 0 1 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 1 0 1 1 0 0 1 1 0 0 0 0 0 0 1\n",
            " 1 1 1 0 1 1 1 1 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 1 1 0 1 1 1 1 0 1 1\n",
            " 1 0 0 0 1 1 0 1 1 1 0 1 0 0 0 0 1 0 1 0 0 0 1 0 1 1 0 1 1 0 0 1 0 1 1 0 1\n",
            " 1 1 0 1 1 0 0 1 0 1 0 0 1 0 0 1 0 1 0 0 0 0 1 1 0 0 0 0 1 0 0 1 1 1 0 0 0\n",
            " 1 1 1 0 1 0 0 0 0 0 0 1 1 0 0 1 1 0 0 0 1 0 1 0 0 0 1 0 1 0 1 0 0 0 0 1 0\n",
            " 1 1 1 0 1 1 1 0 1 0 0 0 1 1 0 0 0 1 1 0 0 1 0 1 0 1 0 1 0 0 0 0 0 1 0 1 0\n",
            " 0 1 1 0 1 1 0 1 1 0 0 1 1 1 1 1 0 1 1 1 1 0 0 1 1 0 1 0 0 1 1 0 1 1 0 0 0\n",
            " 0 1 0 1 0 0 0 0 1 0 1 0 1 0 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 1 0 0 1 0 0 1 0\n",
            " 1 1 0 0 1 1 0 0 1 1 1 0 0 0 0 1 0 1 1 0 1 0 0 1 1 0 0 1 1 0 1 1 1 1 0 1 1\n",
            " 0 0 0 1 0 1 1 1 1 0 0 0 1 1 1 0 1 1 1 0 1 0 0 0 1 1 0 1 0 1 0 0 1 1 0 1 0\n",
            " 0 1 1 0 0 1 0 0 1 0 0 1 1 1 1 0 1 0 1 0 0 1 0 1 1 1 0 1 0 0 0 1 0 1 1 1 0\n",
            " 1 1 1 1 1 0 0 1 0 0 0 1 0 1 1 1 0 1 0 1 0 0 0 1 0 0 1 0 0 1 1 0 1 1 0 0 0\n",
            " 0 0 1 1 1 0 0 0 0 0 1 1 0 0 1 0 0 1 1 0 1 0 0 0 0 1 1 0 1 0 1 0 0 1 0 0 0\n",
            " 1 0 1 0 1 0 1 0 0 0 0 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1\n",
            " 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 1 0 1 1 1 0 0 0 1 1 1\n",
            " 0 1 1 0 1 1 1 0 1 1 0 1 0 1 1 0 1 1 1 1 1 1 0 1 1 0 1 1 0 0 1 1 0 1 1 0 0\n",
            " 1 1 0 1 1 0 1 0 0 0 1 0 1 0 1 1 1 0 1 0 1 0 1 1 1 1 1 1 1 0 0 1 1 0 1 1 0\n",
            " 0 0 1 0 0 1 1 0 1 1 0 0 1 0 1 1 1 1 0 0 1 0 1 1 1 1 0 1 0 0 1 1 1 1 0 0 0\n",
            " 1 1 0 0 0 1 0 1 1 1 1 1 0 0 0]\n",
            "probabilities: (977, 2) \n",
            " [0 1 1 0 0 1 0 0 0 1 1 0 0 1 0 1 1 0 1 1 1 1 0 1 0 1 0 0 1 0 1 1 0 1 0 1 1\n",
            " 1 0 1 1 1 1 0 0 1 1 0 0 1 0 0 1 0 1 1 0 0 0 1 1 1 0 1 1 1 1 0 0 0 1 1 1 1\n",
            " 1 1 1 0 1 1 1 0 0 1 1 1 1 1 1 0 1 0 1 0 0 1 0 0 1 1 0 0 1 0 0 0 1 0 0 0 1\n",
            " 0 1 1 1 1 0 1 0 0 0 1 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 1 1 0 0 0 0 1 0 1\n",
            " 0 0 0 0 0 0 0 1 0 1 1 0 0 1 0 0 1 0 0 0 1 1 0 1 1 1 0 0 1 0 1 0 1 1 0 1 1\n",
            " 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 1 1 0 0 0 0 0 1 0 0 1 0 0 1 1 0 0 1 0 0 0 0\n",
            " 1 1 0 1 0 0 0 0 1 0 0 1 0 1 1 0 0 1 1 1 0 0 0 1 0 0 0 1 1 0 1 1 1 1 1 0 1\n",
            " 1 1 1 0 0 1 0 1 1 1 0 1 1 0 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0\n",
            " 0 0 1 0 1 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 1 0 1 1 0 0 1 1 0 0 0 0 0 0 1\n",
            " 1 1 1 0 1 1 1 1 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 1 1 0 1 1 1 1 0 1 1\n",
            " 1 0 0 0 1 1 0 1 1 1 0 1 0 0 0 0 1 0 1 0 0 0 1 0 1 1 0 1 1 0 0 1 0 1 1 0 1\n",
            " 1 1 0 1 1 0 0 1 0 1 0 0 1 0 0 1 0 1 0 0 0 0 1 1 0 0 0 0 1 0 0 1 1 1 0 0 0\n",
            " 1 1 1 0 1 0 0 0 0 0 0 1 1 0 0 1 1 0 0 0 1 0 1 0 0 0 1 0 1 0 1 0 0 0 0 1 0\n",
            " 1 1 1 0 1 1 1 0 1 0 0 0 1 1 0 0 0 1 1 0 0 1 0 1 0 1 0 1 0 0 0 0 0 1 0 1 0\n",
            " 0 1 1 0 1 1 0 1 1 0 0 1 1 1 1 1 0 1 1 1 1 0 0 1 1 0 1 0 0 1 1 0 1 1 0 0 0\n",
            " 0 1 0 1 0 0 0 0 1 0 1 0 1 0 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 1 0 0 1 0 0 1 0\n",
            " 1 1 0 0 1 1 0 0 1 1 1 0 0 0 0 1 0 1 1 0 1 0 0 1 1 0 0 1 1 0 1 1 1 1 0 1 1\n",
            " 0 0 0 1 0 1 1 1 1 0 0 0 1 1 1 0 1 1 1 0 1 0 0 0 1 1 0 1 0 1 0 0 1 1 0 1 0\n",
            " 0 1 1 0 0 1 0 0 1 0 0 1 1 1 1 0 1 0 1 0 0 1 0 1 1 1 0 1 0 0 0 1 0 1 1 1 0\n",
            " 1 1 1 1 1 0 0 1 0 0 0 1 0 1 1 1 0 1 0 1 0 0 0 1 0 0 1 0 0 1 1 0 1 1 0 0 0\n",
            " 0 0 1 1 1 0 0 0 0 0 1 1 0 0 1 0 0 1 1 0 1 0 0 0 0 1 1 0 1 0 1 0 0 1 0 0 0\n",
            " 1 0 1 0 1 0 1 0 0 0 0 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1\n",
            " 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 1 0 1 1 1 0 0 0 1 1 1\n",
            " 0 1 1 0 1 1 1 0 1 1 0 1 0 1 1 0 1 1 1 1 1 1 0 1 1 0 1 1 0 0 1 1 0 1 1 0 0\n",
            " 1 1 0 1 1 0 1 0 0 0 1 0 1 0 1 1 1 0 1 0 1 0 1 1 1 1 1 1 1 0 0 1 1 0 1 1 0\n",
            " 0 0 1 0 0 1 1 0 1 1 0 0 1 0 1 1 1 1 0 0 1 0 1 1 1 1 0 1 0 0 1 1 1 1 0 0 0\n",
            " 1 1 0 0 0 1 0 1 1 1 1 1 0 0 0]\n",
            "trainset before adding uncertain samples (325, 10) (325,)\n",
            "trainset after adding uncertain samples (350, 10) (350,)\n",
            "updated train set: (350, 10) (350,) unique(labels): [ 78 272] [0 1]\n",
            "val set: (952, 10) (952,)\n",
            "\n",
            "Train set: (350, 10)\n",
            "Validation set: (952, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 14\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.083 s \n",
            "\n",
            "Accuracy rate is 75.576037 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.82      0.83       321\n",
            "           1       0.53      0.57      0.55       113\n",
            "\n",
            "    accuracy                           0.76       434\n",
            "   macro avg       0.69      0.69      0.69       434\n",
            "weighted avg       0.76      0.76      0.76       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[264  57]\n",
            " [ 49  64]]\n",
            "--------------------------------\n",
            "val predicted: (952,) [0 1 1 0 0 1 0 0 0 1 1 0 0 1 0 1 1 0 1 1 1 1 0 1 0 1 0 0 1 0 1 1 0 1 0 1 1\n",
            " 1 0 1 1 1 1 0 0 1 1 0 0 1 0 0 1 0 1 1 0 0 0 1 1 1 0 1 1 1 1 0 0 0 1 1 1 1\n",
            " 1 1 1 0 1 1 1 0 0 1 1 1 1 1 1 0 1 0 1 0 0 1 0 0 1 1 0 0 1 0 0 0 1 0 0 0 1\n",
            " 0 1 1 1 1 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 1 0 1 0 0\n",
            " 0 0 0 0 0 1 0 1 1 0 0 1 0 0 1 0 0 0 1 1 0 1 1 1 0 0 1 0 1 0 1 1 0 1 1 0 1\n",
            " 0 0 0 0 0 0 1 0 0 0 0 0 1 1 1 0 0 0 0 0 1 0 0 1 0 0 1 1 0 0 0 0 0 0 0 1 1\n",
            " 0 1 0 0 0 0 1 0 0 1 0 1 1 0 0 1 1 1 0 0 0 1 0 0 0 1 1 0 1 1 1 1 1 0 1 1 1\n",
            " 1 0 0 1 0 1 1 1 0 1 1 0 1 1 0 1 0 0 1 1 1 1 1 1 1 0 1 1 1 1 0 0 1 0 0 0 0\n",
            " 1 0 1 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 1 0 1 1 0 0 1 1 0 0 0 0 0 0 1 1 1\n",
            " 1 0 1 1 1 1 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 1 1 0 1 1 0 1 0 1 1 1 0\n",
            " 0 0 1 1 0 1 1 1 0 1 0 0 0 0 1 0 1 0 0 0 1 0 0 1 0 1 1 0 0 1 0 1 1 0 1 0 1\n",
            " 0 1 1 0 0 1 0 1 0 0 1 0 0 1 0 1 0 0 0 0 1 1 0 0 0 0 1 0 0 1 1 1 0 0 0 1 1\n",
            " 1 0 1 0 0 0 0 0 0 1 1 0 0 1 1 0 0 0 1 0 1 0 0 0 1 0 1 0 1 0 0 0 0 1 0 1 1\n",
            " 1 0 1 1 1 0 1 0 0 0 1 1 0 0 0 1 1 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 1 1 0 1\n",
            " 1 0 1 1 0 0 1 1 1 1 1 0 1 1 1 1 0 0 1 1 0 1 0 0 1 1 0 1 1 0 0 0 0 1 0 1 1\n",
            " 0 0 0 1 0 1 0 1 0 1 1 1 1 0 1 0 0 1 1 0 0 0 0 0 1 0 0 1 0 0 1 0 1 1 0 0 1\n",
            " 1 0 0 1 1 1 0 0 0 0 1 0 1 1 0 1 0 0 1 1 0 0 0 1 0 1 1 1 1 0 1 1 0 0 1 1 0\n",
            " 1 1 1 1 0 0 0 1 1 0 1 1 1 0 0 0 0 0 1 1 0 1 0 1 0 0 1 1 0 1 0 0 1 1 0 0 1\n",
            " 0 0 1 0 0 1 1 1 0 0 1 0 1 0 0 1 0 1 1 1 0 1 0 0 0 1 0 1 1 1 0 1 1 1 1 1 0\n",
            " 0 1 0 0 0 1 0 1 0 1 0 1 0 0 0 1 0 0 1 1 1 1 0 0 0 0 0 1 1 1 0 0 0 0 0 1 0\n",
            " 0 1 0 0 1 1 0 1 0 0 0 0 1 1 0 1 0 1 0 0 1 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 1\n",
            " 1 0 1 1 1 1 0 1 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 1 0 0 0 0 0 1 1 0 0 0 0 0\n",
            " 0 0 1 0 0 0 1 0 1 0 0 0 0 1 0 1 1 1 0 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 0\n",
            " 1 0 1 1 1 0 1 1 0 1 0 0 0 1 0 0 1 0 0 0 0 0 1 0 1 0 1 1 1 0 1 0 1 0 1 1 1\n",
            " 1 1 1 1 0 0 1 1 0 1 1 0 0 0 1 0 0 1 1 0 1 1 0 0 1 0 1 1 1 1 0 0 1 0 1 1 1\n",
            " 1 0 1 0 0 1 1 1 1 0 0 0 1 1 0 0 0 1 0 1 1 1 1 0 0 0 0]\n",
            "probabilities: (952, 2) \n",
            " [0 1 1 0 0 1 0 0 0 1 1 0 0 1 0 1 1 0 1 1 1 1 0 1 0 1 0 0 1 0 1 1 0 1 0 1 1\n",
            " 1 0 1 1 1 1 0 0 1 1 0 0 1 0 0 1 0 1 1 0 0 0 1 1 1 0 1 1 1 1 0 0 0 1 1 1 1\n",
            " 1 1 1 0 1 1 1 0 0 1 1 1 1 1 1 0 1 0 1 0 0 1 0 0 1 1 0 0 1 0 0 0 1 0 0 0 1\n",
            " 0 1 1 1 1 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 1 0 1 0 0\n",
            " 0 0 0 0 0 1 0 1 1 0 0 1 0 0 1 0 0 0 1 1 0 1 1 1 0 0 1 0 1 0 1 1 0 1 1 0 1\n",
            " 0 0 0 0 0 0 1 0 0 0 0 0 1 1 1 0 0 0 0 0 1 0 0 1 0 0 1 1 0 0 0 0 0 0 0 1 1\n",
            " 0 1 0 0 0 0 1 0 0 1 0 1 1 0 0 1 1 1 0 0 0 1 0 0 0 1 1 0 1 1 1 1 1 0 1 1 1\n",
            " 1 0 0 1 0 1 1 1 0 1 1 0 1 1 0 1 0 0 1 1 1 1 1 1 1 0 1 1 1 1 0 0 1 0 0 0 0\n",
            " 1 0 1 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 1 0 1 1 0 0 1 1 0 0 0 0 0 0 1 1 1\n",
            " 1 0 1 1 1 1 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 1 1 0 1 1 0 1 0 1 1 1 0\n",
            " 0 0 1 1 0 1 1 1 0 1 0 0 0 0 1 0 1 0 0 0 1 0 0 1 0 1 1 0 0 1 0 1 1 0 1 0 1\n",
            " 0 1 1 0 0 1 0 1 0 0 1 0 0 1 0 1 0 0 0 0 1 1 0 0 0 0 1 0 0 1 1 1 0 0 0 1 1\n",
            " 1 0 1 0 0 0 0 0 0 1 1 0 0 1 1 0 0 0 1 0 1 0 0 0 1 0 1 0 1 0 0 0 0 1 0 1 1\n",
            " 1 0 1 1 1 0 1 0 0 0 1 1 0 0 0 1 1 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 1 1 0 1\n",
            " 1 0 1 1 0 0 1 1 1 1 1 0 1 1 1 1 0 0 1 1 0 1 0 0 1 1 0 1 1 0 0 0 0 1 0 1 1\n",
            " 0 0 0 1 0 1 0 1 0 1 1 1 1 0 1 0 0 1 1 0 0 0 0 0 1 0 0 1 0 0 1 0 1 1 0 0 1\n",
            " 1 0 0 1 1 1 0 0 0 0 1 0 1 1 0 1 0 0 1 1 0 0 0 1 0 1 1 1 1 0 1 1 0 0 1 1 0\n",
            " 1 1 1 1 0 0 0 1 1 0 1 1 1 0 0 0 0 0 1 1 0 1 0 1 0 0 1 1 0 1 0 0 1 1 0 0 1\n",
            " 0 0 1 0 0 1 1 1 0 0 1 0 1 0 0 1 0 1 1 1 0 1 0 0 0 1 0 1 1 1 0 1 1 1 1 1 0\n",
            " 0 1 0 0 0 1 0 1 0 1 0 1 0 0 0 1 0 0 1 1 1 1 0 0 0 0 0 1 1 1 0 0 0 0 0 1 0\n",
            " 0 1 0 0 1 1 0 1 0 0 0 0 1 1 0 1 0 1 0 0 1 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 1\n",
            " 1 0 1 1 1 1 0 1 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 1 0 0 0 0 0 1 1 0 0 0 0 0\n",
            " 0 0 1 0 0 0 1 0 1 0 0 0 0 1 0 1 1 1 0 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 0\n",
            " 1 0 1 1 1 0 1 1 0 1 0 0 0 1 0 0 1 0 0 0 0 0 1 0 1 0 1 1 1 0 1 0 1 0 1 1 1\n",
            " 1 1 1 1 0 0 1 1 0 1 1 0 0 0 1 0 0 1 1 0 1 1 0 0 1 0 1 1 1 1 0 0 1 0 1 1 1\n",
            " 1 0 1 0 0 1 1 1 1 0 0 0 1 1 0 0 0 1 0 1 1 1 1 0 0 0 0]\n",
            "trainset before adding uncertain samples (350, 10) (350,)\n",
            "trainset after adding uncertain samples (375, 10) (375,)\n",
            "updated train set: (375, 10) (375,) unique(labels): [ 82 293] [0 1]\n",
            "val set: (927, 10) (927,)\n",
            "\n",
            "Train set: (375, 10)\n",
            "Validation set: (927, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 15\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.107 s \n",
            "\n",
            "Accuracy rate is 75.576037 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.82      0.83       321\n",
            "           1       0.53      0.58      0.55       113\n",
            "\n",
            "    accuracy                           0.76       434\n",
            "   macro avg       0.69      0.70      0.69       434\n",
            "weighted avg       0.76      0.76      0.76       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[263  58]\n",
            " [ 48  65]]\n",
            "--------------------------------\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: divide by zero encountered in log2\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: invalid value encountered in multiply\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: divide by zero encountered in log2\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: invalid value encountered in multiply\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "val predicted: (927,) [0 1 1 0 0 1 0 0 0 1 1 0 0 1 0 1 1 0 1 1 1 1 0 1 0 1 0 0 1 0 1 1 0 1 0 1 1\n",
            " 1 0 1 1 1 1 0 0 1 1 0 0 1 0 0 1 0 1 1 0 0 0 1 1 1 0 1 1 1 0 0 0 1 1 1 1 1\n",
            " 0 1 0 1 1 1 1 1 1 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 1 1 1 1 0 1 0 0 0\n",
            " 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 1 1 0\n",
            " 0 1 0 0 1 0 0 0 1 1 0 1 1 1 0 0 1 0 1 0 1 1 0 1 1 0 1 0 0 0 0 0 0 1 0 0 0\n",
            " 0 0 1 1 1 0 0 0 0 0 1 0 0 1 0 0 1 1 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 1 0 0 1\n",
            " 0 1 1 0 0 1 1 1 0 0 0 1 0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 1 0 0 1 0 1 1 1 0 1\n",
            " 1 0 1 1 0 1 0 0 1 1 1 1 1 1 1 0 1 1 1 1 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 1 0 1 0 1 1 0 1 0 0 0 0 0 0 1 1 1 1 0 1 1 1 1 0 0 0 0 0 0 1\n",
            " 0 0 0 0 0 1 1 0 0 0 0 0 1 1 0 1 1 0 1 0 1 0 1 0 1 0 1 1 0 1 1 1 0 1 0 0 0\n",
            " 0 1 0 1 0 0 0 1 0 0 1 0 1 1 0 0 1 0 1 1 0 1 0 1 0 1 1 0 0 1 0 1 0 0 0 0 0\n",
            " 1 0 1 0 0 0 0 1 1 0 0 0 0 1 0 0 1 1 1 0 0 0 1 1 1 0 1 0 0 0 0 0 0 1 1 0 0\n",
            " 1 1 0 0 0 1 0 1 0 0 0 1 0 1 0 1 0 0 0 0 1 0 1 1 1 0 1 1 1 0 1 0 0 0 1 1 0\n",
            " 0 0 1 1 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 1 1 0 1 1 0 1 1 0 0 1 1 1 1 1 0 1\n",
            " 1 1 1 0 0 1 1 0 1 0 1 1 1 0 1 1 0 0 0 0 1 0 1 1 0 0 0 1 0 1 0 1 0 1 1 1 1\n",
            " 0 1 0 0 1 1 0 0 0 0 0 1 0 0 1 0 0 1 0 1 1 0 0 1 1 0 0 0 1 1 0 0 0 0 1 0 1\n",
            " 1 0 1 0 0 1 1 0 0 1 1 0 1 0 1 1 0 1 1 0 0 1 1 0 1 1 1 1 0 0 0 1 1 0 1 1 1\n",
            " 0 1 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 1 0 0 1 0 0 1 0 0 1 0 1 0 0 1 0 1 1 1 0\n",
            " 1 0 0 0 1 0 1 1 1 0 1 1 1 1 1 0 0 1 0 0 0 1 0 1 0 1 0 1 0 0 0 1 0 0 1 1 1\n",
            " 1 0 0 0 0 0 1 1 1 0 0 0 0 0 1 0 0 1 0 0 1 1 0 1 0 0 0 0 1 1 0 1 0 1 0 0 1\n",
            " 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 1 1 0 1 1 1 1 0 1 1 1 1 1 1 0 0 1 0 0 1 0 1\n",
            " 1 1 1 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 1 0 1 1 0 0 0 0\n",
            " 1 1 1 0 1 1 0 1 1 1 0 1 1 0 1 0 0 1 1 1 0 1 1 0 0 0 0 1 0 0 1 0 0 0 0 1 0\n",
            " 0 1 1 1 0 1 0 1 0 1 1 1 1 1 1 1 0 0 1 1 0 1 1 0 0 0 1 0 0 1 1 0 1 1 0 0 1\n",
            " 0 1 1 1 1 0 0 1 0 1 1 1 1 0 1 0 0 1 1 1 1 0 0 0 1 1 0 0 0 1 0 1 1 1 1 0 0\n",
            " 0 0]\n",
            "probabilities: (927, 2) \n",
            " [0 1 1 0 0 1 0 0 0 1 1 0 0 1 0 1 1 0 1 1 1 1 0 1 0 1 0 0 1 0 1 1 0 1 0 1 1\n",
            " 1 0 1 1 1 1 0 0 1 1 0 0 1 0 0 1 0 1 1 0 0 0 1 1 1 0 1 1 1 0 0 0 1 1 1 1 1\n",
            " 0 1 0 1 1 1 1 1 1 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 1 1 1 1 0 1 0 0 0\n",
            " 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 1 1 0\n",
            " 0 1 0 0 1 0 0 0 1 1 0 1 1 1 0 0 1 0 1 0 1 1 0 1 1 0 1 0 0 0 0 0 0 1 0 0 0\n",
            " 0 0 1 1 1 0 0 0 0 0 1 0 0 1 0 0 1 1 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 1 0 0 1\n",
            " 0 1 1 0 0 1 1 1 0 0 0 1 0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 1 0 0 1 0 1 1 1 0 1\n",
            " 1 0 1 1 0 1 0 0 1 1 1 1 1 1 1 0 1 1 1 1 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 1 0 1 0 1 1 0 1 0 0 0 0 0 0 1 1 1 1 0 1 1 1 1 0 0 0 0 0 0 1\n",
            " 0 0 0 0 0 1 1 0 0 0 0 0 1 1 0 1 1 0 1 0 1 0 1 0 1 0 1 1 0 1 1 1 0 1 0 0 0\n",
            " 0 1 0 1 0 0 0 1 0 0 1 0 1 1 0 0 1 0 1 1 0 1 0 1 0 1 1 0 0 1 0 1 0 0 0 0 0\n",
            " 1 0 1 0 0 0 0 1 1 0 0 0 0 1 0 0 1 1 1 0 0 0 1 1 1 0 1 0 0 0 0 0 0 1 1 0 0\n",
            " 1 1 0 0 0 1 0 1 0 0 0 1 0 1 0 1 0 0 0 0 1 0 1 1 1 0 1 1 1 0 1 0 0 0 1 1 0\n",
            " 0 0 1 1 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 1 1 0 1 1 0 1 1 0 0 1 1 1 1 1 0 1\n",
            " 1 1 1 0 0 1 1 0 1 0 1 1 1 0 1 1 0 0 0 0 1 0 1 1 0 0 0 1 0 1 0 1 0 1 1 1 1\n",
            " 0 1 0 0 1 1 0 0 0 0 0 1 0 0 1 0 0 1 0 1 1 0 0 1 1 0 0 0 1 1 0 0 0 0 1 0 1\n",
            " 1 0 1 0 0 1 1 0 0 1 1 0 1 0 1 1 0 1 1 0 0 1 1 0 1 1 1 1 0 0 0 1 1 0 1 1 1\n",
            " 0 1 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 1 0 0 1 0 0 1 0 0 1 0 1 0 0 1 0 1 1 1 0\n",
            " 1 0 0 0 1 0 1 1 1 0 1 1 1 1 1 0 0 1 0 0 0 1 0 1 0 1 0 1 0 0 0 1 0 0 1 1 1\n",
            " 1 0 0 0 0 0 1 1 1 0 0 0 0 0 1 0 0 1 0 0 1 1 0 1 0 0 0 0 1 1 0 1 0 1 0 0 1\n",
            " 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 1 1 0 1 1 1 1 0 1 1 1 1 1 1 0 0 1 0 0 1 0 1\n",
            " 1 1 1 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 1 0 1 1 0 0 0 0\n",
            " 1 1 1 0 1 1 0 1 1 1 0 1 1 0 1 0 0 1 1 1 0 1 1 0 0 0 0 1 0 0 1 0 0 0 0 1 0\n",
            " 0 1 1 1 0 1 0 1 0 1 1 1 1 1 1 1 0 0 1 1 0 1 1 0 0 0 1 0 0 1 1 0 1 1 0 0 1\n",
            " 0 1 1 1 1 0 0 1 0 1 1 1 1 0 1 0 0 1 1 1 1 0 0 0 1 1 0 0 0 1 0 1 1 1 1 0 0\n",
            " 0 0]\n",
            "trainset before adding uncertain samples (375, 10) (375,)\n",
            "trainset after adding uncertain samples (400, 10) (400,)\n",
            "updated train set: (400, 10) (400,) unique(labels): [ 87 313] [0 1]\n",
            "val set: (902, 10) (902,)\n",
            "\n",
            "Train set: (400, 10)\n",
            "Validation set: (902, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 16\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.075 s \n",
            "\n",
            "Accuracy rate is 74.423963 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.80      0.82       321\n",
            "           1       0.51      0.58      0.54       113\n",
            "\n",
            "    accuracy                           0.74       434\n",
            "   macro avg       0.68      0.69      0.68       434\n",
            "weighted avg       0.76      0.74      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[258  63]\n",
            " [ 48  65]]\n",
            "--------------------------------\n",
            "val predicted: (902,) [0 1 1 0 0 1 0 0 1 1 1 0 0 1 0 1 1 0 1 1 1 1 0 1 0 1 0 0 1 0 1 1 0 1 0 1 0\n",
            " 1 0 0 1 0 0 1 0 0 1 0 1 1 0 0 0 1 1 1 0 1 1 1 0 0 0 1 1 1 1 1 0 1 0 1 1 1\n",
            " 1 1 1 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 1 1 0 1 0 0 0 1 1 0 0 0 0 1 0\n",
            " 0 0 0 0 0 0 0 1 1 1 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 1 1 0 0 1 0 0 1 0 0 0 1\n",
            " 1 0 1 1 1 0 0 1 0 0 0 1 1 0 1 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 1 1 0 0 0 0\n",
            " 0 1 0 0 1 0 0 1 1 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 1 0 0 1 0 1 1 0 0 1 1 1 0\n",
            " 0 0 1 0 0 1 1 0 1 1 1 1 1 0 1 1 1 1 0 0 1 0 1 1 1 0 1 1 0 1 1 0 1 0 1 1 1\n",
            " 1 1 1 1 1 0 1 1 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 1\n",
            " 1 0 1 0 0 0 0 0 0 1 1 1 1 0 1 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0\n",
            " 1 1 0 1 1 0 1 0 1 0 1 0 1 0 1 1 0 1 1 1 0 1 0 0 0 0 1 0 1 0 0 0 1 0 0 1 0\n",
            " 1 1 0 0 1 0 1 1 0 1 1 1 0 1 1 0 0 1 0 1 0 1 0 0 0 1 0 1 0 0 0 0 1 1 0 0 0\n",
            " 0 1 0 0 1 1 1 0 0 0 1 1 1 0 1 0 0 0 0 0 0 1 1 0 0 1 1 0 0 0 1 0 1 0 0 0 1\n",
            " 0 1 0 1 0 0 0 0 1 0 1 1 1 0 1 1 1 0 1 0 0 0 1 1 0 0 0 1 1 0 0 1 0 1 0 0 0\n",
            " 0 0 0 0 0 1 0 0 1 1 0 1 1 0 1 1 0 0 1 1 1 1 1 0 1 1 1 1 0 0 1 1 0 1 0 1 1\n",
            " 0 1 1 0 0 0 0 1 0 1 1 0 0 0 1 0 1 0 1 0 1 1 1 0 1 0 0 1 1 0 0 0 0 0 1 0 0\n",
            " 1 0 0 1 1 0 0 1 1 0 0 1 1 1 1 0 0 0 1 0 1 1 0 1 0 0 1 1 0 0 0 1 1 1 0 1 1\n",
            " 0 1 1 0 0 1 1 0 1 1 1 0 0 0 1 1 0 1 1 1 0 1 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0\n",
            " 1 0 0 1 0 0 1 0 0 1 0 1 0 0 1 0 1 1 1 0 1 0 0 0 1 0 1 1 1 0 1 1 1 1 0 0 1\n",
            " 0 0 0 1 0 1 0 1 0 1 0 0 0 1 0 0 1 1 1 1 0 0 0 0 0 1 1 1 0 0 0 0 0 1 0 0 1\n",
            " 0 0 1 1 0 1 0 0 0 0 1 1 0 1 0 1 0 0 1 0 0 1 0 1 0 1 0 1 1 0 0 0 0 1 1 0 1\n",
            " 1 1 1 0 1 1 1 1 1 1 0 0 1 0 0 1 0 1 1 1 1 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1\n",
            " 0 0 0 1 0 1 0 0 0 0 1 0 1 1 0 0 0 1 1 1 0 1 1 0 1 1 1 0 1 1 0 1 0 0 1 1 1\n",
            " 0 1 1 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 1 1 1 0 1 0 1 0 1 1 1 0 0 1 1 0 1 0 0\n",
            " 0 1 0 0 1 1 0 1 1 0 0 1 0 1 1 1 0 0 1 1 0 1 1 1 1 0 1 0 0 1 1 1 1 0 0 0 1\n",
            " 1 0 0 0 1 0 1 1 1 1 0 0 0 0]\n",
            "probabilities: (902, 2) \n",
            " [0 1 1 0 0 1 0 0 1 1 1 0 0 1 0 1 1 0 1 1 1 1 0 1 0 1 0 0 1 0 1 1 0 1 0 1 0\n",
            " 1 0 0 1 0 0 1 0 0 1 0 1 1 0 0 0 1 1 1 0 1 1 1 0 0 0 1 1 1 1 1 0 1 0 1 1 1\n",
            " 1 1 1 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 1 1 0 1 0 0 0 1 1 0 0 0 0 1 0\n",
            " 0 0 0 0 0 0 0 1 1 1 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 1 1 0 0 1 0 0 1 0 0 0 1\n",
            " 1 0 1 1 1 0 0 1 0 0 0 1 1 0 1 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 1 1 0 0 0 0\n",
            " 0 1 0 0 1 0 0 1 1 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 1 0 0 1 0 1 1 0 0 1 1 1 0\n",
            " 0 0 1 0 0 1 1 0 1 1 1 1 1 0 1 1 1 1 0 0 1 0 1 1 1 0 1 1 0 1 1 0 1 0 1 1 1\n",
            " 1 1 1 1 1 0 1 1 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 1\n",
            " 1 0 1 0 0 0 0 0 0 1 1 1 1 0 1 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0\n",
            " 1 1 0 1 1 0 1 0 1 0 1 0 1 0 1 1 0 1 1 1 0 1 0 0 0 0 1 0 1 0 0 0 1 0 0 1 0\n",
            " 1 1 0 0 1 0 1 1 0 1 1 1 0 1 1 0 0 1 0 1 0 1 0 0 0 1 0 1 0 0 0 0 1 1 0 0 0\n",
            " 0 1 0 0 1 1 1 0 0 0 1 1 1 0 1 0 0 0 0 0 0 1 1 0 0 1 1 0 0 0 1 0 1 0 0 0 1\n",
            " 0 1 0 1 0 0 0 0 1 0 1 1 1 0 1 1 1 0 1 0 0 0 1 1 0 0 0 1 1 0 0 1 0 1 0 0 0\n",
            " 0 0 0 0 0 1 0 0 1 1 0 1 1 0 1 1 0 0 1 1 1 1 1 0 1 1 1 1 0 0 1 1 0 1 0 1 1\n",
            " 0 1 1 0 0 0 0 1 0 1 1 0 0 0 1 0 1 0 1 0 1 1 1 0 1 0 0 1 1 0 0 0 0 0 1 0 0\n",
            " 1 0 0 1 1 0 0 1 1 0 0 1 1 1 1 0 0 0 1 0 1 1 0 1 0 0 1 1 0 0 0 1 1 1 0 1 1\n",
            " 0 1 1 0 0 1 1 0 1 1 1 0 0 0 1 1 0 1 1 1 0 1 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0\n",
            " 1 0 0 1 0 0 1 0 0 1 0 1 0 0 1 0 1 1 1 0 1 0 0 0 1 0 1 1 1 0 1 1 1 1 0 0 1\n",
            " 0 0 0 1 0 1 0 1 0 1 0 0 0 1 0 0 1 1 1 1 0 0 0 0 0 1 1 1 0 0 0 0 0 1 0 0 1\n",
            " 0 0 1 1 0 1 0 0 0 0 1 1 0 1 0 1 0 0 1 0 0 1 0 1 0 1 0 1 1 0 0 0 0 1 1 0 1\n",
            " 1 1 1 0 1 1 1 1 1 1 0 0 1 0 0 1 0 1 1 1 1 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1\n",
            " 0 0 0 1 0 1 0 0 0 0 1 0 1 1 0 0 0 1 1 1 0 1 1 0 1 1 1 0 1 1 0 1 0 0 1 1 1\n",
            " 0 1 1 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 1 1 1 0 1 0 1 0 1 1 1 0 0 1 1 0 1 0 0\n",
            " 0 1 0 0 1 1 0 1 1 0 0 1 0 1 1 1 0 0 1 1 0 1 1 1 1 0 1 0 0 1 1 1 1 0 0 0 1\n",
            " 1 0 0 0 1 0 1 1 1 1 0 0 0 0]\n",
            "trainset before adding uncertain samples (400, 10) (400,)\n",
            "trainset after adding uncertain samples (425, 10) (425,)\n",
            "updated train set: (425, 10) (425,) unique(labels): [ 94 331] [0 1]\n",
            "val set: (877, 10) (877,)\n",
            "\n",
            "Train set: (425, 10)\n",
            "Validation set: (877, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 17\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.063 s \n",
            "\n",
            "Accuracy rate is 74.654378 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.80      0.82       321\n",
            "           1       0.51      0.58      0.55       113\n",
            "\n",
            "    accuracy                           0.75       434\n",
            "   macro avg       0.68      0.69      0.68       434\n",
            "weighted avg       0.76      0.75      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[258  63]\n",
            " [ 47  66]]\n",
            "--------------------------------\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: divide by zero encountered in log2\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: invalid value encountered in multiply\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: divide by zero encountered in log2\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: invalid value encountered in multiply\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: divide by zero encountered in log2\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: invalid value encountered in multiply\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "val predicted: (877,) [0 1 1 0 0 1 0 0 1 1 1 0 0 1 0 1 1 0 1 1 1 1 0 1 0 1 0 0 1 0 1 1 0 1 0 1 0\n",
            " 1 0 0 1 0 0 1 0 0 1 0 1 1 0 0 0 1 1 0 1 1 0 0 0 1 1 1 1 1 0 1 0 1 1 1 1 1\n",
            " 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 1 0 1 0 0 0 1 1 0 0 0 0 1 0 0 0 1\n",
            " 0 0 0 1 1 1 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 1 1 0 0 1 0 0 1 0 0 0 1 1 0 1 0\n",
            " 0 1 0 1 0 1 1 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 1 1 1 0 0 0 0 1 0 0 1 0 0\n",
            " 1 1 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 1 0 0 1 0 1 1 0 0 1 1 1 0 0 0 1 0 0 1 1\n",
            " 0 1 1 0 1 1 0 1 1 1 0 0 1 0 1 1 1 0 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 0\n",
            " 0 0 0 0 0 1 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 1 1 0 0 0 0 0 0 0 0\n",
            " 1 1 1 1 0 1 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 1 1 0 1 0 1\n",
            " 0 1 0 0 0 1 1 0 1 0 1 0 1 0 0 0 0 1 1 1 0 0 0 1 0 0 1 0 1 1 0 0 1 0 1 1 0\n",
            " 1 1 1 0 1 0 0 1 0 1 0 1 0 0 0 1 0 1 0 0 0 0 1 1 0 0 0 0 1 0 0 1 1 1 0 0 0\n",
            " 1 1 0 1 0 0 0 0 0 1 1 0 0 1 1 0 0 0 1 0 1 0 0 0 1 0 1 0 1 0 0 0 0 1 0 1 0\n",
            " 0 1 1 0 1 0 0 0 1 1 0 0 0 1 1 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 1 1 0 1\n",
            " 1 0 0 1 1 1 1 1 0 1 1 1 1 0 0 1 1 0 1 0 1 1 0 1 1 0 0 0 0 1 0 1 1 0 0 0 1\n",
            " 0 1 0 0 1 1 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 1 0 0 1 1 0 0 1 1 1 0 0 0 0 0\n",
            " 0 1 1 0 1 0 0 1 1 0 0 0 1 1 1 0 1 0 1 1 0 0 1 1 0 1 1 0 0 0 1 1 0 1 1 1 0\n",
            " 1 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 1 0 0 1 1 0 1 0 0 1 0 1 0 0 1 0 1 1 1 0 1\n",
            " 0 0 0 1 0 1 1 1 0 1 1 1 1 0 0 1 0 0 0 1 0 1 0 1 0 1 0 0 0 1 0 0 1 1 1 1 0\n",
            " 0 0 0 0 1 1 1 0 0 0 0 0 1 0 0 0 0 1 1 0 1 0 0 0 0 1 1 0 0 0 1 0 0 1 0 0 1\n",
            " 0 1 0 1 0 1 0 0 0 0 0 1 1 0 1 1 1 1 0 1 1 1 1 1 1 0 0 1 0 0 1 0 1 1 1 1 1\n",
            " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 1 1 0 0 0 1 1 1 0 1 1 0\n",
            " 1 1 1 0 1 1 0 1 0 0 1 1 1 0 1 1 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 1 1 0 1 0 1\n",
            " 0 1 1 1 0 0 1 1 0 1 0 0 0 1 0 0 1 1 0 1 1 0 0 1 0 1 1 1 0 0 0 1 0 1 1 1 1\n",
            " 0 1 0 0 1 1 1 1 0 0 0 1 1 0 0 0 1 0 1 1 1 1 0 0 0 0]\n",
            "probabilities: (877, 2) \n",
            " [0 1 1 0 0 1 0 0 1 1 1 0 0 1 0 1 1 0 1 1 1 1 0 1 0 1 0 0 1 0 1 1 0 1 0 1 0\n",
            " 1 0 0 1 0 0 1 0 0 1 0 1 1 0 0 0 1 1 0 1 1 0 0 0 1 1 1 1 1 0 1 0 1 1 1 1 1\n",
            " 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 1 0 1 0 0 0 1 1 0 0 0 0 1 0 0 0 1\n",
            " 0 0 0 1 1 1 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 1 1 0 0 1 0 0 1 0 0 0 1 1 0 1 0\n",
            " 0 1 0 1 0 1 1 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 1 1 1 0 0 0 0 1 0 0 1 0 0\n",
            " 1 1 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 1 0 0 1 0 1 1 0 0 1 1 1 0 0 0 1 0 0 1 1\n",
            " 0 1 1 0 1 1 0 1 1 1 0 0 1 0 1 1 1 0 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 0\n",
            " 0 0 0 0 0 1 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 1 1 0 0 0 0 0 0 0 0\n",
            " 1 1 1 1 0 1 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 1 1 0 1 0 1\n",
            " 0 1 0 0 0 1 1 0 1 0 1 0 1 0 0 0 0 1 1 1 0 0 0 1 0 0 1 0 1 1 0 0 1 0 1 1 0\n",
            " 1 1 1 0 1 0 0 1 0 1 0 1 0 0 0 1 0 1 0 0 0 0 1 1 0 0 0 0 1 0 0 1 1 1 0 0 0\n",
            " 1 1 0 1 0 0 0 0 0 1 1 0 0 1 1 0 0 0 1 0 1 0 0 0 1 0 1 0 1 0 0 0 0 1 0 1 0\n",
            " 0 1 1 0 1 0 0 0 1 1 0 0 0 1 1 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 1 1 0 1\n",
            " 1 0 0 1 1 1 1 1 0 1 1 1 1 0 0 1 1 0 1 0 1 1 0 1 1 0 0 0 0 1 0 1 1 0 0 0 1\n",
            " 0 1 0 0 1 1 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 1 0 0 1 1 0 0 1 1 1 0 0 0 0 0\n",
            " 0 1 1 0 1 0 0 1 1 0 0 0 1 1 1 0 1 0 1 1 0 0 1 1 0 1 1 0 0 0 1 1 0 1 1 1 0\n",
            " 1 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 1 0 0 1 1 0 1 0 0 1 0 1 0 0 1 0 1 1 1 0 1\n",
            " 0 0 0 1 0 1 1 1 0 1 1 1 1 0 0 1 0 0 0 1 0 1 0 1 0 1 0 0 0 1 0 0 1 1 1 1 0\n",
            " 0 0 0 0 1 1 1 0 0 0 0 0 1 0 0 0 0 1 1 0 1 0 0 0 0 1 1 0 0 0 1 0 0 1 0 0 1\n",
            " 0 1 0 1 0 1 0 0 0 0 0 1 1 0 1 1 1 1 0 1 1 1 1 1 1 0 0 1 0 0 1 0 1 1 1 1 1\n",
            " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 1 1 0 0 0 1 1 1 0 1 1 0\n",
            " 1 1 1 0 1 1 0 1 0 0 1 1 1 0 1 1 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 1 1 0 1 0 1\n",
            " 0 1 1 1 0 0 1 1 0 1 0 0 0 1 0 0 1 1 0 1 1 0 0 1 0 1 1 1 0 0 0 1 0 1 1 1 1\n",
            " 0 1 0 0 1 1 1 1 0 0 0 1 1 0 0 0 1 0 1 1 1 1 0 0 0 0]\n",
            "trainset before adding uncertain samples (425, 10) (425,)\n",
            "trainset after adding uncertain samples (450, 10) (450,)\n",
            "updated train set: (450, 10) (450,) unique(labels): [100 350] [0 1]\n",
            "val set: (852, 10) (852,)\n",
            "\n",
            "Train set: (450, 10)\n",
            "Validation set: (852, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 18\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.059 s \n",
            "\n",
            "Accuracy rate is 75.115207 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.80      0.83       321\n",
            "           1       0.52      0.62      0.56       113\n",
            "\n",
            "    accuracy                           0.75       434\n",
            "   macro avg       0.69      0.71      0.70       434\n",
            "weighted avg       0.77      0.75      0.76       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[256  65]\n",
            " [ 43  70]]\n",
            "--------------------------------\n",
            "val predicted: (852,) [0 1 0 0 1 0 0 1 1 1 0 0 1 0 1 1 0 1 0 1 0 1 0 1 0 1 1 0 1 0 1 0 1 0 0 1 0\n",
            " 0 1 0 0 1 0 1 1 0 0 0 1 1 1 1 1 0 0 0 1 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 0 0\n",
            " 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 1 0 1 0 0 0 1 1 0 0 0 0 1 0 0 0 1 0 0 0 1 1\n",
            " 1 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 1 1 0 0 1 0 0 1 0 0 0 1 1 0 1 0 0 1 0 0 0\n",
            " 1 1 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 1 1 1 0 0 0 0 0 1 0 0 1 0 0 1 1 0 0 1 0\n",
            " 0 0 0 1 1 0 1 0 0 0 0 1 0 0 1 0 1 0 0 1 1 1 0 0 0 1 0 1 0 1 0 1 1 0 1 1 1\n",
            " 0 0 1 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1 0 0 0 0 0 0 1 0 1 1 0 0 0 0\n",
            " 0 0 0 0 0 0 1 0 0 0 1 0 1 0 1 1 0 0 0 1 0 0 0 0 1 1 1 1 0 1 1 1 1 0 0 0 0\n",
            " 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 1 1 1 0 1 0 1 0 0 0 1 1 0 1 0 1 0 1 0\n",
            " 0 0 0 1 0 1 0 0 0 1 0 0 1 0 1 1 0 0 1 0 1 1 0 1 1 1 0 0 0 0 1 0 1 0 1 0 0\n",
            " 0 1 0 1 0 0 0 0 1 1 0 0 0 0 1 0 0 1 1 1 0 0 0 1 1 0 1 0 0 0 0 0 1 1 0 0 1\n",
            " 1 0 0 0 1 0 1 0 0 0 1 0 1 0 1 0 0 0 0 1 0 1 0 0 1 1 0 1 0 0 0 1 1 0 0 0 1\n",
            " 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 1 1 0 1 0 0 1 1 1 1 0 1 1 1 1 0 0 1 1\n",
            " 0 1 0 1 1 0 1 1 0 0 0 0 1 0 1 1 0 0 0 1 0 1 0 0 1 1 1 0 0 1 1 0 0 0 0 0 1\n",
            " 0 0 0 1 1 1 0 0 1 0 0 0 0 1 1 1 0 0 0 0 0 1 1 0 1 0 0 1 1 0 0 0 1 1 1 0 1\n",
            " 0 1 1 0 0 1 1 0 1 1 0 0 0 1 1 0 1 1 1 0 1 0 0 0 0 1 1 1 0 0 1 0 0 0 0 0 1\n",
            " 0 0 1 0 0 1 0 0 1 0 1 0 0 1 0 1 1 1 0 1 0 0 0 1 0 1 1 1 0 1 1 1 1 0 0 1 0\n",
            " 0 0 1 0 1 0 1 0 1 0 0 0 0 0 1 1 1 1 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 1 1\n",
            " 0 1 0 0 0 0 1 1 0 1 0 1 0 0 1 0 0 1 0 1 0 1 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0\n",
            " 1 1 1 0 1 1 0 0 1 0 0 0 0 1 1 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
            " 0 0 1 0 1 1 0 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 0 0 1 1 1 0 1 1 0 0 0 0 1\n",
            " 0 0 1 0 0 0 0 1 0 0 1 1 0 1 0 1 0 1 1 1 0 0 1 1 0 1 0 0 0 1 0 0 1 0 1 1 0\n",
            " 0 1 0 1 1 0 0 1 1 0 1 1 1 0 1 0 0 1 1 1 1 0 0 1 1 0 0 0 1 0 1 1 1 1 0 0 0\n",
            " 0]\n",
            "probabilities: (852, 2) \n",
            " [0 1 0 0 1 0 0 1 1 1 0 0 1 0 1 1 0 1 0 1 0 1 0 1 0 1 1 0 1 0 1 0 1 0 0 1 0\n",
            " 0 1 0 0 1 0 1 1 0 0 0 1 1 1 1 1 0 0 0 1 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 0 0\n",
            " 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 1 0 1 0 0 0 1 1 0 0 0 0 1 0 0 0 1 0 0 0 1 1\n",
            " 1 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 1 1 0 0 1 0 0 1 0 0 0 1 1 0 1 0 0 1 0 0 0\n",
            " 1 1 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 1 1 1 0 0 0 0 0 1 0 0 1 0 0 1 1 0 0 1 0\n",
            " 0 0 0 1 1 0 1 0 0 0 0 1 0 0 1 0 1 0 0 1 1 1 0 0 0 1 0 1 0 1 0 1 1 0 1 1 1\n",
            " 0 0 1 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1 0 0 0 0 0 0 1 0 1 1 0 0 0 0\n",
            " 0 0 0 0 0 0 1 0 0 0 1 0 1 0 1 1 0 0 0 1 0 0 0 0 1 1 1 1 0 1 1 1 1 0 0 0 0\n",
            " 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 1 1 1 0 1 0 1 0 0 0 1 1 0 1 0 1 0 1 0\n",
            " 0 0 0 1 0 1 0 0 0 1 0 0 1 0 1 1 0 0 1 0 1 1 0 1 1 1 0 0 0 0 1 0 1 0 1 0 0\n",
            " 0 1 0 1 0 0 0 0 1 1 0 0 0 0 1 0 0 1 1 1 0 0 0 1 1 0 1 0 0 0 0 0 1 1 0 0 1\n",
            " 1 0 0 0 1 0 1 0 0 0 1 0 1 0 1 0 0 0 0 1 0 1 0 0 1 1 0 1 0 0 0 1 1 0 0 0 1\n",
            " 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 1 1 0 1 0 0 1 1 1 1 0 1 1 1 1 0 0 1 1\n",
            " 0 1 0 1 1 0 1 1 0 0 0 0 1 0 1 1 0 0 0 1 0 1 0 0 1 1 1 0 0 1 1 0 0 0 0 0 1\n",
            " 0 0 0 1 1 1 0 0 1 0 0 0 0 1 1 1 0 0 0 0 0 1 1 0 1 0 0 1 1 0 0 0 1 1 1 0 1\n",
            " 0 1 1 0 0 1 1 0 1 1 0 0 0 1 1 0 1 1 1 0 1 0 0 0 0 1 1 1 0 0 1 0 0 0 0 0 1\n",
            " 0 0 1 0 0 1 0 0 1 0 1 0 0 1 0 1 1 1 0 1 0 0 0 1 0 1 1 1 0 1 1 1 1 0 0 1 0\n",
            " 0 0 1 0 1 0 1 0 1 0 0 0 0 0 1 1 1 1 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 1 1\n",
            " 0 1 0 0 0 0 1 1 0 1 0 1 0 0 1 0 0 1 0 1 0 1 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0\n",
            " 1 1 1 0 1 1 0 0 1 0 0 0 0 1 1 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
            " 0 0 1 0 1 1 0 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 0 0 1 1 1 0 1 1 0 0 0 0 1\n",
            " 0 0 1 0 0 0 0 1 0 0 1 1 0 1 0 1 0 1 1 1 0 0 1 1 0 1 0 0 0 1 0 0 1 0 1 1 0\n",
            " 0 1 0 1 1 0 0 1 1 0 1 1 1 0 1 0 0 1 1 1 1 0 0 1 1 0 0 0 1 0 1 1 1 1 0 0 0\n",
            " 0]\n",
            "trainset before adding uncertain samples (450, 10) (450,)\n",
            "trainset after adding uncertain samples (475, 10) (475,)\n",
            "updated train set: (475, 10) (475,) unique(labels): [114 361] [0 1]\n",
            "val set: (827, 10) (827,)\n",
            "\n",
            "Train set: (475, 10)\n",
            "Validation set: (827, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 19\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.059 s \n",
            "\n",
            "Accuracy rate is 75.576037 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.82      0.83       321\n",
            "           1       0.53      0.58      0.55       113\n",
            "\n",
            "    accuracy                           0.76       434\n",
            "   macro avg       0.69      0.70      0.69       434\n",
            "weighted avg       0.76      0.76      0.76       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[263  58]\n",
            " [ 48  65]]\n",
            "--------------------------------\n",
            "val predicted: (827,) [0 1 0 0 1 0 0 1 1 1 0 0 1 0 1 0 0 1 0 1 0 0 0 1 0 1 1 0 1 0 1 0 1 0 0 1 0\n",
            " 0 1 0 0 1 0 1 1 0 0 0 1 1 0 1 0 0 0 1 1 1 1 1 0 1 0 1 1 1 1 1 1 0 1 0 0 0\n",
            " 0 0 0 0 1 0 0 0 0 0 0 0 1 1 1 0 1 0 0 0 1 1 0 0 0 0 1 0 0 0 1 0 0 0 1 1 0\n",
            " 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 1 0 0 1 0 0 1 0 0 0 1 1 0 1 0 0 1 0 0 0 1 1\n",
            " 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 1 0 0 1 0 0 1 1 0 0 1 0 0 0 0 1\n",
            " 1 0 1 0 0 0 1 0 0 0 1 0 0 1 1 0 0 0 1 0 1 0 1 0 1 1 0 1 1 1 0 0 1 0 1 1 0\n",
            " 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 1 0 0 0 0 0\n",
            " 0 0 0 1 0 1 0 1 1 0 0 0 0 0 0 0 1 1 1 1 0 1 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
            " 1 0 0 0 0 0 0 1 1 0 1 0 1 0 1 0 1 0 0 0 1 1 0 1 1 0 1 0 0 0 0 1 1 1 0 0 0\n",
            " 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 0 0 0 1 0 1 0 1 0 0 0 0 1 0 0 0 0 1 1 0 0\n",
            " 0 0 1 0 0 1 1 1 0 0 0 1 1 0 1 0 0 0 0 0 1 1 0 0 1 1 0 0 0 1 0 1 0 0 0 1 0\n",
            " 1 0 1 0 0 0 1 0 1 0 0 1 1 0 1 0 0 0 1 1 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 1\n",
            " 0 0 1 0 1 1 0 1 0 0 1 1 1 0 1 1 1 0 0 1 1 0 1 0 1 1 0 1 1 0 0 0 0 1 0 1 1\n",
            " 0 0 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 0 0 0\n",
            " 0 0 0 1 1 0 1 0 0 1 1 0 0 1 1 1 1 0 1 0 1 1 0 0 1 1 0 1 1 0 0 0 1 1 0 1 1\n",
            " 1 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 1 0 0 1 0 1 0 0 1 1 1 1 1\n",
            " 0 1 0 0 1 0 0 1 0 1 1 1 1 0 0 1 0 0 0 1 0 1 0 1 0 1 0 0 0 0 1 0 1 1 0 0 0\n",
            " 0 0 1 1 1 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 1 1 0 1 1 0 0 1 0 0 1 0 1 0 0\n",
            " 1 0 0 0 0 0 1 1 0 1 1 1 0 0 1 1 1 0 1 1 0 0 1 0 0 1 0 1 1 1 1 0 0 0 0 0 1\n",
            " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1\n",
            " 0 0 1 1 1 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 1 0 1 0 1 0 1 1 1 0 0 1 1\n",
            " 0 1 0 0 0 1 0 0 1 0 0 1 0 0 1 0 1 1 0 0 0 1 0 0 1 1 0 1 0 0 1 1 1 1 0 0 1\n",
            " 1 0 0 0 1 0 0 1 1 0 0 0 0]\n",
            "probabilities: (827, 2) \n",
            " [0 1 0 0 1 0 0 1 1 1 0 0 1 0 1 0 0 1 0 1 0 0 0 1 0 1 1 0 1 0 1 0 1 0 0 1 0\n",
            " 0 1 0 0 1 0 1 1 0 0 0 1 1 0 1 0 0 0 1 1 1 1 1 0 1 0 1 1 1 1 1 1 0 1 0 0 0\n",
            " 0 0 0 0 1 0 0 0 0 0 0 0 1 1 1 0 1 0 0 0 1 1 0 0 0 0 1 0 0 0 1 0 0 0 1 1 0\n",
            " 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 1 0 0 1 0 0 1 0 0 0 1 1 0 1 0 0 1 0 0 0 1 1\n",
            " 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 1 0 0 1 0 0 1 1 0 0 1 0 0 0 0 1\n",
            " 1 0 1 0 0 0 1 0 0 0 1 0 0 1 1 0 0 0 1 0 1 0 1 0 1 1 0 1 1 1 0 0 1 0 1 1 0\n",
            " 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 1 0 0 0 0 0\n",
            " 0 0 0 1 0 1 0 1 1 0 0 0 0 0 0 0 1 1 1 1 0 1 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
            " 1 0 0 0 0 0 0 1 1 0 1 0 1 0 1 0 1 0 0 0 1 1 0 1 1 0 1 0 0 0 0 1 1 1 0 0 0\n",
            " 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 0 0 0 1 0 1 0 1 0 0 0 0 1 0 0 0 0 1 1 0 0\n",
            " 0 0 1 0 0 1 1 1 0 0 0 1 1 0 1 0 0 0 0 0 1 1 0 0 1 1 0 0 0 1 0 1 0 0 0 1 0\n",
            " 1 0 1 0 0 0 1 0 1 0 0 1 1 0 1 0 0 0 1 1 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 1\n",
            " 0 0 1 0 1 1 0 1 0 0 1 1 1 0 1 1 1 0 0 1 1 0 1 0 1 1 0 1 1 0 0 0 0 1 0 1 1\n",
            " 0 0 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 0 0 0\n",
            " 0 0 0 1 1 0 1 0 0 1 1 0 0 1 1 1 1 0 1 0 1 1 0 0 1 1 0 1 1 0 0 0 1 1 0 1 1\n",
            " 1 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 1 0 0 1 0 1 0 0 1 1 1 1 1\n",
            " 0 1 0 0 1 0 0 1 0 1 1 1 1 0 0 1 0 0 0 1 0 1 0 1 0 1 0 0 0 0 1 0 1 1 0 0 0\n",
            " 0 0 1 1 1 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 1 1 0 1 1 0 0 1 0 0 1 0 1 0 0\n",
            " 1 0 0 0 0 0 1 1 0 1 1 1 0 0 1 1 1 0 1 1 0 0 1 0 0 1 0 1 1 1 1 0 0 0 0 0 1\n",
            " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1\n",
            " 0 0 1 1 1 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 1 0 1 0 1 0 1 1 1 0 0 1 1\n",
            " 0 1 0 0 0 1 0 0 1 0 0 1 0 0 1 0 1 1 0 0 0 1 0 0 1 1 0 1 0 0 1 1 1 1 0 0 1\n",
            " 1 0 0 0 1 0 0 1 1 0 0 0 0]\n",
            "trainset before adding uncertain samples (475, 10) (475,)\n",
            "trainset after adding uncertain samples (500, 10) (500,)\n",
            "updated train set: (500, 10) (500,) unique(labels): [132 368] [0 1]\n",
            "val set: (802, 10) (802,)\n",
            "\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: divide by zero encountered in log2\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: invalid value encountered in multiply\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "Train set: (500, 10)\n",
            "Validation set: (802, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 20\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.071 s \n",
            "\n",
            "Accuracy rate is 75.806452 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.83      0.84       321\n",
            "           1       0.53      0.55      0.54       113\n",
            "\n",
            "    accuracy                           0.76       434\n",
            "   macro avg       0.69      0.69      0.69       434\n",
            "weighted avg       0.76      0.76      0.76       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[267  54]\n",
            " [ 51  62]]\n",
            "--------------------------------\n",
            "final active learning accuracies [77.64976958525345, 76.036866359447, 77.64976958525345, 77.64976958525345, 77.18894009216591, 77.64976958525345, 77.41935483870968, 76.72811059907833, 76.26728110599078, 76.49769585253456, 74.65437788018433, 74.65437788018433, 74.88479262672811, 75.57603686635944, 75.57603686635944, 74.42396313364056, 74.65437788018433, 75.11520737327189, 75.57603686635944, 75.80645161290323]\n",
            "saved /Users/wenxuanhuang/Documents/Repo/ML-for-COVID-19-dataset/Results/Active-learning-experiment-34.pkl /Users/wenxuanhuang/Documents/Repo/ML-for-COVID-19-dataset ['Decision_tree.ipynb', 'dec_git.png', 'Logit_default_f10.pdf', 'Logistic.ipynb', 'SVC.ipynb', 'RF_f5e50_featureimp.pdf', 'log_al.png', 'dec_git.pdf', '.DS_Store', 'log_git.png', 'svm_git.png', 'Logistic_Scikit.ipynb', 'knn_git.pdf', 'knn_git.png', 'rf_al.png', 'Best classifier_RF_f5e50.pdf', 'KNN.ipynb', 'GBDC.ipynb', 'rf_git.png', 'README.md', 'all_training.csv', 'Results', 'svm_al.png', 'Log_ROC.png', 'Logit_default_f7(p_removal).pdf', 'Active_learning.ipynb', 'Random_forest.ipynb', 'Model_select.ipynb', 'gdbc_git.png', '.git', '.vscode', 'Untitled', 'RF_f5e50_modelselect.pdf', 'Logit_default_f8(std_removal).pdf']\n",
            "\n",
            "---------------------------- FINISHED ---------------------------\n",
            "\n",
            "Count = 35, using model = KnnModel, selection_function = EntropySelection, k = 10, iteration = 0.\n",
            "\n",
            "initial random chosen samples (10,)\n",
            "initial train set: (10, 10) (10,) unique(labels): [3 7] [0 1]\n",
            "Val set: (1292, 10) (1292,) (10,)\n",
            "\n",
            "Train set: (10, 10)\n",
            "Validation set: (1292, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.120 s \n",
            "\n",
            "Accuracy rate is 26.036866 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       321\n",
            "           1       0.26      1.00      0.41       113\n",
            "\n",
            "    accuracy                           0.26       434\n",
            "   macro avg       0.13      0.50      0.21       434\n",
            "weighted avg       0.07      0.26      0.11       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[  0 321]\n",
            " [  0 113]]\n",
            "--------------------------------\n",
            "val predicted: (1292,) [1 1 1 ... 1 1 1]\n",
            "probabilities: (1292, 2) \n",
            " [1 1 1 ... 1 1 1]\n",
            "trainset before adding uncertain samples (10, 10) (10,)\n",
            "trainset after adding uncertain samples (20, 10) (20,)\n",
            "updated train set: (20, 10) (20,) unique(labels): [ 7 13] [0 1]\n",
            "val set: (1282, 10) (1282,)\n",
            "\n",
            "Train set: (20, 10)\n",
            "Validation set: (1282, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.102 s \n",
            "\n",
            "Accuracy rate is 33.870968 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.13      0.23       321\n",
            "           1       0.27      0.92      0.42       113\n",
            "\n",
            "    accuracy                           0.34       434\n",
            "   macro avg       0.55      0.53      0.33       434\n",
            "weighted avg       0.68      0.34      0.28       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 43 278]\n",
            " [  9 104]]\n",
            "--------------------------------\n",
            "val predicted: (1282,) [1 1 1 ... 1 0 1]\n",
            "probabilities: (1282, 2) \n",
            " [1 1 1 ... 1 0 1]\n",
            "trainset before adding uncertain samples (20, 10) (20,)\n",
            "trainset after adding uncertain samples (30, 10) (30,)\n",
            "updated train set: (30, 10) (30,) unique(labels): [ 7 23] [0 1]\n",
            "val set: (1272, 10) (1272,)\n",
            "\n",
            "Train set: (30, 10)\n",
            "Validation set: (1272, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "/Users/wenxuanhuang/Library/Python/3.8/lib/python/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/Users/wenxuanhuang/Library/Python/3.8/lib/python/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/Users/wenxuanhuang/Library/Python/3.8/lib/python/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: divide by zero encountered in log2\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: invalid value encountered in multiply\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "--------------------------------\n",
            "Iteration: 3\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.098 s \n",
            "\n",
            "Accuracy rate is 28.110599 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.03      0.07       321\n",
            "           1       0.26      0.98      0.42       113\n",
            "\n",
            "    accuracy                           0.28       434\n",
            "   macro avg       0.55      0.51      0.24       434\n",
            "weighted avg       0.69      0.28      0.16       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 11 310]\n",
            " [  2 111]]\n",
            "--------------------------------\n",
            "val predicted: (1272,) [1 1 1 ... 1 0 1]\n",
            "probabilities: (1272, 2) \n",
            " [1 1 1 ... 1 0 1]\n",
            "trainset before adding uncertain samples (30, 10) (30,)\n",
            "trainset after adding uncertain samples (40, 10) (40,)\n",
            "updated train set: (40, 10) (40,) unique(labels): [ 9 31] [0 1]\n",
            "val set: (1262, 10) (1262,)\n",
            "\n",
            "Train set: (40, 10)\n",
            "Validation set: (1262, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 4\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.098 s \n",
            "\n",
            "Accuracy rate is 27.649770 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.03      0.07       321\n",
            "           1       0.26      0.96      0.41       113\n",
            "\n",
            "    accuracy                           0.28       434\n",
            "   macro avg       0.50      0.50      0.24       434\n",
            "weighted avg       0.61      0.28      0.16       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 11 310]\n",
            " [  4 109]]\n",
            "--------------------------------\n",
            "val predicted: (1262,) [1 1 1 ... 1 0 1]\n",
            "probabilities: (1262, 2) \n",
            " [1 1 1 ... 1 0 1]\n",
            "trainset before adding uncertain samples (40, 10) (40,)\n",
            "trainset after adding uncertain samples (50, 10) (50,)\n",
            "updated train set: (50, 10) (50,) unique(labels): [12 38] [0 1]\n",
            "val set: (1252, 10) (1252,)\n",
            "\n",
            "Train set: (50, 10)\n",
            "Validation set: (1252, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: divide by zero encountered in log2\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: invalid value encountered in multiply\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: divide by zero encountered in log2\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: invalid value encountered in multiply\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "--------------------------------\n",
            "Iteration: 5\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.097 s \n",
            "\n",
            "Accuracy rate is 36.175115 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.22      0.34       321\n",
            "           1       0.26      0.76      0.38       113\n",
            "\n",
            "    accuracy                           0.36       434\n",
            "   macro avg       0.49      0.49      0.36       434\n",
            "weighted avg       0.60      0.36      0.35       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 71 250]\n",
            " [ 27  86]]\n",
            "--------------------------------\n",
            "val predicted: (1252,) [0 1 1 ... 1 0 1]\n",
            "probabilities: (1252, 2) \n",
            " [0 1 1 ... 1 0 1]\n",
            "trainset before adding uncertain samples (50, 10) (50,)\n",
            "trainset after adding uncertain samples (60, 10) (60,)\n",
            "updated train set: (60, 10) (60,) unique(labels): [12 48] [0 1]\n",
            "val set: (1242, 10) (1242,)\n",
            "\n",
            "Train set: (60, 10)\n",
            "Validation set: (1242, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 6\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.081 s \n",
            "\n",
            "Accuracy rate is 36.405530 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.23      0.35       321\n",
            "           1       0.25      0.73      0.38       113\n",
            "\n",
            "    accuracy                           0.36       434\n",
            "   macro avg       0.48      0.48      0.36       434\n",
            "weighted avg       0.59      0.36      0.36       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 75 246]\n",
            " [ 30  83]]\n",
            "--------------------------------\n",
            "val predicted: (1242,) [0 1 1 ... 1 0 1]\n",
            "probabilities: (1242, 2) \n",
            " [0 1 1 ... 1 0 1]\n",
            "trainset before adding uncertain samples (60, 10) (60,)\n",
            "trainset after adding uncertain samples (70, 10) (70,)\n",
            "updated train set: (70, 10) (70,) unique(labels): [12 58] [0 1]\n",
            "val set: (1232, 10) (1232,)\n",
            "\n",
            "Train set: (70, 10)\n",
            "Validation set: (1232, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: divide by zero encountered in log2\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: invalid value encountered in multiply\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: divide by zero encountered in log2\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: invalid value encountered in multiply\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "--------------------------------\n",
            "Iteration: 7\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.113 s \n",
            "\n",
            "Accuracy rate is 31.566820 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.66      0.15      0.25       321\n",
            "           1       0.24      0.78      0.37       113\n",
            "\n",
            "    accuracy                           0.32       434\n",
            "   macro avg       0.45      0.47      0.31       434\n",
            "weighted avg       0.55      0.32      0.28       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 49 272]\n",
            " [ 25  88]]\n",
            "--------------------------------\n",
            "val predicted: (1232,) [0 1 1 ... 1 0 1]\n",
            "probabilities: (1232, 2) \n",
            " [0 1 1 ... 1 0 1]\n",
            "trainset before adding uncertain samples (70, 10) (70,)\n",
            "trainset after adding uncertain samples (80, 10) (80,)\n",
            "updated train set: (80, 10) (80,) unique(labels): [12 68] [0 1]\n",
            "val set: (1222, 10) (1222,)\n",
            "\n",
            "Train set: (80, 10)\n",
            "Validation set: (1222, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 8\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.116 s \n",
            "\n",
            "Accuracy rate is 31.566820 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.15      0.24       321\n",
            "           1       0.25      0.79      0.37       113\n",
            "\n",
            "    accuracy                           0.32       434\n",
            "   macro avg       0.46      0.47      0.31       434\n",
            "weighted avg       0.56      0.32      0.28       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 48 273]\n",
            " [ 24  89]]\n",
            "--------------------------------\n",
            "val predicted: (1222,) [0 1 1 ... 1 0 1]\n",
            "probabilities: (1222, 2) \n",
            " [0 1 1 ... 1 0 1]\n",
            "trainset before adding uncertain samples (80, 10) (80,)\n",
            "trainset after adding uncertain samples (90, 10) (90,)\n",
            "updated train set: (90, 10) (90,) unique(labels): [12 78] [0 1]\n",
            "val set: (1212, 10) (1212,)\n",
            "\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: divide by zero encountered in log2\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: invalid value encountered in multiply\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: divide by zero encountered in log2\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: invalid value encountered in multiply\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "Train set: (90, 10)\n",
            "Validation set: (1212, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 9\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.090 s \n",
            "\n",
            "Accuracy rate is 29.262673 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.07      0.13       321\n",
            "           1       0.26      0.92      0.40       113\n",
            "\n",
            "    accuracy                           0.29       434\n",
            "   macro avg       0.49      0.50      0.27       434\n",
            "weighted avg       0.60      0.29      0.20       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 23 298]\n",
            " [  9 104]]\n",
            "--------------------------------\n",
            "val predicted: (1212,) [0 1 1 ... 1 0 1]\n",
            "probabilities: (1212, 2) \n",
            " [0 1 1 ... 1 0 1]\n",
            "trainset before adding uncertain samples (90, 10) (90,)\n",
            "trainset after adding uncertain samples (100, 10) (100,)\n",
            "updated train set: (100, 10) (100,) unique(labels): [14 86] [0 1]\n",
            "val set: (1202, 10) (1202,)\n",
            "\n",
            "Train set: (100, 10)\n",
            "Validation set: (1202, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 10\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.078 s \n",
            "\n",
            "Accuracy rate is 33.640553 \n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: divide by zero encountered in log2\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: invalid value encountered in multiply\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: divide by zero encountered in log2\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: invalid value encountered in multiply\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.20      0.31       321\n",
            "           1       0.24      0.73      0.36       113\n",
            "\n",
            "    accuracy                           0.34       434\n",
            "   macro avg       0.46      0.46      0.34       434\n",
            "weighted avg       0.56      0.34      0.32       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 64 257]\n",
            " [ 31  82]]\n",
            "--------------------------------\n",
            "val predicted: (1202,) [0 1 1 ... 1 0 1]\n",
            "probabilities: (1202, 2) \n",
            " [0 1 1 ... 1 0 1]\n",
            "trainset before adding uncertain samples (100, 10) (100,)\n",
            "trainset after adding uncertain samples (110, 10) (110,)\n",
            "updated train set: (110, 10) (110,) unique(labels): [16 94] [0 1]\n",
            "val set: (1192, 10) (1192,)\n",
            "\n",
            "Train set: (110, 10)\n",
            "Validation set: (1192, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 11\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.071 s \n",
            "\n",
            "Accuracy rate is 34.792627 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.68      0.22      0.33       321\n",
            "           1       0.24      0.71      0.36       113\n",
            "\n",
            "    accuracy                           0.35       434\n",
            "   macro avg       0.46      0.46      0.35       434\n",
            "weighted avg       0.57      0.35      0.34       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 71 250]\n",
            " [ 33  80]]\n",
            "--------------------------------\n",
            "val predicted: (1192,) [0 1 1 ... 1 0 1]\n",
            "probabilities: (1192, 2) \n",
            " [0 1 1 ... 1 0 1]\n",
            "trainset before adding uncertain samples (110, 10) (110,)\n",
            "trainset after adding uncertain samples (120, 10) (120,)\n",
            "updated train set: (120, 10) (120,) unique(labels): [ 18 102] [0 1]\n",
            "val set: (1182, 10) (1182,)\n",
            "\n",
            "Train set: (120, 10)\n",
            "Validation set: (1182, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: divide by zero encountered in log2\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: invalid value encountered in multiply\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: divide by zero encountered in log2\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: invalid value encountered in multiply\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "--------------------------------\n",
            "Iteration: 12\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.079 s \n",
            "\n",
            "Accuracy rate is 41.244240 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.31      0.44       321\n",
            "           1       0.26      0.70      0.38       113\n",
            "\n",
            "    accuracy                           0.41       434\n",
            "   macro avg       0.50      0.51      0.41       434\n",
            "weighted avg       0.62      0.41      0.42       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[100 221]\n",
            " [ 34  79]]\n",
            "--------------------------------\n",
            "val predicted: (1182,) [0 1 1 ... 1 0 1]\n",
            "probabilities: (1182, 2) \n",
            " [0 1 1 ... 1 0 1]\n",
            "trainset before adding uncertain samples (120, 10) (120,)\n",
            "trainset after adding uncertain samples (130, 10) (130,)\n",
            "updated train set: (130, 10) (130,) unique(labels): [ 20 110] [0 1]\n",
            "val set: (1172, 10) (1172,)\n",
            "\n",
            "Train set: (130, 10)\n",
            "Validation set: (1172, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 13\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.108 s \n",
            "\n",
            "Accuracy rate is 40.552995 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.30      0.43       321\n",
            "           1       0.26      0.71      0.38       113\n",
            "\n",
            "    accuracy                           0.41       434\n",
            "   macro avg       0.50      0.50      0.40       434\n",
            "weighted avg       0.62      0.41      0.42       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 96 225]\n",
            " [ 33  80]]\n",
            "--------------------------------\n",
            "val predicted: (1172,) [0 1 1 ... 1 0 1]\n",
            "probabilities: (1172, 2) \n",
            " [0 1 1 ... 1 0 1]\n",
            "trainset before adding uncertain samples (130, 10) (130,)\n",
            "trainset after adding uncertain samples (140, 10) (140,)\n",
            "updated train set: (140, 10) (140,) unique(labels): [ 23 117] [0 1]\n",
            "val set: (1162, 10) (1162,)\n",
            "\n",
            "Train set: (140, 10)\n",
            "Validation set: (1162, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: divide by zero encountered in log2\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: invalid value encountered in multiply\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: divide by zero encountered in log2\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: invalid value encountered in multiply\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "--------------------------------\n",
            "Iteration: 14\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.084 s \n",
            "\n",
            "Accuracy rate is 41.244240 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.31      0.44       321\n",
            "           1       0.26      0.69      0.38       113\n",
            "\n",
            "    accuracy                           0.41       434\n",
            "   macro avg       0.50      0.50      0.41       434\n",
            "weighted avg       0.62      0.41      0.43       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[101 220]\n",
            " [ 35  78]]\n",
            "--------------------------------\n",
            "val predicted: (1162,) [0 1 1 ... 1 0 1]\n",
            "probabilities: (1162, 2) \n",
            " [0 1 1 ... 1 0 1]\n",
            "trainset before adding uncertain samples (140, 10) (140,)\n",
            "trainset after adding uncertain samples (150, 10) (150,)\n",
            "updated train set: (150, 10) (150,) unique(labels): [ 23 127] [0 1]\n",
            "val set: (1152, 10) (1152,)\n",
            "\n",
            "Train set: (150, 10)\n",
            "Validation set: (1152, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 15\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.103 s \n",
            "\n",
            "Accuracy rate is 41.244240 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.31      0.44       321\n",
            "           1       0.26      0.69      0.38       113\n",
            "\n",
            "    accuracy                           0.41       434\n",
            "   macro avg       0.50      0.50      0.41       434\n",
            "weighted avg       0.62      0.41      0.43       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[101 220]\n",
            " [ 35  78]]\n",
            "--------------------------------\n",
            "val predicted: (1152,) [0 1 1 ... 1 0 1]\n",
            "probabilities: (1152, 2) \n",
            " [0 1 1 ... 1 0 1]\n",
            "trainset before adding uncertain samples (150, 10) (150,)\n",
            "trainset after adding uncertain samples (160, 10) (160,)\n",
            "updated train set: (160, 10) (160,) unique(labels): [ 24 136] [0 1]\n",
            "val set: (1142, 10) (1142,)\n",
            "\n",
            "Train set: (160, 10)\n",
            "Validation set: (1142, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: divide by zero encountered in log2\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: invalid value encountered in multiply\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "--------------------------------\n",
            "Iteration: 16\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.066 s \n",
            "\n",
            "Accuracy rate is 41.474654 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.31      0.44       321\n",
            "           1       0.27      0.71      0.39       113\n",
            "\n",
            "    accuracy                           0.41       434\n",
            "   macro avg       0.51      0.51      0.41       434\n",
            "weighted avg       0.63      0.41      0.43       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[100 221]\n",
            " [ 33  80]]\n",
            "--------------------------------\n",
            "val predicted: (1142,) [0 1 1 ... 1 0 1]\n",
            "probabilities: (1142, 2) \n",
            " [0 1 1 ... 1 0 1]\n",
            "trainset before adding uncertain samples (160, 10) (160,)\n",
            "trainset after adding uncertain samples (170, 10) (170,)\n",
            "updated train set: (170, 10) (170,) unique(labels): [ 26 144] [0 1]\n",
            "val set: (1132, 10) (1132,)\n",
            "\n",
            "Train set: (170, 10)\n",
            "Validation set: (1132, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: divide by zero encountered in log2\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: invalid value encountered in multiply\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: divide by zero encountered in log2\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: invalid value encountered in multiply\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "--------------------------------\n",
            "Iteration: 17\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.080 s \n",
            "\n",
            "Accuracy rate is 41.244240 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.31      0.44       321\n",
            "           1       0.26      0.69      0.38       113\n",
            "\n",
            "    accuracy                           0.41       434\n",
            "   macro avg       0.50      0.50      0.41       434\n",
            "weighted avg       0.62      0.41      0.43       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[101 220]\n",
            " [ 35  78]]\n",
            "--------------------------------\n",
            "val predicted: (1132,) [0 1 1 ... 1 0 1]\n",
            "probabilities: (1132, 2) \n",
            " [0 1 1 ... 1 0 1]\n",
            "trainset before adding uncertain samples (170, 10) (170,)\n",
            "trainset after adding uncertain samples (180, 10) (180,)\n",
            "updated train set: (180, 10) (180,) unique(labels): [ 27 153] [0 1]\n",
            "val set: (1122, 10) (1122,)\n",
            "\n",
            "Train set: (180, 10)\n",
            "Validation set: (1122, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 18\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.072 s \n",
            "\n",
            "Accuracy rate is 42.396313 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.32      0.45       321\n",
            "           1       0.27      0.72      0.39       113\n",
            "\n",
            "    accuracy                           0.42       434\n",
            "   macro avg       0.52      0.52      0.42       434\n",
            "weighted avg       0.63      0.42      0.44       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[103 218]\n",
            " [ 32  81]]\n",
            "--------------------------------\n",
            "val predicted: (1122,) [0 1 1 ... 1 0 1]\n",
            "probabilities: (1122, 2) \n",
            " [0 1 1 ... 1 0 1]\n",
            "trainset before adding uncertain samples (180, 10) (180,)\n",
            "trainset after adding uncertain samples (190, 10) (190,)\n",
            "updated train set: (190, 10) (190,) unique(labels): [ 28 162] [0 1]\n",
            "val set: (1112, 10) (1112,)\n",
            "\n",
            "Train set: (190, 10)\n",
            "Validation set: (1112, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: divide by zero encountered in log2\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: invalid value encountered in multiply\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: divide by zero encountered in log2\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: invalid value encountered in multiply\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "--------------------------------\n",
            "Iteration: 19\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.082 s \n",
            "\n",
            "Accuracy rate is 42.165899 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.32      0.45       321\n",
            "           1       0.27      0.72      0.39       113\n",
            "\n",
            "    accuracy                           0.42       434\n",
            "   macro avg       0.52      0.52      0.42       434\n",
            "weighted avg       0.63      0.42      0.43       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[102 219]\n",
            " [ 32  81]]\n",
            "--------------------------------\n",
            "val predicted: (1112,) [0 1 1 ... 1 0 1]\n",
            "probabilities: (1112, 2) \n",
            " [0 1 1 ... 1 0 1]\n",
            "trainset before adding uncertain samples (190, 10) (190,)\n",
            "trainset after adding uncertain samples (200, 10) (200,)\n",
            "updated train set: (200, 10) (200,) unique(labels): [ 28 172] [0 1]\n",
            "val set: (1102, 10) (1102,)\n",
            "\n",
            "Train set: (200, 10)\n",
            "Validation set: (1102, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 20\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.076 s \n",
            "\n",
            "Accuracy rate is 42.396313 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.32      0.45       321\n",
            "           1       0.27      0.72      0.39       113\n",
            "\n",
            "    accuracy                           0.42       434\n",
            "   macro avg       0.52      0.52      0.42       434\n",
            "weighted avg       0.63      0.42      0.44       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[103 218]\n",
            " [ 32  81]]\n",
            "--------------------------------\n",
            "val predicted: (1102,) [0 1 1 ... 1 0 1]\n",
            "probabilities: (1102, 2) \n",
            " [0 1 1 ... 1 0 1]\n",
            "trainset before adding uncertain samples (200, 10) (200,)\n",
            "trainset after adding uncertain samples (210, 10) (210,)\n",
            "updated train set: (210, 10) (210,) unique(labels): [ 31 179] [0 1]\n",
            "val set: (1092, 10) (1092,)\n",
            "\n",
            "Train set: (210, 10)\n",
            "Validation set: (1092, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: divide by zero encountered in log2\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: invalid value encountered in multiply\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: divide by zero encountered in log2\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: invalid value encountered in multiply\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: divide by zero encountered in log2\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: invalid value encountered in multiply\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "--------------------------------\n",
            "Iteration: 21\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.073 s \n",
            "\n",
            "Accuracy rate is 41.013825 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.30      0.43       321\n",
            "           1       0.27      0.72      0.39       113\n",
            "\n",
            "    accuracy                           0.41       434\n",
            "   macro avg       0.51      0.51      0.41       434\n",
            "weighted avg       0.63      0.41      0.42       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 97 224]\n",
            " [ 32  81]]\n",
            "--------------------------------\n",
            "val predicted: (1092,) [0 1 1 ... 1 0 1]\n",
            "probabilities: (1092, 2) \n",
            " [0 1 1 ... 1 0 1]\n",
            "trainset before adding uncertain samples (210, 10) (210,)\n",
            "trainset after adding uncertain samples (220, 10) (220,)\n",
            "updated train set: (220, 10) (220,) unique(labels): [ 33 187] [0 1]\n",
            "val set: (1082, 10) (1082,)\n",
            "\n",
            "Train set: (220, 10)\n",
            "Validation set: (1082, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 22\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.067 s \n",
            "\n",
            "Accuracy rate is 41.935484 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.31      0.44       321\n",
            "           1       0.27      0.72      0.39       113\n",
            "\n",
            "    accuracy                           0.42       434\n",
            "   macro avg       0.51      0.52      0.42       434\n",
            "weighted avg       0.63      0.42      0.43       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[101 220]\n",
            " [ 32  81]]\n",
            "--------------------------------\n",
            "val predicted: (1082,) [0 1 1 ... 1 0 1]\n",
            "probabilities: (1082, 2) \n",
            " [0 1 1 ... 1 0 1]\n",
            "trainset before adding uncertain samples (220, 10) (220,)\n",
            "trainset after adding uncertain samples (230, 10) (230,)\n",
            "updated train set: (230, 10) (230,) unique(labels): [ 35 195] [0 1]\n",
            "val set: (1072, 10) (1072,)\n",
            "\n",
            "Train set: (230, 10)\n",
            "Validation set: (1072, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 23\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.068 s \n",
            "\n",
            "Accuracy rate is 42.396313 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.32      0.45       321\n",
            "           1       0.27      0.72      0.39       113\n",
            "\n",
            "    accuracy                           0.42       434\n",
            "   macro avg       0.52      0.52      0.42       434\n",
            "weighted avg       0.63      0.42      0.44       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[103 218]\n",
            " [ 32  81]]\n",
            "--------------------------------\n",
            "val predicted: (1072,) [0 1 1 ... 1 0 1]\n",
            "probabilities: (1072, 2) \n",
            " [0 1 1 ... 1 0 1]\n",
            "trainset before adding uncertain samples (230, 10) (230,)\n",
            "trainset after adding uncertain samples (240, 10) (240,)\n",
            "updated train set: (240, 10) (240,) unique(labels): [ 36 204] [0 1]\n",
            "val set: (1062, 10) (1062,)\n",
            "\n",
            "Train set: (240, 10)\n",
            "Validation set: (1062, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 24\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.069 s \n",
            "\n",
            "Accuracy rate is 41.705069 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.32      0.45       321\n",
            "           1       0.27      0.70      0.38       113\n",
            "\n",
            "    accuracy                           0.42       434\n",
            "   macro avg       0.51      0.51      0.42       434\n",
            "weighted avg       0.62      0.42      0.43       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[102 219]\n",
            " [ 34  79]]\n",
            "--------------------------------\n",
            "val predicted: (1062,) [0 1 1 ... 1 0 1]\n",
            "probabilities: (1062, 2) \n",
            " [0 1 1 ... 1 0 1]\n",
            "trainset before adding uncertain samples (240, 10) (240,)\n",
            "trainset after adding uncertain samples (250, 10) (250,)\n",
            "updated train set: (250, 10) (250,) unique(labels): [ 39 211] [0 1]\n",
            "val set: (1052, 10) (1052,)\n",
            "\n",
            "Train set: (250, 10)\n",
            "Validation set: (1052, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 25\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.063 s \n",
            "\n",
            "Accuracy rate is 48.617512 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.41      0.54       321\n",
            "           1       0.29      0.70      0.41       113\n",
            "\n",
            "    accuracy                           0.49       434\n",
            "   macro avg       0.54      0.56      0.48       434\n",
            "weighted avg       0.66      0.49      0.51       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[132 189]\n",
            " [ 34  79]]\n",
            "--------------------------------\n",
            "val predicted: (1052,) [0 1 1 ... 1 0 1]\n",
            "probabilities: (1052, 2) \n",
            " [0 1 1 ... 1 0 1]\n",
            "trainset before adding uncertain samples (250, 10) (250,)\n",
            "trainset after adding uncertain samples (260, 10) (260,)\n",
            "updated train set: (260, 10) (260,) unique(labels): [ 39 221] [0 1]\n",
            "val set: (1042, 10) (1042,)\n",
            "\n",
            "Train set: (260, 10)\n",
            "Validation set: (1042, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: divide by zero encountered in log2\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: invalid value encountered in multiply\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: divide by zero encountered in log2\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: invalid value encountered in multiply\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: divide by zero encountered in log2\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: invalid value encountered in multiply\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "--------------------------------\n",
            "Iteration: 26\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.068 s \n",
            "\n",
            "Accuracy rate is 44.239631 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.35      0.48       321\n",
            "           1       0.28      0.71      0.40       113\n",
            "\n",
            "    accuracy                           0.44       434\n",
            "   macro avg       0.52      0.53      0.44       434\n",
            "weighted avg       0.64      0.44      0.46       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[112 209]\n",
            " [ 33  80]]\n",
            "--------------------------------\n",
            "val predicted: (1042,) [0 1 1 ... 1 0 1]\n",
            "probabilities: (1042, 2) \n",
            " [0 1 1 ... 1 0 1]\n",
            "trainset before adding uncertain samples (260, 10) (260,)\n",
            "trainset after adding uncertain samples (270, 10) (270,)\n",
            "updated train set: (270, 10) (270,) unique(labels): [ 39 231] [0 1]\n",
            "val set: (1032, 10) (1032,)\n",
            "\n",
            "Train set: (270, 10)\n",
            "Validation set: (1032, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 27\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.064 s \n",
            "\n",
            "Accuracy rate is 42.857143 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.32      0.46       321\n",
            "           1       0.27      0.73      0.40       113\n",
            "\n",
            "    accuracy                           0.43       434\n",
            "   macro avg       0.52      0.52      0.43       434\n",
            "weighted avg       0.64      0.43      0.44       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[104 217]\n",
            " [ 31  82]]\n",
            "--------------------------------\n",
            "val predicted: (1032,) [0 1 1 ... 1 0 1]\n",
            "probabilities: (1032, 2) \n",
            " [0 1 1 ... 1 0 1]\n",
            "trainset before adding uncertain samples (270, 10) (270,)\n",
            "trainset after adding uncertain samples (280, 10) (280,)\n",
            "updated train set: (280, 10) (280,) unique(labels): [ 40 240] [0 1]\n",
            "val set: (1022, 10) (1022,)\n",
            "\n",
            "Train set: (280, 10)\n",
            "Validation set: (1022, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 28\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.069 s \n",
            "\n",
            "Accuracy rate is 41.935484 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.31      0.44       321\n",
            "           1       0.27      0.74      0.40       113\n",
            "\n",
            "    accuracy                           0.42       434\n",
            "   macro avg       0.52      0.52      0.42       434\n",
            "weighted avg       0.64      0.42      0.43       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 98 223]\n",
            " [ 29  84]]\n",
            "--------------------------------\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: divide by zero encountered in log2\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: invalid value encountered in multiply\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: divide by zero encountered in log2\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: invalid value encountered in multiply\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: divide by zero encountered in log2\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: invalid value encountered in multiply\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "val predicted: (1022,) [0 1 1 ... 1 0 1]\n",
            "probabilities: (1022, 2) \n",
            " [0 1 1 ... 1 0 1]\n",
            "trainset before adding uncertain samples (280, 10) (280,)\n",
            "trainset after adding uncertain samples (290, 10) (290,)\n",
            "updated train set: (290, 10) (290,) unique(labels): [ 45 245] [0 1]\n",
            "val set: (1012, 10) (1012,)\n",
            "\n",
            "Train set: (290, 10)\n",
            "Validation set: (1012, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 29\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.071 s \n",
            "\n",
            "Accuracy rate is 44.470046 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.34      0.48       321\n",
            "           1       0.28      0.73      0.41       113\n",
            "\n",
            "    accuracy                           0.44       434\n",
            "   macro avg       0.53      0.54      0.44       434\n",
            "weighted avg       0.65      0.44      0.46       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[110 211]\n",
            " [ 30  83]]\n",
            "--------------------------------\n",
            "val predicted: (1012,) [0 1 1 ... 1 0 0]\n",
            "probabilities: (1012, 2) \n",
            " [0 1 1 ... 1 0 0]\n",
            "trainset before adding uncertain samples (290, 10) (290,)\n",
            "trainset after adding uncertain samples (300, 10) (300,)\n",
            "updated train set: (300, 10) (300,) unique(labels): [ 45 255] [0 1]\n",
            "val set: (1002, 10) (1002,)\n",
            "\n",
            "Train set: (300, 10)\n",
            "Validation set: (1002, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 30\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.070 s \n",
            "\n",
            "Accuracy rate is 44.700461 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.34      0.48       321\n",
            "           1       0.29      0.75      0.41       113\n",
            "\n",
            "    accuracy                           0.45       434\n",
            "   macro avg       0.54      0.55      0.45       434\n",
            "weighted avg       0.66      0.45      0.46       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[109 212]\n",
            " [ 28  85]]\n",
            "--------------------------------\n",
            "val predicted: (1002,) [0 1 1 ... 1 0 0]\n",
            "probabilities: (1002, 2) \n",
            " [0 1 1 ... 1 0 0]\n",
            "trainset before adding uncertain samples (300, 10) (300,)\n",
            "trainset after adding uncertain samples (310, 10) (310,)\n",
            "updated train set: (310, 10) (310,) unique(labels): [ 46 264] [0 1]\n",
            "val set: (992, 10) (992,)\n",
            "\n",
            "Train set: (310, 10)\n",
            "Validation set: (992, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: divide by zero encountered in log2\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: invalid value encountered in multiply\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: divide by zero encountered in log2\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: invalid value encountered in multiply\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: divide by zero encountered in log2\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: invalid value encountered in multiply\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "--------------------------------\n",
            "Iteration: 31\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.062 s \n",
            "\n",
            "Accuracy rate is 45.622120 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.36      0.50       321\n",
            "           1       0.28      0.72      0.41       113\n",
            "\n",
            "    accuracy                           0.46       434\n",
            "   macro avg       0.53      0.54      0.45       434\n",
            "weighted avg       0.65      0.46      0.47       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[117 204]\n",
            " [ 32  81]]\n",
            "--------------------------------\n",
            "val predicted: (992,) [0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 0 0 1 1 1 1 0 1 1 1 1 1\n",
            " 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 0 1 1\n",
            " 1 1 0 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 0 1 0 1 0 1 0\n",
            " 0 1 0 0 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 0 1 1 1\n",
            " 1 1 1 1 0 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1\n",
            " 0 0 1 1 1 0 1 1 0 1 0 1 1 1 1 1 1 1 0 0 0 0 1 1 1 1 0 1 1 0 1 1 1 0 1 1 1\n",
            " 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 0 0 1 1 1 1 1 1 1 1 1 0 1 1 1\n",
            " 0 1 1 0 1 1 1 0 1 1 1 1 1 0 1 1 1 1 0 1 1 0 1 1 0 1 1 1 0 1 0 1 1 0 1 0 1\n",
            " 1 1 1 0 0 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1\n",
            " 1 1 1 1 0 1 1 0 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 0 1 1 1\n",
            " 1 1 1 1 0 1 1 1 1 0 1 0 0 1 0 1 1 1 0 0 1 1 0 1 1 0 1 0 1 1 1 1 0 1 1 0 1\n",
            " 0 0 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 0 0 0 1 1 1\n",
            " 1 1 0 1 1 1 1 1 0 0 1 1 0 1 1 0 1 1 1 1 1 1 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1\n",
            " 1 1 1 1 0 1 1 1 0 1 1 1 1 1 0 1 0 1 1 1 0 0 1 1 1 1 0 0 1 1 1 0 0 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 0 0 0 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0\n",
            " 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 0 0 1 1 1 1 1 1\n",
            " 0 0 1 0 1 1 1 1 1 1 1 0 1 1 0 1 0 1 0 1 0 0 1 1 1 1 1 1 1 0 1 1 1 0 1 1 0\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 0 1 1 1 1 0\n",
            " 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 0 1 1 1 1 0 1 0 1 0 1 0 1 1 0 1 0 0 1 0 1 1\n",
            " 0 1 1 1 1 0 0 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 0 0 0 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 0 0 0 0 1 0 1 1 1 1 1 0\n",
            " 1 0 1 1 1 1 1 1 1 0 1 0 0 1 1 1 0 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 0 1\n",
            " 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 0 1 1 0 0 0\n",
            " 1 0 0 1 0 1 1 1 1 1 0 0 1 1 0 1 1 0 1 1 1 1 1 0 0 1 1 0 0 1 0 1 1 1 0 1 1\n",
            " 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 0]\n",
            "probabilities: (992, 2) \n",
            " [0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 0 0 1 1 1 1 0 1 1 1 1 1\n",
            " 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 0 1 1\n",
            " 1 1 0 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 0 1 0 1 0 1 0\n",
            " 0 1 0 0 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 0 1 1 1\n",
            " 1 1 1 1 0 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1\n",
            " 0 0 1 1 1 0 1 1 0 1 0 1 1 1 1 1 1 1 0 0 0 0 1 1 1 1 0 1 1 0 1 1 1 0 1 1 1\n",
            " 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 0 0 1 1 1 1 1 1 1 1 1 0 1 1 1\n",
            " 0 1 1 0 1 1 1 0 1 1 1 1 1 0 1 1 1 1 0 1 1 0 1 1 0 1 1 1 0 1 0 1 1 0 1 0 1\n",
            " 1 1 1 0 0 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1\n",
            " 1 1 1 1 0 1 1 0 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 0 1 1 1\n",
            " 1 1 1 1 0 1 1 1 1 0 1 0 0 1 0 1 1 1 0 0 1 1 0 1 1 0 1 0 1 1 1 1 0 1 1 0 1\n",
            " 0 0 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 0 0 0 1 1 1\n",
            " 1 1 0 1 1 1 1 1 0 0 1 1 0 1 1 0 1 1 1 1 1 1 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1\n",
            " 1 1 1 1 0 1 1 1 0 1 1 1 1 1 0 1 0 1 1 1 0 0 1 1 1 1 0 0 1 1 1 0 0 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 0 0 0 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0\n",
            " 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 0 0 1 1 1 1 1 1\n",
            " 0 0 1 0 1 1 1 1 1 1 1 0 1 1 0 1 0 1 0 1 0 0 1 1 1 1 1 1 1 0 1 1 1 0 1 1 0\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 0 1 1 1 1 0\n",
            " 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 0 1 1 1 1 0 1 0 1 0 1 0 1 1 0 1 0 0 1 0 1 1\n",
            " 0 1 1 1 1 0 0 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 0 0 0 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 0 0 0 0 1 0 1 1 1 1 1 0\n",
            " 1 0 1 1 1 1 1 1 1 0 1 0 0 1 1 1 0 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 0 1\n",
            " 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 0 1 1 0 0 0\n",
            " 1 0 0 1 0 1 1 1 1 1 0 0 1 1 0 1 1 0 1 1 1 1 1 0 0 1 1 0 0 1 0 1 1 1 0 1 1\n",
            " 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 0]\n",
            "trainset before adding uncertain samples (310, 10) (310,)\n",
            "trainset after adding uncertain samples (320, 10) (320,)\n",
            "updated train set: (320, 10) (320,) unique(labels): [ 46 274] [0 1]\n",
            "val set: (982, 10) (982,)\n",
            "\n",
            "Train set: (320, 10)\n",
            "Validation set: (982, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 32\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.063 s \n",
            "\n",
            "Accuracy rate is 44.239631 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.34      0.47       321\n",
            "           1       0.28      0.74      0.41       113\n",
            "\n",
            "    accuracy                           0.44       434\n",
            "   macro avg       0.54      0.54      0.44       434\n",
            "weighted avg       0.66      0.44      0.46       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[108 213]\n",
            " [ 29  84]]\n",
            "--------------------------------\n",
            "val predicted: (982,) [0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 0 0 1 1 1 1 0 1 1 1 1 1\n",
            " 1 1 1 0 0 1 1 0 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 0 1 1 1\n",
            " 1 0 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 0 1 0 1 0 1 0 0\n",
            " 1 0 0 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 0 1 1 1 1\n",
            " 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 0 0\n",
            " 1 1 1 0 1 1 0 1 0 1 1 1 1 1 1 1 0 0 0 0 1 1 1 1 0 1 1 0 1 1 1 0 1 1 1 1 0\n",
            " 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 0 0 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1\n",
            " 0 1 1 1 0 1 1 1 1 1 0 1 1 1 0 1 1 0 1 1 0 1 1 1 0 1 0 1 1 0 1 0 1 1 1 1 0\n",
            " 0 0 1 1 1 1 1 1 1 0 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1\n",
            " 1 1 1 0 1 0 1 0 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1\n",
            " 1 1 1 0 1 0 0 1 0 1 1 1 0 0 1 1 0 1 1 0 1 0 1 1 1 1 0 1 1 0 1 0 0 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 0 0 0 1 1 1 1 1 0 1 1 1 0\n",
            " 1 0 0 1 1 0 1 1 0 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1\n",
            " 1 0 1 1 1 1 1 0 1 0 1 1 1 1 0 1 1 1 1 0 0 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 0 1 0 1 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 0 1 0 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 1 1 0 1 1 0 1 1 1\n",
            " 1 1 1 1 0 1 1 0 1 0 1 0 1 0 0 1 1 1 1 1 1 1 0 1 1 1 0 1 1 0 1 1 0 1 1 1 1\n",
            " 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 0 1 1 1 1 0 1 1 0 1 1 1 0\n",
            " 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 0 1 1 0 1 0 0 1 0 1 1 0 1 1 1 1 0 1 1\n",
            " 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 0 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 0 0 0 1 0 1 1 1 1 1 0 1 0 1 1 1 1 1 1\n",
            " 1 1 1 0 0 1 0 1 0 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1\n",
            " 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0 1 0 0 0 1 0 0 0 1 0 0 1 0 1 1 1 1\n",
            " 1 0 0 1 1 0 1 1 0 1 1 1 1 1 0 0 1 1 0 0 1 0 1 1 0 1 1 1 0 1 1 1 0 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 0 1]\n",
            "probabilities: (982, 2) \n",
            " [0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 0 0 1 1 1 1 0 1 1 1 1 1\n",
            " 1 1 1 0 0 1 1 0 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 0 1 1 1\n",
            " 1 0 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 0 1 0 1 0 1 0 0\n",
            " 1 0 0 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 0 1 1 1 1\n",
            " 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 0 0\n",
            " 1 1 1 0 1 1 0 1 0 1 1 1 1 1 1 1 0 0 0 0 1 1 1 1 0 1 1 0 1 1 1 0 1 1 1 1 0\n",
            " 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 0 0 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1\n",
            " 0 1 1 1 0 1 1 1 1 1 0 1 1 1 0 1 1 0 1 1 0 1 1 1 0 1 0 1 1 0 1 0 1 1 1 1 0\n",
            " 0 0 1 1 1 1 1 1 1 0 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1\n",
            " 1 1 1 0 1 0 1 0 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1\n",
            " 1 1 1 0 1 0 0 1 0 1 1 1 0 0 1 1 0 1 1 0 1 0 1 1 1 1 0 1 1 0 1 0 0 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 0 0 0 1 1 1 1 1 0 1 1 1 0\n",
            " 1 0 0 1 1 0 1 1 0 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1\n",
            " 1 0 1 1 1 1 1 0 1 0 1 1 1 1 0 1 1 1 1 0 0 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 0 1 0 1 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 0 1 0 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 1 1 0 1 1 0 1 1 1\n",
            " 1 1 1 1 0 1 1 0 1 0 1 0 1 0 0 1 1 1 1 1 1 1 0 1 1 1 0 1 1 0 1 1 0 1 1 1 1\n",
            " 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 0 1 1 1 1 0 1 1 0 1 1 1 0\n",
            " 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 0 1 1 0 1 0 0 1 0 1 1 0 1 1 1 1 0 1 1\n",
            " 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 0 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 0 0 0 1 0 1 1 1 1 1 0 1 0 1 1 1 1 1 1\n",
            " 1 1 1 0 0 1 0 1 0 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1\n",
            " 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0 1 0 0 0 1 0 0 0 1 0 0 1 0 1 1 1 1\n",
            " 1 0 0 1 1 0 1 1 0 1 1 1 1 1 0 0 1 1 0 0 1 0 1 1 0 1 1 1 0 1 1 1 0 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 0 1]\n",
            "trainset before adding uncertain samples (320, 10) (320,)\n",
            "trainset after adding uncertain samples (330, 10) (330,)\n",
            "updated train set: (330, 10) (330,) unique(labels): [ 47 283] [0 1]\n",
            "val set: (972, 10) (972,)\n",
            "\n",
            "Train set: (330, 10)\n",
            "Validation set: (972, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 33\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.064 s \n",
            "\n",
            "Accuracy rate is 44.239631 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.34      0.47       321\n",
            "           1       0.28      0.74      0.41       113\n",
            "\n",
            "    accuracy                           0.44       434\n",
            "   macro avg       0.54      0.54      0.44       434\n",
            "weighted avg       0.66      0.44      0.46       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[108 213]\n",
            " [ 29  84]]\n",
            "--------------------------------\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: divide by zero encountered in log2\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: invalid value encountered in multiply\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: divide by zero encountered in log2\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: invalid value encountered in multiply\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: divide by zero encountered in log2\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: invalid value encountered in multiply\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "val predicted: (972,) [0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 0 0 1 1 1 1 0 1 1 1 1 1 1 1\n",
            " 0 0 1 1 0 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 0 1 1 1 1 0 1\n",
            " 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 0 1 0 1 0 1 0 0 1 0 1\n",
            " 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1\n",
            " 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 0 1 1 1 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 0 0 1 1 1\n",
            " 0 1 1 0 1 0 1 1 1 1 1 1 0 0 0 0 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 0 1 1 0 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 0 0 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 0 1 1 1\n",
            " 0 1 1 1 1 1 0 1 1 1 0 1 1 0 1 1 0 1 1 1 0 1 0 1 1 0 1 0 1 1 1 0 0 0 1 1 1\n",
            " 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0\n",
            " 1 0 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 0 1 0 0\n",
            " 1 0 1 1 1 0 0 1 1 0 1 1 0 1 0 1 1 1 1 0 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1\n",
            " 0 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 0 0 0 1 1 1 1 1 0 1 1 1 0 1 0 0 1 1 0 1 1\n",
            " 0 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 0\n",
            " 1 0 1 1 1 1 0 1 1 1 1 0 0 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0\n",
            " 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0\n",
            " 1 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 0 1 1 0 1 0\n",
            " 1 0 1 0 0 1 1 1 1 1 1 1 0 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 0 1\n",
            " 1 1 1 1 1 1 1 1 1 1 0 0 0 1 0 1 1 1 1 0 1 1 0 1 1 1 0 0 1 1 1 1 1 1 1 0 1\n",
            " 1 1 1 1 1 1 0 1 0 1 1 0 0 0 0 1 0 1 1 0 1 1 1 1 0 1 1 0 1 1 1 1 0 1 1 1 1\n",
            " 1 0 1 1 1 1 1 0 1 1 1 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1\n",
            " 1 1 1 0 1 1 1 1 0 0 1 1 0 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 0 0 1 0 1 0 1\n",
            " 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1\n",
            " 1 1 1 1 1 0 0 1 0 0 1 0 0 0 1 0 0 0 1 0 0 1 0 1 1 1 1 1 0 0 1 1 0 1 1 0 1\n",
            " 1 1 1 1 0 0 1 1 0 0 1 0 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1\n",
            " 1 1 0 1 1 1 1 1 0 1]\n",
            "probabilities: (972, 2) \n",
            " [0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 0 0 1 1 1 1 0 1 1 1 1 1 1 1\n",
            " 0 0 1 1 0 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 0 1 1 1 1 0 1\n",
            " 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 0 1 0 1 0 1 0 0 1 0 1\n",
            " 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1\n",
            " 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 0 1 1 1 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 0 0 1 1 1\n",
            " 0 1 1 0 1 0 1 1 1 1 1 1 0 0 0 0 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 0 1 1 0 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 0 0 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 0 1 1 1\n",
            " 0 1 1 1 1 1 0 1 1 1 0 1 1 0 1 1 0 1 1 1 0 1 0 1 1 0 1 0 1 1 1 0 0 0 1 1 1\n",
            " 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0\n",
            " 1 0 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 0 1 0 0\n",
            " 1 0 1 1 1 0 0 1 1 0 1 1 0 1 0 1 1 1 1 0 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1\n",
            " 0 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 0 0 0 1 1 1 1 1 0 1 1 1 0 1 0 0 1 1 0 1 1\n",
            " 0 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 0\n",
            " 1 0 1 1 1 1 0 1 1 1 1 0 0 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0\n",
            " 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0\n",
            " 1 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 0 1 1 0 1 0\n",
            " 1 0 1 0 0 1 1 1 1 1 1 1 0 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 0 1\n",
            " 1 1 1 1 1 1 1 1 1 1 0 0 0 1 0 1 1 1 1 0 1 1 0 1 1 1 0 0 1 1 1 1 1 1 1 0 1\n",
            " 1 1 1 1 1 1 0 1 0 1 1 0 0 0 0 1 0 1 1 0 1 1 1 1 0 1 1 0 1 1 1 1 0 1 1 1 1\n",
            " 1 0 1 1 1 1 1 0 1 1 1 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1\n",
            " 1 1 1 0 1 1 1 1 0 0 1 1 0 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 0 0 1 0 1 0 1\n",
            " 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1\n",
            " 1 1 1 1 1 0 0 1 0 0 1 0 0 0 1 0 0 0 1 0 0 1 0 1 1 1 1 1 0 0 1 1 0 1 1 0 1\n",
            " 1 1 1 1 0 0 1 1 0 0 1 0 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1\n",
            " 1 1 0 1 1 1 1 1 0 1]\n",
            "trainset before adding uncertain samples (330, 10) (330,)\n",
            "trainset after adding uncertain samples (340, 10) (340,)\n",
            "updated train set: (340, 10) (340,) unique(labels): [ 50 290] [0 1]\n",
            "val set: (962, 10) (962,)\n",
            "\n",
            "Train set: (340, 10)\n",
            "Validation set: (962, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 34\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.063 s \n",
            "\n",
            "Accuracy rate is 45.852535 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.39      0.52       321\n",
            "           1       0.27      0.65      0.39       113\n",
            "\n",
            "    accuracy                           0.46       434\n",
            "   macro avg       0.52      0.52      0.45       434\n",
            "weighted avg       0.64      0.46      0.48       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[125 196]\n",
            " [ 39  74]]\n",
            "--------------------------------\n",
            "val predicted: (962,) [0 1 1 0 0 1 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 0 0 1 1 1 1 0 1 1 1 1 1 1 1 0\n",
            " 0 1 1 0 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 0 1 1 1 1 0 1 1 1\n",
            " 1 1 0 1 1 0 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 0 1 0 1 0 1 0 0 1 0 0 1 1\n",
            " 1 0 1 1 0 0 1 1 1 1 1 0 1 1 1 1 1 0 1 0 0 1 1 1 1 1 0 0 1 1 0 1 1 1 1 0 1\n",
            " 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1\n",
            " 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 0 0 1 1 1 0 1\n",
            " 1 0 1 0 1 1 0 1 1 1 0 0 0 0 1 1 1 0 1 1 0 1 1 1 0 1 1 1 1 0 0 1 0 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 0 1 0 1 0 0 1 1 1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 1 1 0 1 1\n",
            " 1 1 1 0 1 1 1 0 1 1 0 1 1 0 1 1 1 0 1 0 1 1 0 1 1 1 1 0 0 1 1 1 0 1 1 1 1\n",
            " 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 0 1 0 1 1 0 1 0 1 0 1 1 1 1\n",
            " 0 1 1 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 0 1 0 0 1 0 1 1 1 0\n",
            " 0 1 1 0 1 1 0 1 0 1 1 1 1 0 1 1 0 1 0 0 1 1 1 1 1 0 1 1 0 1 1 0 1 1 1 0 1\n",
            " 1 1 1 0 0 1 1 1 1 1 0 0 0 1 1 1 1 1 0 0 1 1 1 1 0 0 1 1 0 1 1 0 1 1 1 1 0\n",
            " 1 1 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 0 1 0 1 1 1 0\n",
            " 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 0 0 1 0 1 0 1\n",
            " 1 1 1 1 1 0 1 1 1 0 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 0 0 0 0 1\n",
            " 1 1 1 1 0 1 0 0 1 1 0 1 0 0 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 0 1 1 0 0 1 0 0 1 1 1 1 1 0 0 0 1 0 1 1 1 1 0 1 1 0 1 1 0 1 0 1 0 1 0 0 1\n",
            " 1 0 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1\n",
            " 1 1 1 0 0 0 1 0 1 1 1 1 0 1 1 0 1 1 1 0 0 1 1 1 0 0 1 0 1 1 1 0 1 1 1 0 1\n",
            " 0 1 1 0 0 0 0 1 1 1 0 1 1 1 1 0 0 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 0 1\n",
            " 1 1 0 0 0 0 0 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 0 1 1 0 1 0 0 0 0\n",
            " 0 0 1 0 1 1 0 1 0 0 0 0 1 1 1 1 1 1 1 1 1 0 0 1 0 1 0 1 1 1 1 1 0 0 1 1 1\n",
            " 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 0 1 0\n",
            " 0 1 0 0 1 1 0 0 0 1 0 0 1 0 1 1 1 1 1 0 0 1 1 0 1 1 0 1 1 1 1 1 0 0 1 1 0\n",
            " 0 1 0 1 1 1 0 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 0 1 1 1 1 0 0]\n",
            "probabilities: (962, 2) \n",
            " [0 1 1 0 0 1 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 0 0 1 1 1 1 0 1 1 1 1 1 1 1 0\n",
            " 0 1 1 0 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 0 1 1 1 1 0 1 1 1\n",
            " 1 1 0 1 1 0 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 0 1 0 1 0 1 0 0 1 0 0 1 1\n",
            " 1 0 1 1 0 0 1 1 1 1 1 0 1 1 1 1 1 0 1 0 0 1 1 1 1 1 0 0 1 1 0 1 1 1 1 0 1\n",
            " 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1\n",
            " 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 0 0 1 1 1 0 1\n",
            " 1 0 1 0 1 1 0 1 1 1 0 0 0 0 1 1 1 0 1 1 0 1 1 1 0 1 1 1 1 0 0 1 0 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 0 1 0 1 0 0 1 1 1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 1 1 0 1 1\n",
            " 1 1 1 0 1 1 1 0 1 1 0 1 1 0 1 1 1 0 1 0 1 1 0 1 1 1 1 0 0 1 1 1 0 1 1 1 1\n",
            " 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 0 1 0 1 1 0 1 0 1 0 1 1 1 1\n",
            " 0 1 1 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 0 1 0 0 1 0 1 1 1 0\n",
            " 0 1 1 0 1 1 0 1 0 1 1 1 1 0 1 1 0 1 0 0 1 1 1 1 1 0 1 1 0 1 1 0 1 1 1 0 1\n",
            " 1 1 1 0 0 1 1 1 1 1 0 0 0 1 1 1 1 1 0 0 1 1 1 1 0 0 1 1 0 1 1 0 1 1 1 1 0\n",
            " 1 1 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 0 1 0 1 1 1 0\n",
            " 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 0 0 1 0 1 0 1\n",
            " 1 1 1 1 1 0 1 1 1 0 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 0 0 0 0 1\n",
            " 1 1 1 1 0 1 0 0 1 1 0 1 0 0 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 0 1 1 0 0 1 0 0 1 1 1 1 1 0 0 0 1 0 1 1 1 1 0 1 1 0 1 1 0 1 0 1 0 1 0 0 1\n",
            " 1 0 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1\n",
            " 1 1 1 0 0 0 1 0 1 1 1 1 0 1 1 0 1 1 1 0 0 1 1 1 0 0 1 0 1 1 1 0 1 1 1 0 1\n",
            " 0 1 1 0 0 0 0 1 1 1 0 1 1 1 1 0 0 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 0 1\n",
            " 1 1 0 0 0 0 0 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 0 1 1 0 1 0 0 0 0\n",
            " 0 0 1 0 1 1 0 1 0 0 0 0 1 1 1 1 1 1 1 1 1 0 0 1 0 1 0 1 1 1 1 1 0 0 1 1 1\n",
            " 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 0 1 0\n",
            " 0 1 0 0 1 1 0 0 0 1 0 0 1 0 1 1 1 1 1 0 0 1 1 0 1 1 0 1 1 1 1 1 0 0 1 1 0\n",
            " 0 1 0 1 1 1 0 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 0 1 1 1 1 0 0]\n",
            "trainset before adding uncertain samples (340, 10) (340,)\n",
            "trainset after adding uncertain samples (350, 10) (350,)\n",
            "updated train set: (350, 10) (350,) unique(labels): [ 53 297] [0 1]\n",
            "val set: (952, 10) (952,)\n",
            "\n",
            "Train set: (350, 10)\n",
            "Validation set: (952, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 35\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.071 s \n",
            "\n",
            "Accuracy rate is 60.829493 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.59      0.69       321\n",
            "           1       0.36      0.65      0.47       113\n",
            "\n",
            "    accuracy                           0.61       434\n",
            "   macro avg       0.60      0.62      0.58       434\n",
            "weighted avg       0.71      0.61      0.63       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[190 131]\n",
            " [ 39  74]]\n",
            "--------------------------------\n",
            "val predicted: (952,) [0 1 1 0 0 1 1 0 1 1 0 1 1 0 1 1 0 0 1 0 1 1 0 0 1 1 1 1 0 1 1 1 1 1 1 1 0\n",
            " 0 1 0 0 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 0 0 1 0 1 1 0 1 0 0 1 1 0 1 0 1 0 1\n",
            " 1 0 0 1 1 0 1 0 1 0 1 1 1 1 0 1 0 1 1 1 1 1 0 0 0 1 0 1 0 1 0 0 1 0 0 1 1\n",
            " 1 0 1 1 0 0 1 0 1 0 1 0 1 1 1 0 1 0 1 0 0 1 0 0 1 1 0 0 1 1 0 1 1 1 1 0 1\n",
            " 0 1 0 1 1 1 1 0 1 1 1 1 1 1 1 0 0 1 1 1 0 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1\n",
            " 1 1 1 1 0 1 0 1 1 0 0 1 0 0 1 1 1 1 1 1 1 0 0 0 0 1 1 1 1 1 0 0 1 1 1 0 0\n",
            " 1 0 1 0 1 1 0 1 1 1 0 0 0 0 1 1 1 0 1 1 0 1 0 1 0 0 1 1 1 0 0 1 0 1 1 1 0\n",
            " 1 1 1 1 1 1 0 0 0 0 1 0 0 0 1 1 1 1 1 1 0 1 0 1 0 1 0 0 1 0 1 1 0 0 0 0 1\n",
            " 0 1 0 1 1 0 0 0 0 0 1 1 0 1 1 1 1 1 0 1 0 0 1 1 0 1 0 0 1 1 1 0 1 1 1 1 0\n",
            " 1 0 1 0 0 1 1 1 1 1 1 1 0 1 0 0 0 1 1 1 1 1 0 1 0 1 1 0 1 0 0 0 1 1 1 1 0\n",
            " 1 1 1 1 1 0 0 1 1 1 1 1 0 0 1 1 1 1 1 1 1 0 1 1 1 1 0 1 0 0 1 1 0 1 1 0 0\n",
            " 1 1 0 1 1 0 0 0 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1 0 0 1 1 1 1 0 1 0 1 1 1 1 0\n",
            " 1 0 0 0 1 1 1 1 0 0 0 1 1 1 1 1 0 0 0 1 1 1 0 0 1 1 0 1 0 1 0 1 1 1 0 1 1\n",
            " 1 0 1 1 0 1 0 1 0 1 1 1 1 1 0 1 1 1 0 1 1 0 0 1 1 1 0 1 0 1 0 1 1 1 0 0 1\n",
            " 0 1 0 0 0 1 0 1 0 0 1 1 0 1 1 0 0 1 1 1 1 1 0 1 1 0 1 1 0 0 1 0 0 0 1 1 1\n",
            " 1 1 0 0 1 1 0 1 0 0 0 0 1 1 1 1 1 1 1 0 1 1 0 1 0 0 1 0 1 0 0 0 1 1 0 1 1\n",
            " 1 0 0 0 1 1 0 1 0 0 1 1 0 0 1 0 1 0 0 1 0 1 1 1 0 0 1 0 1 1 1 1 1 0 1 1 0\n",
            " 0 1 0 0 1 1 1 1 1 0 0 0 1 0 1 1 1 1 0 1 1 0 1 1 1 0 1 0 1 0 1 1 1 1 0 1 0\n",
            " 1 1 0 1 1 0 1 1 0 1 1 1 1 0 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 0 0 1 0 0 0 0\n",
            " 0 1 1 1 1 0 1 1 0 0 1 1 1 0 1 1 1 0 0 1 0 1 1 1 0 1 0 1 0 0 0 1 1 0 1 0 0\n",
            " 1 1 1 0 1 1 1 1 0 0 1 0 1 1 1 1 0 1 1 1 1 0 0 1 1 0 1 0 0 1 0 0 0 0 0 1 0\n",
            " 1 1 1 1 1 0 1 1 1 1 1 0 1 0 1 1 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 0 1 1 0\n",
            " 1 0 0 1 0 0 1 1 1 0 1 0 1 0 0 0 1 0 1 0 1 0 0 1 1 0 0 1 1 1 0 1 0 0 1 1 1\n",
            " 0 1 1 1 0 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 0 0 1 1 0 0 0 0 1 1 0 0 0\n",
            " 1 0 0 1 0 1 1 1 1 1 0 0 1 1 0 1 1 0 1 1 1 0 1 1 0 0 1 0 0 1 0 1 1 1 0 1 1\n",
            " 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 0 1 1 1 1 0]\n",
            "probabilities: (952, 2) \n",
            " [0 1 1 0 0 1 1 0 1 1 0 1 1 0 1 1 0 0 1 0 1 1 0 0 1 1 1 1 0 1 1 1 1 1 1 1 0\n",
            " 0 1 0 0 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 0 0 1 0 1 1 0 1 0 0 1 1 0 1 0 1 0 1\n",
            " 1 0 0 1 1 0 1 0 1 0 1 1 1 1 0 1 0 1 1 1 1 1 0 0 0 1 0 1 0 1 0 0 1 0 0 1 1\n",
            " 1 0 1 1 0 0 1 0 1 0 1 0 1 1 1 0 1 0 1 0 0 1 0 0 1 1 0 0 1 1 0 1 1 1 1 0 1\n",
            " 0 1 0 1 1 1 1 0 1 1 1 1 1 1 1 0 0 1 1 1 0 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1\n",
            " 1 1 1 1 0 1 0 1 1 0 0 1 0 0 1 1 1 1 1 1 1 0 0 0 0 1 1 1 1 1 0 0 1 1 1 0 0\n",
            " 1 0 1 0 1 1 0 1 1 1 0 0 0 0 1 1 1 0 1 1 0 1 0 1 0 0 1 1 1 0 0 1 0 1 1 1 0\n",
            " 1 1 1 1 1 1 0 0 0 0 1 0 0 0 1 1 1 1 1 1 0 1 0 1 0 1 0 0 1 0 1 1 0 0 0 0 1\n",
            " 0 1 0 1 1 0 0 0 0 0 1 1 0 1 1 1 1 1 0 1 0 0 1 1 0 1 0 0 1 1 1 0 1 1 1 1 0\n",
            " 1 0 1 0 0 1 1 1 1 1 1 1 0 1 0 0 0 1 1 1 1 1 0 1 0 1 1 0 1 0 0 0 1 1 1 1 0\n",
            " 1 1 1 1 1 0 0 1 1 1 1 1 0 0 1 1 1 1 1 1 1 0 1 1 1 1 0 1 0 0 1 1 0 1 1 0 0\n",
            " 1 1 0 1 1 0 0 0 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1 0 0 1 1 1 1 0 1 0 1 1 1 1 0\n",
            " 1 0 0 0 1 1 1 1 0 0 0 1 1 1 1 1 0 0 0 1 1 1 0 0 1 1 0 1 0 1 0 1 1 1 0 1 1\n",
            " 1 0 1 1 0 1 0 1 0 1 1 1 1 1 0 1 1 1 0 1 1 0 0 1 1 1 0 1 0 1 0 1 1 1 0 0 1\n",
            " 0 1 0 0 0 1 0 1 0 0 1 1 0 1 1 0 0 1 1 1 1 1 0 1 1 0 1 1 0 0 1 0 0 0 1 1 1\n",
            " 1 1 0 0 1 1 0 1 0 0 0 0 1 1 1 1 1 1 1 0 1 1 0 1 0 0 1 0 1 0 0 0 1 1 0 1 1\n",
            " 1 0 0 0 1 1 0 1 0 0 1 1 0 0 1 0 1 0 0 1 0 1 1 1 0 0 1 0 1 1 1 1 1 0 1 1 0\n",
            " 0 1 0 0 1 1 1 1 1 0 0 0 1 0 1 1 1 1 0 1 1 0 1 1 1 0 1 0 1 0 1 1 1 1 0 1 0\n",
            " 1 1 0 1 1 0 1 1 0 1 1 1 1 0 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 0 0 1 0 0 0 0\n",
            " 0 1 1 1 1 0 1 1 0 0 1 1 1 0 1 1 1 0 0 1 0 1 1 1 0 1 0 1 0 0 0 1 1 0 1 0 0\n",
            " 1 1 1 0 1 1 1 1 0 0 1 0 1 1 1 1 0 1 1 1 1 0 0 1 1 0 1 0 0 1 0 0 0 0 0 1 0\n",
            " 1 1 1 1 1 0 1 1 1 1 1 0 1 0 1 1 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 0 1 1 0\n",
            " 1 0 0 1 0 0 1 1 1 0 1 0 1 0 0 0 1 0 1 0 1 0 0 1 1 0 0 1 1 1 0 1 0 0 1 1 1\n",
            " 0 1 1 1 0 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 0 0 1 1 0 0 0 0 1 1 0 0 0\n",
            " 1 0 0 1 0 1 1 1 1 1 0 0 1 1 0 1 1 0 1 1 1 0 1 1 0 0 1 0 0 1 0 1 1 1 0 1 1\n",
            " 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 0 1 1 1 1 0]\n",
            "trainset before adding uncertain samples (350, 10) (350,)\n",
            "trainset after adding uncertain samples (360, 10) (360,)\n",
            "updated train set: (360, 10) (360,) unique(labels): [ 58 302] [0 1]\n",
            "val set: (942, 10) (942,)\n",
            "\n",
            "Train set: (360, 10)\n",
            "Validation set: (942, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 36\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.061 s \n",
            "\n",
            "Accuracy rate is 58.064516 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.55      0.66       321\n",
            "           1       0.34      0.67      0.46       113\n",
            "\n",
            "    accuracy                           0.58       434\n",
            "   macro avg       0.59      0.61      0.56       434\n",
            "weighted avg       0.70      0.58      0.61       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[176 145]\n",
            " [ 37  76]]\n",
            "--------------------------------\n",
            "val predicted: (942,) [1 1 1 0 1 1 0 1 1 0 1 1 0 1 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 0 0\n",
            " 1 0 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 0 1 0 1 1 0 1 0 0 1 1 0 1 0 1 0 1 1\n",
            " 0 1 1 1 0 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 0 1 1 1 0 0 1 0 0 1 1 1\n",
            " 0 1 1 0 0 1 0 1 1 1 1 1 1 1 0 1 0 1 0 0 1 1 0 1 1 0 0 1 1 0 1 1 1 1 0 1 0\n",
            " 1 0 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 0 0 1 0 1 1 1 0 1 1\n",
            " 1 1 1 1 1 1 1 1 0 0 1 0 0 1 1 1 1 1 1 1 0 0 0 0 1 1 1 1 1 1 0 1 1 1 0 0 1\n",
            " 1 1 1 1 1 0 1 1 1 0 0 0 0 1 1 1 0 1 1 0 1 0 1 0 0 1 1 1 0 0 1 0 1 1 1 1 1\n",
            " 1 1 1 1 0 0 0 0 1 0 0 0 1 1 1 1 1 1 1 1 0 1 0 1 0 0 1 1 0 0 0 1 0 1 0 1 1\n",
            " 1 0 0 0 0 1 1 0 1 1 1 1 1 0 1 0 1 1 1 0 1 0 0 1 1 1 0 1 1 1 0 0 1 0 1 0 0\n",
            " 1 1 1 1 1 1 1 0 1 0 0 0 1 1 1 1 1 0 1 0 1 1 0 1 0 1 0 1 1 1 1 0 1 1 1 0 1\n",
            " 0 0 1 1 1 1 1 0 0 1 1 1 1 1 1 1 0 1 1 1 1 0 1 0 0 1 1 0 1 1 0 0 1 1 0 1 1\n",
            " 0 0 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1 0 0 1 1 1 1 0 1 1 1 1 1 1 0 1 0 0 0 1 1\n",
            " 1 1 0 0 0 1 1 1 1 1 0 0 0 1 1 1 0 0 1 1 0 1 0 1 0 1 1 1 0 1 1 1 1 1 1 0 1\n",
            " 0 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 0 1 1 1 1 0 0 1 0 1 1 1 0 0 1 0 1 0 0 1 1\n",
            " 0 1 0 0 1 1 0 1 1 0 0 1 1 1 1 1 0 1 1 0 1 1 0 0 0 0 0 0 1 1 1 1 1 0 1 1 1\n",
            " 0 1 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 0 0 0 1 1 0 0 1 1 0 0 0 1 1 0\n",
            " 1 0 0 1 1 0 1 1 0 1 0 0 1 0 1 1 1 0 1 1 0 1 1 1 1 1 0 1 1 0 1 1 0 0 1 1 1\n",
            " 1 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 0 1 1 1 0 1 1 0 1 1 0 1 1 0 1\n",
            " 1 0 1 1 1 1 0 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 0 0 1 0 0 0 0 0 1 1 1 1 0 1\n",
            " 1 0 0 1 1 1 0 1 1 1 0 1 1 0 1 1 1 0 1 0 1 0 0 0 1 1 0 1 1 0 1 1 1 0 1 1 0\n",
            " 1 0 0 0 0 1 1 1 1 0 1 1 1 1 0 0 1 1 0 1 0 0 1 0 0 0 0 1 1 1 1 1 1 1 0 1 1\n",
            " 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 0 1 0 0 0 1 0 0 1 0 1 1 0 0 1 0 1 0 0 1 1 0\n",
            " 0 1 1 1 0 0 0 1 0 1 1 1 1 0 1 1 0 0 1 1 1 1 1 1 0 1 1 1 0 1 1 1 0 1 0 1 1\n",
            " 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 0 0 1 1 0 0 0 0 1 1 0 0 0 1 0 0 1 0 1 1 1 1\n",
            " 1 0 0 1 1 0 1 1 0 0 1 1 1 0 1 0 0 1 1 0 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 0 0 0 0 1 1 1 1 0]\n",
            "probabilities: (942, 2) \n",
            " [1 1 1 0 1 1 0 1 1 0 1 1 0 1 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 0 0\n",
            " 1 0 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 0 1 0 1 1 0 1 0 0 1 1 0 1 0 1 0 1 1\n",
            " 0 1 1 1 0 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 0 1 1 1 0 0 1 0 0 1 1 1\n",
            " 0 1 1 0 0 1 0 1 1 1 1 1 1 1 0 1 0 1 0 0 1 1 0 1 1 0 0 1 1 0 1 1 1 1 0 1 0\n",
            " 1 0 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 0 0 1 0 1 1 1 0 1 1\n",
            " 1 1 1 1 1 1 1 1 0 0 1 0 0 1 1 1 1 1 1 1 0 0 0 0 1 1 1 1 1 1 0 1 1 1 0 0 1\n",
            " 1 1 1 1 1 0 1 1 1 0 0 0 0 1 1 1 0 1 1 0 1 0 1 0 0 1 1 1 0 0 1 0 1 1 1 1 1\n",
            " 1 1 1 1 0 0 0 0 1 0 0 0 1 1 1 1 1 1 1 1 0 1 0 1 0 0 1 1 0 0 0 1 0 1 0 1 1\n",
            " 1 0 0 0 0 1 1 0 1 1 1 1 1 0 1 0 1 1 1 0 1 0 0 1 1 1 0 1 1 1 0 0 1 0 1 0 0\n",
            " 1 1 1 1 1 1 1 0 1 0 0 0 1 1 1 1 1 0 1 0 1 1 0 1 0 1 0 1 1 1 1 0 1 1 1 0 1\n",
            " 0 0 1 1 1 1 1 0 0 1 1 1 1 1 1 1 0 1 1 1 1 0 1 0 0 1 1 0 1 1 0 0 1 1 0 1 1\n",
            " 0 0 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1 0 0 1 1 1 1 0 1 1 1 1 1 1 0 1 0 0 0 1 1\n",
            " 1 1 0 0 0 1 1 1 1 1 0 0 0 1 1 1 0 0 1 1 0 1 0 1 0 1 1 1 0 1 1 1 1 1 1 0 1\n",
            " 0 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 0 1 1 1 1 0 0 1 0 1 1 1 0 0 1 0 1 0 0 1 1\n",
            " 0 1 0 0 1 1 0 1 1 0 0 1 1 1 1 1 0 1 1 0 1 1 0 0 0 0 0 0 1 1 1 1 1 0 1 1 1\n",
            " 0 1 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 0 0 0 1 1 0 0 1 1 0 0 0 1 1 0\n",
            " 1 0 0 1 1 0 1 1 0 1 0 0 1 0 1 1 1 0 1 1 0 1 1 1 1 1 0 1 1 0 1 1 0 0 1 1 1\n",
            " 1 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 0 1 1 1 0 1 1 0 1 1 0 1 1 0 1\n",
            " 1 0 1 1 1 1 0 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 0 0 1 0 0 0 0 0 1 1 1 1 0 1\n",
            " 1 0 0 1 1 1 0 1 1 1 0 1 1 0 1 1 1 0 1 0 1 0 0 0 1 1 0 1 1 0 1 1 1 0 1 1 0\n",
            " 1 0 0 0 0 1 1 1 1 0 1 1 1 1 0 0 1 1 0 1 0 0 1 0 0 0 0 1 1 1 1 1 1 1 0 1 1\n",
            " 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 0 1 0 0 0 1 0 0 1 0 1 1 0 0 1 0 1 0 0 1 1 0\n",
            " 0 1 1 1 0 0 0 1 0 1 1 1 1 0 1 1 0 0 1 1 1 1 1 1 0 1 1 1 0 1 1 1 0 1 0 1 1\n",
            " 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 0 0 1 1 0 0 0 0 1 1 0 0 0 1 0 0 1 0 1 1 1 1\n",
            " 1 0 0 1 1 0 1 1 0 0 1 1 1 0 1 0 0 1 1 0 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 0 0 0 0 1 1 1 1 0]\n",
            "trainset before adding uncertain samples (360, 10) (360,)\n",
            "trainset after adding uncertain samples (370, 10) (370,)\n",
            "updated train set: (370, 10) (370,) unique(labels): [ 63 307] [0 1]\n",
            "val set: (932, 10) (932,)\n",
            "\n",
            "Train set: (370, 10)\n",
            "Validation set: (932, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 37\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.068 s \n",
            "\n",
            "Accuracy rate is 56.682028 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.53      0.65       321\n",
            "           1       0.33      0.66      0.44       113\n",
            "\n",
            "    accuracy                           0.57       434\n",
            "   macro avg       0.58      0.60      0.54       434\n",
            "weighted avg       0.69      0.57      0.59       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[171 150]\n",
            " [ 38  75]]\n",
            "--------------------------------\n",
            "val predicted: (932,) [1 1 0 0 1 1 0 1 1 0 1 1 0 1 1 0 0 1 0 1 1 1 0 1 0 1 1 0 1 1 1 1 1 1 1 0 0\n",
            " 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 0 1 0 0 1 1 0 0 0 1 1 0 1 0\n",
            " 0 1 1 0 1 1 0 0 1 1 1 1 0 1 0 0 1 1 1 1 1 0 0 1 0 1 0 1 0 1 1 0 0 1 1 1 0\n",
            " 1 1 0 1 1 1 1 1 1 1 1 0 1 0 1 0 1 0 0 1 1 1 1 1 0 0 0 1 0 1 1 1 1 0 1 0 1\n",
            " 0 0 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 0 0 1 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 1\n",
            " 1 1 1 1 0 1 1 0 0 1 0 1 1 1 1 1 1 0 1 0 0 0 0 1 1 1 1 1 1 0 1 1 1 0 0 1 1\n",
            " 1 0 1 1 0 1 1 1 0 0 0 0 1 0 1 0 1 1 0 1 1 1 0 0 1 0 0 0 1 0 1 1 1 1 1 1 1\n",
            " 1 1 0 0 0 0 1 0 0 0 1 1 1 1 1 1 1 0 1 0 1 0 0 1 1 0 0 0 1 0 1 0 1 1 1 0 0\n",
            " 0 0 1 1 0 1 1 1 1 1 0 1 1 0 1 1 0 1 0 0 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1\n",
            " 1 1 1 1 0 1 0 1 1 1 1 1 0 1 0 1 1 0 1 0 1 0 1 1 1 0 0 1 1 1 0 1 0 1 1 1 1\n",
            " 1 1 0 0 1 1 1 1 1 1 1 0 1 1 1 1 0 1 0 0 1 0 0 1 1 0 0 1 1 0 1 1 0 0 0 1 1\n",
            " 1 0 1 1 0 1 1 0 1 1 1 1 0 0 1 1 1 1 0 1 1 1 1 1 0 0 1 0 0 0 1 1 1 1 0 0 0\n",
            " 1 1 1 1 1 0 1 1 1 1 1 0 0 1 1 0 1 0 1 0 1 1 1 0 1 1 1 1 1 1 0 1 0 1 0 1 1\n",
            " 0 1 1 0 1 1 1 1 1 1 0 0 1 1 1 1 0 0 1 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1\n",
            " 1 0 1 1 0 0 1 1 1 1 1 0 1 1 0 1 1 0 0 1 0 0 0 1 1 1 1 1 0 1 0 1 0 1 0 0 0\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 0 1 0 0 1 1 0 1\n",
            " 1 0 1 0 0 1 0 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 0 0 1 0 0 1 1 1 1 1 0 0 0 1 0\n",
            " 1 1 0 1 0 1 1 1 1 1 1 0 1 0 1 0 1 1 1 0 0 1 0 1 1 0 1 1 0 1 0 0 1 1 1 0 0\n",
            " 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 0 0 1 1 0 0 0 0 1 1 1 1 0 1 1 0 0 1 1 0 0\n",
            " 1 1 1 0 1 1 0 1 0 1 0 1 1 0 0 0 0 1 1 0 0 1 0 1 1 1 0 1 1 0 1 0 0 0 0 1 1\n",
            " 1 0 0 1 1 1 1 0 0 1 1 1 1 0 0 1 0 0 0 0 0 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0\n",
            " 1 1 1 1 0 1 1 0 1 0 0 1 0 0 0 1 0 1 1 1 0 0 1 0 0 1 0 0 0 1 1 0 0 0 0 1 0\n",
            " 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 0 1 0 1 0 1 0 1 1 1 1 1 0 0 1 1 1 1\n",
            " 1 1 1 1 1 1 0 0 1 1 0 0 0 0 1 1 0 0 1 1 0 0 1 0 1 1 0 1 1 0 0 1 1 0 1 1 0\n",
            " 0 1 1 1 0 1 0 0 1 1 0 1 0 1 1 0 0 0 1 0 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 0 0\n",
            " 1 0 0 1 1 1 0]\n",
            "probabilities: (932, 2) \n",
            " [1 1 0 0 1 1 0 1 1 0 1 1 0 1 1 0 0 1 0 1 1 1 0 1 0 1 1 0 1 1 1 1 1 1 1 0 0\n",
            " 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 0 1 0 0 1 1 0 0 0 1 1 0 1 0\n",
            " 0 1 1 0 1 1 0 0 1 1 1 1 0 1 0 0 1 1 1 1 1 0 0 1 0 1 0 1 0 1 1 0 0 1 1 1 0\n",
            " 1 1 0 1 1 1 1 1 1 1 1 0 1 0 1 0 1 0 0 1 1 1 1 1 0 0 0 1 0 1 1 1 1 0 1 0 1\n",
            " 0 0 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 0 0 1 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 1\n",
            " 1 1 1 1 0 1 1 0 0 1 0 1 1 1 1 1 1 0 1 0 0 0 0 1 1 1 1 1 1 0 1 1 1 0 0 1 1\n",
            " 1 0 1 1 0 1 1 1 0 0 0 0 1 0 1 0 1 1 0 1 1 1 0 0 1 0 0 0 1 0 1 1 1 1 1 1 1\n",
            " 1 1 0 0 0 0 1 0 0 0 1 1 1 1 1 1 1 0 1 0 1 0 0 1 1 0 0 0 1 0 1 0 1 1 1 0 0\n",
            " 0 0 1 1 0 1 1 1 1 1 0 1 1 0 1 1 0 1 0 0 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1\n",
            " 1 1 1 1 0 1 0 1 1 1 1 1 0 1 0 1 1 0 1 0 1 0 1 1 1 0 0 1 1 1 0 1 0 1 1 1 1\n",
            " 1 1 0 0 1 1 1 1 1 1 1 0 1 1 1 1 0 1 0 0 1 0 0 1 1 0 0 1 1 0 1 1 0 0 0 1 1\n",
            " 1 0 1 1 0 1 1 0 1 1 1 1 0 0 1 1 1 1 0 1 1 1 1 1 0 0 1 0 0 0 1 1 1 1 0 0 0\n",
            " 1 1 1 1 1 0 1 1 1 1 1 0 0 1 1 0 1 0 1 0 1 1 1 0 1 1 1 1 1 1 0 1 0 1 0 1 1\n",
            " 0 1 1 0 1 1 1 1 1 1 0 0 1 1 1 1 0 0 1 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1\n",
            " 1 0 1 1 0 0 1 1 1 1 1 0 1 1 0 1 1 0 0 1 0 0 0 1 1 1 1 1 0 1 0 1 0 1 0 0 0\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 0 1 0 0 1 1 0 1\n",
            " 1 0 1 0 0 1 0 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 0 0 1 0 0 1 1 1 1 1 0 0 0 1 0\n",
            " 1 1 0 1 0 1 1 1 1 1 1 0 1 0 1 0 1 1 1 0 0 1 0 1 1 0 1 1 0 1 0 0 1 1 1 0 0\n",
            " 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 0 0 1 1 0 0 0 0 1 1 1 1 0 1 1 0 0 1 1 0 0\n",
            " 1 1 1 0 1 1 0 1 0 1 0 1 1 0 0 0 0 1 1 0 0 1 0 1 1 1 0 1 1 0 1 0 0 0 0 1 1\n",
            " 1 0 0 1 1 1 1 0 0 1 1 1 1 0 0 1 0 0 0 0 0 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0\n",
            " 1 1 1 1 0 1 1 0 1 0 0 1 0 0 0 1 0 1 1 1 0 0 1 0 0 1 0 0 0 1 1 0 0 0 0 1 0\n",
            " 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 0 1 0 1 0 1 0 1 1 1 1 1 0 0 1 1 1 1\n",
            " 1 1 1 1 1 1 0 0 1 1 0 0 0 0 1 1 0 0 1 1 0 0 1 0 1 1 0 1 1 0 0 1 1 0 1 1 0\n",
            " 0 1 1 1 0 1 0 0 1 1 0 1 0 1 1 0 0 0 1 0 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 0 0\n",
            " 1 0 0 1 1 1 0]\n",
            "trainset before adding uncertain samples (370, 10) (370,)\n",
            "trainset after adding uncertain samples (380, 10) (380,)\n",
            "updated train set: (380, 10) (380,) unique(labels): [ 67 313] [0 1]\n",
            "val set: (922, 10) (922,)\n",
            "\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: divide by zero encountered in log2\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: invalid value encountered in multiply\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: divide by zero encountered in log2\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: invalid value encountered in multiply\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: divide by zero encountered in log2\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: invalid value encountered in multiply\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "Train set: (380, 10)\n",
            "Validation set: (922, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 38\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.064 s \n",
            "\n",
            "Accuracy rate is 54.608295 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.50      0.62       321\n",
            "           1       0.32      0.67      0.44       113\n",
            "\n",
            "    accuracy                           0.55       434\n",
            "   macro avg       0.57      0.59      0.53       434\n",
            "weighted avg       0.69      0.55      0.57       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[161 160]\n",
            " [ 37  76]]\n",
            "--------------------------------\n",
            "val predicted: (922,) [1 1 0 0 1 1 0 1 1 0 1 1 0 1 1 0 0 1 1 1 1 1 0 1 0 1 1 0 1 1 1 1 1 1 1 0 0\n",
            " 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 0\n",
            " 0 1 1 0 1 0 1 0 1 1 1 1 0 1 0 0 1 1 1 1 1 0 0 1 1 1 0 1 0 0 1 0 1 1 1 1 0\n",
            " 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 0 0 0 1 0 1 1 1 1 0 1 0 1 0 1\n",
            " 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1\n",
            " 1 0 1 1 0 0 1 0 1 1 1 1 1 1 0 1 0 0 0 0 1 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 1\n",
            " 1 0 1 1 1 0 0 0 0 1 0 1 0 1 1 0 0 1 1 0 0 1 0 0 0 1 0 1 1 1 0 1 1 1 1 1 0\n",
            " 0 0 0 1 0 0 0 1 1 1 1 1 0 1 0 1 0 0 0 0 1 1 0 0 1 1 0 1 0 1 1 1 0 0 0 1 1\n",
            " 1 0 1 1 1 0 1 0 1 0 0 1 1 0 1 0 0 1 1 1 1 1 1 1 1 0 1 0 0 1 0 1 1 1 1 1 0\n",
            " 1 0 1 0 1 1 1 1 1 0 1 0 1 1 0 0 0 1 0 1 1 1 0 0 1 1 1 0 1 0 1 1 1 1 1 1 1\n",
            " 0 1 0 1 1 1 1 1 0 1 1 1 1 0 1 0 0 1 0 0 1 1 0 0 1 1 1 1 1 0 0 0 1 1 1 0 1\n",
            " 1 0 1 1 0 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 0 0 1 0 0 0 1 1 1 1 0 0 0 1 1 1\n",
            " 1 1 0 0 0 1 1 1 0 0 1 1 0 1 0 1 0 1 1 1 0 1 1 1 0 1 1 0 1 1 1 0 1 1 1 1 0\n",
            " 1 1 1 1 1 1 1 0 1 1 1 0 0 0 1 0 1 1 1 1 0 1 0 1 1 0 1 1 0 1 0 0 1 1 0 1 1\n",
            " 0 0 1 1 1 1 1 0 1 1 0 1 1 0 0 1 0 0 0 0 1 1 1 1 0 1 0 1 0 1 0 0 1 1 1 1 1\n",
            " 0 1 1 1 1 1 0 1 1 1 1 0 1 0 0 0 0 1 0 0 1 0 0 1 1 0 1 0 0 1 1 0 1 1 1 0 1\n",
            " 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 0 1 1 1 1 1 1 0 0 0 0 0 1 1 1 0 1 1 1\n",
            " 0 1 1 1 0 1 0 1 0 1 1 1 0 0 1 0 1 1 1 1 1 0 1 0 0 1 1 1 0 1 1 1 1 1 0 1 0\n",
            " 0 1 1 0 1 1 1 1 1 0 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1 0 1 1 0 0 1 1 1 0 1 1 0\n",
            " 1 0 1 0 1 1 0 0 0 0 1 1 0 0 0 0 1 1 1 0 1 1 0 1 0 0 0 0 1 1 1 0 0 1 1 1 1\n",
            " 0 0 1 1 1 1 0 0 1 0 0 0 0 0 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 1\n",
            " 0 0 0 0 0 0 0 0 1 0 1 1 1 1 0 0 1 0 0 1 1 0 0 0 0 1 0 1 1 1 1 1 1 1 0 0 1\n",
            " 1 1 1 1 1 0 1 1 1 0 1 0 1 0 1 0 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 0 0 1 1\n",
            " 0 1 0 0 1 1 0 0 1 1 0 0 1 0 1 1 1 1 1 0 0 1 1 0 1 1 0 0 0 1 1 0 1 0 0 1 1\n",
            " 0 1 0 1 1 0 0 1 1 0 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 0 0 1 0 0 1 1 1 0]\n",
            "probabilities: (922, 2) \n",
            " [1 1 0 0 1 1 0 1 1 0 1 1 0 1 1 0 0 1 1 1 1 1 0 1 0 1 1 0 1 1 1 1 1 1 1 0 0\n",
            " 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 0\n",
            " 0 1 1 0 1 0 1 0 1 1 1 1 0 1 0 0 1 1 1 1 1 0 0 1 1 1 0 1 0 0 1 0 1 1 1 1 0\n",
            " 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 0 0 0 1 0 1 1 1 1 0 1 0 1 0 1\n",
            " 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1\n",
            " 1 0 1 1 0 0 1 0 1 1 1 1 1 1 0 1 0 0 0 0 1 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 1\n",
            " 1 0 1 1 1 0 0 0 0 1 0 1 0 1 1 0 0 1 1 0 0 1 0 0 0 1 0 1 1 1 0 1 1 1 1 1 0\n",
            " 0 0 0 1 0 0 0 1 1 1 1 1 0 1 0 1 0 0 0 0 1 1 0 0 1 1 0 1 0 1 1 1 0 0 0 1 1\n",
            " 1 0 1 1 1 0 1 0 1 0 0 1 1 0 1 0 0 1 1 1 1 1 1 1 1 0 1 0 0 1 0 1 1 1 1 1 0\n",
            " 1 0 1 0 1 1 1 1 1 0 1 0 1 1 0 0 0 1 0 1 1 1 0 0 1 1 1 0 1 0 1 1 1 1 1 1 1\n",
            " 0 1 0 1 1 1 1 1 0 1 1 1 1 0 1 0 0 1 0 0 1 1 0 0 1 1 1 1 1 0 0 0 1 1 1 0 1\n",
            " 1 0 1 1 0 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 0 0 1 0 0 0 1 1 1 1 0 0 0 1 1 1\n",
            " 1 1 0 0 0 1 1 1 0 0 1 1 0 1 0 1 0 1 1 1 0 1 1 1 0 1 1 0 1 1 1 0 1 1 1 1 0\n",
            " 1 1 1 1 1 1 1 0 1 1 1 0 0 0 1 0 1 1 1 1 0 1 0 1 1 0 1 1 0 1 0 0 1 1 0 1 1\n",
            " 0 0 1 1 1 1 1 0 1 1 0 1 1 0 0 1 0 0 0 0 1 1 1 1 0 1 0 1 0 1 0 0 1 1 1 1 1\n",
            " 0 1 1 1 1 1 0 1 1 1 1 0 1 0 0 0 0 1 0 0 1 0 0 1 1 0 1 0 0 1 1 0 1 1 1 0 1\n",
            " 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 0 1 1 1 1 1 1 0 0 0 0 0 1 1 1 0 1 1 1\n",
            " 0 1 1 1 0 1 0 1 0 1 1 1 0 0 1 0 1 1 1 1 1 0 1 0 0 1 1 1 0 1 1 1 1 1 0 1 0\n",
            " 0 1 1 0 1 1 1 1 1 0 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1 0 1 1 0 0 1 1 1 0 1 1 0\n",
            " 1 0 1 0 1 1 0 0 0 0 1 1 0 0 0 0 1 1 1 0 1 1 0 1 0 0 0 0 1 1 1 0 0 1 1 1 1\n",
            " 0 0 1 1 1 1 0 0 1 0 0 0 0 0 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 1\n",
            " 0 0 0 0 0 0 0 0 1 0 1 1 1 1 0 0 1 0 0 1 1 0 0 0 0 1 0 1 1 1 1 1 1 1 0 0 1\n",
            " 1 1 1 1 1 0 1 1 1 0 1 0 1 0 1 0 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 0 0 1 1\n",
            " 0 1 0 0 1 1 0 0 1 1 0 0 1 0 1 1 1 1 1 0 0 1 1 0 1 1 0 0 0 1 1 0 1 0 0 1 1\n",
            " 0 1 0 1 1 0 0 1 1 0 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 0 0 1 0 0 1 1 1 0]\n",
            "trainset before adding uncertain samples (380, 10) (380,)\n",
            "trainset after adding uncertain samples (390, 10) (390,)\n",
            "updated train set: (390, 10) (390,) unique(labels): [ 72 318] [0 1]\n",
            "val set: (912, 10) (912,)\n",
            "\n",
            "Train set: (390, 10)\n",
            "Validation set: (912, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 39\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.067 s \n",
            "\n",
            "Accuracy rate is 59.447005 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.58      0.68       321\n",
            "           1       0.35      0.65      0.45       113\n",
            "\n",
            "    accuracy                           0.59       434\n",
            "   macro avg       0.59      0.61      0.57       434\n",
            "weighted avg       0.70      0.59      0.62       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[185 136]\n",
            " [ 40  73]]\n",
            "--------------------------------\n",
            "val predicted: (912,) [1 1 0 0 1 1 0 1 1 0 1 1 0 1 1 0 0 1 1 1 1 1 0 1 0 1 1 0 0 1 1 1 1 1 1 0 0\n",
            " 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 0\n",
            " 0 1 1 0 1 0 1 0 1 1 1 1 0 1 0 1 1 1 1 1 0 0 1 0 1 0 1 0 0 1 0 0 1 1 1 0 1\n",
            " 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 0 1 1 0 1 1 0 0 0 1 0 1 1 1 1 0 1 0 1 0 0 1\n",
            " 1 1 0 1 1 1 1 1 1 0 0 1 1 0 1 0 0 1 1 1 1 1 0 0 1 0 1 1 1 0 1 1 1 1 1 0 1\n",
            " 0 1 1 0 0 1 0 1 1 1 1 1 1 0 1 0 0 0 0 1 1 1 1 1 1 0 0 1 1 0 0 1 1 1 0 1 1\n",
            " 0 1 1 1 0 0 0 0 1 0 1 0 1 1 0 0 1 1 0 0 1 0 0 0 0 0 1 1 1 0 0 1 1 1 1 0 0\n",
            " 0 0 1 0 0 0 1 1 1 1 1 0 1 0 1 0 0 0 0 1 1 0 0 1 1 0 1 0 1 1 1 0 0 0 1 1 1\n",
            " 0 1 1 1 0 1 0 1 0 0 1 1 0 1 0 0 1 1 1 0 1 1 1 1 0 1 0 0 1 0 1 1 1 1 1 0 1\n",
            " 0 1 0 1 1 1 1 0 1 0 0 1 0 0 0 1 0 1 1 1 0 0 1 1 1 0 1 0 1 1 1 1 1 1 1 0 1\n",
            " 0 1 1 1 1 1 0 1 1 0 0 1 0 0 1 0 0 1 1 0 0 1 1 1 1 1 0 0 0 1 0 1 0 0 1 0 1\n",
            " 1 0 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 0 0 1 0 0 0 1 1 1 1 0 0 0 1 1 1 1 1 0\n",
            " 1 1 1 0 0 1 1 0 1 0 1 0 1 1 1 0 1 1 1 0 1 1 0 1 0 1 0 1 0 1 1 0 1 1 1 1 1\n",
            " 1 0 1 1 1 0 0 0 1 0 1 1 1 1 0 1 0 1 1 0 1 1 0 1 0 0 1 1 0 1 1 0 0 1 1 1 1\n",
            " 0 1 1 0 1 1 0 0 1 0 0 0 0 1 1 1 1 0 1 0 1 0 1 0 0 1 0 1 1 1 0 1 1 0 0 1 1\n",
            " 1 0 1 0 1 0 0 0 0 1 0 0 1 0 0 1 1 0 1 0 0 1 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1\n",
            " 1 1 1 1 0 1 1 0 0 1 0 0 1 1 1 1 1 0 0 0 0 0 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1\n",
            " 0 1 1 0 0 0 1 0 1 1 1 1 1 0 1 0 0 1 1 1 0 0 0 1 0 1 0 1 0 0 1 1 0 1 1 1 1\n",
            " 0 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1 1 1 1 0 0 1 0 1 0 1 1 0 1 0 1 0 1 1 0 0 0\n",
            " 0 1 1 0 0 0 1 1 1 0 1 1 0 1 0 0 0 0 1 1 1 0 0 1 1 0 1 0 0 1 1 0 1 0 0 1 0\n",
            " 0 0 0 0 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 0 0 0 0 0 0 0 0 1 0\n",
            " 1 1 0 1 0 0 1 0 0 1 1 0 0 0 0 1 0 1 1 1 1 0 0 1 0 0 1 1 1 1 1 0 0 1 1 1 0\n",
            " 1 0 1 0 1 0 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 0 1 0 0 1 1 0 0 0 0 1 1 0 0 1 1\n",
            " 0 0 1 0 1 1 1 1 1 0 0 1 1 0 1 1 0 0 1 1 0 0 1 0 0 1 1 0 1 0 1 1 0 0 0 1 0\n",
            " 1 1 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 0 1 1 1 0]\n",
            "probabilities: (912, 2) \n",
            " [1 1 0 0 1 1 0 1 1 0 1 1 0 1 1 0 0 1 1 1 1 1 0 1 0 1 1 0 0 1 1 1 1 1 1 0 0\n",
            " 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 0\n",
            " 0 1 1 0 1 0 1 0 1 1 1 1 0 1 0 1 1 1 1 1 0 0 1 0 1 0 1 0 0 1 0 0 1 1 1 0 1\n",
            " 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 0 1 1 0 1 1 0 0 0 1 0 1 1 1 1 0 1 0 1 0 0 1\n",
            " 1 1 0 1 1 1 1 1 1 0 0 1 1 0 1 0 0 1 1 1 1 1 0 0 1 0 1 1 1 0 1 1 1 1 1 0 1\n",
            " 0 1 1 0 0 1 0 1 1 1 1 1 1 0 1 0 0 0 0 1 1 1 1 1 1 0 0 1 1 0 0 1 1 1 0 1 1\n",
            " 0 1 1 1 0 0 0 0 1 0 1 0 1 1 0 0 1 1 0 0 1 0 0 0 0 0 1 1 1 0 0 1 1 1 1 0 0\n",
            " 0 0 1 0 0 0 1 1 1 1 1 0 1 0 1 0 0 0 0 1 1 0 0 1 1 0 1 0 1 1 1 0 0 0 1 1 1\n",
            " 0 1 1 1 0 1 0 1 0 0 1 1 0 1 0 0 1 1 1 0 1 1 1 1 0 1 0 0 1 0 1 1 1 1 1 0 1\n",
            " 0 1 0 1 1 1 1 0 1 0 0 1 0 0 0 1 0 1 1 1 0 0 1 1 1 0 1 0 1 1 1 1 1 1 1 0 1\n",
            " 0 1 1 1 1 1 0 1 1 0 0 1 0 0 1 0 0 1 1 0 0 1 1 1 1 1 0 0 0 1 0 1 0 0 1 0 1\n",
            " 1 0 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 0 0 1 0 0 0 1 1 1 1 0 0 0 1 1 1 1 1 0\n",
            " 1 1 1 0 0 1 1 0 1 0 1 0 1 1 1 0 1 1 1 0 1 1 0 1 0 1 0 1 0 1 1 0 1 1 1 1 1\n",
            " 1 0 1 1 1 0 0 0 1 0 1 1 1 1 0 1 0 1 1 0 1 1 0 1 0 0 1 1 0 1 1 0 0 1 1 1 1\n",
            " 0 1 1 0 1 1 0 0 1 0 0 0 0 1 1 1 1 0 1 0 1 0 1 0 0 1 0 1 1 1 0 1 1 0 0 1 1\n",
            " 1 0 1 0 1 0 0 0 0 1 0 0 1 0 0 1 1 0 1 0 0 1 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1\n",
            " 1 1 1 1 0 1 1 0 0 1 0 0 1 1 1 1 1 0 0 0 0 0 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1\n",
            " 0 1 1 0 0 0 1 0 1 1 1 1 1 0 1 0 0 1 1 1 0 0 0 1 0 1 0 1 0 0 1 1 0 1 1 1 1\n",
            " 0 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1 1 1 1 0 0 1 0 1 0 1 1 0 1 0 1 0 1 1 0 0 0\n",
            " 0 1 1 0 0 0 1 1 1 0 1 1 0 1 0 0 0 0 1 1 1 0 0 1 1 0 1 0 0 1 1 0 1 0 0 1 0\n",
            " 0 0 0 0 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 0 0 0 0 0 0 0 0 1 0\n",
            " 1 1 0 1 0 0 1 0 0 1 1 0 0 0 0 1 0 1 1 1 1 0 0 1 0 0 1 1 1 1 1 0 0 1 1 1 0\n",
            " 1 0 1 0 1 0 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 0 1 0 0 1 1 0 0 0 0 1 1 0 0 1 1\n",
            " 0 0 1 0 1 1 1 1 1 0 0 1 1 0 1 1 0 0 1 1 0 0 1 0 0 1 1 0 1 0 1 1 0 0 0 1 0\n",
            " 1 1 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 0 1 1 1 0]\n",
            "trainset before adding uncertain samples (390, 10) (390,)\n",
            "trainset after adding uncertain samples (400, 10) (400,)\n",
            "updated train set: (400, 10) (400,) unique(labels): [ 78 322] [0 1]\n",
            "val set: (902, 10) (902,)\n",
            "\n",
            "Train set: (400, 10)\n",
            "Validation set: (902, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: divide by zero encountered in log2\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: invalid value encountered in multiply\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "--------------------------------\n",
            "Iteration: 40\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.074 s \n",
            "\n",
            "Accuracy rate is 73.271889 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.80      0.82       321\n",
            "           1       0.49      0.54      0.51       113\n",
            "\n",
            "    accuracy                           0.73       434\n",
            "   macro avg       0.66      0.67      0.66       434\n",
            "weighted avg       0.74      0.73      0.74       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[257  64]\n",
            " [ 52  61]]\n",
            "--------------------------------\n",
            "val predicted: (902,) [1 1 0 0 1 1 0 1 1 0 0 1 0 1 1 0 0 1 0 1 0 0 0 1 0 1 1 0 0 1 1 0 1 1 1 0 1\n",
            " 0 0 1 0 0 1 0 1 1 0 0 1 1 1 1 1 0 0 1 0 1 0 0 1 0 0 1 1 0 0 0 1 0 0 1 0 0\n",
            " 1 0 0 1 1 0 1 1 1 1 0 1 0 0 1 1 1 0 0 0 0 0 1 0 1 0 0 1 0 0 1 1 1 0 0 0 0\n",
            " 0 1 0 1 1 0 0 0 1 0 1 0 0 1 0 0 0 1 0 0 0 1 0 1 1 1 1 0 1 0 1 0 0 1 1 0 1\n",
            " 1 1 0 1 0 0 0 0 0 0 1 0 0 0 1 1 1 1 0 0 1 0 0 1 1 0 1 1 1 1 0 0 1 0 1 0 0\n",
            " 0 1 0 1 1 1 1 0 1 0 1 0 0 0 0 1 1 1 1 1 0 0 0 0 1 0 0 1 0 1 0 0 1 0 0 1 1\n",
            " 0 0 0 0 1 0 1 0 1 1 0 1 0 1 0 0 1 0 0 0 0 0 1 1 1 0 0 1 1 1 1 0 0 0 0 1 0\n",
            " 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 1 0 0 0 0 0 1 0 1 1 1 0 0\n",
            " 0 1 0 0 1 1 1 1 0 0 1 1 1 0 1 0 1 1 0 1 0 0 1 0 1 1 0 1 1 0 1 0 1 0 1 1 1\n",
            " 1 0 1 0 0 1 0 0 0 0 0 1 1 1 0 0 1 0 0 0 1 0 0 1 1 1 0 1 0 0 0 0 1 1 1 1 1\n",
            " 0 1 0 0 0 1 0 0 1 0 0 0 1 0 0 0 1 1 0 1 0 0 0 1 0 1 0 0 1 0 1 1 0 1 1 1 1\n",
            " 0 0 1 0 1 1 0 1 0 1 1 1 0 0 1 0 0 0 1 1 1 1 0 0 0 1 1 1 1 1 0 0 1 0 0 0 1\n",
            " 1 0 0 0 0 0 1 0 1 0 0 0 0 0 1 1 0 1 0 1 0 1 1 1 1 1 1 0 1 1 0 0 1 1 1 0 0\n",
            " 0 1 0 0 0 1 0 0 1 0 0 0 0 0 1 0 1 0 0 1 1 0 1 1 0 0 1 1 1 1 0 1 1 0 1 1 0\n",
            " 0 0 0 0 0 0 1 1 1 0 0 0 0 1 0 1 0 0 0 0 1 1 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0\n",
            " 0 0 1 0 0 1 0 0 1 1 0 1 0 0 1 1 0 0 1 1 0 1 0 1 1 1 0 1 1 1 1 1 1 1 0 1 1\n",
            " 0 0 1 0 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 1 0 0 0 1 1 0 0 0 1\n",
            " 0 0 1 0 0 1 0 1 0 0 1 1 1 0 0 0 0 1 0 1 0 0 1 1 0 1 1 1 1 0 0 1 0 0 0 0 0\n",
            " 1 1 1 0 0 1 1 0 0 0 1 0 0 1 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0\n",
            " 1 0 1 1 0 1 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 1 1 0 1 0 0 0 0 0 0 0 0 1 1 1 1\n",
            " 1 0 1 1 0 1 1 1 1 1 0 1 1 1 1 0 0 1 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 1 0 0\n",
            " 1 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 1 1 1 0 1 0 0 1 1 1 0 1 1 0 1 0 1 1 0 1\n",
            " 1 0 0 1 1 1 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 1 1 1 1 1 0\n",
            " 0 1 1 0 1 1 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 1 0 1 1 1 0 1 0 0 1 1 1\n",
            " 0 0 0 1 1 0 0 0 0 0 1 1 0 0]\n",
            "probabilities: (902, 2) \n",
            " [1 1 0 0 1 1 0 1 1 0 0 1 0 1 1 0 0 1 0 1 0 0 0 1 0 1 1 0 0 1 1 0 1 1 1 0 1\n",
            " 0 0 1 0 0 1 0 1 1 0 0 1 1 1 1 1 0 0 1 0 1 0 0 1 0 0 1 1 0 0 0 1 0 0 1 0 0\n",
            " 1 0 0 1 1 0 1 1 1 1 0 1 0 0 1 1 1 0 0 0 0 0 1 0 1 0 0 1 0 0 1 1 1 0 0 0 0\n",
            " 0 1 0 1 1 0 0 0 1 0 1 0 0 1 0 0 0 1 0 0 0 1 0 1 1 1 1 0 1 0 1 0 0 1 1 0 1\n",
            " 1 1 0 1 0 0 0 0 0 0 1 0 0 0 1 1 1 1 0 0 1 0 0 1 1 0 1 1 1 1 0 0 1 0 1 0 0\n",
            " 0 1 0 1 1 1 1 0 1 0 1 0 0 0 0 1 1 1 1 1 0 0 0 0 1 0 0 1 0 1 0 0 1 0 0 1 1\n",
            " 0 0 0 0 1 0 1 0 1 1 0 1 0 1 0 0 1 0 0 0 0 0 1 1 1 0 0 1 1 1 1 0 0 0 0 1 0\n",
            " 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 1 0 0 0 0 0 1 0 1 1 1 0 0\n",
            " 0 1 0 0 1 1 1 1 0 0 1 1 1 0 1 0 1 1 0 1 0 0 1 0 1 1 0 1 1 0 1 0 1 0 1 1 1\n",
            " 1 0 1 0 0 1 0 0 0 0 0 1 1 1 0 0 1 0 0 0 1 0 0 1 1 1 0 1 0 0 0 0 1 1 1 1 1\n",
            " 0 1 0 0 0 1 0 0 1 0 0 0 1 0 0 0 1 1 0 1 0 0 0 1 0 1 0 0 1 0 1 1 0 1 1 1 1\n",
            " 0 0 1 0 1 1 0 1 0 1 1 1 0 0 1 0 0 0 1 1 1 1 0 0 0 1 1 1 1 1 0 0 1 0 0 0 1\n",
            " 1 0 0 0 0 0 1 0 1 0 0 0 0 0 1 1 0 1 0 1 0 1 1 1 1 1 1 0 1 1 0 0 1 1 1 0 0\n",
            " 0 1 0 0 0 1 0 0 1 0 0 0 0 0 1 0 1 0 0 1 1 0 1 1 0 0 1 1 1 1 0 1 1 0 1 1 0\n",
            " 0 0 0 0 0 0 1 1 1 0 0 0 0 1 0 1 0 0 0 0 1 1 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0\n",
            " 0 0 1 0 0 1 0 0 1 1 0 1 0 0 1 1 0 0 1 1 0 1 0 1 1 1 0 1 1 1 1 1 1 1 0 1 1\n",
            " 0 0 1 0 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 1 0 0 0 1 1 0 0 0 1\n",
            " 0 0 1 0 0 1 0 1 0 0 1 1 1 0 0 0 0 1 0 1 0 0 1 1 0 1 1 1 1 0 0 1 0 0 0 0 0\n",
            " 1 1 1 0 0 1 1 0 0 0 1 0 0 1 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0\n",
            " 1 0 1 1 0 1 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 1 1 0 1 0 0 0 0 0 0 0 0 1 1 1 1\n",
            " 1 0 1 1 0 1 1 1 1 1 0 1 1 1 1 0 0 1 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 1 0 0\n",
            " 1 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 1 1 1 0 1 0 0 1 1 1 0 1 1 0 1 0 1 1 0 1\n",
            " 1 0 0 1 1 1 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 1 1 1 1 1 0\n",
            " 0 1 1 0 1 1 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 1 0 1 1 1 0 1 0 0 1 1 1\n",
            " 0 0 0 1 1 0 0 0 0 0 1 1 0 0]\n",
            "trainset before adding uncertain samples (400, 10) (400,)\n",
            "trainset after adding uncertain samples (410, 10) (410,)\n",
            "updated train set: (410, 10) (410,) unique(labels): [ 83 327] [0 1]\n",
            "val set: (892, 10) (892,)\n",
            "\n",
            "Train set: (410, 10)\n",
            "Validation set: (892, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 41\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.063 s \n",
            "\n",
            "Accuracy rate is 76.728111 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.85      0.84       321\n",
            "           1       0.56      0.52      0.54       113\n",
            "\n",
            "    accuracy                           0.77       434\n",
            "   macro avg       0.70      0.69      0.69       434\n",
            "weighted avg       0.76      0.77      0.76       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[274  47]\n",
            " [ 54  59]]\n",
            "--------------------------------\n",
            "val predicted: (892,) [1 1 0 0 1 1 0 1 1 0 0 1 0 1 1 0 0 1 0 1 0 0 0 1 0 1 1 0 0 1 1 1 1 0 0 1 0\n",
            " 0 0 0 0 1 0 1 1 0 0 1 1 1 1 1 0 0 1 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 1\n",
            " 0 0 0 1 0 0 1 1 1 0 1 0 1 1 0 0 0 0 0 0 1 0 1 0 0 1 0 0 1 1 1 0 0 0 0 0 1\n",
            " 0 1 1 0 0 0 1 0 1 0 1 1 0 0 0 1 0 0 0 1 0 1 1 1 1 0 1 0 1 0 0 1 1 0 1 1 1\n",
            " 0 1 0 0 0 0 0 0 1 0 0 0 1 1 1 1 0 0 1 0 0 1 1 0 1 1 1 1 0 0 1 0 1 0 0 0 1\n",
            " 0 0 1 1 1 0 1 0 1 0 0 0 0 1 1 1 0 1 0 0 1 0 1 0 0 1 0 1 0 0 1 0 0 0 1 0 0\n",
            " 0 0 1 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 1 1 1 0 0 1 1 1 1 0 0 0 0 1 0 0 1\n",
            " 1 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 1 1 1 0 0 0 1 0\n",
            " 0 1 1 0 1 0 0 1 1 1 0 1 0 1 1 0 1 0 0 1 0 0 1 0 1 1 0 1 0 1 0 1 1 1 1 0 1\n",
            " 0 0 1 0 0 0 0 0 1 1 1 0 0 1 0 0 0 1 0 0 0 1 1 0 1 0 0 0 0 1 1 1 1 1 0 0 0\n",
            " 0 1 0 0 1 0 0 1 0 0 0 1 0 0 1 0 0 1 1 0 1 0 0 0 0 0 1 0 1 1 1 1 0 0 1 0 1\n",
            " 1 0 1 0 1 1 1 0 0 1 0 0 0 1 1 0 1 0 0 0 0 1 1 1 1 0 0 1 0 0 0 1 1 0 0 0 1\n",
            " 0 1 0 1 0 0 0 0 0 1 1 0 1 0 0 0 1 1 1 0 1 1 0 1 1 0 0 1 1 1 0 0 0 1 0 0 0\n",
            " 1 0 0 0 0 0 0 0 0 1 0 1 0 0 1 1 0 1 1 0 0 1 1 1 1 0 1 1 0 1 1 0 0 0 0 0 0\n",
            " 1 1 1 0 0 0 1 0 1 0 0 0 0 1 1 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0\n",
            " 0 0 1 0 1 1 0 0 1 0 0 1 1 0 1 0 1 1 0 0 1 0 1 1 0 1 1 0 1 1 0 0 1 0 0 1 1\n",
            " 1 0 1 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 1 0 0 0 1 1 0 0 0 1 0 0 1 1 0 1 0 1 0\n",
            " 0 1 1 1 0 0 0 0 1 0 1 0 0 1 1 0 0 1 1 1 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0\n",
            " 0 1 0 0 1 0 0 0 0 1 0 1 0 1 0 1 0 0 0 0 0 1 1 0 0 0 0 1 0 1 1 0 1 0 0 0 0\n",
            " 1 1 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 1 1 1 1 0 1 1 0 1 0 1 0 1\n",
            " 0 1 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0\n",
            " 0 1 0 0 0 0 0 1 1 1 0 1 0 0 1 1 0 0 1 1 0 1 0 1 0 0 1 1 0 0 1 1 1 1 1 1 0\n",
            " 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 1 1 1 1 1 0 0 1 1 0 1 1 0 0 0 1\n",
            " 0 0 1 0 0 1 0 0 1 0 0 1 0 0 0 1 0 1 1 1 0 1 0 0 1 1 1 0 0 0 1 1 0 0 0 0 0\n",
            " 1 1 0 0]\n",
            "probabilities: (892, 2) \n",
            " [1 1 0 0 1 1 0 1 1 0 0 1 0 1 1 0 0 1 0 1 0 0 0 1 0 1 1 0 0 1 1 1 1 0 0 1 0\n",
            " 0 0 0 0 1 0 1 1 0 0 1 1 1 1 1 0 0 1 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 1\n",
            " 0 0 0 1 0 0 1 1 1 0 1 0 1 1 0 0 0 0 0 0 1 0 1 0 0 1 0 0 1 1 1 0 0 0 0 0 1\n",
            " 0 1 1 0 0 0 1 0 1 0 1 1 0 0 0 1 0 0 0 1 0 1 1 1 1 0 1 0 1 0 0 1 1 0 1 1 1\n",
            " 0 1 0 0 0 0 0 0 1 0 0 0 1 1 1 1 0 0 1 0 0 1 1 0 1 1 1 1 0 0 1 0 1 0 0 0 1\n",
            " 0 0 1 1 1 0 1 0 1 0 0 0 0 1 1 1 0 1 0 0 1 0 1 0 0 1 0 1 0 0 1 0 0 0 1 0 0\n",
            " 0 0 1 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 1 1 1 0 0 1 1 1 1 0 0 0 0 1 0 0 1\n",
            " 1 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 1 1 1 0 0 0 1 0\n",
            " 0 1 1 0 1 0 0 1 1 1 0 1 0 1 1 0 1 0 0 1 0 0 1 0 1 1 0 1 0 1 0 1 1 1 1 0 1\n",
            " 0 0 1 0 0 0 0 0 1 1 1 0 0 1 0 0 0 1 0 0 0 1 1 0 1 0 0 0 0 1 1 1 1 1 0 0 0\n",
            " 0 1 0 0 1 0 0 1 0 0 0 1 0 0 1 0 0 1 1 0 1 0 0 0 0 0 1 0 1 1 1 1 0 0 1 0 1\n",
            " 1 0 1 0 1 1 1 0 0 1 0 0 0 1 1 0 1 0 0 0 0 1 1 1 1 0 0 1 0 0 0 1 1 0 0 0 1\n",
            " 0 1 0 1 0 0 0 0 0 1 1 0 1 0 0 0 1 1 1 0 1 1 0 1 1 0 0 1 1 1 0 0 0 1 0 0 0\n",
            " 1 0 0 0 0 0 0 0 0 1 0 1 0 0 1 1 0 1 1 0 0 1 1 1 1 0 1 1 0 1 1 0 0 0 0 0 0\n",
            " 1 1 1 0 0 0 1 0 1 0 0 0 0 1 1 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0\n",
            " 0 0 1 0 1 1 0 0 1 0 0 1 1 0 1 0 1 1 0 0 1 0 1 1 0 1 1 0 1 1 0 0 1 0 0 1 1\n",
            " 1 0 1 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 1 0 0 0 1 1 0 0 0 1 0 0 1 1 0 1 0 1 0\n",
            " 0 1 1 1 0 0 0 0 1 0 1 0 0 1 1 0 0 1 1 1 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0\n",
            " 0 1 0 0 1 0 0 0 0 1 0 1 0 1 0 1 0 0 0 0 0 1 1 0 0 0 0 1 0 1 1 0 1 0 0 0 0\n",
            " 1 1 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 1 1 1 1 0 1 1 0 1 0 1 0 1\n",
            " 0 1 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0\n",
            " 0 1 0 0 0 0 0 1 1 1 0 1 0 0 1 1 0 0 1 1 0 1 0 1 0 0 1 1 0 0 1 1 1 1 1 1 0\n",
            " 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 1 1 1 1 1 0 0 1 1 0 1 1 0 0 0 1\n",
            " 0 0 1 0 0 1 0 0 1 0 0 1 0 0 0 1 0 1 1 1 0 1 0 0 1 1 1 0 0 0 1 1 0 0 0 0 0\n",
            " 1 1 0 0]\n",
            "trainset before adding uncertain samples (410, 10) (410,)\n",
            "trainset after adding uncertain samples (420, 10) (420,)\n",
            "updated train set: (420, 10) (420,) unique(labels): [ 90 330] [0 1]\n",
            "val set: (882, 10) (882,)\n",
            "\n",
            "Train set: (420, 10)\n",
            "Validation set: (882, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: divide by zero encountered in log2\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: invalid value encountered in multiply\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: divide by zero encountered in log2\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: invalid value encountered in multiply\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "--------------------------------\n",
            "Iteration: 42\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.069 s \n",
            "\n",
            "Accuracy rate is 76.267281 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.84      0.84       321\n",
            "           1       0.54      0.54      0.54       113\n",
            "\n",
            "    accuracy                           0.76       434\n",
            "   macro avg       0.69      0.69      0.69       434\n",
            "weighted avg       0.76      0.76      0.76       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[270  51]\n",
            " [ 52  61]]\n",
            "--------------------------------\n",
            "val predicted: (882,) [1 1 0 0 1 1 0 1 1 0 0 1 0 1 1 0 0 1 0 1 0 0 0 1 0 1 1 0 0 1 1 1 1 0 0 1 0\n",
            " 0 0 0 0 1 0 1 1 0 0 1 1 1 1 1 0 0 1 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 1\n",
            " 1 0 0 0 0 0 1 1 1 0 1 0 1 1 0 0 0 0 0 0 1 0 1 0 0 1 0 0 1 0 1 0 0 0 0 0 1\n",
            " 0 1 1 0 0 0 1 0 1 0 1 1 0 0 1 1 0 0 0 1 0 1 1 1 1 0 1 0 1 0 0 1 1 0 1 1 1\n",
            " 1 1 0 0 0 0 1 0 1 0 0 0 1 1 1 1 0 0 1 0 0 0 1 0 1 1 1 1 0 0 1 0 1 0 0 0 1\n",
            " 0 0 1 1 1 0 1 0 1 0 0 0 0 1 1 1 0 1 0 0 1 0 1 0 0 1 0 1 0 0 1 0 0 0 1 0 0\n",
            " 0 0 1 0 0 0 1 1 0 0 0 1 0 0 1 0 0 0 0 0 1 1 1 0 0 1 1 1 1 0 0 0 0 1 0 0 1\n",
            " 1 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 1 1 1 0 0 0 1 0\n",
            " 0 1 1 0 1 0 0 1 1 1 0 1 0 1 1 0 1 0 0 1 0 0 1 0 1 1 0 1 0 1 0 1 1 1 1 1 1\n",
            " 0 0 1 0 0 0 0 0 1 1 1 0 0 1 0 0 0 1 0 1 1 0 1 0 0 1 1 1 1 1 0 1 1 0 1 0 0\n",
            " 1 0 0 1 0 0 0 1 0 0 1 0 0 0 1 0 1 0 0 0 0 0 1 0 1 1 1 1 0 0 1 0 1 1 0 1 0\n",
            " 1 1 0 0 0 1 0 0 0 1 1 0 1 0 0 0 0 0 1 1 1 0 0 1 0 0 0 1 1 0 0 0 0 0 1 0 1\n",
            " 0 0 0 0 1 1 0 1 0 1 0 1 0 1 0 1 1 0 1 1 0 0 0 1 1 0 0 0 1 0 0 0 1 0 0 0 0\n",
            " 1 0 0 0 1 0 1 0 0 1 1 0 1 1 0 0 1 1 1 1 0 1 1 0 1 1 0 0 0 0 0 0 1 1 1 0 0\n",
            " 0 1 0 0 0 0 0 0 1 1 0 0 1 1 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 1 0 1 1\n",
            " 0 0 1 0 0 1 1 0 1 0 1 1 1 0 1 0 1 1 0 1 1 0 1 1 0 0 1 0 0 1 1 1 0 1 0 0 0\n",
            " 0 0 0 0 0 0 0 1 1 0 1 0 1 0 0 0 1 1 0 0 0 1 0 0 1 1 0 1 0 1 0 0 1 1 1 0 0\n",
            " 0 0 1 0 1 0 0 1 1 0 1 1 0 1 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0 1 0\n",
            " 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 1 0 1 1 0 1 0 0 0 0 1 1 0 0 0 0\n",
            " 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 1 1 1 1 0 1 1 0 1 0 1 0 1 0 1 1 1 1 0 0\n",
            " 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 1\n",
            " 1 1 0 1 0 0 1 1 1 0 1 1 0 1 0 1 0 0 1 1 0 0 1 1 1 1 1 1 0 1 0 0 0 0 0 0 0\n",
            " 0 0 0 1 0 0 0 1 0 0 1 0 1 1 1 1 1 0 0 1 0 1 1 0 0 0 1 0 0 0 0 0 1 0 0 1 0\n",
            " 0 1 0 0 0 1 0 1 1 1 0 1 0 0 1 1 1 0 0 0 1 1 0 0 0 0 0 1 1 0 0]\n",
            "probabilities: (882, 2) \n",
            " [1 1 0 0 1 1 0 1 1 0 0 1 0 1 1 0 0 1 0 1 0 0 0 1 0 1 1 0 0 1 1 1 1 0 0 1 0\n",
            " 0 0 0 0 1 0 1 1 0 0 1 1 1 1 1 0 0 1 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 1\n",
            " 1 0 0 0 0 0 1 1 1 0 1 0 1 1 0 0 0 0 0 0 1 0 1 0 0 1 0 0 1 0 1 0 0 0 0 0 1\n",
            " 0 1 1 0 0 0 1 0 1 0 1 1 0 0 1 1 0 0 0 1 0 1 1 1 1 0 1 0 1 0 0 1 1 0 1 1 1\n",
            " 1 1 0 0 0 0 1 0 1 0 0 0 1 1 1 1 0 0 1 0 0 0 1 0 1 1 1 1 0 0 1 0 1 0 0 0 1\n",
            " 0 0 1 1 1 0 1 0 1 0 0 0 0 1 1 1 0 1 0 0 1 0 1 0 0 1 0 1 0 0 1 0 0 0 1 0 0\n",
            " 0 0 1 0 0 0 1 1 0 0 0 1 0 0 1 0 0 0 0 0 1 1 1 0 0 1 1 1 1 0 0 0 0 1 0 0 1\n",
            " 1 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 1 1 1 0 0 0 1 0\n",
            " 0 1 1 0 1 0 0 1 1 1 0 1 0 1 1 0 1 0 0 1 0 0 1 0 1 1 0 1 0 1 0 1 1 1 1 1 1\n",
            " 0 0 1 0 0 0 0 0 1 1 1 0 0 1 0 0 0 1 0 1 1 0 1 0 0 1 1 1 1 1 0 1 1 0 1 0 0\n",
            " 1 0 0 1 0 0 0 1 0 0 1 0 0 0 1 0 1 0 0 0 0 0 1 0 1 1 1 1 0 0 1 0 1 1 0 1 0\n",
            " 1 1 0 0 0 1 0 0 0 1 1 0 1 0 0 0 0 0 1 1 1 0 0 1 0 0 0 1 1 0 0 0 0 0 1 0 1\n",
            " 0 0 0 0 1 1 0 1 0 1 0 1 0 1 0 1 1 0 1 1 0 0 0 1 1 0 0 0 1 0 0 0 1 0 0 0 0\n",
            " 1 0 0 0 1 0 1 0 0 1 1 0 1 1 0 0 1 1 1 1 0 1 1 0 1 1 0 0 0 0 0 0 1 1 1 0 0\n",
            " 0 1 0 0 0 0 0 0 1 1 0 0 1 1 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 1 0 1 1\n",
            " 0 0 1 0 0 1 1 0 1 0 1 1 1 0 1 0 1 1 0 1 1 0 1 1 0 0 1 0 0 1 1 1 0 1 0 0 0\n",
            " 0 0 0 0 0 0 0 1 1 0 1 0 1 0 0 0 1 1 0 0 0 1 0 0 1 1 0 1 0 1 0 0 1 1 1 0 0\n",
            " 0 0 1 0 1 0 0 1 1 0 1 1 0 1 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0 1 0\n",
            " 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 1 0 1 1 0 1 0 0 0 0 1 1 0 0 0 0\n",
            " 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 1 1 1 1 0 1 1 0 1 0 1 0 1 0 1 1 1 1 0 0\n",
            " 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 1\n",
            " 1 1 0 1 0 0 1 1 1 0 1 1 0 1 0 1 0 0 1 1 0 0 1 1 1 1 1 1 0 1 0 0 0 0 0 0 0\n",
            " 0 0 0 1 0 0 0 1 0 0 1 0 1 1 1 1 1 0 0 1 0 1 1 0 0 0 1 0 0 0 0 0 1 0 0 1 0\n",
            " 0 1 0 0 0 1 0 1 1 1 0 1 0 0 1 1 1 0 0 0 1 1 0 0 0 0 0 1 1 0 0]\n",
            "trainset before adding uncertain samples (420, 10) (420,)\n",
            "trainset after adding uncertain samples (430, 10) (430,)\n",
            "updated train set: (430, 10) (430,) unique(labels): [ 94 336] [0 1]\n",
            "val set: (872, 10) (872,)\n",
            "\n",
            "Train set: (430, 10)\n",
            "Validation set: (872, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 43\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.071 s \n",
            "\n",
            "Accuracy rate is 75.576037 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.83      0.83       321\n",
            "           1       0.53      0.53      0.53       113\n",
            "\n",
            "    accuracy                           0.76       434\n",
            "   macro avg       0.68      0.68      0.68       434\n",
            "weighted avg       0.76      0.76      0.76       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[268  53]\n",
            " [ 53  60]]\n",
            "--------------------------------\n",
            "val predicted: (872,) [1 1 0 0 1 1 0 1 1 0 0 1 0 1 1 0 0 1 0 1 0 0 0 1 0 1 1 0 0 1 1 1 1 1 0 1 0\n",
            " 0 0 0 0 1 0 1 1 0 0 1 1 1 1 1 0 0 1 0 1 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 1 1\n",
            " 0 0 0 0 0 1 1 1 0 1 0 1 1 0 0 0 0 0 0 1 0 1 0 0 1 0 0 1 0 1 0 0 0 0 0 1 0\n",
            " 1 1 0 0 0 1 0 1 0 1 1 0 0 1 1 0 0 0 1 0 1 1 1 0 1 0 1 0 0 1 1 0 1 1 1 0 1\n",
            " 0 0 0 0 0 0 1 0 0 0 1 1 1 1 0 0 1 0 0 1 0 1 1 1 1 0 0 1 0 1 0 0 0 1 0 0 1\n",
            " 1 1 0 1 0 1 0 0 0 0 1 1 1 0 1 0 0 1 0 1 0 0 1 0 1 0 0 1 0 0 0 1 0 0 0 0 1\n",
            " 0 1 0 1 1 0 0 0 1 0 0 1 0 0 0 0 0 1 1 1 0 0 1 1 1 1 0 0 0 1 0 0 1 0 1 1 1\n",
            " 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 1 1 1 0 0 0 1 0 0 1 1 0\n",
            " 1 0 0 1 1 1 0 1 0 1 1 0 1 0 0 1 0 1 1 0 1 1 0 1 0 0 0 1 1 1 1 1 1 0 0 1 0\n",
            " 0 0 0 0 1 1 1 0 0 1 0 0 1 1 0 1 1 0 1 0 0 1 1 1 1 1 0 1 0 0 1 0 0 1 0 0 1\n",
            " 0 0 1 1 0 0 1 0 0 0 1 0 1 0 0 0 0 0 1 0 1 1 1 1 0 0 1 0 1 1 0 1 0 1 1 0 0\n",
            " 0 1 0 0 0 1 1 0 1 0 0 0 0 0 1 1 1 0 0 1 0 0 0 1 1 0 0 0 1 0 1 0 0 0 0 1 0\n",
            " 1 1 0 1 0 1 0 1 0 1 0 1 1 0 1 1 0 0 0 1 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0\n",
            " 1 0 1 0 0 1 1 0 1 1 0 0 1 1 1 0 1 1 0 1 0 0 0 0 0 0 1 1 1 0 0 1 0 1 0 0 0\n",
            " 0 1 1 0 0 1 1 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 1 0 1 1 0 0 1 0 0 1 1\n",
            " 0 1 0 1 1 1 0 1 0 1 0 0 1 1 0 1 1 0 1 1 0 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0\n",
            " 1 1 0 1 0 1 0 0 0 1 1 0 0 0 1 0 0 1 0 0 1 0 1 0 0 0 1 1 0 0 0 0 1 0 1 0 0\n",
            " 1 1 0 1 1 1 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 1 0 0\n",
            " 0 1 0 0 0 0 1 1 0 0 0 0 1 0 1 1 0 1 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 0 1 0 1\n",
            " 0 0 0 0 0 0 0 1 1 1 1 1 0 1 1 0 1 0 1 0 1 0 1 1 1 1 1 0 1 0 0 0 0 0 0 0 0\n",
            " 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 1 1 1 0 1 0 0 1 1 1\n",
            " 0 1 1 0 1 0 1 1 0 1 1 0 0 1 1 1 1 1 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0\n",
            " 1 0 1 1 1 1 1 0 0 1 0 1 1 0 0 0 1 0 0 1 0 1 1 0 0 1 0 0 1 0 0 0 1 0 1 1 1\n",
            " 0 1 0 0 1 0 1 0 0 0 1 1 0 0 0 0 0 1 1 0 0]\n",
            "probabilities: (872, 2) \n",
            " [1 1 0 0 1 1 0 1 1 0 0 1 0 1 1 0 0 1 0 1 0 0 0 1 0 1 1 0 0 1 1 1 1 1 0 1 0\n",
            " 0 0 0 0 1 0 1 1 0 0 1 1 1 1 1 0 0 1 0 1 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 1 1\n",
            " 0 0 0 0 0 1 1 1 0 1 0 1 1 0 0 0 0 0 0 1 0 1 0 0 1 0 0 1 0 1 0 0 0 0 0 1 0\n",
            " 1 1 0 0 0 1 0 1 0 1 1 0 0 1 1 0 0 0 1 0 1 1 1 0 1 0 1 0 0 1 1 0 1 1 1 0 1\n",
            " 0 0 0 0 0 0 1 0 0 0 1 1 1 1 0 0 1 0 0 1 0 1 1 1 1 0 0 1 0 1 0 0 0 1 0 0 1\n",
            " 1 1 0 1 0 1 0 0 0 0 1 1 1 0 1 0 0 1 0 1 0 0 1 0 1 0 0 1 0 0 0 1 0 0 0 0 1\n",
            " 0 1 0 1 1 0 0 0 1 0 0 1 0 0 0 0 0 1 1 1 0 0 1 1 1 1 0 0 0 1 0 0 1 0 1 1 1\n",
            " 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 1 1 1 0 0 0 1 0 0 1 1 0\n",
            " 1 0 0 1 1 1 0 1 0 1 1 0 1 0 0 1 0 1 1 0 1 1 0 1 0 0 0 1 1 1 1 1 1 0 0 1 0\n",
            " 0 0 0 0 1 1 1 0 0 1 0 0 1 1 0 1 1 0 1 0 0 1 1 1 1 1 0 1 0 0 1 0 0 1 0 0 1\n",
            " 0 0 1 1 0 0 1 0 0 0 1 0 1 0 0 0 0 0 1 0 1 1 1 1 0 0 1 0 1 1 0 1 0 1 1 0 0\n",
            " 0 1 0 0 0 1 1 0 1 0 0 0 0 0 1 1 1 0 0 1 0 0 0 1 1 0 0 0 1 0 1 0 0 0 0 1 0\n",
            " 1 1 0 1 0 1 0 1 0 1 0 1 1 0 1 1 0 0 0 1 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0\n",
            " 1 0 1 0 0 1 1 0 1 1 0 0 1 1 1 0 1 1 0 1 0 0 0 0 0 0 1 1 1 0 0 1 0 1 0 0 0\n",
            " 0 1 1 0 0 1 1 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 1 0 1 1 0 0 1 0 0 1 1\n",
            " 0 1 0 1 1 1 0 1 0 1 0 0 1 1 0 1 1 0 1 1 0 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0\n",
            " 1 1 0 1 0 1 0 0 0 1 1 0 0 0 1 0 0 1 0 0 1 0 1 0 0 0 1 1 0 0 0 0 1 0 1 0 0\n",
            " 1 1 0 1 1 1 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 1 0 0\n",
            " 0 1 0 0 0 0 1 1 0 0 0 0 1 0 1 1 0 1 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 0 1 0 1\n",
            " 0 0 0 0 0 0 0 1 1 1 1 1 0 1 1 0 1 0 1 0 1 0 1 1 1 1 1 0 1 0 0 0 0 0 0 0 0\n",
            " 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 1 1 1 0 1 0 0 1 1 1\n",
            " 0 1 1 0 1 0 1 1 0 1 1 0 0 1 1 1 1 1 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0\n",
            " 1 0 1 1 1 1 1 0 0 1 0 1 1 0 0 0 1 0 0 1 0 1 1 0 0 1 0 0 1 0 0 0 1 0 1 1 1\n",
            " 0 1 0 0 1 0 1 0 0 0 1 1 0 0 0 0 0 1 1 0 0]\n",
            "trainset before adding uncertain samples (430, 10) (430,)\n",
            "trainset after adding uncertain samples (440, 10) (440,)\n",
            "updated train set: (440, 10) (440,) unique(labels): [ 96 344] [0 1]\n",
            "val set: (862, 10) (862,)\n",
            "\n",
            "Train set: (440, 10)\n",
            "Validation set: (862, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: divide by zero encountered in log2\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: invalid value encountered in multiply\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: divide by zero encountered in log2\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: invalid value encountered in multiply\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "Iteration: 44\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.063 s \n",
            "\n",
            "Accuracy rate is 75.576037 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.83      0.83       321\n",
            "           1       0.53      0.54      0.54       113\n",
            "\n",
            "    accuracy                           0.76       434\n",
            "   macro avg       0.68      0.69      0.68       434\n",
            "weighted avg       0.76      0.76      0.76       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[267  54]\n",
            " [ 52  61]]\n",
            "--------------------------------\n",
            "val predicted: (862,) [1 1 0 0 1 1 0 1 1 0 0 1 0 1 1 0 0 0 1 0 0 0 1 0 1 1 0 0 1 1 1 1 1 0 1 0 0\n",
            " 0 0 0 1 0 1 1 0 0 1 1 1 1 1 0 0 1 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 0\n",
            " 0 0 1 1 1 0 1 0 1 1 0 0 0 0 0 0 1 0 1 0 0 1 0 0 1 0 1 0 0 0 0 0 1 0 1 1 0\n",
            " 0 1 0 1 0 1 1 0 0 1 1 0 0 0 1 0 1 1 1 0 1 0 1 0 0 1 1 0 1 1 1 1 1 0 0 0 0\n",
            " 0 0 1 0 0 0 1 1 1 1 0 0 1 0 0 1 0 1 1 1 1 0 0 1 0 1 0 0 0 1 0 0 1 1 1 0 1\n",
            " 0 1 0 0 0 0 1 1 1 0 1 0 0 1 0 1 0 0 1 0 1 0 0 1 0 0 0 1 0 0 0 0 1 0 1 0 1\n",
            " 1 0 0 0 1 0 0 1 0 0 0 0 0 1 1 1 0 0 1 1 1 0 0 0 1 0 0 1 0 1 1 1 0 0 0 0 0\n",
            " 0 0 0 0 1 0 0 0 1 0 1 0 0 1 0 0 0 0 1 0 1 1 1 0 0 0 1 0 1 1 0 1 0 0 1 1 1\n",
            " 0 1 0 1 1 0 1 0 0 1 0 1 1 0 1 1 0 1 0 1 0 1 1 1 1 1 1 0 0 1 0 0 0 0 0 1 1\n",
            " 1 0 0 1 0 0 1 1 0 1 1 0 0 0 1 1 0 1 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 1 0 0 1\n",
            " 0 0 0 1 0 1 0 0 0 0 0 1 0 1 1 1 1 0 0 1 0 1 1 0 1 0 1 1 1 0 0 1 0 0 0 1 1\n",
            " 0 1 0 0 0 0 1 1 1 1 0 0 1 0 0 0 1 1 0 0 0 1 0 1 0 0 0 0 0 0 1 1 0 1 0 1 0\n",
            " 1 0 1 0 1 1 0 1 1 0 0 0 1 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 1 1\n",
            " 0 1 0 0 1 1 1 0 1 1 0 1 0 0 0 0 0 0 1 1 1 0 0 1 0 1 0 0 0 0 1 1 0 0 1 1 1\n",
            " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 1 1 0 0 1 0 0 1 1 0 1 0 1 1 1 0 1 0\n",
            " 1 0 0 1 1 0 1 1 0 1 1 0 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 1 0\n",
            " 1 1 0 0 0 1 0 0 1 0 0 1 0 1 0 0 0 1 1 0 0 0 0 1 0 1 0 0 1 1 0 1 1 1 0 0 0\n",
            " 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 1 1 0\n",
            " 0 0 0 1 0 1 1 0 1 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 1 1\n",
            " 1 1 1 0 1 1 0 1 0 1 0 1 0 1 1 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
            " 1 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 1 1 1 0 1 0 0 1 1 1 0 1 1 0 1 0 1 1 0 1\n",
            " 1 0 0 1 1 1 1 1 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 1 1 1 1 1 0 0 1\n",
            " 0 1 1 0 0 0 1 0 0 0 0 1 1 0 0 1 0 0 1 0 0 1 1 0 1 1 1 0 1 0 0 1 0 1 0 0 0\n",
            " 1 1 0 0 0 0 0 1 1 0 0]\n",
            "probabilities: (862, 2) \n",
            " [1 1 0 0 1 1 0 1 1 0 0 1 0 1 1 0 0 0 1 0 0 0 1 0 1 1 0 0 1 1 1 1 1 0 1 0 0\n",
            " 0 0 0 1 0 1 1 0 0 1 1 1 1 1 0 0 1 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 0\n",
            " 0 0 1 1 1 0 1 0 1 1 0 0 0 0 0 0 1 0 1 0 0 1 0 0 1 0 1 0 0 0 0 0 1 0 1 1 0\n",
            " 0 1 0 1 0 1 1 0 0 1 1 0 0 0 1 0 1 1 1 0 1 0 1 0 0 1 1 0 1 1 1 1 1 0 0 0 0\n",
            " 0 0 1 0 0 0 1 1 1 1 0 0 1 0 0 1 0 1 1 1 1 0 0 1 0 1 0 0 0 1 0 0 1 1 1 0 1\n",
            " 0 1 0 0 0 0 1 1 1 0 1 0 0 1 0 1 0 0 1 0 1 0 0 1 0 0 0 1 0 0 0 0 1 0 1 0 1\n",
            " 1 0 0 0 1 0 0 1 0 0 0 0 0 1 1 1 0 0 1 1 1 0 0 0 1 0 0 1 0 1 1 1 0 0 0 0 0\n",
            " 0 0 0 0 1 0 0 0 1 0 1 0 0 1 0 0 0 0 1 0 1 1 1 0 0 0 1 0 1 1 0 1 0 0 1 1 1\n",
            " 0 1 0 1 1 0 1 0 0 1 0 1 1 0 1 1 0 1 0 1 0 1 1 1 1 1 1 0 0 1 0 0 0 0 0 1 1\n",
            " 1 0 0 1 0 0 1 1 0 1 1 0 0 0 1 1 0 1 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 1 0 0 1\n",
            " 0 0 0 1 0 1 0 0 0 0 0 1 0 1 1 1 1 0 0 1 0 1 1 0 1 0 1 1 1 0 0 1 0 0 0 1 1\n",
            " 0 1 0 0 0 0 1 1 1 1 0 0 1 0 0 0 1 1 0 0 0 1 0 1 0 0 0 0 0 0 1 1 0 1 0 1 0\n",
            " 1 0 1 0 1 1 0 1 1 0 0 0 1 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 1 1\n",
            " 0 1 0 0 1 1 1 0 1 1 0 1 0 0 0 0 0 0 1 1 1 0 0 1 0 1 0 0 0 0 1 1 0 0 1 1 1\n",
            " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 1 1 0 0 1 0 0 1 1 0 1 0 1 1 1 0 1 0\n",
            " 1 0 0 1 1 0 1 1 0 1 1 0 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 1 0\n",
            " 1 1 0 0 0 1 0 0 1 0 0 1 0 1 0 0 0 1 1 0 0 0 0 1 0 1 0 0 1 1 0 1 1 1 0 0 0\n",
            " 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 1 1 0\n",
            " 0 0 0 1 0 1 1 0 1 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 1 1\n",
            " 1 1 1 0 1 1 0 1 0 1 0 1 0 1 1 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
            " 1 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 1 1 1 0 1 0 0 1 1 1 0 1 1 0 1 0 1 1 0 1\n",
            " 1 0 0 1 1 1 1 1 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 1 1 1 1 1 0 0 1\n",
            " 0 1 1 0 0 0 1 0 0 0 0 1 1 0 0 1 0 0 1 0 0 1 1 0 1 1 1 0 1 0 0 1 0 1 0 0 0\n",
            " 1 1 0 0 0 0 0 1 1 0 0]\n",
            "trainset before adding uncertain samples (440, 10) (440,)\n",
            "trainset after adding uncertain samples (450, 10) (450,)\n",
            "updated train set: (450, 10) (450,) unique(labels): [102 348] [0 1]\n",
            "val set: (852, 10) (852,)\n",
            "\n",
            "Train set: (450, 10)\n",
            "Validation set: (852, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 45\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.067 s \n",
            "\n",
            "Accuracy rate is 76.497696 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.85      0.84       321\n",
            "           1       0.55      0.53      0.54       113\n",
            "\n",
            "    accuracy                           0.76       434\n",
            "   macro avg       0.69      0.69      0.69       434\n",
            "weighted avg       0.76      0.76      0.76       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[272  49]\n",
            " [ 53  60]]\n",
            "--------------------------------\n",
            "val predicted: (852,) [1 1 0 0 1 0 0 1 0 0 1 0 1 1 0 0 0 1 0 0 0 1 0 1 1 0 0 1 1 1 1 1 0 1 0 0 0\n",
            " 0 0 1 0 1 1 0 0 1 1 1 1 0 0 0 1 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0\n",
            " 0 1 1 1 0 1 0 1 1 0 0 0 0 0 1 0 1 0 0 1 0 0 1 0 1 0 0 0 0 0 1 0 1 1 0 0 1\n",
            " 0 1 0 1 1 0 0 1 1 0 0 0 1 0 1 1 1 0 1 0 1 0 0 1 1 0 1 1 1 0 1 0 0 0 0 0 0\n",
            " 1 0 0 0 1 1 1 1 0 0 1 0 0 1 0 1 1 1 1 0 0 1 0 1 0 0 0 1 0 0 1 1 1 0 1 0 1\n",
            " 0 0 0 0 1 1 1 0 1 0 0 1 0 1 0 0 1 0 1 0 0 1 0 0 0 1 0 0 0 0 1 0 1 0 1 1 0\n",
            " 0 0 1 0 0 1 0 0 0 0 0 0 1 1 0 0 1 1 1 0 0 0 1 0 0 1 0 1 1 1 0 0 0 0 0 1 0\n",
            " 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 1 1 1 0 0 0 1 0 1 1 0 1 0 0 1 1 1 0 1\n",
            " 0 1 1 0 1 0 0 1 0 1 1 0 1 1 0 1 0 1 0 1 1 1 1 1 1 0 0 1 0 0 0 0 0 1 1 0 0\n",
            " 1 0 0 0 1 0 1 1 0 0 0 1 1 0 1 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 1 0 0 1 0 0 0\n",
            " 1 0 1 0 1 0 0 0 1 0 1 1 0 1 0 0 1 0 1 1 0 1 0 1 1 1 0 0 1 0 0 0 1 1 0 1 0\n",
            " 0 0 0 1 1 1 1 0 0 1 0 0 0 1 1 0 0 0 1 0 1 0 0 0 0 1 0 1 1 0 1 0 1 0 1 0 1\n",
            " 0 1 1 0 1 1 0 0 0 1 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 1 1 0 1 0\n",
            " 0 1 1 1 0 1 1 0 1 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 1 1 0 1 1 1 0 0 0 0\n",
            " 0 0 0 0 0 0 1 0 0 1 0 0 1 1 0 0 0 1 0 0 1 1 0 1 0 1 1 0 0 1 0 0 0 0 1 1 0\n",
            " 1 1 0 0 0 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 1 0 0 1 0 0 0 1 0\n",
            " 0 1 0 0 1 0 1 0 0 0 1 1 0 0 0 0 1 0 1 0 0 1 1 0 1 1 1 0 0 0 0 0 0 0 0 1 1\n",
            " 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 1 1 0 0 0 0 1 0 1 1\n",
            " 0 1 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 1 1 1 1 1 0 1 1 0\n",
            " 1 0 1 0 1 0 1 1 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1\n",
            " 0 1 0 0 1 0 0 0 0 0 1 1 1 0 1 0 0 1 1 1 0 1 1 0 1 0 1 0 0 1 0 0 0 1 1 1 1\n",
            " 1 1 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 1 1 1 1 0 0 1 0 1 1 0 0 1 1 0 0 1\n",
            " 0 1 1 0 0 1 0 0 1 0 0 1 1 0 1 1 1 0 1 0 0 1 1 1 0 0 0 1 1 0 0 0 0 0 1 1 0\n",
            " 0]\n",
            "probabilities: (852, 2) \n",
            " [1 1 0 0 1 0 0 1 0 0 1 0 1 1 0 0 0 1 0 0 0 1 0 1 1 0 0 1 1 1 1 1 0 1 0 0 0\n",
            " 0 0 1 0 1 1 0 0 1 1 1 1 0 0 0 1 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0\n",
            " 0 1 1 1 0 1 0 1 1 0 0 0 0 0 1 0 1 0 0 1 0 0 1 0 1 0 0 0 0 0 1 0 1 1 0 0 1\n",
            " 0 1 0 1 1 0 0 1 1 0 0 0 1 0 1 1 1 0 1 0 1 0 0 1 1 0 1 1 1 0 1 0 0 0 0 0 0\n",
            " 1 0 0 0 1 1 1 1 0 0 1 0 0 1 0 1 1 1 1 0 0 1 0 1 0 0 0 1 0 0 1 1 1 0 1 0 1\n",
            " 0 0 0 0 1 1 1 0 1 0 0 1 0 1 0 0 1 0 1 0 0 1 0 0 0 1 0 0 0 0 1 0 1 0 1 1 0\n",
            " 0 0 1 0 0 1 0 0 0 0 0 0 1 1 0 0 1 1 1 0 0 0 1 0 0 1 0 1 1 1 0 0 0 0 0 1 0\n",
            " 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 1 1 1 0 0 0 1 0 1 1 0 1 0 0 1 1 1 0 1\n",
            " 0 1 1 0 1 0 0 1 0 1 1 0 1 1 0 1 0 1 0 1 1 1 1 1 1 0 0 1 0 0 0 0 0 1 1 0 0\n",
            " 1 0 0 0 1 0 1 1 0 0 0 1 1 0 1 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 1 0 0 1 0 0 0\n",
            " 1 0 1 0 1 0 0 0 1 0 1 1 0 1 0 0 1 0 1 1 0 1 0 1 1 1 0 0 1 0 0 0 1 1 0 1 0\n",
            " 0 0 0 1 1 1 1 0 0 1 0 0 0 1 1 0 0 0 1 0 1 0 0 0 0 1 0 1 1 0 1 0 1 0 1 0 1\n",
            " 0 1 1 0 1 1 0 0 0 1 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 1 1 0 1 0\n",
            " 0 1 1 1 0 1 1 0 1 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 1 1 0 1 1 1 0 0 0 0\n",
            " 0 0 0 0 0 0 1 0 0 1 0 0 1 1 0 0 0 1 0 0 1 1 0 1 0 1 1 0 0 1 0 0 0 0 1 1 0\n",
            " 1 1 0 0 0 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 1 0 0 1 0 0 0 1 0\n",
            " 0 1 0 0 1 0 1 0 0 0 1 1 0 0 0 0 1 0 1 0 0 1 1 0 1 1 1 0 0 0 0 0 0 0 0 1 1\n",
            " 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 1 1 0 0 0 0 1 0 1 1\n",
            " 0 1 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 1 1 1 1 1 0 1 1 0\n",
            " 1 0 1 0 1 0 1 1 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1\n",
            " 0 1 0 0 1 0 0 0 0 0 1 1 1 0 1 0 0 1 1 1 0 1 1 0 1 0 1 0 0 1 0 0 0 1 1 1 1\n",
            " 1 1 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 1 1 1 1 0 0 1 0 1 1 0 0 1 1 0 0 1\n",
            " 0 1 1 0 0 1 0 0 1 0 0 1 1 0 1 1 1 0 1 0 0 1 1 1 0 0 0 1 1 0 0 0 0 0 1 1 0\n",
            " 0]\n",
            "trainset before adding uncertain samples (450, 10) (450,)\n",
            "trainset after adding uncertain samples (460, 10) (460,)\n",
            "updated train set: (460, 10) (460,) unique(labels): [108 352] [0 1]\n",
            "val set: (842, 10) (842,)\n",
            "\n",
            "Train set: (460, 10)\n",
            "Validation set: (842, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: divide by zero encountered in log2\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: invalid value encountered in multiply\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: divide by zero encountered in log2\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: invalid value encountered in multiply\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "--------------------------------\n",
            "Iteration: 46\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.076 s \n",
            "\n",
            "Accuracy rate is 76.958525 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.86      0.85       321\n",
            "           1       0.56      0.52      0.54       113\n",
            "\n",
            "    accuracy                           0.77       434\n",
            "   macro avg       0.70      0.69      0.69       434\n",
            "weighted avg       0.76      0.77      0.77       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[275  46]\n",
            " [ 54  59]]\n",
            "--------------------------------\n",
            "val predicted: (842,) [1 0 0 1 0 0 1 0 0 1 0 1 1 0 1 0 1 0 0 0 1 0 0 1 0 1 1 1 1 1 1 0 1 0 0 0 0\n",
            " 0 1 0 1 1 0 0 1 1 1 1 0 0 0 1 0 1 0 0 0 0 1 1 0 1 0 0 0 0 0 1 1 0 0 1 0 0\n",
            " 1 1 1 0 1 0 1 1 0 1 0 0 0 1 0 1 0 0 1 0 0 1 0 1 0 0 0 0 0 1 0 1 1 0 0 1 0\n",
            " 1 0 1 1 0 0 1 1 0 0 0 1 0 1 1 1 0 1 0 1 0 0 1 0 0 1 1 1 0 1 0 0 0 0 0 0 1\n",
            " 0 0 0 1 1 1 1 0 1 1 0 0 1 0 1 1 1 1 0 0 1 1 1 0 0 0 1 0 0 1 1 1 0 1 1 0 0\n",
            " 0 0 1 1 1 0 1 0 0 1 0 1 0 0 1 0 1 0 0 1 0 0 0 1 0 0 0 0 1 0 1 0 1 1 0 0 0\n",
            " 1 0 0 1 0 0 0 0 0 0 1 1 0 0 1 1 1 1 0 0 1 0 0 1 0 1 1 1 0 0 0 0 0 1 0 0 0\n",
            " 1 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 1 1 1 0 0 0 1 0 1 1 0 1 0 0 1 1 1 0 1 0 1\n",
            " 1 0 1 0 0 1 0 1 1 0 1 1 0 1 0 1 0 1 1 1 1 1 1 0 0 1 0 0 0 0 0 1 1 0 0 1 0\n",
            " 0 0 1 0 1 1 0 0 0 1 1 0 1 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 1 0 0 1 0 0 0 1 0\n",
            " 1 0 1 0 0 1 1 0 1 1 0 1 0 0 1 1 1 0 1 0 1 1 0 0 0 1 0 0 0 1 1 0 1 0 0 0 0\n",
            " 1 1 1 1 0 0 1 0 0 0 1 1 0 0 0 1 0 1 0 0 0 0 0 0 1 1 0 1 0 1 0 1 1 1 0 1 1\n",
            " 0 1 1 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 1 0 1 0 0 1 1 1\n",
            " 0 1 1 0 1 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 1 1 0 1 1 1 0 0 0 0 0 0 0 0\n",
            " 0 0 1 0 0 1 0 0 1 1 1 0 0 1 0 0 1 1 0 1 0 1 1 0 0 1 0 0 1 0 1 1 0 1 1 0 0\n",
            " 0 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 1 1 0 0 1 0 0 1 0 1 0 0 1 0 1\n",
            " 0 0 1 1 1 0 0 0 0 1 0 1 0 0 1 1 0 1 1 1 0 0 1 0 0 0 0 0 1 1 1 0 0 0 1 0 0\n",
            " 0 1 0 0 1 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 1 1 0 0 0 1 0 1 1 0 1 0 0 0 0 1 1\n",
            " 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 1 1 0 1 1 1 0 1 0 1 0\n",
            " 1 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0\n",
            " 0 1 1 1 0 1 0 0 1 1 1 0 1 1 0 1 0 1 0 0 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 0 0\n",
            " 0 0 0 1 0 1 0 0 1 0 1 1 1 1 0 0 1 0 1 1 0 0 1 1 0 0 1 0 1 1 0 0 1 0 0 1 0\n",
            " 0 1 1 0 1 1 1 0 1 0 0 1 1 1 0 0 0 1 1 0 0 0 0 0 1 1 0 0]\n",
            "probabilities: (842, 2) \n",
            " [1 0 0 1 0 0 1 0 0 1 0 1 1 0 1 0 1 0 0 0 1 0 0 1 0 1 1 1 1 1 1 0 1 0 0 0 0\n",
            " 0 1 0 1 1 0 0 1 1 1 1 0 0 0 1 0 1 0 0 0 0 1 1 0 1 0 0 0 0 0 1 1 0 0 1 0 0\n",
            " 1 1 1 0 1 0 1 1 0 1 0 0 0 1 0 1 0 0 1 0 0 1 0 1 0 0 0 0 0 1 0 1 1 0 0 1 0\n",
            " 1 0 1 1 0 0 1 1 0 0 0 1 0 1 1 1 0 1 0 1 0 0 1 0 0 1 1 1 0 1 0 0 0 0 0 0 1\n",
            " 0 0 0 1 1 1 1 0 1 1 0 0 1 0 1 1 1 1 0 0 1 1 1 0 0 0 1 0 0 1 1 1 0 1 1 0 0\n",
            " 0 0 1 1 1 0 1 0 0 1 0 1 0 0 1 0 1 0 0 1 0 0 0 1 0 0 0 0 1 0 1 0 1 1 0 0 0\n",
            " 1 0 0 1 0 0 0 0 0 0 1 1 0 0 1 1 1 1 0 0 1 0 0 1 0 1 1 1 0 0 0 0 0 1 0 0 0\n",
            " 1 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 1 1 1 0 0 0 1 0 1 1 0 1 0 0 1 1 1 0 1 0 1\n",
            " 1 0 1 0 0 1 0 1 1 0 1 1 0 1 0 1 0 1 1 1 1 1 1 0 0 1 0 0 0 0 0 1 1 0 0 1 0\n",
            " 0 0 1 0 1 1 0 0 0 1 1 0 1 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 1 0 0 1 0 0 0 1 0\n",
            " 1 0 1 0 0 1 1 0 1 1 0 1 0 0 1 1 1 0 1 0 1 1 0 0 0 1 0 0 0 1 1 0 1 0 0 0 0\n",
            " 1 1 1 1 0 0 1 0 0 0 1 1 0 0 0 1 0 1 0 0 0 0 0 0 1 1 0 1 0 1 0 1 1 1 0 1 1\n",
            " 0 1 1 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 1 0 1 0 0 1 1 1\n",
            " 0 1 1 0 1 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 1 1 0 1 1 1 0 0 0 0 0 0 0 0\n",
            " 0 0 1 0 0 1 0 0 1 1 1 0 0 1 0 0 1 1 0 1 0 1 1 0 0 1 0 0 1 0 1 1 0 1 1 0 0\n",
            " 0 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 1 1 0 0 1 0 0 1 0 1 0 0 1 0 1\n",
            " 0 0 1 1 1 0 0 0 0 1 0 1 0 0 1 1 0 1 1 1 0 0 1 0 0 0 0 0 1 1 1 0 0 0 1 0 0\n",
            " 0 1 0 0 1 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 1 1 0 0 0 1 0 1 1 0 1 0 0 0 0 1 1\n",
            " 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 1 1 0 1 1 1 0 1 0 1 0\n",
            " 1 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0\n",
            " 0 1 1 1 0 1 0 0 1 1 1 0 1 1 0 1 0 1 0 0 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 0 0\n",
            " 0 0 0 1 0 1 0 0 1 0 1 1 1 1 0 0 1 0 1 1 0 0 1 1 0 0 1 0 1 1 0 0 1 0 0 1 0\n",
            " 0 1 1 0 1 1 1 0 1 0 0 1 1 1 0 0 0 1 1 0 0 0 0 0 1 1 0 0]\n",
            "trainset before adding uncertain samples (460, 10) (460,)\n",
            "trainset after adding uncertain samples (470, 10) (470,)\n",
            "updated train set: (470, 10) (470,) unique(labels): [114 356] [0 1]\n",
            "val set: (832, 10) (832,)\n",
            "\n",
            "Train set: (470, 10)\n",
            "Validation set: (832, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 47\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.064 s \n",
            "\n",
            "Accuracy rate is 76.958525 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.85      0.85       321\n",
            "           1       0.56      0.53      0.55       113\n",
            "\n",
            "    accuracy                           0.77       434\n",
            "   macro avg       0.70      0.69      0.70       434\n",
            "weighted avg       0.77      0.77      0.77       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[274  47]\n",
            " [ 53  60]]\n",
            "--------------------------------\n",
            "val predicted: (832,) [1 0 0 1 0 1 1 0 0 1 0 1 1 0 1 0 1 0 0 0 1 0 0 1 0 0 1 1 1 1 0 1 0 0 0 0 0\n",
            " 1 0 1 1 0 0 1 1 1 1 0 0 0 1 0 1 1 0 0 0 1 1 0 1 0 0 0 0 0 1 0 0 0 1 0 0 1\n",
            " 1 1 0 1 0 1 1 0 0 0 0 0 1 0 1 0 1 0 0 1 1 0 0 0 0 0 1 0 1 1 0 0 1 0 1 0 1\n",
            " 1 0 0 1 1 0 0 0 1 0 1 1 1 0 1 1 0 0 1 0 0 1 1 1 0 1 0 0 0 0 0 0 1 0 0 0 1\n",
            " 1 1 1 0 1 1 0 0 1 0 1 1 1 1 0 0 0 1 1 0 0 0 1 0 0 1 1 1 0 1 1 0 0 0 0 1 1\n",
            " 1 0 1 0 0 1 0 1 0 0 1 1 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 1 1 0 0 0 1 0 0 1 0\n",
            " 0 0 0 0 1 1 1 0 0 1 1 1 0 0 0 1 0 0 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
            " 0 1 0 0 0 0 0 0 0 1 0 1 1 1 0 0 0 1 1 0 1 0 0 1 1 1 0 1 0 1 1 0 1 0 0 1 0\n",
            " 1 1 0 1 1 0 1 0 0 0 1 1 1 1 1 1 0 0 1 0 0 0 0 0 1 1 0 0 1 0 0 0 1 0 1 1 0\n",
            " 0 0 1 1 0 1 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 1 0 0 1 0 0 0 1 0 1 0 0 0 0 1 1\n",
            " 0 1 1 0 1 0 0 1 1 0 1 0 1 1 0 0 0 1 0 0 0 1 1 0 1 0 0 0 0 1 1 1 1 0 0 1 0\n",
            " 0 0 1 1 0 0 0 1 0 1 0 0 0 0 0 0 1 1 0 1 0 1 0 1 0 1 0 1 1 0 1 1 0 0 0 1 1\n",
            " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 1 0 1 0 0 1 1 1 0 1 1 0 1 0 0 0\n",
            " 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 1 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0\n",
            " 1 1 1 0 0 1 0 0 1 1 0 0 0 1 1 0 0 1 0 0 0 0 1 1 0 1 1 0 0 0 0 1 1 1 0 1 0\n",
            " 0 0 0 0 0 0 0 0 0 1 1 0 1 0 1 1 0 1 0 0 1 0 1 0 0 1 0 1 0 0 0 1 1 0 0 0 0\n",
            " 1 0 1 0 0 1 1 0 1 1 1 0 0 0 0 0 0 0 0 1 1 1 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0\n",
            " 1 0 1 0 0 0 1 0 0 0 0 1 1 0 0 0 1 0 1 1 0 1 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0\n",
            " 0 1 0 1 0 0 0 0 0 0 0 1 1 1 1 1 0 1 1 0 1 1 1 0 1 0 1 1 1 1 0 1 0 0 0 0 0\n",
            " 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 1 1 0 1 0 0 1\n",
            " 1 1 0 1 1 0 1 0 1 0 0 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 1\n",
            " 0 1 1 1 1 0 0 1 0 1 1 0 0 1 1 0 0 1 0 1 1 0 0 1 0 0 1 0 0 1 1 0 1 1 1 0 0\n",
            " 0 1 1 1 0 0 0 1 1 0 0 0 0 0 1 1 0 0]\n",
            "probabilities: (832, 2) \n",
            " [1 0 0 1 0 1 1 0 0 1 0 1 1 0 1 0 1 0 0 0 1 0 0 1 0 0 1 1 1 1 0 1 0 0 0 0 0\n",
            " 1 0 1 1 0 0 1 1 1 1 0 0 0 1 0 1 1 0 0 0 1 1 0 1 0 0 0 0 0 1 0 0 0 1 0 0 1\n",
            " 1 1 0 1 0 1 1 0 0 0 0 0 1 0 1 0 1 0 0 1 1 0 0 0 0 0 1 0 1 1 0 0 1 0 1 0 1\n",
            " 1 0 0 1 1 0 0 0 1 0 1 1 1 0 1 1 0 0 1 0 0 1 1 1 0 1 0 0 0 0 0 0 1 0 0 0 1\n",
            " 1 1 1 0 1 1 0 0 1 0 1 1 1 1 0 0 0 1 1 0 0 0 1 0 0 1 1 1 0 1 1 0 0 0 0 1 1\n",
            " 1 0 1 0 0 1 0 1 0 0 1 1 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 1 1 0 0 0 1 0 0 1 0\n",
            " 0 0 0 0 1 1 1 0 0 1 1 1 0 0 0 1 0 0 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
            " 0 1 0 0 0 0 0 0 0 1 0 1 1 1 0 0 0 1 1 0 1 0 0 1 1 1 0 1 0 1 1 0 1 0 0 1 0\n",
            " 1 1 0 1 1 0 1 0 0 0 1 1 1 1 1 1 0 0 1 0 0 0 0 0 1 1 0 0 1 0 0 0 1 0 1 1 0\n",
            " 0 0 1 1 0 1 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 1 0 0 1 0 0 0 1 0 1 0 0 0 0 1 1\n",
            " 0 1 1 0 1 0 0 1 1 0 1 0 1 1 0 0 0 1 0 0 0 1 1 0 1 0 0 0 0 1 1 1 1 0 0 1 0\n",
            " 0 0 1 1 0 0 0 1 0 1 0 0 0 0 0 0 1 1 0 1 0 1 0 1 0 1 0 1 1 0 1 1 0 0 0 1 1\n",
            " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 1 0 1 0 0 1 1 1 0 1 1 0 1 0 0 0\n",
            " 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 1 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0\n",
            " 1 1 1 0 0 1 0 0 1 1 0 0 0 1 1 0 0 1 0 0 0 0 1 1 0 1 1 0 0 0 0 1 1 1 0 1 0\n",
            " 0 0 0 0 0 0 0 0 0 1 1 0 1 0 1 1 0 1 0 0 1 0 1 0 0 1 0 1 0 0 0 1 1 0 0 0 0\n",
            " 1 0 1 0 0 1 1 0 1 1 1 0 0 0 0 0 0 0 0 1 1 1 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0\n",
            " 1 0 1 0 0 0 1 0 0 0 0 1 1 0 0 0 1 0 1 1 0 1 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0\n",
            " 0 1 0 1 0 0 0 0 0 0 0 1 1 1 1 1 0 1 1 0 1 1 1 0 1 0 1 1 1 1 0 1 0 0 0 0 0\n",
            " 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 1 1 0 1 0 0 1\n",
            " 1 1 0 1 1 0 1 0 1 0 0 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 1\n",
            " 0 1 1 1 1 0 0 1 0 1 1 0 0 1 1 0 0 1 0 1 1 0 0 1 0 0 1 0 0 1 1 0 1 1 1 0 0\n",
            " 0 1 1 1 0 0 0 1 1 0 0 0 0 0 1 1 0 0]\n",
            "trainset before adding uncertain samples (470, 10) (470,)\n",
            "trainset after adding uncertain samples (480, 10) (480,)\n",
            "updated train set: (480, 10) (480,) unique(labels): [118 362] [0 1]\n",
            "val set: (822, 10) (822,)\n",
            "\n",
            "Train set: (480, 10)\n",
            "Validation set: (822, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: divide by zero encountered in log2\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: invalid value encountered in multiply\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: divide by zero encountered in log2\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: invalid value encountered in multiply\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "--------------------------------\n",
            "Iteration: 48\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.079 s \n",
            "\n",
            "Accuracy rate is 76.728111 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.85      0.84       321\n",
            "           1       0.56      0.52      0.54       113\n",
            "\n",
            "    accuracy                           0.77       434\n",
            "   macro avg       0.70      0.69      0.69       434\n",
            "weighted avg       0.76      0.77      0.76       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[274  47]\n",
            " [ 54  59]]\n",
            "--------------------------------\n",
            "val predicted: (822,) [1 0 0 1 0 1 1 0 0 1 0 1 1 0 0 0 1 0 0 0 1 0 0 1 0 0 1 1 1 1 0 1 0 0 0 0 1\n",
            " 1 0 1 1 0 0 1 1 1 1 0 0 0 1 0 1 1 0 0 0 1 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1\n",
            " 1 1 0 1 0 1 1 0 0 0 0 0 1 0 1 0 1 0 0 1 1 0 0 0 0 0 1 0 1 0 0 0 1 0 1 0 1\n",
            " 1 0 0 1 1 0 0 0 1 0 1 1 1 0 1 1 0 0 1 0 0 1 1 0 1 0 0 0 0 0 0 1 0 0 0 1 1\n",
            " 1 1 0 1 1 0 0 1 0 1 1 1 1 0 0 0 1 1 0 0 0 1 0 0 1 1 1 0 1 1 0 0 0 0 1 1 0\n",
            " 1 0 1 0 1 0 1 1 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 1 1 0 0 0 1 0 0 1 0 0 0 0 0\n",
            " 1 1 1 0 0 1 1 1 0 0 0 1 0 0 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0\n",
            " 0 0 0 0 1 0 1 1 1 0 0 0 1 1 0 1 0 0 1 1 1 0 1 0 1 1 0 1 0 0 1 0 1 1 0 1 1\n",
            " 0 1 0 0 0 1 1 1 1 1 1 0 0 1 0 0 0 0 0 1 1 0 0 1 0 0 0 1 0 1 1 0 0 0 1 1 0\n",
            " 1 1 0 1 0 0 1 0 0 0 0 0 1 0 0 1 1 0 0 1 0 0 0 1 0 1 0 1 0 1 1 0 1 1 0 1 0\n",
            " 0 1 1 0 1 0 1 1 0 0 0 1 0 0 0 1 1 0 1 0 0 0 0 1 1 1 1 0 0 1 0 0 0 1 1 0 0\n",
            " 0 1 0 1 0 0 0 0 0 0 1 1 0 1 0 1 0 1 0 1 0 1 1 0 1 1 0 0 0 1 1 0 0 0 1 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 1 0 0 1 1 1 0 1 1 0 1 0 0 0 0 0 0 1 1 1 0\n",
            " 0 0 0 0 0 0 0 0 1 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 1 1 0 0 1 0\n",
            " 0 1 1 0 1 0 1 1 0 0 1 0 0 0 0 1 1 0 1 1 0 0 0 0 1 1 1 0 1 0 0 0 0 0 0 0 0\n",
            " 0 0 1 1 0 1 0 1 1 0 1 0 0 1 0 1 0 0 1 0 1 0 0 0 1 1 0 0 0 0 1 0 1 0 0 1 1\n",
            " 0 1 1 1 0 0 0 0 0 0 0 0 1 1 1 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 1 0 1 0 0 0 1\n",
            " 0 0 0 0 1 1 0 0 0 1 0 1 0 1 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0\n",
            " 0 0 0 1 1 1 1 1 0 1 1 0 1 1 1 0 1 0 1 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
            " 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 1 1 0 1 0 0 1 1 0 1 1 0 1 0 1\n",
            " 0 0 1 1 0 0 1 1 1 1 1 1 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 1 1 1 1 0 0 1 0\n",
            " 1 1 0 0 1 1 0 0 1 0 1 1 0 0 1 0 0 1 0 0 1 0 1 1 1 0 0 0 1 1 1 0 0 0 1 1 0\n",
            " 0 0 0 0 1 1 0 0]\n",
            "probabilities: (822, 2) \n",
            " [1 0 0 1 0 1 1 0 0 1 0 1 1 0 0 0 1 0 0 0 1 0 0 1 0 0 1 1 1 1 0 1 0 0 0 0 1\n",
            " 1 0 1 1 0 0 1 1 1 1 0 0 0 1 0 1 1 0 0 0 1 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1\n",
            " 1 1 0 1 0 1 1 0 0 0 0 0 1 0 1 0 1 0 0 1 1 0 0 0 0 0 1 0 1 0 0 0 1 0 1 0 1\n",
            " 1 0 0 1 1 0 0 0 1 0 1 1 1 0 1 1 0 0 1 0 0 1 1 0 1 0 0 0 0 0 0 1 0 0 0 1 1\n",
            " 1 1 0 1 1 0 0 1 0 1 1 1 1 0 0 0 1 1 0 0 0 1 0 0 1 1 1 0 1 1 0 0 0 0 1 1 0\n",
            " 1 0 1 0 1 0 1 1 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 1 1 0 0 0 1 0 0 1 0 0 0 0 0\n",
            " 1 1 1 0 0 1 1 1 0 0 0 1 0 0 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0\n",
            " 0 0 0 0 1 0 1 1 1 0 0 0 1 1 0 1 0 0 1 1 1 0 1 0 1 1 0 1 0 0 1 0 1 1 0 1 1\n",
            " 0 1 0 0 0 1 1 1 1 1 1 0 0 1 0 0 0 0 0 1 1 0 0 1 0 0 0 1 0 1 1 0 0 0 1 1 0\n",
            " 1 1 0 1 0 0 1 0 0 0 0 0 1 0 0 1 1 0 0 1 0 0 0 1 0 1 0 1 0 1 1 0 1 1 0 1 0\n",
            " 0 1 1 0 1 0 1 1 0 0 0 1 0 0 0 1 1 0 1 0 0 0 0 1 1 1 1 0 0 1 0 0 0 1 1 0 0\n",
            " 0 1 0 1 0 0 0 0 0 0 1 1 0 1 0 1 0 1 0 1 0 1 1 0 1 1 0 0 0 1 1 0 0 0 1 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 1 0 0 1 1 1 0 1 1 0 1 0 0 0 0 0 0 1 1 1 0\n",
            " 0 0 0 0 0 0 0 0 1 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 1 1 0 0 1 0\n",
            " 0 1 1 0 1 0 1 1 0 0 1 0 0 0 0 1 1 0 1 1 0 0 0 0 1 1 1 0 1 0 0 0 0 0 0 0 0\n",
            " 0 0 1 1 0 1 0 1 1 0 1 0 0 1 0 1 0 0 1 0 1 0 0 0 1 1 0 0 0 0 1 0 1 0 0 1 1\n",
            " 0 1 1 1 0 0 0 0 0 0 0 0 1 1 1 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 1 0 1 0 0 0 1\n",
            " 0 0 0 0 1 1 0 0 0 1 0 1 0 1 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0\n",
            " 0 0 0 1 1 1 1 1 0 1 1 0 1 1 1 0 1 0 1 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
            " 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 1 1 0 1 0 0 1 1 0 1 1 0 1 0 1\n",
            " 0 0 1 1 0 0 1 1 1 1 1 1 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 1 1 1 1 0 0 1 0\n",
            " 1 1 0 0 1 1 0 0 1 0 1 1 0 0 1 0 0 1 0 0 1 0 1 1 1 0 0 0 1 1 1 0 0 0 1 1 0\n",
            " 0 0 0 0 1 1 0 0]\n",
            "trainset before adding uncertain samples (480, 10) (480,)\n",
            "trainset after adding uncertain samples (490, 10) (490,)\n",
            "updated train set: (490, 10) (490,) unique(labels): [123 367] [0 1]\n",
            "val set: (812, 10) (812,)\n",
            "\n",
            "Train set: (490, 10)\n",
            "Validation set: (812, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 49\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.071 s \n",
            "\n",
            "Accuracy rate is 77.188940 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.85      0.85       321\n",
            "           1       0.56      0.55      0.56       113\n",
            "\n",
            "    accuracy                           0.77       434\n",
            "   macro avg       0.70      0.70      0.70       434\n",
            "weighted avg       0.77      0.77      0.77       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[273  48]\n",
            " [ 51  62]]\n",
            "--------------------------------\n",
            "val predicted: (812,) [1 0 0 0 0 1 1 0 0 1 0 1 1 0 0 1 0 0 0 1 0 0 1 0 1 1 1 1 0 1 0 0 0 0 0 1 0\n",
            " 1 1 0 0 1 1 1 1 0 0 0 1 0 1 1 0 0 0 1 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 1 1\n",
            " 0 1 0 1 1 0 0 0 0 0 1 0 1 0 1 0 0 1 1 0 0 0 0 0 1 0 1 0 0 0 1 0 1 0 1 1 0\n",
            " 0 1 1 0 0 0 1 0 1 1 1 0 1 1 0 0 1 0 0 1 1 0 1 0 0 0 0 0 1 0 1 0 1 1 1 1 0\n",
            " 1 1 0 0 1 0 1 1 1 1 0 0 0 1 1 0 0 0 1 0 0 1 1 1 0 1 1 0 0 0 0 1 1 0 1 0 1\n",
            " 0 1 0 1 1 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 1 1 0 1 0 1 0 0 1 0 0 0 0 0 1 1 1\n",
            " 0 0 1 1 1 1 0 0 1 0 0 1 0 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0\n",
            " 0 1 0 1 1 1 0 0 0 1 1 1 0 0 1 1 1 0 1 0 1 1 0 1 0 0 1 0 1 1 0 1 1 0 1 0 1\n",
            " 0 1 1 1 1 1 0 0 1 0 0 0 0 0 1 1 0 0 1 0 0 0 1 0 1 1 0 0 0 1 1 0 1 1 0 1 0\n",
            " 0 1 0 0 1 0 0 1 0 0 1 1 0 0 1 0 0 0 1 0 1 0 0 0 1 1 0 1 1 0 1 0 0 1 1 0 1\n",
            " 0 1 1 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 1 1 1 1 0 0 1 0 0 0 1 1 0 0 0 1 0 1 0\n",
            " 0 0 0 0 1 1 0 1 0 1 0 1 1 1 0 1 1 0 1 1 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 1 0 0 1 1 0 1 0 0 1 1 1 0 1 1 0 1 0 0 0 0 0 0 1 1 1 0 0 1 0 0 0 0\n",
            " 0 0 1 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 1 1 0 0 1 0 0 1 1 0 1 0\n",
            " 1 1 0 0 1 0 0 0 0 1 1 0 1 1 0 0 0 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 1\n",
            " 0 1 1 0 1 0 0 1 0 1 0 0 1 0 1 0 0 1 1 1 0 0 0 0 1 0 1 0 0 1 1 0 1 1 1 0 0\n",
            " 0 0 0 0 0 1 1 1 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 1 1 0\n",
            " 0 0 1 0 1 0 1 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 1 1 1 1\n",
            " 0 1 1 0 1 1 1 0 1 0 1 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0\n",
            " 0 1 0 1 0 0 0 0 0 0 0 1 1 1 0 1 0 0 1 1 0 1 1 1 1 0 1 0 0 1 1 0 0 1 1 1 1\n",
            " 1 1 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 1 1 1 1 0 0 1 0 1 1 0 1 1 1 0 0 1 0\n",
            " 1 1 0 0 1 0 0 1 0 0 1 0 1 1 1 0 0 0 1 1 1 0 0 0 1 1 0 0 0 0 0 1 1 0 0]\n",
            "probabilities: (812, 2) \n",
            " [1 0 0 0 0 1 1 0 0 1 0 1 1 0 0 1 0 0 0 1 0 0 1 0 1 1 1 1 0 1 0 0 0 0 0 1 0\n",
            " 1 1 0 0 1 1 1 1 0 0 0 1 0 1 1 0 0 0 1 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 1 1\n",
            " 0 1 0 1 1 0 0 0 0 0 1 0 1 0 1 0 0 1 1 0 0 0 0 0 1 0 1 0 0 0 1 0 1 0 1 1 0\n",
            " 0 1 1 0 0 0 1 0 1 1 1 0 1 1 0 0 1 0 0 1 1 0 1 0 0 0 0 0 1 0 1 0 1 1 1 1 0\n",
            " 1 1 0 0 1 0 1 1 1 1 0 0 0 1 1 0 0 0 1 0 0 1 1 1 0 1 1 0 0 0 0 1 1 0 1 0 1\n",
            " 0 1 0 1 1 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 1 1 0 1 0 1 0 0 1 0 0 0 0 0 1 1 1\n",
            " 0 0 1 1 1 1 0 0 1 0 0 1 0 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0\n",
            " 0 1 0 1 1 1 0 0 0 1 1 1 0 0 1 1 1 0 1 0 1 1 0 1 0 0 1 0 1 1 0 1 1 0 1 0 1\n",
            " 0 1 1 1 1 1 0 0 1 0 0 0 0 0 1 1 0 0 1 0 0 0 1 0 1 1 0 0 0 1 1 0 1 1 0 1 0\n",
            " 0 1 0 0 1 0 0 1 0 0 1 1 0 0 1 0 0 0 1 0 1 0 0 0 1 1 0 1 1 0 1 0 0 1 1 0 1\n",
            " 0 1 1 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 1 1 1 1 0 0 1 0 0 0 1 1 0 0 0 1 0 1 0\n",
            " 0 0 0 0 1 1 0 1 0 1 0 1 1 1 0 1 1 0 1 1 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 1 0 0 1 1 0 1 0 0 1 1 1 0 1 1 0 1 0 0 0 0 0 0 1 1 1 0 0 1 0 0 0 0\n",
            " 0 0 1 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 1 1 0 0 1 0 0 1 1 0 1 0\n",
            " 1 1 0 0 1 0 0 0 0 1 1 0 1 1 0 0 0 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 1\n",
            " 0 1 1 0 1 0 0 1 0 1 0 0 1 0 1 0 0 1 1 1 0 0 0 0 1 0 1 0 0 1 1 0 1 1 1 0 0\n",
            " 0 0 0 0 0 1 1 1 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 1 1 0\n",
            " 0 0 1 0 1 0 1 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 1 1 1 1\n",
            " 0 1 1 0 1 1 1 0 1 0 1 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0\n",
            " 0 1 0 1 0 0 0 0 0 0 0 1 1 1 0 1 0 0 1 1 0 1 1 1 1 0 1 0 0 1 1 0 0 1 1 1 1\n",
            " 1 1 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 1 1 1 1 0 0 1 0 1 1 0 1 1 1 0 0 1 0\n",
            " 1 1 0 0 1 0 0 1 0 0 1 0 1 1 1 0 0 0 1 1 1 0 0 0 1 1 0 0 0 0 0 1 1 0 0]\n",
            "trainset before adding uncertain samples (490, 10) (490,)\n",
            "trainset after adding uncertain samples (500, 10) (500,)\n",
            "updated train set: (500, 10) (500,) unique(labels): [129 371] [0 1]\n",
            "val set: (802, 10) (802,)\n",
            "\n",
            "Train set: (500, 10)\n",
            "Validation set: (802, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: divide by zero encountered in log2\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: invalid value encountered in multiply\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: divide by zero encountered in log2\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "<ipython-input-42-82e50070648f>:24: RuntimeWarning: invalid value encountered in multiply\n",
            "  e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
            "--------------------------------\n",
            "Iteration: 50\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.069 s \n",
            "\n",
            "Accuracy rate is 77.188940 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.85      0.85       321\n",
            "           1       0.56      0.54      0.55       113\n",
            "\n",
            "    accuracy                           0.77       434\n",
            "   macro avg       0.70      0.70      0.70       434\n",
            "weighted avg       0.77      0.77      0.77       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[274  47]\n",
            " [ 52  61]]\n",
            "--------------------------------\n",
            "final active learning accuracies [26.036866359447004, 33.87096774193548, 28.110599078341014, 27.64976958525346, 36.175115207373274, 36.405529953917046, 31.566820276497698, 31.566820276497698, 29.262672811059907, 33.6405529953917, 34.7926267281106, 41.244239631336406, 40.55299539170507, 41.244239631336406, 41.244239631336406, 41.474654377880185, 41.244239631336406, 42.3963133640553, 42.16589861751152, 42.3963133640553, 41.013824884792626, 41.935483870967744, 42.3963133640553, 41.705069124423964, 48.61751152073733, 44.23963133640553, 42.857142857142854, 41.935483870967744, 44.47004608294931, 44.70046082949309, 45.622119815668206, 44.23963133640553, 44.23963133640553, 45.852534562211986, 60.82949308755761, 58.06451612903226, 56.68202764976959, 54.60829493087558, 59.44700460829493, 73.27188940092167, 76.72811059907833, 76.26728110599078, 75.57603686635944, 75.57603686635944, 76.49769585253456, 76.95852534562212, 76.95852534562212, 76.72811059907833, 77.18894009216591, 77.18894009216591]\n",
            "saved /Users/wenxuanhuang/Documents/Repo/ML-for-COVID-19-dataset/Results/Active-learning-experiment-35.pkl /Users/wenxuanhuang/Documents/Repo/ML-for-COVID-19-dataset ['Decision_tree.ipynb', 'dec_git.png', 'Logit_default_f10.pdf', 'Logistic.ipynb', 'SVC.ipynb', 'RF_f5e50_featureimp.pdf', 'log_al.png', 'dec_git.pdf', '.DS_Store', 'log_git.png', 'svm_git.png', 'Logistic_Scikit.ipynb', 'knn_git.pdf', 'knn_git.png', 'rf_al.png', 'Best classifier_RF_f5e50.pdf', 'KNN.ipynb', 'GBDC.ipynb', 'rf_git.png', 'README.md', 'all_training.csv', 'Results', 'svm_al.png', 'Log_ROC.png', 'Logit_default_f7(p_removal).pdf', 'Active_learning.ipynb', 'Random_forest.ipynb', 'Model_select.ipynb', 'gdbc_git.png', '.git', '.vscode', 'Untitled', 'RF_f5e50_modelselect.pdf', 'Logit_default_f8(std_removal).pdf']\n",
            "{\n",
            "  \"GDBCModel\": {\n",
            "    \"EntropySelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          65.2073732718894,\n",
            "          76.95852534562212,\n",
            "          75.11520737327189,\n",
            "          70.04608294930875,\n",
            "          72.35023041474655,\n",
            "          71.42857142857143,\n",
            "          77.41935483870968,\n",
            "          76.26728110599078,\n",
            "          77.41935483870968,\n",
            "          77.88018433179722,\n",
            "          78.57142857142857,\n",
            "          73.963133640553,\n",
            "          79.49308755760369,\n",
            "          79.03225806451613,\n",
            "          79.49308755760369,\n",
            "          79.26267281105991,\n",
            "          78.3410138248848,\n",
            "          78.57142857142857,\n",
            "          79.03225806451613,\n",
            "          80.18433179723502,\n",
            "          79.95391705069125,\n",
            "          80.18433179723502,\n",
            "          78.80184331797236,\n",
            "          79.49308755760369,\n",
            "          79.72350230414746,\n",
            "          80.18433179723502,\n",
            "          79.95391705069125,\n",
            "          81.5668202764977,\n",
            "          81.79723502304147,\n",
            "          81.5668202764977,\n",
            "          81.33640552995391,\n",
            "          80.64516129032258,\n",
            "          80.4147465437788,\n",
            "          81.10599078341014,\n",
            "          79.49308755760369,\n",
            "          80.64516129032258,\n",
            "          80.87557603686636,\n",
            "          80.87557603686636,\n",
            "          79.49308755760369,\n",
            "          80.18433179723502,\n",
            "          79.72350230414746,\n",
            "          79.95391705069125,\n",
            "          78.80184331797236,\n",
            "          79.72350230414746,\n",
            "          79.49308755760369,\n",
            "          80.4147465437788,\n",
            "          79.49308755760369,\n",
            "          80.4147465437788,\n",
            "          79.72350230414746,\n",
            "          79.95391705069125\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          77.41935483870968,\n",
            "          79.03225806451613,\n",
            "          80.64516129032258,\n",
            "          80.18433179723502\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          70.04608294930875,\n",
            "          76.49769585253456,\n",
            "          79.03225806451613,\n",
            "          78.57142857142857,\n",
            "          77.64976958525345,\n",
            "          78.80184331797236,\n",
            "          78.80184331797236,\n",
            "          77.41935483870968,\n",
            "          77.88018433179722,\n",
            "          77.64976958525345,\n",
            "          79.03225806451613,\n",
            "          77.88018433179722,\n",
            "          78.80184331797236,\n",
            "          78.80184331797236,\n",
            "          79.26267281105991,\n",
            "          79.72350230414746,\n",
            "          79.03225806451613,\n",
            "          79.72350230414746,\n",
            "          80.4147465437788,\n",
            "          80.87557603686636\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          78.57142857142857,\n",
            "          80.4147465437788\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          75.34562211981567,\n",
            "          80.64516129032258,\n",
            "          79.95391705069125,\n",
            "          79.03225806451613,\n",
            "          80.64516129032258,\n",
            "          80.18433179723502,\n",
            "          79.95391705069125,\n",
            "          79.49308755760369,\n",
            "          79.72350230414746,\n",
            "          79.49308755760369\n",
            "        ]\n",
            "      ]\n",
            "    },\n",
            "    \"MarginSamplingSelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          49.07834101382488,\n",
            "          63.133640552995395,\n",
            "          72.58064516129032,\n",
            "          68.89400921658986,\n",
            "          72.58064516129032,\n",
            "          76.036866359447,\n",
            "          75.34562211981567,\n",
            "          74.19354838709677,\n",
            "          74.65437788018433,\n",
            "          73.73271889400922,\n",
            "          75.11520737327189,\n",
            "          70.50691244239631,\n",
            "          75.57603686635944,\n",
            "          75.34562211981567,\n",
            "          75.11520737327189,\n",
            "          75.80645161290323,\n",
            "          76.72811059907833,\n",
            "          76.49769585253456,\n",
            "          77.41935483870968,\n",
            "          77.18894009216591,\n",
            "          77.41935483870968,\n",
            "          76.95852534562212,\n",
            "          78.80184331797236,\n",
            "          78.3410138248848,\n",
            "          78.57142857142857,\n",
            "          79.72350230414746,\n",
            "          79.72350230414746,\n",
            "          79.26267281105991,\n",
            "          79.49308755760369,\n",
            "          79.49308755760369,\n",
            "          79.26267281105991,\n",
            "          78.57142857142857,\n",
            "          79.03225806451613,\n",
            "          79.49308755760369,\n",
            "          79.95391705069125,\n",
            "          79.95391705069125,\n",
            "          80.18433179723502,\n",
            "          79.95391705069125,\n",
            "          80.64516129032258,\n",
            "          79.49308755760369,\n",
            "          78.57142857142857,\n",
            "          78.80184331797236,\n",
            "          78.57142857142857,\n",
            "          79.03225806451613,\n",
            "          79.26267281105991,\n",
            "          78.57142857142857,\n",
            "          79.26267281105991,\n",
            "          78.80184331797236,\n",
            "          79.26267281105991,\n",
            "          79.49308755760369\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          76.95852534562212,\n",
            "          78.80184331797236,\n",
            "          79.03225806451613,\n",
            "          81.10599078341014\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          74.65437788018433,\n",
            "          69.81566820276498,\n",
            "          80.18433179723502,\n",
            "          72.11981566820278,\n",
            "          72.81105990783409,\n",
            "          73.73271889400922,\n",
            "          73.50230414746544,\n",
            "          78.57142857142857,\n",
            "          78.57142857142857,\n",
            "          81.10599078341014,\n",
            "          80.64516129032258,\n",
            "          78.80184331797236,\n",
            "          79.26267281105991,\n",
            "          80.18433179723502,\n",
            "          79.72350230414746,\n",
            "          79.26267281105991,\n",
            "          79.95391705069125,\n",
            "          79.72350230414746,\n",
            "          79.95391705069125,\n",
            "          79.72350230414746\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          76.26728110599078,\n",
            "          79.26267281105991\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          78.11059907834101,\n",
            "          78.11059907834101,\n",
            "          78.57142857142857,\n",
            "          78.57142857142857,\n",
            "          80.4147465437788,\n",
            "          80.18433179723502,\n",
            "          79.95391705069125,\n",
            "          79.72350230414746,\n",
            "          79.49308755760369,\n",
            "          78.80184331797236\n",
            "        ]\n",
            "      ]\n",
            "    },\n",
            "    \"MinStdSelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          73.73271889400922,\n",
            "          77.18894009216591,\n",
            "          77.18894009216591,\n",
            "          76.72811059907833,\n",
            "          71.19815668202764,\n",
            "          76.49769585253456,\n",
            "          77.88018433179722,\n",
            "          78.11059907834101,\n",
            "          77.88018433179722,\n",
            "          77.88018433179722,\n",
            "          79.03225806451613,\n",
            "          79.03225806451613,\n",
            "          79.72350230414746,\n",
            "          78.57142857142857,\n",
            "          79.26267281105991,\n",
            "          79.26267281105991,\n",
            "          75.34562211981567,\n",
            "          73.50230414746544,\n",
            "          74.42396313364056,\n",
            "          73.963133640553,\n",
            "          74.19354838709677,\n",
            "          73.963133640553,\n",
            "          74.19354838709677,\n",
            "          74.42396313364056,\n",
            "          75.80645161290323,\n",
            "          75.80645161290323,\n",
            "          74.88479262672811,\n",
            "          74.65437788018433,\n",
            "          74.65437788018433,\n",
            "          75.34562211981567,\n",
            "          75.80645161290323,\n",
            "          80.87557603686636,\n",
            "          80.18433179723502,\n",
            "          80.64516129032258,\n",
            "          80.87557603686636,\n",
            "          81.10599078341014,\n",
            "          81.5668202764977,\n",
            "          81.5668202764977,\n",
            "          81.10599078341014,\n",
            "          81.33640552995391,\n",
            "          81.5668202764977,\n",
            "          82.7188940092166,\n",
            "          82.25806451612904,\n",
            "          82.25806451612904,\n",
            "          81.79723502304147,\n",
            "          80.4147465437788,\n",
            "          80.87557603686636,\n",
            "          81.10599078341014,\n",
            "          80.87557603686636,\n",
            "          81.33640552995391\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          78.3410138248848,\n",
            "          76.036866359447,\n",
            "          80.18433179723502,\n",
            "          79.72350230414746\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          77.64976958525345,\n",
            "          77.88018433179722,\n",
            "          73.04147465437788,\n",
            "          74.19354838709677,\n",
            "          80.64516129032258,\n",
            "          80.18433179723502,\n",
            "          79.72350230414746,\n",
            "          80.87557603686636,\n",
            "          81.33640552995391,\n",
            "          80.87557603686636,\n",
            "          79.49308755760369,\n",
            "          80.18433179723502,\n",
            "          80.87557603686636,\n",
            "          80.87557603686636,\n",
            "          80.87557603686636,\n",
            "          80.87557603686636,\n",
            "          81.33640552995391,\n",
            "          81.33640552995391,\n",
            "          80.18433179723502,\n",
            "          80.4147465437788\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          75.11520737327189,\n",
            "          79.26267281105991\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          79.95391705069125,\n",
            "          76.95852534562212,\n",
            "          80.18433179723502,\n",
            "          79.49308755760369,\n",
            "          79.26267281105991,\n",
            "          79.72350230414746,\n",
            "          79.95391705069125,\n",
            "          79.72350230414746,\n",
            "          79.72350230414746,\n",
            "          79.72350230414746\n",
            "        ]\n",
            "      ]\n",
            "    },\n",
            "    \"RandomSelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          63.36405529953917,\n",
            "          70.73732718894009,\n",
            "          61.29032258064516,\n",
            "          63.594470046082954,\n",
            "          74.65437788018433,\n",
            "          75.80645161290323,\n",
            "          76.49769585253456,\n",
            "          76.49769585253456,\n",
            "          77.41935483870968,\n",
            "          76.72811059907833,\n",
            "          78.3410138248848,\n",
            "          78.80184331797236,\n",
            "          77.41935483870968,\n",
            "          79.49308755760369,\n",
            "          77.64976958525345,\n",
            "          76.95852534562212,\n",
            "          77.18894009216591,\n",
            "          76.95852534562212,\n",
            "          77.64976958525345,\n",
            "          78.11059907834101,\n",
            "          78.11059907834101,\n",
            "          77.64976958525345,\n",
            "          77.64976958525345,\n",
            "          78.3410138248848,\n",
            "          78.57142857142857,\n",
            "          77.64976958525345,\n",
            "          77.64976958525345,\n",
            "          77.41935483870968,\n",
            "          77.88018433179722,\n",
            "          77.88018433179722,\n",
            "          77.88018433179722,\n",
            "          78.11059907834101,\n",
            "          77.64976958525345,\n",
            "          78.3410138248848,\n",
            "          78.80184331797236,\n",
            "          79.26267281105991,\n",
            "          78.57142857142857,\n",
            "          77.88018433179722,\n",
            "          77.64976958525345,\n",
            "          77.64976958525345,\n",
            "          78.11059907834101,\n",
            "          79.72350230414746,\n",
            "          79.72350230414746,\n",
            "          79.49308755760369,\n",
            "          79.03225806451613,\n",
            "          79.72350230414746,\n",
            "          78.80184331797236,\n",
            "          78.57142857142857,\n",
            "          79.49308755760369,\n",
            "          79.26267281105991\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          72.58064516129032,\n",
            "          72.58064516129032,\n",
            "          76.036866359447,\n",
            "          76.26728110599078\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          72.35023041474655,\n",
            "          72.11981566820278,\n",
            "          71.88940092165899,\n",
            "          73.04147465437788,\n",
            "          72.81105990783409,\n",
            "          75.11520737327189,\n",
            "          73.50230414746544,\n",
            "          76.036866359447,\n",
            "          76.26728110599078,\n",
            "          76.49769585253456,\n",
            "          76.72811059907833,\n",
            "          77.18894009216591,\n",
            "          76.72811059907833,\n",
            "          78.11059907834101,\n",
            "          78.3410138248848,\n",
            "          77.64976958525345,\n",
            "          79.72350230414746,\n",
            "          79.95391705069125,\n",
            "          80.18433179723502,\n",
            "          80.87557603686636\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          78.3410138248848,\n",
            "          79.95391705069125\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          69.35483870967742,\n",
            "          76.72811059907833,\n",
            "          78.3410138248848,\n",
            "          78.57142857142857,\n",
            "          78.80184331797236,\n",
            "          79.95391705069125,\n",
            "          79.26267281105991,\n",
            "          79.03225806451613,\n",
            "          79.03225806451613,\n",
            "          78.80184331797236\n",
            "        ]\n",
            "      ]\n",
            "    }\n",
            "  },\n",
            "  \"KnnModel\": {\n",
            "    \"EntropySelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          26.036866359447004,\n",
            "          33.87096774193548,\n",
            "          28.110599078341014,\n",
            "          27.64976958525346,\n",
            "          36.175115207373274,\n",
            "          36.405529953917046,\n",
            "          31.566820276497698,\n",
            "          31.566820276497698,\n",
            "          29.262672811059907,\n",
            "          33.6405529953917,\n",
            "          34.7926267281106,\n",
            "          41.244239631336406,\n",
            "          40.55299539170507,\n",
            "          41.244239631336406,\n",
            "          41.244239631336406,\n",
            "          41.474654377880185,\n",
            "          41.244239631336406,\n",
            "          42.3963133640553,\n",
            "          42.16589861751152,\n",
            "          42.3963133640553,\n",
            "          41.013824884792626,\n",
            "          41.935483870967744,\n",
            "          42.3963133640553,\n",
            "          41.705069124423964,\n",
            "          48.61751152073733,\n",
            "          44.23963133640553,\n",
            "          42.857142857142854,\n",
            "          41.935483870967744,\n",
            "          44.47004608294931,\n",
            "          44.70046082949309,\n",
            "          45.622119815668206,\n",
            "          44.23963133640553,\n",
            "          44.23963133640553,\n",
            "          45.852534562211986,\n",
            "          60.82949308755761,\n",
            "          58.06451612903226,\n",
            "          56.68202764976959,\n",
            "          54.60829493087558,\n",
            "          59.44700460829493,\n",
            "          73.27188940092167,\n",
            "          76.72811059907833,\n",
            "          76.26728110599078,\n",
            "          75.57603686635944,\n",
            "          75.57603686635944,\n",
            "          76.49769585253456,\n",
            "          76.95852534562212,\n",
            "          76.95852534562212,\n",
            "          76.72811059907833,\n",
            "          77.18894009216591,\n",
            "          77.18894009216591\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          78.11059907834101,\n",
            "          78.11059907834101,\n",
            "          79.72350230414746,\n",
            "          78.57142857142857\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          77.64976958525345,\n",
            "          76.036866359447,\n",
            "          77.64976958525345,\n",
            "          77.64976958525345,\n",
            "          77.18894009216591,\n",
            "          77.64976958525345,\n",
            "          77.41935483870968,\n",
            "          76.72811059907833,\n",
            "          76.26728110599078,\n",
            "          76.49769585253456,\n",
            "          74.65437788018433,\n",
            "          74.65437788018433,\n",
            "          74.88479262672811,\n",
            "          75.57603686635944,\n",
            "          75.57603686635944,\n",
            "          74.42396313364056,\n",
            "          74.65437788018433,\n",
            "          75.11520737327189,\n",
            "          75.57603686635944,\n",
            "          75.80645161290323\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          77.18894009216591,\n",
            "          77.88018433179722\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          79.72350230414746,\n",
            "          78.80184331797236,\n",
            "          78.80184331797236,\n",
            "          76.26728110599078,\n",
            "          76.26728110599078,\n",
            "          77.18894009216591,\n",
            "          78.80184331797236,\n",
            "          77.41935483870968,\n",
            "          78.11059907834101,\n",
            "          77.64976958525345\n",
            "        ]\n",
            "      ]\n",
            "    },\n",
            "    \"MarginSamplingSelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          26.036866359447004,\n",
            "          71.42857142857143,\n",
            "          76.036866359447,\n",
            "          78.3410138248848,\n",
            "          78.57142857142857,\n",
            "          77.64976958525345,\n",
            "          76.72811059907833,\n",
            "          77.41935483870968,\n",
            "          79.03225806451613,\n",
            "          78.11059907834101,\n",
            "          76.95852534562212,\n",
            "          78.57142857142857,\n",
            "          77.88018433179722,\n",
            "          79.26267281105991,\n",
            "          79.26267281105991,\n",
            "          79.72350230414746,\n",
            "          80.64516129032258,\n",
            "          81.10599078341014,\n",
            "          78.80184331797236,\n",
            "          78.3410138248848,\n",
            "          80.18433179723502,\n",
            "          79.49308755760369,\n",
            "          80.87557603686636,\n",
            "          80.4147465437788,\n",
            "          80.64516129032258,\n",
            "          80.64516129032258,\n",
            "          80.18433179723502,\n",
            "          79.72350230414746,\n",
            "          80.18433179723502,\n",
            "          80.18433179723502,\n",
            "          80.18433179723502,\n",
            "          80.87557603686636,\n",
            "          81.5668202764977,\n",
            "          80.64516129032258,\n",
            "          80.87557603686636,\n",
            "          81.5668202764977,\n",
            "          81.79723502304147,\n",
            "          79.03225806451613,\n",
            "          78.3410138248848,\n",
            "          79.03225806451613,\n",
            "          78.80184331797236,\n",
            "          78.57142857142857,\n",
            "          78.3410138248848,\n",
            "          78.3410138248848,\n",
            "          77.41935483870968,\n",
            "          78.3410138248848,\n",
            "          77.88018433179722,\n",
            "          78.80184331797236,\n",
            "          78.3410138248848,\n",
            "          78.11059907834101\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          77.18894009216591,\n",
            "          77.64976958525345,\n",
            "          78.57142857142857,\n",
            "          79.72350230414746\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          44.00921658986175,\n",
            "          77.88018433179722,\n",
            "          72.81105990783409,\n",
            "          80.4147465437788,\n",
            "          78.80184331797236,\n",
            "          76.72811059907833,\n",
            "          79.26267281105991,\n",
            "          80.18433179723502,\n",
            "          78.80184331797236,\n",
            "          79.03225806451613,\n",
            "          79.72350230414746,\n",
            "          79.49308755760369,\n",
            "          79.26267281105991,\n",
            "          78.11059907834101,\n",
            "          78.3410138248848,\n",
            "          80.4147465437788,\n",
            "          80.64516129032258,\n",
            "          81.10599078341014,\n",
            "          80.18433179723502,\n",
            "          79.72350230414746\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          77.88018433179722,\n",
            "          80.18433179723502\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          79.72350230414746,\n",
            "          75.11520737327189,\n",
            "          78.80184331797236,\n",
            "          79.26267281105991,\n",
            "          80.64516129032258,\n",
            "          79.49308755760369,\n",
            "          78.11059907834101,\n",
            "          78.57142857142857,\n",
            "          77.88018433179722,\n",
            "          78.3410138248848\n",
            "        ]\n",
            "      ]\n",
            "    },\n",
            "    \"RandomSelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          26.036866359447004,\n",
            "          63.594470046082954,\n",
            "          72.58064516129032,\n",
            "          75.80645161290323,\n",
            "          73.73271889400922,\n",
            "          75.80645161290323,\n",
            "          76.26728110599078,\n",
            "          76.036866359447,\n",
            "          76.72811059907833,\n",
            "          77.18894009216591,\n",
            "          76.49769585253456,\n",
            "          74.88479262672811,\n",
            "          77.41935483870968,\n",
            "          76.49769585253456,\n",
            "          76.95852534562212,\n",
            "          76.72811059907833,\n",
            "          78.11059907834101,\n",
            "          77.64976958525345,\n",
            "          78.3410138248848,\n",
            "          77.18894009216591,\n",
            "          78.3410138248848,\n",
            "          78.57142857142857,\n",
            "          79.26267281105991,\n",
            "          78.80184331797236,\n",
            "          78.11059907834101,\n",
            "          77.88018433179722,\n",
            "          77.64976958525345,\n",
            "          77.64976958525345,\n",
            "          77.18894009216591,\n",
            "          76.95852534562212,\n",
            "          77.18894009216591,\n",
            "          77.18894009216591,\n",
            "          76.95852534562212,\n",
            "          77.41935483870968,\n",
            "          79.03225806451613,\n",
            "          78.57142857142857,\n",
            "          78.80184331797236,\n",
            "          78.3410138248848,\n",
            "          77.88018433179722,\n",
            "          77.88018433179722,\n",
            "          78.57142857142857,\n",
            "          78.80184331797236,\n",
            "          78.80184331797236,\n",
            "          78.11059907834101,\n",
            "          78.80184331797236,\n",
            "          78.80184331797236,\n",
            "          79.03225806451613,\n",
            "          78.57142857142857,\n",
            "          78.57142857142857,\n",
            "          78.57142857142857\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          76.036866359447,\n",
            "          77.18894009216591,\n",
            "          78.11059907834101,\n",
            "          78.3410138248848\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          71.88940092165899,\n",
            "          77.41935483870968,\n",
            "          74.19354838709677,\n",
            "          76.26728110599078,\n",
            "          77.41935483870968,\n",
            "          78.11059907834101,\n",
            "          77.64976958525345,\n",
            "          78.57142857142857,\n",
            "          78.80184331797236,\n",
            "          78.57142857142857,\n",
            "          78.80184331797236,\n",
            "          77.41935483870968,\n",
            "          77.18894009216591,\n",
            "          77.88018433179722,\n",
            "          78.11059907834101,\n",
            "          78.11059907834101,\n",
            "          77.41935483870968,\n",
            "          79.03225806451613,\n",
            "          78.57142857142857,\n",
            "          79.26267281105991\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          76.036866359447,\n",
            "          77.64976958525345\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          78.11059907834101,\n",
            "          77.88018433179722,\n",
            "          76.95852534562212,\n",
            "          77.18894009216591,\n",
            "          76.49769585253456,\n",
            "          76.95852534562212,\n",
            "          76.95852534562212,\n",
            "          78.11059907834101,\n",
            "          77.41935483870968,\n",
            "          78.57142857142857\n",
            "        ]\n",
            "      ]\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "---------------------------- FINISHED ---------------------------\n",
            "\n",
            "Count = 36, using model = KnnModel, selection_function = MinStdSelection, k = 250, iteration = 0.\n",
            "\n",
            "initial random chosen samples (250,)\n",
            "initial train set: (250, 10) (250,) unique(labels): [114 136] [0 1]\n",
            "Val set: (1052, 10) (1052,) (250,)\n",
            "\n",
            "Train set: (250, 10)\n",
            "Validation set: (1052, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.086 s \n",
            "\n",
            "Accuracy rate is 76.728111 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.85      0.84       321\n",
            "           1       0.56      0.52      0.54       113\n",
            "\n",
            "    accuracy                           0.77       434\n",
            "   macro avg       0.70      0.69      0.69       434\n",
            "weighted avg       0.76      0.77      0.76       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[274  47]\n",
            " [ 54  59]]\n",
            "--------------------------------\n",
            "val predicted: (1052,) [0 1 1 ... 0 0 1]\n",
            "probabilities: (1052, 2) \n",
            " [0 1 1 ... 0 0 1]\n",
            "std (1052,) [10. 50. 10. ... 20. 30. 10.]\n",
            "selection [ 759  667  829  298  823  299  593  106   39  306   77  455  329  332\n",
            "  489  758  755  742   52  438  383  635  725  396  692  657  851  853\n",
            "  297  461  176 1036    3    5  496 1022   91 1012  468  465  937  224\n",
            "  211  144  861  874  554  547  927  242   65  895  147  463  462  440\n",
            "  466  459  446  469  436  433  458  428  441  456    0  419  178  190\n",
            "  195  199  207  220  231  233  244  263  272  275  423  287  305  317\n",
            "  326  327  343  353  360  371  384  398  400  404  304  479  596  494\n",
            "  773  775  785  789  797  810  818  825  838  848  854  859  883  768\n",
            "  884  889  892  899  900  929  945  954 1000 1009 1016 1023 1035 1044\n",
            "  887  484  767  745  502  510  523  531  541  555  559  583  174  597\n",
            "  603  612  613  762  629  646  654  659  662  685  691  693  699  710\n",
            "  729  733  737  740  632  164 1051   41   94   82  132   14   73  115\n",
            "    2  123   13  126  146   69  107   51  109   58  905   43  336  546\n",
            "  545  339  782  915  913  125   17  533  909  906  551  534  903  535\n",
            "  350  558   44  957  956  580  955  290  575  138   48  947  567  135\n",
            "  944  942  454  309  312  314  316  319  321  932  894  930  928  529\n",
            "  308   88  482  421  820   96   27  858  426   34  857  856  434  117\n",
            "  113  831  439  832  467   99  834  448  105  840  457  452] (250,) [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
            "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
            "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
            " 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.\n",
            " 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.\n",
            " 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.\n",
            " 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.\n",
            " 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.\n",
            " 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.\n",
            " 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 20. 20.\n",
            " 20. 20. 20. 20. 20. 20. 20. 20. 20. 20. 20. 20. 20. 20. 20. 20. 20. 20.\n",
            " 20. 20. 20. 20. 20. 20. 20. 20. 20. 20. 20. 20. 20. 20. 20. 20. 20. 20.\n",
            " 20. 20. 20. 20. 20. 20. 20. 20. 20. 20. 20. 20. 20. 20. 20. 20. 20. 20.\n",
            " 20. 20. 20. 20. 20. 20. 20. 20. 20. 20. 20. 20. 20. 20. 20. 20.]\n",
            "trainset before adding uncertain samples (250, 10) (250,)\n",
            "trainset after adding uncertain samples (500, 10) (500,)\n",
            "updated train set: (500, 10) (500,) unique(labels): [259 241] [0 1]\n",
            "val set: (802, 10) (802,)\n",
            "\n",
            "Train set: (500, 10)\n",
            "Validation set: (802, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.098 s \n",
            "\n",
            "Accuracy rate is 80.645161 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.90      0.87       321\n",
            "           1       0.66      0.54      0.59       113\n",
            "\n",
            "    accuracy                           0.81       434\n",
            "   macro avg       0.75      0.72      0.73       434\n",
            "weighted avg       0.80      0.81      0.80       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[289  32]\n",
            " [ 52  61]]\n",
            "--------------------------------\n",
            "final active learning accuracies [76.72811059907833, 80.64516129032258]\n",
            "saved /Users/wenxuanhuang/Documents/Repo/ML-for-COVID-19-dataset/Results/Active-learning-experiment-36.pkl /Users/wenxuanhuang/Documents/Repo/ML-for-COVID-19-dataset ['Decision_tree.ipynb', 'dec_git.png', 'Logit_default_f10.pdf', 'Logistic.ipynb', 'SVC.ipynb', 'RF_f5e50_featureimp.pdf', 'log_al.png', 'dec_git.pdf', '.DS_Store', 'log_git.png', 'svm_git.png', 'Logistic_Scikit.ipynb', 'knn_git.pdf', 'knn_git.png', 'rf_al.png', 'Best classifier_RF_f5e50.pdf', 'KNN.ipynb', 'GBDC.ipynb', 'rf_git.png', 'README.md', 'all_training.csv', 'Results', 'svm_al.png', 'Log_ROC.png', 'Logit_default_f7(p_removal).pdf', 'Active_learning.ipynb', 'Random_forest.ipynb', 'Model_select.ipynb', 'gdbc_git.png', '.git', '.vscode', 'Untitled', 'RF_f5e50_modelselect.pdf', 'Logit_default_f8(std_removal).pdf']\n",
            "\n",
            "---------------------------- FINISHED ---------------------------\n",
            "\n",
            "Count = 37, using model = KnnModel, selection_function = MinStdSelection, k = 125, iteration = 0.\n",
            "\n",
            "initial random chosen samples (125,)\n",
            "initial train set: (125, 10) (125,) unique(labels): [43 82] [0 1]\n",
            "Val set: (1177, 10) (1177,) (125,)\n",
            "\n",
            "Train set: (125, 10)\n",
            "Validation set: (1177, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.097 s \n",
            "\n",
            "Accuracy rate is 74.193548 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.79      0.82       321\n",
            "           1       0.50      0.59      0.54       113\n",
            "\n",
            "    accuracy                           0.74       434\n",
            "   macro avg       0.68      0.69      0.68       434\n",
            "weighted avg       0.76      0.74      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[255  66]\n",
            " [ 46  67]]\n",
            "--------------------------------\n",
            "val predicted: (1177,) [0 1 0 ... 0 0 0]\n",
            "probabilities: (1177, 2) \n",
            " [0 1 0 ... 0 0 0]\n",
            "std (1177,) [ 0. 30.  0. ...  0. 40. 30.]\n",
            "selection [   0  636  665  712  716  135  268  745  746  756  121  807  810  830\n",
            "  633   97   95  849  852  853   88   87  873   83  875  876  886  906\n",
            "  907  846  620  160  601  258  283  290  312  328  340  359  364  232\n",
            "  368  383  385  401  421  429  438  454  204  474  478  489  512  531\n",
            "  180  544  546  549  566  579  909  910  740   50 1107 1111 1112 1001\n",
            "   52 1043 1166 1000 1072 1143 1171  983 1074 1161   60 1131    2 1174\n",
            "   14  971  970  495  441  442  476  447  459  450  466  463 1130  497\n",
            "  456  471  461  928  505  562  551 1095  547 1096 1097  542  536 1098\n",
            " 1100  529  521  519  516  515  440 1106  508  507  504 1132  412] (125,) [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
            "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
            "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
            "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
            "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. 10. 10. 10.\n",
            " 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.\n",
            " 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.]\n",
            "trainset before adding uncertain samples (125, 10) (125,)\n",
            "trainset after adding uncertain samples (250, 10) (250,)\n",
            "updated train set: (250, 10) (250,) unique(labels): [120 130] [0 1]\n",
            "val set: (1052, 10) (1052,)\n",
            "\n",
            "Train set: (250, 10)\n",
            "Validation set: (1052, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.086 s \n",
            "\n",
            "Accuracy rate is 79.032258 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.89      0.86       321\n",
            "           1       0.62      0.50      0.56       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.73      0.70      0.71       434\n",
            "weighted avg       0.78      0.79      0.78       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[286  35]\n",
            " [ 56  57]]\n",
            "--------------------------------\n",
            "val predicted: (1052,) [1 0 1 ... 1 0 0]\n",
            "probabilities: (1052, 2) \n",
            " [1 0 1 ... 1 0 0]\n",
            "std (1052,) [20.  0. 20. ... 50. 10. 20.]\n",
            "selection [ 723  231  131  818  909  224  134  922   64  806   77  140  693  694\n",
            "  934  143  847  212  942   51  946  512   78  297  893  602  623  115\n",
            "  268  837  864  868  869  274  238  120  545  544  737  830  125  233\n",
            "  824  889  534  296  951  701  317  961  463 1003  717 1009  702  721\n",
            "  389  731  755  168   14  416  373 1038  751  748  183  182    1  993\n",
            "  201  351  617  157  977  153  492  500  971  486   42  780  155  185\n",
            "  633  213  634  204  627  706  186  695  703  187  660  638  734  639\n",
            "  713  644  724  716  197  198  688  199  684  225  662  237  733  287\n",
            "  256  323  324  504  501  499  335  337  480  470  465  347  349] (125,) [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
            "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
            "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
            "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
            "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. 10. 10. 10. 10. 10. 10. 10.\n",
            " 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.\n",
            " 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.]\n",
            "trainset before adding uncertain samples (250, 10) (250,)\n",
            "trainset after adding uncertain samples (375, 10) (375,)\n",
            "updated train set: (375, 10) (375,) unique(labels): [185 190] [0 1]\n",
            "val set: (927, 10) (927,)\n",
            "\n",
            "Train set: (375, 10)\n",
            "Validation set: (927, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 3\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.092 s \n",
            "\n",
            "Accuracy rate is 80.875576 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.90      0.87       321\n",
            "           1       0.66      0.55      0.60       113\n",
            "\n",
            "    accuracy                           0.81       434\n",
            "   macro avg       0.75      0.72      0.74       434\n",
            "weighted avg       0.80      0.81      0.80       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[289  32]\n",
            " [ 51  62]]\n",
            "--------------------------------\n",
            "val predicted: (927,) [1 1 0 0 1 1 0 0 1 0 1 0 1 1 0 1 0 1 0 0 1 0 0 0 0 1 0 1 1 0 1 1 1 1 0 0 1\n",
            " 1 0 0 0 0 1 1 0 1 1 0 1 1 1 0 0 1 1 1 0 1 0 0 1 1 0 0 1 1 1 1 1 1 0 1 1 1\n",
            " 0 0 1 1 0 0 0 1 0 0 0 1 1 1 0 1 1 1 0 1 0 0 0 1 1 1 1 0 0 0 1 0 1 0 1 0 0\n",
            " 1 1 1 0 1 0 1 0 1 0 1 0 0 0 0 0 1 1 0 1 1 0 1 0 0 1 1 1 0 1 1 1 1 1 1 1 0\n",
            " 1 1 1 0 0 1 1 0 1 1 1 1 0 0 0 1 0 1 1 1 1 1 1 1 0 0 1 1 0 1 1 0 1 0 0 0 0\n",
            " 0 0 0 1 1 1 0 1 0 0 0 0 1 1 0 1 0 1 0 1 1 0 1 1 0 0 1 1 1 0 0 0 0 0 0 1 0\n",
            " 1 1 0 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1\n",
            " 0 1 1 0 0 1 0 1 1 1 1 0 0 0 0 0 0 1 0 1 0 0 0 1 1 0 1 0 1 0 0 0 0 0 0 1 1\n",
            " 1 1 0 1 1 0 1 1 0 1 1 1 0 1 1 0 0 0 1 1 1 1 1 0 0 1 1 1 0 0 1 0 0 1 0 1 0\n",
            " 0 1 1 1 1 1 0 1 0 0 0 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0 1 1 1 1 1 1 0 1\n",
            " 1 1 1 1 1 1 1 1 1 0 1 0 1 1 0 1 1 0 0 1 1 1 1 0 0 0 1 1 0 1 1 0 0 1 1 0 1\n",
            " 0 1 1 1 1 1 1 1 0 1 1 0 1 0 1 0 0 1 1 1 1 1 1 0 0 0 1 1 1 0 1 0 0 0 1 0 0\n",
            " 1 0 1 1 0 0 0 0 0 0 1 1 1 0 1 0 0 0 1 1 1 1 0 1 1 1 1 0 1 0 0 0 1 0 1 1 0\n",
            " 0 1 1 0 0 1 1 1 1 1 1 1 0 0 0 1 0 1 0 1 0 1 1 0 1 1 0 1 1 0 0 1 1 1 1 1 0\n",
            " 1 1 1 1 1 1 1 1 1 1 0 0 0 1 0 1 0 1 1 0 1 1 1 1 1 0 0 0 0 1 0 0 0 0 0 1 1\n",
            " 0 1 1 1 0 1 1 1 0 1 1 0 0 1 0 1 0 0 0 0 1 0 1 1 1 1 0 1 1 0 1 1 0 1 1 0 1\n",
            " 1 1 1 1 1 0 1 1 0 1 0 0 1 1 1 1 1 0 1 0 1 1 1 0 1 0 1 0 1 1 1 1 1 1 1 1 0\n",
            " 1 1 1 1 0 1 1 0 1 0 1 0 1 0 1 1 1 0 0 1 0 0 0 0 1 1 0 1 0 1 0 1 1 1 1 0 1\n",
            " 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1 0 0 0 0 1 0 1 1 0 1 0 0 1 0 0 0 1 0 0 1 0 0\n",
            " 0 1 0 1 1 1 1 0 1 0 0 1 1 1 1 1 0 0 0 1 1 0 1 1 0 1 1 0 0 0 1 1 0 0 0 0 1\n",
            " 1 0 1 0 1 1 1 0 1 0 0 1 0 0 0 0 0 0 1 1 1 1 0 1 1 1 0 0 1 0 0 1 0 1 1 1 0\n",
            " 1 1 0 0 0 1 0 0 1 1 0 1 1 1 0 1 1 0 0 0 1 0 0 1 0 1 0 1 0 1 1 1 0 1 0 1 1\n",
            " 0 1 1 0 1 1 0 0 0 1 1 1 1 1 1 1 0 1 1 0 1 1 0 1 1 1 0 1 1 0 1 1 1 0 1 0 0\n",
            " 1 1 1 1 1 1 1 0 1 1 0 0 1 0 1 1 1 1 0 1 0 0 1 1 0 1 0 1 0 1 1 1 1 1 1 1 0\n",
            " 1 1 0 0 1 1 0 0 0 1 0 1 0 0 1 1 0 1 1 1 0 0 1 0 1 1 1 0 1 0 1 0 0 1 0 0 1\n",
            " 0 0]\n",
            "probabilities: (927, 2) \n",
            " [1 1 0 0 1 1 0 0 1 0 1 0 1 1 0 1 0 1 0 0 1 0 0 0 0 1 0 1 1 0 1 1 1 1 0 0 1\n",
            " 1 0 0 0 0 1 1 0 1 1 0 1 1 1 0 0 1 1 1 0 1 0 0 1 1 0 0 1 1 1 1 1 1 0 1 1 1\n",
            " 0 0 1 1 0 0 0 1 0 0 0 1 1 1 0 1 1 1 0 1 0 0 0 1 1 1 1 0 0 0 1 0 1 0 1 0 0\n",
            " 1 1 1 0 1 0 1 0 1 0 1 0 0 0 0 0 1 1 0 1 1 0 1 0 0 1 1 1 0 1 1 1 1 1 1 1 0\n",
            " 1 1 1 0 0 1 1 0 1 1 1 1 0 0 0 1 0 1 1 1 1 1 1 1 0 0 1 1 0 1 1 0 1 0 0 0 0\n",
            " 0 0 0 1 1 1 0 1 0 0 0 0 1 1 0 1 0 1 0 1 1 0 1 1 0 0 1 1 1 0 0 0 0 0 0 1 0\n",
            " 1 1 0 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1\n",
            " 0 1 1 0 0 1 0 1 1 1 1 0 0 0 0 0 0 1 0 1 0 0 0 1 1 0 1 0 1 0 0 0 0 0 0 1 1\n",
            " 1 1 0 1 1 0 1 1 0 1 1 1 0 1 1 0 0 0 1 1 1 1 1 0 0 1 1 1 0 0 1 0 0 1 0 1 0\n",
            " 0 1 1 1 1 1 0 1 0 0 0 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0 1 1 1 1 1 1 0 1\n",
            " 1 1 1 1 1 1 1 1 1 0 1 0 1 1 0 1 1 0 0 1 1 1 1 0 0 0 1 1 0 1 1 0 0 1 1 0 1\n",
            " 0 1 1 1 1 1 1 1 0 1 1 0 1 0 1 0 0 1 1 1 1 1 1 0 0 0 1 1 1 0 1 0 0 0 1 0 0\n",
            " 1 0 1 1 0 0 0 0 0 0 1 1 1 0 1 0 0 0 1 1 1 1 0 1 1 1 1 0 1 0 0 0 1 0 1 1 0\n",
            " 0 1 1 0 0 1 1 1 1 1 1 1 0 0 0 1 0 1 0 1 0 1 1 0 1 1 0 1 1 0 0 1 1 1 1 1 0\n",
            " 1 1 1 1 1 1 1 1 1 1 0 0 0 1 0 1 0 1 1 0 1 1 1 1 1 0 0 0 0 1 0 0 0 0 0 1 1\n",
            " 0 1 1 1 0 1 1 1 0 1 1 0 0 1 0 1 0 0 0 0 1 0 1 1 1 1 0 1 1 0 1 1 0 1 1 0 1\n",
            " 1 1 1 1 1 0 1 1 0 1 0 0 1 1 1 1 1 0 1 0 1 1 1 0 1 0 1 0 1 1 1 1 1 1 1 1 0\n",
            " 1 1 1 1 0 1 1 0 1 0 1 0 1 0 1 1 1 0 0 1 0 0 0 0 1 1 0 1 0 1 0 1 1 1 1 0 1\n",
            " 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1 0 0 0 0 1 0 1 1 0 1 0 0 1 0 0 0 1 0 0 1 0 0\n",
            " 0 1 0 1 1 1 1 0 1 0 0 1 1 1 1 1 0 0 0 1 1 0 1 1 0 1 1 0 0 0 1 1 0 0 0 0 1\n",
            " 1 0 1 0 1 1 1 0 1 0 0 1 0 0 0 0 0 0 1 1 1 1 0 1 1 1 0 0 1 0 0 1 0 1 1 1 0\n",
            " 1 1 0 0 0 1 0 0 1 1 0 1 1 1 0 1 1 0 0 0 1 0 0 1 0 1 0 1 0 1 1 1 0 1 0 1 1\n",
            " 0 1 1 0 1 1 0 0 0 1 1 1 1 1 1 1 0 1 1 0 1 1 0 1 1 1 0 1 1 0 1 1 1 0 1 0 0\n",
            " 1 1 1 1 1 1 1 0 1 1 0 0 1 0 1 1 1 1 0 1 0 0 1 1 0 1 0 1 0 1 1 1 1 1 1 1 0\n",
            " 1 1 0 0 1 1 0 0 0 1 0 1 0 0 1 1 0 1 1 1 0 0 1 0 1 1 1 0 1 0 1 0 0 1 0 0 1\n",
            " 0 0]\n",
            "std (927,) [40. 20. 20.  0. 20. 30. 20. 40. 20. 30. 20. 40. 40. 40. 40. 50. 30. 30.\n",
            " 30. 20. 20. 10.  0. 10. 20. 10. 20. 50. 30. 30. 20. 30. 20. 50. 20. 40.\n",
            " 20. 30. 30. 40. 30. 10. 30. 40. 40. 30. 40. 10. 20. 20. 40. 20. 30. 40.\n",
            " 50. 40. 30. 30. 30. 20. 30. 20. 20. 30. 40. 30. 40. 30. 50. 40. 10. 40.\n",
            " 40. 30. 40. 20. 40. 40. 10.  0. 30. 40. 40. 10. 30. 30. 50. 10. 10. 40.\n",
            " 50. 20. 40. 20. 30. 40. 30. 30. 10. 20. 10. 30. 30. 30. 40. 20. 30. 40.\n",
            " 30. 40. 30. 50. 40. 10.  0. 30.  0. 30. 30. 20. 40. 20. 30. 40. 20. 20.\n",
            " 30. 50. 10. 10. 40. 40. 30. 20. 10. 30. 30. 20. 20. 40. 30. 30. 50. 30.\n",
            " 30. 30. 30. 30. 40. 50. 40. 20. 30. 40. 30. 40. 30. 20. 20. 40. 10. 10.\n",
            " 30. 20. 30. 20. 20. 20. 30. 40. 20. 40. 40.  0. 40. 30. 30. 30. 30.  0.\n",
            " 20. 30. 20.  0. 20. 30. 20. 20. 30. 10. 30. 20. 20. 40. 30. 30. 30. 20.\n",
            " 50. 20. 40. 40. 20. 30. 40. 40. 50. 30. 30. 30. 30. 40. 30. 40. 40. 10.\n",
            " 10. 40. 40. 20. 50. 30. 20. 30. 10. 40. 20. 30. 30. 30. 30. 40. 10. 50.\n",
            " 50. 40. 40. 40. 20. 50. 40. 40. 10. 30. 50. 20. 40. 30. 10. 10. 50. 40.\n",
            " 10. 10. 10. 50. 30. 30. 30. 40. 50. 50. 20. 40. 50.  0. 10. 40. 40. 30.\n",
            " 30. 30. 30. 30. 20. 20. 20. 30. 40.  0. 20. 30. 30. 50. 20. 30. 30. 20.\n",
            " 50. 20. 20. 30. 20. 30. 40. 30. 30. 40.  0. 20. 20. 30. 20. 40. 40. 50.\n",
            " 30. 30. 10. 30. 30. 40. 30. 20. 30. 30. 30. 30. 20. 40. 40. 20. 30. 30.\n",
            " 30. 10. 40. 50. 40. 30. 10. 40. 30. 50. 50. 30. 30. 40. 40. 40. 20.  0.\n",
            " 40. 10. 40. 10. 20. 30. 50. 40. 30. 40. 20. 40. 40. 10. 30. 20. 30. 30.\n",
            " 30. 20. 30. 30. 30. 10. 40. 30. 50. 40. 10. 40. 40. 40. 20. 30. 40. 50.\n",
            " 20. 10. 50. 20. 30. 40. 30. 20. 30. 40. 20. 20. 40. 40. 40. 40. 20. 20.\n",
            " 20. 30. 40. 40. 20. 30. 10. 20. 10. 30. 30. 30. 20. 30. 20. 40. 40. 50.\n",
            " 20.  0. 40. 50. 40. 40. 30. 40. 10. 40. 40. 30. 40. 30. 40. 20. 20. 30.\n",
            " 50. 30. 40. 20. 20. 20. 50. 10. 10. 30. 30. 30. 20. 30. 20. 40. 10. 30.\n",
            " 10. 30. 40.  0. 50. 20. 20. 40. 30. 40.  0. 40. 30. 40. 20. 30. 30. 30.\n",
            " 20. 10. 20. 20. 20.  0. 40. 40. 50. 10. 40. 50. 30.  0. 30. 40. 30. 30.\n",
            " 10. 50. 30. 10. 40. 40. 50. 20. 10. 20. 40. 20. 20. 20. 40. 30. 40. 30.\n",
            " 40. 20. 40. 30. 30. 40.  0. 30. 50. 10. 20. 10. 30. 30. 30. 50. 20. 40.\n",
            " 30. 30. 40. 40. 30. 40. 30. 30. 20. 20. 50. 30. 20. 20. 40. 20. 30. 50.\n",
            " 30. 40. 30. 30. 30. 30.  0. 30. 40.  0. 10. 20. 40. 40. 20. 30. 40. 40.\n",
            " 30. 30. 40. 40. 20. 20. 40. 50. 40. 10. 50. 10. 40. 30. 30. 30. 30. 30.\n",
            " 50. 10. 40. 20. 40. 10. 10. 20. 40. 30. 40. 10. 10. 30. 50. 30. 10. 40.\n",
            " 30. 40. 40. 40. 10. 30. 30. 20. 40. 20. 40. 40. 40. 40. 40. 30. 40. 20.\n",
            " 40. 30. 10. 40. 40. 30. 30. 40. 40. 20. 40. 10. 40. 50. 40. 30. 30. 20.\n",
            " 10. 40. 40. 40. 30. 50. 30. 30. 20. 40.  0. 30. 30. 10. 50. 30. 30.  0.\n",
            " 20. 30. 30. 30. 30. 10. 50.  0. 20. 10. 20. 40. 30. 20. 30. 20. 30. 10.\n",
            " 30. 30. 10. 30. 30. 10. 20. 10. 10. 40. 10. 20. 30. 30. 30. 30. 30. 30.\n",
            " 50. 40. 40. 20. 30.  0. 20. 10.  0. 40. 50. 40. 30. 50. 10. 40. 10. 40.\n",
            " 30. 50. 30. 40. 30. 30. 30. 40. 40. 30. 50. 40. 40. 20. 50. 10. 30. 40.\n",
            " 30. 40. 30. 30. 30. 30. 30. 10. 40. 10. 20. 50. 40. 30. 20. 30. 30. 40.\n",
            " 10. 10. 30. 30. 50. 20. 30. 40. 30. 40. 40. 20. 30. 40. 40.  0. 40. 40.\n",
            " 30. 30. 50. 30. 30. 20.  0. 30. 10. 10. 30. 30. 30. 10. 20. 40. 30. 20.\n",
            " 30. 40. 20. 30. 20. 10. 30. 10. 30. 30. 40. 50. 20. 20. 50. 30. 40. 40.\n",
            " 40. 10. 40. 40. 30. 30. 20. 40. 40. 20. 30. 20. 30. 40. 10. 40. 40. 30.\n",
            " 10. 30. 40. 10. 10. 20. 10. 30. 40. 50. 40.  0. 30. 30. 20. 30. 40. 50.\n",
            " 50. 40. 40. 30. 50. 30. 30. 50. 20. 40. 50. 30. 20. 20. 40. 50. 40. 20.\n",
            " 10. 20. 40. 10. 30. 30. 40. 20. 10. 30. 40. 20. 20. 40. 30. 30. 30. 40.\n",
            " 10. 20. 30. 50. 50.  0. 50. 50. 20. 30. 30. 30. 40. 20. 40. 30. 30. 50.\n",
            " 30. 50. 20. 30. 30. 30. 30. 20. 30. 30. 40. 20. 30. 20. 30. 40. 20. 30.\n",
            " 40. 20. 30. 40. 10. 20. 40. 50.  0. 20. 40. 30. 30. 20. 40. 30. 40.  0.\n",
            " 40. 40. 30. 40. 10. 10. 50. 30. 40.]\n",
            "selection [473 917 265 460 753 655 453 908 546 762 821 549 183 179 173 869  79 116\n",
            " 692 114 689 640 510 647  22 415 341 279   3 481 298 343 440 330 577 160\n",
            " 161 864 581 469 569 567 486 489 806 810 439 379 325 691 113 477 698 128\n",
            " 582 129 700 134 592 781 588 587 598 717 189 308 242 729 248 816 249 739\n",
            " 727 252 254 738 345 515 266 513 253 846 232 793 365 550 813 814 448 494\n",
            " 450 422 854 215 779 216 849 224 355 370 614 671  87 769  88 665 764 653\n",
            " 673  83 904 630  78 657 404 676  70  21  23 402 922  41  25 643 674] (125,) [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
            "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. 10. 10. 10. 10. 10.\n",
            " 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.\n",
            " 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.\n",
            " 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.\n",
            " 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.\n",
            " 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.]\n",
            "trainset before adding uncertain samples (375, 10) (375,)\n",
            "trainset after adding uncertain samples (500, 10) (500,)\n",
            "updated train set: (500, 10) (500,) unique(labels): [257 243] [0 1]\n",
            "val set: (802, 10) (802,)\n",
            "\n",
            "Train set: (500, 10)\n",
            "Validation set: (802, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 4\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.177 s \n",
            "\n",
            "Accuracy rate is 79.262673 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.89      0.86       321\n",
            "           1       0.62      0.52      0.57       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.73      0.70      0.72       434\n",
            "weighted avg       0.78      0.79      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[285  36]\n",
            " [ 54  59]]\n",
            "--------------------------------\n",
            "final active learning accuracies [74.19354838709677, 79.03225806451613, 80.87557603686636, 79.26267281105991]\n",
            "saved /Users/wenxuanhuang/Documents/Repo/ML-for-COVID-19-dataset/Results/Active-learning-experiment-37.pkl /Users/wenxuanhuang/Documents/Repo/ML-for-COVID-19-dataset ['Decision_tree.ipynb', 'dec_git.png', 'Logit_default_f10.pdf', 'Logistic.ipynb', 'SVC.ipynb', 'RF_f5e50_featureimp.pdf', 'log_al.png', 'dec_git.pdf', '.DS_Store', 'log_git.png', 'svm_git.png', 'Logistic_Scikit.ipynb', 'knn_git.pdf', 'knn_git.png', 'rf_al.png', 'Best classifier_RF_f5e50.pdf', 'KNN.ipynb', 'GBDC.ipynb', 'rf_git.png', 'README.md', 'all_training.csv', 'Results', 'svm_al.png', 'Log_ROC.png', 'Logit_default_f7(p_removal).pdf', 'Active_learning.ipynb', 'Random_forest.ipynb', 'Model_select.ipynb', 'gdbc_git.png', '.git', '.vscode', 'Untitled', 'RF_f5e50_modelselect.pdf', 'Logit_default_f8(std_removal).pdf']\n",
            "\n",
            "---------------------------- FINISHED ---------------------------\n",
            "\n",
            "Count = 38, using model = KnnModel, selection_function = MinStdSelection, k = 50, iteration = 0.\n",
            "\n",
            "initial random chosen samples (50,)\n",
            "initial train set: (50, 10) (50,) unique(labels): [25 25] [0 1]\n",
            "Val set: (1252, 10) (1252,) (50,)\n",
            "\n",
            "Train set: (50, 10)\n",
            "Validation set: (1252, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.170 s \n",
            "\n",
            "Accuracy rate is 76.958525 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.86      0.85       321\n",
            "           1       0.56      0.52      0.54       113\n",
            "\n",
            "    accuracy                           0.77       434\n",
            "   macro avg       0.70      0.69      0.69       434\n",
            "weighted avg       0.76      0.77      0.77       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[275  46]\n",
            " [ 54  59]]\n",
            "--------------------------------\n",
            "val predicted: (1252,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1252, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "std (1252,) [30. 20. 40. ... 40. 30.  0.]\n",
            "selection [1251  531  903  854  293  618  753  617 1040  466  304  213  796  678\n",
            " 1211  917   47   46 1085  918   74 1052  506  780  253  879  649  634\n",
            "   93  239 1178   90  111  237  173  786  892 1053  757  866 1027 1075\n",
            "  424 1138  994  996  997  410 1107  586] (50,) [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0.]\n",
            "trainset before adding uncertain samples (50, 10) (50,)\n",
            "trainset after adding uncertain samples (100, 10) (100,)\n",
            "updated train set: (100, 10) (100,) unique(labels): [50 50] [0 1]\n",
            "val set: (1202, 10) (1202,)\n",
            "\n",
            "Train set: (100, 10)\n",
            "Validation set: (1202, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.076 s \n",
            "\n",
            "Accuracy rate is 74.654378 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.83      0.83       321\n",
            "           1       0.51      0.51      0.51       113\n",
            "\n",
            "    accuracy                           0.75       434\n",
            "   macro avg       0.67      0.67      0.67       434\n",
            "weighted avg       0.75      0.75      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[266  55]\n",
            " [ 55  58]]\n",
            "--------------------------------\n",
            "val predicted: (1202,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1202, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "std (1202,) [30. 20. 30. ... 30. 30. 30.]\n",
            "selection [ 600  888 1147  997  611 1095  879 1151   95  878  872  869   88  890\n",
            " 1012  166 1013   80 1158  643  646   73  860  365  230 1021  672   84\n",
            "  992  989  986  954  163  950  161  171  962  154  932 1122  455  528\n",
            " 1127  532  450  139  550 1057 1134  444] (50,) [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0.]\n",
            "trainset before adding uncertain samples (100, 10) (100,)\n",
            "trainset after adding uncertain samples (150, 10) (150,)\n",
            "updated train set: (150, 10) (150,) unique(labels): [80 70] [0 1]\n",
            "val set: (1152, 10) (1152,)\n",
            "\n",
            "Train set: (150, 10)\n",
            "Validation set: (1152, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 3\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.086 s \n",
            "\n",
            "Accuracy rate is 78.110599 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.88      0.86       321\n",
            "           1       0.60      0.49      0.54       113\n",
            "\n",
            "    accuracy                           0.78       434\n",
            "   macro avg       0.71      0.69      0.70       434\n",
            "weighted avg       0.77      0.78      0.77       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[284  37]\n",
            " [ 58  55]]\n",
            "--------------------------------\n",
            "val predicted: (1152,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1152, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "std (1152,) [30. 20. 40. ... 20. 30. 30.]\n",
            "selection [ 575  112  728  120  621  620  619  497  821 1072  296  961  133  135\n",
            "  813  812 1065  616  505  311 1015  336  705  940  334  649  647  942\n",
            "  312   90   94  644  950  952  953  716  717  327  508  145  146  184\n",
            "  244  573  190  191  765  571  248  768] (50,) [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0.]\n",
            "trainset before adding uncertain samples (150, 10) (150,)\n",
            "trainset after adding uncertain samples (200, 10) (200,)\n",
            "updated train set: (200, 10) (200,) unique(labels): [112  88] [0 1]\n",
            "val set: (1102, 10) (1102,)\n",
            "\n",
            "Train set: (200, 10)\n",
            "Validation set: (1102, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 4\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.073 s \n",
            "\n",
            "Accuracy rate is 78.571429 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.90      0.86       321\n",
            "           1       0.62      0.47      0.53       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.72      0.68      0.70       434\n",
            "weighted avg       0.77      0.79      0.78       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[288  33]\n",
            " [ 60  53]]\n",
            "--------------------------------\n",
            "val predicted: (1102,) [0 0 1 ... 0 0 0]\n",
            "probabilities: (1102, 2) \n",
            " [0 0 1 ... 0 0 0]\n",
            "std (1102,) [ 0. 10. 30. ... 20. 10. 40.]\n",
            "selection [  0 671 172 666 661 656 655 182 653 652 185 648 188 638 636 625 622 200\n",
            " 600 598 169 208 166 164  95 849 830 827 826 820 809 117 801 774 772 771\n",
            " 764 135 758 144 728 714 318 676 873 571 569 459 454 450] (50,) [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0.]\n",
            "trainset before adding uncertain samples (200, 10) (200,)\n",
            "trainset after adding uncertain samples (250, 10) (250,)\n",
            "updated train set: (250, 10) (250,) unique(labels): [132 118] [0 1]\n",
            "val set: (1052, 10) (1052,)\n",
            "\n",
            "Train set: (250, 10)\n",
            "Validation set: (1052, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 5\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.070 s \n",
            "\n",
            "Accuracy rate is 77.419355 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.87      0.85       321\n",
            "           1       0.58      0.50      0.54       113\n",
            "\n",
            "    accuracy                           0.77       434\n",
            "   macro avg       0.70      0.69      0.69       434\n",
            "weighted avg       0.77      0.77      0.77       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[279  42]\n",
            " [ 56  57]]\n",
            "--------------------------------\n",
            "val predicted: (1052,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1052, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "std (1052,) [10. 40. 10. ... 10. 40. 40.]\n",
            "selection [ 910  556  384  390  952  824  401   62  695 1011   59   58  411  414\n",
            "  141   51  245  244  721  146  370  284  778  766  332  336  343  962\n",
            "  305  740  353  304   90  122  296  914  733  727  992  997  234  108\n",
            "  880  543  621  185  498  895  537  526] (50,) [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0.]\n",
            "trainset before adding uncertain samples (250, 10) (250,)\n",
            "trainset after adding uncertain samples (300, 10) (300,)\n",
            "updated train set: (300, 10) (300,) unique(labels): [154 146] [0 1]\n",
            "val set: (1002, 10) (1002,)\n",
            "\n",
            "Train set: (300, 10)\n",
            "Validation set: (1002, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 6\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.071 s \n",
            "\n",
            "Accuracy rate is 77.188940 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.85      0.85       321\n",
            "           1       0.56      0.54      0.55       113\n",
            "\n",
            "    accuracy                           0.77       434\n",
            "   macro avg       0.70      0.70      0.70       434\n",
            "weighted avg       0.77      0.77      0.77       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[274  47]\n",
            " [ 52  61]]\n",
            "--------------------------------\n",
            "val predicted: (1002,) [1 1 0 ... 0 0 0]\n",
            "probabilities: (1002, 2) \n",
            " [1 1 0 ... 0 0 0]\n",
            "std (1002,) [10. 40.  0. ...  0. 20. 40.]\n",
            "selection [500 471 476 493 516 532 576 582 584 595 663 735 754 762 765 779 795 812\n",
            " 450 819 446 439 190 192 202 171 221 269 271 295 309 333 340 348 391 410\n",
            " 130 431 436 125 826 184 955 988 910 981  25 868  15   5] (50,) [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0.]\n",
            "trainset before adding uncertain samples (300, 10) (300,)\n",
            "trainset after adding uncertain samples (350, 10) (350,)\n",
            "updated train set: (350, 10) (350,) unique(labels): [180 170] [0 1]\n",
            "val set: (952, 10) (952,)\n",
            "\n",
            "Train set: (350, 10)\n",
            "Validation set: (952, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 7\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.069 s \n",
            "\n",
            "Accuracy rate is 78.341014 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86       321\n",
            "           1       0.60      0.52      0.56       113\n",
            "\n",
            "    accuracy                           0.78       434\n",
            "   macro avg       0.72      0.70      0.71       434\n",
            "weighted avg       0.78      0.78      0.78       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[281  40]\n",
            " [ 54  59]]\n",
            "--------------------------------\n",
            "val predicted: (952,) [1 1 0 0 1 1 0 1 1 0 0 1 0 0 0 1 1 1 0 1 0 1 0 0 1 0 0 1 0 1 1 1 0 1 1 1 1\n",
            " 0 0 1 1 0 1 0 1 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 1 1 0 0 1 1 1 1 1\n",
            " 1 0 1 1 0 0 1 1 1 0 1 0 1 1 0 1 1 1 0 1 0 0 0 1 1 1 0 0 0 0 1 0 0 1 0 0 1\n",
            " 0 1 1 1 1 1 0 1 0 0 1 0 0 1 1 0 1 0 0 1 1 0 1 0 1 1 1 1 1 1 0 1 0 1 0 0 1\n",
            " 0 1 1 1 0 0 1 0 0 0 1 1 1 1 1 1 1 0 1 0 0 1 1 0 1 1 0 1 0 0 0 1 0 0 1 1 0\n",
            " 1 0 0 0 0 0 1 1 0 0 1 0 0 1 1 0 1 1 0 1 1 0 0 1 1 1 0 0 0 0 0 1 1 0 1 1 1\n",
            " 1 1 1 1 1 0 0 0 1 1 0 1 0 1 1 1 1 1 0 0 0 1 1 0 1 1 0 1 1 1 1 0 1 1 1 1 1\n",
            " 0 0 1 1 0 1 1 0 0 0 1 1 1 1 1 0 0 0 1 0 1 0 1 0 0 1 0 1 0 0 1 0 0 0 1 0 0\n",
            " 0 0 0 1 1 1 1 1 1 0 1 0 0 1 1 1 0 1 0 1 0 0 1 1 0 0 0 1 1 0 1 0 0 1 0 1 1\n",
            " 1 1 1 1 1 0 1 1 0 1 1 0 0 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 0 1 1 0 1 1\n",
            " 1 1 0 1 1 0 1 1 0 1 1 0 0 1 1 1 1 0 1 0 1 1 0 1 1 1 0 1 1 1 1 0 0 1 0 1 1\n",
            " 1 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 1 0 0 1 0 1 1 1 1 0 0 1 0 1 1 1 1 1 0 1 0\n",
            " 1 1 0 0 0 0 1 1 1 1 1 1 1 0 0 0 1 0 1 0 1 1 0 1 0 0 0 0 1 0 0 0 1 1 0 0 0\n",
            " 0 1 1 0 1 0 1 1 1 0 1 1 1 1 1 0 1 1 0 0 1 1 0 0 0 1 0 1 1 1 1 1 0 1 1 0 0\n",
            " 0 1 0 0 1 1 0 0 1 0 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 0 0 1 0 0 1 1 1 1 1 1 1\n",
            " 0 0 0 0 1 0 0 1 1 0 1 1 1 0 1 1 1 0 1 0 1 0 0 1 0 1 0 0 1 0 0 1 0 1 1 1 0\n",
            " 1 0 0 0 1 0 1 1 0 1 1 0 1 1 1 0 1 1 0 1 0 1 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0\n",
            " 0 1 1 0 1 0 0 1 0 1 0 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 0 0 0 1 1 1 0 1 0 1 1\n",
            " 0 1 0 0 0 1 0 1 0 1 0 1 0 0 1 0 0 1 1 1 1 0 0 1 1 0 0 1 1 1 1 1 0 0 0 1 1\n",
            " 1 0 0 1 0 0 1 0 1 0 0 0 0 0 0 1 0 0 1 1 0 1 0 0 0 0 1 1 1 1 1 0 0 0 0 1 0\n",
            " 0 1 0 1 1 0 0 1 1 1 0 0 0 1 0 0 1 0 1 1 0 1 0 1 0 0 0 0 0 0 0 1 1 1 1 1 1\n",
            " 0 0 1 0 0 1 1 0 1 1 1 0 0 0 1 0 0 0 1 0 1 1 0 1 0 1 0 0 0 1 0 1 0 1 0 1 0\n",
            " 1 1 0 0 1 0 1 1 1 0 1 1 0 0 1 0 1 1 1 1 1 1 1 0 1 1 1 0 0 1 1 1 1 0 1 1 1\n",
            " 0 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 0 1 1 0 1 1 0 0 1 0 1 1 1 0 0 0\n",
            " 0 1 0 1 1 0 0 1 0 1 1 1 1 1 0 1 0 1 1 0 0 0 0 1 0 1 0 1 0 1 0 0 0 1 1 1 1\n",
            " 1 0 0 1 0 0 1 0 1 0 0 0 1 1 1 0 0 1 0 0 0 1 1 1 0 0 0]\n",
            "probabilities: (952, 2) \n",
            " [1 1 0 0 1 1 0 1 1 0 0 1 0 0 0 1 1 1 0 1 0 1 0 0 1 0 0 1 0 1 1 1 0 1 1 1 1\n",
            " 0 0 1 1 0 1 0 1 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 1 1 0 0 1 1 1 1 1\n",
            " 1 0 1 1 0 0 1 1 1 0 1 0 1 1 0 1 1 1 0 1 0 0 0 1 1 1 0 0 0 0 1 0 0 1 0 0 1\n",
            " 0 1 1 1 1 1 0 1 0 0 1 0 0 1 1 0 1 0 0 1 1 0 1 0 1 1 1 1 1 1 0 1 0 1 0 0 1\n",
            " 0 1 1 1 0 0 1 0 0 0 1 1 1 1 1 1 1 0 1 0 0 1 1 0 1 1 0 1 0 0 0 1 0 0 1 1 0\n",
            " 1 0 0 0 0 0 1 1 0 0 1 0 0 1 1 0 1 1 0 1 1 0 0 1 1 1 0 0 0 0 0 1 1 0 1 1 1\n",
            " 1 1 1 1 1 0 0 0 1 1 0 1 0 1 1 1 1 1 0 0 0 1 1 0 1 1 0 1 1 1 1 0 1 1 1 1 1\n",
            " 0 0 1 1 0 1 1 0 0 0 1 1 1 1 1 0 0 0 1 0 1 0 1 0 0 1 0 1 0 0 1 0 0 0 1 0 0\n",
            " 0 0 0 1 1 1 1 1 1 0 1 0 0 1 1 1 0 1 0 1 0 0 1 1 0 0 0 1 1 0 1 0 0 1 0 1 1\n",
            " 1 1 1 1 1 0 1 1 0 1 1 0 0 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 0 1 1 0 1 1\n",
            " 1 1 0 1 1 0 1 1 0 1 1 0 0 1 1 1 1 0 1 0 1 1 0 1 1 1 0 1 1 1 1 0 0 1 0 1 1\n",
            " 1 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 1 0 0 1 0 1 1 1 1 0 0 1 0 1 1 1 1 1 0 1 0\n",
            " 1 1 0 0 0 0 1 1 1 1 1 1 1 0 0 0 1 0 1 0 1 1 0 1 0 0 0 0 1 0 0 0 1 1 0 0 0\n",
            " 0 1 1 0 1 0 1 1 1 0 1 1 1 1 1 0 1 1 0 0 1 1 0 0 0 1 0 1 1 1 1 1 0 1 1 0 0\n",
            " 0 1 0 0 1 1 0 0 1 0 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 0 0 1 0 0 1 1 1 1 1 1 1\n",
            " 0 0 0 0 1 0 0 1 1 0 1 1 1 0 1 1 1 0 1 0 1 0 0 1 0 1 0 0 1 0 0 1 0 1 1 1 0\n",
            " 1 0 0 0 1 0 1 1 0 1 1 0 1 1 1 0 1 1 0 1 0 1 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0\n",
            " 0 1 1 0 1 0 0 1 0 1 0 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 0 0 0 1 1 1 0 1 0 1 1\n",
            " 0 1 0 0 0 1 0 1 0 1 0 1 0 0 1 0 0 1 1 1 1 0 0 1 1 0 0 1 1 1 1 1 0 0 0 1 1\n",
            " 1 0 0 1 0 0 1 0 1 0 0 0 0 0 0 1 0 0 1 1 0 1 0 0 0 0 1 1 1 1 1 0 0 0 0 1 0\n",
            " 0 1 0 1 1 0 0 1 1 1 0 0 0 1 0 0 1 0 1 1 0 1 0 1 0 0 0 0 0 0 0 1 1 1 1 1 1\n",
            " 0 0 1 0 0 1 1 0 1 1 1 0 0 0 1 0 0 0 1 0 1 1 0 1 0 1 0 0 0 1 0 1 0 1 0 1 0\n",
            " 1 1 0 0 1 0 1 1 1 0 1 1 0 0 1 0 1 1 1 1 1 1 1 0 1 1 1 0 0 1 1 1 1 0 1 1 1\n",
            " 0 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 0 1 1 0 1 1 0 0 1 0 1 1 1 0 0 0\n",
            " 0 1 0 1 1 0 0 1 0 1 1 1 1 1 0 1 0 1 1 0 0 0 0 1 0 1 0 1 0 1 0 0 0 1 1 1 1\n",
            " 1 0 0 1 0 0 1 0 1 0 0 0 1 1 1 0 0 1 0 0 0 1 1 1 0 0 0]\n",
            "std (952,) [30. 40.  0.  0. 10. 20. 10. 40. 20. 30. 40. 40. 20.  0. 30. 20. 20. 50.\n",
            " 30. 30. 30. 10. 10. 30. 10. 10. 20. 50.  0. 30. 50. 50. 30. 40. 10. 30.\n",
            " 10. 20. 30. 40. 30. 50. 40. 30. 20. 30. 10. 50. 10. 10. 20. 20. 10. 30.\n",
            " 50. 20. 10. 30. 30. 50. 40. 10. 30. 50. 10. 40. 10. 20.  0. 20. 40. 30.\n",
            " 30. 30. 30. 20. 30. 30. 50. 10. 50. 30. 30. 10. 40. 20. 50. 40. 10. 20.\n",
            " 20. 40. 30. 40. 10. 20. 30. 30. 10. 30. 40. 20. 20. 50. 20. 20. 40. 40.\n",
            " 10. 30. 10. 30. 20. 20. 20. 30. 30. 30. 20. 40. 30. 50. 40. 30. 50. 30.\n",
            "  0. 30. 30. 40. 40. 10. 20. 20. 20. 40. 30. 30. 30. 30. 30. 10. 40. 30.\n",
            " 50. 40. 30. 30. 30. 30. 40. 40. 20. 40. 40. 10. 30. 10. 10. 40. 20. 50.\n",
            " 30. 20. 40. 40. 20. 40. 30. 20. 30. 30. 50. 40.  0. 30. 40. 40. 40. 30.\n",
            " 10. 20. 10. 10. 30. 20. 40. 30. 20. 20. 20. 10. 20. 20.  0. 30. 40. 40.\n",
            " 30. 30. 30. 40. 10. 40. 40. 30. 30. 30. 30. 10. 50. 30. 20. 20. 40. 30.\n",
            " 20. 20. 10. 30. 30. 30. 50. 30. 40. 30. 40.  0. 50. 20. 40. 40. 20. 30.\n",
            " 30. 30. 40. 40. 50. 20. 40.  0. 20. 20. 20.  0. 50. 20. 10. 10. 20. 40.\n",
            " 30. 20. 10. 10. 20. 30. 20. 40. 20. 20. 20. 30. 40. 30. 30. 10. 30. 40.\n",
            " 20. 40. 50. 30. 30. 10. 10. 50. 30. 30. 20. 10. 30. 20. 20. 30. 30. 30.\n",
            " 40. 10. 30. 30. 20. 50. 30. 10. 30. 50. 30. 30. 40. 30. 10. 30. 40. 10.\n",
            " 30. 10. 30. 20. 40. 30. 30. 40. 20. 50. 30. 30. 50. 50.  0. 20. 40. 50.\n",
            " 20. 40. 50. 30.  0. 20. 20. 20. 50. 10. 50. 50. 30. 30.  0. 10. 40. 40.\n",
            " 40. 20. 50.  0. 10. 40. 20. 30. 50. 50. 20. 20. 30. 50. 10. 30. 40. 20.\n",
            " 40. 30. 30. 40. 20. 50. 50. 20. 20. 10. 40. 30. 10. 50. 40. 30. 30. 40.\n",
            " 20. 20. 10. 40. 10. 30. 20. 40. 50. 30. 20. 20. 30. 40. 10. 40. 10. 40.\n",
            " 20. 40. 50. 40. 30. 10. 40. 50. 10. 20. 40. 30. 40. 20. 20. 10. 30. 20.\n",
            " 30.  0. 40. 50. 10. 10. 30. 10. 20. 20. 30. 10. 10.  0. 30. 30. 30. 30.\n",
            " 10.  0. 50. 10. 40. 30. 40. 40. 50. 40. 40. 20. 40. 30. 30.  0. 10. 20.\n",
            " 50. 20. 10. 30. 40. 20. 30. 10. 10. 50. 20. 10. 50.  0. 40. 10. 20. 40.\n",
            " 40. 30. 20. 20. 20. 30. 20. 50. 50. 20. 20. 30. 30. 10. 30. 30. 20. 40.\n",
            " 30. 30. 20. 50. 20. 50. 40. 50. 40. 20. 20. 40. 50. 40. 30. 40. 10.  0.\n",
            " 20. 50. 40. 40. 10. 30. 30. 20. 20. 30. 30. 40. 30. 20. 40. 10. 30. 30.\n",
            " 40. 50. 40.  0. 40. 30. 30. 40. 50. 30. 40. 20. 10. 50. 50. 30. 30. 10.\n",
            " 30. 40. 40. 10. 20. 40. 30.  0. 50. 40. 30. 30. 30. 20. 40. 40. 20. 10.\n",
            " 20. 40. 20. 40. 20. 40. 30. 30. 40. 50. 20. 50. 10. 50. 10. 50.  0. 10.\n",
            " 30.  0. 30. 30. 50. 10. 30. 30. 30. 20. 30. 40. 30. 10. 40. 30. 30.  0.\n",
            " 10. 30. 40. 10. 20. 20. 20. 40. 30. 30. 50. 20. 40. 20. 30. 30. 40. 50.\n",
            " 40. 10. 50. 20. 50. 40. 10. 40. 40. 10. 30. 20. 40. 30. 40. 10.  0. 10.\n",
            " 40. 30. 10. 40. 40. 20. 10.  0. 30. 10. 40. 20. 50. 50. 20. 30. 20. 40.\n",
            " 20. 10. 30. 20. 40. 30. 30.  0. 30. 30. 50. 40. 20. 10. 50. 40. 10. 30.\n",
            " 20. 30. 40. 50. 10. 20. 20. 30. 30. 20. 10. 40.  0.  0. 30.  0. 30. 40.\n",
            " 10. 30. 50. 40. 40. 50. 10. 20.  0. 50. 20. 20. 20. 30. 20. 20. 50. 50.\n",
            " 40. 40. 40. 10. 10. 30. 30. 40. 30. 20. 10. 40. 10. 30. 30. 40. 40. 30.\n",
            " 40. 30. 40. 30. 30. 30. 20. 40. 10. 40. 20. 30. 30. 10. 30. 20. 40. 30.\n",
            " 30. 30. 40. 20.  0. 30. 40. 20. 40. 40. 30. 30. 20. 20. 50. 30. 40. 20.\n",
            " 30. 20. 50. 40.  0. 10. 40. 50. 10. 50. 50. 10. 50. 30. 10. 30. 40. 40.\n",
            " 20. 30. 20.  0. 10. 50. 20. 10. 30. 50. 20. 30. 50. 20. 20. 20.  0. 40.\n",
            " 20. 30.  0. 40. 10. 40. 10. 50. 20. 30. 10. 40. 30. 10. 20. 40. 40. 30.\n",
            " 30. 10. 40. 50. 20. 40. 30. 10. 20. 30. 10. 20. 20. 30. 30. 20. 40. 10.\n",
            " 40. 10. 10. 30. 10. 50. 40. 40. 10. 40. 40. 40. 30. 30. 50. 40. 30. 30.\n",
            " 30.  0. 30. 20. 30. 40. 30. 20. 30. 20. 40. 50. 30. 20. 50. 30. 30. 40.\n",
            " 40. 30. 20. 20. 30. 40. 40. 40. 30. 10. 30. 10. 50. 10. 30. 40. 10. 30.\n",
            " 50. 40. 30. 40. 30. 20. 20. 20. 20. 10. 40. 10. 10. 40. 30. 30. 40. 40.\n",
            " 50. 40. 20. 30. 10. 10. 10.  0.  0. 50.  0. 30. 10. 20. 20. 30. 10. 50.\n",
            "  0. 20. 20. 30. 40. 10. 50. 20.  0. 30. 20. 40. 30. 30.  0. 10.  0.  0.\n",
            " 30. 30. 30. 20. 30. 30. 30.  0. 30. 10. 40. 30. 30. 10. 10. 30.]\n",
            "selection [126 932 241 678 742 320 926 227 328 760 574 655 338 918 679 547 345 777\n",
            " 628 910 447 790  68 194 908 907 174 637 794 463 934 433 681 935 692 427\n",
            " 847 525 943 415   3 503  13   2  28 245 577 593 392 627] (50,) [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
            "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
            "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. 10. 10.]\n",
            "trainset before adding uncertain samples (350, 10) (350,)\n",
            "trainset after adding uncertain samples (400, 10) (400,)\n",
            "updated train set: (400, 10) (400,) unique(labels): [209 191] [0 1]\n",
            "val set: (902, 10) (902,)\n",
            "\n",
            "Train set: (400, 10)\n",
            "Validation set: (902, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 8\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.074 s \n",
            "\n",
            "Accuracy rate is 78.801843 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.89      0.86       321\n",
            "           1       0.62      0.50      0.55       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.72      0.69      0.71       434\n",
            "weighted avg       0.78      0.79      0.78       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[286  35]\n",
            " [ 57  56]]\n",
            "--------------------------------\n",
            "val predicted: (902,) [1 1 0 1 0 1 1 0 0 1 0 0 1 0 1 0 1 0 1 0 0 0 0 0 1 1 1 1 0 1 0 1 1 0 0 1 1\n",
            " 0 1 0 1 1 1 0 1 0 1 0 0 1 1 1 0 1 1 1 1 1 0 1 0 1 1 0 1 1 1 1 1 1 0 1 1 0\n",
            " 0 1 1 1 0 1 0 1 1 0 1 1 1 0 1 0 0 0 1 1 1 0 0 0 0 1 0 0 1 0 0 1 0 1 1 1 1\n",
            " 1 0 1 0 0 1 0 0 1 1 1 0 0 1 0 0 1 0 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 1 1 0 0\n",
            " 1 0 0 0 1 1 1 1 1 1 1 0 1 0 0 1 1 0 1 1 1 0 0 0 1 0 0 1 1 0 1 0 0 0 0 0 0\n",
            " 1 0 1 0 0 1 1 0 1 0 0 1 1 0 0 1 1 1 0 0 0 0 0 1 1 0 1 1 1 1 1 1 1 1 0 0 1\n",
            " 1 0 1 0 1 1 1 1 1 0 0 1 1 1 1 0 0 1 1 1 0 1 1 1 1 1 0 0 1 1 0 1 1 0 0 0 1\n",
            " 1 1 1 1 0 0 0 1 0 1 0 0 0 0 1 0 1 0 0 1 0 0 0 1 0 0 0 0 0 1 1 1 1 1 1 0 1\n",
            " 0 0 1 1 1 0 1 0 1 0 0 1 1 0 0 1 1 0 1 0 1 0 1 1 0 1 1 1 1 1 1 0 1 1 0 0 1\n",
            " 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 0 1 1 0 1 1 1 1 0 1 1 0 1 1 0 1 1 0 0 1 1\n",
            " 1 1 0 1 0 1 1 1 1 1 0 1 1 1 1 0 0 1 0 1 1 1 1 1 0 0 1 1 0 1 1 0 0 1 1 0 1\n",
            " 0 0 0 1 1 1 1 0 1 0 1 1 1 1 1 0 1 0 1 1 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 1 1\n",
            " 1 0 1 0 0 0 0 1 0 0 0 1 1 0 0 0 0 1 1 0 1 0 1 1 1 0 1 1 1 1 1 0 1 1 0 0 1\n",
            " 1 0 0 1 0 0 1 1 1 1 0 1 1 0 0 0 1 0 0 1 1 0 1 0 1 1 0 1 1 0 1 1 1 1 1 1 1\n",
            " 1 1 0 0 1 0 1 1 1 1 1 1 1 0 0 0 0 1 0 0 1 1 0 1 1 1 0 1 1 1 0 1 1 0 1 0 1\n",
            " 0 0 1 0 0 1 0 1 1 1 0 1 0 0 1 0 1 1 0 1 1 0 1 1 1 0 1 1 0 1 0 1 0 0 1 1 0\n",
            " 1 1 1 1 1 0 1 1 0 1 1 0 1 0 0 0 1 0 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1\n",
            " 1 0 1 0 0 1 0 1 0 0 0 0 0 1 0 1 0 1 1 0 1 0 1 1 0 0 1 0 0 1 1 1 1 1 0 0 0\n",
            " 1 1 1 0 0 1 0 0 1 0 1 0 0 0 0 0 0 1 0 0 1 1 0 1 0 0 0 0 1 1 1 1 1 0 0 0 0\n",
            " 1 0 0 1 1 1 0 0 1 1 1 0 0 0 1 0 0 1 0 1 1 1 0 1 0 0 0 0 0 0 0 1 1 1 1 1 1\n",
            " 0 1 0 0 1 1 0 1 1 1 0 0 1 0 0 1 0 1 0 0 1 0 0 0 0 0 1 0 1 0 1 0 1 0 1 1 0\n",
            " 0 1 0 1 1 1 0 1 1 0 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 1 1 1 1 1 1 0 1 1 1\n",
            " 1 0 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 0 1 1 0 1 1 0 0 1 0 1 1 1 0 0 0 0 1 0 0\n",
            " 1 0 0 1 0 1 1 1 1 1 0 1 0 1 1 0 1 0 1 0 1 0 1 0 0 1 1 1 1 1 0 1 0 0 1 1 0\n",
            " 1 1 1 0 0 1 0 0 1 1 1 0 0 0]\n",
            "probabilities: (902, 2) \n",
            " [1 1 0 1 0 1 1 0 0 1 0 0 1 0 1 0 1 0 1 0 0 0 0 0 1 1 1 1 0 1 0 1 1 0 0 1 1\n",
            " 0 1 0 1 1 1 0 1 0 1 0 0 1 1 1 0 1 1 1 1 1 0 1 0 1 1 0 1 1 1 1 1 1 0 1 1 0\n",
            " 0 1 1 1 0 1 0 1 1 0 1 1 1 0 1 0 0 0 1 1 1 0 0 0 0 1 0 0 1 0 0 1 0 1 1 1 1\n",
            " 1 0 1 0 0 1 0 0 1 1 1 0 0 1 0 0 1 0 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 1 1 0 0\n",
            " 1 0 0 0 1 1 1 1 1 1 1 0 1 0 0 1 1 0 1 1 1 0 0 0 1 0 0 1 1 0 1 0 0 0 0 0 0\n",
            " 1 0 1 0 0 1 1 0 1 0 0 1 1 0 0 1 1 1 0 0 0 0 0 1 1 0 1 1 1 1 1 1 1 1 0 0 1\n",
            " 1 0 1 0 1 1 1 1 1 0 0 1 1 1 1 0 0 1 1 1 0 1 1 1 1 1 0 0 1 1 0 1 1 0 0 0 1\n",
            " 1 1 1 1 0 0 0 1 0 1 0 0 0 0 1 0 1 0 0 1 0 0 0 1 0 0 0 0 0 1 1 1 1 1 1 0 1\n",
            " 0 0 1 1 1 0 1 0 1 0 0 1 1 0 0 1 1 0 1 0 1 0 1 1 0 1 1 1 1 1 1 0 1 1 0 0 1\n",
            " 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 0 1 1 0 1 1 1 1 0 1 1 0 1 1 0 1 1 0 0 1 1\n",
            " 1 1 0 1 0 1 1 1 1 1 0 1 1 1 1 0 0 1 0 1 1 1 1 1 0 0 1 1 0 1 1 0 0 1 1 0 1\n",
            " 0 0 0 1 1 1 1 0 1 0 1 1 1 1 1 0 1 0 1 1 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 1 1\n",
            " 1 0 1 0 0 0 0 1 0 0 0 1 1 0 0 0 0 1 1 0 1 0 1 1 1 0 1 1 1 1 1 0 1 1 0 0 1\n",
            " 1 0 0 1 0 0 1 1 1 1 0 1 1 0 0 0 1 0 0 1 1 0 1 0 1 1 0 1 1 0 1 1 1 1 1 1 1\n",
            " 1 1 0 0 1 0 1 1 1 1 1 1 1 0 0 0 0 1 0 0 1 1 0 1 1 1 0 1 1 1 0 1 1 0 1 0 1\n",
            " 0 0 1 0 0 1 0 1 1 1 0 1 0 0 1 0 1 1 0 1 1 0 1 1 1 0 1 1 0 1 0 1 0 0 1 1 0\n",
            " 1 1 1 1 1 0 1 1 0 1 1 0 1 0 0 0 1 0 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1\n",
            " 1 0 1 0 0 1 0 1 0 0 0 0 0 1 0 1 0 1 1 0 1 0 1 1 0 0 1 0 0 1 1 1 1 1 0 0 0\n",
            " 1 1 1 0 0 1 0 0 1 0 1 0 0 0 0 0 0 1 0 0 1 1 0 1 0 0 0 0 1 1 1 1 1 0 0 0 0\n",
            " 1 0 0 1 1 1 0 0 1 1 1 0 0 0 1 0 0 1 0 1 1 1 0 1 0 0 0 0 0 0 0 1 1 1 1 1 1\n",
            " 0 1 0 0 1 1 0 1 1 1 0 0 1 0 0 1 0 1 0 0 1 0 0 0 0 0 1 0 1 0 1 0 1 0 1 1 0\n",
            " 0 1 0 1 1 1 0 1 1 0 0 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 1 1 1 1 1 1 0 1 1 1\n",
            " 1 0 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 0 1 1 0 1 1 0 0 1 0 1 1 1 0 0 0 0 1 0 0\n",
            " 1 0 0 1 0 1 1 1 1 1 0 1 0 1 1 0 1 0 1 0 1 0 1 0 0 1 1 1 1 1 0 1 0 0 1 1 0\n",
            " 1 1 1 0 0 1 0 0 1 1 1 0 0 0]\n",
            "std (902,) [40. 40.  0. 10. 20. 50. 20. 20. 40. 40. 20. 30. 30.  0. 50. 40. 30. 30.\n",
            " 20. 20. 40.  0. 20. 30. 50. 10. 50. 40. 30. 30.  0. 30. 10. 20. 30. 30.\n",
            " 30. 50. 40. 30. 20. 30. 10. 40. 40.  0. 20. 20.  0. 30. 50. 20. 20. 30.\n",
            " 30. 50. 30. 10. 30. 50. 10. 20. 10. 30. 20. 40. 30. 20. 30. 20.  0. 30.\n",
            " 40. 50.  0. 50. 20. 30. 20. 30. 30. 50. 40. 10. 20. 20. 40. 30. 30. 10.\n",
            " 20. 30. 30. 10. 20. 40. 20. 20. 50. 20. 20. 40. 40. 30. 30. 10. 30. 20.\n",
            " 10. 40. 30. 30. 30. 40. 40. 30. 40. 40. 30. 40. 30. 40. 30. 40. 40.  0.\n",
            " 30. 20. 10. 40. 30. 30. 30. 40. 30. 30. 30. 30. 50. 20. 30. 40. 20. 30.\n",
            " 30. 50. 10. 40. 30. 10. 30. 30. 10. 40. 10. 50. 30. 20. 30. 40. 20. 30.\n",
            " 30. 30. 20. 30. 50. 40. 30. 50. 30. 30. 40. 10. 20. 40. 10. 30. 30. 40.\n",
            " 30. 10. 20. 20.  0. 20. 20. 30. 40. 40. 20. 10. 30. 40.  0. 40. 50. 20.\n",
            " 30. 30. 30. 10. 50. 50. 20. 30. 40. 30. 20. 40. 10. 30. 30. 30. 40. 30.\n",
            " 30. 40. 40. 50. 30. 40. 50. 30. 40. 30. 30. 40. 40. 50. 30. 40. 10. 20.\n",
            " 10. 40. 20. 20.  0. 20. 40. 30.  0. 20. 10. 20. 30. 20. 40. 10. 20. 20.\n",
            " 40. 40. 20. 20. 20. 40. 40. 20. 40. 50. 30. 30. 30. 10. 50. 30. 20. 10.\n",
            "  0. 30. 20. 10. 40. 30. 30. 40. 10. 30. 30. 20. 50. 30. 20. 30. 50. 20.\n",
            " 30. 40. 30. 10. 10. 40. 30. 30. 10. 30. 30. 50. 30. 30. 40. 20. 50. 30.\n",
            " 30. 50. 50. 20. 50. 50. 20. 40. 50. 30. 30. 30. 10. 50.  0. 50. 40. 20.\n",
            " 30. 10. 40. 40. 50. 20. 40. 10. 30. 10. 20. 40. 40. 20. 20. 30. 50. 20.\n",
            " 20. 30. 20. 40. 20. 30. 50. 30. 40. 50. 20. 20. 10. 40. 20. 10. 50. 40.\n",
            " 30. 30. 30. 40. 30. 10. 40. 30. 30. 20. 40. 40. 30. 30. 30. 40. 40. 30.\n",
            " 20. 40. 10. 30. 50. 40. 30.  0. 20. 40. 10. 20. 40. 30. 40. 30. 30. 10.\n",
            " 30. 20. 30. 40. 50. 20. 10. 30. 10. 30. 20. 30.  0. 20. 20. 20. 30. 30.\n",
            " 10. 50. 20. 40. 30. 20. 50. 40. 40. 40. 20. 40. 20. 30. 20. 30. 40. 20.\n",
            " 20. 30. 30. 20. 30. 30. 30. 50.  0. 10. 50. 40. 10. 20. 40. 40. 30. 10.\n",
            " 20. 20. 40. 20. 50. 40. 30. 20. 30. 20. 10. 40. 30. 20. 40. 40. 20. 20.\n",
            " 50. 20. 40. 40. 50. 30. 10. 10. 40. 50. 40. 30. 40. 10. 10. 50. 30. 40.\n",
            "  0. 30. 30. 20. 10. 40. 20. 40. 30. 30. 40. 10. 30. 30. 30. 40. 40. 40.\n",
            "  0. 30. 30. 50. 40. 40. 20. 10. 50. 50. 30. 30. 10. 30. 40. 50. 30. 30.\n",
            " 20. 30. 40. 40. 40. 30. 30. 20. 40. 40. 30. 20. 20. 40. 10. 40. 20. 40.\n",
            " 30. 30. 40. 40. 20. 50. 30. 50. 10. 50. 20. 30. 30. 30. 50. 30. 40. 30.\n",
            " 30. 20. 30. 40. 30. 10. 40. 30. 40.  0. 30. 40. 10. 20. 20. 20. 30. 30.\n",
            " 40. 50. 10. 40. 20. 30. 30. 40. 50. 40. 20. 50. 10. 40. 50.  0. 40. 40.\n",
            " 10. 40. 10. 40. 30. 40. 10. 30. 30. 20. 40. 50. 20.  0. 30. 30. 40. 20.\n",
            " 50. 50. 30. 30. 20. 40. 20. 20. 30. 40. 50. 20. 30. 30. 30. 50. 40. 10.\n",
            " 10. 50. 40.  0. 30. 20. 20. 40. 50.  0.  0. 10. 40. 30. 20. 20. 40. 20.\n",
            " 30. 40.  0. 30. 50. 40. 40. 50. 10. 30. 50. 20. 30. 20. 20. 30. 30. 40.\n",
            " 40. 40. 40. 50.  0. 10. 40. 30. 40. 30. 20. 10. 40. 10. 30. 30. 40. 30.\n",
            " 30. 40. 30. 40. 20. 40. 30. 20. 30. 30. 40. 10. 30. 30. 40. 30. 20. 40.\n",
            " 30. 30. 30. 40. 10. 40. 40. 20. 50. 40. 40. 30. 20. 30. 50. 30. 40. 30.\n",
            " 40. 10. 40. 40. 10. 40. 50. 20. 50. 50. 10. 50. 40. 30. 20. 40. 40. 20.\n",
            " 30. 20. 30. 50. 20. 10. 20. 50. 20. 30. 40. 10.  0. 30. 30. 10. 30. 40.\n",
            " 10. 40.  0. 50. 20. 30.  0. 40. 30. 20. 20. 30. 30. 30. 30. 10. 40. 50.\n",
            " 20. 40. 10. 30. 30. 30. 10. 30. 20. 30. 20. 10. 40. 10. 20. 20. 20. 40.\n",
            " 20. 50. 40. 20.  0. 40. 40. 30. 30. 30. 50. 40. 30. 20. 40. 20. 20. 30.\n",
            " 30. 10. 20. 10. 20. 40. 50. 20. 20. 50. 30. 40. 40. 30. 40. 20. 20. 30.\n",
            " 50. 40. 40. 30. 20. 30. 30. 50. 20. 20. 40. 20. 20. 50. 30. 40. 40. 30.\n",
            " 30. 20. 20. 20.  0. 40. 30. 20. 40. 30. 30. 30. 40. 40. 30. 20. 30. 20.\n",
            " 10. 10. 50. 50. 30. 10. 20. 30. 10. 50. 20. 20. 20. 40. 10. 40. 10. 30.\n",
            " 20. 30. 30. 20. 30. 30. 20. 10. 20. 40. 30. 20. 30.  0. 30. 20. 40. 20.\n",
            " 30. 40.]\n",
            "selection [125 796 385 607  30 320 750  74 194 670 440 184 591 758  45 408  48 850\n",
            " 567  70  21 762  13 242 504 640 639 486 895 238 633 270   2 650 404 414\n",
            " 149 475 152 146 154 402 743 105 474 872 753 128 108 441] (50,) [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
            "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. 10. 10.\n",
            " 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.]\n",
            "trainset before adding uncertain samples (400, 10) (400,)\n",
            "trainset after adding uncertain samples (450, 10) (450,)\n",
            "updated train set: (450, 10) (450,) unique(labels): [230 220] [0 1]\n",
            "val set: (852, 10) (852,)\n",
            "\n",
            "Train set: (450, 10)\n",
            "Validation set: (852, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 9\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.070 s \n",
            "\n",
            "Accuracy rate is 80.184332 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.88      0.87       321\n",
            "           1       0.63      0.58      0.60       113\n",
            "\n",
            "    accuracy                           0.80       434\n",
            "   macro avg       0.74      0.73      0.73       434\n",
            "weighted avg       0.80      0.80      0.80       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[283  38]\n",
            " [ 48  65]]\n",
            "--------------------------------\n",
            "val predicted: (852,) [1 1 0 0 1 1 0 0 1 0 0 1 1 0 1 0 1 0 0 0 0 1 0 1 1 0 1 1 0 0 0 1 1 0 1 0 1\n",
            " 1 1 0 1 1 0 1 1 1 0 1 1 1 1 1 0 1 0 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1\n",
            " 1 0 1 1 1 0 1 0 0 0 1 1 1 0 0 0 0 1 0 0 1 0 0 0 1 1 1 1 0 1 0 0 1 0 0 1 1\n",
            " 1 0 0 1 0 1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 1 1 0 1 0 0 1 1 1 1 1 0 1 0 0 1\n",
            " 1 0 1 1 1 0 0 0 1 0 0 1 1 0 1 0 0 0 0 0 1 0 1 0 0 1 1 0 1 0 1 1 0 0 1 0 1\n",
            " 0 0 0 0 0 1 1 0 1 1 1 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 1 0 0 1 1 1 1 0 1 1\n",
            " 1 1 1 1 1 1 0 0 1 1 0 1 1 0 0 0 1 1 1 1 1 0 0 0 1 0 1 0 0 0 1 0 1 0 0 1 0\n",
            " 0 0 1 0 0 0 0 0 1 1 1 1 1 1 0 1 0 0 1 1 1 0 1 0 1 0 0 1 1 0 0 1 1 0 1 0 1\n",
            " 0 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 0 1 1 0 1 1\n",
            " 1 1 0 1 1 0 1 1 0 1 0 0 0 1 1 1 1 0 1 0 1 1 1 1 1 0 1 1 1 1 0 1 0 1 1 1 1\n",
            " 1 0 0 1 1 0 1 1 0 1 0 1 0 0 1 1 1 1 1 0 1 1 1 1 1 0 1 0 1 1 0 0 0 1 1 1 1\n",
            " 1 1 1 0 0 0 1 1 1 0 1 0 0 0 0 1 0 0 0 1 1 0 0 0 0 1 1 0 1 0 1 1 1 0 1 1 1\n",
            " 1 1 1 0 0 1 1 0 0 1 0 1 1 1 1 0 1 1 0 0 0 1 0 0 1 1 0 1 1 1 0 1 1 0 1 1 1\n",
            " 1 1 1 1 1 1 0 0 1 0 1 1 1 1 1 1 1 0 0 0 0 1 0 0 1 1 0 1 1 1 0 1 1 1 0 1 1\n",
            " 0 1 0 1 0 0 1 0 0 1 0 1 1 1 0 1 0 1 0 1 1 0 1 1 0 1 1 1 0 1 1 0 1 0 1 0 0\n",
            " 1 1 1 1 1 1 1 0 1 1 0 1 1 0 1 0 0 1 0 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1\n",
            " 1 1 0 1 0 1 0 1 0 0 0 1 0 1 0 1 1 0 1 1 1 0 0 1 0 0 1 1 1 1 1 0 0 0 1 1 1\n",
            " 0 1 0 0 1 0 1 0 0 0 0 0 0 1 0 0 1 1 0 1 0 0 0 0 1 0 1 1 1 0 0 0 0 1 0 0 1\n",
            " 1 1 0 0 1 1 1 0 0 0 1 0 0 1 0 1 1 0 0 1 0 0 0 0 0 0 0 1 1 1 1 1 1 0 1 0 1\n",
            " 1 0 1 1 1 0 1 0 1 0 1 0 1 0 0 0 0 1 0 1 0 1 0 1 0 1 1 0 0 1 0 1 1 1 0 1 1\n",
            " 0 0 1 0 1 1 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 1 1 0 1 1 0 1 0 1 1 0 1 1 0 1 1\n",
            " 1 1 1 1 0 1 1 0 1 1 0 1 1 0 0 1 0 1 1 1 0 0 0 0 1 0 1 0 0 1 0 1 1 1 1 1 0\n",
            " 1 0 1 1 0 1 0 1 0 1 1 0 0 1 1 1 1 1 0 1 0 0 1 1 0 1 1 1 0 0 1 0 1 1 1 0 0\n",
            " 0]\n",
            "probabilities: (852, 2) \n",
            " [1 1 0 0 1 1 0 0 1 0 0 1 1 0 1 0 1 0 0 0 0 1 0 1 1 0 1 1 0 0 0 1 1 0 1 0 1\n",
            " 1 1 0 1 1 0 1 1 1 0 1 1 1 1 1 0 1 0 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1\n",
            " 1 0 1 1 1 0 1 0 0 0 1 1 1 0 0 0 0 1 0 0 1 0 0 0 1 1 1 1 0 1 0 0 1 0 0 1 1\n",
            " 1 0 0 1 0 1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 1 1 0 1 0 0 1 1 1 1 1 0 1 0 0 1\n",
            " 1 0 1 1 1 0 0 0 1 0 0 1 1 0 1 0 0 0 0 0 1 0 1 0 0 1 1 0 1 0 1 1 0 0 1 0 1\n",
            " 0 0 0 0 0 1 1 0 1 1 1 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 1 0 0 1 1 1 1 0 1 1\n",
            " 1 1 1 1 1 1 0 0 1 1 0 1 1 0 0 0 1 1 1 1 1 0 0 0 1 0 1 0 0 0 1 0 1 0 0 1 0\n",
            " 0 0 1 0 0 0 0 0 1 1 1 1 1 1 0 1 0 0 1 1 1 0 1 0 1 0 0 1 1 0 0 1 1 0 1 0 1\n",
            " 0 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 0 1 1 0 1 1\n",
            " 1 1 0 1 1 0 1 1 0 1 0 0 0 1 1 1 1 0 1 0 1 1 1 1 1 0 1 1 1 1 0 1 0 1 1 1 1\n",
            " 1 0 0 1 1 0 1 1 0 1 0 1 0 0 1 1 1 1 1 0 1 1 1 1 1 0 1 0 1 1 0 0 0 1 1 1 1\n",
            " 1 1 1 0 0 0 1 1 1 0 1 0 0 0 0 1 0 0 0 1 1 0 0 0 0 1 1 0 1 0 1 1 1 0 1 1 1\n",
            " 1 1 1 0 0 1 1 0 0 1 0 1 1 1 1 0 1 1 0 0 0 1 0 0 1 1 0 1 1 1 0 1 1 0 1 1 1\n",
            " 1 1 1 1 1 1 0 0 1 0 1 1 1 1 1 1 1 0 0 0 0 1 0 0 1 1 0 1 1 1 0 1 1 1 0 1 1\n",
            " 0 1 0 1 0 0 1 0 0 1 0 1 1 1 0 1 0 1 0 1 1 0 1 1 0 1 1 1 0 1 1 0 1 0 1 0 0\n",
            " 1 1 1 1 1 1 1 0 1 1 0 1 1 0 1 0 0 1 0 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1\n",
            " 1 1 0 1 0 1 0 1 0 0 0 1 0 1 0 1 1 0 1 1 1 0 0 1 0 0 1 1 1 1 1 0 0 0 1 1 1\n",
            " 0 1 0 0 1 0 1 0 0 0 0 0 0 1 0 0 1 1 0 1 0 0 0 0 1 0 1 1 1 0 0 0 0 1 0 0 1\n",
            " 1 1 0 0 1 1 1 0 0 0 1 0 0 1 0 1 1 0 0 1 0 0 0 0 0 0 0 1 1 1 1 1 1 0 1 0 1\n",
            " 1 0 1 1 1 0 1 0 1 0 1 0 1 0 0 0 0 1 0 1 0 1 0 1 0 1 1 0 0 1 0 1 1 1 0 1 1\n",
            " 0 0 1 0 1 1 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 1 1 0 1 1 0 1 0 1 1 0 1 1 0 1 1\n",
            " 1 1 1 1 0 1 1 0 1 1 0 1 1 0 0 1 0 1 1 1 0 0 0 0 1 0 1 0 0 1 0 1 1 1 1 1 0\n",
            " 1 0 1 1 0 1 0 1 0 1 1 0 0 1 1 1 1 1 0 1 0 0 1 1 0 1 1 1 0 0 1 0 1 1 1 0 0\n",
            " 0]\n",
            "std (852,) [40. 40.  0. 20. 50. 20. 20. 30. 40. 30. 40. 40. 50. 30. 30. 40. 20. 20.\n",
            " 40. 20. 40. 50.  0. 50. 40. 40. 30. 30.  0. 20. 30. 30. 30. 50. 40. 20.\n",
            " 30. 30. 10. 50. 40. 20. 10. 30. 50. 20. 30. 30. 40. 50. 40. 20. 30. 50.\n",
            " 10. 10. 20. 30. 30. 40. 30. 20. 30. 20. 40. 40. 30. 50. 30. 30. 30. 30.\n",
            " 20. 50. 40. 10. 10. 10. 40. 30. 30. 30. 20. 40. 30. 10. 20. 50. 20. 20.\n",
            " 40. 20. 20. 30. 40. 30. 30. 40. 30. 40. 40. 30. 20. 40. 30. 30. 30. 40.\n",
            " 20. 50. 30. 40. 30. 40. 40. 30. 20. 40. 30. 30. 30. 40. 30. 30. 20. 30.\n",
            " 50. 30. 40. 40. 30. 40. 40. 40. 30. 30. 30. 20. 40. 50. 50. 30. 30. 30.\n",
            " 20. 30. 40. 30. 30. 40. 50. 40. 30. 40. 40. 30. 40. 10. 30. 40. 10. 30.\n",
            " 30. 30. 30. 40. 30. 30. 40. 10. 30. 40. 40. 20. 30. 30. 40. 40. 50. 30.\n",
            " 30. 30. 40.  0. 50. 40. 20. 20. 40. 20. 20. 40. 20. 20. 30. 40. 40. 30.\n",
            " 20. 30. 40. 50. 30. 40. 40. 30. 40. 30. 30. 40. 40. 40. 40. 40. 40. 30.\n",
            " 20. 30. 20. 40. 20. 40. 40. 40. 10. 20. 30. 20. 40. 40. 20. 30. 30. 30.\n",
            " 20. 30. 30. 30. 30. 40. 50. 50. 30. 30. 30. 30. 50. 40. 20. 10. 30. 40.\n",
            " 10. 30. 30. 10. 40. 20. 30. 30. 20. 50. 30. 30. 40. 50. 20. 30. 40. 30.\n",
            " 10. 10. 40.  0. 30. 10. 40. 30. 50. 40. 30. 40. 30. 50. 40. 30. 50. 50.\n",
            " 20. 40. 50. 30. 40. 50. 40. 30. 40. 20. 50. 40. 40. 20. 30. 20. 40. 30.\n",
            " 50. 20. 40. 20. 30. 10. 20. 30. 50. 10. 20. 30. 50. 10. 20. 30. 20. 40.\n",
            " 20. 30. 50. 40. 40. 50. 20. 20. 20. 40. 20. 10. 50. 30. 40. 30. 30. 30.\n",
            " 40.  0. 40. 10. 30. 20. 30. 40. 30. 30. 30. 30. 40. 30. 10. 50. 20. 30.\n",
            " 50. 40. 40. 20. 50. 10. 20. 40. 40. 40. 30. 30. 10. 30. 20. 30. 40. 50.\n",
            " 30. 20. 30. 20. 40. 20. 10. 30. 40. 30. 40. 10. 40. 30. 10. 50. 40. 40.\n",
            " 40. 30. 40. 30. 40. 10. 30. 40. 20. 30. 40. 50. 50. 20. 40. 30. 50. 50.\n",
            " 40. 20. 20. 40. 40. 30. 30. 20. 30. 40. 30. 50. 40. 30. 30. 40. 20.  0.\n",
            " 40. 30. 30. 40. 30. 20. 30. 50. 30. 30. 40. 50. 30. 50. 50. 40. 30. 40.\n",
            " 20. 10. 50. 40. 50. 40. 30. 20. 30. 30. 20. 40. 30. 20. 40. 10. 40. 30.\n",
            " 40. 30. 40. 40. 30. 30. 30. 40. 40.  0. 10. 50. 50. 30. 30. 10. 30. 40.\n",
            " 50. 30. 30. 20. 30. 40. 40. 40. 30. 30. 20. 40. 40. 30. 20. 10. 40.  0.\n",
            " 40. 20. 40. 20. 30. 40. 40. 20. 50. 30. 50. 10. 50. 20. 30. 30. 30. 50.\n",
            " 30. 40. 30. 40. 10. 30. 40. 30. 10. 40. 40. 40. 40. 40. 10. 20. 20. 20.\n",
            " 30. 40. 40. 50. 20. 40. 20. 30. 30. 40. 50. 40. 10. 50. 30. 50. 50. 40.\n",
            " 40. 10. 40. 20. 30. 50. 40.  0. 40. 30. 40. 50. 50. 20. 30. 30. 40. 20.\n",
            " 50. 50. 30. 40. 20. 40. 10. 30. 20. 40. 50. 20. 40. 40. 40. 50. 40. 10.\n",
            " 10. 50. 30. 30. 20. 20. 30. 40. 10. 40. 30. 20. 20. 40. 30. 30. 30. 30.\n",
            " 50. 30. 40. 50.  0. 30. 50. 20. 20. 20. 20. 40. 40. 50. 30. 40. 40. 40.\n",
            " 10. 30. 30. 40. 40. 20. 10. 40.  0. 30. 40. 50. 40. 30. 40. 40. 30. 10.\n",
            " 40. 30. 20. 30. 30. 40.  0. 30. 20. 40. 30. 10. 40. 40. 30. 30. 40. 10.\n",
            " 40. 50. 20. 50. 40. 30. 20. 20. 30. 50. 30. 40. 30. 40. 20. 30. 40.  0.\n",
            " 40. 50. 20. 40. 40. 30. 50. 30. 30. 10. 40. 40. 20. 20. 20. 40. 50. 30.\n",
            " 30. 40. 20. 30. 40. 10. 40. 40. 30. 40. 10. 40. 40. 20. 40. 40. 30. 30.\n",
            " 40. 20. 40. 30. 30. 10. 50. 40. 20. 30. 20. 30. 30. 30. 20. 20. 20. 40.\n",
            " 30. 10. 40. 10. 30. 20. 20. 40. 10. 40. 40. 20. 50. 40. 30. 30. 40. 40.\n",
            " 50. 30. 30. 40. 20. 10. 30. 30. 10. 20.  0. 20. 40. 50. 20. 20. 50. 40.\n",
            " 40. 40. 30. 40. 10. 20. 30. 40. 40. 40. 30. 20. 30. 30. 50. 20. 20. 40.\n",
            " 20. 30. 50. 40. 40. 40. 20. 20. 20. 20. 10. 40. 30. 20. 30. 40. 30. 50.\n",
            " 40. 30. 30. 30. 20. 30. 20. 10. 40. 40. 30. 20. 10. 30. 50. 10. 10. 30.\n",
            " 40. 20. 30. 20. 30. 20. 30. 40. 20. 30. 40. 20. 10. 20. 40. 40. 20. 40.\n",
            " 40. 20. 40. 20. 30. 40.]\n",
            "selection [273  22 183 638 343 654 477 683  28 503 766 565 431   2 616 707 817  85\n",
            " 335 356  76  77 712  75 822 536 372 693 825 826 384 389 365 319 255 311\n",
            " 559 169 160 764 157 761 602 224 552 746 249 594 593 252] (50,) [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. 10. 10. 10.\n",
            " 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.\n",
            " 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.]\n",
            "trainset before adding uncertain samples (450, 10) (450,)\n",
            "trainset after adding uncertain samples (500, 10) (500,)\n",
            "updated train set: (500, 10) (500,) unique(labels): [256 244] [0 1]\n",
            "val set: (802, 10) (802,)\n",
            "\n",
            "Train set: (500, 10)\n",
            "Validation set: (802, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 10\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.062 s \n",
            "\n",
            "Accuracy rate is 80.875576 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.89      0.87       321\n",
            "           1       0.65      0.58      0.61       113\n",
            "\n",
            "    accuracy                           0.81       434\n",
            "   macro avg       0.75      0.74      0.74       434\n",
            "weighted avg       0.80      0.81      0.81       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[285  36]\n",
            " [ 47  66]]\n",
            "--------------------------------\n",
            "final active learning accuracies [76.95852534562212, 74.65437788018433, 78.11059907834101, 78.57142857142857, 77.41935483870968, 77.18894009216591, 78.3410138248848, 78.80184331797236, 80.18433179723502, 80.87557603686636]\n",
            "saved /Users/wenxuanhuang/Documents/Repo/ML-for-COVID-19-dataset/Results/Active-learning-experiment-38.pkl /Users/wenxuanhuang/Documents/Repo/ML-for-COVID-19-dataset ['Decision_tree.ipynb', 'dec_git.png', 'Logit_default_f10.pdf', 'Logistic.ipynb', 'SVC.ipynb', 'RF_f5e50_featureimp.pdf', 'log_al.png', 'dec_git.pdf', '.DS_Store', 'log_git.png', 'svm_git.png', 'Logistic_Scikit.ipynb', 'knn_git.pdf', 'knn_git.png', 'rf_al.png', 'Best classifier_RF_f5e50.pdf', 'KNN.ipynb', 'GBDC.ipynb', 'rf_git.png', 'README.md', 'all_training.csv', 'Results', 'svm_al.png', 'Log_ROC.png', 'Logit_default_f7(p_removal).pdf', 'Active_learning.ipynb', 'Random_forest.ipynb', 'Model_select.ipynb', 'gdbc_git.png', '.git', '.vscode', 'Untitled', 'RF_f5e50_modelselect.pdf', 'Logit_default_f8(std_removal).pdf']\n",
            "\n",
            "---------------------------- FINISHED ---------------------------\n",
            "\n",
            "Count = 39, using model = KnnModel, selection_function = MinStdSelection, k = 25, iteration = 0.\n",
            "\n",
            "initial random chosen samples (25,)\n",
            "initial train set: (25, 10) (25,) unique(labels): [13 12] [0 1]\n",
            "Val set: (1277, 10) (1277,) (25,)\n",
            "\n",
            "Train set: (25, 10)\n",
            "Validation set: (1277, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.080 s \n",
            "\n",
            "Accuracy rate is 77.419355 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.85      0.85       321\n",
            "           1       0.57      0.55      0.56       113\n",
            "\n",
            "    accuracy                           0.77       434\n",
            "   macro avg       0.71      0.70      0.70       434\n",
            "weighted avg       0.77      0.77      0.77       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[274  47]\n",
            " [ 51  62]]\n",
            "--------------------------------\n",
            "val predicted: (1277,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1277, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "std (1277,) [ 0. 40. 30. ... 30. 20.  0.]\n",
            "selection [  0 553 550 546 542 536 532 509 504 498 496 466 461 455 454 449 442 434\n",
            " 555 433 559 564 674 667 666] (25,) [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0.]\n",
            "trainset before adding uncertain samples (25, 10) (25,)\n",
            "trainset after adding uncertain samples (50, 10) (50,)\n",
            "updated train set: (50, 10) (50,) unique(labels): [31 19] [0 1]\n",
            "val set: (1252, 10) (1252,)\n",
            "\n",
            "Train set: (50, 10)\n",
            "Validation set: (1252, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.081 s \n",
            "\n",
            "Accuracy rate is 78.571429 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.96      0.87       321\n",
            "           1       0.71      0.30      0.42       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.75      0.63      0.65       434\n",
            "weighted avg       0.77      0.79      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[307  14]\n",
            " [ 79  34]]\n",
            "--------------------------------\n",
            "val predicted: (1252,) [0 0 0 ... 0 0 0]\n",
            "probabilities: (1252, 2) \n",
            " [0 0 0 ... 0 0 0]\n",
            "std (1252,) [ 0.  0. 20. ... 40. 20.  0.]\n",
            "selection [  0 502 498 480 477 475 467 465 459 507 457 453 452 445 444 443 442 438\n",
            " 437 456 508 511 515 629 627] (25,) [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0.]\n",
            "trainset before adding uncertain samples (50, 10) (50,)\n",
            "trainset after adding uncertain samples (75, 10) (75,)\n",
            "updated train set: (75, 10) (75,) unique(labels): [37 38] [0 1]\n",
            "val set: (1227, 10) (1227,)\n",
            "\n",
            "Train set: (75, 10)\n",
            "Validation set: (1227, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 3\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.080 s \n",
            "\n",
            "Accuracy rate is 77.188940 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.86      0.85       321\n",
            "           1       0.57      0.51      0.54       113\n",
            "\n",
            "    accuracy                           0.77       434\n",
            "   macro avg       0.70      0.69      0.69       434\n",
            "weighted avg       0.77      0.77      0.77       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[277  44]\n",
            " [ 55  58]]\n",
            "--------------------------------\n",
            "val predicted: (1227,) [1 0 0 ... 0 0 0]\n",
            "probabilities: (1227, 2) \n",
            " [1 0 0 ... 0 0 0]\n",
            "std (1227,) [30. 20. 30. ... 40. 10. 10.]\n",
            "selection [ 215  918  503  758  501   81  940  220  961   74  965  968  484  223\n",
            "  747  740  472  466  738  736  282  453 1002 1004  127] (25,) [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0.]\n",
            "trainset before adding uncertain samples (75, 10) (75,)\n",
            "trainset after adding uncertain samples (100, 10) (100,)\n",
            "updated train set: (100, 10) (100,) unique(labels): [53 47] [0 1]\n",
            "val set: (1202, 10) (1202,)\n",
            "\n",
            "Train set: (100, 10)\n",
            "Validation set: (1202, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 4\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.093 s \n",
            "\n",
            "Accuracy rate is 77.188940 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.88      0.85       321\n",
            "           1       0.58      0.47      0.52       113\n",
            "\n",
            "    accuracy                           0.77       434\n",
            "   macro avg       0.70      0.67      0.68       434\n",
            "weighted avg       0.76      0.77      0.76       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[282  39]\n",
            " [ 60  53]]\n",
            "--------------------------------\n",
            "val predicted: (1202,) [1 0 0 ... 0 0 1]\n",
            "probabilities: (1202, 2) \n",
            " [1 0 0 ... 0 0 1]\n",
            "std (1202,) [50.  0. 30. ... 40. 30. 20.]\n",
            "selection [ 600  904  203  885  882  222  225  861  860  199  228  234  849  846\n",
            "  247  832  831  826  817  232  811  915  941  115 1031] (25,) [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0.]\n",
            "trainset before adding uncertain samples (100, 10) (100,)\n",
            "trainset after adding uncertain samples (125, 10) (125,)\n",
            "updated train set: (125, 10) (125,) unique(labels): [69 56] [0 1]\n",
            "val set: (1177, 10) (1177,)\n",
            "\n",
            "Train set: (125, 10)\n",
            "Validation set: (1177, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 5\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.108 s \n",
            "\n",
            "Accuracy rate is 77.419355 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.89      0.85       321\n",
            "           1       0.59      0.45      0.51       113\n",
            "\n",
            "    accuracy                           0.77       434\n",
            "   macro avg       0.70      0.67      0.68       434\n",
            "weighted avg       0.76      0.77      0.76       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[285  36]\n",
            " [ 62  51]]\n",
            "--------------------------------\n",
            "val predicted: (1177,) [1 0 0 ... 0 0 1]\n",
            "probabilities: (1177, 2) \n",
            " [1 0 0 ... 0 0 1]\n",
            "std (1177,) [40. 20. 30. ... 40. 40. 30.]\n",
            "selection [ 120  575 1126  319   64  821 1027 1130 1132 1124  757 1133 1053  751\n",
            "   51  305  304  960 1074  755  603  487  918  365 1097] (25,) [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0.]\n",
            "trainset before adding uncertain samples (125, 10) (125,)\n",
            "trainset after adding uncertain samples (150, 10) (150,)\n",
            "updated train set: (150, 10) (150,) unique(labels): [85 65] [0 1]\n",
            "val set: (1152, 10) (1152,)\n",
            "\n",
            "Train set: (150, 10)\n",
            "Validation set: (1152, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 6\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.080 s \n",
            "\n",
            "Accuracy rate is 77.419355 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.89      0.85       321\n",
            "           1       0.59      0.43      0.50       113\n",
            "\n",
            "    accuracy                           0.77       434\n",
            "   macro avg       0.70      0.66      0.68       434\n",
            "weighted avg       0.76      0.77      0.76       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[287  34]\n",
            " [ 64  49]]\n",
            "--------------------------------\n",
            "val predicted: (1152,) [1 0 0 ... 0 0 1]\n",
            "probabilities: (1152, 2) \n",
            " [1 0 0 ... 0 0 1]\n",
            "std (1152,) [40. 10. 20. ... 30. 30. 30.]\n",
            "selection [ 877  562  563  921  735  318  134  135  730 1061  312  311  723  310\n",
            "  570  927  148 1066  326  153  558 1055  780 1127   96] (25,) [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0.]\n",
            "trainset before adding uncertain samples (150, 10) (150,)\n",
            "trainset after adding uncertain samples (175, 10) (175,)\n",
            "updated train set: (175, 10) (175,) unique(labels): [98 77] [0 1]\n",
            "val set: (1127, 10) (1127,)\n",
            "\n",
            "Train set: (175, 10)\n",
            "Validation set: (1127, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 7\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.094 s \n",
            "\n",
            "Accuracy rate is 78.341014 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.90      0.86       321\n",
            "           1       0.61      0.46      0.53       113\n",
            "\n",
            "    accuracy                           0.78       434\n",
            "   macro avg       0.72      0.68      0.69       434\n",
            "weighted avg       0.77      0.78      0.77       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[288  33]\n",
            " [ 61  52]]\n",
            "--------------------------------\n",
            "val predicted: (1127,) [1 0 0 ... 0 0 1]\n",
            "probabilities: (1127, 2) \n",
            " [1 0 0 ... 0 0 1]\n",
            "std (1127,) [40.  0. 20. ... 30. 40. 10.]\n",
            "selection [ 965  126  974  385  967 1086  399  956 1091  945  447  930  473  482\n",
            " 1099  504  912  525  899  547  888  565 1107  885  979] (25,) [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0.]\n",
            "trainset before adding uncertain samples (175, 10) (175,)\n",
            "trainset after adding uncertain samples (200, 10) (200,)\n",
            "updated train set: (200, 10) (200,) unique(labels): [113  87] [0 1]\n",
            "val set: (1102, 10) (1102,)\n",
            "\n",
            "Train set: (200, 10)\n",
            "Validation set: (1102, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 8\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.137 s \n",
            "\n",
            "Accuracy rate is 79.493088 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.92      0.87       321\n",
            "           1       0.66      0.43      0.52       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.74      0.68      0.70       434\n",
            "weighted avg       0.78      0.79      0.78       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[296  25]\n",
            " [ 64  49]]\n",
            "--------------------------------\n",
            "val predicted: (1102,) [1 0 0 ... 0 0 1]\n",
            "probabilities: (1102, 2) \n",
            " [1 0 0 ... 0 0 1]\n",
            "std (1102,) [40.  0. 20. ... 30. 40. 10.]\n",
            "selection [ 161  484  965  515  299  568  841 1046  319  270 1045  269  935  601\n",
            "  604  818  812   52  320   72   73  384  367 1057  930] (25,) [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0.]\n",
            "trainset before adding uncertain samples (200, 10) (200,)\n",
            "trainset after adding uncertain samples (225, 10) (225,)\n",
            "updated train set: (225, 10) (225,) unique(labels): [122 103] [0 1]\n",
            "val set: (1077, 10) (1077,)\n",
            "\n",
            "Train set: (225, 10)\n",
            "Validation set: (1077, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 9\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.082 s \n",
            "\n",
            "Accuracy rate is 79.953917 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.91      0.87       321\n",
            "           1       0.65      0.50      0.56       113\n",
            "\n",
            "    accuracy                           0.80       434\n",
            "   macro avg       0.74      0.70      0.72       434\n",
            "weighted avg       0.79      0.80      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[291  30]\n",
            " [ 57  56]]\n",
            "--------------------------------\n",
            "val predicted: (1077,) [1 1 0 ... 0 0 0]\n",
            "probabilities: (1077, 2) \n",
            " [1 1 0 ... 0 0 0]\n",
            "std (1077,) [40. 10.  0. ... 10. 40.  0.]\n",
            "selection [1076  760  778  637  234  980   48  629  243  748  558  976  370  368\n",
            "  359   37   62  617   68  329  328 1047  272  159   80] (25,) [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0.]\n",
            "trainset before adding uncertain samples (225, 10) (225,)\n",
            "trainset after adding uncertain samples (250, 10) (250,)\n",
            "updated train set: (250, 10) (250,) unique(labels): [135 115] [0 1]\n",
            "val set: (1052, 10) (1052,)\n",
            "\n",
            "Train set: (250, 10)\n",
            "Validation set: (1052, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 10\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.079 s \n",
            "\n",
            "Accuracy rate is 78.341014 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.89      0.86       321\n",
            "           1       0.61      0.47      0.53       113\n",
            "\n",
            "    accuracy                           0.78       434\n",
            "   macro avg       0.72      0.68      0.69       434\n",
            "weighted avg       0.77      0.78      0.77       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[287  34]\n",
            " [ 60  53]]\n",
            "--------------------------------\n",
            "val predicted: (1052,) [1 0 0 ... 0 0 0]\n",
            "probabilities: (1052, 2) \n",
            " [1 0 0 ... 0 0 0]\n",
            "std (1052,) [40.  0. 10. ... 10. 20. 50.]\n",
            "selection [ 499  345  917  580  921  924  713  595  291  283  945  725  951  246\n",
            "  622  628   89  968  207  774  190  770  141 1018  743] (25,) [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0.]\n",
            "trainset before adding uncertain samples (250, 10) (250,)\n",
            "trainset after adding uncertain samples (275, 10) (275,)\n",
            "updated train set: (275, 10) (275,) unique(labels): [147 128] [0 1]\n",
            "val set: (1027, 10) (1027,)\n",
            "\n",
            "Train set: (275, 10)\n",
            "Validation set: (1027, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 11\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.085 s \n",
            "\n",
            "Accuracy rate is 79.032258 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.91      0.86       321\n",
            "           1       0.63      0.46      0.53       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.73      0.68      0.70       434\n",
            "weighted avg       0.78      0.79      0.78       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[291  30]\n",
            " [ 61  52]]\n",
            "--------------------------------\n",
            "val predicted: (1027,) [1 0 0 ... 0 0 0]\n",
            "probabilities: (1027, 2) \n",
            " [1 0 0 ... 0 0 0]\n",
            "std (1027,) [30.  0. 10. ... 20. 20. 50.]\n",
            "selection [ 183  431  863  960   89  412  674 1020  596  402  660  239  968  614\n",
            " 1018  744  625  635  748  356  187  354   97  288  529] (25,) [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0.]\n",
            "trainset before adding uncertain samples (275, 10) (275,)\n",
            "trainset after adding uncertain samples (300, 10) (300,)\n",
            "updated train set: (300, 10) (300,) unique(labels): [159 141] [0 1]\n",
            "val set: (1002, 10) (1002,)\n",
            "\n",
            "Train set: (300, 10)\n",
            "Validation set: (1002, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 12\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.096 s \n",
            "\n",
            "Accuracy rate is 79.032258 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.90      0.86       321\n",
            "           1       0.62      0.49      0.55       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.73      0.69      0.71       434\n",
            "weighted avg       0.78      0.79      0.78       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[288  33]\n",
            " [ 58  55]]\n",
            "--------------------------------\n",
            "val predicted: (1002,) [1 0 0 ... 0 0 0]\n",
            "probabilities: (1002, 2) \n",
            " [1 0 0 ... 0 0 0]\n",
            "std (1002,) [40.  0. 20. ... 20. 20. 50.]\n",
            "selection [499 713  96 631  93 887 463 989 350 130 528 757 423 583 664 788  72 166\n",
            " 704 111   1 121 884 716 534] (25,) [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
            "  0.  0.  0.  0.  0. 10. 10.]\n",
            "trainset before adding uncertain samples (300, 10) (300,)\n",
            "trainset after adding uncertain samples (325, 10) (325,)\n",
            "updated train set: (325, 10) (325,) unique(labels): [170 155] [0 1]\n",
            "val set: (977, 10) (977,)\n",
            "\n",
            "Train set: (325, 10)\n",
            "Validation set: (977, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 13\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.067 s \n",
            "\n",
            "Accuracy rate is 79.032258 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.89      0.86       321\n",
            "           1       0.62      0.50      0.56       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.73      0.70      0.71       434\n",
            "weighted avg       0.78      0.79      0.78       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[286  35]\n",
            " [ 56  57]]\n",
            "--------------------------------\n",
            "val predicted: (977,) [1 0 1 1 0 0 1 1 0 0 1 0 1 0 0 1 1 1 1 0 1 0 1 0 0 0 0 1 0 0 1 0 1 1 1 1 1\n",
            " 0 0 0 1 1 0 0 1 0 1 0 1 0 0 1 0 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1 0 0 1 1 1 1\n",
            " 1 0 1 0 1 0 0 1 0 0 1 1 0 0 0 1 0 1 1 1 1 0 1 0 0 1 1 1 0 0 0 0 1 1 0 0 1\n",
            " 0 0 1 0 1 1 0 0 1 0 0 1 0 0 1 0 0 0 0 1 1 0 1 1 1 0 1 1 0 0 1 1 1 1 1 0 1\n",
            " 1 1 1 1 1 0 1 0 1 1 0 0 1 1 0 1 1 1 1 1 0 1 0 0 0 1 0 1 1 1 1 1 0 1 0 0 1\n",
            " 1 0 1 1 1 0 0 0 0 0 1 0 0 1 1 1 0 0 1 0 0 0 0 1 1 1 0 1 0 0 1 0 1 0 1 1 0\n",
            " 1 1 0 0 1 1 0 0 0 0 1 1 0 1 1 0 1 1 1 1 1 1 1 0 0 1 1 0 0 1 1 1 1 1 0 1 1\n",
            " 0 1 1 1 1 0 1 1 0 1 1 1 1 1 0 0 1 0 1 1 0 0 1 1 1 1 1 0 0 0 0 0 1 0 0 1 0\n",
            " 1 0 0 0 1 0 1 0 1 0 1 0 0 1 0 0 0 0 0 0 1 1 1 1 1 0 0 1 1 0 1 1 0 1 0 1 0\n",
            " 1 1 0 0 0 1 1 0 1 1 1 0 1 1 0 1 0 0 0 1 1 0 1 0 1 0 1 1 1 1 1 0 1 1 1 1 1\n",
            " 1 0 0 0 1 0 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 0 1 0 1 0 0 1 1 1 1 1\n",
            " 0 0 1 1 0 1 0 1 1 0 1 1 0 0 1 0 1 1 1 1 0 0 1 1 1 1 1 0 1 0 1 0 1 1 0 0 0\n",
            " 0 0 0 1 1 1 1 0 1 1 0 0 1 0 1 1 1 0 1 0 0 1 0 0 0 1 0 0 0 0 0 1 1 0 1 0 1\n",
            " 0 0 1 0 1 0 0 1 1 1 0 1 1 1 1 0 1 1 0 0 1 0 1 1 0 1 1 0 1 1 1 0 1 0 1 0 0\n",
            " 0 0 1 1 0 1 0 1 1 0 1 1 0 1 1 0 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 0 1 1 0 0\n",
            " 0 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 1 0 0 1 0 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1\n",
            " 0 1 1 0 0 1 0 0 1 0 0 1 1 0 1 1 0 0 0 1 0 1 0 1 0 1 1 1 1 1 0 1 1 0 0 0 1\n",
            " 1 1 1 1 1 0 0 1 1 1 0 1 1 0 1 1 0 0 1 1 0 0 1 1 1 1 0 1 1 0 1 1 1 1 0 1 0\n",
            " 1 1 0 1 0 1 0 1 1 0 0 0 0 1 0 1 0 1 1 1 0 1 0 0 1 0 1 0 0 0 1 0 1 1 1 0 1\n",
            " 0 0 1 0 1 0 1 1 1 1 1 1 0 0 0 0 0 1 0 1 1 1 0 0 1 0 0 1 0 1 0 1 0 0 0 1 0\n",
            " 1 1 1 1 0 0 0 1 0 0 1 1 1 1 0 0 0 0 1 1 0 0 1 1 0 1 1 1 0 0 1 0 0 1 1 0 1\n",
            " 0 0 1 0 1 1 1 1 0 1 0 0 0 0 0 0 0 1 0 1 1 0 1 1 1 1 1 1 1 0 0 1 0 0 1 0 1\n",
            " 1 1 1 1 1 1 0 1 0 0 0 0 1 0 0 1 1 0 1 1 0 1 0 0 0 0 0 1 0 0 1 1 1 0 1 1 0\n",
            " 0 0 1 1 0 0 1 1 0 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 1 1 1 0 1 1 0 1 1 0 1 1 0\n",
            " 0 1 1 1 0 0 1 1 1 1 1 1 0 1 1 0 1 1 0 1 0 0 0 1 0 1 1 1 0 0 1 0 1 0 1 1 0\n",
            " 1 0 1 0 1 1 1 1 1 0 0 1 1 1 0 0 0 0 1 0 0 1 1 1 0 1 1 1 1 1 0 1 0 1 0 1 1\n",
            " 0 0 1 1 0 0 0 1 0 1 1 1 0 0 0]\n",
            "probabilities: (977, 2) \n",
            " [1 0 1 1 0 0 1 1 0 0 1 0 1 0 0 1 1 1 1 0 1 0 1 0 0 0 0 1 0 0 1 0 1 1 1 1 1\n",
            " 0 0 0 1 1 0 0 1 0 1 0 1 0 0 1 0 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1 0 0 1 1 1 1\n",
            " 1 0 1 0 1 0 0 1 0 0 1 1 0 0 0 1 0 1 1 1 1 0 1 0 0 1 1 1 0 0 0 0 1 1 0 0 1\n",
            " 0 0 1 0 1 1 0 0 1 0 0 1 0 0 1 0 0 0 0 1 1 0 1 1 1 0 1 1 0 0 1 1 1 1 1 0 1\n",
            " 1 1 1 1 1 0 1 0 1 1 0 0 1 1 0 1 1 1 1 1 0 1 0 0 0 1 0 1 1 1 1 1 0 1 0 0 1\n",
            " 1 0 1 1 1 0 0 0 0 0 1 0 0 1 1 1 0 0 1 0 0 0 0 1 1 1 0 1 0 0 1 0 1 0 1 1 0\n",
            " 1 1 0 0 1 1 0 0 0 0 1 1 0 1 1 0 1 1 1 1 1 1 1 0 0 1 1 0 0 1 1 1 1 1 0 1 1\n",
            " 0 1 1 1 1 0 1 1 0 1 1 1 1 1 0 0 1 0 1 1 0 0 1 1 1 1 1 0 0 0 0 0 1 0 0 1 0\n",
            " 1 0 0 0 1 0 1 0 1 0 1 0 0 1 0 0 0 0 0 0 1 1 1 1 1 0 0 1 1 0 1 1 0 1 0 1 0\n",
            " 1 1 0 0 0 1 1 0 1 1 1 0 1 1 0 1 0 0 0 1 1 0 1 0 1 0 1 1 1 1 1 0 1 1 1 1 1\n",
            " 1 0 0 0 1 0 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 0 1 0 1 0 0 1 1 1 1 1\n",
            " 0 0 1 1 0 1 0 1 1 0 1 1 0 0 1 0 1 1 1 1 0 0 1 1 1 1 1 0 1 0 1 0 1 1 0 0 0\n",
            " 0 0 0 1 1 1 1 0 1 1 0 0 1 0 1 1 1 0 1 0 0 1 0 0 0 1 0 0 0 0 0 1 1 0 1 0 1\n",
            " 0 0 1 0 1 0 0 1 1 1 0 1 1 1 1 0 1 1 0 0 1 0 1 1 0 1 1 0 1 1 1 0 1 0 1 0 0\n",
            " 0 0 1 1 0 1 0 1 1 0 1 1 0 1 1 0 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 0 1 1 0 0\n",
            " 0 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 1 0 0 1 0 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1\n",
            " 0 1 1 0 0 1 0 0 1 0 0 1 1 0 1 1 0 0 0 1 0 1 0 1 0 1 1 1 1 1 0 1 1 0 0 0 1\n",
            " 1 1 1 1 1 0 0 1 1 1 0 1 1 0 1 1 0 0 1 1 0 0 1 1 1 1 0 1 1 0 1 1 1 1 0 1 0\n",
            " 1 1 0 1 0 1 0 1 1 0 0 0 0 1 0 1 0 1 1 1 0 1 0 0 1 0 1 0 0 0 1 0 1 1 1 0 1\n",
            " 0 0 1 0 1 0 1 1 1 1 1 1 0 0 0 0 0 1 0 1 1 1 0 0 1 0 0 1 0 1 0 1 0 0 0 1 0\n",
            " 1 1 1 1 0 0 0 1 0 0 1 1 1 1 0 0 0 0 1 1 0 0 1 1 0 1 1 1 0 0 1 0 0 1 1 0 1\n",
            " 0 0 1 0 1 1 1 1 0 1 0 0 0 0 0 0 0 1 0 1 1 0 1 1 1 1 1 1 1 0 0 1 0 0 1 0 1\n",
            " 1 1 1 1 1 1 0 1 0 0 0 0 1 0 0 1 1 0 1 1 0 1 0 0 0 0 0 1 0 0 1 1 1 0 1 1 0\n",
            " 0 0 1 1 0 0 1 1 0 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 1 1 1 0 1 1 0 1 1 0 1 1 0\n",
            " 0 1 1 1 0 0 1 1 1 1 1 1 0 1 1 0 1 1 0 1 0 0 0 1 0 1 1 1 0 0 1 0 1 0 1 1 0\n",
            " 1 0 1 0 1 1 1 1 1 0 0 1 1 1 0 0 0 0 1 0 0 1 1 1 0 1 1 1 1 1 0 1 0 1 0 1 1\n",
            " 0 0 1 1 0 0 0 1 0 1 1 1 0 0 0]\n",
            "std (977,) [40. 10. 20. 10.  0. 10. 50. 30. 30. 20. 20. 40. 10. 20. 10. 40. 10. 50.\n",
            " 50. 30. 30. 40. 20. 20. 10. 10. 20. 20. 30. 10. 30. 30. 10. 50. 40. 30.\n",
            " 40. 20. 30. 30. 30. 30. 40. 40. 30. 20. 20. 30. 40. 50. 20. 40.  0. 20.\n",
            " 20. 10. 50. 20. 50. 10. 30. 30. 40. 30. 20. 40. 20. 40. 40. 20. 30. 30.\n",
            " 50. 30. 50. 30. 10. 10. 40. 40. 20. 30. 40. 10. 50. 30. 40. 20. 30. 30.\n",
            " 20. 40. 50. 20. 30. 30. 30. 20. 40. 20. 10. 30. 40. 30. 10. 40. 40. 40.\n",
            " 20. 20. 50. 20. 30. 40. 30. 50. 50. 10. 20. 40. 40. 20. 40. 40. 30. 40.\n",
            " 10. 30. 20. 30. 50. 20. 10. 20. 20. 40. 40. 20. 10. 10. 30. 40. 10. 20.\n",
            " 10. 20. 20. 40. 30. 30. 50. 50. 20. 20. 30. 20. 50. 40. 20. 40. 50. 30.\n",
            " 30. 50. 20. 30. 50. 20. 40. 40. 30. 10. 10. 50. 30. 40. 50. 20. 30. 30.\n",
            " 30. 30. 30. 40. 30. 20. 50. 50. 20. 30. 40. 40. 40. 30. 20. 30. 20. 40.\n",
            " 20. 30. 40. 10. 30. 20. 30. 30. 30. 30. 10. 50. 10. 10. 30. 30. 40. 10.\n",
            " 40. 10. 10. 40. 30. 40. 40. 30. 20. 40. 30. 50. 20. 20. 50. 30. 30. 50.\n",
            " 30. 20. 30. 20. 30. 10. 50. 40. 20. 30. 30. 40. 40. 30. 50. 30. 30. 40.\n",
            " 50. 40. 50. 50. 50. 40. 40. 30. 50. 50. 50. 20. 20. 40. 20. 30. 50. 40.\n",
            " 20. 40. 20. 40. 20. 30. 40. 30. 50. 20. 10. 10. 20. 40. 40. 40. 40. 40.\n",
            " 20. 40. 10. 10. 10. 30. 50. 40. 30.  0. 40. 40. 20. 30. 50. 30. 20. 40.\n",
            " 20. 30. 40. 30. 20. 10. 20. 40. 50. 30. 30. 10. 50. 50. 10. 10.  0. 40.\n",
            " 50. 40. 30. 50. 40. 50. 20. 50. 20. 30. 30. 40. 20. 20. 40. 50. 10. 50.\n",
            " 20. 30. 30. 50. 50. 30. 50. 30. 30. 40. 50. 40. 40. 50. 30. 40. 10. 20.\n",
            " 50. 40. 40. 50. 20. 40. 20. 20. 50. 30. 50. 30. 40. 30. 30. 20. 20. 10.\n",
            " 10.  0. 50. 50. 30. 40. 40. 30. 30. 30. 40. 40. 30. 40. 40. 50. 30. 50.\n",
            " 50. 40. 20. 50. 20. 20. 40. 50. 50. 40. 50. 30. 30. 30. 40. 50. 40. 20.\n",
            " 30. 20. 20. 50. 30.  0. 40. 40.  0. 30. 10. 40. 20. 40. 10. 50. 30. 10.\n",
            " 10. 20. 30. 40. 30. 20. 40. 50. 50. 20. 30. 30. 10. 20. 20. 20. 30. 30.\n",
            " 30.  0. 50. 20. 30. 40. 30. 30. 50. 30. 30. 30. 40. 40. 20. 20. 30. 20.\n",
            " 30. 20. 30. 40. 40. 10. 50. 40. 30. 30. 10. 20. 10. 30. 20. 30. 40. 30.\n",
            " 20. 30. 50. 30. 50. 30. 40. 30. 50. 30.  0. 40. 40. 40. 40. 50. 20. 20.\n",
            " 50. 40. 40. 50. 40. 40. 50. 20. 20. 50. 20. 50. 30. 30. 40. 20. 40. 40.\n",
            " 30. 40. 30. 50. 30. 20. 20. 40. 20. 40. 40. 20. 30. 50. 20. 20. 30. 40.\n",
            " 40. 40. 10. 20. 30. 50. 40. 40. 20. 30. 10. 10. 20. 50.  0. 20. 40. 30.\n",
            " 40. 30. 30. 30. 40. 30. 50. 30. 30. 40. 40. 10.  0. 10. 50. 40. 40. 40.\n",
            " 20. 30. 50. 30. 40. 40. 40. 50. 30. 20. 40. 10. 50. 20. 30. 40. 40. 20.\n",
            " 30. 30. 40. 40. 20. 40. 40. 30. 40. 50. 30. 50. 30. 40. 10. 30. 10. 40.\n",
            " 10. 30.  0. 20. 30. 50. 30. 50. 30. 40. 40. 30. 50. 30. 50. 30. 30. 50.\n",
            " 50. 40. 30. 30. 40. 30. 50. 40. 20. 10. 40. 50. 30. 30. 30. 50. 20. 30.\n",
            " 50. 30. 30. 20. 50. 40. 50. 20. 20. 40. 10. 50. 30. 30. 10. 10. 40. 20.\n",
            " 50. 20. 10. 30. 40. 40. 40. 40. 20. 10. 10. 40. 40. 40. 20. 40. 20. 20.\n",
            " 50. 20. 20. 30. 40. 50. 40. 40. 40. 30. 10. 10. 30. 40. 40. 20. 40. 10.\n",
            " 40. 30. 40. 50. 30. 40. 30. 20. 10. 10. 50. 30. 30. 30. 10. 30. 10. 40.\n",
            " 40. 30. 50. 20. 50. 30. 30. 20. 40. 40. 50. 40. 40. 30. 20. 30. 40. 50.\n",
            " 30. 40. 40. 50. 40. 30. 30. 30. 40. 40. 30. 20. 10. 30. 20. 40. 40. 40.\n",
            " 40. 40. 40. 30. 40. 50. 50. 40. 30. 40. 40. 40. 30. 50. 50. 30. 20. 30.\n",
            " 30. 50. 20. 40. 30. 50. 10. 40. 30. 20. 40. 30. 30. 40. 40. 30. 50. 30.\n",
            " 10. 20. 30. 30. 10. 40. 10. 30. 20. 30. 20. 10. 20. 30. 20. 20. 50.  0.\n",
            " 30. 30. 20. 40. 30. 30. 40. 40. 40. 20. 10. 30. 20. 30. 40. 10. 40. 10.\n",
            " 40. 40. 20. 10. 30. 30. 40. 30. 20. 40. 30. 20. 10. 20. 40. 20. 50. 40.\n",
            " 40. 30. 50. 30. 10. 30. 40. 40. 30. 10. 40. 30. 50. 30. 40. 30. 20. 40.\n",
            " 50. 50. 10. 10. 40. 30. 40. 40. 30. 40. 20. 40. 50. 40. 20. 20. 40. 40.\n",
            " 10. 50. 30. 40. 40. 20. 20. 20. 40. 50. 30. 40. 20. 40. 30. 20. 20. 30.\n",
            " 20. 30. 40. 40. 40. 40. 10. 50. 30. 40. 40. 20. 20. 50. 50. 50. 30. 30.\n",
            " 20. 30. 40. 10. 20. 40. 20. 10. 30. 50. 50. 20. 40. 30. 40. 40. 30. 40.\n",
            " 40. 30. 20. 30. 30. 40. 40. 20. 20. 20. 10. 50. 20. 30. 30. 40. 20. 50.\n",
            " 40. 20. 30. 40. 20. 10. 10. 30. 20. 40. 30. 10.  0. 40. 40. 50.  0. 20.\n",
            " 30. 40. 20. 20. 50.]\n",
            "selection [554 966 451  52 322 970 614 496 422 379 419 570 297 809   4 280 694 587\n",
            " 311 317 138 320 139 321 142] (25,) [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. 10. 10. 10.\n",
            " 10. 10. 10. 10. 10. 10. 10.]\n",
            "trainset before adding uncertain samples (325, 10) (325,)\n",
            "trainset after adding uncertain samples (350, 10) (350,)\n",
            "updated train set: (350, 10) (350,) unique(labels): [181 169] [0 1]\n",
            "val set: (952, 10) (952,)\n",
            "\n",
            "Train set: (350, 10)\n",
            "Validation set: (952, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 14\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.113 s \n",
            "\n",
            "Accuracy rate is 79.262673 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.89      0.86       321\n",
            "           1       0.62      0.52      0.57       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.73      0.70      0.72       434\n",
            "weighted avg       0.78      0.79      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[285  36]\n",
            " [ 54  59]]\n",
            "--------------------------------\n",
            "val predicted: (952,) [1 1 1 1 0 1 1 0 0 1 0 1 0 0 1 1 1 1 0 1 0 1 0 1 0 0 1 0 0 1 0 1 1 1 1 1 0\n",
            " 0 0 1 1 0 0 1 0 1 0 1 0 0 1 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 0\n",
            " 1 0 1 0 0 1 0 0 1 1 0 0 0 1 0 1 1 1 1 0 1 0 0 1 0 1 0 0 0 0 1 1 0 0 1 0 0\n",
            " 1 0 1 1 0 0 1 0 0 1 0 0 1 0 0 0 0 1 1 0 1 1 1 0 1 0 1 1 1 1 0 1 1 1 1 1 1\n",
            " 0 1 0 1 1 0 0 1 1 0 1 1 1 1 1 0 1 0 0 0 1 0 1 1 1 1 1 0 1 0 0 1 1 0 1 1 1\n",
            " 0 0 0 0 0 1 0 0 1 1 1 0 0 1 0 0 0 0 1 1 1 0 1 0 0 1 0 1 0 1 1 0 1 1 0 0 1\n",
            " 1 0 0 0 0 1 1 0 1 1 0 1 1 1 1 1 1 1 0 0 1 1 0 0 1 1 1 1 1 0 1 1 0 1 1 1 1\n",
            " 0 1 1 0 1 1 1 1 1 0 0 1 0 1 1 0 1 1 1 1 1 0 0 0 0 0 1 0 0 1 0 1 0 0 1 0 1\n",
            " 0 1 0 1 0 0 1 0 0 0 0 0 1 1 1 1 1 0 1 1 0 1 0 1 0 1 1 0 0 0 1 1 0 1 1 1 0\n",
            " 1 1 0 1 0 0 0 1 1 0 1 0 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 0 0 1 0 1 1 1 1 1 1\n",
            " 1 1 0 1 1 1 1 1 0 1 1 1 1 0 1 0 1 0 0 1 1 1 1 1 0 0 1 1 0 1 0 1 1 0 1 1 0\n",
            " 1 1 1 1 1 0 0 1 1 1 1 1 0 1 0 1 0 1 1 0 0 0 0 0 0 1 1 1 1 1 1 0 0 1 0 1 1\n",
            " 1 0 1 0 0 1 0 0 0 1 0 0 0 1 0 1 1 0 1 0 0 0 0 1 0 1 0 0 1 1 1 0 1 1 1 1 1\n",
            " 1 0 0 1 0 1 1 0 1 1 0 1 1 1 0 1 0 1 0 0 0 0 1 1 0 1 0 1 1 0 1 1 0 1 1 0 0\n",
            " 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 0 1 1 0 0 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 1 0\n",
            " 0 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 0 0 1 0 0 1 1 0 1 1 0 0 0 1\n",
            " 0 1 1 0 1 1 1 1 1 0 1 1 0 0 0 1 1 1 1 1 1 0 0 1 1 1 0 1 1 0 1 1 0 0 1 1 0\n",
            " 0 1 1 1 1 0 1 1 1 1 1 1 1 0 1 0 1 1 0 1 0 1 0 1 1 0 0 0 0 1 0 1 0 1 1 1 0\n",
            " 1 0 0 1 0 1 0 0 1 0 1 1 1 0 1 0 0 1 0 1 0 1 0 1 1 1 1 0 0 0 0 0 1 0 1 1 1\n",
            " 0 0 1 0 0 1 0 1 0 1 0 0 0 1 0 1 1 1 1 0 0 0 1 0 0 1 1 1 1 0 0 0 0 1 1 0 0\n",
            " 1 1 0 1 1 1 0 0 1 0 0 1 1 0 1 0 0 1 0 1 1 1 1 0 1 0 0 0 0 0 0 0 1 0 1 1 0\n",
            " 1 1 1 1 1 1 1 0 0 1 0 1 0 1 1 1 1 1 1 1 0 1 0 0 0 0 1 0 0 1 1 0 1 1 0 1 0\n",
            " 0 0 0 0 1 0 0 1 1 1 0 1 1 0 0 0 1 1 0 0 1 1 0 0 1 1 1 1 1 1 0 0 1 1 1 0 0\n",
            " 1 1 1 1 0 1 1 0 1 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1 1 0 1 1 0 1 1 0 1 0 0 0\n",
            " 1 0 1 1 1 0 0 1 0 1 0 1 1 0 1 0 1 0 1 1 1 1 1 0 0 1 1 1 0 0 0 0 1 0 0 1 1\n",
            " 1 0 1 1 1 1 1 0 1 0 1 0 1 1 0 0 1 1 0 0 1 1 1 1 0 0 0]\n",
            "probabilities: (952, 2) \n",
            " [1 1 1 1 0 1 1 0 0 1 0 1 0 0 1 1 1 1 0 1 0 1 0 1 0 0 1 0 0 1 0 1 1 1 1 1 0\n",
            " 0 0 1 1 0 0 1 0 1 0 1 0 0 1 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 0\n",
            " 1 0 1 0 0 1 0 0 1 1 0 0 0 1 0 1 1 1 1 0 1 0 0 1 0 1 0 0 0 0 1 1 0 0 1 0 0\n",
            " 1 0 1 1 0 0 1 0 0 1 0 0 1 0 0 0 0 1 1 0 1 1 1 0 1 0 1 1 1 1 0 1 1 1 1 1 1\n",
            " 0 1 0 1 1 0 0 1 1 0 1 1 1 1 1 0 1 0 0 0 1 0 1 1 1 1 1 0 1 0 0 1 1 0 1 1 1\n",
            " 0 0 0 0 0 1 0 0 1 1 1 0 0 1 0 0 0 0 1 1 1 0 1 0 0 1 0 1 0 1 1 0 1 1 0 0 1\n",
            " 1 0 0 0 0 1 1 0 1 1 0 1 1 1 1 1 1 1 0 0 1 1 0 0 1 1 1 1 1 0 1 1 0 1 1 1 1\n",
            " 0 1 1 0 1 1 1 1 1 0 0 1 0 1 1 0 1 1 1 1 1 0 0 0 0 0 1 0 0 1 0 1 0 0 1 0 1\n",
            " 0 1 0 1 0 0 1 0 0 0 0 0 1 1 1 1 1 0 1 1 0 1 0 1 0 1 1 0 0 0 1 1 0 1 1 1 0\n",
            " 1 1 0 1 0 0 0 1 1 0 1 0 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 0 0 1 0 1 1 1 1 1 1\n",
            " 1 1 0 1 1 1 1 1 0 1 1 1 1 0 1 0 1 0 0 1 1 1 1 1 0 0 1 1 0 1 0 1 1 0 1 1 0\n",
            " 1 1 1 1 1 0 0 1 1 1 1 1 0 1 0 1 0 1 1 0 0 0 0 0 0 1 1 1 1 1 1 0 0 1 0 1 1\n",
            " 1 0 1 0 0 1 0 0 0 1 0 0 0 1 0 1 1 0 1 0 0 0 0 1 0 1 0 0 1 1 1 0 1 1 1 1 1\n",
            " 1 0 0 1 0 1 1 0 1 1 0 1 1 1 0 1 0 1 0 0 0 0 1 1 0 1 0 1 1 0 1 1 0 1 1 0 0\n",
            " 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 0 1 1 0 0 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 1 0\n",
            " 0 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 0 0 1 0 0 1 1 0 1 1 0 0 0 1\n",
            " 0 1 1 0 1 1 1 1 1 0 1 1 0 0 0 1 1 1 1 1 1 0 0 1 1 1 0 1 1 0 1 1 0 0 1 1 0\n",
            " 0 1 1 1 1 0 1 1 1 1 1 1 1 0 1 0 1 1 0 1 0 1 0 1 1 0 0 0 0 1 0 1 0 1 1 1 0\n",
            " 1 0 0 1 0 1 0 0 1 0 1 1 1 0 1 0 0 1 0 1 0 1 0 1 1 1 1 0 0 0 0 0 1 0 1 1 1\n",
            " 0 0 1 0 0 1 0 1 0 1 0 0 0 1 0 1 1 1 1 0 0 0 1 0 0 1 1 1 1 0 0 0 0 1 1 0 0\n",
            " 1 1 0 1 1 1 0 0 1 0 0 1 1 0 1 0 0 1 0 1 1 1 1 0 1 0 0 0 0 0 0 0 1 0 1 1 0\n",
            " 1 1 1 1 1 1 1 0 0 1 0 1 0 1 1 1 1 1 1 1 0 1 0 0 0 0 1 0 0 1 1 0 1 1 0 1 0\n",
            " 0 0 0 0 1 0 0 1 1 1 0 1 1 0 0 0 1 1 0 0 1 1 0 0 1 1 1 1 1 1 0 0 1 1 1 0 0\n",
            " 1 1 1 1 0 1 1 0 1 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1 1 0 1 1 0 1 1 0 1 0 0 0\n",
            " 1 0 1 1 1 0 0 1 0 1 0 1 1 0 1 0 1 0 1 1 1 1 1 0 0 1 1 1 0 0 0 0 1 0 0 1 1\n",
            " 1 0 1 1 1 1 1 0 1 0 1 0 1 1 0 0 1 1 0 0 1 1 1 1 0 0 0]\n",
            "std (952,) [40. 10. 30. 20. 10. 50. 40. 30. 20. 20. 30. 10. 10. 20. 50. 10. 50. 50.\n",
            " 40. 30. 40. 20. 20. 10.  0. 20. 10. 30. 30. 30. 40. 10. 50. 40. 30. 40.\n",
            " 10. 30. 20. 20. 30. 40. 40. 30. 30. 20. 30. 30. 50. 10. 30. 20. 20. 20.\n",
            " 50. 20. 50. 20. 20. 30. 40. 30. 30. 40. 20. 40. 40. 10. 40. 30. 50. 30.\n",
            " 50. 30. 20. 10. 40. 40. 20. 30. 40. 10. 50. 30. 30. 30. 40. 30. 20. 40.\n",
            " 50. 20. 20. 30. 30. 20. 40. 30.  0. 40. 40. 30. 20. 40. 40. 40. 20. 20.\n",
            " 50. 30. 30. 50. 30. 50. 50.  0. 20. 30. 40. 20. 40. 40. 30. 30. 10. 40.\n",
            " 30. 30. 50. 20.  0. 10. 20. 40. 40. 20. 30. 40. 20. 20. 30. 20. 40. 20.\n",
            " 20. 50. 50. 10. 30. 30. 20. 50. 40. 20. 40. 50. 30. 20. 50. 20. 30. 50.\n",
            " 20. 30. 30. 30. 10. 20. 50. 30. 30. 50. 30. 30. 30. 30. 30. 30. 40. 30.\n",
            " 30. 50. 50. 20. 30. 30. 40. 40. 20. 30. 30. 20. 40. 20. 20. 40. 10. 30.\n",
            " 20. 30. 30. 10. 30. 10. 50. 10. 20. 20. 30. 40. 20. 40. 10. 20. 40. 30.\n",
            " 40. 50. 20. 20. 40. 40. 50. 20. 30. 50. 30. 30. 50. 20. 20. 20. 20. 30.\n",
            " 10. 50. 40. 20. 30. 30. 50. 40. 20. 50. 30. 30. 40. 50. 30. 50. 50. 50.\n",
            " 40. 40. 30. 50. 50. 50. 30. 20. 40. 20. 30. 50. 40. 20. 40. 20. 50. 20.\n",
            " 20. 40. 40. 50. 30. 20. 20. 40. 40. 40. 30. 40. 30. 40. 10. 10. 10. 20.\n",
            " 50. 40. 30. 40. 30. 20. 30. 50. 30. 20. 40. 20. 30. 40. 30. 20. 20. 40.\n",
            " 50. 30. 30. 50. 50. 50. 50. 40. 40. 50. 40. 50. 20. 50. 20. 30. 30. 40.\n",
            " 30. 20. 40. 50. 10. 50. 20. 30. 40. 50. 50. 30. 40. 20. 20. 40. 50. 30.\n",
            " 40. 50. 40. 50. 10. 20. 50. 40. 40. 50. 20. 40. 20. 30. 40. 30. 50. 30.\n",
            " 40. 30. 30. 20. 10. 20. 10. 50. 50. 30. 40. 40. 40. 20. 20. 40. 50. 30.\n",
            " 40. 40. 50. 30. 50. 50. 40. 30. 50. 20. 20. 40. 50. 50. 40. 50. 30. 40.\n",
            " 30. 40. 50. 40. 10. 30. 20. 20. 50. 20. 40. 40. 30. 10. 40. 20. 40. 20.\n",
            " 50. 30. 10. 10. 20. 30. 40. 30. 20. 30. 40. 50. 10. 30. 40. 10. 20. 20.\n",
            " 10. 30. 40. 30. 40. 10. 20. 40. 20. 20. 50. 30. 20. 30. 40. 40. 20. 20.\n",
            " 30. 20. 20. 10. 40. 40. 40. 10. 50. 40. 30. 30. 10. 20.  0. 30. 30. 30.\n",
            " 30. 30. 30. 30. 50. 30. 50. 30. 40. 30. 50. 20. 40. 40. 40. 30. 50. 20.\n",
            " 20. 50. 40. 40. 50. 40. 40. 50. 30. 20. 50.  0. 50. 30. 20. 40. 30. 40.\n",
            " 40. 30. 40. 40. 50. 40. 30. 20. 30. 20. 40. 40. 10. 40. 40. 30. 20. 30.\n",
            " 40. 30. 40. 10. 20. 20. 50. 40. 40. 20. 30. 20. 10. 30. 40. 10. 40. 30.\n",
            " 30. 30. 20. 20. 40. 30. 50. 40. 30. 40. 20. 10. 10. 50. 30. 40. 40. 20.\n",
            " 20. 50. 30. 30. 40. 40. 50. 30. 10. 40. 50. 20. 30. 40. 40. 10. 30. 30.\n",
            " 40. 40. 30. 30. 40. 30. 40. 50. 20. 40. 30. 40. 10. 30. 10. 40. 10. 20.\n",
            " 20. 20. 50. 30. 50. 30. 40. 40. 30. 50. 40. 50. 30. 30. 50. 50. 50. 40.\n",
            " 20. 40. 30. 50. 30. 20.  0. 40. 50. 30. 30. 30. 50. 20. 20. 50. 30. 40.\n",
            " 10. 50. 40. 50. 30. 20. 40. 10. 50. 40. 30. 10. 20. 40. 20. 50. 20. 20.\n",
            " 40. 40. 40. 50. 30. 20. 10. 20. 40. 40. 30.  0. 40. 20. 20. 50. 20. 30.\n",
            " 20. 40. 50. 50. 40. 40. 30. 10. 30. 40. 40. 20. 40. 10. 40. 30. 40. 50.\n",
            " 30. 30. 30. 30.  0. 10. 50. 20. 30. 40. 10. 30. 10. 40. 30. 30. 50. 20.\n",
            " 50. 20. 30. 20. 40. 40. 50. 40. 30. 30. 10. 30. 40. 50. 30. 50. 40. 50.\n",
            " 40. 30. 40. 30. 40. 40. 30. 30. 10. 40. 20. 40. 40. 40. 40. 40. 40. 30.\n",
            " 40. 50. 50. 30. 10. 40. 40. 50. 30. 40. 50. 20. 20. 20. 30. 50. 20. 30.\n",
            " 30. 50. 20. 40. 30. 30. 40. 40. 30. 40. 40. 30. 40. 30. 10. 20. 40. 30.\n",
            " 10. 40. 10. 20. 30. 30. 20. 10. 20. 30. 30. 30. 50. 30. 30. 20. 40. 30.\n",
            " 40. 40. 40. 40. 20. 10. 30. 30. 30. 30. 20. 40. 10. 40. 40. 20. 20. 30.\n",
            " 30. 40. 30. 30. 40. 40. 20. 10. 20. 40. 20. 50. 40. 40. 40. 50. 40. 20.\n",
            " 30. 40. 40. 30. 10. 40. 30. 50. 40. 40. 30. 20. 50. 50. 40. 10. 10. 40.\n",
            " 30. 40. 40. 50. 40. 30. 40. 50. 50. 20. 20. 40. 40. 10. 50. 40. 40. 40.\n",
            " 20. 20. 20. 40. 50. 20. 40. 20. 40. 30. 30. 30. 30. 30. 30. 40. 40. 50.\n",
            " 40. 10. 50. 30. 40. 40. 30. 20. 50. 50. 50. 30. 30. 30. 30. 40. 20. 30.\n",
            " 40. 20. 10. 30. 50. 50. 20. 40. 40. 40. 40.  0. 40. 40. 30. 20. 20. 30.\n",
            " 40. 40. 20. 20. 20. 20. 50. 20. 30. 20. 40. 20. 40. 40. 20. 30. 40. 20.\n",
            "  0. 10. 40. 20. 40. 30. 10. 30. 40. 50. 20. 30. 40. 20. 20. 50.]\n",
            "selection [659 497 911 936  98 115 464 130  24 688 618 437 552  81 817  75 551 641\n",
            " 689  67 429 712 124 426 328] (25,) [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. 10. 10. 10. 10. 10. 10. 10.\n",
            " 10. 10. 10. 10. 10. 10. 10.]\n",
            "trainset before adding uncertain samples (350, 10) (350,)\n",
            "trainset after adding uncertain samples (375, 10) (375,)\n",
            "updated train set: (375, 10) (375,) unique(labels): [195 180] [0 1]\n",
            "val set: (927, 10) (927,)\n",
            "\n",
            "Train set: (375, 10)\n",
            "Validation set: (927, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 15\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.085 s \n",
            "\n",
            "Accuracy rate is 78.110599 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.88      0.86       321\n",
            "           1       0.60      0.49      0.54       113\n",
            "\n",
            "    accuracy                           0.78       434\n",
            "   macro avg       0.71      0.69      0.70       434\n",
            "weighted avg       0.77      0.78      0.77       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[284  37]\n",
            " [ 58  55]]\n",
            "--------------------------------\n",
            "val predicted: (927,) [1 0 1 1 0 1 1 0 0 1 0 1 0 0 1 1 1 1 0 1 0 1 0 0 0 1 0 0 1 0 1 1 1 1 1 0 0\n",
            " 0 1 1 0 0 1 0 1 0 1 0 0 1 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1 0 1 1 1 1 1 0 1 1\n",
            " 0 0 1 0 1 1 0 0 0 1 0 1 1 1 1 0 1 0 0 1 1 0 0 0 0 1 1 0 0 1 0 0 1 0 1 1 0\n",
            " 1 0 0 1 0 0 1 0 0 0 1 1 1 1 1 0 1 0 1 1 1 1 0 1 1 1 1 1 1 0 1 0 1 1 0 0 1\n",
            " 1 0 1 1 1 1 1 0 1 0 0 0 1 0 1 1 1 1 1 0 1 0 0 1 1 0 1 1 1 0 0 0 0 0 1 0 0\n",
            " 1 1 1 0 0 1 0 0 0 0 1 1 1 0 1 0 0 1 0 1 0 1 1 0 1 1 0 0 1 1 0 0 0 0 1 1 0\n",
            " 1 1 0 1 1 1 1 1 1 1 0 0 1 1 0 0 1 1 1 1 1 0 1 1 0 1 1 1 1 0 1 1 0 1 1 1 1\n",
            " 1 0 0 1 0 1 1 0 1 1 1 1 1 0 0 0 0 0 1 0 0 1 0 1 0 0 1 0 1 0 1 0 1 0 0 1 0\n",
            " 0 0 0 0 1 1 1 1 1 0 1 1 0 1 0 1 0 1 1 0 0 0 1 1 1 1 1 0 1 1 0 1 0 0 0 1 1\n",
            " 0 1 0 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0\n",
            " 1 1 1 1 0 1 0 1 0 0 1 1 1 1 1 0 0 1 1 0 1 0 1 1 0 1 1 0 1 1 1 1 1 0 0 1 1\n",
            " 1 1 1 0 1 0 1 0 1 1 0 0 0 0 1 1 1 1 1 0 0 1 0 1 1 1 0 1 0 0 1 0 0 0 1 0 0\n",
            " 0 1 0 1 1 0 1 0 0 0 1 0 1 0 0 1 1 1 0 1 1 1 1 1 1 0 0 1 0 1 1 0 1 1 0 1 1\n",
            " 1 0 1 1 0 0 0 0 1 1 0 1 0 1 1 0 1 1 0 1 1 0 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1\n",
            " 0 0 1 1 0 0 1 1 1 1 0 1 1 1 1 1 0 0 0 1 0 0 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1\n",
            " 1 0 1 1 0 0 1 0 0 1 0 0 1 1 0 1 1 0 0 0 1 0 1 1 0 1 1 1 1 1 0 1 1 0 0 0 1\n",
            " 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 0 0 1 1 0 0 1 1 1 1 0 1 1 0 1 1 1 0 1 0 1 1\n",
            " 0 1 0 1 0 1 1 0 0 0 0 1 1 0 1 1 1 0 1 0 0 1 0 1 0 0 1 0 1 1 1 0 1 0 0 1 0\n",
            " 1 0 1 1 1 1 0 0 0 0 0 1 0 1 1 1 0 0 1 0 0 1 0 1 0 0 0 0 1 0 1 1 1 1 0 0 0\n",
            " 1 0 0 1 1 1 1 0 0 0 0 1 1 0 0 1 1 0 1 1 1 0 0 1 0 0 1 1 0 1 0 0 1 0 1 1 1\n",
            " 1 0 1 0 0 0 0 0 0 0 1 0 1 1 0 1 1 1 1 0 1 1 0 0 1 0 1 0 1 1 1 1 1 1 1 0 1\n",
            " 0 0 0 0 1 0 0 1 1 0 1 1 0 1 0 0 0 0 1 0 0 1 1 1 0 1 1 0 0 0 1 1 0 0 1 1 0\n",
            " 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 1 1 1 0 1 1 0 1 1 0 1 1 0 0 1 1 1 0 0 1 1 1\n",
            " 1 1 1 0 1 1 0 1 1 0 1 0 0 0 1 0 1 1 1 0 0 1 0 1 0 1 1 0 1 0 1 0 1 1 1 1 1\n",
            " 0 1 1 1 0 0 0 0 1 0 0 1 1 1 0 1 1 1 1 1 0 1 0 1 1 1 0 0 1 1 0 0 1 1 1 1 0\n",
            " 0 0]\n",
            "probabilities: (927, 2) \n",
            " [1 0 1 1 0 1 1 0 0 1 0 1 0 0 1 1 1 1 0 1 0 1 0 0 0 1 0 0 1 0 1 1 1 1 1 0 0\n",
            " 0 1 1 0 0 1 0 1 0 1 0 0 1 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1 0 1 1 1 1 1 0 1 1\n",
            " 0 0 1 0 1 1 0 0 0 1 0 1 1 1 1 0 1 0 0 1 1 0 0 0 0 1 1 0 0 1 0 0 1 0 1 1 0\n",
            " 1 0 0 1 0 0 1 0 0 0 1 1 1 1 1 0 1 0 1 1 1 1 0 1 1 1 1 1 1 0 1 0 1 1 0 0 1\n",
            " 1 0 1 1 1 1 1 0 1 0 0 0 1 0 1 1 1 1 1 0 1 0 0 1 1 0 1 1 1 0 0 0 0 0 1 0 0\n",
            " 1 1 1 0 0 1 0 0 0 0 1 1 1 0 1 0 0 1 0 1 0 1 1 0 1 1 0 0 1 1 0 0 0 0 1 1 0\n",
            " 1 1 0 1 1 1 1 1 1 1 0 0 1 1 0 0 1 1 1 1 1 0 1 1 0 1 1 1 1 0 1 1 0 1 1 1 1\n",
            " 1 0 0 1 0 1 1 0 1 1 1 1 1 0 0 0 0 0 1 0 0 1 0 1 0 0 1 0 1 0 1 0 1 0 0 1 0\n",
            " 0 0 0 0 1 1 1 1 1 0 1 1 0 1 0 1 0 1 1 0 0 0 1 1 1 1 1 0 1 1 0 1 0 0 0 1 1\n",
            " 0 1 0 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0\n",
            " 1 1 1 1 0 1 0 1 0 0 1 1 1 1 1 0 0 1 1 0 1 0 1 1 0 1 1 0 1 1 1 1 1 0 0 1 1\n",
            " 1 1 1 0 1 0 1 0 1 1 0 0 0 0 1 1 1 1 1 0 0 1 0 1 1 1 0 1 0 0 1 0 0 0 1 0 0\n",
            " 0 1 0 1 1 0 1 0 0 0 1 0 1 0 0 1 1 1 0 1 1 1 1 1 1 0 0 1 0 1 1 0 1 1 0 1 1\n",
            " 1 0 1 1 0 0 0 0 1 1 0 1 0 1 1 0 1 1 0 1 1 0 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1\n",
            " 0 0 1 1 0 0 1 1 1 1 0 1 1 1 1 1 0 0 0 1 0 0 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1\n",
            " 1 0 1 1 0 0 1 0 0 1 0 0 1 1 0 1 1 0 0 0 1 0 1 1 0 1 1 1 1 1 0 1 1 0 0 0 1\n",
            " 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 0 0 1 1 0 0 1 1 1 1 0 1 1 0 1 1 1 0 1 0 1 1\n",
            " 0 1 0 1 0 1 1 0 0 0 0 1 1 0 1 1 1 0 1 0 0 1 0 1 0 0 1 0 1 1 1 0 1 0 0 1 0\n",
            " 1 0 1 1 1 1 0 0 0 0 0 1 0 1 1 1 0 0 1 0 0 1 0 1 0 0 0 0 1 0 1 1 1 1 0 0 0\n",
            " 1 0 0 1 1 1 1 0 0 0 0 1 1 0 0 1 1 0 1 1 1 0 0 1 0 0 1 1 0 1 0 0 1 0 1 1 1\n",
            " 1 0 1 0 0 0 0 0 0 0 1 0 1 1 0 1 1 1 1 0 1 1 0 0 1 0 1 0 1 1 1 1 1 1 1 0 1\n",
            " 0 0 0 0 1 0 0 1 1 0 1 1 0 1 0 0 0 0 1 0 0 1 1 1 0 1 1 0 0 0 1 1 0 0 1 1 0\n",
            " 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 1 1 1 0 1 1 0 1 1 0 1 1 0 0 1 1 1 0 0 1 1 1\n",
            " 1 1 1 0 1 1 0 1 1 0 1 0 0 0 1 0 1 1 1 0 0 1 0 1 0 1 1 0 1 0 1 0 1 1 1 1 1\n",
            " 0 1 1 1 0 0 0 0 1 0 0 1 1 1 0 1 1 1 1 1 0 1 0 1 1 1 0 0 1 1 0 0 1 1 1 1 0\n",
            " 0 0]\n",
            "std (927,) [40.  0. 20. 10. 10. 50. 30. 30. 30. 20. 30. 10. 20. 30. 50. 10. 50. 50.\n",
            " 40. 30. 40. 20. 20. 10. 20. 10. 30. 30. 30. 40. 10. 50. 40. 30. 40. 10.\n",
            " 30. 20. 20. 30. 40. 40. 30. 30. 10. 40. 30. 50. 10. 30. 20. 20. 20. 40.\n",
            " 10. 50. 20. 20. 30. 50. 30. 20. 50. 20. 40. 50. 40. 30. 50. 30. 50. 30.\n",
            " 20. 40. 40. 20. 30. 40. 50. 30. 30. 30. 30. 30. 20. 40. 50. 20. 20. 30.\n",
            " 30. 20. 40. 30. 40. 40. 40. 20. 40. 40. 40. 30. 30. 50. 30. 30. 50. 30.\n",
            " 50. 50. 30. 20. 30. 20. 50. 40. 30. 30. 40. 30. 30. 50. 20. 20. 20. 40.\n",
            " 40. 20. 30. 40. 20. 10. 30. 20. 40. 10. 10. 50. 50. 10. 30. 30. 30. 50.\n",
            " 40. 20. 40. 50. 30. 20. 50. 20. 30. 50. 20. 30. 30. 30. 10. 20. 50. 30.\n",
            " 30. 50. 40. 30. 40. 30. 30. 30. 40. 30. 30. 50. 50. 20. 30. 40. 40. 40.\n",
            " 20. 30. 30. 20. 40. 20. 20. 40. 20. 30. 20. 30. 20. 30. 30. 10. 50. 10.\n",
            " 20. 20. 40. 40. 20. 40. 10. 30. 40. 30. 40. 50. 20. 20. 40. 40. 50. 20.\n",
            " 40. 50. 30. 30. 50. 30. 20. 20. 30. 30. 10. 50. 40. 20. 20. 30. 50. 40.\n",
            " 20. 50. 30. 30. 40. 50. 30. 50. 50. 50. 40. 40. 30. 50. 50. 50. 30. 20.\n",
            " 40. 20. 30. 50. 40. 20. 40. 20. 50. 20. 30. 30. 40. 50. 30. 20. 20. 50.\n",
            " 40. 30. 30. 40. 30. 40. 10. 20. 10. 20. 50. 40. 30. 40. 30. 30. 30. 50.\n",
            " 30. 20. 40. 20. 30. 30. 30. 20. 30. 40. 50. 30. 30. 50. 50. 50. 50. 40.\n",
            " 40. 50. 40. 50. 30. 50. 20. 30. 40. 40. 40. 10. 40. 50. 50. 20. 30. 40.\n",
            " 50. 50. 30. 40. 20. 20. 50. 50. 30. 40. 40. 30. 50. 10. 20. 50. 40. 40.\n",
            " 50. 20. 40. 20. 30. 40. 30. 50. 40. 40. 30. 30. 20. 10. 20. 10. 50. 50.\n",
            " 30. 40. 40. 40. 30. 20. 40. 50. 30. 40. 40. 40. 30. 50. 30. 40. 30. 50.\n",
            "  0. 20. 50. 50. 50. 40. 50. 30. 30. 20. 40. 50. 40. 30. 30. 20. 30. 50.\n",
            " 30. 40. 40. 30. 10. 40. 10. 40. 20. 50. 30. 10. 10. 20. 30. 40. 40. 20.\n",
            " 30. 30. 50. 20. 40. 20. 20. 10. 30. 40. 30. 40. 40. 50. 10. 10. 50. 30.\n",
            " 10. 30. 40. 40. 20. 20. 30. 30. 20. 10. 40. 40. 40. 20. 50. 40. 30. 30.\n",
            " 10. 20. 30. 30. 30. 40. 30. 30. 30. 50. 30. 50. 30. 40. 30. 40. 20. 40.\n",
            " 40. 40. 40. 50. 20. 30. 50. 50. 40. 50. 40. 40. 50. 30. 20. 50. 50. 30.\n",
            " 20. 30. 40. 40. 40. 30. 40. 40. 50. 40. 40. 20. 30. 20. 30. 40. 10. 40.\n",
            " 40. 30. 20. 30. 40. 30. 40.  0. 20. 20. 50. 40. 40. 20. 30. 20. 20. 30.\n",
            " 40. 10. 40. 40. 30. 30. 20. 20. 40. 20. 50. 40. 40. 40. 20. 50. 20. 40.\n",
            " 30. 10. 30. 50. 30. 40. 40. 40. 50. 30. 10. 40. 50. 20. 30. 40. 40. 10.\n",
            " 30. 30. 40. 40. 30. 40. 40. 40. 40. 50. 20. 50. 30. 40.  0. 30. 10. 40.\n",
            " 10. 30. 20. 40. 50. 30. 50. 30. 30. 40. 30. 50. 40. 50. 30. 30. 50. 50.\n",
            " 50. 40. 30. 40. 30. 50. 40. 20. 40. 50. 20. 20. 30. 50. 10. 30. 50. 30.\n",
            " 40. 20. 50. 40. 50. 30. 20. 40.  0. 50. 40. 20. 20. 50. 30. 50. 20. 20.\n",
            " 40. 40. 40. 40. 50. 20. 10. 20. 40. 40. 40. 50. 20. 20. 50. 20. 30. 30.\n",
            " 40. 50. 50. 40. 40. 30. 10. 40. 40. 40. 20. 40.  0. 50. 30. 40. 50. 40.\n",
            " 20. 30. 30. 50. 20. 30. 40. 10. 30. 10. 50. 30. 20. 50. 10. 40. 30. 30.\n",
            " 20. 40. 40. 50. 40. 20. 40. 30. 40. 50. 30. 50. 40. 50. 40. 30. 40. 20.\n",
            " 30. 40. 30. 30. 10. 40. 20. 30. 40. 20. 40. 40. 40. 30. 30. 50. 50. 30.\n",
            " 20. 40. 40. 50. 30. 40. 50. 20. 30. 20. 30. 50. 20. 30. 30. 50. 20. 40.\n",
            " 30. 30. 40. 40. 30. 30. 40. 30. 50. 30.  0. 20. 40. 30. 10. 40. 10. 30.\n",
            " 30. 30. 20.  0. 20. 30. 30. 20. 50. 30. 20. 20. 40. 30. 40. 40. 40. 40.\n",
            " 20. 10. 30. 30. 30. 20. 20. 40. 10. 40. 40. 20. 20. 30. 30. 40. 30. 30.\n",
            " 40. 40. 20. 20. 30. 20. 50. 40. 40. 30. 50. 40. 20. 30. 30. 40. 30. 10.\n",
            " 40. 30. 50. 40. 40. 30. 20. 50. 50. 40. 10. 10. 40. 20. 40. 40. 40. 40.\n",
            " 30. 40. 50. 50. 20. 20. 40. 40. 10. 50. 40. 40. 40. 20. 30. 30. 40. 50.\n",
            " 20. 40. 20. 40. 30. 30. 30. 30. 30. 30. 40. 40. 40. 40. 10. 50. 30. 40.\n",
            " 40. 30. 20. 50. 50. 50. 30. 30. 30. 30. 40. 30. 30. 40. 20. 10. 20. 50.\n",
            " 50. 20. 40. 40. 40. 50. 30. 40. 30. 10. 20. 30. 40. 30. 20. 30. 20. 20.\n",
            " 50. 20. 20. 20. 50. 20. 40. 40. 20. 30. 50. 20. 10. 40. 20. 40. 30. 10.\n",
            " 30. 40. 50. 20. 20. 40. 20. 30. 50.]\n",
            "selection [660 759 748 620 378 572 511   1 408 879 337 355 357 754 752 421 541 432\n",
            " 429 557 400 428 402 407 550] (25,) [ 0.  0.  0.  0.  0.  0.  0.  0. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.\n",
            " 10. 10. 10. 10. 10. 10. 10.]\n",
            "trainset before adding uncertain samples (375, 10) (375,)\n",
            "trainset after adding uncertain samples (400, 10) (400,)\n",
            "updated train set: (400, 10) (400,) unique(labels): [205 195] [0 1]\n",
            "val set: (902, 10) (902,)\n",
            "\n",
            "Train set: (400, 10)\n",
            "Validation set: (902, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 16\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.070 s \n",
            "\n",
            "Accuracy rate is 79.953917 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.89      0.87       321\n",
            "           1       0.64      0.54      0.58       113\n",
            "\n",
            "    accuracy                           0.80       434\n",
            "   macro avg       0.74      0.72      0.73       434\n",
            "weighted avg       0.79      0.80      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[286  35]\n",
            " [ 52  61]]\n",
            "--------------------------------\n",
            "val predicted: (902,) [1 1 1 0 1 1 0 0 1 0 1 0 0 1 1 1 1 0 1 0 1 0 0 0 1 0 0 1 0 1 1 1 1 1 0 0 0\n",
            " 1 1 0 0 1 0 1 0 1 0 0 1 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1 0 1 1 1 1 1 0 1 1 0\n",
            " 0 1 0 1 1 0 0 0 1 0 1 1 1 1 0 1 0 0 1 1 0 0 0 0 1 1 0 0 1 0 0 1 0 1 1 0 1\n",
            " 0 0 1 0 0 1 0 0 0 1 1 1 1 1 0 1 0 1 1 1 1 0 1 1 1 1 1 1 0 1 0 1 1 0 0 1 1\n",
            " 0 1 1 1 1 1 0 1 0 0 0 1 0 1 1 1 1 1 0 1 0 0 1 1 0 1 1 1 0 0 0 0 0 1 0 0 1\n",
            " 1 1 0 0 1 0 0 0 0 1 1 0 0 1 0 0 1 0 1 0 1 1 0 1 1 0 0 1 1 0 0 0 0 1 1 0 1\n",
            " 1 0 1 1 1 1 1 1 1 0 0 1 1 0 0 1 1 1 1 1 0 1 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1\n",
            " 0 0 1 0 1 1 0 1 1 1 1 1 0 0 0 0 0 1 0 0 1 0 1 0 0 1 0 1 0 1 0 1 0 0 1 0 0\n",
            " 0 0 0 1 1 1 1 1 0 1 1 0 1 0 1 0 1 1 0 0 0 1 1 1 1 1 0 1 1 0 1 0 0 0 1 1 0\n",
            " 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 0 0 0 1 0 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1\n",
            " 0 1 0 1 0 1 1 1 1 1 0 0 1 1 0 1 0 1 1 0 1 1 0 1 1 1 0 0 1 1 1 0 1 0 1 0 1\n",
            " 1 0 0 0 0 1 1 1 1 0 0 1 1 0 1 0 0 1 0 0 0 1 0 0 0 1 0 1 1 0 1 0 0 0 1 0 1\n",
            " 0 0 1 1 1 0 1 1 1 1 1 1 0 0 1 0 1 1 0 1 1 0 1 1 1 0 1 1 0 0 0 0 1 1 0 1 0\n",
            " 1 1 0 1 1 0 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 0 0 1 1 1 1 0 1 1 1\n",
            " 1 1 0 0 0 1 0 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 0 0 1 0 0 1 1 0 1 1\n",
            " 0 0 1 0 1 1 0 1 1 1 1 1 0 1 1 0 0 0 1 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 0 0 1\n",
            " 1 0 0 1 1 1 1 0 1 1 1 1 1 0 1 0 1 1 0 1 0 1 0 1 1 0 0 0 0 1 1 0 1 1 1 0 1\n",
            " 0 0 1 0 1 0 0 1 0 1 1 1 1 0 0 1 0 1 0 1 1 1 1 0 0 0 0 0 1 0 1 1 1 0 0 1 0\n",
            " 0 1 0 1 0 0 0 0 1 0 1 1 1 1 0 0 0 1 0 0 1 1 1 1 0 0 0 0 1 1 0 0 1 1 0 1 1\n",
            " 1 0 0 1 0 0 1 1 0 1 0 0 1 0 1 1 1 1 0 1 0 0 0 0 0 0 1 0 1 1 1 1 1 1 1 0 0\n",
            " 1 0 1 0 1 1 1 1 1 1 1 0 1 0 0 0 0 1 0 0 1 1 0 1 1 0 1 0 0 0 0 1 0 0 1 1 1\n",
            " 0 1 1 0 0 0 1 1 0 0 1 1 0 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 1 1 1 0 1 1 0 0 1\n",
            " 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1 1 0 1 1 0 1 1 0 1 0 0 0 1 0 1 1 1 0 0 1 0 1\n",
            " 0 1 1 0 0 1 0 1 1 1 1 1 0 1 1 1 0 0 0 0 1 0 0 1 1 1 0 1 1 1 1 1 0 1 0 1 1\n",
            " 1 0 0 1 0 0 0 1 1 1 1 0 0 0]\n",
            "probabilities: (902, 2) \n",
            " [1 1 1 0 1 1 0 0 1 0 1 0 0 1 1 1 1 0 1 0 1 0 0 0 1 0 0 1 0 1 1 1 1 1 0 0 0\n",
            " 1 1 0 0 1 0 1 0 1 0 0 1 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1 0 1 1 1 1 1 0 1 1 0\n",
            " 0 1 0 1 1 0 0 0 1 0 1 1 1 1 0 1 0 0 1 1 0 0 0 0 1 1 0 0 1 0 0 1 0 1 1 0 1\n",
            " 0 0 1 0 0 1 0 0 0 1 1 1 1 1 0 1 0 1 1 1 1 0 1 1 1 1 1 1 0 1 0 1 1 0 0 1 1\n",
            " 0 1 1 1 1 1 0 1 0 0 0 1 0 1 1 1 1 1 0 1 0 0 1 1 0 1 1 1 0 0 0 0 0 1 0 0 1\n",
            " 1 1 0 0 1 0 0 0 0 1 1 0 0 1 0 0 1 0 1 0 1 1 0 1 1 0 0 1 1 0 0 0 0 1 1 0 1\n",
            " 1 0 1 1 1 1 1 1 1 0 0 1 1 0 0 1 1 1 1 1 0 1 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1\n",
            " 0 0 1 0 1 1 0 1 1 1 1 1 0 0 0 0 0 1 0 0 1 0 1 0 0 1 0 1 0 1 0 1 0 0 1 0 0\n",
            " 0 0 0 1 1 1 1 1 0 1 1 0 1 0 1 0 1 1 0 0 0 1 1 1 1 1 0 1 1 0 1 0 0 0 1 1 0\n",
            " 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 0 0 0 1 0 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1\n",
            " 0 1 0 1 0 1 1 1 1 1 0 0 1 1 0 1 0 1 1 0 1 1 0 1 1 1 0 0 1 1 1 0 1 0 1 0 1\n",
            " 1 0 0 0 0 1 1 1 1 0 0 1 1 0 1 0 0 1 0 0 0 1 0 0 0 1 0 1 1 0 1 0 0 0 1 0 1\n",
            " 0 0 1 1 1 0 1 1 1 1 1 1 0 0 1 0 1 1 0 1 1 0 1 1 1 0 1 1 0 0 0 0 1 1 0 1 0\n",
            " 1 1 0 1 1 0 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 0 0 1 1 1 1 0 1 1 1\n",
            " 1 1 0 0 0 1 0 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 0 0 1 0 0 1 1 0 1 1\n",
            " 0 0 1 0 1 1 0 1 1 1 1 1 0 1 1 0 0 0 1 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 0 0 1\n",
            " 1 0 0 1 1 1 1 0 1 1 1 1 1 0 1 0 1 1 0 1 0 1 0 1 1 0 0 0 0 1 1 0 1 1 1 0 1\n",
            " 0 0 1 0 1 0 0 1 0 1 1 1 1 0 0 1 0 1 0 1 1 1 1 0 0 0 0 0 1 0 1 1 1 0 0 1 0\n",
            " 0 1 0 1 0 0 0 0 1 0 1 1 1 1 0 0 0 1 0 0 1 1 1 1 0 0 0 0 1 1 0 0 1 1 0 1 1\n",
            " 1 0 0 1 0 0 1 1 0 1 0 0 1 0 1 1 1 1 0 1 0 0 0 0 0 0 1 0 1 1 1 1 1 1 1 0 0\n",
            " 1 0 1 0 1 1 1 1 1 1 1 0 1 0 0 0 0 1 0 0 1 1 0 1 1 0 1 0 0 0 0 1 0 0 1 1 1\n",
            " 0 1 1 0 0 0 1 1 0 0 1 1 0 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 1 1 1 0 1 1 0 0 1\n",
            " 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1 1 0 1 1 0 1 1 0 1 0 0 0 1 0 1 1 1 0 0 1 0 1\n",
            " 0 1 1 0 0 1 0 1 1 1 1 1 0 1 1 1 0 0 0 0 1 0 0 1 1 1 0 1 1 1 1 1 0 1 0 1 1\n",
            " 1 0 0 1 0 0 0 1 1 1 1 0 0 0]\n",
            "std (902,) [40. 30. 10. 10. 50. 40. 20. 20. 30. 30. 10. 20. 30. 50. 10. 50. 50. 40.\n",
            " 40. 40. 20. 20. 20. 20. 20. 20. 30. 30. 40. 10. 50. 40. 30. 40. 10. 30.\n",
            " 20. 20. 30. 40. 50. 30. 30. 20. 30. 30. 50. 10. 40. 20. 20. 20. 50. 10.\n",
            " 50. 20. 20. 20. 50. 30. 20. 50. 10. 40. 40. 40. 30. 40. 30. 50. 40. 20.\n",
            " 40. 40. 20. 30. 40. 50. 30. 30. 20. 30. 20. 20. 40. 50. 20. 20. 40. 20.\n",
            " 20. 40. 30. 40. 40. 40. 30. 40. 50. 40. 20. 30. 50. 20. 40. 50. 30. 50.\n",
            " 50. 30. 20. 30. 20. 50. 40. 40. 40. 40. 30. 20. 50. 20. 20. 20. 40. 40.\n",
            " 20. 40. 40. 20. 10. 30. 20. 40. 20. 20. 40. 50. 20. 20. 30. 30. 50. 40.\n",
            " 20. 40. 40. 30. 30. 50. 20. 30. 50. 20. 40. 30. 30. 10. 10. 40. 30. 30.\n",
            " 50. 30. 40. 40. 30. 30. 30. 40. 40. 20. 50. 50. 20. 30. 40. 30. 40. 20.\n",
            " 30. 30. 20. 40. 30. 20. 40. 20. 30. 30. 30. 40. 40. 30. 20. 50.  0. 10.\n",
            " 20. 30. 40. 20. 40. 10. 30. 40. 30. 40. 50. 30. 20. 40. 40. 50. 20. 40.\n",
            " 50. 30. 40. 50. 30. 20. 20. 20. 30. 10. 50. 30. 20. 40. 20. 50. 30. 20.\n",
            " 40. 30. 30. 40. 50. 30. 40. 50. 40. 40. 40. 40. 50. 40. 40. 20. 20. 40.\n",
            " 20. 20. 50. 40. 20. 40. 20. 50. 40. 30. 40. 30. 50. 20. 20. 20. 50. 40.\n",
            " 30. 40. 40. 20. 40. 10. 30. 10. 20. 50. 40. 30. 40. 30. 20. 30. 40. 30.\n",
            " 30. 40. 20. 30. 30. 30. 10. 20. 40. 50. 30. 30. 50. 50. 40. 50. 40. 30.\n",
            " 50. 40. 50. 30. 50. 30. 40. 30. 50. 40. 10. 40. 50. 50. 20. 30. 40. 50.\n",
            " 50. 30. 40. 20. 30. 50. 50. 30. 50. 40. 40. 50. 20. 40. 40. 40. 50. 20.\n",
            " 40. 20. 30. 50. 50. 50. 40. 40. 30. 30. 20. 20. 50. 40. 30. 40. 40. 30.\n",
            " 30. 30. 30. 40. 30. 40. 40. 30. 30. 50. 30. 40. 30. 50. 20. 50. 50. 40.\n",
            " 30. 50. 30. 30. 30. 30. 50. 40. 30. 30. 30. 30. 50. 40. 40. 40. 20. 30.\n",
            " 30. 20. 50. 30. 20. 30. 40. 50. 30. 30. 30. 50. 20. 50. 20. 30. 30. 40.\n",
            " 30. 50. 40. 50. 50. 30. 30. 40. 40. 20. 20. 30. 20. 20. 10. 30. 40. 40.\n",
            " 20. 50. 40. 40. 20. 10. 20. 30. 30. 30. 40. 30. 30. 30. 50. 30. 50. 40.\n",
            " 40. 30. 40. 20. 40. 40. 50. 40. 50. 20. 20. 50. 50. 50. 50. 40. 30. 50.\n",
            " 30. 20. 40. 50. 30. 20. 30. 40. 40. 40. 30. 40. 40. 50. 30. 40. 20. 30.\n",
            " 20. 30. 40. 10. 40. 40. 30. 20. 30. 40. 40. 40. 30. 20. 50. 30. 40. 30.\n",
            " 30. 20. 20. 40. 40. 10. 40. 30. 30. 30. 20. 20. 50. 40. 40. 40. 40. 40.\n",
            " 30. 40. 20. 50. 40. 30. 50. 30. 40. 40. 40. 50. 30. 50. 50. 20. 30. 40.\n",
            " 40. 30. 30. 40. 40. 20. 40. 40. 50. 40. 50. 40. 50. 30. 40. 30. 20. 40.\n",
            " 10. 30. 30. 50. 50. 40. 50. 40. 40. 40. 30. 50. 40. 50. 30. 30. 50. 50.\n",
            " 50. 40. 40. 40. 30. 50. 40. 20. 40. 40. 30. 30. 30. 50.  0. 20. 50. 20.\n",
            " 40. 10. 50. 40. 50. 30. 20. 40. 50. 30. 30. 30. 50. 30. 50. 20. 10. 40.\n",
            " 50. 40. 50. 40. 20. 10. 20. 40. 40. 40. 40. 20. 20. 40. 20. 30. 30. 40.\n",
            " 50. 40. 40. 40. 30.  0. 40. 50. 30. 20. 40. 50. 30. 40. 50. 40. 20. 30.\n",
            " 30. 50. 20. 30. 40. 10. 20.  0. 40. 30. 30. 50. 30. 40. 30. 20. 20. 40.\n",
            " 40. 50. 40. 40. 30. 40. 40. 50. 30. 50. 40. 40. 40. 30. 40. 20. 30. 40.\n",
            " 40. 20. 10. 40. 20. 40. 40. 30. 40. 40. 40. 40. 30. 50. 40. 30. 20. 40.\n",
            " 40. 40. 30. 40. 50. 30. 20. 10. 30. 50. 20. 30. 30. 50. 30. 40. 30. 30.\n",
            " 30. 40. 30. 40. 40. 40. 50. 30. 20. 40. 40. 40. 40. 20. 30. 20. 20. 30.\n",
            " 30. 20. 50. 30. 20. 20. 40. 30. 30. 40. 40. 40. 20. 10. 30. 30. 30. 10.\n",
            " 10. 50. 10. 40. 40. 30. 20. 30. 30. 40. 30. 30. 40. 40. 20. 40. 20. 20.\n",
            " 50. 30. 40. 40. 50. 30. 30. 30. 40. 40. 30. 10. 40. 30. 50. 40. 40. 20.\n",
            " 20. 40. 40. 40. 10. 10. 40. 40. 40. 40. 50. 40. 30. 40. 50. 50. 20. 20.\n",
            " 40. 40.  0. 50. 40. 40. 40. 20. 20. 30. 40. 50. 10. 40. 20. 40. 40. 30.\n",
            " 20. 40. 30. 40. 40. 40. 40. 40. 20. 50. 30. 40. 40. 30. 20. 50. 50. 50.\n",
            " 30. 30. 30. 30. 40. 30. 40. 40. 20. 20. 40. 50. 20. 40. 30. 40. 40. 30.\n",
            " 30. 30. 30. 20. 30. 40. 30. 20. 20. 20. 20. 50. 20. 30. 20. 50. 10. 50.\n",
            " 40. 20. 30. 40. 10. 20. 40. 20. 40. 20.  0. 30. 50. 50. 30. 20. 40. 20.\n",
            " 30. 50.]\n",
            "selection [892 812 635 655 590 196 822 157 686 595 158 428 437 489  62  53 558 130\n",
            " 197 203 751 755 294 756 758] (25,) [ 0.  0.  0.  0.  0.  0. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.\n",
            " 10. 10. 10. 10. 10. 10. 10.]\n",
            "trainset before adding uncertain samples (400, 10) (400,)\n",
            "trainset after adding uncertain samples (425, 10) (425,)\n",
            "updated train set: (425, 10) (425,) unique(labels): [220 205] [0 1]\n",
            "val set: (877, 10) (877,)\n",
            "\n",
            "Train set: (425, 10)\n",
            "Validation set: (877, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 17\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.089 s \n",
            "\n",
            "Accuracy rate is 79.493088 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.89      0.87       321\n",
            "           1       0.63      0.51      0.57       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.73      0.70      0.72       434\n",
            "weighted avg       0.78      0.79      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[287  34]\n",
            " [ 55  58]]\n",
            "--------------------------------\n",
            "val predicted: (877,) [1 1 1 0 1 1 0 0 1 0 1 0 0 1 0 1 1 0 1 0 1 0 0 0 1 0 0 1 0 1 1 1 1 1 0 0 0\n",
            " 1 1 0 0 1 0 1 0 1 0 0 1 0 1 1 1 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 0 1 1 0 0 1\n",
            " 0 1 1 0 0 0 1 0 1 1 1 1 0 1 0 0 1 1 0 0 0 0 1 1 0 0 1 0 0 1 0 1 1 0 1 0 0\n",
            " 1 0 0 1 0 0 0 1 1 1 1 1 0 1 0 1 1 1 0 1 1 1 1 1 1 0 1 0 1 1 0 0 1 1 0 1 1\n",
            " 1 1 1 0 1 0 1 0 1 1 1 1 1 0 1 0 0 1 1 0 1 1 1 0 0 0 0 0 1 0 0 1 1 1 0 0 1\n",
            " 0 0 0 0 1 1 1 0 0 1 0 0 1 1 0 1 1 0 0 1 1 0 0 0 0 1 1 0 1 1 0 1 1 1 1 1 1\n",
            " 1 0 0 1 1 0 0 1 1 1 1 1 0 1 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 0 0 1 0 1 1 0 1\n",
            " 1 1 1 1 0 0 0 0 0 1 0 0 1 0 1 0 0 1 0 1 0 1 0 1 0 0 1 0 0 0 0 1 1 1 1 1 0\n",
            " 1 1 0 1 0 1 0 1 1 0 0 0 1 1 1 1 1 0 1 1 0 1 0 0 0 1 1 0 1 0 1 1 1 1 1 1 0\n",
            " 1 1 1 1 1 1 0 0 0 1 0 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 0 1 0 1 0 1 1 1 1\n",
            " 1 0 0 1 1 0 1 0 1 1 0 1 1 0 1 1 1 0 0 1 1 1 0 1 0 1 0 1 1 0 0 0 0 1 1 1 1\n",
            " 0 0 1 1 0 1 0 0 1 0 0 0 0 0 0 1 0 1 1 0 0 0 0 1 0 1 0 0 1 1 1 0 1 1 1 1 1\n",
            " 1 0 0 1 0 1 1 0 1 1 0 1 1 1 0 1 1 0 0 0 0 1 1 0 1 0 1 1 0 1 1 0 1 1 0 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 0 0 1 1 1 1 0 1 1 1 1 1 0 0 0 1 0 0 1 1 1 0\n",
            " 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 0 0 1 0 0 1 1 0 1 1 0 0 1 1 1 0 1 1 1 1 1 0\n",
            " 1 1 0 0 0 1 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 0 1 1 0 0 1 1 1 0 1 1 1 1 1 0 1\n",
            " 0 1 1 0 1 0 1 0 1 1 0 0 0 0 1 1 0 1 1 1 0 1 0 0 1 0 1 0 1 0 1 1 1 1 0 0 1\n",
            " 0 1 0 1 1 1 1 0 0 0 0 1 0 1 1 1 0 0 1 0 0 1 0 1 0 0 0 0 1 0 1 1 1 1 0 0 0\n",
            " 1 0 0 1 1 1 0 0 0 0 1 1 0 0 1 1 0 1 1 1 0 0 1 0 0 1 1 0 1 0 0 1 0 1 1 1 1\n",
            " 0 1 0 0 0 0 0 0 1 0 1 1 1 1 1 1 1 0 0 1 0 1 0 1 1 1 1 1 1 1 1 0 0 1 0 1 1\n",
            " 0 1 1 0 1 0 0 0 0 1 0 0 1 1 1 0 1 1 0 0 0 1 1 0 0 1 1 0 0 1 1 1 1 1 1 0 0\n",
            " 1 1 1 0 0 1 1 1 1 0 1 1 0 1 0 1 1 0 0 1 1 1 0 1 1 1 1 1 1 0 1 1 0 1 1 0 1\n",
            " 0 0 0 1 0 1 1 1 0 0 1 0 1 0 1 1 0 0 1 0 1 1 1 1 1 0 1 1 1 0 0 0 0 1 0 0 1\n",
            " 1 1 0 1 1 1 1 1 0 1 0 1 1 1 0 0 1 0 0 1 1 1 1 0 0 0]\n",
            "probabilities: (877, 2) \n",
            " [1 1 1 0 1 1 0 0 1 0 1 0 0 1 0 1 1 0 1 0 1 0 0 0 1 0 0 1 0 1 1 1 1 1 0 0 0\n",
            " 1 1 0 0 1 0 1 0 1 0 0 1 0 1 1 1 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 0 1 1 0 0 1\n",
            " 0 1 1 0 0 0 1 0 1 1 1 1 0 1 0 0 1 1 0 0 0 0 1 1 0 0 1 0 0 1 0 1 1 0 1 0 0\n",
            " 1 0 0 1 0 0 0 1 1 1 1 1 0 1 0 1 1 1 0 1 1 1 1 1 1 0 1 0 1 1 0 0 1 1 0 1 1\n",
            " 1 1 1 0 1 0 1 0 1 1 1 1 1 0 1 0 0 1 1 0 1 1 1 0 0 0 0 0 1 0 0 1 1 1 0 0 1\n",
            " 0 0 0 0 1 1 1 0 0 1 0 0 1 1 0 1 1 0 0 1 1 0 0 0 0 1 1 0 1 1 0 1 1 1 1 1 1\n",
            " 1 0 0 1 1 0 0 1 1 1 1 1 0 1 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 0 0 1 0 1 1 0 1\n",
            " 1 1 1 1 0 0 0 0 0 1 0 0 1 0 1 0 0 1 0 1 0 1 0 1 0 0 1 0 0 0 0 1 1 1 1 1 0\n",
            " 1 1 0 1 0 1 0 1 1 0 0 0 1 1 1 1 1 0 1 1 0 1 0 0 0 1 1 0 1 0 1 1 1 1 1 1 0\n",
            " 1 1 1 1 1 1 0 0 0 1 0 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 0 1 0 1 0 1 1 1 1\n",
            " 1 0 0 1 1 0 1 0 1 1 0 1 1 0 1 1 1 0 0 1 1 1 0 1 0 1 0 1 1 0 0 0 0 1 1 1 1\n",
            " 0 0 1 1 0 1 0 0 1 0 0 0 0 0 0 1 0 1 1 0 0 0 0 1 0 1 0 0 1 1 1 0 1 1 1 1 1\n",
            " 1 0 0 1 0 1 1 0 1 1 0 1 1 1 0 1 1 0 0 0 0 1 1 0 1 0 1 1 0 1 1 0 1 1 0 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 0 0 1 1 1 1 0 1 1 1 1 1 0 0 0 1 0 0 1 1 1 0\n",
            " 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 0 0 1 0 0 1 1 0 1 1 0 0 1 1 1 0 1 1 1 1 1 0\n",
            " 1 1 0 0 0 1 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 0 1 1 0 0 1 1 1 0 1 1 1 1 1 0 1\n",
            " 0 1 1 0 1 0 1 0 1 1 0 0 0 0 1 1 0 1 1 1 0 1 0 0 1 0 1 0 1 0 1 1 1 1 0 0 1\n",
            " 0 1 0 1 1 1 1 0 0 0 0 1 0 1 1 1 0 0 1 0 0 1 0 1 0 0 0 0 1 0 1 1 1 1 0 0 0\n",
            " 1 0 0 1 1 1 0 0 0 0 1 1 0 0 1 1 0 1 1 1 0 0 1 0 0 1 1 0 1 0 0 1 0 1 1 1 1\n",
            " 0 1 0 0 0 0 0 0 1 0 1 1 1 1 1 1 1 0 0 1 0 1 0 1 1 1 1 1 1 1 1 0 0 1 0 1 1\n",
            " 0 1 1 0 1 0 0 0 0 1 0 0 1 1 1 0 1 1 0 0 0 1 1 0 0 1 1 0 0 1 1 1 1 1 1 0 0\n",
            " 1 1 1 0 0 1 1 1 1 0 1 1 0 1 0 1 1 0 0 1 1 1 0 1 1 1 1 1 1 0 1 1 0 1 1 0 1\n",
            " 0 0 0 1 0 1 1 1 0 0 1 0 1 0 1 1 0 0 1 0 1 1 1 1 1 0 1 1 1 0 0 0 0 1 0 0 1\n",
            " 1 1 0 1 1 1 1 1 0 1 0 1 1 1 0 0 1 0 0 1 1 1 1 0 0 0]\n",
            "std (877,) [40. 30. 10. 10. 50. 40. 20. 30. 30. 30. 10. 10. 30. 50.  0. 50. 50. 40.\n",
            " 40. 40. 20. 30. 30. 20. 20. 20. 30. 30. 40. 10. 50. 40. 30. 40. 10. 30.\n",
            " 20. 30. 30. 40. 50. 30. 30. 20. 30. 30. 50. 10. 40. 20. 20. 20. 50. 50.\n",
            " 30. 20. 30. 50. 30. 30. 50. 40. 50. 30. 20. 40. 30. 50. 40. 20. 30. 40.\n",
            " 10. 30. 40. 50. 30. 30. 30. 30. 20. 20. 40. 50. 20. 20. 50. 20. 20. 40.\n",
            " 30. 40. 40. 40. 30. 40. 50. 40. 30. 30. 50. 30. 40. 50. 30. 50. 50. 20.\n",
            " 30. 30. 20. 50. 40. 40. 40. 40. 30. 20. 50. 20. 20. 20. 40. 40. 20. 40.\n",
            " 40. 10. 30. 20. 40. 30. 20. 40. 50. 20. 30. 30. 30. 50. 40. 20. 40. 30.\n",
            " 30. 30. 50. 20. 30. 50. 20. 40. 30. 40. 50. 30. 30. 50. 30. 40. 40. 30.\n",
            " 30. 30. 40. 40. 30. 50. 50. 20. 30. 40. 50. 40. 20. 30. 30. 20. 40. 30.\n",
            " 20. 30. 20. 30. 30. 30. 40. 40. 30. 20. 50. 30. 30. 40. 20. 40. 30. 40.\n",
            " 20. 40. 50. 20. 20. 40. 40. 50. 30. 50. 40. 40. 40. 50. 30. 30. 20. 20.\n",
            " 30. 10. 50. 30. 20. 30. 20. 50. 40. 20. 40. 30. 30. 40. 50. 40. 50. 50.\n",
            " 50. 40. 40. 40. 50. 50. 40. 20. 20. 40. 20. 20. 50. 40. 20. 40. 30. 50.\n",
            " 40. 30. 40. 30. 40. 20. 20. 20. 50. 40. 30. 40. 40. 30. 40. 20. 30. 10.\n",
            " 30. 50. 40. 30. 40. 30. 20. 30. 40. 30. 40. 40. 20. 30. 30. 40. 30. 40.\n",
            " 50. 20. 30. 50. 50. 40. 50. 40. 30. 50. 40. 50. 20. 50. 30. 40. 30. 50.\n",
            " 40. 20. 40. 50. 50. 20. 30. 40. 50. 50. 40. 40. 20. 30. 50. 50. 30. 40.\n",
            " 40. 40. 50. 20. 40. 40. 40. 50. 20. 40. 20. 30. 50. 40. 50. 40. 50. 30.\n",
            " 30. 30. 20. 50. 50. 30. 40. 40. 40. 30. 30. 30. 40. 30. 40. 40. 50. 30.\n",
            " 50. 30. 40. 30. 50. 20. 50. 40. 40. 30. 50. 30. 30. 30. 30. 50. 40. 40.\n",
            " 30. 20. 30. 50. 40. 40. 40. 20. 30. 40. 20. 50. 20. 20. 30. 40. 50. 30.\n",
            " 40. 30. 50. 30. 50. 20. 30. 40. 40. 30. 50. 40. 50. 50. 30. 30. 40. 40.\n",
            " 30. 20. 30. 20. 30. 40. 40. 40. 30. 50. 40. 40. 20. 20. 40. 20. 30. 40.\n",
            " 30. 30. 30. 40. 30. 50. 40. 30. 30. 40. 20. 40. 40. 50. 40. 50. 20. 20.\n",
            " 50. 50. 40. 50. 40. 40. 50. 30. 20. 40. 40. 30. 20. 30. 40. 30. 40. 30.\n",
            " 50. 40. 50. 30. 40. 20. 30. 20. 30. 40. 40. 50. 30. 10. 20. 40. 40. 40.\n",
            " 20. 10. 50. 30. 40. 30. 30. 20. 20. 40. 40. 20. 40. 30. 30. 30. 20. 20.\n",
            " 40. 30. 40. 30. 40. 40. 30. 40. 10. 50. 40. 30. 50. 50. 40. 40. 40. 50.\n",
            " 30. 50. 50. 10. 30. 40. 40. 30. 40. 40. 40. 30. 40. 30. 40. 40. 50. 40.\n",
            " 40. 30. 40. 30. 20. 40. 30. 30. 50. 50. 50. 50. 40. 40. 40. 40. 50. 40.\n",
            " 50. 30. 20. 50. 50. 50. 40. 40. 40. 40. 50. 40. 20. 40. 40. 30. 30. 30.\n",
            " 50. 20. 50. 30. 40. 50. 40. 50. 30. 20. 40. 50. 40. 30. 30. 50. 30. 50.\n",
            " 10. 20. 50. 40. 40. 50. 40. 20. 20. 20. 40. 40. 40. 50. 20. 20. 40. 20.\n",
            " 30. 30. 40. 50. 30. 40. 40. 20. 30. 50. 30. 20. 40. 50. 30. 50. 50. 40.\n",
            " 20. 30. 30. 50. 30. 30. 40. 10. 30. 50. 30. 30. 50. 20. 40. 40. 10. 20.\n",
            " 40. 40. 50. 40. 40. 30. 40. 40. 50. 30. 50. 40. 40. 30. 30. 40. 20. 20.\n",
            " 40. 50. 30. 40. 20. 40. 40. 30. 40. 40. 40. 40. 40. 50. 40. 30. 20. 30.\n",
            " 50. 40. 30. 40. 50. 30. 30. 20. 40. 50. 20. 40. 30. 50. 30. 30. 30. 30.\n",
            " 30. 40. 30. 40. 40. 40. 50. 40. 20. 40. 30. 40. 40. 20. 30. 20. 20. 30.\n",
            " 30. 30. 50. 30. 20. 20. 40. 30. 20. 40. 40. 40. 20. 30. 30. 20. 50. 40.\n",
            " 40. 20. 20. 30. 30. 40. 30. 30. 40. 40. 20. 40. 20. 20. 50. 30. 50. 40.\n",
            " 50. 40. 20. 30. 40. 40. 30. 10. 40. 30. 50. 40. 40. 20. 20. 30. 40. 50.\n",
            " 10.  0. 40. 30. 30. 40. 40. 40. 30. 40. 50. 50.  0. 20. 40. 40. 50. 40.\n",
            " 40. 40. 20. 40. 30. 40. 50. 40. 20. 30. 40. 30. 20. 30. 30. 40. 40. 40.\n",
            " 40. 40. 30. 50. 30. 40. 40. 30. 20. 50. 50. 50. 30. 40. 40. 30. 40. 30.\n",
            " 40. 40. 30. 30. 30. 50. 20. 40. 30. 40. 40. 30. 30. 40. 30. 30. 30. 40.\n",
            " 30. 20. 30. 30. 20. 50. 20. 30. 30. 50. 20. 50. 40. 30. 30. 50. 30. 20.\n",
            " 40. 20. 40. 20. 40. 40. 40. 30. 30. 40. 20. 30. 50.]\n",
            "selection [775 786  14 217 763  47 481 637  72 525 269 594  29 646  11  10 127 487\n",
            " 774   3   2  34 512 174 385] (25,) [ 0.  0.  0. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.\n",
            " 10. 10. 10. 10. 10. 20. 20.]\n",
            "trainset before adding uncertain samples (425, 10) (425,)\n",
            "trainset after adding uncertain samples (450, 10) (450,)\n",
            "updated train set: (450, 10) (450,) unique(labels): [235 215] [0 1]\n",
            "val set: (852, 10) (852,)\n",
            "\n",
            "Train set: (450, 10)\n",
            "Validation set: (852, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 18\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.092 s \n",
            "\n",
            "Accuracy rate is 80.875576 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.90      0.87       321\n",
            "           1       0.66      0.55      0.60       113\n",
            "\n",
            "    accuracy                           0.81       434\n",
            "   macro avg       0.75      0.72      0.74       434\n",
            "weighted avg       0.80      0.81      0.80       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[289  32]\n",
            " [ 51  62]]\n",
            "--------------------------------\n",
            "val predicted: (852,) [1 1 1 1 0 0 1 0 0 1 1 1 0 1 0 1 0 0 0 1 0 0 1 0 1 1 1 1 0 0 1 1 0 0 1 0 1\n",
            " 0 1 0 1 0 1 1 1 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 0 1 1 0 1 0 1 1 0 0 0 1 0 1\n",
            " 1 1 1 0 1 0 0 1 1 0 0 0 0 1 1 0 0 1 0 0 1 0 1 1 0 1 0 0 1 0 0 1 0 0 0 1 1\n",
            " 0 1 1 0 1 0 1 1 0 1 1 1 1 1 1 0 1 0 1 1 0 0 1 1 0 1 1 1 1 1 0 1 0 1 0 1 1\n",
            " 1 1 1 0 1 0 0 1 1 0 1 1 1 0 0 0 0 1 0 0 1 1 1 0 0 1 0 0 0 0 1 1 1 0 0 1 0\n",
            " 0 1 1 0 1 1 0 0 1 1 0 0 0 0 1 1 0 1 1 0 1 1 1 1 1 1 0 0 1 1 0 0 1 1 1 1 1\n",
            " 0 1 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 0 0 1 0 1 1 0 1 1 1 1 1 0 0 0 0 0 1 0 1\n",
            " 0 1 0 0 1 0 1 0 1 0 1 0 0 1 0 0 0 0 1 1 1 1 1 0 1 1 0 1 0 1 0 1 1 0 0 0 1\n",
            " 1 1 1 1 0 1 1 0 1 0 0 0 1 1 0 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 0 0 0 1 0 1 1\n",
            " 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 0 1 0 1 0 1 1 1 1 1 0 0 1 1 0 1 0 1 1 0 1 1\n",
            " 0 1 1 0 0 1 1 0 0 1 0 1 0 1 1 0 0 0 0 1 1 1 1 0 0 1 1 0 1 0 0 1 0 0 0 0 0\n",
            " 0 1 0 1 1 0 0 0 0 1 0 1 0 0 1 1 1 0 1 1 1 1 1 1 0 0 1 0 1 1 0 1 1 0 1 1 1\n",
            " 0 1 1 0 0 0 0 1 1 0 1 0 1 1 0 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 0\n",
            " 0 1 1 1 1 0 1 1 1 1 1 0 0 0 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 0 0 1 0 0 1\n",
            " 0 0 1 1 0 1 1 0 0 1 1 1 0 1 1 1 1 1 0 1 1 0 0 0 1 1 1 1 1 1 0 0 1 1 1 1 1\n",
            " 0 1 1 0 1 1 0 0 1 1 1 0 1 1 1 1 1 0 1 0 1 0 1 0 1 0 1 1 0 0 0 0 1 1 0 1 1\n",
            " 1 0 1 0 0 1 0 1 0 1 0 1 1 1 1 0 0 1 0 1 0 1 1 1 1 0 0 0 1 0 1 1 1 0 1 0 0\n",
            " 1 0 1 0 0 0 0 1 0 1 1 1 1 0 0 0 1 0 0 1 1 1 0 0 0 0 1 1 0 0 1 1 0 1 1 1 0\n",
            " 0 1 0 0 1 1 0 0 0 0 1 0 1 1 1 1 0 1 0 0 0 0 0 0 1 0 1 1 1 1 1 1 1 0 0 1 0\n",
            " 1 0 1 1 1 1 1 1 1 1 0 0 1 0 1 1 0 1 1 0 1 0 0 0 0 1 0 0 1 1 1 0 1 1 0 0 0\n",
            " 1 1 0 1 1 0 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 1 0 1 0 1 1 0 0 1 1 1 0 1 1\n",
            " 1 1 1 1 0 1 1 0 1 1 0 1 0 0 0 1 0 1 1 1 0 0 1 0 1 0 1 1 0 0 1 0 1 1 1 1 1\n",
            " 0 1 1 1 0 0 0 0 1 0 0 1 1 1 0 1 1 1 1 1 0 1 0 1 1 1 0 0 1 0 0 1 1 1 1 0 0\n",
            " 0]\n",
            "probabilities: (852, 2) \n",
            " [1 1 1 1 0 0 1 0 0 1 1 1 0 1 0 1 0 0 0 1 0 0 1 0 1 1 1 1 0 0 1 1 0 0 1 0 1\n",
            " 0 1 0 1 0 1 1 1 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 0 1 1 0 1 0 1 1 0 0 0 1 0 1\n",
            " 1 1 1 0 1 0 0 1 1 0 0 0 0 1 1 0 0 1 0 0 1 0 1 1 0 1 0 0 1 0 0 1 0 0 0 1 1\n",
            " 0 1 1 0 1 0 1 1 0 1 1 1 1 1 1 0 1 0 1 1 0 0 1 1 0 1 1 1 1 1 0 1 0 1 0 1 1\n",
            " 1 1 1 0 1 0 0 1 1 0 1 1 1 0 0 0 0 1 0 0 1 1 1 0 0 1 0 0 0 0 1 1 1 0 0 1 0\n",
            " 0 1 1 0 1 1 0 0 1 1 0 0 0 0 1 1 0 1 1 0 1 1 1 1 1 1 0 0 1 1 0 0 1 1 1 1 1\n",
            " 0 1 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 0 0 1 0 1 1 0 1 1 1 1 1 0 0 0 0 0 1 0 1\n",
            " 0 1 0 0 1 0 1 0 1 0 1 0 0 1 0 0 0 0 1 1 1 1 1 0 1 1 0 1 0 1 0 1 1 0 0 0 1\n",
            " 1 1 1 1 0 1 1 0 1 0 0 0 1 1 0 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 0 0 0 1 0 1 1\n",
            " 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 0 1 0 1 0 1 1 1 1 1 0 0 1 1 0 1 0 1 1 0 1 1\n",
            " 0 1 1 0 0 1 1 0 0 1 0 1 0 1 1 0 0 0 0 1 1 1 1 0 0 1 1 0 1 0 0 1 0 0 0 0 0\n",
            " 0 1 0 1 1 0 0 0 0 1 0 1 0 0 1 1 1 0 1 1 1 1 1 1 0 0 1 0 1 1 0 1 1 0 1 1 1\n",
            " 0 1 1 0 0 0 0 1 1 0 1 0 1 1 0 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 0\n",
            " 0 1 1 1 1 0 1 1 1 1 1 0 0 0 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 0 0 1 0 0 1\n",
            " 0 0 1 1 0 1 1 0 0 1 1 1 0 1 1 1 1 1 0 1 1 0 0 0 1 1 1 1 1 1 0 0 1 1 1 1 1\n",
            " 0 1 1 0 1 1 0 0 1 1 1 0 1 1 1 1 1 0 1 0 1 0 1 0 1 0 1 1 0 0 0 0 1 1 0 1 1\n",
            " 1 0 1 0 0 1 0 1 0 1 0 1 1 1 1 0 0 1 0 1 0 1 1 1 1 0 0 0 1 0 1 1 1 0 1 0 0\n",
            " 1 0 1 0 0 0 0 1 0 1 1 1 1 0 0 0 1 0 0 1 1 1 0 0 0 0 1 1 0 0 1 1 0 1 1 1 0\n",
            " 0 1 0 0 1 1 0 0 0 0 1 0 1 1 1 1 0 1 0 0 0 0 0 0 1 0 1 1 1 1 1 1 1 0 0 1 0\n",
            " 1 0 1 1 1 1 1 1 1 1 0 0 1 0 1 1 0 1 1 0 1 0 0 0 0 1 0 0 1 1 1 0 1 1 0 0 0\n",
            " 1 1 0 1 1 0 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 1 0 1 0 1 1 0 0 1 1 1 0 1 1\n",
            " 1 1 1 1 0 1 1 0 1 1 0 1 0 0 0 1 0 1 1 1 0 0 1 0 1 0 1 1 0 0 1 0 1 1 1 1 1\n",
            " 0 1 1 1 0 0 0 0 1 0 0 1 1 1 0 1 1 1 1 1 0 1 0 1 1 1 0 0 1 0 0 1 1 1 1 0 0\n",
            " 0]\n",
            "std (852,) [40. 30. 50. 40. 30. 40. 30. 30. 30. 40. 50. 50. 30. 30. 40. 10. 30. 30.\n",
            " 20. 20. 20. 30. 30. 30. 50. 40. 30. 30. 30. 20. 30. 30. 40. 50. 30. 30.\n",
            " 30. 30. 20. 50. 20. 20. 20. 10. 40. 50. 30.  0. 30. 50. 40. 30. 50. 40.\n",
            " 50. 40. 30. 30. 50. 50. 40. 20. 40. 40. 20. 40. 50. 30. 30. 30. 30. 20.\n",
            " 20. 40. 50. 30. 20. 50. 10. 10. 40. 20. 30. 30. 40. 30. 40. 50. 40. 30.\n",
            " 30. 50. 30. 40. 50. 30. 50. 40. 20. 20. 30. 20. 30. 40. 40. 40. 40. 30.\n",
            " 30. 50. 20.  0. 20. 50. 40. 20. 40. 40. 30. 20. 40. 20. 20. 40. 50. 20.\n",
            " 30. 30. 30. 50. 40. 20. 40. 20. 30. 40. 50. 20. 30. 50. 30. 40. 30. 30.\n",
            " 40. 30. 30. 50. 40. 40. 40. 30. 30. 30. 40. 40. 20. 50. 50. 20. 20. 30.\n",
            " 50. 40. 30. 30. 20. 40. 30. 20. 40. 20. 30. 30. 30. 40. 40. 30. 10. 50.\n",
            " 30. 40. 40. 10. 40. 30. 40. 30. 50. 50. 40. 20. 30. 40. 50. 30. 50. 50.\n",
            " 40. 40. 40. 40. 30. 20. 20. 30. 50. 20. 30. 40. 20. 50. 30. 20. 40. 30.\n",
            " 30. 40. 50. 30. 40. 50. 50. 40. 40. 40. 50. 50. 40. 20. 20. 50. 20. 30.\n",
            " 50. 40. 20. 40. 30. 50. 40. 30. 50. 30. 40. 30. 30. 20. 40. 40. 30. 40.\n",
            " 40. 30. 40. 20. 20. 30. 50. 40. 30. 40. 30. 10. 30. 40. 30. 40. 40. 20.\n",
            " 20. 30. 40. 30. 40. 50. 20. 30. 50. 50. 40. 40. 40. 20. 50. 40. 50. 30.\n",
            " 50. 30. 40. 40. 40. 40. 10. 40. 50. 50. 20. 30. 40. 50. 40. 40. 40. 20.\n",
            " 30. 50. 50. 30. 50. 40. 40. 50. 30. 40. 30. 40. 50. 20. 40. 20. 30. 50.\n",
            " 40. 50. 20. 50. 30. 30. 20. 20. 50. 50. 30. 30. 40. 40. 30. 30. 20. 40.\n",
            " 40. 40. 40. 50. 30. 50. 30. 40. 30. 50. 20. 50. 40. 40. 20. 50. 30. 30.\n",
            " 20. 30. 50. 40. 40. 30. 30. 30. 50. 40. 40. 40. 20. 40. 10. 50. 30.  0.\n",
            " 30. 40. 50. 30. 40. 30. 40. 30. 50. 20. 40. 30. 50. 20. 40. 40. 50. 50.\n",
            " 30. 40. 40. 50. 30. 10. 30. 20. 30. 40. 40. 40. 30. 50. 40. 40. 30. 20.\n",
            " 40. 20. 30. 40. 30. 40. 30. 40. 30. 50. 30. 30. 30. 40. 20. 40. 40. 50.\n",
            " 50. 50. 20. 30. 40. 50. 40. 50. 40. 20. 50. 20. 20. 30. 40. 30. 20. 30.\n",
            " 40. 40. 40. 30. 40. 40. 50. 30. 40. 20. 30. 20. 30. 10. 40. 40. 40. 20.\n",
            " 40. 40. 40. 30. 50. 30. 40. 10. 30. 20.  0. 40. 40. 20. 30. 30. 30. 30.\n",
            " 30. 20. 50. 40. 40. 40. 40. 40. 30. 40. 30. 40. 40. 50. 50. 40. 50. 40.\n",
            " 50. 40. 50. 50. 20. 40. 50. 20. 30. 30. 40. 30. 40. 30. 50. 40. 50. 40.\n",
            " 40. 10. 40. 30. 20. 40. 30. 30. 50. 50. 50. 50. 40. 40. 50. 40. 50. 40.\n",
            " 50. 30. 10. 50. 50. 50. 40. 40. 40. 40. 50. 40. 10. 40. 40. 40. 20. 30.\n",
            " 50. 10. 50. 30. 30. 50. 40. 40. 30. 10. 40. 50. 40. 30. 30. 50. 30. 50.\n",
            " 20. 40. 40. 40. 50. 50. 20. 20. 20. 40. 40. 40. 40. 20. 20. 40. 30. 30.\n",
            " 30. 30. 50. 20. 40. 40. 20. 30. 40. 20. 20. 30. 50. 30. 50. 50. 50. 30.\n",
            " 30. 10. 30. 20. 30. 40. 30. 50. 30. 30. 50. 30. 40. 20. 20. 40. 40. 50.\n",
            " 40. 40. 40. 40. 40. 50. 30. 50. 40. 40. 30. 30. 40. 20. 40. 40. 40. 30.\n",
            " 40. 20. 30. 40. 20. 50. 40. 40. 20. 40. 50. 40. 30. 10. 30. 40. 40. 30.\n",
            " 40. 40. 30. 20. 20. 40. 50.  0. 30. 30. 40. 30. 30. 20. 20. 30. 40. 40.\n",
            " 40. 40. 40. 50. 30. 30. 40. 20. 40. 30. 20. 30. 10. 20. 30. 30. 30. 50.\n",
            " 30. 20. 20. 40. 30. 30. 40. 40. 30. 10. 30. 30. 10. 50. 40. 40. 20. 20.\n",
            " 30. 40. 40. 30. 30. 40. 40. 20. 40. 20. 20. 50. 20. 40. 40. 40. 40. 20.\n",
            " 40. 30. 40. 30. 40. 20. 50. 40. 40. 20. 10. 20. 40. 50. 40. 40. 40. 40.\n",
            " 40. 40. 40. 40. 40. 50. 30. 30. 40. 40. 40. 50. 40. 20. 40. 30. 40. 50.\n",
            " 40. 30. 30. 40. 10. 20. 30. 30. 40. 50. 40. 40. 40. 20. 50. 30. 40. 40.\n",
            " 30. 20. 50. 50. 40. 30. 40. 40. 30. 20. 30. 40. 40. 30. 20. 20. 50. 40.\n",
            " 40. 30. 40. 40. 30. 30. 40. 30. 20. 30. 40. 20. 10. 30. 30. 20. 50. 20.\n",
            " 10. 20. 50. 10. 50. 30. 30. 20. 50. 10. 10. 40. 20. 40. 10. 40. 40. 50.\n",
            " 40. 30. 40. 20. 30. 50.]\n",
            "selection [673 377 111  47 478 263 401 837  43 374  79 831  78 828 178 475 183 822\n",
            " 661 748 463 567 778 838 542] (25,) [ 0.  0.  0.  0.  0. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.\n",
            " 10. 10. 10. 10. 10. 10. 10.]\n",
            "trainset before adding uncertain samples (450, 10) (450,)\n",
            "trainset after adding uncertain samples (475, 10) (475,)\n",
            "updated train set: (475, 10) (475,) unique(labels): [242 233] [0 1]\n",
            "val set: (827, 10) (827,)\n",
            "\n",
            "Train set: (475, 10)\n",
            "Validation set: (827, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 19\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.076 s \n",
            "\n",
            "Accuracy rate is 79.493088 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.89      0.86       321\n",
            "           1       0.62      0.53      0.57       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.73      0.71      0.72       434\n",
            "weighted avg       0.79      0.79      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[285  36]\n",
            " [ 53  60]]\n",
            "--------------------------------\n",
            "val predicted: (827,) [1 1 1 1 0 0 1 0 0 1 1 1 0 1 0 1 0 0 0 1 0 0 1 0 1 1 1 1 0 0 1 1 0 0 1 0 1\n",
            " 0 1 0 1 0 1 1 1 0 1 1 1 0 1 1 0 1 1 1 1 1 0 1 1 0 1 0 1 1 0 0 0 1 0 1 1 1\n",
            " 1 0 0 1 1 0 0 0 0 1 1 0 0 1 0 0 1 0 1 1 0 1 0 0 1 0 0 1 0 0 0 1 1 1 1 0 1\n",
            " 0 1 1 0 1 1 1 1 1 1 0 1 0 1 1 0 0 1 1 0 1 1 1 1 1 0 1 0 1 0 1 1 1 1 1 0 1\n",
            " 0 0 1 1 0 1 1 1 0 0 0 0 1 0 0 1 1 1 0 0 1 0 0 0 0 1 1 0 0 0 0 1 1 0 1 1 0\n",
            " 0 1 1 0 0 0 0 1 1 0 1 1 0 1 1 1 1 1 1 0 0 1 1 0 0 1 1 1 1 1 0 1 1 0 1 1 1\n",
            " 1 0 1 1 0 1 1 1 1 1 0 0 1 0 1 1 0 1 1 1 1 1 0 0 0 0 0 1 0 1 0 1 0 0 0 1 0\n",
            " 1 0 1 0 0 1 0 0 0 0 1 1 1 1 1 0 1 1 0 1 0 1 0 1 1 0 0 0 1 1 1 1 1 0 1 1 0\n",
            " 1 0 0 0 1 1 0 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 0 0 0 1 0 1 1 1 1 1 1 0 1 1 1\n",
            " 1 1 0 1 1 1 1 0 1 0 1 0 1 1 1 1 1 0 0 1 1 0 1 0 1 1 0 1 1 0 1 1 0 1 1 0 1\n",
            " 0 1 0 1 1 0 0 0 0 1 1 1 1 0 0 1 1 0 1 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 1 0\n",
            " 1 0 0 1 1 1 0 1 1 1 1 1 1 0 0 1 0 1 1 0 1 1 0 1 1 1 0 1 1 0 0 0 0 1 1 0 1\n",
            " 0 1 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0 1 1 1 1 0 1 1 1 1 1 0 0 0\n",
            " 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 0 0 1 0 0 1 0 0 1 1 0 1 1 0 0 1 1 1 0 1\n",
            " 1 1 1 1 0 1 1 0 0 0 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 0 0 1 0 0 1 1 1 0 1 1 1\n",
            " 1 0 1 0 1 0 1 0 1 0 1 1 0 0 0 0 1 1 0 1 1 1 0 1 0 0 1 0 1 0 1 0 1 1 1 1 0\n",
            " 0 1 0 1 0 1 1 1 1 0 0 0 1 0 1 1 1 0 1 0 0 1 0 1 0 0 0 0 1 0 1 1 1 1 0 0 0\n",
            " 1 0 0 1 1 1 0 0 0 0 1 1 0 0 1 1 1 1 1 0 0 1 0 0 1 1 0 0 0 1 0 1 1 1 1 0 1\n",
            " 0 0 0 0 0 0 1 0 1 1 1 1 1 1 1 0 0 1 0 1 0 1 1 1 1 1 1 1 1 0 0 1 0 1 1 0 1\n",
            " 1 0 1 0 0 0 0 1 0 0 1 1 1 0 1 1 0 0 0 1 1 0 1 1 0 0 1 1 1 1 0 1 1 1 0 0 1\n",
            " 1 1 1 1 1 0 1 0 1 1 0 0 1 1 1 0 1 1 1 1 1 0 1 1 0 1 1 0 1 0 0 0 1 0 1 1 1\n",
            " 0 0 1 0 1 0 1 1 0 0 1 0 1 1 1 1 1 0 1 1 1 0 0 0 0 0 0 1 1 1 1 1 1 1 0 1 0\n",
            " 1 0 0 1 0 0 1 1 1 1 0 0 0]\n",
            "probabilities: (827, 2) \n",
            " [1 1 1 1 0 0 1 0 0 1 1 1 0 1 0 1 0 0 0 1 0 0 1 0 1 1 1 1 0 0 1 1 0 0 1 0 1\n",
            " 0 1 0 1 0 1 1 1 0 1 1 1 0 1 1 0 1 1 1 1 1 0 1 1 0 1 0 1 1 0 0 0 1 0 1 1 1\n",
            " 1 0 0 1 1 0 0 0 0 1 1 0 0 1 0 0 1 0 1 1 0 1 0 0 1 0 0 1 0 0 0 1 1 1 1 0 1\n",
            " 0 1 1 0 1 1 1 1 1 1 0 1 0 1 1 0 0 1 1 0 1 1 1 1 1 0 1 0 1 0 1 1 1 1 1 0 1\n",
            " 0 0 1 1 0 1 1 1 0 0 0 0 1 0 0 1 1 1 0 0 1 0 0 0 0 1 1 0 0 0 0 1 1 0 1 1 0\n",
            " 0 1 1 0 0 0 0 1 1 0 1 1 0 1 1 1 1 1 1 0 0 1 1 0 0 1 1 1 1 1 0 1 1 0 1 1 1\n",
            " 1 0 1 1 0 1 1 1 1 1 0 0 1 0 1 1 0 1 1 1 1 1 0 0 0 0 0 1 0 1 0 1 0 0 0 1 0\n",
            " 1 0 1 0 0 1 0 0 0 0 1 1 1 1 1 0 1 1 0 1 0 1 0 1 1 0 0 0 1 1 1 1 1 0 1 1 0\n",
            " 1 0 0 0 1 1 0 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 0 0 0 1 0 1 1 1 1 1 1 0 1 1 1\n",
            " 1 1 0 1 1 1 1 0 1 0 1 0 1 1 1 1 1 0 0 1 1 0 1 0 1 1 0 1 1 0 1 1 0 1 1 0 1\n",
            " 0 1 0 1 1 0 0 0 0 1 1 1 1 0 0 1 1 0 1 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 1 0\n",
            " 1 0 0 1 1 1 0 1 1 1 1 1 1 0 0 1 0 1 1 0 1 1 0 1 1 1 0 1 1 0 0 0 0 1 1 0 1\n",
            " 0 1 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0 1 1 1 1 0 1 1 1 1 1 0 0 0\n",
            " 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 0 0 1 0 0 1 0 0 1 1 0 1 1 0 0 1 1 1 0 1\n",
            " 1 1 1 1 0 1 1 0 0 0 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 0 0 1 0 0 1 1 1 0 1 1 1\n",
            " 1 0 1 0 1 0 1 0 1 0 1 1 0 0 0 0 1 1 0 1 1 1 0 1 0 0 1 0 1 0 1 0 1 1 1 1 0\n",
            " 0 1 0 1 0 1 1 1 1 0 0 0 1 0 1 1 1 0 1 0 0 1 0 1 0 0 0 0 1 0 1 1 1 1 0 0 0\n",
            " 1 0 0 1 1 1 0 0 0 0 1 1 0 0 1 1 1 1 1 0 0 1 0 0 1 1 0 0 0 1 0 1 1 1 1 0 1\n",
            " 0 0 0 0 0 0 1 0 1 1 1 1 1 1 1 0 0 1 0 1 0 1 1 1 1 1 1 1 1 0 0 1 0 1 1 0 1\n",
            " 1 0 1 0 0 0 0 1 0 0 1 1 1 0 1 1 0 0 0 1 1 0 1 1 0 0 1 1 1 1 0 1 1 1 0 0 1\n",
            " 1 1 1 1 1 0 1 0 1 1 0 0 1 1 1 0 1 1 1 1 1 0 1 1 0 1 1 0 1 0 0 0 1 0 1 1 1\n",
            " 0 0 1 0 1 0 1 1 0 0 1 0 1 1 1 1 1 0 1 1 1 0 0 0 0 0 0 1 1 1 1 1 1 1 0 1 0\n",
            " 1 0 0 1 0 0 1 1 1 1 0 0 0]\n",
            "std (827,) [40. 30. 50. 40. 20. 40. 30. 30. 30. 50. 50. 50. 40. 30. 40. 20. 30. 30.\n",
            " 30. 20. 20. 30. 30. 40. 50. 40. 30. 30. 30. 30. 20. 30. 40. 50. 20. 30.\n",
            " 30. 30. 20. 50. 40. 20. 20. 40. 50. 30. 30. 50. 40. 30. 50. 40. 50. 40.\n",
            " 30. 40. 50. 50. 40. 10. 40. 50. 40. 40. 50. 30. 30. 30. 30. 30. 20. 40.\n",
            " 50. 30. 20. 50. 40. 40. 20. 40. 40. 30. 40. 50. 40. 30. 30. 50. 30. 40.\n",
            " 50. 30. 50. 40. 10. 20. 40. 20. 30. 40. 40. 40. 40. 30. 30. 50. 20. 40.\n",
            " 50. 40. 20. 40. 40. 30. 20. 40. 20. 20. 40. 50. 20. 30. 20. 30. 50. 40.\n",
            " 20. 40. 30. 30. 40. 50. 20. 30. 50. 20. 40. 30. 30. 40. 30. 30. 50. 30.\n",
            " 50. 40. 30. 30. 30. 40. 40. 30. 50. 50. 30. 20. 40. 50. 40. 20. 30. 20.\n",
            " 50. 30. 10. 40. 20. 30. 30. 30. 40. 40. 30. 50. 30. 40. 40. 40. 30. 40.\n",
            " 30. 50. 50. 30. 20. 30. 40. 50. 30. 50. 50. 40. 30. 50. 40. 30. 30. 20.\n",
            " 30. 50. 20. 30. 40. 20. 50. 40. 20. 40. 30. 30. 40. 50. 30. 40. 50. 50.\n",
            " 40. 40. 40. 50. 50. 40. 20. 20. 50. 10. 20. 50. 50. 30. 40. 30. 50. 40.\n",
            " 30. 50. 30. 40. 30. 30. 30. 40. 40. 30. 40. 40. 30. 40. 20. 20. 30. 50.\n",
            " 40. 40. 40. 30. 30. 40. 30. 40. 40. 20. 20. 30. 40. 30. 40. 50. 20. 30.\n",
            " 50. 50. 40. 40. 40. 50. 50. 40. 50. 20. 50. 30. 40. 40. 50. 40. 10. 40.\n",
            " 50. 50. 10. 30. 40. 50. 40. 40. 40. 20. 30. 50. 50. 30. 50. 40. 40. 50.\n",
            " 30. 40. 40. 40. 50. 20. 50. 40. 30. 50. 40. 50. 30. 50. 30. 40. 20. 20.\n",
            " 50. 40. 30. 30. 40. 40. 30. 30. 30. 40. 40. 40. 40. 40. 30. 50. 30. 40.\n",
            " 30. 50. 30. 50. 40. 40. 30. 50. 30. 30. 20. 30. 50. 40. 40. 30. 30. 30.\n",
            " 50. 40. 40. 40. 30. 30. 50. 30. 30. 30. 50. 30. 40. 30. 40. 30. 50. 20.\n",
            " 40. 30. 50. 30. 40. 40. 50. 50. 30. 40. 40. 50. 30. 30. 20. 20. 40. 40.\n",
            " 30. 30. 50. 40. 40. 30. 20. 40. 20. 30. 40. 30. 40. 30. 30. 30. 50. 40.\n",
            " 40. 30. 40. 20. 40. 40. 50. 50. 50. 20. 30. 40. 50. 40. 50. 40. 20. 50.\n",
            " 20. 20. 30. 40. 30. 20. 40. 40. 40. 40. 30. 40. 40. 50. 30. 40. 20. 30.\n",
            " 20. 30. 40. 40. 40. 20. 40. 40. 40. 30. 50. 30. 40. 40. 20. 40. 40. 20.\n",
            " 50. 40. 30. 40. 20. 30. 50. 40. 40. 40. 40. 40. 30. 40. 40. 40. 40. 50.\n",
            " 50. 40. 50. 40. 50. 40. 50. 50. 10. 40. 50. 30. 30. 40. 50. 30. 40. 40.\n",
            " 50. 20. 50. 40. 40. 50. 40. 40. 10. 40. 30. 30. 50. 50. 50. 50. 30. 40.\n",
            " 50. 40. 50. 40. 50. 20. 50. 50. 50. 30. 40. 40. 40. 50. 30. 10. 40. 40.\n",
            " 40. 20. 30. 50.  0. 50. 30. 40. 50. 40. 40. 30. 40. 50. 40. 30. 30. 50.\n",
            " 30. 50. 20. 20. 50. 40. 50. 40. 20. 20. 20. 40. 40. 40. 40. 20. 10. 40.\n",
            " 30. 30. 30. 30. 40. 30. 40. 40. 20. 40. 40. 20. 20. 30. 50. 30. 50. 50.\n",
            " 50. 30. 30. 50. 40. 20. 30. 40. 30. 50. 20. 30. 50. 30. 40. 30. 20. 40.\n",
            " 40. 50. 40. 40. 40. 40. 40. 50. 40. 50. 40. 40. 30. 20. 40. 30. 40. 40.\n",
            " 40. 30. 40. 20. 40. 40. 20. 50. 40. 40. 40. 40. 50. 40. 30. 40. 40. 40.\n",
            " 30. 40. 40. 20. 30. 30. 40. 50. 30. 30. 50. 30. 40. 40. 20. 40. 40. 30.\n",
            " 40. 40. 40. 50. 30. 30. 40. 30. 40. 30. 20. 30. 30. 20. 20. 30. 30. 50.\n",
            " 30. 20. 20. 40. 20. 20. 40. 40. 40. 10. 30. 30. 20. 50. 40. 40. 20. 20.\n",
            " 30. 40. 40. 30. 30. 40. 40. 20. 30. 20. 20. 40. 20. 40. 40. 50. 40. 30.\n",
            " 40. 20. 40. 20. 40. 20. 50. 40. 40. 10. 30. 50. 50. 40. 40. 40. 40. 50.\n",
            " 40. 40. 40. 40. 50. 30. 40. 30. 40. 30. 40. 40. 20. 40. 40. 40. 50. 40.\n",
            " 30. 30. 40. 20. 30. 30. 30. 50. 40. 50. 40. 20. 50. 30. 40. 40. 40. 20.\n",
            " 50. 50. 50. 30. 40. 40. 30. 50. 30. 40. 40. 30. 30. 20. 50. 40. 40. 30.\n",
            " 40. 40. 30. 20. 40. 20. 30. 20. 40. 10. 30. 30. 20. 50. 20. 20. 50. 50.\n",
            " 30. 20. 30. 50. 40. 20. 40. 10. 40. 50. 50. 40. 20. 40. 20. 30. 50.]\n",
            "selection [544 537 286 290 574 693 817 164  59 729 512 225 494  94 801 132 566 135\n",
            " 527 455 561 297 560 651 279] (25,) [ 0. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 20. 20. 20.\n",
            " 20. 20. 20. 20. 20. 20. 20.]\n",
            "trainset before adding uncertain samples (475, 10) (475,)\n",
            "trainset after adding uncertain samples (500, 10) (500,)\n",
            "updated train set: (500, 10) (500,) unique(labels): [256 244] [0 1]\n",
            "val set: (802, 10) (802,)\n",
            "\n",
            "Train set: (500, 10)\n",
            "Validation set: (802, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 20\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.074 s \n",
            "\n",
            "Accuracy rate is 79.032258 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86       321\n",
            "           1       0.61      0.53      0.57       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.73      0.71      0.72       434\n",
            "weighted avg       0.78      0.79      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[283  38]\n",
            " [ 53  60]]\n",
            "--------------------------------\n",
            "final active learning accuracies [77.41935483870968, 78.57142857142857, 77.18894009216591, 77.18894009216591, 77.41935483870968, 77.41935483870968, 78.3410138248848, 79.49308755760369, 79.95391705069125, 78.3410138248848, 79.03225806451613, 79.03225806451613, 79.03225806451613, 79.26267281105991, 78.11059907834101, 79.95391705069125, 79.49308755760369, 80.87557603686636, 79.49308755760369, 79.03225806451613]\n",
            "saved /Users/wenxuanhuang/Documents/Repo/ML-for-COVID-19-dataset/Results/Active-learning-experiment-39.pkl /Users/wenxuanhuang/Documents/Repo/ML-for-COVID-19-dataset ['Decision_tree.ipynb', 'dec_git.png', 'Logit_default_f10.pdf', 'Logistic.ipynb', 'SVC.ipynb', 'RF_f5e50_featureimp.pdf', 'log_al.png', 'dec_git.pdf', '.DS_Store', 'log_git.png', 'svm_git.png', 'Logistic_Scikit.ipynb', 'knn_git.pdf', 'knn_git.png', 'rf_al.png', 'Best classifier_RF_f5e50.pdf', 'KNN.ipynb', 'GBDC.ipynb', 'rf_git.png', 'README.md', 'all_training.csv', 'Results', 'svm_al.png', 'Log_ROC.png', 'Logit_default_f7(p_removal).pdf', 'Active_learning.ipynb', 'Random_forest.ipynb', 'Model_select.ipynb', 'gdbc_git.png', '.git', '.vscode', 'Untitled', 'RF_f5e50_modelselect.pdf', 'Logit_default_f8(std_removal).pdf']\n",
            "\n",
            "---------------------------- FINISHED ---------------------------\n",
            "\n",
            "Count = 40, using model = KnnModel, selection_function = MinStdSelection, k = 10, iteration = 0.\n",
            "\n",
            "initial random chosen samples (10,)\n",
            "initial train set: (10, 10) (10,) unique(labels): [6 4] [0 1]\n",
            "Val set: (1292, 10) (1292,) (10,)\n",
            "\n",
            "Train set: (10, 10)\n",
            "Validation set: (1292, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.095 s \n",
            "\n",
            "Accuracy rate is 73.963134 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      1.00      0.85       321\n",
            "           1       0.00      0.00      0.00       113\n",
            "\n",
            "    accuracy                           0.74       434\n",
            "   macro avg       0.37      0.50      0.43       434\n",
            "weighted avg       0.55      0.74      0.63       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[321   0]\n",
            " [113   0]]\n",
            "--------------------------------\n",
            "val predicted: (1292,) [0 0 0 ... 0 0 0]\n",
            "probabilities: (1292, 2) \n",
            " [0 0 0 ... 0 0 0]\n",
            "std (1292,) [10. 10. 10. ... 10. 10. 10.]\n",
            "selection [  0 865 864 863 862 861 860 859 866 858] (10,) [10. 10. 10. 10. 10. 10. 10. 10. 10. 10.]\n",
            "trainset before adding uncertain samples (10, 10) (10,)\n",
            "trainset after adding uncertain samples (20, 10) (20,)\n",
            "updated train set: (20, 10) (20,) unique(labels): [12  8] [0 1]\n",
            "val set: (1282, 10) (1282,)\n",
            "\n",
            "Train set: (20, 10)\n",
            "Validation set: (1282, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.113 s \n",
            "\n",
            "Accuracy rate is 67.741935 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.71      0.77       321\n",
            "           1       0.42      0.58      0.49       113\n",
            "\n",
            "    accuracy                           0.68       434\n",
            "   macro avg       0.62      0.65      0.63       434\n",
            "weighted avg       0.72      0.68      0.69       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[228  93]\n",
            " [ 47  66]]\n",
            "--------------------------------\n",
            "val predicted: (1282,) [1 1 1 ... 0 0 1]\n",
            "probabilities: (1282, 2) \n",
            " [1 1 1 ... 0 0 1]\n",
            "std (1282,) [20. 20. 10. ... 50.  0. 10.]\n",
            "selection [912 242 421 240 422 945 946 668 234 956] (10,) [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "trainset before adding uncertain samples (20, 10) (20,)\n",
            "trainset after adding uncertain samples (30, 10) (30,)\n",
            "updated train set: (30, 10) (30,) unique(labels): [17 13] [0 1]\n",
            "val set: (1272, 10) (1272,)\n",
            "\n",
            "Train set: (30, 10)\n",
            "Validation set: (1272, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "/Users/wenxuanhuang/Library/Python/3.8/lib/python/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/Users/wenxuanhuang/Library/Python/3.8/lib/python/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/Users/wenxuanhuang/Library/Python/3.8/lib/python/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "--------------------------------\n",
            "Iteration: 3\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.115 s \n",
            "\n",
            "Accuracy rate is 66.129032 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.69      0.75       321\n",
            "           1       0.40      0.58      0.47       113\n",
            "\n",
            "    accuracy                           0.66       434\n",
            "   macro avg       0.61      0.63      0.61       434\n",
            "weighted avg       0.71      0.66      0.68       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[222  99]\n",
            " [ 48  65]]\n",
            "--------------------------------\n",
            "val predicted: (1272,) [1 1 1 ... 0 0 0]\n",
            "probabilities: (1272, 2) \n",
            " [1 1 1 ... 0 0 0]\n",
            "std (1272,) [10. 20. 10. ... 30. 20.  0.]\n",
            "selection [1271  840  839  829  828  825  240  241  823  817] (10,) [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "trainset before adding uncertain samples (30, 10) (30,)\n",
            "trainset after adding uncertain samples (40, 10) (40,)\n",
            "updated train set: (40, 10) (40,) unique(labels): [24 16] [0 1]\n",
            "val set: (1262, 10) (1262,)\n",
            "\n",
            "Train set: (40, 10)\n",
            "Validation set: (1262, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 4\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.108 s \n",
            "\n",
            "Accuracy rate is 76.728111 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.88      0.85       321\n",
            "           1       0.57      0.43      0.49       113\n",
            "\n",
            "    accuracy                           0.77       434\n",
            "   macro avg       0.69      0.66      0.67       434\n",
            "weighted avg       0.75      0.77      0.76       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[284  37]\n",
            " [ 64  49]]\n",
            "--------------------------------\n",
            "val predicted: (1262,) [1 1 1 ... 0 0 0]\n",
            "probabilities: (1262, 2) \n",
            " [1 1 1 ... 0 0 0]\n",
            "std (1262,) [30. 20. 10. ... 20. 30. 50.]\n",
            "selection [1030  350  129  808  807 1211  805  232  136  914] (10,) [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "trainset before adding uncertain samples (40, 10) (40,)\n",
            "trainset after adding uncertain samples (50, 10) (50,)\n",
            "updated train set: (50, 10) (50,) unique(labels): [30 20] [0 1]\n",
            "val set: (1252, 10) (1252,)\n",
            "\n",
            "Train set: (50, 10)\n",
            "Validation set: (1252, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 5\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.086 s \n",
            "\n",
            "Accuracy rate is 78.341014 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.92      0.86       321\n",
            "           1       0.64      0.39      0.48       113\n",
            "\n",
            "    accuracy                           0.78       434\n",
            "   macro avg       0.72      0.66      0.67       434\n",
            "weighted avg       0.77      0.78      0.76       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[296  25]\n",
            " [ 69  44]]\n",
            "--------------------------------\n",
            "val predicted: (1252,) [1 1 0 ... 0 0 0]\n",
            "probabilities: (1252, 2) \n",
            " [1 1 0 ... 0 0 0]\n",
            "std (1252,) [20. 20.  0. ... 20. 10. 50.]\n",
            "selection [ 482  238  855  250 1180 1179  259  847 1169  283] (10,) [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "trainset before adding uncertain samples (50, 10) (50,)\n",
            "trainset after adding uncertain samples (60, 10) (60,)\n",
            "updated train set: (60, 10) (60,) unique(labels): [31 29] [0 1]\n",
            "val set: (1242, 10) (1242,)\n",
            "\n",
            "Train set: (60, 10)\n",
            "Validation set: (1242, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 6\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.093 s \n",
            "\n",
            "Accuracy rate is 75.115207 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.83      0.83       321\n",
            "           1       0.52      0.54      0.53       113\n",
            "\n",
            "    accuracy                           0.75       434\n",
            "   macro avg       0.68      0.68      0.68       434\n",
            "weighted avg       0.75      0.75      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[265  56]\n",
            " [ 52  61]]\n",
            "--------------------------------\n",
            "val predicted: (1242,) [1 1 0 ... 0 0 0]\n",
            "probabilities: (1242, 2) \n",
            " [1 1 0 ... 0 0 0]\n",
            "std (1242,) [40. 30.  0. ... 20. 10. 40.]\n",
            "selection [1011  626 1206 1099  159 1210  680  139  720  135] (10,) [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "trainset before adding uncertain samples (60, 10) (60,)\n",
            "trainset after adding uncertain samples (70, 10) (70,)\n",
            "updated train set: (70, 10) (70,) unique(labels): [36 34] [0 1]\n",
            "val set: (1232, 10) (1232,)\n",
            "\n",
            "Train set: (70, 10)\n",
            "Validation set: (1232, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 7\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.089 s \n",
            "\n",
            "Accuracy rate is 73.502304 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.82      0.82       321\n",
            "           1       0.49      0.50      0.49       113\n",
            "\n",
            "    accuracy                           0.74       434\n",
            "   macro avg       0.66      0.66      0.66       434\n",
            "weighted avg       0.74      0.74      0.74       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[263  58]\n",
            " [ 57  56]]\n",
            "--------------------------------\n",
            "val predicted: (1232,) [1 1 0 ... 0 0 0]\n",
            "probabilities: (1232, 2) \n",
            " [1 1 0 ... 0 0 0]\n",
            "std (1232,) [40. 30.  0. ... 10. 10. 40.]\n",
            "selection [1195  247 1190  836  839  674  427  424  252 1178] (10,) [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "trainset before adding uncertain samples (70, 10) (70,)\n",
            "trainset after adding uncertain samples (80, 10) (80,)\n",
            "updated train set: (80, 10) (80,) unique(labels): [44 36] [0 1]\n",
            "val set: (1222, 10) (1222,)\n",
            "\n",
            "Train set: (80, 10)\n",
            "Validation set: (1222, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 8\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.088 s \n",
            "\n",
            "Accuracy rate is 75.806452 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.86      0.84       321\n",
            "           1       0.54      0.48      0.51       113\n",
            "\n",
            "    accuracy                           0.76       434\n",
            "   macro avg       0.68      0.67      0.67       434\n",
            "weighted avg       0.75      0.76      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[275  46]\n",
            " [ 59  54]]\n",
            "--------------------------------\n",
            "val predicted: (1222,) [1 1 0 ... 0 0 0]\n",
            "probabilities: (1222, 2) \n",
            " [1 1 0 ... 0 0 0]\n",
            "std (1222,) [40. 30.  0. ... 10. 30. 30.]\n",
            "selection [1063 1174  552  548  361  877  880  115  116  881] (10,) [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "trainset before adding uncertain samples (80, 10) (80,)\n",
            "trainset after adding uncertain samples (90, 10) (90,)\n",
            "updated train set: (90, 10) (90,) unique(labels): [47 43] [0 1]\n",
            "val set: (1212, 10) (1212,)\n",
            "\n",
            "Train set: (90, 10)\n",
            "Validation set: (1212, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 9\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.100 s \n",
            "\n",
            "Accuracy rate is 74.654378 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.83      0.83       321\n",
            "           1       0.51      0.51      0.51       113\n",
            "\n",
            "    accuracy                           0.75       434\n",
            "   macro avg       0.67      0.67      0.67       434\n",
            "weighted avg       0.75      0.75      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[266  55]\n",
            " [ 55  58]]\n",
            "--------------------------------\n",
            "val predicted: (1212,) [1 1 0 ... 0 0 0]\n",
            "probabilities: (1212, 2) \n",
            " [1 1 0 ... 0 0 0]\n",
            "std (1212,) [40. 40. 10. ...  0. 30. 20.]\n",
            "selection [ 863  132 1126  516  315  765  520 1121  129  144] (10,) [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "trainset before adding uncertain samples (90, 10) (90,)\n",
            "trainset after adding uncertain samples (100, 10) (100,)\n",
            "updated train set: (100, 10) (100,) unique(labels): [54 46] [0 1]\n",
            "val set: (1202, 10) (1202,)\n",
            "\n",
            "Train set: (100, 10)\n",
            "Validation set: (1202, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 10\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.081 s \n",
            "\n",
            "Accuracy rate is 76.267281 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.87      0.84       321\n",
            "           1       0.55      0.46      0.50       113\n",
            "\n",
            "    accuracy                           0.76       434\n",
            "   macro avg       0.69      0.66      0.67       434\n",
            "weighted avg       0.75      0.76      0.76       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[279  42]\n",
            " [ 61  52]]\n",
            "--------------------------------\n",
            "val predicted: (1202,) [1 1 0 ... 0 0 0]\n",
            "probabilities: (1202, 2) \n",
            " [1 1 0 ... 0 0 0]\n",
            "std (1202,) [30. 30. 10. ... 10. 20. 20.]\n",
            "selection [600 655 427 959 205 419 413 958 106 830] (10,) [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "trainset before adding uncertain samples (100, 10) (100,)\n",
            "trainset after adding uncertain samples (110, 10) (110,)\n",
            "updated train set: (110, 10) (110,) unique(labels): [61 49] [0 1]\n",
            "val set: (1192, 10) (1192,)\n",
            "\n",
            "Train set: (110, 10)\n",
            "Validation set: (1192, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 11\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.098 s \n",
            "\n",
            "Accuracy rate is 74.884793 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.83      0.83       321\n",
            "           1       0.52      0.52      0.52       113\n",
            "\n",
            "    accuracy                           0.75       434\n",
            "   macro avg       0.67      0.68      0.67       434\n",
            "weighted avg       0.75      0.75      0.75       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[266  55]\n",
            " [ 54  59]]\n",
            "--------------------------------\n",
            "val predicted: (1192,) [1 1 0 ... 0 0 0]\n",
            "probabilities: (1192, 2) \n",
            " [1 1 0 ... 0 0 0]\n",
            "std (1192,) [30. 20.  0. ... 10. 20. 20.]\n",
            "selection [1054  324 1076  427  115  426  214 1071  434 1070] (10,) [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "trainset before adding uncertain samples (110, 10) (110,)\n",
            "trainset after adding uncertain samples (120, 10) (120,)\n",
            "updated train set: (120, 10) (120,) unique(labels): [63 57] [0 1]\n",
            "val set: (1182, 10) (1182,)\n",
            "\n",
            "Train set: (120, 10)\n",
            "Validation set: (1182, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 12\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.095 s \n",
            "\n",
            "Accuracy rate is 76.728111 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.82      0.84       321\n",
            "           1       0.55      0.62      0.58       113\n",
            "\n",
            "    accuracy                           0.77       434\n",
            "   macro avg       0.70      0.72      0.71       434\n",
            "weighted avg       0.78      0.77      0.77       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[263  58]\n",
            " [ 43  70]]\n",
            "--------------------------------\n",
            "val predicted: (1182,) [1 1 0 ... 0 0 0]\n",
            "probabilities: (1182, 2) \n",
            " [1 1 0 ... 0 0 0]\n",
            "std (1182,) [30. 40.  0. ... 10. 20. 20.]\n",
            "selection [757 638 532 991 993 379 827 998 639 467] (10,) [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "trainset before adding uncertain samples (120, 10) (120,)\n",
            "trainset after adding uncertain samples (130, 10) (130,)\n",
            "updated train set: (130, 10) (130,) unique(labels): [70 60] [0 1]\n",
            "val set: (1172, 10) (1172,)\n",
            "\n",
            "Train set: (130, 10)\n",
            "Validation set: (1172, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 13\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.105 s \n",
            "\n",
            "Accuracy rate is 78.341014 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.86      0.85       321\n",
            "           1       0.59      0.57      0.58       113\n",
            "\n",
            "    accuracy                           0.78       434\n",
            "   macro avg       0.72      0.71      0.72       434\n",
            "weighted avg       0.78      0.78      0.78       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[276  45]\n",
            " [ 49  64]]\n",
            "--------------------------------\n",
            "val predicted: (1172,) [1 1 0 ... 0 0 0]\n",
            "probabilities: (1172, 2) \n",
            " [1 1 0 ... 0 0 0]\n",
            "std (1172,) [10. 40. 10. ... 20. 30. 30.]\n",
            "selection [ 853  855  484  860 1076  152  153  157  463  462] (10,) [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "trainset before adding uncertain samples (130, 10) (130,)\n",
            "trainset after adding uncertain samples (140, 10) (140,)\n",
            "updated train set: (140, 10) (140,) unique(labels): [76 64] [0 1]\n",
            "val set: (1162, 10) (1162,)\n",
            "\n",
            "Train set: (140, 10)\n",
            "Validation set: (1162, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 14\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.103 s \n",
            "\n",
            "Accuracy rate is 77.419355 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.88      0.85       321\n",
            "           1       0.58      0.49      0.53       113\n",
            "\n",
            "    accuracy                           0.77       434\n",
            "   macro avg       0.70      0.68      0.69       434\n",
            "weighted avg       0.76      0.77      0.77       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[281  40]\n",
            " [ 58  55]]\n",
            "--------------------------------\n",
            "val predicted: (1162,) [0 1 0 ... 0 0 0]\n",
            "probabilities: (1162, 2) \n",
            " [0 1 0 ... 0 0 0]\n",
            "std (1162,) [10. 40.  0. ... 10. 30. 20.]\n",
            "selection [246 371 693 998 997 358 700 989 680 136] (10,) [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "trainset before adding uncertain samples (140, 10) (140,)\n",
            "trainset after adding uncertain samples (150, 10) (150,)\n",
            "updated train set: (150, 10) (150,) unique(labels): [80 70] [0 1]\n",
            "val set: (1152, 10) (1152,)\n",
            "\n",
            "Train set: (150, 10)\n",
            "Validation set: (1152, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 15\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.086 s \n",
            "\n",
            "Accuracy rate is 76.267281 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.86      0.84       321\n",
            "           1       0.55      0.50      0.52       113\n",
            "\n",
            "    accuracy                           0.76       434\n",
            "   macro avg       0.69      0.68      0.68       434\n",
            "weighted avg       0.76      0.76      0.76       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[275  46]\n",
            " [ 57  56]]\n",
            "--------------------------------\n",
            "val predicted: (1152,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1152, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "std (1152,) [10. 40. 10. ...  0. 30. 20.]\n",
            "selection [498 962 702 983 984 673 661 126 370 649] (10,) [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "trainset before adding uncertain samples (150, 10) (150,)\n",
            "trainset after adding uncertain samples (160, 10) (160,)\n",
            "updated train set: (160, 10) (160,) unique(labels): [85 75] [0 1]\n",
            "val set: (1142, 10) (1142,)\n",
            "\n",
            "Train set: (160, 10)\n",
            "Validation set: (1142, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 16\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.078 s \n",
            "\n",
            "Accuracy rate is 76.728111 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.86      0.85       321\n",
            "           1       0.56      0.50      0.53       113\n",
            "\n",
            "    accuracy                           0.77       434\n",
            "   macro avg       0.69      0.68      0.69       434\n",
            "weighted avg       0.76      0.77      0.76       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[277  44]\n",
            " [ 57  56]]\n",
            "--------------------------------\n",
            "val predicted: (1142,) [0 1 1 ... 0 0 0]\n",
            "probabilities: (1142, 2) \n",
            " [0 1 1 ... 0 0 0]\n",
            "std (1142,) [ 0. 40. 20. ... 10. 30. 20.]\n",
            "selection [   0 1013  873  634   93 1025  619 1028  618 1031] (10,) [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "trainset before adding uncertain samples (160, 10) (160,)\n",
            "trainset after adding uncertain samples (170, 10) (170,)\n",
            "updated train set: (170, 10) (170,) unique(labels): [87 83] [0 1]\n",
            "val set: (1132, 10) (1132,)\n",
            "\n",
            "Train set: (170, 10)\n",
            "Validation set: (1132, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 17\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.097 s \n",
            "\n",
            "Accuracy rate is 76.036866 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.85      0.84       321\n",
            "           1       0.54      0.50      0.52       113\n",
            "\n",
            "    accuracy                           0.76       434\n",
            "   macro avg       0.69      0.67      0.68       434\n",
            "weighted avg       0.75      0.76      0.76       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[274  47]\n",
            " [ 57  56]]\n",
            "--------------------------------\n",
            "val predicted: (1132,) [1 1 0 ... 0 0 0]\n",
            "probabilities: (1132, 2) \n",
            " [1 1 0 ... 0 0 0]\n",
            "std (1132,) [40. 20. 10. ... 10. 30. 30.]\n",
            "selection [161 533 805  61 744  59  58 979 398 392] (10,) [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "trainset before adding uncertain samples (170, 10) (170,)\n",
            "trainset after adding uncertain samples (180, 10) (180,)\n",
            "updated train set: (180, 10) (180,) unique(labels): [89 91] [0 1]\n",
            "val set: (1122, 10) (1122,)\n",
            "\n",
            "Train set: (180, 10)\n",
            "Validation set: (1122, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 18\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.083 s \n",
            "\n",
            "Accuracy rate is 76.728111 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.86      0.84       321\n",
            "           1       0.56      0.51      0.53       113\n",
            "\n",
            "    accuracy                           0.77       434\n",
            "   macro avg       0.70      0.68      0.69       434\n",
            "weighted avg       0.76      0.77      0.76       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[275  46]\n",
            " [ 55  58]]\n",
            "--------------------------------\n",
            "val predicted: (1122,) [1 1 0 ... 0 0 0]\n",
            "probabilities: (1122, 2) \n",
            " [1 1 0 ... 0 0 0]\n",
            "std (1122,) [50. 20. 10. ... 10. 30. 30.]\n",
            "selection [560 859 991 488 634 778 484 296 480 656] (10,) [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "trainset before adding uncertain samples (180, 10) (180,)\n",
            "trainset after adding uncertain samples (190, 10) (190,)\n",
            "updated train set: (190, 10) (190,) unique(labels): [94 96] [0 1]\n",
            "val set: (1112, 10) (1112,)\n",
            "\n",
            "Train set: (190, 10)\n",
            "Validation set: (1112, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 19\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.106 s \n",
            "\n",
            "Accuracy rate is 76.267281 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.85      0.84       321\n",
            "           1       0.55      0.50      0.53       113\n",
            "\n",
            "    accuracy                           0.76       434\n",
            "   macro avg       0.69      0.68      0.68       434\n",
            "weighted avg       0.76      0.76      0.76       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[274  47]\n",
            " [ 56  57]]\n",
            "--------------------------------\n",
            "val predicted: (1112,) [1 1 0 ... 0 0 0]\n",
            "probabilities: (1112, 2) \n",
            " [1 1 0 ... 0 0 0]\n",
            "std (1112,) [50. 20. 10. ... 20. 30. 30.]\n",
            "selection [ 788 1067  888  336  756   75  433  813 1084  420] (10,) [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "trainset before adding uncertain samples (190, 10) (190,)\n",
            "trainset after adding uncertain samples (200, 10) (200,)\n",
            "updated train set: (200, 10) (200,) unique(labels): [ 99 101] [0 1]\n",
            "val set: (1102, 10) (1102,)\n",
            "\n",
            "Train set: (200, 10)\n",
            "Validation set: (1102, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 20\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.089 s \n",
            "\n",
            "Accuracy rate is 76.728111 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.86      0.84       321\n",
            "           1       0.56      0.51      0.53       113\n",
            "\n",
            "    accuracy                           0.77       434\n",
            "   macro avg       0.70      0.68      0.69       434\n",
            "weighted avg       0.76      0.77      0.76       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[275  46]\n",
            " [ 55  58]]\n",
            "--------------------------------\n",
            "val predicted: (1102,) [1 1 0 ... 0 0 0]\n",
            "probabilities: (1102, 2) \n",
            " [1 1 0 ... 0 0 0]\n",
            "std (1102,) [50. 10. 10. ... 20. 30. 30.]\n",
            "selection [ 824  539  578   94  593 1011  596 1003  141  665] (10,) [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "trainset before adding uncertain samples (200, 10) (200,)\n",
            "trainset after adding uncertain samples (210, 10) (210,)\n",
            "updated train set: (210, 10) (210,) unique(labels): [106 104] [0 1]\n",
            "val set: (1092, 10) (1092,)\n",
            "\n",
            "Train set: (210, 10)\n",
            "Validation set: (1092, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 21\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.089 s \n",
            "\n",
            "Accuracy rate is 77.419355 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.87      0.85       321\n",
            "           1       0.57      0.51      0.54       113\n",
            "\n",
            "    accuracy                           0.77       434\n",
            "   macro avg       0.70      0.69      0.70       434\n",
            "weighted avg       0.77      0.77      0.77       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[278  43]\n",
            " [ 55  58]]\n",
            "--------------------------------\n",
            "val predicted: (1092,) [1 1 0 ... 0 0 0]\n",
            "probabilities: (1092, 2) \n",
            " [1 1 0 ... 0 0 0]\n",
            "std (1092,) [50. 10. 10. ... 20. 30. 40.]\n",
            "selection [372 509 699 382 910 903 776 901 676  79] (10,) [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "trainset before adding uncertain samples (210, 10) (210,)\n",
            "trainset after adding uncertain samples (220, 10) (220,)\n",
            "updated train set: (220, 10) (220,) unique(labels): [113 107] [0 1]\n",
            "val set: (1082, 10) (1082,)\n",
            "\n",
            "Train set: (220, 10)\n",
            "Validation set: (1082, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 22\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.094 s \n",
            "\n",
            "Accuracy rate is 77.880184 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.87      0.85       321\n",
            "           1       0.59      0.51      0.55       113\n",
            "\n",
            "    accuracy                           0.78       434\n",
            "   macro avg       0.71      0.69      0.70       434\n",
            "weighted avg       0.77      0.78      0.77       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[280  41]\n",
            " [ 55  58]]\n",
            "--------------------------------\n",
            "val predicted: (1082,) [1 0 0 ... 0 0 0]\n",
            "probabilities: (1082, 2) \n",
            " [1 0 0 ... 0 0 0]\n",
            "std (1082,) [50.  0. 10. ... 20. 30. 40.]\n",
            "selection [892 210 515  87 482 483 326 258 959 557] (10,) [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "trainset before adding uncertain samples (220, 10) (220,)\n",
            "trainset after adding uncertain samples (230, 10) (230,)\n",
            "updated train set: (230, 10) (230,) unique(labels): [116 114] [0 1]\n",
            "val set: (1072, 10) (1072,)\n",
            "\n",
            "Train set: (230, 10)\n",
            "Validation set: (1072, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 23\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.101 s \n",
            "\n",
            "Accuracy rate is 77.880184 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.88      0.85       321\n",
            "           1       0.59      0.50      0.54       113\n",
            "\n",
            "    accuracy                           0.78       434\n",
            "   macro avg       0.71      0.69      0.70       434\n",
            "weighted avg       0.77      0.78      0.77       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[282  39]\n",
            " [ 57  56]]\n",
            "--------------------------------\n",
            "val predicted: (1072,) [1 1 0 ... 0 0 0]\n",
            "probabilities: (1072, 2) \n",
            " [1 1 0 ... 0 0 0]\n",
            "std (1072,) [50. 10. 10. ... 20. 30. 50.]\n",
            "selection [298 180 808 666 143 787 506 177 406 205] (10,) [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "trainset before adding uncertain samples (230, 10) (230,)\n",
            "trainset after adding uncertain samples (240, 10) (240,)\n",
            "updated train set: (240, 10) (240,) unique(labels): [121 119] [0 1]\n",
            "val set: (1062, 10) (1062,)\n",
            "\n",
            "Train set: (240, 10)\n",
            "Validation set: (1062, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 24\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.096 s \n",
            "\n",
            "Accuracy rate is 79.723502 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.88      0.87       321\n",
            "           1       0.63      0.55      0.58       113\n",
            "\n",
            "    accuracy                           0.80       434\n",
            "   macro avg       0.74      0.72      0.73       434\n",
            "weighted avg       0.79      0.80      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[284  37]\n",
            " [ 51  62]]\n",
            "--------------------------------\n",
            "val predicted: (1062,) [1 0 0 ... 0 0 0]\n",
            "probabilities: (1062, 2) \n",
            " [1 0 0 ... 0 0 0]\n",
            "std (1062,) [50.  0. 10. ... 20. 30. 50.]\n",
            "selection [ 141 1025  416  769  115  812  231  476  836   64] (10,) [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "trainset before adding uncertain samples (240, 10) (240,)\n",
            "trainset after adding uncertain samples (250, 10) (250,)\n",
            "updated train set: (250, 10) (250,) unique(labels): [129 121] [0 1]\n",
            "val set: (1052, 10) (1052,)\n",
            "\n",
            "Train set: (250, 10)\n",
            "Validation set: (1052, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 25\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.085 s \n",
            "\n",
            "Accuracy rate is 79.032258 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.89      0.86       321\n",
            "           1       0.62      0.51      0.56       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.73      0.70      0.71       434\n",
            "weighted avg       0.78      0.79      0.78       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[285  36]\n",
            " [ 55  58]]\n",
            "--------------------------------\n",
            "val predicted: (1052,) [1 0 0 ... 0 0 0]\n",
            "probabilities: (1052, 2) \n",
            " [1 0 0 ... 0 0 0]\n",
            "std (1052,) [50.  0. 10. ... 20. 30. 50.]\n",
            "selection [ 447 1038  858  752 1045  632  847   40  133  547] (10,) [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "trainset before adding uncertain samples (250, 10) (250,)\n",
            "trainset after adding uncertain samples (260, 10) (260,)\n",
            "updated train set: (260, 10) (260,) unique(labels): [134 126] [0 1]\n",
            "val set: (1042, 10) (1042,)\n",
            "\n",
            "Train set: (260, 10)\n",
            "Validation set: (1042, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 26\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.088 s \n",
            "\n",
            "Accuracy rate is 79.953917 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.90      0.87       321\n",
            "           1       0.65      0.50      0.57       113\n",
            "\n",
            "    accuracy                           0.80       434\n",
            "   macro avg       0.74      0.70      0.72       434\n",
            "weighted avg       0.79      0.80      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[290  31]\n",
            " [ 56  57]]\n",
            "--------------------------------\n",
            "val predicted: (1042,) [1 0 0 ... 0 0 0]\n",
            "probabilities: (1042, 2) \n",
            " [1 0 0 ... 0 0 0]\n",
            "std (1042,) [50. 10. 10. ... 20. 30. 50.]\n",
            "selection [248 398 811 387 793 790 965  57 353  99] (10,) [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "trainset before adding uncertain samples (260, 10) (260,)\n",
            "trainset after adding uncertain samples (270, 10) (270,)\n",
            "updated train set: (270, 10) (270,) unique(labels): [141 129] [0 1]\n",
            "val set: (1032, 10) (1032,)\n",
            "\n",
            "Train set: (270, 10)\n",
            "Validation set: (1032, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 27\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.079 s \n",
            "\n",
            "Accuracy rate is 80.184332 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.91      0.87       321\n",
            "           1       0.66      0.50      0.57       113\n",
            "\n",
            "    accuracy                           0.80       434\n",
            "   macro avg       0.75      0.71      0.72       434\n",
            "weighted avg       0.79      0.80      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[291  30]\n",
            " [ 56  57]]\n",
            "--------------------------------\n",
            "val predicted: (1032,) [1 0 0 ... 0 0 0]\n",
            "probabilities: (1032, 2) \n",
            " [1 0 0 ... 0 0 0]\n",
            "std (1032,) [50. 10. 10. ... 20. 30. 50.]\n",
            "selection [1012  407  441   93  253  154  555  245  550  945] (10,) [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "trainset before adding uncertain samples (270, 10) (270,)\n",
            "trainset after adding uncertain samples (280, 10) (280,)\n",
            "updated train set: (280, 10) (280,) unique(labels): [144 136] [0 1]\n",
            "val set: (1022, 10) (1022,)\n",
            "\n",
            "Train set: (280, 10)\n",
            "Validation set: (1022, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 28\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.080 s \n",
            "\n",
            "Accuracy rate is 78.801843 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86       321\n",
            "           1       0.61      0.52      0.56       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.72      0.70      0.71       434\n",
            "weighted avg       0.78      0.79      0.78       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[283  38]\n",
            " [ 54  59]]\n",
            "--------------------------------\n",
            "val predicted: (1022,) [1 0 0 ... 0 0 0]\n",
            "probabilities: (1022, 2) \n",
            " [1 0 0 ... 0 0 0]\n",
            "std (1022,) [50. 10.  0. ... 20. 20. 50.]\n",
            "selection [356 337 349 995 807 962 496 303 820 969] (10,) [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "trainset before adding uncertain samples (280, 10) (280,)\n",
            "trainset after adding uncertain samples (290, 10) (290,)\n",
            "updated train set: (290, 10) (290,) unique(labels): [148 142] [0 1]\n",
            "val set: (1012, 10) (1012,)\n",
            "\n",
            "Train set: (290, 10)\n",
            "Validation set: (1012, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 29\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.085 s \n",
            "\n",
            "Accuracy rate is 79.493088 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.89      0.86       321\n",
            "           1       0.62      0.53      0.57       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.73      0.71      0.72       434\n",
            "weighted avg       0.79      0.79      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[285  36]\n",
            " [ 53  60]]\n",
            "--------------------------------\n",
            "val predicted: (1012,) [1 0 0 ... 0 0 0]\n",
            "probabilities: (1012, 2) \n",
            " [1 0 0 ... 0 0 0]\n",
            "std (1012,) [50. 10.  0. ... 20. 20. 50.]\n",
            "selection [790 860  61 972 495 514 525  46 954 457] (10,) [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "trainset before adding uncertain samples (290, 10) (290,)\n",
            "trainset after adding uncertain samples (300, 10) (300,)\n",
            "updated train set: (300, 10) (300,) unique(labels): [155 145] [0 1]\n",
            "val set: (1002, 10) (1002,)\n",
            "\n",
            "Train set: (300, 10)\n",
            "Validation set: (1002, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 30\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.089 s \n",
            "\n",
            "Accuracy rate is 79.723502 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.89      0.87       321\n",
            "           1       0.63      0.52      0.57       113\n",
            "\n",
            "    accuracy                           0.80       434\n",
            "   macro avg       0.74      0.71      0.72       434\n",
            "weighted avg       0.79      0.80      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[287  34]\n",
            " [ 54  59]]\n",
            "--------------------------------\n",
            "val predicted: (1002,) [1 0 0 ... 0 0 0]\n",
            "probabilities: (1002, 2) \n",
            " [1 0 0 ... 0 0 0]\n",
            "std (1002,) [50. 10.  0. ... 20. 20. 40.]\n",
            "selection [271 364   2 370 203 770 985 813 274 177] (10,) [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "trainset before adding uncertain samples (300, 10) (300,)\n",
            "trainset after adding uncertain samples (310, 10) (310,)\n",
            "updated train set: (310, 10) (310,) unique(labels): [161 149] [0 1]\n",
            "val set: (992, 10) (992,)\n",
            "\n",
            "Train set: (310, 10)\n",
            "Validation set: (992, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 31\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.083 s \n",
            "\n",
            "Accuracy rate is 80.184332 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.90      0.87       321\n",
            "           1       0.65      0.53      0.58       113\n",
            "\n",
            "    accuracy                           0.80       434\n",
            "   macro avg       0.74      0.71      0.73       434\n",
            "weighted avg       0.79      0.80      0.80       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[288  33]\n",
            " [ 53  60]]\n",
            "--------------------------------\n",
            "val predicted: (992,) [1 0 1 1 0 1 1 1 0 0 1 0 0 0 0 1 1 1 1 0 1 0 1 0 0 0 1 0 0 1 0 1 1 1 0 1 1\n",
            " 1 1 0 0 1 1 0 0 0 1 1 0 1 1 0 0 0 1 1 1 1 1 0 1 1 1 1 1 0 1 0 0 1 1 0 0 1\n",
            " 1 1 1 1 1 1 0 1 0 0 1 0 1 1 0 0 0 0 1 0 0 1 1 1 1 0 1 0 0 0 1 1 1 0 0 1 0\n",
            " 0 1 0 1 0 1 1 1 1 0 1 0 0 1 0 0 1 0 0 1 1 1 1 0 1 1 0 0 1 1 0 0 1 1 1 0 1\n",
            " 1 1 1 1 0 1 0 1 1 0 0 0 1 1 0 1 1 1 0 0 1 0 0 0 0 1 0 1 1 0 1 1 1 1 0 0 1\n",
            " 0 1 1 0 1 1 1 0 0 0 1 0 0 1 1 1 0 0 0 0 0 0 1 0 0 1 0 0 1 1 0 1 1 0 1 1 0\n",
            " 0 1 1 1 0 0 0 0 0 0 1 1 0 1 1 1 1 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 1 0 1 1\n",
            " 0 1 1 1 0 1 1 0 1 0 1 1 1 1 1 1 1 0 0 0 1 1 0 1 0 0 0 1 1 1 1 1 1 0 0 0 0\n",
            " 1 0 1 0 1 0 0 0 1 0 1 0 1 0 1 0 0 1 0 1 0 0 0 0 1 1 1 1 1 1 1 1 0 1 1 0 1\n",
            " 0 1 0 1 0 0 1 1 1 1 0 0 1 0 1 0 1 0 1 1 0 0 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 0 1 1 1 1 0 0 0 1 1 0 1 1 1 0 1 1 0 1 0 1 0 0 1 1 1 1 0 1 1 0 1\n",
            " 0 1 1 1 0 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 0 0 0 1 1 0 1 0 0 1 0 0 0 1 1 0 1\n",
            " 1 0 0 1 1 1 1 0 0 1 0 1 1 1 1 1 0 1 0 1 1 0 0 0 0 0 1 1 1 1 1 1 0 1 0 0 0\n",
            " 1 1 1 1 0 1 0 0 1 0 0 0 1 0 0 0 0 1 1 0 1 0 0 0 1 1 1 0 1 0 0 0 1 1 1 0 1\n",
            " 1 1 1 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 1 1 0 1 1 0 0 0 0 1 1 0 1 0 1 1 0 1\n",
            " 1 0 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1 1 0 1 1 1 1 0 1 0 0\n",
            " 1 1 0 1 1 0 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 0 1 1 1 0 0 1 0 1 0 1 0 0 1 0 1\n",
            " 0 0 1 1 1 1 1 1 0 0 1 1 0 1 1 0 1 1 1 0 1 1 1 0 1 1 0 1 1 1 1 1 0 1 0 1 1\n",
            " 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 0 0 1 0 1 1 0 0 0 0 1 1 1 0 1\n",
            " 1 1 0 0 1 1 0 0 1 0 1 1 1 0 1 0 0 1 1 1 1 0 0 1 0 1 0 1 1 1 1 1 0 0 0 0 0\n",
            " 1 0 1 1 1 1 0 0 1 0 0 1 0 1 0 1 0 0 0 1 0 1 1 1 0 0 1 0 0 1 1 0 1 1 1 0 0\n",
            " 0 1 1 0 0 1 0 1 1 1 1 0 0 1 0 0 1 0 0 0 1 0 0 0 1 1 1 1 0 1 0 0 1 0 0 0 0\n",
            " 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0 1 0 0 1 1 1 1 1 0 1 0 0 0 0 0 0 1 1 1 1\n",
            " 0 0 0 0 0 1 0 1 0 1 0 1 0 1 1 0 0 1 0 1 1 0 1 0 1 1 1 0 0 1 0 1 1 1 1 1 0\n",
            " 1 1 1 0 0 1 0 1 0 1 1 1 0 1 1 1 0 0 1 1 1 0 0 1 1 1 1 1 0 1 1 0 1 1 1 0 0\n",
            " 0 1 0 1 1 1 0 0 0 1 0 1 0 1 0 1 0 1 1 1 1 1 1 0 0 1 0 1 1 0 1 1 0 1 0 0 0\n",
            " 1 1 0 1 1 1 1 0 0 0 0 1 0 1 0 0 1 1 1 0 0 1 1 0 1 1 1 0 0 0]\n",
            "probabilities: (992, 2) \n",
            " [1 0 1 1 0 1 1 1 0 0 1 0 0 0 0 1 1 1 1 0 1 0 1 0 0 0 1 0 0 1 0 1 1 1 0 1 1\n",
            " 1 1 0 0 1 1 0 0 0 1 1 0 1 1 0 0 0 1 1 1 1 1 0 1 1 1 1 1 0 1 0 0 1 1 0 0 1\n",
            " 1 1 1 1 1 1 0 1 0 0 1 0 1 1 0 0 0 0 1 0 0 1 1 1 1 0 1 0 0 0 1 1 1 0 0 1 0\n",
            " 0 1 0 1 0 1 1 1 1 0 1 0 0 1 0 0 1 0 0 1 1 1 1 0 1 1 0 0 1 1 0 0 1 1 1 0 1\n",
            " 1 1 1 1 0 1 0 1 1 0 0 0 1 1 0 1 1 1 0 0 1 0 0 0 0 1 0 1 1 0 1 1 1 1 0 0 1\n",
            " 0 1 1 0 1 1 1 0 0 0 1 0 0 1 1 1 0 0 0 0 0 0 1 0 0 1 0 0 1 1 0 1 1 0 1 1 0\n",
            " 0 1 1 1 0 0 0 0 0 0 1 1 0 1 1 1 1 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 1 0 1 1\n",
            " 0 1 1 1 0 1 1 0 1 0 1 1 1 1 1 1 1 0 0 0 1 1 0 1 0 0 0 1 1 1 1 1 1 0 0 0 0\n",
            " 1 0 1 0 1 0 0 0 1 0 1 0 1 0 1 0 0 1 0 1 0 0 0 0 1 1 1 1 1 1 1 1 0 1 1 0 1\n",
            " 0 1 0 1 0 0 1 1 1 1 0 0 1 0 1 0 1 0 1 1 0 0 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 0 1 1 1 1 0 0 0 1 1 0 1 1 1 0 1 1 0 1 0 1 0 0 1 1 1 1 0 1 1 0 1\n",
            " 0 1 1 1 0 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 0 0 0 1 1 0 1 0 0 1 0 0 0 1 1 0 1\n",
            " 1 0 0 1 1 1 1 0 0 1 0 1 1 1 1 1 0 1 0 1 1 0 0 0 0 0 1 1 1 1 1 1 0 1 0 0 0\n",
            " 1 1 1 1 0 1 0 0 1 0 0 0 1 0 0 0 0 1 1 0 1 0 0 0 1 1 1 0 1 0 0 0 1 1 1 0 1\n",
            " 1 1 1 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 1 1 0 1 1 0 0 0 0 1 1 0 1 0 1 1 0 1\n",
            " 1 0 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1 1 0 1 1 1 1 0 1 0 0\n",
            " 1 1 0 1 1 0 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 0 1 1 1 0 0 1 0 1 0 1 0 0 1 0 1\n",
            " 0 0 1 1 1 1 1 1 0 0 1 1 0 1 1 0 1 1 1 0 1 1 1 0 1 1 0 1 1 1 1 1 0 1 0 1 1\n",
            " 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 0 0 1 0 1 1 0 0 0 0 1 1 1 0 1\n",
            " 1 1 0 0 1 1 0 0 1 0 1 1 1 0 1 0 0 1 1 1 1 0 0 1 0 1 0 1 1 1 1 1 0 0 0 0 0\n",
            " 1 0 1 1 1 1 0 0 1 0 0 1 0 1 0 1 0 0 0 1 0 1 1 1 0 0 1 0 0 1 1 0 1 1 1 0 0\n",
            " 0 1 1 0 0 1 0 1 1 1 1 0 0 1 0 0 1 0 0 0 1 0 0 0 1 1 1 1 0 1 0 0 1 0 0 0 0\n",
            " 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0 1 0 0 1 1 1 1 1 0 1 0 0 0 0 0 0 1 1 1 1\n",
            " 0 0 0 0 0 1 0 1 0 1 0 1 0 1 1 0 0 1 0 1 1 0 1 0 1 1 1 0 0 1 0 1 1 1 1 1 0\n",
            " 1 1 1 0 0 1 0 1 0 1 1 1 0 1 1 1 0 0 1 1 1 0 0 1 1 1 1 1 0 1 1 0 1 1 1 0 0\n",
            " 0 1 0 1 1 1 0 0 0 1 0 1 0 1 0 1 0 1 1 1 1 1 1 0 0 1 0 1 1 0 1 1 0 1 0 0 0\n",
            " 1 1 0 1 1 1 1 0 0 0 0 1 0 1 0 0 1 1 1 0 0 1 1 0 1 1 1 0 0 0]\n",
            "std (992,) [50. 10. 10. 10.  0. 10. 50. 50. 10. 40. 30. 30.  0.  0. 40. 50. 10. 50.\n",
            " 40. 40. 50. 10. 30. 20. 20.  0. 20. 10. 30. 20. 10. 20. 50. 10. 10. 20.\n",
            " 50. 10. 40. 20. 30. 10. 40. 40. 50. 10. 20. 30. 30. 30. 50. 30. 50. 20.\n",
            " 40. 10. 10. 10. 50. 20. 20. 40. 40. 50. 10. 30. 40. 10. 20. 10. 20. 30.\n",
            " 30. 20. 30. 40. 30. 50. 20. 40. 10. 50. 30. 10. 30. 50. 40. 40. 20. 20.\n",
            " 20. 20. 40. 10. 30. 50. 40. 20. 20. 30. 30. 20. 30. 10. 30. 30. 40. 30.\n",
            " 50. 50. 30. 30. 40. 30. 30. 40. 30. 30. 20. 30. 20. 50. 20. 40. 40. 40.\n",
            " 30. 40. 30. 40. 40. 30. 10. 30. 40. 20. 10. 10. 40. 50. 20. 20. 30. 10.\n",
            " 30. 40. 30. 20. 40. 40. 40. 20. 30. 30. 30. 50. 50. 20. 10. 10. 50. 40.\n",
            " 40. 30. 50. 50. 10. 30. 50. 20. 40. 30. 10. 20. 40. 40. 50. 20. 50. 30.\n",
            " 40. 30. 30.  0. 30. 40. 40. 20. 40. 40. 30. 40. 30. 30. 20. 20. 30. 30.\n",
            " 10. 30. 30. 30. 40. 30. 10. 30. 20. 30. 30. 10. 40. 30. 30. 20. 30. 30.\n",
            " 20. 40. 50. 50. 30. 30. 30. 30. 30. 50.  0. 20. 20. 40. 20. 20. 30. 40.\n",
            " 30. 30. 40. 30. 40. 50. 30. 20. 30. 10. 40. 40. 20. 50. 20. 20. 30. 40.\n",
            " 40. 30. 30. 30. 50. 20. 30. 30. 30. 40. 10. 30. 40. 30. 20. 50. 50. 30.\n",
            " 40. 30. 20. 10. 20. 10.  0. 50. 20. 10. 30. 40. 30. 20. 20. 40. 10. 30.\n",
            " 30. 40. 50. 50. 40. 10. 30. 10. 20. 20. 50. 10. 40. 10. 40. 30. 30. 40.\n",
            " 40. 30. 20. 30. 20. 20. 30. 40. 20. 20. 10. 30. 30. 20. 40. 50. 50. 30.\n",
            " 20. 20. 40. 30. 10. 20. 30. 50. 40. 10. 50. 30. 50. 30. 40. 30. 30. 40.\n",
            " 20. 30. 40. 50. 40. 30. 10. 50. 30. 40. 20. 40. 40. 50. 40. 20. 30. 30.\n",
            " 50. 40. 30. 30. 40. 10. 40. 50. 40. 30. 40. 40. 50. 40. 20. 10. 20. 40.\n",
            " 30. 30. 30. 40. 30. 50. 20. 30. 20. 30. 20. 10. 40. 40. 10. 20. 20. 50.\n",
            " 40.  0. 40. 20. 40. 40. 40. 40. 40. 40. 50. 20. 10. 10. 40. 20. 40. 20.\n",
            " 40. 20. 40. 40. 20. 50. 30. 20. 40. 30. 40. 40. 50. 20. 10. 20. 30. 40.\n",
            " 40. 20. 10. 10. 50. 20. 10. 20. 20. 10. 20. 30. 10. 20.  0. 10. 30. 40.\n",
            " 40. 20. 20. 50. 20. 30. 20. 20. 30. 50. 40. 40. 40. 50. 50. 30. 40. 10.\n",
            " 10. 20. 50. 40. 30. 40. 20. 40.  0. 20. 30. 30. 50. 20. 40. 20. 20. 40.\n",
            " 50. 40. 10. 10. 20. 30. 10. 30. 20. 10. 30. 40. 50. 30. 30. 20. 40. 10.\n",
            " 10. 40. 30. 30. 30. 30. 30. 10. 20. 50. 40. 50. 30. 50. 40. 40. 50. 50.\n",
            " 10. 10. 30. 40. 50. 30. 40. 40. 30. 50. 30. 40. 20. 20. 30. 30. 40. 40.\n",
            " 50. 40. 30. 30. 20. 40. 40. 50. 30. 40. 30. 30. 50. 30. 40. 30. 20. 40.\n",
            " 40. 40. 20. 30. 40. 40. 10. 20. 50. 40. 30. 30. 20. 50. 40. 40. 30. 30.\n",
            " 30. 30. 30. 50. 30. 40. 40. 10. 30. 30. 50. 30. 10. 50. 40. 40. 10. 10.\n",
            " 20. 20. 40. 40. 40. 30. 10. 50. 40. 30. 50. 50. 20. 30. 40. 20. 10. 20.\n",
            " 50. 10. 50. 30. 10. 40. 20. 40. 30. 10. 20. 40. 30. 30. 50. 30. 30. 20.\n",
            "  0. 30. 40. 50. 20. 20. 30. 30. 20. 30. 20. 30. 30. 50. 30. 50. 30. 50.\n",
            " 20. 30. 50. 40. 40. 40. 20. 30. 50. 50. 30. 30. 30. 10. 40. 20. 20. 10.\n",
            " 20. 10. 20. 20. 40. 50. 30. 20. 30. 40. 50. 10. 20. 50. 40. 30. 30. 50.\n",
            " 20. 30. 10. 20. 10. 40. 40. 40. 30. 40. 10. 10. 10. 10. 40. 10. 20. 10.\n",
            " 30. 50. 40. 30. 20. 20. 30. 20. 40. 40. 30. 20. 50. 20. 10. 40. 20. 50.\n",
            " 40. 40. 20. 50. 20. 40. 50. 30. 30. 10. 10. 40. 30. 40. 40. 40. 20. 30.\n",
            " 10. 40. 40. 20. 30. 50. 30. 50. 40. 10. 30. 40. 40. 50. 10. 50. 30. 20.\n",
            " 30. 10. 50. 30. 30. 50. 40. 20. 30. 20. 40. 50. 30. 30. 10. 30. 30. 30.\n",
            " 40. 40. 40. 10. 40. 20. 40. 30. 30. 30. 50. 40. 40. 40. 10. 40. 40. 20.\n",
            " 20. 20. 20. 40. 50. 20. 10. 30. 10. 50. 40. 20. 30. 40. 20. 20. 40. 30.\n",
            " 40. 10. 40. 30. 20. 40. 50. 30. 20. 10. 20. 30. 40. 30. 10. 20. 10. 30.\n",
            " 40. 20. 30. 50. 20.  0. 30. 30. 50. 40. 50. 10. 30. 30. 20. 10. 30. 20.\n",
            " 10. 50. 40. 20. 20. 40. 40. 30. 20. 20. 40. 30. 30. 30. 40. 20. 40. 30.\n",
            " 50. 30. 40. 40. 30. 30. 30. 20. 10. 10. 10. 10. 40. 10. 40. 10. 30. 20.\n",
            " 40. 40. 30. 40. 20. 50. 30. 40. 50. 30. 30. 50. 10. 20. 20. 10. 30. 20.\n",
            " 20. 40. 40. 30. 20. 20. 20. 30. 40. 30. 10. 30. 40. 30. 10. 10. 30. 30.\n",
            " 40. 30. 40. 50. 50. 20. 10. 30. 30. 40. 50. 40. 50. 30. 40. 30. 20. 30.\n",
            " 30. 20. 20. 20. 50. 50. 30. 30. 30. 40. 50. 40. 10. 10. 30. 30. 50. 20.\n",
            " 30. 20. 30. 20. 30. 30. 20. 30. 50. 20. 20. 40. 30. 50. 10. 20.  0. 30.\n",
            " 10. 40.  0. 40. 20. 10. 20. 20. 20. 30. 40. 40. 10. 30. 40. 50. 30. 30.\n",
            " 20. 40.]\n",
            "selection [ 25 397 476 974  13  12 833 446 226 183] (10,) [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "trainset before adding uncertain samples (310, 10) (310,)\n",
            "trainset after adding uncertain samples (320, 10) (320,)\n",
            "updated train set: (320, 10) (320,) unique(labels): [166 154] [0 1]\n",
            "val set: (982, 10) (982,)\n",
            "\n",
            "Train set: (320, 10)\n",
            "Validation set: (982, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 32\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.071 s \n",
            "\n",
            "Accuracy rate is 80.645161 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.91      0.87       321\n",
            "           1       0.67      0.51      0.58       113\n",
            "\n",
            "    accuracy                           0.81       434\n",
            "   macro avg       0.75      0.71      0.73       434\n",
            "weighted avg       0.80      0.81      0.80       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[292  29]\n",
            " [ 55  58]]\n",
            "--------------------------------\n",
            "val predicted: (982,) [1 0 1 1 1 1 1 1 0 0 1 0 0 1 1 1 1 0 1 0 1 0 0 1 0 0 1 0 1 1 1 0 1 1 1 1 0\n",
            " 0 1 1 0 0 0 1 1 0 0 1 0 0 0 1 1 1 1 1 0 1 1 1 1 1 0 1 0 0 1 1 0 0 1 1 1 1\n",
            " 1 1 1 0 1 0 0 1 0 1 1 0 0 0 0 1 0 0 1 1 1 1 0 1 0 0 0 1 1 1 0 0 1 0 0 1 0\n",
            " 1 0 1 1 1 1 0 1 0 0 1 0 0 1 0 0 1 1 1 1 0 1 1 0 0 1 1 0 0 1 1 1 0 1 1 1 1\n",
            " 1 0 1 0 1 1 0 0 0 1 1 0 1 1 1 0 0 1 0 0 0 0 1 0 1 1 0 1 1 1 1 0 1 0 1 1 0\n",
            " 1 1 1 0 0 0 1 0 0 1 1 1 0 0 0 0 0 0 1 0 0 1 0 0 1 1 0 1 1 0 1 1 0 0 1 1 1\n",
            " 0 0 0 0 0 1 1 0 1 1 1 1 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 1 0 1 1 0 1 1 1 0\n",
            " 1 1 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 0 1 0 0 0 1 1 1 1 1 1 0 0 0 0 1 0 1 0 1\n",
            " 0 0 0 1 0 1 0 1 0 1 0 0 1 0 1 0 0 0 0 1 1 1 1 1 1 1 1 0 1 1 0 1 0 1 0 1 0\n",
            " 0 1 1 1 1 0 0 1 0 1 0 1 0 1 1 0 0 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 0 1 1 1 1 0 0 0 1 1 0 1 1 1 0 1 1 0 1 0 1 0 1 1 1 1 0 1 1 0 1 0 1 1 1 0 1\n",
            " 1 1 0 1 1 0 1 1 0 1 1 1 1 1 0 0 0 1 1 0 1 0 0 1 0 0 0 1 1 0 1 1 0 1 1 1 1\n",
            " 0 0 1 0 1 1 1 1 1 0 1 0 1 1 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 1 1 1 1 0 1 0 0\n",
            " 1 0 0 0 1 0 0 0 0 1 1 0 1 0 0 0 1 1 1 0 1 0 0 0 1 1 1 0 1 1 1 1 1 1 1 1 1\n",
            " 0 0 1 1 0 1 0 1 1 1 1 1 1 0 1 1 0 0 0 0 1 1 0 1 0 1 1 0 1 1 0 1 0 1 1 1 1\n",
            " 1 0 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1 1 0 1 1 1 1 0 1 0 0 1 1 0 1 1 0 1 0\n",
            " 1 1 0 1 1 1 0 1 1 1 1 0 1 0 1 1 1 0 0 1 0 1 0 1 0 0 1 0 1 0 1 1 1 1 1 1 1\n",
            " 0 0 1 1 0 1 1 0 1 1 1 0 1 1 1 0 1 1 0 1 1 1 1 1 0 1 0 1 1 1 0 1 1 1 1 0 1\n",
            " 1 1 1 0 1 1 1 1 1 1 1 1 1 0 0 0 1 0 1 1 0 0 0 0 1 1 1 0 1 1 1 0 0 1 1 0 0\n",
            " 1 0 1 1 1 0 1 0 0 1 1 1 1 0 0 1 0 1 0 1 1 1 1 1 0 0 0 0 0 1 0 1 1 1 1 0 0\n",
            " 1 0 0 1 0 1 0 1 0 0 0 1 0 1 1 1 0 0 1 0 0 1 1 0 1 1 1 0 0 0 1 1 0 0 1 0 1\n",
            " 1 1 1 0 0 1 0 0 1 0 0 0 1 0 0 0 1 1 1 1 0 1 0 0 1 0 0 0 0 0 1 1 1 1 1 1 1\n",
            " 1 1 1 1 0 0 1 0 0 1 0 1 1 1 1 1 0 1 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 1 0 1 0\n",
            " 1 0 1 0 1 1 0 0 1 0 1 1 0 1 0 1 1 1 0 0 1 0 1 1 1 1 1 0 1 1 1 0 0 1 0 1 0\n",
            " 1 1 1 0 1 1 1 0 0 1 1 1 0 0 1 1 1 1 0 0 1 1 0 1 1 1 0 0 0 1 0 1 1 1 0 0 0\n",
            " 1 0 1 0 1 0 1 0 1 1 1 1 1 1 0 0 1 0 1 1 0 1 1 0 1 0 0 0 1 1 0 1 1 1 1 0 0\n",
            " 0 0 1 1 0 0 1 1 1 0 0 1 1 0 1 1 1 0 0 0]\n",
            "probabilities: (982, 2) \n",
            " [1 0 1 1 1 1 1 1 0 0 1 0 0 1 1 1 1 0 1 0 1 0 0 1 0 0 1 0 1 1 1 0 1 1 1 1 0\n",
            " 0 1 1 0 0 0 1 1 0 0 1 0 0 0 1 1 1 1 1 0 1 1 1 1 1 0 1 0 0 1 1 0 0 1 1 1 1\n",
            " 1 1 1 0 1 0 0 1 0 1 1 0 0 0 0 1 0 0 1 1 1 1 0 1 0 0 0 1 1 1 0 0 1 0 0 1 0\n",
            " 1 0 1 1 1 1 0 1 0 0 1 0 0 1 0 0 1 1 1 1 0 1 1 0 0 1 1 0 0 1 1 1 0 1 1 1 1\n",
            " 1 0 1 0 1 1 0 0 0 1 1 0 1 1 1 0 0 1 0 0 0 0 1 0 1 1 0 1 1 1 1 0 1 0 1 1 0\n",
            " 1 1 1 0 0 0 1 0 0 1 1 1 0 0 0 0 0 0 1 0 0 1 0 0 1 1 0 1 1 0 1 1 0 0 1 1 1\n",
            " 0 0 0 0 0 1 1 0 1 1 1 1 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 1 0 1 1 0 1 1 1 0\n",
            " 1 1 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 0 1 0 0 0 1 1 1 1 1 1 0 0 0 0 1 0 1 0 1\n",
            " 0 0 0 1 0 1 0 1 0 1 0 0 1 0 1 0 0 0 0 1 1 1 1 1 1 1 1 0 1 1 0 1 0 1 0 1 0\n",
            " 0 1 1 1 1 0 0 1 0 1 0 1 0 1 1 0 0 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 0 1 1 1 1 0 0 0 1 1 0 1 1 1 0 1 1 0 1 0 1 0 1 1 1 1 0 1 1 0 1 0 1 1 1 0 1\n",
            " 1 1 0 1 1 0 1 1 0 1 1 1 1 1 0 0 0 1 1 0 1 0 0 1 0 0 0 1 1 0 1 1 0 1 1 1 1\n",
            " 0 0 1 0 1 1 1 1 1 0 1 0 1 1 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 1 1 1 1 0 1 0 0\n",
            " 1 0 0 0 1 0 0 0 0 1 1 0 1 0 0 0 1 1 1 0 1 0 0 0 1 1 1 0 1 1 1 1 1 1 1 1 1\n",
            " 0 0 1 1 0 1 0 1 1 1 1 1 1 0 1 1 0 0 0 0 1 1 0 1 0 1 1 0 1 1 0 1 0 1 1 1 1\n",
            " 1 0 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1 1 0 1 1 1 1 0 1 0 0 1 1 0 1 1 0 1 0\n",
            " 1 1 0 1 1 1 0 1 1 1 1 0 1 0 1 1 1 0 0 1 0 1 0 1 0 0 1 0 1 0 1 1 1 1 1 1 1\n",
            " 0 0 1 1 0 1 1 0 1 1 1 0 1 1 1 0 1 1 0 1 1 1 1 1 0 1 0 1 1 1 0 1 1 1 1 0 1\n",
            " 1 1 1 0 1 1 1 1 1 1 1 1 1 0 0 0 1 0 1 1 0 0 0 0 1 1 1 0 1 1 1 0 0 1 1 0 0\n",
            " 1 0 1 1 1 0 1 0 0 1 1 1 1 0 0 1 0 1 0 1 1 1 1 1 0 0 0 0 0 1 0 1 1 1 1 0 0\n",
            " 1 0 0 1 0 1 0 1 0 0 0 1 0 1 1 1 0 0 1 0 0 1 1 0 1 1 1 0 0 0 1 1 0 0 1 0 1\n",
            " 1 1 1 0 0 1 0 0 1 0 0 0 1 0 0 0 1 1 1 1 0 1 0 0 1 0 0 0 0 0 1 1 1 1 1 1 1\n",
            " 1 1 1 1 0 0 1 0 0 1 0 1 1 1 1 1 0 1 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 1 0 1 0\n",
            " 1 0 1 0 1 1 0 0 1 0 1 1 0 1 0 1 1 1 0 0 1 0 1 1 1 1 1 0 1 1 1 0 0 1 0 1 0\n",
            " 1 1 1 0 1 1 1 0 0 1 1 1 0 0 1 1 1 1 0 0 1 1 0 1 1 1 0 0 0 1 0 1 1 1 0 0 0\n",
            " 1 0 1 0 1 0 1 0 1 1 1 1 1 1 0 0 1 0 1 1 0 1 1 0 1 0 0 0 1 1 0 1 1 1 1 0 0\n",
            " 0 0 1 1 0 0 1 1 1 0 0 1 1 0 1 1 1 0 0 0]\n",
            "std (982,) [50. 10. 10. 10. 10. 10. 50. 50. 10. 40. 20. 30. 30. 50. 10. 50. 40. 40.\n",
            " 50. 10. 30. 20. 20. 20. 10. 20. 20. 10. 20. 40. 10. 10. 20. 50. 10. 40.\n",
            " 10. 30. 10. 40. 40. 50. 10. 10. 30. 30.  0. 50. 40. 50. 20. 40. 10. 10.\n",
            " 10. 50. 10. 20. 30. 40. 50. 10. 30. 40. 10. 20. 10. 20. 30. 30. 10. 20.\n",
            " 40. 30. 50. 20. 40. 10. 50. 30. 10. 30. 40. 40. 40. 30. 20. 20. 20. 30.\n",
            " 20. 30. 50. 40. 30. 20. 30. 40. 20. 20. 10. 20. 30. 30. 30. 50. 50. 30.\n",
            " 30. 40. 30. 30. 50. 30. 30. 20. 30. 20. 50. 30. 40. 40. 40. 40. 40. 30.\n",
            " 30. 40. 20. 10. 30. 40. 20. 10. 10. 40. 50. 20. 20. 30. 10. 40. 30. 30.\n",
            " 20. 40. 40. 40. 20. 30. 10. 30. 50. 50. 20. 10. 10. 50. 40. 40. 30. 50.\n",
            " 50.  0. 30. 50. 20. 40. 30. 10. 20. 40. 40. 50. 20. 50. 30. 40. 30. 40.\n",
            " 30. 40. 40. 20. 40. 40. 30. 40. 20. 30. 30. 10. 30. 30. 20. 30. 30. 30.\n",
            " 40. 30. 10. 30. 30. 30. 30. 10. 40. 30. 30. 20. 30. 30. 20. 40. 40. 50.\n",
            " 30. 30. 30. 30. 20. 50. 20. 20. 30. 30. 20. 30. 40. 30. 30. 40. 30. 30.\n",
            " 50. 30. 20. 30. 10. 40. 40. 20. 50. 10. 20. 30. 50. 40. 30. 30. 30. 50.\n",
            " 20. 30. 30. 30. 40. 10. 30. 40. 30. 20. 50. 30. 30. 30. 40. 20. 20. 20.\n",
            " 10. 10. 40. 20. 10. 30. 40. 30. 20. 10. 30. 10. 20. 30. 40. 50. 50. 40.\n",
            " 10. 30. 10. 10. 20. 50. 10. 40.  0. 40. 30. 20. 30. 40. 30. 20. 30. 20.\n",
            " 20. 30. 40. 20. 20. 20. 30. 30. 20. 40. 40. 50. 40. 20. 20. 40. 30. 10.\n",
            " 20. 30. 40. 40. 20. 50. 30. 50. 20. 30. 20. 30. 40. 10. 30. 50. 50. 40.\n",
            " 30. 10. 50. 40. 40. 20. 40. 50. 50. 50. 20. 30. 30. 50. 40. 30. 30. 40.\n",
            " 10. 40. 50. 30. 30. 40. 40. 50. 40. 20. 10. 20. 40. 30. 30. 30. 30. 30.\n",
            " 50. 20. 30. 10. 20. 20. 10. 40. 40. 10. 10. 20. 50. 40. 40. 20. 40. 40.\n",
            " 40. 40. 40. 40. 50. 20. 10. 10. 40. 20. 40. 30. 40. 20. 30. 40. 20. 50.\n",
            " 30. 20. 40. 30. 40. 30. 50. 20. 20. 20. 30. 40. 40. 20. 10. 10. 50. 20.\n",
            " 10. 20. 20. 10. 20. 30. 10. 10. 10. 30. 30. 30. 20. 20. 50. 30. 30. 20.\n",
            " 20. 20. 40. 40. 40. 40. 50. 50. 30. 40. 20. 10. 20. 50. 40. 30. 40. 20.\n",
            " 40. 20. 40. 30. 50. 20. 40. 20. 20. 40. 50. 40. 20. 10. 20. 20. 10. 30.\n",
            " 30. 10. 30. 40. 50. 30. 30. 20. 30. 10.  0. 40. 20. 30. 30. 30. 40. 10.\n",
            " 20. 50. 40. 50. 30. 40. 40. 40. 50. 50. 10. 10. 20. 40. 50. 30. 40. 20.\n",
            " 30. 50. 30. 40. 20. 20. 30. 30. 40. 30. 50. 40. 30. 20. 20. 40. 40. 50.\n",
            " 20. 40. 30. 30. 50. 30. 40. 30. 20. 40. 40. 40. 20. 30. 40. 40. 10. 20.\n",
            " 50. 40. 40. 30. 10. 50. 30. 40. 20. 30. 40. 30. 30. 50. 30. 40. 50. 20.\n",
            " 30. 20. 50. 20. 10. 50. 40. 40. 10. 10. 20. 20. 40. 40. 40. 30. 20. 50.\n",
            " 50. 30. 50. 50. 20. 30. 40. 20. 10. 20. 50. 10. 50. 40. 20. 40. 20. 40.\n",
            " 30. 10. 20. 40. 30. 30. 50. 30. 30. 20. 10. 30. 30. 50. 20. 20. 20. 30.\n",
            " 20. 30. 20. 30. 30. 50. 30. 50. 30. 50. 20. 30. 50. 40. 30. 50. 10. 30.\n",
            " 50. 50. 30. 30. 30. 20. 40. 20. 20. 10. 10.  0. 20. 30. 40. 50. 30. 30.\n",
            " 30. 40. 50. 10. 20. 50. 40. 40. 30. 50. 20. 30. 10. 20. 10. 40. 40. 40.\n",
            " 30. 40. 10. 10. 10. 10. 40. 10. 20. 10. 30. 50. 40. 20. 20. 20. 30. 30.\n",
            " 40. 40. 30. 20. 50. 20. 10. 40. 20. 50. 40. 40. 20. 50. 20. 40. 50. 30.\n",
            " 20. 10. 10. 30. 30. 40. 40. 40. 20. 30. 10. 40. 40. 30. 20. 50. 30. 50.\n",
            " 30. 10. 20. 40. 40. 50. 10. 50. 30. 20. 30. 10. 50. 30. 30. 50. 40. 20.\n",
            " 30. 20. 40. 50. 20. 30. 10. 30. 30. 20. 40. 40. 40. 10. 40. 20. 40. 30.\n",
            " 30. 20. 40. 40. 40. 40. 10. 40. 40. 20. 10. 20. 20. 40. 50. 20. 10. 30.\n",
            " 10. 50. 40. 20. 30. 40. 20. 20. 40. 30. 40. 10. 30. 30. 20. 40. 50. 30.\n",
            " 20. 10. 20. 30. 40. 30. 20. 10. 10. 20. 50. 20. 30. 50. 10. 30. 30. 50.\n",
            " 40. 30. 10. 30. 30. 20. 10. 30. 20. 10. 50. 30. 20. 30. 40. 40. 40. 20.\n",
            " 20. 40. 20. 30. 30. 40. 20. 40. 30. 50. 30. 40. 40. 20. 30. 30. 20. 10.\n",
            " 10. 10. 20. 40. 10. 40. 10. 30. 30. 40. 40. 30. 30. 10. 40. 30. 40. 50.\n",
            " 30. 30. 50. 10. 20. 20. 10. 30. 20. 20. 40. 40. 20. 20. 20. 20. 30. 40.\n",
            " 30. 20. 30. 40. 30. 10.  0. 20. 40. 40. 30. 40. 50. 50. 20. 10. 30. 20.\n",
            " 40. 50. 50. 50. 30. 40. 20. 20. 30. 30. 20. 20. 20. 50. 50. 30. 30. 30.\n",
            " 40. 50. 40. 10. 10. 20. 20. 50. 10. 30. 20. 30. 20. 20. 30. 20. 20. 50.\n",
            " 20. 20. 40. 40. 50. 10. 20.  0. 40. 10. 40. 30. 10. 10. 20. 20. 20. 30.\n",
            " 40. 40. 10. 30. 40. 50. 30. 30. 20. 40.]\n",
            "selection [496 961 906 163 659  46 296 939 343 360] (10,) [ 0.  0.  0.  0.  0.  0.  0. 10. 10. 10.]\n",
            "trainset before adding uncertain samples (320, 10) (320,)\n",
            "trainset after adding uncertain samples (330, 10) (330,)\n",
            "updated train set: (330, 10) (330,) unique(labels): [171 159] [0 1]\n",
            "val set: (972, 10) (972,)\n",
            "\n",
            "Train set: (330, 10)\n",
            "Validation set: (972, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 33\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.069 s \n",
            "\n",
            "Accuracy rate is 80.414747 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.90      0.87       321\n",
            "           1       0.65      0.54      0.59       113\n",
            "\n",
            "    accuracy                           0.80       434\n",
            "   macro avg       0.75      0.72      0.73       434\n",
            "weighted avg       0.80      0.80      0.80       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[288  33]\n",
            " [ 52  61]]\n",
            "--------------------------------\n",
            "val predicted: (972,) [1 0 1 1 0 1 1 1 0 0 1 0 0 1 1 1 1 0 1 0 1 0 0 1 0 0 1 0 1 1 1 0 1 1 0 1 0\n",
            " 0 1 1 0 0 0 1 1 0 1 0 0 0 1 1 1 1 1 0 1 1 1 1 1 0 1 0 0 1 1 0 0 1 1 1 1 1\n",
            " 1 1 0 1 0 0 1 0 1 1 0 0 0 0 1 0 0 1 1 1 1 0 1 0 0 0 1 1 1 0 0 1 0 0 1 0 1\n",
            " 0 1 1 1 1 0 1 0 0 1 0 0 1 0 0 1 1 1 1 0 1 1 0 0 1 1 0 0 1 1 1 0 1 1 1 1 1\n",
            " 0 1 0 1 1 0 0 0 1 1 0 1 1 1 0 1 0 0 0 0 1 0 1 1 0 1 1 1 1 0 1 0 1 1 0 1 1\n",
            " 1 0 0 0 1 0 0 1 1 1 0 0 0 0 0 0 1 0 0 1 0 0 1 1 0 1 1 0 1 1 0 0 1 1 1 0 0\n",
            " 0 0 0 1 1 0 1 1 1 1 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 1 0 1 1 0 1 1 1 0 1 1\n",
            " 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 0 1 0 0 0 1 1 1 1 1 1 0 0 0 0 1 0 1 0 1 0 0\n",
            " 1 0 1 0 1 0 1 0 0 1 0 1 0 0 0 0 1 1 1 1 1 1 1 1 0 1 1 0 1 0 1 0 1 0 0 1 1\n",
            " 1 1 0 0 1 0 1 1 0 1 1 0 0 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1\n",
            " 0 0 0 1 1 0 1 1 1 0 1 1 0 1 0 1 0 1 1 1 1 0 1 1 0 1 0 1 1 1 0 1 1 1 0 1 1\n",
            " 0 1 1 0 1 1 1 1 1 0 0 0 1 1 0 1 0 0 1 0 0 0 1 1 0 1 0 0 1 1 1 1 0 0 1 0 1\n",
            " 1 1 1 1 0 1 0 1 1 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 1 1 1 1 0 1 0 0 1 0 0 0 1\n",
            " 0 0 0 0 1 1 0 1 0 0 1 1 1 0 1 0 0 0 1 1 1 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1\n",
            " 0 1 1 1 1 1 1 0 1 1 0 0 0 0 1 1 0 1 0 1 1 0 1 1 0 1 0 1 1 1 1 1 0 1 1 1 1\n",
            " 1 1 1 1 1 1 0 0 1 0 1 1 1 1 0 1 1 1 1 0 1 0 0 1 1 0 1 1 0 1 0 1 1 0 1 1 1\n",
            " 0 1 1 1 1 0 1 0 1 1 1 0 0 1 0 1 0 1 0 0 1 0 1 0 1 1 1 1 1 1 1 0 0 1 1 0 1\n",
            " 1 0 1 1 1 0 1 1 1 0 1 1 0 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1\n",
            " 1 1 1 1 1 1 0 0 0 1 0 1 1 0 0 0 0 1 1 1 0 1 1 1 0 0 1 1 0 0 1 0 1 1 1 0 1\n",
            " 0 0 1 1 1 1 0 0 1 0 1 0 1 1 1 1 1 0 0 0 0 0 1 0 1 1 1 1 0 0 1 0 0 1 0 1 0\n",
            " 1 0 0 0 1 0 1 1 1 0 0 1 0 0 1 0 0 1 1 1 0 0 0 1 1 0 0 1 0 1 1 1 1 0 0 1 0\n",
            " 0 1 0 0 0 1 0 0 0 1 1 1 1 0 1 0 0 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1\n",
            " 0 0 1 0 1 1 1 1 1 0 1 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 1 0 1 0 1 0 1 0 1 1 0\n",
            " 0 1 0 1 1 0 0 0 1 1 1 0 0 1 0 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 1 1 1 0 1 1 1\n",
            " 0 0 1 1 1 0 0 1 1 1 1 0 1 1 0 1 1 1 0 0 0 1 0 1 1 1 0 0 0 1 0 1 0 1 0 1 0\n",
            " 1 1 1 1 1 1 0 1 0 1 0 0 1 1 0 1 0 0 0 1 1 0 1 1 1 1 0 0 0 1 1 0 0 1 1 1 0\n",
            " 0 1 1 0 1 1 1 0 0 0]\n",
            "probabilities: (972, 2) \n",
            " [1 0 1 1 0 1 1 1 0 0 1 0 0 1 1 1 1 0 1 0 1 0 0 1 0 0 1 0 1 1 1 0 1 1 0 1 0\n",
            " 0 1 1 0 0 0 1 1 0 1 0 0 0 1 1 1 1 1 0 1 1 1 1 1 0 1 0 0 1 1 0 0 1 1 1 1 1\n",
            " 1 1 0 1 0 0 1 0 1 1 0 0 0 0 1 0 0 1 1 1 1 0 1 0 0 0 1 1 1 0 0 1 0 0 1 0 1\n",
            " 0 1 1 1 1 0 1 0 0 1 0 0 1 0 0 1 1 1 1 0 1 1 0 0 1 1 0 0 1 1 1 0 1 1 1 1 1\n",
            " 0 1 0 1 1 0 0 0 1 1 0 1 1 1 0 1 0 0 0 0 1 0 1 1 0 1 1 1 1 0 1 0 1 1 0 1 1\n",
            " 1 0 0 0 1 0 0 1 1 1 0 0 0 0 0 0 1 0 0 1 0 0 1 1 0 1 1 0 1 1 0 0 1 1 1 0 0\n",
            " 0 0 0 1 1 0 1 1 1 1 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 1 0 1 1 0 1 1 1 0 1 1\n",
            " 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 0 1 0 0 0 1 1 1 1 1 1 0 0 0 0 1 0 1 0 1 0 0\n",
            " 1 0 1 0 1 0 1 0 0 1 0 1 0 0 0 0 1 1 1 1 1 1 1 1 0 1 1 0 1 0 1 0 1 0 0 1 1\n",
            " 1 1 0 0 1 0 1 1 0 1 1 0 0 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1\n",
            " 0 0 0 1 1 0 1 1 1 0 1 1 0 1 0 1 0 1 1 1 1 0 1 1 0 1 0 1 1 1 0 1 1 1 0 1 1\n",
            " 0 1 1 0 1 1 1 1 1 0 0 0 1 1 0 1 0 0 1 0 0 0 1 1 0 1 0 0 1 1 1 1 0 0 1 0 1\n",
            " 1 1 1 1 0 1 0 1 1 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 1 1 1 1 0 1 0 0 1 0 0 0 1\n",
            " 0 0 0 0 1 1 0 1 0 0 1 1 1 0 1 0 0 0 1 1 1 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1\n",
            " 0 1 1 1 1 1 1 0 1 1 0 0 0 0 1 1 0 1 0 1 1 0 1 1 0 1 0 1 1 1 1 1 0 1 1 1 1\n",
            " 1 1 1 1 1 1 0 0 1 0 1 1 1 1 0 1 1 1 1 0 1 0 0 1 1 0 1 1 0 1 0 1 1 0 1 1 1\n",
            " 0 1 1 1 1 0 1 0 1 1 1 0 0 1 0 1 0 1 0 0 1 0 1 0 1 1 1 1 1 1 1 0 0 1 1 0 1\n",
            " 1 0 1 1 1 0 1 1 1 0 1 1 0 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1\n",
            " 1 1 1 1 1 1 0 0 0 1 0 1 1 0 0 0 0 1 1 1 0 1 1 1 0 0 1 1 0 0 1 0 1 1 1 0 1\n",
            " 0 0 1 1 1 1 0 0 1 0 1 0 1 1 1 1 1 0 0 0 0 0 1 0 1 1 1 1 0 0 1 0 0 1 0 1 0\n",
            " 1 0 0 0 1 0 1 1 1 0 0 1 0 0 1 0 0 1 1 1 0 0 0 1 1 0 0 1 0 1 1 1 1 0 0 1 0\n",
            " 0 1 0 0 0 1 0 0 0 1 1 1 1 0 1 0 0 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1\n",
            " 0 0 1 0 1 1 1 1 1 0 1 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 1 0 1 0 1 0 1 0 1 1 0\n",
            " 0 1 0 1 1 0 0 0 1 1 1 0 0 1 0 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 1 1 1 0 1 1 1\n",
            " 0 0 1 1 1 0 0 1 1 1 1 0 1 1 0 1 1 1 0 0 0 1 0 1 1 1 0 0 0 1 0 1 0 1 0 1 0\n",
            " 1 1 1 1 1 1 0 1 0 1 0 0 1 1 0 1 0 0 0 1 1 0 1 1 1 1 0 0 0 1 1 0 0 1 1 1 0\n",
            " 0 1 1 0 1 1 1 0 0 0]\n",
            "std (972,) [50. 10. 10. 10. 10. 10. 50. 50. 20. 40. 20. 30. 30. 50. 10. 40. 40. 30.\n",
            " 40. 20. 30. 20. 20. 20. 10. 20. 20. 20. 20. 50. 10. 20. 20. 30.  0. 30.\n",
            " 10. 40. 20. 40. 40. 50. 10. 10. 30. 30. 40. 40. 50. 20. 40. 20. 10. 10.\n",
            " 50. 10. 20. 20. 30. 50. 10. 30. 40. 20. 20. 10. 20. 30. 20. 20. 20. 40.\n",
            " 30. 50. 20. 40. 10. 50. 30. 10. 30. 50. 30. 40. 30. 20. 20. 30. 20. 20.\n",
            " 30. 40. 40. 30. 30. 30. 30. 20. 20. 20. 30. 30. 30. 30. 50. 50. 40. 30.\n",
            " 50. 30. 30. 40. 30. 30. 20. 30. 20. 50. 30. 40. 40. 40. 30. 40. 30. 30.\n",
            " 50. 20. 10. 40. 30. 20. 10. 10. 40. 50. 20. 10. 30. 10. 20. 30. 30. 30.\n",
            " 40. 30. 40. 30. 20. 10. 30. 50. 50. 20. 20. 20. 50. 30. 40. 30. 50. 50.\n",
            " 20. 50. 20. 40. 20. 10. 20. 30. 40. 40. 20. 50. 30. 40. 20. 40. 20. 40.\n",
            " 50. 20. 40. 40. 30. 40. 30. 20. 20. 20. 20. 40. 20. 30. 30. 30. 40. 30.\n",
            " 20. 30. 20. 30. 30. 20. 40. 30. 30. 20. 30. 30. 30. 40. 50. 50. 30. 30.\n",
            " 30. 30. 20. 40. 20. 20. 30. 30. 20. 40. 40. 20. 30. 40. 30. 30. 40. 30.\n",
            " 20. 40. 10. 40. 30. 30. 50. 10. 20. 30. 40. 40. 30. 30. 30. 50. 20. 30.\n",
            " 30. 30. 40. 10. 30. 40. 40. 10. 50. 40. 40. 30. 30. 20. 10. 30. 10. 10.\n",
            " 50. 20. 20. 40. 40. 40. 20. 10. 30. 10. 30. 30. 40. 40. 50. 40. 20. 30.\n",
            " 20. 10. 10. 50. 20. 40. 40. 20. 20. 30. 40. 40. 10. 30. 20. 20. 30. 40.\n",
            " 20. 10. 20. 30. 30. 20. 30. 40. 50. 40. 40. 20. 40. 30. 20. 20. 40. 50.\n",
            " 40. 20. 50. 30. 50. 30. 40. 20. 30. 40. 10. 30. 40. 50. 40. 20. 50. 30.\n",
            " 40. 20. 40. 50. 40. 20. 10. 30. 30. 50. 40. 30. 30. 50. 40. 50. 20. 30.\n",
            " 40. 30. 50. 40. 30. 10. 30. 50. 30. 30. 40. 30. 30. 40. 10. 30. 10. 30.\n",
            " 20. 10. 40. 40. 20. 10. 20. 50. 40. 40. 20. 40. 40. 40. 40. 40. 40. 50.\n",
            " 10. 10. 10. 40. 20. 30. 10. 50. 20. 30. 40. 10. 50. 40. 20. 40. 30. 40.\n",
            " 30. 50. 20. 10. 20. 30. 40. 30. 30. 10. 20. 50. 10. 10. 20. 10. 10. 20.\n",
            " 30.  0. 10. 10. 30. 30. 40. 20. 30. 50. 30. 30. 20. 20. 30. 30. 40. 40.\n",
            " 40. 50. 50. 30. 40. 10. 10. 20. 40. 40. 30. 40. 20. 40. 20. 30. 30. 50.\n",
            " 20. 40. 20. 20. 40. 50. 50. 20. 10. 20. 20. 10. 30. 10. 20. 30. 30. 40.\n",
            " 30. 40. 20. 40. 20. 40. 20. 20. 20. 30. 30. 10. 20. 50. 40. 50. 30. 40.\n",
            " 40. 40. 50. 50. 20.  0. 20. 40. 50. 30. 40. 20. 30. 50. 40. 40. 30. 20.\n",
            " 30. 40. 40. 30. 40. 40. 30. 20. 20. 30. 40. 50. 30. 40. 40. 30. 50. 40.\n",
            " 40. 30. 20. 40. 40. 40. 20. 30. 40. 40. 10. 30. 40. 40. 30. 30. 20. 50.\n",
            " 30. 40. 30. 30. 40. 30. 30. 50. 30. 40. 50. 20. 30. 20. 50. 20. 10. 50.\n",
            " 40. 30. 10. 10. 20. 20. 40. 40. 40. 30. 20. 40. 30. 30. 50. 50. 20. 30.\n",
            " 40. 20. 10. 20. 50. 10. 50. 30. 20. 40. 20. 30. 40. 10. 20. 40. 30. 30.\n",
            " 50. 30. 10. 20. 10. 30. 30. 50. 20. 30. 30. 30. 30. 30. 20. 20. 40. 50.\n",
            " 20. 50. 30. 50. 20. 30. 50. 50. 40. 40. 20. 30. 50. 50. 40. 30. 30.  0.\n",
            " 50. 20. 20. 20. 10. 20. 20. 40. 40. 30. 30. 40. 30. 50.  0. 20. 40. 40.\n",
            " 40. 20. 50. 30. 40. 10. 20. 20. 40. 40. 40. 30. 40. 20. 10. 20. 20. 40.\n",
            " 10. 20. 10. 30. 50. 40. 20. 20. 20. 30. 20. 40. 40. 30. 20. 50. 30.  0.\n",
            " 40. 20. 50. 30. 40. 10. 50. 20. 40. 50. 30. 30. 10. 10. 30. 30. 50. 40.\n",
            " 40. 20. 30. 10. 40. 40. 20. 20. 50. 30. 50. 30. 10. 20. 30. 30. 50. 20.\n",
            " 40. 30. 20. 30. 20. 50. 30. 30. 50. 40. 20. 30. 20. 40. 50. 30. 30.  0.\n",
            " 30. 30. 20. 40. 40. 30. 20. 50. 30. 40. 30. 30. 20. 40. 40. 40. 30. 20.\n",
            " 50. 40. 20. 10. 10. 10. 40. 50. 20. 10. 30. 10. 50. 40. 30. 30. 40. 20.\n",
            " 30. 40. 30. 40. 20. 40. 30. 10. 40. 50. 30. 20. 10. 20. 30. 30. 30. 20.\n",
            " 10. 10. 20. 40. 20. 30. 50. 10. 30. 30. 50. 40. 30. 20. 20. 20. 20. 20.\n",
            " 30. 20. 10. 50. 30. 30. 20. 40. 40. 30. 10. 10. 40. 30. 30. 30. 40. 20.\n",
            " 40. 30. 50. 30. 40. 30. 20. 30. 30. 20.  0.  0. 20. 20. 50. 10. 40. 20.\n",
            " 30. 30. 40. 40. 30. 30.  0. 40. 40. 40. 50. 30. 30. 50. 10. 10. 20. 10.\n",
            " 10. 20. 20. 40. 40. 20. 10. 20. 20. 30. 40. 30. 20. 30. 40. 30. 20. 20.\n",
            " 40. 40. 30. 40. 50. 50. 20. 20. 30. 20. 40. 40. 50. 50. 30. 40. 10. 20.\n",
            " 30. 30. 30. 20. 10. 50. 50. 30. 40. 30. 40. 50. 40. 10. 20. 20. 50.  0.\n",
            " 40. 20. 20. 20. 20. 30. 20. 10. 40. 10. 30. 40. 40. 50. 10. 20. 30. 20.\n",
            " 40. 40. 10. 20. 20. 20. 30. 30. 40. 40. 10. 30. 40. 50. 20. 30. 20. 40.]\n",
            "selection [870 935 662 433 755 647 701 509  34 857] (10,) [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "trainset before adding uncertain samples (330, 10) (330,)\n",
            "trainset after adding uncertain samples (340, 10) (340,)\n",
            "updated train set: (340, 10) (340,) unique(labels): [175 165] [0 1]\n",
            "val set: (962, 10) (962,)\n",
            "\n",
            "Train set: (340, 10)\n",
            "Validation set: (962, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 34\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.078 s \n",
            "\n",
            "Accuracy rate is 79.953917 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.89      0.87       321\n",
            "           1       0.64      0.53      0.58       113\n",
            "\n",
            "    accuracy                           0.80       434\n",
            "   macro avg       0.74      0.71      0.72       434\n",
            "weighted avg       0.79      0.80      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[287  34]\n",
            " [ 53  60]]\n",
            "--------------------------------\n",
            "val predicted: (962,) [1 0 1 1 0 1 1 1 0 0 1 0 0 1 1 1 1 0 1 0 1 0 0 1 0 0 1 0 1 1 1 0 1 1 1 0 0\n",
            " 1 1 0 0 0 0 1 0 1 0 0 0 1 1 1 1 1 0 1 1 1 1 1 0 1 0 0 1 1 0 0 1 1 1 1 1 1\n",
            " 1 0 1 0 0 1 0 1 1 0 0 0 0 1 0 0 1 1 1 1 0 1 0 0 0 1 1 1 0 0 1 0 0 1 0 1 0\n",
            " 1 1 1 1 0 1 0 0 1 0 0 1 0 0 1 1 1 1 0 1 1 0 0 1 1 0 0 1 1 1 0 1 1 1 1 1 0\n",
            " 1 0 1 1 0 0 0 1 1 0 1 1 1 0 1 0 0 0 0 1 0 1 1 0 1 1 1 1 0 1 0 1 1 0 1 1 1\n",
            " 0 0 0 1 0 0 1 1 1 0 0 0 0 0 0 1 0 0 1 0 0 1 1 0 1 1 0 1 1 0 0 1 1 1 0 0 0\n",
            " 0 0 1 1 0 1 1 1 1 1 1 1 1 0 0 0 1 1 0 1 0 1 1 1 1 1 0 1 1 0 1 1 1 0 1 1 0\n",
            " 1 0 1 1 1 1 1 1 1 1 0 0 1 1 0 1 0 0 0 1 1 1 1 1 1 0 0 0 0 1 0 1 0 1 0 0 1\n",
            " 0 1 0 1 0 1 0 0 1 0 1 0 0 0 0 1 1 1 1 1 1 1 1 0 1 1 0 1 0 1 0 1 0 0 1 1 1\n",
            " 1 0 0 1 0 1 1 0 1 1 0 0 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0\n",
            " 0 0 1 1 0 1 1 1 0 1 1 0 1 0 1 0 1 1 1 1 0 1 1 0 1 0 1 1 1 0 1 1 1 0 1 1 0\n",
            " 1 1 0 1 1 1 1 1 0 0 0 1 1 0 1 0 0 1 0 0 0 1 1 0 1 0 1 1 1 1 0 0 1 0 1 1 1\n",
            " 1 1 0 1 0 1 1 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 1 1 1 1 0 1 0 0 0 0 0 0 1 0 0\n",
            " 0 0 1 1 0 1 0 0 1 1 1 0 1 0 0 0 1 1 1 0 1 1 1 1 1 1 1 1 0 0 1 1 0 1 0 1 1\n",
            " 1 1 1 1 0 1 1 0 0 0 0 1 1 0 1 0 1 1 0 1 1 0 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1\n",
            " 1 1 1 0 0 1 0 1 1 1 1 0 1 1 1 1 0 1 0 0 1 1 0 1 1 0 1 0 1 1 0 1 1 1 0 1 1\n",
            " 1 1 0 1 0 1 1 1 0 0 1 0 1 0 1 0 0 1 0 1 0 1 1 1 1 1 1 1 0 0 1 1 0 1 1 0 1\n",
            " 1 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 0 0 0 1 0 1 1 0 0 0 0 1 1 1 0 1 1 1 0 0 1 1 0 0 1 0 1 1 1 1 0 0 1 1 1 1\n",
            " 0 0 1 0 1 0 1 1 1 1 1 0 0 0 0 0 1 0 1 1 1 1 0 0 1 0 0 1 0 1 0 1 0 0 0 1 0\n",
            " 1 1 1 0 0 1 0 0 1 0 1 1 1 0 0 0 1 1 0 0 1 0 1 1 1 1 0 0 1 0 0 1 0 0 0 1 0\n",
            " 0 0 1 1 1 1 0 1 0 0 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0 1 0 1 1 1\n",
            " 1 1 0 1 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 1 0 1 0 1 0 1 0 1 1 0 0 1 0 1 1 0 0\n",
            " 1 1 1 0 0 1 0 1 1 1 1 0 1 1 1 0 0 1 0 1 0 1 1 1 0 1 1 1 0 0 1 1 1 0 0 1 1\n",
            " 1 1 0 1 1 0 1 1 1 0 0 0 1 0 1 1 1 0 0 0 1 0 1 0 1 0 1 0 1 1 1 1 1 1 0 1 0\n",
            " 1 0 1 1 0 1 0 0 0 1 1 0 1 1 1 1 0 0 0 1 1 0 0 1 1 1 0 0 1 1 0 1 1 1 0 0 0]\n",
            "probabilities: (962, 2) \n",
            " [1 0 1 1 0 1 1 1 0 0 1 0 0 1 1 1 1 0 1 0 1 0 0 1 0 0 1 0 1 1 1 0 1 1 1 0 0\n",
            " 1 1 0 0 0 0 1 0 1 0 0 0 1 1 1 1 1 0 1 1 1 1 1 0 1 0 0 1 1 0 0 1 1 1 1 1 1\n",
            " 1 0 1 0 0 1 0 1 1 0 0 0 0 1 0 0 1 1 1 1 0 1 0 0 0 1 1 1 0 0 1 0 0 1 0 1 0\n",
            " 1 1 1 1 0 1 0 0 1 0 0 1 0 0 1 1 1 1 0 1 1 0 0 1 1 0 0 1 1 1 0 1 1 1 1 1 0\n",
            " 1 0 1 1 0 0 0 1 1 0 1 1 1 0 1 0 0 0 0 1 0 1 1 0 1 1 1 1 0 1 0 1 1 0 1 1 1\n",
            " 0 0 0 1 0 0 1 1 1 0 0 0 0 0 0 1 0 0 1 0 0 1 1 0 1 1 0 1 1 0 0 1 1 1 0 0 0\n",
            " 0 0 1 1 0 1 1 1 1 1 1 1 1 0 0 0 1 1 0 1 0 1 1 1 1 1 0 1 1 0 1 1 1 0 1 1 0\n",
            " 1 0 1 1 1 1 1 1 1 1 0 0 1 1 0 1 0 0 0 1 1 1 1 1 1 0 0 0 0 1 0 1 0 1 0 0 1\n",
            " 0 1 0 1 0 1 0 0 1 0 1 0 0 0 0 1 1 1 1 1 1 1 1 0 1 1 0 1 0 1 0 1 0 0 1 1 1\n",
            " 1 0 0 1 0 1 1 0 1 1 0 0 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0\n",
            " 0 0 1 1 0 1 1 1 0 1 1 0 1 0 1 0 1 1 1 1 0 1 1 0 1 0 1 1 1 0 1 1 1 0 1 1 0\n",
            " 1 1 0 1 1 1 1 1 0 0 0 1 1 0 1 0 0 1 0 0 0 1 1 0 1 0 1 1 1 1 0 0 1 0 1 1 1\n",
            " 1 1 0 1 0 1 1 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 1 1 1 1 0 1 0 0 0 0 0 0 1 0 0\n",
            " 0 0 1 1 0 1 0 0 1 1 1 0 1 0 0 0 1 1 1 0 1 1 1 1 1 1 1 1 0 0 1 1 0 1 0 1 1\n",
            " 1 1 1 1 0 1 1 0 0 0 0 1 1 0 1 0 1 1 0 1 1 0 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1\n",
            " 1 1 1 0 0 1 0 1 1 1 1 0 1 1 1 1 0 1 0 0 1 1 0 1 1 0 1 0 1 1 0 1 1 1 0 1 1\n",
            " 1 1 0 1 0 1 1 1 0 0 1 0 1 0 1 0 0 1 0 1 0 1 1 1 1 1 1 1 0 0 1 1 0 1 1 0 1\n",
            " 1 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 0 0 0 1 0 1 1 0 0 0 0 1 1 1 0 1 1 1 0 0 1 1 0 0 1 0 1 1 1 1 0 0 1 1 1 1\n",
            " 0 0 1 0 1 0 1 1 1 1 1 0 0 0 0 0 1 0 1 1 1 1 0 0 1 0 0 1 0 1 0 1 0 0 0 1 0\n",
            " 1 1 1 0 0 1 0 0 1 0 1 1 1 0 0 0 1 1 0 0 1 0 1 1 1 1 0 0 1 0 0 1 0 0 0 1 0\n",
            " 0 0 1 1 1 1 0 1 0 0 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0 1 0 1 1 1\n",
            " 1 1 0 1 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 1 0 1 0 1 0 1 0 1 1 0 0 1 0 1 1 0 0\n",
            " 1 1 1 0 0 1 0 1 1 1 1 0 1 1 1 0 0 1 0 1 0 1 1 1 0 1 1 1 0 0 1 1 1 0 0 1 1\n",
            " 1 1 0 1 1 0 1 1 1 0 0 0 1 0 1 1 1 0 0 0 1 0 1 0 1 0 1 0 1 1 1 1 1 1 0 1 0\n",
            " 1 0 1 1 0 1 0 0 0 1 1 0 1 1 1 1 0 0 0 1 1 0 0 1 1 1 0 0 1 1 0 1 1 1 0 0 0]\n",
            "std (962,) [50. 10. 10. 20. 10. 20. 50. 50. 20. 30. 20. 30. 30. 50. 10. 40. 40. 30.\n",
            " 40. 20. 30. 20. 20. 20. 10. 20. 20. 20. 20. 50. 10. 20. 20. 50. 30. 10.\n",
            " 30. 20. 40. 40. 50. 10.  0. 30. 40. 40. 40. 40. 20. 40. 20. 10. 10. 50.\n",
            " 10. 30. 30. 40. 50. 10. 30. 40. 20. 10. 10. 20. 30. 30. 30. 20. 40. 30.\n",
            " 50. 30. 40. 10. 50. 30. 10. 30. 50. 30. 30. 30. 20. 20. 20. 30. 20. 30.\n",
            " 40. 50. 30. 30. 30. 40. 20. 20. 20. 30. 30. 30. 30. 50. 50. 40. 30. 50.\n",
            " 20. 30. 40. 30. 30. 10. 30. 20. 50. 30. 40. 40. 40. 40. 40. 30. 30. 50.\n",
            " 20. 10. 40. 30. 20. 10. 10. 40. 50. 10. 10. 30. 10. 20. 30. 30. 30. 40.\n",
            " 40. 40. 20. 20. 10. 30. 50. 50. 20. 20. 20. 50. 30. 40. 30. 50. 50. 30.\n",
            " 50. 20. 40. 30. 10. 20. 40. 40. 40. 20. 50. 30. 40. 20. 40. 20. 40. 50.\n",
            " 20. 40. 40. 30. 40. 30. 20. 30. 20. 30. 40. 20. 20. 30. 30. 40. 30. 20.\n",
            " 30. 20. 30. 30. 20. 40. 30. 30. 20. 30. 30. 30. 30. 50. 50. 30. 30. 40.\n",
            " 40. 20. 40. 30. 20. 30. 30. 20. 30. 40. 20. 30. 40. 30. 30. 50. 30. 20.\n",
            " 40.  0. 40. 30. 30. 50. 10. 20. 30. 40. 40. 30. 30. 30. 50. 20. 40. 30.\n",
            " 30. 40. 10. 30. 40. 40. 10. 50. 40. 40. 30. 40. 10. 10. 30. 10. 10. 40.\n",
            " 20. 20. 40. 30. 40. 20. 10. 20. 10. 30. 30. 40. 40. 50. 40. 20. 30. 20.\n",
            " 10. 10. 50. 20. 40. 40. 20. 20. 30. 40. 40. 20. 30. 20. 20. 30. 50. 20.\n",
            " 10. 20. 30. 30. 20. 40. 50. 50. 40. 40. 20. 40. 30. 20. 20. 40. 50. 40.\n",
            " 20. 50. 30. 50. 20. 40. 30. 30. 40. 20. 30. 50. 50. 40. 30. 50. 30. 30.\n",
            " 20. 40. 50. 40. 40. 20. 20. 30. 50. 40. 20. 30. 50. 40. 50. 20. 40. 30.\n",
            " 40. 50. 30. 30. 10. 30. 40. 30. 30. 30. 40. 30. 40. 20. 30. 10. 30. 20.\n",
            " 10. 50. 40. 20. 10. 20. 50. 40. 40. 20. 40. 40. 50. 40. 40. 40. 50. 20.\n",
            " 10. 10. 40. 20. 30. 20. 50. 20. 30. 40. 10. 50. 40. 30. 40. 30. 40. 40.\n",
            " 50. 20. 10. 20. 30. 40. 30. 30. 10. 20. 50. 10. 10. 20. 10. 10. 20. 30.\n",
            " 10. 10. 30. 40. 40. 20. 30. 50. 30. 30. 20. 20. 20. 30. 40. 40. 50. 50.\n",
            " 50. 30. 40. 10. 10. 20. 40. 30. 30. 40. 20. 40. 20. 30. 30. 50. 20. 40.\n",
            " 20. 20. 40. 50. 40. 20.  0. 20. 20. 10. 40. 10. 20. 30. 30. 40. 30. 40.\n",
            " 20. 30. 20. 40. 10. 20. 30. 30. 40. 10. 20. 50. 30. 50. 30. 40. 40. 30.\n",
            " 50. 50. 20. 30. 40. 50. 30. 30. 20. 30. 50. 30. 40. 30. 20. 30. 30. 40.\n",
            " 30. 50. 40. 30. 20. 20. 30. 40. 50. 30. 40. 40. 30. 50. 40. 30. 30. 20.\n",
            " 40. 50. 40. 20. 30. 40. 40. 10. 30. 40. 40. 40. 30. 20. 40. 30. 40. 20.\n",
            " 30. 30. 30. 30. 50. 30. 40. 40. 20. 30. 20. 50. 20. 10. 50. 40. 40. 10.\n",
            " 10. 20. 20. 40. 30. 40. 30. 10. 50. 30. 40. 50. 50. 20. 30. 40. 20. 20.\n",
            " 20. 50. 10. 50. 40. 20. 40. 20. 20. 40. 10. 20. 40. 30. 30. 50. 30. 20.\n",
            " 30. 20. 30. 30. 50. 20. 30. 20. 30. 20. 30. 20. 20. 40. 50. 30. 50. 30.\n",
            " 50. 20. 30. 50. 50. 40. 50. 20. 30. 50. 50. 30. 20. 30. 50. 20. 20. 20.\n",
            " 10. 20. 20. 40. 40. 30. 30. 40. 40. 50. 20. 40. 40. 40. 20. 50. 30. 30.\n",
            " 10. 20. 20. 40. 40. 50. 30. 40. 20. 10. 20. 20. 40. 10. 20. 10. 30. 50.\n",
            " 50. 20. 10. 20. 20. 30. 40. 40. 30. 20. 50. 20. 40. 20. 50. 30. 40. 30.\n",
            " 50. 30. 40. 50. 30. 30. 10. 10. 30. 20. 50. 40. 40. 20. 30. 10. 40. 40.\n",
            " 20. 10. 50. 30. 50. 30. 10. 10. 40. 40. 50. 20. 50. 30. 20. 30. 20. 50.\n",
            " 30. 30. 50. 40. 30. 20. 20. 40. 50. 30. 30. 30. 30. 20. 40. 40. 40. 20.\n",
            " 50. 30. 30. 30. 30. 20. 40. 40. 40. 40. 20. 50. 40. 20. 10. 10. 20. 40.\n",
            " 50. 20. 10. 40. 10. 50. 40. 30. 30. 40. 20. 30. 40. 30. 40. 20. 40. 30.\n",
            " 10. 40. 40. 30. 20. 10. 20. 30. 30. 30. 10. 20. 10. 20. 50. 20. 30. 50.\n",
            " 10. 30. 30. 50. 40. 30. 20. 30. 20. 20. 10. 30. 20. 10. 50. 30. 30. 20.\n",
            " 40. 40. 40. 10. 20. 40. 30. 30. 30. 40. 20. 40. 30. 40. 30. 40. 30. 20.\n",
            " 30. 20. 10.  0. 20. 20. 50. 10. 50. 20. 30. 30. 40. 40. 30. 20. 40. 40.\n",
            " 40. 50. 30. 30. 50. 10. 20. 20. 10. 10. 20. 20. 40. 40. 20. 20. 10. 20.\n",
            " 30. 40. 40. 20. 30. 40. 30. 20. 30. 40. 40. 30. 40. 50. 50. 20. 20. 30.\n",
            " 10. 40. 40. 50. 50. 30. 40. 20. 20. 30. 30. 30. 20. 10. 50. 50. 30. 40.\n",
            " 30. 40. 50. 40. 10. 10. 20. 50. 40. 20. 30. 20. 20. 30. 20. 10. 40. 20.\n",
            " 10. 40. 40. 50. 20. 20. 40. 20. 40. 40. 10. 20. 20. 20. 30. 30. 40. 40.\n",
            " 10. 30. 40. 50. 20. 30. 20. 40.]\n",
            "selection [474 235  42 849 429 268 820 267 265 576] (10,) [ 0.  0.  0.  0. 10. 10. 10. 10. 10. 10.]\n",
            "trainset before adding uncertain samples (340, 10) (340,)\n",
            "trainset after adding uncertain samples (350, 10) (350,)\n",
            "updated train set: (350, 10) (350,) unique(labels): [180 170] [0 1]\n",
            "val set: (952, 10) (952,)\n",
            "\n",
            "Train set: (350, 10)\n",
            "Validation set: (952, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 35\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.081 s \n",
            "\n",
            "Accuracy rate is 80.645161 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.90      0.87       321\n",
            "           1       0.66      0.53      0.59       113\n",
            "\n",
            "    accuracy                           0.81       434\n",
            "   macro avg       0.75      0.72      0.73       434\n",
            "weighted avg       0.80      0.81      0.80       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[290  31]\n",
            " [ 53  60]]\n",
            "--------------------------------\n",
            "val predicted: (952,) [1 0 1 1 0 1 1 1 0 0 1 0 0 1 1 1 1 0 1 0 1 0 0 1 0 0 1 0 1 1 1 0 1 1 1 0 0\n",
            " 1 1 0 0 0 1 0 1 0 0 0 1 1 1 1 1 0 1 1 1 1 1 0 1 0 0 1 1 0 0 1 1 1 1 1 1 1\n",
            " 0 1 0 0 1 0 1 1 0 0 0 0 1 0 0 1 1 1 1 0 1 0 0 0 1 1 1 0 0 1 0 0 1 0 1 0 1\n",
            " 1 1 1 0 1 0 0 1 0 0 1 0 0 1 1 1 1 0 1 1 0 0 1 1 0 0 1 1 1 0 1 1 1 1 1 0 1\n",
            " 0 1 1 0 0 0 1 1 0 1 1 1 0 1 0 0 0 0 1 0 1 1 0 1 1 1 1 0 1 0 1 1 0 1 1 1 0\n",
            " 0 0 1 0 0 1 1 1 0 0 0 0 0 0 1 0 0 1 0 0 1 1 0 1 1 0 1 1 0 0 1 1 1 0 0 0 0\n",
            " 0 1 1 0 1 1 1 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 1 0 1 1 0 1 1 1 0 1 1 0 1 0\n",
            " 1 1 1 1 1 0 0 1 1 0 1 0 0 0 1 1 1 1 1 1 0 0 0 0 0 0 1 0 1 0 0 1 0 1 0 1 0\n",
            " 1 0 0 1 0 1 0 0 0 0 1 1 1 1 1 1 1 1 0 1 1 0 1 0 1 0 1 0 0 1 1 1 1 0 0 1 0\n",
            " 1 1 0 1 1 0 0 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 0 1 1 0\n",
            " 1 1 1 0 1 1 0 1 0 1 0 1 1 1 1 0 1 1 0 1 0 1 1 1 0 1 1 1 0 1 1 0 1 1 0 1 1\n",
            " 1 1 1 0 0 0 1 1 0 1 0 0 1 0 0 0 1 0 1 0 1 1 1 1 0 0 1 0 1 1 1 1 1 0 1 0 1\n",
            " 1 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 1 1 1 1 0 1 0 0 0 0 0 1 0 0 0 0 1 1 0 1 0\n",
            " 0 1 1 1 0 1 0 0 0 1 1 1 0 1 1 1 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 1 1 0 1 1\n",
            " 0 0 0 0 1 1 0 1 0 1 1 0 1 1 0 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 0 1 0\n",
            " 1 1 1 1 0 1 1 1 1 0 1 0 0 1 0 1 1 0 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 0 1 1 1\n",
            " 0 0 1 0 1 0 1 0 0 1 0 1 0 1 1 1 1 1 1 1 0 0 1 1 0 1 1 0 1 1 1 0 1 1 1 0 1\n",
            " 1 0 1 1 1 1 1 1 0 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 0 1 1\n",
            " 0 0 0 0 1 0 1 0 1 1 1 0 0 1 1 0 0 1 0 1 1 1 1 0 0 1 1 1 1 0 0 1 0 1 0 1 1\n",
            " 1 1 1 0 0 0 0 0 1 0 0 1 1 1 0 0 1 0 0 1 0 1 0 1 0 0 0 1 0 1 1 1 0 0 1 0 0\n",
            " 1 0 1 1 1 0 0 0 1 1 0 0 1 0 1 1 1 1 0 0 1 0 0 1 0 0 0 1 0 0 0 1 1 1 1 0 1\n",
            " 0 0 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0 1 0 1 1 1 1 1 0 1 0 0 0 0\n",
            " 0 1 1 1 1 0 0 0 0 0 1 0 1 0 1 0 1 0 1 1 0 0 1 0 1 0 0 1 1 1 0 0 1 0 1 1 1\n",
            " 1 0 1 1 1 0 0 1 0 1 0 1 1 1 0 1 1 1 0 0 1 1 1 0 0 1 1 1 1 0 1 1 0 1 1 1 0\n",
            " 0 0 1 0 1 1 1 0 0 0 1 0 1 0 1 0 1 0 1 1 1 1 1 1 0 1 0 1 0 1 1 0 1 0 0 0 1\n",
            " 1 0 1 1 1 1 0 0 0 1 1 0 0 1 1 1 0 0 1 1 0 1 1 1 0 0 0]\n",
            "probabilities: (952, 2) \n",
            " [1 0 1 1 0 1 1 1 0 0 1 0 0 1 1 1 1 0 1 0 1 0 0 1 0 0 1 0 1 1 1 0 1 1 1 0 0\n",
            " 1 1 0 0 0 1 0 1 0 0 0 1 1 1 1 1 0 1 1 1 1 1 0 1 0 0 1 1 0 0 1 1 1 1 1 1 1\n",
            " 0 1 0 0 1 0 1 1 0 0 0 0 1 0 0 1 1 1 1 0 1 0 0 0 1 1 1 0 0 1 0 0 1 0 1 0 1\n",
            " 1 1 1 0 1 0 0 1 0 0 1 0 0 1 1 1 1 0 1 1 0 0 1 1 0 0 1 1 1 0 1 1 1 1 1 0 1\n",
            " 0 1 1 0 0 0 1 1 0 1 1 1 0 1 0 0 0 0 1 0 1 1 0 1 1 1 1 0 1 0 1 1 0 1 1 1 0\n",
            " 0 0 1 0 0 1 1 1 0 0 0 0 0 0 1 0 0 1 0 0 1 1 0 1 1 0 1 1 0 0 1 1 1 0 0 0 0\n",
            " 0 1 1 0 1 1 1 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 1 0 1 1 0 1 1 1 0 1 1 0 1 0\n",
            " 1 1 1 1 1 0 0 1 1 0 1 0 0 0 1 1 1 1 1 1 0 0 0 0 0 0 1 0 1 0 0 1 0 1 0 1 0\n",
            " 1 0 0 1 0 1 0 0 0 0 1 1 1 1 1 1 1 1 0 1 1 0 1 0 1 0 1 0 0 1 1 1 1 0 0 1 0\n",
            " 1 1 0 1 1 0 0 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 0 1 1 0\n",
            " 1 1 1 0 1 1 0 1 0 1 0 1 1 1 1 0 1 1 0 1 0 1 1 1 0 1 1 1 0 1 1 0 1 1 0 1 1\n",
            " 1 1 1 0 0 0 1 1 0 1 0 0 1 0 0 0 1 0 1 0 1 1 1 1 0 0 1 0 1 1 1 1 1 0 1 0 1\n",
            " 1 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 1 1 1 1 0 1 0 0 0 0 0 1 0 0 0 0 1 1 0 1 0\n",
            " 0 1 1 1 0 1 0 0 0 1 1 1 0 1 1 1 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 1 1 0 1 1\n",
            " 0 0 0 0 1 1 0 1 0 1 1 0 1 1 0 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 0 1 0\n",
            " 1 1 1 1 0 1 1 1 1 0 1 0 0 1 0 1 1 0 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 0 1 1 1\n",
            " 0 0 1 0 1 0 1 0 0 1 0 1 0 1 1 1 1 1 1 1 0 0 1 1 0 1 1 0 1 1 1 0 1 1 1 0 1\n",
            " 1 0 1 1 1 1 1 1 0 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 0 1 1\n",
            " 0 0 0 0 1 0 1 0 1 1 1 0 0 1 1 0 0 1 0 1 1 1 1 0 0 1 1 1 1 0 0 1 0 1 0 1 1\n",
            " 1 1 1 0 0 0 0 0 1 0 0 1 1 1 0 0 1 0 0 1 0 1 0 1 0 0 0 1 0 1 1 1 0 0 1 0 0\n",
            " 1 0 1 1 1 0 0 0 1 1 0 0 1 0 1 1 1 1 0 0 1 0 0 1 0 0 0 1 0 0 0 1 1 1 1 0 1\n",
            " 0 0 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0 1 0 1 1 1 1 1 0 1 0 0 0 0\n",
            " 0 1 1 1 1 0 0 0 0 0 1 0 1 0 1 0 1 0 1 1 0 0 1 0 1 0 0 1 1 1 0 0 1 0 1 1 1\n",
            " 1 0 1 1 1 0 0 1 0 1 0 1 1 1 0 1 1 1 0 0 1 1 1 0 0 1 1 1 1 0 1 1 0 1 1 1 0\n",
            " 0 0 1 0 1 1 1 0 0 0 1 0 1 0 1 0 1 0 1 1 1 1 1 1 0 1 0 1 0 1 1 0 1 0 0 0 1\n",
            " 1 0 1 1 1 1 0 0 0 1 1 0 0 1 1 1 0 0 1 1 0 1 1 1 0 0 0]\n",
            "std (952,) [50. 10. 10. 10. 10. 20. 50. 40. 20. 30. 20. 30. 30. 50. 10. 40. 40. 30.\n",
            " 40. 20. 30. 20. 20. 20. 20. 20. 20. 20. 20. 50. 10. 20. 20. 40. 30. 10.\n",
            " 30. 20. 40. 40. 50. 10. 30. 40. 40. 40. 40. 20. 30. 20. 10. 10. 50. 10.\n",
            " 30. 20. 40. 50. 10. 30. 40. 20. 20. 10. 20. 30. 30. 30. 20. 40. 30. 50.\n",
            " 30. 40. 10. 50. 30. 10. 20. 50. 40. 50. 30. 20. 20. 10. 30. 20. 20. 40.\n",
            " 50. 30. 30. 30. 30. 20. 20. 20. 20. 30. 20. 30. 50. 40. 30. 30. 50. 20.\n",
            " 30. 40. 40. 30. 10. 30. 20. 50. 30. 40. 30. 40. 40. 40. 30. 30. 50. 10.\n",
            " 20. 40. 30. 20. 10. 10. 40. 50. 20. 10. 30. 10. 10. 20. 30. 20. 40. 40.\n",
            " 40. 20. 20. 10. 30. 50. 50. 10. 20. 20. 50. 30. 40. 30. 50. 50. 30. 50.\n",
            " 20. 40. 30. 10. 20. 40. 40. 50. 20. 50. 30. 40. 20. 40. 20. 40. 50. 20.\n",
            " 40. 40. 30. 40. 30. 20. 30. 10. 30. 40. 30. 10. 30. 30. 40. 30. 10. 30.\n",
            " 20. 30. 30. 20. 40. 30. 30. 10. 30. 40. 30. 30. 50. 50. 30. 30. 40. 40.\n",
            " 20. 40. 20. 10. 30. 30. 20. 20. 40. 20. 30. 40. 30. 20. 40. 30. 20. 40.\n",
            " 40. 30. 30. 50. 10. 30. 30. 40. 40. 30. 30. 40. 50. 20. 40. 30. 30. 40.\n",
            " 10. 30. 40. 40. 10. 50. 40. 40. 30. 30. 20. 30. 40. 20. 20. 30. 40. 40.\n",
            " 20. 10. 20. 20. 20. 30. 40. 40. 40. 40. 20. 30. 20.  0. 10. 50. 20. 40.\n",
            " 40. 20. 10. 40. 40. 40. 20. 30. 20. 20. 30. 50. 20. 10. 10. 30. 30. 20.\n",
            " 30. 50. 50. 40. 30. 10. 40. 30. 20. 30. 40. 50. 40. 20. 50. 30. 50. 30.\n",
            " 40. 30. 30. 40. 20. 30. 50. 50. 40. 20. 50. 30. 30. 20. 40. 50. 40. 40.\n",
            " 20. 20. 30. 50. 40. 30. 30. 50. 40. 50. 20. 30. 20. 30. 50. 40. 20. 10.\n",
            " 30. 40. 30. 30. 30. 40. 30. 40. 20. 30. 20. 20. 20. 10. 40. 40. 20. 10.\n",
            " 20. 50. 40. 40. 20. 40. 40. 40. 50. 40. 40. 50. 10. 10. 10. 40. 20. 30.\n",
            " 20. 50. 20. 30. 30. 10. 50. 30. 20. 40. 30. 30. 30. 40. 20. 10. 20. 30.\n",
            " 40. 30. 30. 10. 20. 50. 30. 10. 20. 10. 20. 30. 10. 10. 30. 30. 40. 20.\n",
            " 30. 50. 30. 30. 20. 20. 20. 30. 40. 40. 50. 50. 50. 30. 40. 10. 10. 20.\n",
            " 40. 30. 30. 40. 30. 40. 20. 30. 30. 50. 20. 40. 20. 20. 40. 50. 40. 20.\n",
            " 20. 20. 10. 40. 10. 20. 30. 30. 40. 30. 40. 20. 40. 20. 40. 10. 20. 30.\n",
            " 30. 30. 20. 20. 50. 40. 50. 30. 40. 40. 40. 50. 50. 20. 30. 40. 50. 30.\n",
            " 40. 20. 30. 50. 40. 40. 30. 10. 30. 40. 40. 30. 40. 40. 30. 20. 20. 30.\n",
            " 40. 40. 30. 40. 40. 30. 50. 40. 30. 30. 20. 40. 50. 50. 20. 20. 30. 40.\n",
            " 10. 20. 40. 40. 40. 30. 20. 40. 30. 40. 20. 30. 30. 30. 30. 50. 30. 30.\n",
            " 30. 20. 30. 20. 50. 20. 10. 40. 40. 40. 10. 20. 20. 40. 30. 40. 30. 10.\n",
            " 50. 30. 40. 50. 50. 20. 30. 40. 20. 10. 20. 50. 10. 50. 30. 20. 40. 20.\n",
            " 20. 40. 10. 20. 40. 30. 40. 50. 30. 20. 20. 10. 40. 30. 50. 20. 30. 30.\n",
            " 30. 30. 30. 20. 20. 40. 50. 30. 50. 30. 50. 20. 20. 50. 40. 40. 40. 20.\n",
            " 30. 50. 50. 30. 20. 30. 50. 20. 20. 20.  0. 20. 20. 40. 40. 30. 30. 40.\n",
            " 40. 50. 20. 40. 40. 40. 20. 50. 30. 30. 10. 20. 20. 40. 40. 50. 30. 40.\n",
            " 20. 10. 20. 20. 40.  0. 20. 10. 30. 50. 40. 20. 20. 20. 20. 30. 50. 40.\n",
            " 30. 20. 50. 20. 40. 20. 50. 30. 40. 20. 50. 30. 40. 50. 30. 30. 10. 10.\n",
            " 30. 20. 50. 40. 40. 20. 30. 10. 40. 40. 30.  0. 50. 30. 50. 30. 10. 20.\n",
            " 30. 30. 50. 20. 50. 30. 20. 30. 20. 50. 30. 30. 50. 40. 30. 30. 20. 40.\n",
            " 50. 30. 40. 30. 30. 10. 40. 40. 40. 20. 40. 30. 40. 30. 30. 20. 40. 40.\n",
            " 40. 40. 20. 50. 40. 20. 10. 10. 20. 40. 50. 30. 10. 30. 10. 50. 40. 30.\n",
            " 30. 40. 20. 30. 40. 30. 40. 10. 40. 30. 10. 40. 40. 30. 20. 10. 20. 20.\n",
            " 20. 30. 10. 20. 10. 20. 50. 20. 30. 50. 10. 30. 40. 50. 40. 30. 30. 30.\n",
            " 20. 20. 30. 20. 10. 50. 30. 20. 30. 40. 40. 30. 10. 20. 40. 30. 30. 30.\n",
            " 40. 20. 40. 30. 50. 30. 40. 30. 10. 30. 20.  0. 20. 20. 50. 10. 50. 20.\n",
            " 30. 30. 40. 40. 30. 20. 40. 40. 40. 50. 30. 40. 50. 10. 20. 20. 10. 30.\n",
            " 10. 20. 40. 40. 10. 10. 10. 20. 30. 40. 30. 20. 30. 40. 30. 20. 30. 40.\n",
            " 30. 30. 40. 50. 50. 20. 20. 40. 10. 40. 40. 50. 50. 30. 40. 10. 20. 30.\n",
            " 30. 30. 20. 10. 50. 50. 30. 40. 30. 40. 50. 40. 10. 20. 20. 50. 40. 20.\n",
            " 30. 20. 20. 30. 20. 10. 40. 10. 20. 40. 40. 50. 20. 20. 40. 20. 40. 40.\n",
            " 10. 20. 20. 10. 20. 30. 40. 40. 20. 30. 40. 50. 30. 30. 20. 40.]\n",
            "selection [671 640 283 839 713 869 271 814 472 470] (10,) [ 0.  0.  0.  0.  0. 10. 10. 10. 10. 10.]\n",
            "trainset before adding uncertain samples (350, 10) (350,)\n",
            "trainset after adding uncertain samples (360, 10) (360,)\n",
            "updated train set: (360, 10) (360,) unique(labels): [185 175] [0 1]\n",
            "val set: (942, 10) (942,)\n",
            "\n",
            "Train set: (360, 10)\n",
            "Validation set: (942, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 36\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.079 s \n",
            "\n",
            "Accuracy rate is 78.571429 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86       321\n",
            "           1       0.61      0.50      0.55       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.72      0.69      0.71       434\n",
            "weighted avg       0.78      0.79      0.78       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[284  37]\n",
            " [ 56  57]]\n",
            "--------------------------------\n",
            "val predicted: (942,) [1 0 0 1 0 0 1 1 0 0 1 0 0 1 1 1 1 0 1 0 1 0 0 1 0 0 1 0 1 1 1 0 1 1 1 0 0\n",
            " 1 1 0 0 0 1 0 1 0 0 0 1 1 1 1 1 0 1 1 1 1 0 0 1 0 0 0 1 0 0 1 1 1 1 1 1 1\n",
            " 0 1 0 0 1 0 1 1 0 0 0 0 1 0 0 1 1 1 1 0 1 0 0 0 1 1 1 0 0 1 0 0 1 0 1 0 1\n",
            " 1 1 1 0 1 0 0 1 0 0 1 0 0 1 1 1 1 0 1 1 0 0 1 1 0 0 1 1 1 0 1 1 1 1 1 0 1\n",
            " 0 1 1 0 0 0 1 1 0 1 1 1 0 1 0 0 0 0 1 0 1 1 0 1 1 1 1 0 1 0 1 1 0 1 1 1 0\n",
            " 0 0 1 0 0 1 1 1 0 0 0 0 0 0 1 0 0 1 0 0 1 1 0 1 1 0 1 1 0 0 1 1 1 0 0 0 0\n",
            " 0 1 1 0 1 1 1 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 1 0 1 1 0 1 1 1 0 1 1 0 1 0\n",
            " 1 1 1 1 1 0 0 1 1 0 1 0 0 1 1 1 1 1 1 0 0 0 0 0 1 0 1 0 0 1 0 1 0 1 0 1 0\n",
            " 0 1 0 1 0 0 0 0 1 1 1 1 1 1 1 1 0 1 1 0 1 0 1 0 1 0 0 1 1 1 1 0 0 1 0 1 1\n",
            " 0 1 1 0 0 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 0 1 1 0 1 1\n",
            " 1 0 1 1 0 1 0 1 0 1 1 1 1 0 1 1 0 1 0 1 1 1 0 1 1 1 0 1 1 0 1 1 0 1 1 1 1\n",
            " 1 0 0 0 1 1 0 1 0 0 1 0 0 0 1 0 1 0 1 1 1 1 0 0 1 0 1 1 1 1 1 0 1 0 1 1 0\n",
            " 0 0 0 0 1 1 1 1 1 1 1 0 0 0 1 1 1 1 0 1 0 0 0 0 1 0 0 0 1 1 0 1 0 0 1 1 1\n",
            " 0 1 0 0 0 1 1 1 0 1 1 1 1 1 1 1 1 0 0 1 1 0 1 0 1 1 0 1 1 1 0 1 1 0 0 0 0\n",
            " 1 1 0 1 0 1 1 0 1 1 0 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1 1\n",
            " 0 1 1 1 1 0 1 0 0 1 0 1 1 0 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 0 1 1 1 0 0 1 0\n",
            " 1 0 1 0 0 1 0 1 0 1 1 1 1 1 1 1 0 0 1 1 0 1 1 0 1 1 1 0 1 1 1 0 1 1 0 1 1\n",
            " 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 1 0 1 1 0 0 0 0 1\n",
            " 1 0 1 1 1 0 0 1 1 0 0 1 0 1 1 1 1 0 0 1 1 1 1 0 0 1 0 1 0 1 1 1 1 1 0 0 0\n",
            " 0 0 1 0 1 1 1 0 0 1 0 0 1 0 1 0 1 0 0 0 1 0 1 1 1 0 0 1 0 0 1 0 1 1 1 0 0\n",
            " 0 1 1 0 0 1 0 1 1 1 1 0 0 1 0 0 1 0 0 0 1 0 0 0 1 1 1 1 0 1 0 0 1 0 0 0 0\n",
            " 0 1 1 1 1 0 1 1 1 1 1 1 0 0 1 0 0 1 0 1 1 1 1 1 0 1 0 0 0 0 1 1 1 1 0 0 0\n",
            " 0 0 1 0 1 0 1 0 1 0 1 1 0 0 1 0 1 0 1 1 0 0 0 1 0 1 1 1 1 0 1 1 1 0 0 1 0\n",
            " 1 0 1 1 1 0 1 1 1 0 1 1 1 0 0 1 1 1 1 0 1 1 0 1 1 1 0 0 0 1 0 1 1 1 0 0 0\n",
            " 1 0 1 0 1 0 1 0 1 1 1 1 1 1 0 1 0 1 0 1 1 0 1 0 0 0 1 1 0 1 1 1 1 0 0 0 1\n",
            " 1 0 0 1 0 1 0 0 1 1 0 1 1 1 0 0 0]\n",
            "probabilities: (942, 2) \n",
            " [1 0 0 1 0 0 1 1 0 0 1 0 0 1 1 1 1 0 1 0 1 0 0 1 0 0 1 0 1 1 1 0 1 1 1 0 0\n",
            " 1 1 0 0 0 1 0 1 0 0 0 1 1 1 1 1 0 1 1 1 1 0 0 1 0 0 0 1 0 0 1 1 1 1 1 1 1\n",
            " 0 1 0 0 1 0 1 1 0 0 0 0 1 0 0 1 1 1 1 0 1 0 0 0 1 1 1 0 0 1 0 0 1 0 1 0 1\n",
            " 1 1 1 0 1 0 0 1 0 0 1 0 0 1 1 1 1 0 1 1 0 0 1 1 0 0 1 1 1 0 1 1 1 1 1 0 1\n",
            " 0 1 1 0 0 0 1 1 0 1 1 1 0 1 0 0 0 0 1 0 1 1 0 1 1 1 1 0 1 0 1 1 0 1 1 1 0\n",
            " 0 0 1 0 0 1 1 1 0 0 0 0 0 0 1 0 0 1 0 0 1 1 0 1 1 0 1 1 0 0 1 1 1 0 0 0 0\n",
            " 0 1 1 0 1 1 1 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 1 0 1 1 0 1 1 1 0 1 1 0 1 0\n",
            " 1 1 1 1 1 0 0 1 1 0 1 0 0 1 1 1 1 1 1 0 0 0 0 0 1 0 1 0 0 1 0 1 0 1 0 1 0\n",
            " 0 1 0 1 0 0 0 0 1 1 1 1 1 1 1 1 0 1 1 0 1 0 1 0 1 0 0 1 1 1 1 0 0 1 0 1 1\n",
            " 0 1 1 0 0 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 0 1 1 0 1 1\n",
            " 1 0 1 1 0 1 0 1 0 1 1 1 1 0 1 1 0 1 0 1 1 1 0 1 1 1 0 1 1 0 1 1 0 1 1 1 1\n",
            " 1 0 0 0 1 1 0 1 0 0 1 0 0 0 1 0 1 0 1 1 1 1 0 0 1 0 1 1 1 1 1 0 1 0 1 1 0\n",
            " 0 0 0 0 1 1 1 1 1 1 1 0 0 0 1 1 1 1 0 1 0 0 0 0 1 0 0 0 1 1 0 1 0 0 1 1 1\n",
            " 0 1 0 0 0 1 1 1 0 1 1 1 1 1 1 1 1 0 0 1 1 0 1 0 1 1 0 1 1 1 0 1 1 0 0 0 0\n",
            " 1 1 0 1 0 1 1 0 1 1 0 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1 1\n",
            " 0 1 1 1 1 0 1 0 0 1 0 1 1 0 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 0 1 1 1 0 0 1 0\n",
            " 1 0 1 0 0 1 0 1 0 1 1 1 1 1 1 1 0 0 1 1 0 1 1 0 1 1 1 0 1 1 1 0 1 1 0 1 1\n",
            " 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 1 0 1 1 0 0 0 0 1\n",
            " 1 0 1 1 1 0 0 1 1 0 0 1 0 1 1 1 1 0 0 1 1 1 1 0 0 1 0 1 0 1 1 1 1 1 0 0 0\n",
            " 0 0 1 0 1 1 1 0 0 1 0 0 1 0 1 0 1 0 0 0 1 0 1 1 1 0 0 1 0 0 1 0 1 1 1 0 0\n",
            " 0 1 1 0 0 1 0 1 1 1 1 0 0 1 0 0 1 0 0 0 1 0 0 0 1 1 1 1 0 1 0 0 1 0 0 0 0\n",
            " 0 1 1 1 1 0 1 1 1 1 1 1 0 0 1 0 0 1 0 1 1 1 1 1 0 1 0 0 0 0 1 1 1 1 0 0 0\n",
            " 0 0 1 0 1 0 1 0 1 0 1 1 0 0 1 0 1 0 1 1 0 0 0 1 0 1 1 1 1 0 1 1 1 0 0 1 0\n",
            " 1 0 1 1 1 0 1 1 1 0 1 1 1 0 0 1 1 1 1 0 1 1 0 1 1 1 0 0 0 1 0 1 1 1 0 0 0\n",
            " 1 0 1 0 1 0 1 0 1 1 1 1 1 1 0 1 0 1 0 1 1 0 1 0 0 0 1 1 0 1 1 1 1 0 0 0 1\n",
            " 1 0 0 1 0 1 0 0 1 1 0 1 1 1 0 0 0]\n",
            "std (942,) [50. 10.  0. 10.  0.  0. 50. 40. 20. 30. 20. 30. 30. 50. 10. 40. 40. 30.\n",
            " 40. 20. 30. 10. 20. 20. 10. 20. 20. 20. 20. 50. 10. 20. 20. 40. 30. 20.\n",
            " 40. 10. 40. 40. 50. 10. 30. 30. 40. 30. 40. 20. 30. 20. 10. 10. 50. 10.\n",
            " 30. 30. 30. 50.  0. 30. 40. 20. 20.  0. 20. 30. 30. 20. 20. 40. 30. 50.\n",
            " 30. 40. 10. 50. 30.  0. 30. 50. 40. 50. 30. 20. 20. 10. 20. 10. 20. 40.\n",
            " 50. 30. 30. 30. 30. 30. 20. 20. 30. 30. 10. 30. 50. 40. 40. 30. 50. 20.\n",
            " 20. 40. 40. 20. 20. 40. 20. 50. 30. 40. 30. 40. 30. 40. 30. 30. 50. 20.\n",
            " 20. 40. 30. 10. 10. 10. 40. 50. 30. 10. 30. 20. 20. 10. 30. 30. 40. 40.\n",
            " 40. 20. 30. 20. 30. 50. 50. 10. 30. 20. 40. 40. 40. 20. 50. 50. 30. 50.\n",
            " 20. 40. 20. 10. 20. 40. 40. 50. 10. 50. 30. 40. 20. 40. 30. 40. 40. 20.\n",
            " 40. 40. 30. 40. 30. 20. 30. 20. 30. 40. 20. 20. 30. 30. 40. 30. 10. 30.\n",
            " 20. 30. 30. 20. 40. 30. 30. 10. 30. 40. 30. 40. 50. 50. 30. 30. 40. 40.\n",
            " 10. 50. 20. 10. 30. 30. 20. 10. 40. 20. 30. 40. 30. 40. 40. 20. 30. 40.\n",
            " 40. 30. 30. 50. 20. 30. 30. 40. 40. 30. 30. 40. 40. 20. 40. 30. 40. 40.\n",
            " 10. 30. 40. 40. 10. 50. 40. 40. 30. 40. 20. 20. 50. 20. 20. 30. 40. 40.\n",
            " 20. 30. 30. 20. 30. 40. 40. 50. 40. 20. 30. 20. 10. 50. 20. 50. 40. 30.\n",
            " 10. 30. 40. 40. 20. 30. 20. 20. 20. 40. 20. 10. 10. 30. 40. 20. 40. 40.\n",
            " 50. 40. 30. 10. 40. 20. 20. 30. 40. 50. 40. 20. 50. 30. 50. 30. 30. 30.\n",
            " 30. 40. 20. 30. 50. 50. 40. 30. 50. 30. 30. 20. 40. 40. 50. 30. 20. 30.\n",
            " 30. 50. 40. 30. 30. 50. 40. 50. 30. 30. 30. 40. 50. 50. 20. 10. 30. 40.\n",
            " 20. 30. 30. 30. 30. 40. 10. 30. 20. 20. 20. 10. 50. 40. 20. 10. 20. 50.\n",
            " 40. 40. 20. 30. 40. 30. 40. 40. 40. 50. 20. 10. 10. 40. 20. 30. 20. 50.\n",
            " 20. 20. 30. 10. 50. 40. 20. 40. 20. 40. 30. 40. 30. 10. 20. 30. 40. 40.\n",
            " 30. 10. 20. 50. 30. 10. 10. 10. 20. 30. 10. 10. 30. 30. 40. 20. 30. 50.\n",
            " 30. 30. 20. 10. 20. 30. 40. 40. 50. 50. 50. 30. 40. 10. 10. 20. 40. 30.\n",
            " 30. 40. 30. 40. 20. 30. 30. 50. 20. 40. 20. 20. 40. 50. 40. 20. 10. 20.\n",
            " 40. 20. 30. 40. 40. 30. 40. 10. 40. 20. 40. 10. 20. 30. 30. 30. 20. 20.\n",
            " 50. 30. 50. 30. 40. 40. 40. 50. 50. 20. 30. 40. 50. 30. 40. 10. 20. 50.\n",
            " 40. 40. 40.  0. 30. 40. 40. 30. 50. 40. 30. 10. 20. 30. 40. 40. 30. 30.\n",
            " 30. 30. 50. 40. 30. 30. 20. 40. 50. 50. 20. 20. 40. 40. 10. 20. 40. 40.\n",
            " 40. 30. 20. 40. 30. 50. 30. 30. 40. 20. 30. 50. 30. 30. 30. 20. 30. 20.\n",
            " 50. 20.  0. 40. 40. 40. 10. 20. 20. 40. 30. 40. 30. 10. 50. 30. 40. 50.\n",
            " 50. 20. 30. 40. 20. 10. 20. 50. 10. 50. 30. 20. 40. 20. 20. 40. 10. 20.\n",
            " 40. 30. 40. 50. 30. 10. 30. 20. 40. 30. 50. 10. 30. 30. 30. 30. 30. 20.\n",
            " 20. 40. 50. 30. 50. 30. 50. 20. 20. 50. 40. 40. 40. 20. 30. 50. 50. 30.\n",
            " 20. 30. 50. 20. 20. 20. 20. 30. 40. 40. 30. 20. 30. 30. 50. 20. 40. 40.\n",
            " 40. 20. 50. 30. 40.  0. 20. 20. 40. 40. 40. 30. 40. 20. 10. 20. 20. 40.\n",
            " 20. 10. 30. 50. 50. 20. 20. 20. 30. 30. 40. 40. 30. 20. 50. 20. 30. 10.\n",
            " 50. 30. 40. 20. 50. 20. 40. 50. 30. 30. 10. 10. 40. 20. 50. 40. 40. 20.\n",
            " 30. 10. 40. 40. 30. 50. 30. 50. 30. 10. 10. 40. 40. 50. 20. 50. 30. 20.\n",
            " 30. 20. 50. 30. 40. 40. 40. 30. 30. 30. 40. 50. 30. 30. 30. 30. 20. 40.\n",
            " 40. 30. 20. 40. 30. 40. 20. 30. 20. 40. 40. 40. 40. 20. 50. 40. 20. 20.\n",
            " 10. 20. 40. 50. 30. 10. 40. 10. 50. 40. 30. 40. 40. 20. 20. 40. 30. 40.\n",
            " 10. 40. 30. 10. 40. 40. 30. 20.  0. 20. 20. 20. 30. 10. 20. 10. 20. 50.\n",
            " 20. 30. 50. 10. 30. 30. 50. 40. 30. 20. 30. 20. 20. 30. 20. 50. 30. 20.\n",
            " 30. 40. 40. 30. 10. 10. 40. 30. 30. 30. 40. 20. 40. 30. 50. 30. 40. 30.\n",
            " 20. 30. 20. 20. 20. 40.  0. 40. 20. 20. 40. 40. 40. 30. 20. 40. 40. 40.\n",
            " 50. 30. 30. 50.  0. 20. 20. 10. 20. 10. 20. 40. 40. 20.  0. 20. 30. 40.\n",
            " 30. 20. 30. 40. 30. 20. 20. 40. 30. 30. 40. 50. 50. 20. 20. 30. 20. 40.\n",
            " 40. 50. 50. 30. 40. 30. 20. 30. 40. 30. 10. 20. 50. 50. 30. 40. 30. 40.\n",
            " 50. 40. 20. 10. 20. 50. 40. 30. 30. 30. 20. 30. 10. 10. 50. 10. 20. 30.\n",
            " 40. 50. 20. 10. 40. 20. 30. 40. 10. 20. 10.  0. 20. 30. 40. 40. 10. 30.\n",
            " 40. 50. 30. 30. 30. 40.]\n",
            "selection [ 63 507 653 929 860 782 560  77 834   2] (10,) [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "trainset before adding uncertain samples (360, 10) (360,)\n",
            "trainset after adding uncertain samples (370, 10) (370,)\n",
            "updated train set: (370, 10) (370,) unique(labels): [188 182] [0 1]\n",
            "val set: (932, 10) (932,)\n",
            "\n",
            "Train set: (370, 10)\n",
            "Validation set: (932, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 37\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.095 s \n",
            "\n",
            "Accuracy rate is 79.262673 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.88      0.86       321\n",
            "           1       0.61      0.55      0.58       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.73      0.71      0.72       434\n",
            "weighted avg       0.79      0.79      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[282  39]\n",
            " [ 51  62]]\n",
            "--------------------------------\n",
            "val predicted: (932,) [1 0 0 0 1 1 1 0 0 1 0 0 1 1 1 1 0 1 0 1 0 0 1 0 0 1 0 1 1 1 0 1 1 1 0 0 1\n",
            " 1 0 0 0 1 0 1 0 0 0 1 1 1 1 1 0 1 1 1 1 1 0 1 0 0 1 0 0 1 1 1 1 1 1 1 0 1\n",
            " 0 1 0 1 1 0 0 0 0 1 0 0 1 1 1 1 0 1 0 0 0 1 1 1 0 0 1 0 0 1 0 1 0 1 1 1 1\n",
            " 0 1 0 0 1 0 0 1 0 0 1 1 1 1 0 1 1 0 0 1 1 0 0 1 1 1 0 1 1 1 1 1 0 1 0 1 1\n",
            " 0 0 0 1 1 0 1 1 1 0 1 0 0 0 0 1 0 1 1 0 1 1 1 1 0 1 0 1 1 0 1 1 1 0 0 0 1\n",
            " 0 0 1 1 1 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 1 1 0 1 1 0 0 1 1 1 0 0 0 0 0 1 1\n",
            " 0 1 1 1 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 1 0 1 1 0 1 1 1 0 1 1 0 1 0 1 1 1\n",
            " 1 1 0 0 1 1 0 1 0 0 1 1 1 1 1 1 0 0 0 0 0 1 0 1 0 0 1 0 1 0 1 0 1 0 0 1 0\n",
            " 1 0 0 0 0 1 1 1 1 1 1 1 1 0 1 1 0 1 0 1 0 1 0 0 1 1 1 1 0 0 1 0 1 1 0 1 1\n",
            " 0 0 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 0 1 1 0 1 1 1 0 1\n",
            " 1 0 1 0 1 0 1 1 1 1 0 1 1 0 1 0 1 1 1 0 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 0 0\n",
            " 0 1 1 0 1 0 0 1 0 0 0 1 0 1 0 1 1 1 1 0 0 1 0 1 1 1 1 1 0 1 0 1 1 0 0 0 0\n",
            " 0 1 1 1 1 1 1 1 0 0 0 1 1 1 1 0 1 0 0 0 0 1 0 0 0 1 1 0 1 0 0 1 1 1 0 1 0\n",
            " 0 0 1 1 1 0 1 1 1 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 1 0 1 1 0 0 0 0 1 1 0 1\n",
            " 0 1 1 0 1 1 0 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1 1 0 1 1 1\n",
            " 1 1 0 0 0 0 1 1 0 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 0 1 1 1 0 0 1 0 0 0 1 0 0\n",
            " 1 0 1 0 1 1 1 1 0 1 1 0 0 1 1 0 1 1 0 1 1 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0\n",
            " 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 0 1 1 0 0 0 0 1 1 0 1 1 1 0\n",
            " 0 1 1 0 0 1 0 1 1 1 1 0 0 1 1 1 1 0 0 1 0 1 0 1 1 1 1 1 0 0 0 0 0 1 0 1 1\n",
            " 1 0 0 1 0 0 1 0 1 0 1 0 0 0 1 0 1 1 1 0 0 1 0 0 1 0 1 1 1 0 0 0 1 1 0 0 1\n",
            " 0 1 1 1 1 0 0 1 0 0 1 0 0 0 1 0 0 0 1 1 1 1 0 1 0 0 1 0 0 0 0 0 1 1 1 1 1\n",
            " 1 1 1 1 1 0 0 1 0 0 1 0 1 1 1 1 1 0 1 0 0 0 0 1 1 1 1 0 0 0 0 0 1 0 1 0 1\n",
            " 0 1 0 1 1 0 0 1 0 1 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1 0 0 1 0 1 0 1 1 0 0 1 1\n",
            " 1 1 1 1 0 0 1 1 1 1 0 1 1 0 1 1 1 0 0 0 1 0 1 1 1 0 0 0 1 0 1 0 1 0 1 0 1\n",
            " 1 1 1 1 1 0 1 0 1 0 1 1 0 1 0 0 0 1 1 0 1 1 1 1 0 0 0 1 1 0 0 1 1 0 0 1 1\n",
            " 0 1 1 1 0 0 0]\n",
            "probabilities: (932, 2) \n",
            " [1 0 0 0 1 1 1 0 0 1 0 0 1 1 1 1 0 1 0 1 0 0 1 0 0 1 0 1 1 1 0 1 1 1 0 0 1\n",
            " 1 0 0 0 1 0 1 0 0 0 1 1 1 1 1 0 1 1 1 1 1 0 1 0 0 1 0 0 1 1 1 1 1 1 1 0 1\n",
            " 0 1 0 1 1 0 0 0 0 1 0 0 1 1 1 1 0 1 0 0 0 1 1 1 0 0 1 0 0 1 0 1 0 1 1 1 1\n",
            " 0 1 0 0 1 0 0 1 0 0 1 1 1 1 0 1 1 0 0 1 1 0 0 1 1 1 0 1 1 1 1 1 0 1 0 1 1\n",
            " 0 0 0 1 1 0 1 1 1 0 1 0 0 0 0 1 0 1 1 0 1 1 1 1 0 1 0 1 1 0 1 1 1 0 0 0 1\n",
            " 0 0 1 1 1 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 1 1 0 1 1 0 0 1 1 1 0 0 0 0 0 1 1\n",
            " 0 1 1 1 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 1 0 1 1 0 1 1 1 0 1 1 0 1 0 1 1 1\n",
            " 1 1 0 0 1 1 0 1 0 0 1 1 1 1 1 1 0 0 0 0 0 1 0 1 0 0 1 0 1 0 1 0 1 0 0 1 0\n",
            " 1 0 0 0 0 1 1 1 1 1 1 1 1 0 1 1 0 1 0 1 0 1 0 0 1 1 1 1 0 0 1 0 1 1 0 1 1\n",
            " 0 0 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 0 1 1 0 1 1 1 0 1\n",
            " 1 0 1 0 1 0 1 1 1 1 0 1 1 0 1 0 1 1 1 0 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 0 0\n",
            " 0 1 1 0 1 0 0 1 0 0 0 1 0 1 0 1 1 1 1 0 0 1 0 1 1 1 1 1 0 1 0 1 1 0 0 0 0\n",
            " 0 1 1 1 1 1 1 1 0 0 0 1 1 1 1 0 1 0 0 0 0 1 0 0 0 1 1 0 1 0 0 1 1 1 0 1 0\n",
            " 0 0 1 1 1 0 1 1 1 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 1 0 1 1 0 0 0 0 1 1 0 1\n",
            " 0 1 1 0 1 1 0 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1 1 0 1 1 1\n",
            " 1 1 0 0 0 0 1 1 0 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 0 1 1 1 0 0 1 0 0 0 1 0 0\n",
            " 1 0 1 0 1 1 1 1 0 1 1 0 0 1 1 0 1 1 0 1 1 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0\n",
            " 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 0 1 1 0 0 0 0 1 1 0 1 1 1 0\n",
            " 0 1 1 0 0 1 0 1 1 1 1 0 0 1 1 1 1 0 0 1 0 1 0 1 1 1 1 1 0 0 0 0 0 1 0 1 1\n",
            " 1 0 0 1 0 0 1 0 1 0 1 0 0 0 1 0 1 1 1 0 0 1 0 0 1 0 1 1 1 0 0 0 1 1 0 0 1\n",
            " 0 1 1 1 1 0 0 1 0 0 1 0 0 0 1 0 0 0 1 1 1 1 0 1 0 0 1 0 0 0 0 0 1 1 1 1 1\n",
            " 1 1 1 1 1 0 0 1 0 0 1 0 1 1 1 1 1 0 1 0 0 0 0 1 1 1 1 0 0 0 0 0 1 0 1 0 1\n",
            " 0 1 0 1 1 0 0 1 0 1 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1 0 0 1 0 1 0 1 1 0 0 1 1\n",
            " 1 1 1 1 0 0 1 1 1 1 0 1 1 0 1 1 1 0 0 0 1 0 1 1 1 0 0 0 1 0 1 0 1 0 1 0 1\n",
            " 1 1 1 1 1 0 1 0 1 0 1 1 0 1 0 0 0 1 1 0 1 1 1 1 0 0 0 1 1 0 0 1 1 0 0 1 1\n",
            " 0 1 1 1 0 0 0]\n",
            "std (932,) [50. 10.  0.  0. 10. 50. 40. 20. 40. 20. 30. 30. 50. 10. 40. 40. 30. 40.\n",
            " 20. 20. 10. 20. 20. 10. 20. 20. 20. 20. 50. 10. 20. 20. 40. 30. 20. 40.\n",
            " 10. 40. 40. 50. 10. 30. 30. 50. 30. 40. 20. 30. 20. 20. 10. 50. 10. 30.\n",
            " 30. 40. 50. 10. 20. 40. 20. 20. 20. 30. 30. 30. 30. 40. 40. 50. 20. 40.\n",
            " 10. 50. 40. 30. 50. 40. 50. 30. 20. 20. 20. 20. 10. 20. 40. 50. 30. 30.\n",
            " 30. 30. 30. 20. 20. 30. 30. 20. 30. 50. 40. 30. 30. 40. 20. 30. 30. 40.\n",
            " 20. 20. 40. 20. 50. 30. 30. 30. 40. 30. 30. 30. 20. 50. 20. 30. 30. 30.\n",
            " 20. 10. 10. 40. 50. 30. 10. 30. 20. 10. 10. 30. 30. 40. 40. 40. 20. 30.\n",
            " 20. 30. 50. 50. 20. 20. 20. 40. 40. 40. 20. 50. 50. 30. 50. 20. 40. 20.\n",
            " 10. 30. 40. 40. 50. 10. 50. 30. 40. 20. 40. 30. 40. 40. 20. 40. 40. 30.\n",
            " 40. 30. 20. 30. 20. 30. 40. 20. 20. 30. 30. 40. 30. 10. 30. 20. 30. 30.\n",
            " 20. 40. 40. 30.  0. 30. 40. 30. 40. 50. 50. 30. 30. 40. 40. 10. 50. 20.\n",
            " 20. 30. 30. 20. 10. 40. 20. 30. 40. 30. 40. 40. 20. 30. 30. 40. 30. 30.\n",
            " 40. 20. 30. 30. 40. 40. 30. 40. 40. 30. 30. 30. 30. 40. 40. 10. 30. 40.\n",
            " 40. 10. 50. 40. 40. 20. 40. 30. 30. 50. 20. 20. 40. 40. 30. 20. 20. 40.\n",
            " 20. 30. 40. 40. 50. 40. 20. 30. 20. 10. 50. 20. 50. 40. 20. 20. 30. 40.\n",
            " 40. 20. 30. 20. 20. 20. 40. 10. 10. 20. 30. 30. 20. 40. 50. 50. 40. 20.\n",
            " 10. 40. 30. 20. 30. 40. 50. 40. 20. 50. 30. 50. 40. 30. 30. 30. 40. 20.\n",
            " 30. 50. 50. 40. 30. 50. 30. 30. 20. 40. 40. 40. 30. 20. 30. 30. 50. 40.\n",
            " 30. 30. 50. 40. 50. 30. 30. 20. 40. 50. 50. 20. 10. 30. 50. 20. 30. 30.\n",
            " 40. 30. 50. 20. 40. 20. 20. 20. 10. 40. 40. 20. 10. 30. 50. 40. 40. 10.\n",
            " 30. 40. 30. 50. 40. 40. 50. 20. 10. 10. 30. 20. 30. 10. 50. 20. 30. 40.\n",
            " 10. 50. 40. 10. 40. 30. 40. 40. 40. 30. 10. 20. 30. 40. 40. 30. 10. 20.\n",
            " 50. 30. 10. 10. 10. 20. 30. 10. 10. 30. 40. 30. 20. 30. 50. 30. 30. 20.\n",
            " 10. 20. 30. 40. 40. 50. 50. 50. 30. 40. 10. 10. 20. 40. 30. 20. 40. 30.\n",
            " 40. 10. 30. 30. 50. 10. 40. 20. 20. 40. 50. 40. 20. 10. 20. 40. 20. 30.\n",
            " 40. 40. 30. 40. 10. 40. 20. 40. 10. 20. 30. 30. 30. 10. 20. 50. 30. 50.\n",
            " 30. 40. 40. 40. 50. 40. 20. 30. 40. 50. 30. 40. 10. 40. 50. 40. 40. 40.\n",
            " 30. 40. 30. 30. 40. 40. 30. 10. 20. 30. 40. 40. 30. 30. 30. 30. 40. 30.\n",
            " 30. 30. 20. 40. 50. 50. 20. 20. 40. 40. 10. 20. 40. 40. 30. 30. 20. 40.\n",
            " 30. 50. 30. 30. 40. 20. 30. 50. 30. 30. 30. 20. 30. 20. 50. 20. 40. 40.\n",
            " 30.  0. 20. 20. 40. 30. 40. 30. 10. 50. 40. 40. 50. 50. 20. 30. 40. 20.\n",
            " 10. 20. 50. 10. 50. 30. 20. 40. 20. 20. 40.  0. 20. 40. 30. 40. 50. 30.\n",
            " 20. 20. 20. 40. 30. 50.  0. 30. 30. 30. 30. 30. 20. 20. 30. 50. 30. 50.\n",
            " 30. 50. 20. 20. 50. 40. 40. 30. 20. 30. 50. 50. 40. 30. 30. 50. 20. 30.\n",
            " 20. 20. 30. 40. 30. 30. 20. 30. 40. 50. 10. 40. 40. 30. 20. 50. 30. 40.\n",
            " 20. 20. 40. 40. 40. 30. 40. 20. 10. 20. 20. 40. 20. 10. 30. 50. 40. 20.\n",
            " 20. 20. 30. 30. 40. 40. 30. 20. 50. 20. 30. 10. 50. 20. 40. 30. 50. 20.\n",
            " 40. 50. 30. 20. 10. 10. 40. 30. 50. 40. 40. 20. 30. 10. 40. 30. 30. 50.\n",
            " 30. 50. 30. 10. 20. 30. 30. 50. 20. 50. 30. 20. 30. 20. 50. 30. 40. 40.\n",
            " 40. 20. 20. 20. 30. 50. 30. 30. 30. 30. 20. 40. 40. 30. 20. 40. 30. 40.\n",
            " 30. 30. 20. 40. 40. 40. 40. 20. 50. 40. 20. 20. 10. 30. 50. 50. 30. 10.\n",
            " 40. 10. 50. 40. 30. 40. 40. 20. 20. 40. 30. 40. 10. 40. 30. 10. 40. 40.\n",
            " 30. 20. 20. 20. 20. 30. 10. 20. 10. 20. 50. 30. 20. 50. 10. 30. 30. 50.\n",
            " 40. 30. 20. 30. 20. 20. 30. 20. 50. 30. 20. 40. 40. 40. 40. 10. 10. 40.\n",
            " 30. 30. 30. 40. 20. 40. 30. 50. 40. 40. 30. 20. 20. 20. 20. 20. 40. 40.\n",
            " 20. 30. 40. 40. 40. 30. 20. 50. 30. 40. 50. 40. 30. 50.  0. 20. 20. 10.\n",
            " 20.  0. 20. 40. 40. 20. 20. 30. 40. 30. 20. 30. 30. 30. 20. 30. 20. 30.\n",
            " 30. 40. 50. 50. 10. 20. 30. 20. 40. 40. 50. 50. 30. 30. 20. 20. 30. 40.\n",
            " 30. 20. 20. 50. 50. 30. 40. 30. 40. 50. 40. 20. 20. 20. 50. 40. 30. 30.\n",
            " 30. 20. 20. 10. 10. 50. 10. 20. 30. 40. 50. 20. 10. 40. 20. 30. 40. 10.\n",
            " 20. 10. 30. 30. 40. 40. 10. 30. 40. 50. 30. 20. 30. 40.]\n",
            "selection [842   2   3 600 202 847 587 559  84 788] (10,) [ 0.  0.  0.  0.  0.  0.  0.  0. 10. 10.]\n",
            "trainset before adding uncertain samples (370, 10) (370,)\n",
            "trainset after adding uncertain samples (380, 10) (380,)\n",
            "updated train set: (380, 10) (380,) unique(labels): [193 187] [0 1]\n",
            "val set: (922, 10) (922,)\n",
            "\n",
            "Train set: (380, 10)\n",
            "Validation set: (922, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 38\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.103 s \n",
            "\n",
            "Accuracy rate is 79.493088 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.88      0.86       321\n",
            "           1       0.62      0.54      0.58       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.73      0.71      0.72       434\n",
            "weighted avg       0.79      0.79      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[284  37]\n",
            " [ 52  61]]\n",
            "--------------------------------\n",
            "val predicted: (922,) [1 0 0 1 1 0 0 1 0 0 1 1 1 1 0 1 0 1 0 0 1 0 0 1 0 1 1 1 0 1 1 1 0 0 1 1 0\n",
            " 0 0 1 0 1 0 0 0 1 1 1 1 1 0 1 1 1 1 1 0 1 0 0 1 0 0 1 1 1 1 1 1 1 0 1 0 1\n",
            " 0 1 1 0 0 0 0 1 0 1 1 1 1 0 1 0 0 0 1 1 1 0 0 1 0 0 1 0 1 0 1 1 1 1 0 1 0\n",
            " 0 1 0 0 1 0 0 1 1 1 1 0 1 1 0 0 1 1 0 0 1 1 1 0 1 1 1 1 1 0 1 0 1 1 0 0 0\n",
            " 1 1 0 1 1 1 0 1 0 0 0 0 1 0 1 1 0 1 1 1 1 0 1 0 1 1 0 1 1 1 0 0 0 1 0 0 1\n",
            " 1 1 0 0 0 0 0 0 1 0 0 1 0 0 1 0 1 1 0 1 1 0 0 1 1 1 0 0 0 0 0 1 1 0 1 1 1\n",
            " 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 1 0 1 1 0 1 1 1 0 1 1 0 1 0 1 1 1 1 1 0 0\n",
            " 1 1 0 1 0 0 1 1 1 1 1 1 0 0 0 0 0 1 0 1 0 0 1 0 1 0 1 0 1 0 0 1 0 1 0 0 0\n",
            " 0 1 1 1 1 1 1 1 1 0 1 1 0 1 0 1 0 1 0 0 1 1 1 1 0 0 1 0 1 1 0 1 1 0 0 1 1\n",
            " 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 0 1 1 0 1 1 1 0 1 1 0 1 0\n",
            " 1 0 1 1 1 1 0 1 1 0 1 0 1 1 1 0 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 0 0 0 1 1 0\n",
            " 1 0 0 1 0 0 0 1 0 1 0 1 1 1 1 0 0 1 0 1 1 1 1 1 0 1 0 1 1 0 0 0 0 0 1 1 1\n",
            " 1 1 1 1 0 0 0 1 1 1 1 0 1 0 0 0 0 1 0 0 0 1 1 0 0 0 0 1 1 1 0 1 0 0 0 1 1\n",
            " 1 0 1 1 1 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 1 0 1 1 0 0 0 0 1 1 0 1 0 1 1 0\n",
            " 1 1 0 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1 1 0 1 1 1 1 1 0 0\n",
            " 0 1 1 0 1 0 1 1 0 1 1 1 0 1 1 1 0 0 1 0 1 1 1 0 0 1 0 0 1 0 0 1 0 1 0 1 1\n",
            " 1 1 1 1 0 0 1 1 0 1 1 0 1 1 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 0\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 0 1 1 0 0 0 0 1 1 0 1 1 1 0 0 1 1 0 0 1 0\n",
            " 1 1 1 1 0 0 1 1 1 1 0 0 1 0 1 0 1 1 1 1 1 0 0 0 0 0 1 0 1 1 1 0 0 1 0 0 1\n",
            " 0 1 0 1 0 0 0 1 0 1 1 1 0 0 1 0 0 1 0 1 1 1 0 0 0 1 1 0 0 1 0 1 1 1 1 0 0\n",
            " 1 0 0 1 0 0 0 1 0 0 0 1 1 1 1 0 1 0 0 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 0\n",
            " 1 0 0 1 1 1 1 1 1 0 1 0 0 0 0 1 1 1 1 0 0 0 0 0 1 0 1 0 1 0 1 0 1 1 0 0 1\n",
            " 0 1 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1 0 0 1 1 0 0 1 0 1 1 1 1 1 1 0 0 1 1 1 1\n",
            " 0 1 1 0 1 1 1 0 0 0 1 0 1 1 1 0 0 0 1 0 1 0 1 0 1 0 1 1 1 1 1 1 0 1 0 1 0\n",
            " 1 1 0 1 0 0 0 1 1 0 1 1 1 1 0 0 0 1 1 0 0 1 1 0 0 1 1 0 1 1 1 0 0 0]\n",
            "probabilities: (922, 2) \n",
            " [1 0 0 1 1 0 0 1 0 0 1 1 1 1 0 1 0 1 0 0 1 0 0 1 0 1 1 1 0 1 1 1 0 0 1 1 0\n",
            " 0 0 1 0 1 0 0 0 1 1 1 1 1 0 1 1 1 1 1 0 1 0 0 1 0 0 1 1 1 1 1 1 1 0 1 0 1\n",
            " 0 1 1 0 0 0 0 1 0 1 1 1 1 0 1 0 0 0 1 1 1 0 0 1 0 0 1 0 1 0 1 1 1 1 0 1 0\n",
            " 0 1 0 0 1 0 0 1 1 1 1 0 1 1 0 0 1 1 0 0 1 1 1 0 1 1 1 1 1 0 1 0 1 1 0 0 0\n",
            " 1 1 0 1 1 1 0 1 0 0 0 0 1 0 1 1 0 1 1 1 1 0 1 0 1 1 0 1 1 1 0 0 0 1 0 0 1\n",
            " 1 1 0 0 0 0 0 0 1 0 0 1 0 0 1 0 1 1 0 1 1 0 0 1 1 1 0 0 0 0 0 1 1 0 1 1 1\n",
            " 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 1 0 1 1 0 1 1 1 0 1 1 0 1 0 1 1 1 1 1 0 0\n",
            " 1 1 0 1 0 0 1 1 1 1 1 1 0 0 0 0 0 1 0 1 0 0 1 0 1 0 1 0 1 0 0 1 0 1 0 0 0\n",
            " 0 1 1 1 1 1 1 1 1 0 1 1 0 1 0 1 0 1 0 0 1 1 1 1 0 0 1 0 1 1 0 1 1 0 0 1 1\n",
            " 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 0 1 1 0 1 1 1 0 1 1 0 1 0\n",
            " 1 0 1 1 1 1 0 1 1 0 1 0 1 1 1 0 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 0 0 0 1 1 0\n",
            " 1 0 0 1 0 0 0 1 0 1 0 1 1 1 1 0 0 1 0 1 1 1 1 1 0 1 0 1 1 0 0 0 0 0 1 1 1\n",
            " 1 1 1 1 0 0 0 1 1 1 1 0 1 0 0 0 0 1 0 0 0 1 1 0 0 0 0 1 1 1 0 1 0 0 0 1 1\n",
            " 1 0 1 1 1 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 1 0 1 1 0 0 0 0 1 1 0 1 0 1 1 0\n",
            " 1 1 0 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1 1 0 1 1 1 1 1 0 0\n",
            " 0 1 1 0 1 0 1 1 0 1 1 1 0 1 1 1 0 0 1 0 1 1 1 0 0 1 0 0 1 0 0 1 0 1 0 1 1\n",
            " 1 1 1 1 0 0 1 1 0 1 1 0 1 1 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 0\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 0 1 1 0 0 0 0 1 1 0 1 1 1 0 0 1 1 0 0 1 0\n",
            " 1 1 1 1 0 0 1 1 1 1 0 0 1 0 1 0 1 1 1 1 1 0 0 0 0 0 1 0 1 1 1 0 0 1 0 0 1\n",
            " 0 1 0 1 0 0 0 1 0 1 1 1 0 0 1 0 0 1 0 1 1 1 0 0 0 1 1 0 0 1 0 1 1 1 1 0 0\n",
            " 1 0 0 1 0 0 0 1 0 0 0 1 1 1 1 0 1 0 0 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 0\n",
            " 1 0 0 1 1 1 1 1 1 0 1 0 0 0 0 1 1 1 1 0 0 0 0 0 1 0 1 0 1 0 1 0 1 1 0 0 1\n",
            " 0 1 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1 0 0 1 1 0 0 1 0 1 1 1 1 1 1 0 0 1 1 1 1\n",
            " 0 1 1 0 1 1 1 0 0 0 1 0 1 1 1 0 0 0 1 0 1 0 1 0 1 0 1 1 1 1 1 1 0 1 0 1 0\n",
            " 1 1 0 1 0 0 0 1 1 0 1 1 1 1 0 0 0 1 1 0 0 1 1 0 0 1 1 0 1 1 1 0 0 0]\n",
            "std (922,) [50. 10.  0. 50. 40. 20. 40. 20. 30. 30. 50. 20. 40. 40. 30. 40. 20. 20.\n",
            " 20. 10. 20. 20. 20. 20. 20. 20. 50. 10. 20. 20. 40. 30. 10. 40. 10. 40.\n",
            " 40. 50. 20. 30. 30. 50. 20. 40. 10. 30. 20. 20. 10. 50. 10. 30. 40. 40.\n",
            " 50. 10. 20. 40. 20. 20. 20. 30. 40. 30. 20. 40. 30. 50. 10. 40. 10. 50.\n",
            " 30. 30. 50. 40. 50. 30. 30. 30. 20. 30. 20. 40. 50. 40. 30. 30. 20. 30.\n",
            " 20. 20. 30. 30. 20. 30. 50. 40. 40. 30. 40. 30. 20. 30. 40. 20. 20. 40.\n",
            " 20. 40. 30. 30. 30. 40. 30. 30. 30. 20. 50. 20. 20. 40. 30. 20. 10. 10.\n",
            " 40. 50. 30. 20. 30. 10. 10. 20. 30. 20. 40. 40. 40. 20. 30. 30. 30. 50.\n",
            " 50. 10. 20. 20. 40. 40. 40. 20. 50. 50. 30. 50. 20. 40. 20. 10. 30. 40.\n",
            " 40. 40. 10. 50. 30. 40. 20. 40. 30. 40. 40. 20. 30. 40. 30. 40. 30. 20.\n",
            " 30. 20. 40. 40. 20. 20. 30. 30. 40. 30. 10. 30. 20. 30. 30. 20. 40. 40.\n",
            " 30. 20. 30. 30. 40. 50. 50. 30. 30. 40. 40. 10. 50. 20. 20. 50. 40. 30.\n",
            " 10. 50. 20. 30. 40. 30. 40. 40. 20. 30. 40. 40. 30. 30. 50. 20. 20. 30.\n",
            " 40. 40. 30. 40. 40. 30. 30. 30. 30. 40. 40. 10. 30. 40. 30. 20. 50. 40.\n",
            " 40. 30. 40. 30. 30. 50. 20. 20. 40. 40. 30. 20. 30. 40. 20. 30. 40. 40.\n",
            " 50. 40. 20. 30. 20. 20. 50. 20. 50. 30. 30. 20. 30. 40. 40. 20. 20. 20.\n",
            " 20. 20. 40. 10. 10. 20. 30. 40. 20. 40. 30. 50. 40. 20. 10. 40. 30. 20.\n",
            " 30. 40. 50. 40. 20. 50. 30. 50. 30. 40. 30. 30. 40. 20. 30. 50. 50. 40.\n",
            " 30. 50. 30. 30. 20. 40. 40. 50. 20. 20. 30. 30. 50. 40. 30. 30. 50. 40.\n",
            " 50. 30. 30. 20. 40. 50. 50. 20. 10. 20. 50. 30. 30. 30. 40. 40. 50. 20.\n",
            " 40. 20. 20. 20. 10. 50. 40. 20. 20. 30. 50. 40. 40. 10. 40. 40. 30. 50.\n",
            " 40. 40. 50. 20. 10. 10. 30. 20. 30. 10. 50. 20. 30. 30. 20. 50. 30. 10.\n",
            " 40. 30. 40. 40. 40. 30. 20. 20. 30. 40. 40. 30. 20. 20. 50. 30. 10. 10.\n",
            " 10. 20. 30. 20. 20. 30. 40. 30. 30. 30. 50. 30. 30. 20. 10. 20. 30. 40.\n",
            " 40. 50. 50. 50. 30. 50. 10. 10. 10. 40. 40. 20. 40. 20. 50. 10. 30. 30.\n",
            " 50. 10. 40. 30. 10. 40. 50. 40. 20. 20. 20. 40. 20. 30. 50. 40. 30. 30.\n",
            "  0. 40. 20. 40. 10. 20. 30. 30. 40. 10. 20. 50. 30. 50. 30. 40. 40. 40.\n",
            " 50. 40. 20. 30. 40. 50. 30. 40. 20. 40. 50. 40. 40. 40. 30. 40. 20. 30.\n",
            " 40. 40. 30. 10. 20. 40. 40. 40. 30. 30. 30. 30. 40. 20. 30. 30. 20. 40.\n",
            " 50. 50. 30. 20. 40. 50. 20. 10. 40. 40. 30. 30. 20. 40. 30. 50. 30. 30.\n",
            " 40. 10. 30. 50. 30. 30. 30. 20. 30. 20. 50. 20. 40. 40. 30. 20. 20. 40.\n",
            " 30. 40. 30. 10. 50. 40. 40. 50. 50. 30. 30. 40. 20.  0. 20. 50. 10. 50.\n",
            " 30. 20. 40. 20. 20. 40. 20. 40. 30. 40. 50. 20. 10. 30. 10. 40. 30. 50.\n",
            " 30. 30. 30. 30. 30. 20. 20. 30. 50. 30. 50. 30. 50. 20. 30. 50. 30. 40.\n",
            " 40. 20. 30. 50. 50. 30. 30. 30. 50. 20. 30. 20. 20. 30. 40. 30. 30. 20.\n",
            " 30. 40. 50. 10. 40. 40. 10. 20. 50. 30. 30. 20. 20. 40. 40. 40. 30. 40.\n",
            " 10. 20. 20. 20. 40. 20. 10. 30. 50. 50. 20. 20. 20. 30. 40. 50. 40. 40.\n",
            " 20. 50. 20. 20. 10. 50. 20. 40. 20. 50. 20. 40. 50. 30. 30. 10. 30. 40.\n",
            " 30. 50. 40. 40. 20. 40. 10. 40. 30. 20. 40. 30. 50. 30. 20. 10. 30. 40.\n",
            " 50. 20. 40. 30. 20. 30. 20. 50. 30. 30. 40. 40. 20. 10. 30. 30. 50. 30.\n",
            " 30. 20. 30. 20. 40. 40. 30. 20. 40. 30. 40. 30. 30. 20. 40. 40. 40. 40.\n",
            " 20. 50. 40. 20. 30. 10. 30. 50. 50. 30. 10. 40. 20. 50. 40. 30. 40. 40.\n",
            " 20. 20. 40. 30. 40. 10. 40. 20. 10. 40. 40. 30. 20. 20. 20. 20. 20. 10.\n",
            " 20. 10. 20. 50. 30. 20. 40. 30. 30. 50. 40. 30. 30. 30. 20. 20. 30. 20.\n",
            " 50. 30. 20. 40. 40. 40. 40. 20. 10. 40. 30. 30. 20. 40. 20. 40. 30. 50.\n",
            " 40. 30. 30. 20. 30. 20. 20. 20. 40. 40. 20. 30. 30. 40. 40. 30. 20. 50.\n",
            " 40. 40. 50. 40. 30. 50. 30. 20.  0. 10. 20. 40. 40. 20. 20. 30. 40. 20.\n",
            " 20. 30. 30. 30. 20. 30. 20. 30. 30. 40. 50. 50. 10. 20. 30. 20. 30. 40.\n",
            " 50. 50. 30. 30. 20. 20. 30. 40. 30. 20. 20. 50. 50. 30. 40. 30. 40. 50.\n",
            " 40. 20. 30. 20. 40. 40. 30. 30. 30. 10. 20. 10. 10. 50. 10. 20. 20. 40.\n",
            " 50. 20. 10. 40. 20. 20. 30. 10. 20. 30. 30. 20. 40. 40. 10. 30. 40. 50.\n",
            " 30. 20. 30. 40.]\n",
            "selection [  2 836 571 468 636 124 743 412 413 414] (10,) [ 0.  0.  0.  0. 10. 10. 10. 10. 10. 10.]\n",
            "trainset before adding uncertain samples (380, 10) (380,)\n",
            "trainset after adding uncertain samples (390, 10) (390,)\n",
            "updated train set: (390, 10) (390,) unique(labels): [197 193] [0 1]\n",
            "val set: (912, 10) (912,)\n",
            "\n",
            "Train set: (390, 10)\n",
            "Validation set: (912, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 39\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.106 s \n",
            "\n",
            "Accuracy rate is 79.723502 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.88      0.87       321\n",
            "           1       0.62      0.56      0.59       113\n",
            "\n",
            "    accuracy                           0.80       434\n",
            "   macro avg       0.74      0.72      0.73       434\n",
            "weighted avg       0.79      0.80      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[283  38]\n",
            " [ 50  63]]\n",
            "--------------------------------\n",
            "val predicted: (912,) [1 0 1 1 0 0 1 0 0 1 1 1 1 0 1 0 1 0 0 1 0 0 1 0 1 1 1 0 1 1 1 0 0 1 1 0 0\n",
            " 0 1 0 1 0 0 0 1 1 1 1 1 0 1 1 1 1 1 0 1 0 0 1 0 0 1 1 1 1 1 1 1 0 1 0 1 0\n",
            " 1 1 0 0 0 0 1 0 1 1 1 1 0 1 0 0 0 1 1 1 0 0 1 0 0 1 0 1 0 1 1 1 1 0 1 0 0\n",
            " 1 0 0 1 0 0 1 1 1 1 0 1 0 0 1 1 0 0 1 1 1 0 1 1 1 1 1 0 1 0 1 1 0 0 0 1 1\n",
            " 0 1 1 1 0 1 0 0 0 0 1 0 1 1 0 1 1 1 1 0 1 0 1 1 0 1 1 1 0 0 0 1 0 0 1 1 1\n",
            " 0 0 0 0 0 0 1 0 0 1 0 0 1 0 1 1 0 1 1 0 0 1 0 1 0 0 0 0 0 1 1 0 1 1 1 1 1\n",
            " 1 1 1 0 0 1 1 0 1 0 1 1 1 1 1 0 1 1 0 1 1 1 0 1 1 0 1 0 1 1 1 1 1 0 0 1 1\n",
            " 0 1 0 0 1 1 1 1 1 1 0 0 0 0 0 1 0 1 0 0 1 0 1 0 1 0 1 0 0 1 0 1 0 0 0 0 1\n",
            " 1 1 1 1 1 1 1 0 1 1 0 1 0 1 0 1 0 0 1 1 1 1 0 0 1 0 1 1 0 1 1 0 0 1 1 1 1\n",
            " 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 0 1 1 0 1 1 1 0 1 1 0 1 0 1 0\n",
            " 1 1 1 1 0 1 1 0 1 0 1 1 1 0 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 0 0 0 1 1 0 1 0\n",
            " 0 1 0 0 1 0 1 1 1 1 0 0 1 0 1 1 1 1 1 0 1 0 1 1 0 0 0 0 0 1 1 1 1 1 1 1 0\n",
            " 0 0 1 1 1 1 0 1 0 0 0 0 1 0 0 0 1 1 0 0 0 1 1 1 0 1 0 0 0 1 1 1 0 1 1 1 1\n",
            " 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 1 0 1 1 0 0 0 0 1 1 0 1 0 1 1 0 1 1 0 1 0 1\n",
            " 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1 1 0 1 1 1 1 1 0 0 0 1 1 0 1 0\n",
            " 1 1 0 1 1 1 0 1 1 1 0 1 0 1 1 1 0 0 1 0 0 1 0 0 1 0 1 0 1 1 1 1 1 1 0 0 1\n",
            " 1 0 1 1 0 1 1 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1\n",
            " 1 1 1 1 0 0 0 1 0 1 1 0 0 0 0 1 1 0 1 1 1 0 0 1 1 0 0 1 0 1 1 1 1 0 0 1 1\n",
            " 1 1 0 0 1 0 1 0 1 1 1 1 1 0 0 0 0 0 1 0 1 1 1 0 0 1 0 0 1 0 1 0 1 0 0 0 1\n",
            " 0 1 1 1 0 0 1 0 0 1 0 1 1 1 0 0 0 1 1 0 0 1 0 1 1 1 1 0 0 1 0 0 0 0 0 1 0\n",
            " 0 0 1 1 1 1 0 1 0 0 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0 1 1 1 1 1 1\n",
            " 0 1 0 0 0 0 1 1 1 1 0 0 0 0 0 1 0 1 0 1 0 1 0 1 1 0 0 1 0 1 0 1 1 0 0 1 0\n",
            " 1 1 1 1 0 1 1 1 0 0 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 1 0 1 1 0 1 1 1 0 0 0\n",
            " 1 0 1 1 1 0 0 0 1 0 1 0 1 0 1 0 1 1 1 1 1 1 0 1 0 1 0 1 1 0 1 0 0 0 1 1 0\n",
            " 1 1 1 1 0 0 0 1 1 0 0 1 1 0 0 1 1 0 1 1 1 0 0 0]\n",
            "probabilities: (912, 2) \n",
            " [1 0 1 1 0 0 1 0 0 1 1 1 1 0 1 0 1 0 0 1 0 0 1 0 1 1 1 0 1 1 1 0 0 1 1 0 0\n",
            " 0 1 0 1 0 0 0 1 1 1 1 1 0 1 1 1 1 1 0 1 0 0 1 0 0 1 1 1 1 1 1 1 0 1 0 1 0\n",
            " 1 1 0 0 0 0 1 0 1 1 1 1 0 1 0 0 0 1 1 1 0 0 1 0 0 1 0 1 0 1 1 1 1 0 1 0 0\n",
            " 1 0 0 1 0 0 1 1 1 1 0 1 0 0 1 1 0 0 1 1 1 0 1 1 1 1 1 0 1 0 1 1 0 0 0 1 1\n",
            " 0 1 1 1 0 1 0 0 0 0 1 0 1 1 0 1 1 1 1 0 1 0 1 1 0 1 1 1 0 0 0 1 0 0 1 1 1\n",
            " 0 0 0 0 0 0 1 0 0 1 0 0 1 0 1 1 0 1 1 0 0 1 0 1 0 0 0 0 0 1 1 0 1 1 1 1 1\n",
            " 1 1 1 0 0 1 1 0 1 0 1 1 1 1 1 0 1 1 0 1 1 1 0 1 1 0 1 0 1 1 1 1 1 0 0 1 1\n",
            " 0 1 0 0 1 1 1 1 1 1 0 0 0 0 0 1 0 1 0 0 1 0 1 0 1 0 1 0 0 1 0 1 0 0 0 0 1\n",
            " 1 1 1 1 1 1 1 0 1 1 0 1 0 1 0 1 0 0 1 1 1 1 0 0 1 0 1 1 0 1 1 0 0 1 1 1 1\n",
            " 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 0 1 1 0 1 1 1 0 1 1 0 1 0 1 0\n",
            " 1 1 1 1 0 1 1 0 1 0 1 1 1 0 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 0 0 0 1 1 0 1 0\n",
            " 0 1 0 0 1 0 1 1 1 1 0 0 1 0 1 1 1 1 1 0 1 0 1 1 0 0 0 0 0 1 1 1 1 1 1 1 0\n",
            " 0 0 1 1 1 1 0 1 0 0 0 0 1 0 0 0 1 1 0 0 0 1 1 1 0 1 0 0 0 1 1 1 0 1 1 1 1\n",
            " 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 1 0 1 1 0 0 0 0 1 1 0 1 0 1 1 0 1 1 0 1 0 1\n",
            " 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1 1 0 1 1 1 1 1 0 0 0 1 1 0 1 0\n",
            " 1 1 0 1 1 1 0 1 1 1 0 1 0 1 1 1 0 0 1 0 0 1 0 0 1 0 1 0 1 1 1 1 1 1 0 0 1\n",
            " 1 0 1 1 0 1 1 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1\n",
            " 1 1 1 1 0 0 0 1 0 1 1 0 0 0 0 1 1 0 1 1 1 0 0 1 1 0 0 1 0 1 1 1 1 0 0 1 1\n",
            " 1 1 0 0 1 0 1 0 1 1 1 1 1 0 0 0 0 0 1 0 1 1 1 0 0 1 0 0 1 0 1 0 1 0 0 0 1\n",
            " 0 1 1 1 0 0 1 0 0 1 0 1 1 1 0 0 0 1 1 0 0 1 0 1 1 1 1 0 0 1 0 0 0 0 0 1 0\n",
            " 0 0 1 1 1 1 0 1 0 0 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0 1 1 1 1 1 1\n",
            " 0 1 0 0 0 0 1 1 1 1 0 0 0 0 0 1 0 1 0 1 0 1 0 1 1 0 0 1 0 1 0 1 1 0 0 1 0\n",
            " 1 1 1 1 0 1 1 1 0 0 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 1 0 1 1 0 1 1 1 0 0 0\n",
            " 1 0 1 1 1 0 0 0 1 0 1 0 1 0 1 0 1 1 1 1 1 1 0 1 0 1 0 1 1 0 1 0 0 0 1 1 0\n",
            " 1 1 1 1 0 0 0 1 1 0 0 1 1 0 0 1 1 0 1 1 1 0 0 0]\n",
            "std (912,) [50. 10. 50. 40. 20. 30. 20. 30. 30. 50. 20. 40. 40. 40. 30. 20. 20. 10.\n",
            " 20. 20. 10. 30. 20. 20. 10. 40. 20. 20. 10. 40. 30. 10. 40. 20. 40. 40.\n",
            " 50. 20. 30. 30. 40. 10. 50. 10. 30. 20. 10. 10. 40. 20. 30. 40. 40. 40.\n",
            " 10. 30. 40. 20. 20. 10. 30. 30. 30. 20. 40. 30. 50. 20. 40. 10. 50. 30.\n",
            " 30. 40. 40. 40. 30. 30. 30. 20. 30. 30. 40. 50. 30. 40. 30. 20. 30. 20.\n",
            " 20. 30. 30. 20. 30. 50. 40. 30. 30. 40. 40. 20. 30. 40. 20. 20. 30. 20.\n",
            " 30. 30. 30. 30. 40. 50. 40. 30. 20. 50. 20. 20. 30. 30. 20. 10. 50. 50.\n",
            " 30. 20. 30. 10. 20. 30. 20. 30. 40. 40. 30. 20. 30. 30. 30. 50. 50. 20.\n",
            " 20. 20. 40. 40. 30. 20. 50. 50. 30. 40. 20. 40. 20. 10. 30. 40. 40. 40.\n",
            " 10. 50. 30. 40. 20. 40. 30. 30. 40. 20. 30. 40. 30. 30. 30. 20. 30. 20.\n",
            " 30. 40. 20. 20. 30. 30. 40. 30. 10. 30. 20. 30. 30. 30. 40. 40. 30. 20.\n",
            " 40. 30. 40. 50. 50. 30. 30. 40. 40.  0. 40. 20. 30. 30. 40. 20. 10. 50.\n",
            " 20. 30. 40. 30. 40. 40. 20. 30. 40. 40. 30. 30. 40. 20. 30. 30. 50. 40.\n",
            " 40. 30. 30. 30. 30. 30. 30. 30. 30. 20. 20. 30. 40. 20. 50. 30. 40. 30.\n",
            " 30. 20. 30. 40. 20. 20. 40. 40. 30. 20. 30. 40. 20. 30. 40. 40. 50. 40.\n",
            " 20. 30. 20. 20. 50. 20. 50. 40. 30. 10. 30. 30. 40. 20. 40. 10. 30. 20.\n",
            " 40. 10. 10. 20. 30. 40. 20. 40. 40. 50. 40. 30. 20. 40. 30. 20. 30. 40.\n",
            " 40. 30. 20. 50. 30. 50. 40. 40. 30. 40. 40. 20. 30. 50. 50. 40. 30. 50.\n",
            " 30. 30. 20. 40. 40. 40. 50. 20. 40. 40. 40. 40. 40. 30. 50. 30. 50. 20.\n",
            " 30. 30. 40. 50. 50. 20. 10. 30. 50. 30. 30. 30. 40. 40. 50. 20. 40. 20.\n",
            " 20. 20. 10. 50. 30. 20. 20. 20. 50. 40. 40. 10. 40. 30. 30. 40. 40. 40.\n",
            " 50. 20. 10. 10. 30. 10. 30. 10. 50. 20. 30. 40. 20. 50. 40. 10. 40. 20.\n",
            " 40. 40. 40. 20. 20. 20. 30. 30. 40. 30. 20. 20. 50. 30. 20. 20. 20. 10.\n",
            " 30. 40. 40. 30. 30. 40. 20. 30. 20. 10. 30. 30. 40. 30. 50. 40. 50. 30.\n",
            " 40. 20. 10. 10. 40. 40. 20. 30. 20. 50. 10. 30. 30. 50. 20. 40. 20. 10.\n",
            " 40. 50. 40. 20. 10. 20. 50. 20. 30. 50. 40. 30. 40. 30. 20. 40. 10. 30.\n",
            " 30. 30. 40. 10. 20. 50. 30. 50. 30. 40. 40. 50. 40. 40. 20. 30. 40. 50.\n",
            " 30. 40. 30. 30. 50. 40. 30. 40. 20. 40. 20. 30. 40. 40. 30. 10. 30. 40.\n",
            " 40. 40. 20. 40. 30. 20. 40. 20. 30. 40. 20. 40. 40. 50. 30. 20. 30. 50.\n",
            " 10. 30. 40. 40. 30. 30. 20. 40. 20. 50. 30. 40. 40. 10. 30. 50. 30. 30.\n",
            " 30. 10. 30. 20. 50. 20. 40. 40. 40. 20. 30. 40. 30. 30. 20. 20. 50. 40.\n",
            " 40. 50. 50. 30. 30. 40. 30. 10. 50. 10. 50. 40. 30. 30. 20. 20. 40. 20.\n",
            " 40. 40. 40. 50. 20. 40. 30. 20. 40. 40. 50. 30. 30. 30. 30. 30. 10. 20.\n",
            " 30. 50. 30. 50. 40. 50. 10. 30. 50. 30. 40. 40. 20. 20. 40. 50. 30. 30.\n",
            " 20. 50. 20. 30. 30. 10. 30. 30. 30. 30. 30. 30. 40. 50. 20. 40. 40. 30.\n",
            " 50. 30. 30. 20. 20. 40. 40. 40. 30. 40.  0. 10. 20. 20. 40. 30. 10. 30.\n",
            " 50. 50. 20. 20. 20. 30. 40. 40. 50. 40. 10. 50. 20. 20. 10. 50. 20. 40.\n",
            " 20. 50. 20. 40. 50. 30. 40. 10. 30. 40. 30. 50. 40. 40. 20. 40. 20. 50.\n",
            " 20. 20. 40. 30. 50. 30. 20. 30. 40. 40. 50. 20. 50. 30. 20. 30. 20. 50.\n",
            " 30. 40. 40. 40. 20. 20. 20. 30. 40. 30. 30. 10. 30. 20. 40. 40. 40. 20.\n",
            " 40. 30. 40. 40. 30. 20. 50. 40. 40. 40. 20. 40. 30. 20. 30. 40. 40. 50.\n",
            " 30.  0. 30. 20. 50. 40. 30. 40. 40. 20. 20. 40. 30. 40. 10. 40. 20. 10.\n",
            " 40. 40. 30. 20. 30. 20. 20. 30. 10. 20.  0. 30. 50. 30. 20. 40. 20. 30.\n",
            " 50. 40. 30. 20. 30. 30. 20. 30. 20. 50. 30. 20. 40. 40. 40. 30. 20. 10.\n",
            " 40. 30. 20. 20. 40. 10. 40. 30. 50. 40. 30. 30. 20. 30. 20. 20. 20. 40.\n",
            " 40. 20. 30. 30. 50. 30. 30. 20. 50. 40. 40. 50. 40. 30. 50. 20. 20. 20.\n",
            " 20. 40. 40. 20. 20. 30. 30. 20. 20. 30. 30. 30. 20. 30. 30. 30. 40. 40.\n",
            " 50. 50. 10. 20. 30. 20. 30. 40. 50. 50. 30. 30. 20. 20. 30. 40. 30. 30.\n",
            " 20. 40. 50. 20. 40. 30. 40. 50. 40. 20. 30. 20. 50. 30. 30. 30. 30. 10.\n",
            " 20. 10. 10. 50. 10. 20. 20. 40. 40. 20. 10. 40. 20. 20. 30. 10. 20. 30.\n",
            " 30. 20. 40. 40. 20. 40. 40. 50. 30. 30. 30. 40.]\n",
            "selection [766 739 207 640 883 884 423 886  69 413] (10,) [ 0.  0.  0.  0. 10. 10. 10. 10. 10. 10.]\n",
            "trainset before adding uncertain samples (390, 10) (390,)\n",
            "trainset after adding uncertain samples (400, 10) (400,)\n",
            "updated train set: (400, 10) (400,) unique(labels): [202 198] [0 1]\n",
            "val set: (902, 10) (902,)\n",
            "\n",
            "Train set: (400, 10)\n",
            "Validation set: (902, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 40\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.067 s \n",
            "\n",
            "Accuracy rate is 80.875576 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.89      0.87       321\n",
            "           1       0.65      0.58      0.61       113\n",
            "\n",
            "    accuracy                           0.81       434\n",
            "   macro avg       0.75      0.73      0.74       434\n",
            "weighted avg       0.80      0.81      0.80       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[286  35]\n",
            " [ 48  65]]\n",
            "--------------------------------\n",
            "val predicted: (902,) [1 0 1 1 0 0 1 0 0 1 1 1 1 0 1 0 1 0 0 1 0 0 1 0 1 1 1 0 1 1 1 0 0 1 1 0 0\n",
            " 0 1 0 1 0 0 0 1 1 1 1 1 0 1 1 1 1 1 0 1 0 0 1 0 0 1 1 1 1 1 1 1 1 0 1 0 1\n",
            " 1 0 0 0 0 1 0 1 1 1 1 0 1 0 0 0 1 1 1 0 0 1 0 0 1 0 1 0 1 1 1 1 0 1 0 0 1\n",
            " 0 0 1 0 0 1 1 1 1 0 1 0 0 1 1 0 0 1 1 1 0 1 1 1 1 1 0 1 0 1 1 0 0 0 1 1 0\n",
            " 1 1 1 0 1 0 0 0 0 1 0 1 1 0 1 1 1 1 0 1 0 1 1 0 1 1 1 0 0 0 1 0 0 1 1 1 0\n",
            " 0 0 0 0 0 1 0 0 1 0 0 1 0 1 1 0 1 1 0 0 1 1 0 0 0 0 0 1 1 0 1 1 1 1 1 1 1\n",
            " 1 0 0 1 1 0 1 0 1 1 1 1 1 0 1 1 0 1 1 1 0 1 1 0 1 0 1 1 1 1 1 0 0 1 1 0 1\n",
            " 0 0 1 1 1 1 1 1 0 0 0 0 0 1 0 1 0 0 1 0 1 0 1 0 1 0 0 1 0 1 0 0 0 0 1 1 1\n",
            " 1 1 1 1 1 0 1 1 0 1 0 1 0 1 0 0 1 1 1 1 0 0 1 0 1 1 0 1 1 0 0 1 1 1 1 1 0\n",
            " 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 0 1 1 0 1 1 1 0 1 1 0 1 0 1 0 1 1\n",
            " 1 1 0 1 1 0 1 0 1 1 1 0 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 0 0 0 1 1 0 1 0 0 1\n",
            " 0 0 1 0 1 1 1 0 0 1 0 1 1 1 1 0 1 0 1 1 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 1 1\n",
            " 1 1 0 1 0 0 0 0 1 0 0 0 1 1 0 0 0 1 1 1 0 1 0 0 0 1 1 1 0 1 1 1 1 1 1 1 1\n",
            " 0 0 1 1 0 1 0 1 1 1 1 1 0 1 1 0 0 0 0 1 1 0 1 0 1 1 0 1 1 0 1 0 1 1 1 1 1\n",
            " 0 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1 1 0 1 1 1 1 1 0 0 0 1 1 0 1 0 1 1 0 1\n",
            " 1 1 0 1 1 1 0 1 0 1 1 1 0 0 1 0 0 1 0 0 1 0 1 0 1 1 1 1 1 1 0 0 1 1 0 1 1\n",
            " 0 1 1 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1\n",
            " 0 0 0 1 0 1 1 0 0 0 1 1 0 1 1 1 0 0 1 1 0 0 1 0 1 1 1 1 0 0 1 1 1 1 0 0 1\n",
            " 0 1 0 1 1 1 1 1 0 0 0 0 0 1 0 1 1 1 0 0 1 0 0 1 0 1 0 1 0 0 0 1 0 1 1 1 0\n",
            " 0 1 0 0 1 0 1 1 1 0 0 0 1 1 0 0 1 0 1 1 1 1 0 0 1 0 0 0 0 0 1 0 0 1 1 1 1\n",
            " 0 1 0 0 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 0 1 0 0 0 0 1\n",
            " 1 1 1 0 0 0 0 0 1 0 1 0 1 0 1 0 1 1 0 0 1 0 1 0 1 1 0 0 1 0 1 1 1 1 0 1 1\n",
            " 1 0 0 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 1 0 1 1 0 1 1 1 0 0 0 1 0 1 1 1 0 0\n",
            " 0 1 0 1 0 1 0 1 0 1 1 1 1 1 1 0 1 0 1 0 1 1 0 1 0 1 0 1 1 1 1 0 0 0 1 1 0\n",
            " 0 1 1 0 0 1 1 0 1 1 1 0 0 0]\n",
            "probabilities: (902, 2) \n",
            " [1 0 1 1 0 0 1 0 0 1 1 1 1 0 1 0 1 0 0 1 0 0 1 0 1 1 1 0 1 1 1 0 0 1 1 0 0\n",
            " 0 1 0 1 0 0 0 1 1 1 1 1 0 1 1 1 1 1 0 1 0 0 1 0 0 1 1 1 1 1 1 1 1 0 1 0 1\n",
            " 1 0 0 0 0 1 0 1 1 1 1 0 1 0 0 0 1 1 1 0 0 1 0 0 1 0 1 0 1 1 1 1 0 1 0 0 1\n",
            " 0 0 1 0 0 1 1 1 1 0 1 0 0 1 1 0 0 1 1 1 0 1 1 1 1 1 0 1 0 1 1 0 0 0 1 1 0\n",
            " 1 1 1 0 1 0 0 0 0 1 0 1 1 0 1 1 1 1 0 1 0 1 1 0 1 1 1 0 0 0 1 0 0 1 1 1 0\n",
            " 0 0 0 0 0 1 0 0 1 0 0 1 0 1 1 0 1 1 0 0 1 1 0 0 0 0 0 1 1 0 1 1 1 1 1 1 1\n",
            " 1 0 0 1 1 0 1 0 1 1 1 1 1 0 1 1 0 1 1 1 0 1 1 0 1 0 1 1 1 1 1 0 0 1 1 0 1\n",
            " 0 0 1 1 1 1 1 1 0 0 0 0 0 1 0 1 0 0 1 0 1 0 1 0 1 0 0 1 0 1 0 0 0 0 1 1 1\n",
            " 1 1 1 1 1 0 1 1 0 1 0 1 0 1 0 0 1 1 1 1 0 0 1 0 1 1 0 1 1 0 0 1 1 1 1 1 0\n",
            " 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 0 1 1 0 1 1 1 0 1 1 0 1 0 1 0 1 1\n",
            " 1 1 0 1 1 0 1 0 1 1 1 0 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 0 0 0 1 1 0 1 0 0 1\n",
            " 0 0 1 0 1 1 1 0 0 1 0 1 1 1 1 0 1 0 1 1 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 1 1\n",
            " 1 1 0 1 0 0 0 0 1 0 0 0 1 1 0 0 0 1 1 1 0 1 0 0 0 1 1 1 0 1 1 1 1 1 1 1 1\n",
            " 0 0 1 1 0 1 0 1 1 1 1 1 0 1 1 0 0 0 0 1 1 0 1 0 1 1 0 1 1 0 1 0 1 1 1 1 1\n",
            " 0 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1 1 0 1 1 1 1 1 0 0 0 1 1 0 1 0 1 1 0 1\n",
            " 1 1 0 1 1 1 0 1 0 1 1 1 0 0 1 0 0 1 0 0 1 0 1 0 1 1 1 1 1 1 0 0 1 1 0 1 1\n",
            " 0 1 1 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1\n",
            " 0 0 0 1 0 1 1 0 0 0 1 1 0 1 1 1 0 0 1 1 0 0 1 0 1 1 1 1 0 0 1 1 1 1 0 0 1\n",
            " 0 1 0 1 1 1 1 1 0 0 0 0 0 1 0 1 1 1 0 0 1 0 0 1 0 1 0 1 0 0 0 1 0 1 1 1 0\n",
            " 0 1 0 0 1 0 1 1 1 0 0 0 1 1 0 0 1 0 1 1 1 1 0 0 1 0 0 0 0 0 1 0 0 1 1 1 1\n",
            " 0 1 0 0 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 0 1 0 0 0 0 1\n",
            " 1 1 1 0 0 0 0 0 1 0 1 0 1 0 1 0 1 1 0 0 1 0 1 0 1 1 0 0 1 0 1 1 1 1 0 1 1\n",
            " 1 0 0 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 1 0 1 1 0 1 1 1 0 0 0 1 0 1 1 1 0 0\n",
            " 0 1 0 1 0 1 0 1 0 1 1 1 1 1 1 0 1 0 1 0 1 1 0 1 0 1 0 1 1 1 1 0 0 0 1 1 0\n",
            " 0 1 1 0 0 1 1 0 1 1 1 0 0 0]\n",
            "std (902,) [40. 10. 50. 40. 10. 30. 20. 30. 30. 50. 20. 40. 40. 40. 30. 20. 20. 10.\n",
            " 20. 20. 10. 30. 20. 20. 10. 40. 20. 20. 10. 30. 30. 10. 40. 20. 40. 40.\n",
            " 50. 10. 30. 30. 40. 10. 50. 10. 30. 20. 20. 10. 40. 20. 30. 40. 40. 40.\n",
            " 10. 30. 40. 20. 20. 10. 30. 40. 30. 20. 40. 30. 50. 20. 40. 50. 30. 30.\n",
            " 40. 40. 50. 30. 20. 30. 30. 30. 30. 40. 50. 30. 40. 30. 20. 30. 20. 20.\n",
            " 30. 30. 20. 30. 50. 40. 30. 30. 40. 40. 20. 30. 40. 20. 20. 30. 20. 30.\n",
            " 30. 30. 30. 40. 50. 30. 30. 20. 50. 20. 20. 30. 30. 20. 10. 50. 50. 30.\n",
            " 20. 30. 10. 10. 20. 20. 20. 40. 40. 30. 20. 30. 30. 30. 50. 50. 20. 20.\n",
            " 20. 40. 30. 30. 20. 40. 50. 30. 40. 20. 30. 10.  0. 30. 40. 40. 40. 10.\n",
            " 40. 30. 40. 20. 40. 30. 30. 40. 20. 30. 40. 30. 30. 30. 20. 30. 20. 30.\n",
            " 40. 30. 20. 30. 30. 40. 30. 20. 30. 30. 30. 30. 30. 40. 40. 40. 20. 40.\n",
            " 30. 40. 50. 40. 30. 30. 40. 40. 40. 20. 30. 30. 40. 20. 10. 50. 20. 30.\n",
            " 40. 30. 40. 40. 20. 30. 30. 40. 40. 30. 40. 20. 30. 30. 50. 40. 40. 30.\n",
            " 30. 30. 30. 30. 30. 30. 30. 20. 20. 30. 40. 20. 50. 30. 40. 30. 30. 20.\n",
            " 30. 40. 20. 20. 40. 40. 30. 20. 20. 40. 20. 40. 40. 40. 50. 40. 20. 30.\n",
            " 20. 20. 50. 20. 50. 40. 30. 10. 30. 30. 40. 20. 40. 10. 30. 20. 40. 10.\n",
            " 10. 30. 30. 40. 20. 40. 40. 40. 40. 30. 20. 40. 30. 20. 30. 40. 40. 30.\n",
            " 20. 50. 30. 50. 30. 40. 30. 40. 40. 20. 30. 50. 50. 40. 30. 50. 30. 20.\n",
            " 20. 30. 40. 40. 40. 20. 40. 40. 40. 50. 30. 30. 50. 30. 50. 20. 30. 30.\n",
            " 40. 50. 50. 20. 10. 30. 50. 30. 30. 30. 40. 40. 50. 20. 40. 20. 20. 20.\n",
            " 10. 50. 30. 20. 20. 20. 50. 40. 40. 10. 40. 30. 30. 50. 30. 30. 40. 20.\n",
            " 10. 10. 30. 10. 30. 20. 40. 20. 40. 40. 30. 50. 40. 10. 40. 20. 40. 40.\n",
            " 40. 20. 20. 20. 30. 30. 40. 30. 20. 20. 50. 30. 20. 20. 20. 30. 40. 40.\n",
            " 30. 30. 40. 20. 30. 20. 30. 30. 40. 30. 50. 40. 50. 30. 40. 20. 20. 20.\n",
            " 30. 40. 30. 30. 20. 40. 10. 30. 30. 50. 20. 40. 20. 10. 40. 50. 40. 20.\n",
            " 10. 20. 50. 20. 30. 50. 30. 30. 30. 20. 20. 40. 10. 30. 30. 30. 40. 10.\n",
            " 20. 50. 40. 50. 30. 30. 40. 40. 40. 40. 20. 30. 40. 50. 30. 40. 30. 30.\n",
            " 50. 40. 30. 40. 30. 40. 20. 30. 40. 40. 30. 10. 20. 40. 40. 40. 20. 40.\n",
            " 30. 30. 30. 30. 30. 40. 30. 40. 40. 50. 30. 20. 30. 50. 10. 30. 40. 40.\n",
            " 30. 30. 20. 50. 30. 50. 30. 40. 40. 20. 30. 50. 30. 30. 30. 10. 30. 30.\n",
            " 50. 20. 40. 40. 40. 20. 30. 40. 30. 30. 20. 10. 50. 40. 40. 50. 50. 30.\n",
            " 30. 40. 30. 10. 50. 10. 50. 40. 40. 30. 20. 20. 30. 20. 40. 40. 40. 50.\n",
            " 20. 30. 30. 30. 50. 40. 50. 30. 30. 20. 30. 30. 10. 20. 30. 50. 40. 50.\n",
            " 40. 50. 10. 30. 50. 30. 40. 30. 20. 10. 40. 50. 30. 30. 20. 50. 20. 30.\n",
            " 30. 10. 30. 30. 20. 40. 30. 30. 40. 50. 20. 40. 50. 30. 50. 30. 30. 20.\n",
            " 20. 40. 40. 40. 30. 40. 20. 20. 20. 40. 30. 10. 30. 50. 40. 20. 20. 20.\n",
            " 30. 40. 40. 40. 40. 10. 50. 20. 20. 10. 50. 20. 40. 20. 40. 20. 40. 50.\n",
            " 30. 40. 20. 20. 40. 30. 50. 40. 40. 20. 40. 20. 50. 20. 30. 40. 30. 50.\n",
            " 30. 20. 20. 40. 40. 50. 20. 50. 30. 10. 30. 20. 50. 30. 40. 40. 40. 20.\n",
            " 20. 20. 30. 40. 30. 30. 10. 30. 20. 40. 40. 40. 20. 30. 30. 40. 40. 30.\n",
            " 20. 50. 40. 40. 40. 20. 40. 30. 30. 30. 40. 40. 50. 30. 30. 20. 50. 40.\n",
            " 30. 40. 40. 20. 20. 40. 30. 40. 20. 40. 20. 20. 40. 40. 30. 20. 30. 30.\n",
            " 20. 30. 10. 30. 30. 50. 30. 20. 40. 20. 30. 50. 40. 30. 30. 30. 30. 20.\n",
            " 30. 20. 50. 30. 20. 40. 40. 40. 40. 20. 10. 40. 30. 20. 20. 30.  0. 40.\n",
            " 30. 50. 40. 20. 30. 20. 30. 20. 20. 30. 50. 40. 20. 30. 30. 40. 30. 30.\n",
            " 20. 50. 30. 40. 50. 40. 30. 50. 20. 20. 20. 30. 40. 40. 20. 20. 30. 30.\n",
            " 20. 20. 30. 30. 30. 20. 30. 30. 30. 40. 50. 50. 50. 10. 20. 30. 20. 40.\n",
            " 40. 50. 50. 30. 30. 20. 20. 30. 40. 30. 30. 20. 40. 40. 20. 40. 40. 40.\n",
            " 50. 40. 20. 30. 20. 50. 30. 30. 30. 30. 10. 20. 50. 20. 30. 40. 40. 20.\n",
            " 10. 40. 20. 20. 40. 10. 20. 30. 30. 20. 40. 40. 20. 30. 40. 50. 30. 30.\n",
            " 30. 40.]\n",
            "selection [156 790 450  54 882 537 438  47 551  43] (10,) [ 0.  0. 10. 10. 10. 10. 10. 10. 10. 10.]\n",
            "trainset before adding uncertain samples (400, 10) (400,)\n",
            "trainset after adding uncertain samples (410, 10) (410,)\n",
            "updated train set: (410, 10) (410,) unique(labels): [208 202] [0 1]\n",
            "val set: (892, 10) (892,)\n",
            "\n",
            "Train set: (410, 10)\n",
            "Validation set: (892, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 41\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.092 s \n",
            "\n",
            "Accuracy rate is 81.336406 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.90      0.88       321\n",
            "           1       0.67      0.57      0.61       113\n",
            "\n",
            "    accuracy                           0.81       434\n",
            "   macro avg       0.76      0.73      0.74       434\n",
            "weighted avg       0.81      0.81      0.81       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[289  32]\n",
            " [ 49  64]]\n",
            "--------------------------------\n",
            "val predicted: (892,) [1 0 1 1 0 0 1 0 0 1 1 1 1 0 1 0 1 0 0 1 0 0 1 0 1 1 1 0 1 1 1 0 0 1 1 0 0\n",
            " 0 1 0 1 0 0 1 1 1 1 0 1 1 1 1 0 1 0 0 1 0 0 1 1 1 1 1 1 1 1 0 1 0 1 1 0 0\n",
            " 0 0 1 0 1 1 1 1 0 1 0 0 0 1 1 1 0 0 1 0 0 1 0 1 0 1 1 1 1 0 1 0 0 1 0 0 1\n",
            " 0 0 1 1 1 1 0 1 0 0 1 1 0 0 1 1 1 0 1 1 1 1 1 0 1 0 1 1 0 0 0 1 1 0 1 1 1\n",
            " 0 1 0 0 0 1 0 1 1 0 1 1 1 1 0 1 0 1 1 0 1 1 1 0 0 0 1 0 0 1 1 1 0 0 0 0 0\n",
            " 0 1 0 0 1 0 0 1 0 1 1 0 1 1 0 0 1 1 0 0 0 0 0 1 1 0 1 1 1 1 1 1 1 1 0 0 1\n",
            " 1 0 1 0 1 1 1 1 1 0 1 1 0 1 1 1 0 1 1 0 1 0 1 1 1 1 1 0 0 1 1 0 1 0 0 1 1\n",
            " 1 1 1 1 0 0 0 0 0 1 0 1 0 0 1 0 1 0 1 0 1 0 0 1 0 0 0 0 0 0 1 1 1 1 1 1 1\n",
            " 1 0 1 1 0 1 0 1 0 1 0 0 1 1 1 1 0 0 1 0 1 1 0 1 1 0 0 1 1 1 1 1 0 1 0 1 1\n",
            " 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 0 1 1 0 1 1 1 0 1 1 0 1 0 1 0 1 1 1 1 0 1\n",
            " 1 0 1 0 1 1 1 0 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 0 0 0 1 1 0 1 0 0 1 0 0 1 0\n",
            " 1 1 1 0 0 1 0 1 1 1 1 0 1 0 1 1 0 0 0 0 0 1 1 1 1 1 1 0 0 0 1 1 1 1 0 1 0\n",
            " 0 0 1 0 0 0 1 1 0 0 0 1 1 1 0 1 0 0 0 1 1 1 0 1 1 1 1 1 1 1 1 0 0 1 1 0 1\n",
            " 0 1 1 1 1 1 0 1 1 0 0 0 0 1 1 0 1 0 1 1 0 1 1 0 1 0 1 1 1 1 1 0 1 1 1 1 1\n",
            " 1 1 1 1 1 0 0 1 0 1 1 1 1 1 1 1 1 1 0 0 0 1 1 0 1 0 1 0 1 1 1 0 1 1 1 0 1\n",
            " 0 1 1 1 0 0 1 0 0 1 0 0 1 0 1 0 1 1 1 1 1 1 0 0 1 1 0 1 1 0 1 1 1 0 1 1 1\n",
            " 0 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 0 1 1 0\n",
            " 0 0 1 1 0 1 1 1 0 0 1 1 0 0 1 0 1 1 1 1 0 0 1 1 1 1 0 0 1 0 1 0 1 1 1 1 1\n",
            " 0 0 0 0 0 1 0 1 1 1 0 0 1 0 0 1 0 1 0 1 0 0 0 1 0 1 1 1 0 0 1 0 0 1 0 1 1\n",
            " 1 0 0 0 1 1 0 0 1 0 1 1 1 1 0 0 1 0 0 0 0 0 1 0 0 1 1 1 1 0 1 0 0 1 0 0 0\n",
            " 0 0 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 0 1 0 0 0 0 1 1 1 1 0 0 0 0 0\n",
            " 1 0 1 0 1 1 0 1 1 0 0 1 0 1 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1 0 0 1 1 0 1 0 1\n",
            " 1 1 1 1 1 0 0 1 1 1 1 0 1 1 0 1 1 1 0 0 0 1 0 1 1 1 0 0 0 1 0 1 0 1 0 1 0\n",
            " 1 1 1 1 1 1 0 1 0 1 0 1 1 0 1 0 1 0 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 1 1\n",
            " 1 0 0 0]\n",
            "probabilities: (892, 2) \n",
            " [1 0 1 1 0 0 1 0 0 1 1 1 1 0 1 0 1 0 0 1 0 0 1 0 1 1 1 0 1 1 1 0 0 1 1 0 0\n",
            " 0 1 0 1 0 0 1 1 1 1 0 1 1 1 1 0 1 0 0 1 0 0 1 1 1 1 1 1 1 1 0 1 0 1 1 0 0\n",
            " 0 0 1 0 1 1 1 1 0 1 0 0 0 1 1 1 0 0 1 0 0 1 0 1 0 1 1 1 1 0 1 0 0 1 0 0 1\n",
            " 0 0 1 1 1 1 0 1 0 0 1 1 0 0 1 1 1 0 1 1 1 1 1 0 1 0 1 1 0 0 0 1 1 0 1 1 1\n",
            " 0 1 0 0 0 1 0 1 1 0 1 1 1 1 0 1 0 1 1 0 1 1 1 0 0 0 1 0 0 1 1 1 0 0 0 0 0\n",
            " 0 1 0 0 1 0 0 1 0 1 1 0 1 1 0 0 1 1 0 0 0 0 0 1 1 0 1 1 1 1 1 1 1 1 0 0 1\n",
            " 1 0 1 0 1 1 1 1 1 0 1 1 0 1 1 1 0 1 1 0 1 0 1 1 1 1 1 0 0 1 1 0 1 0 0 1 1\n",
            " 1 1 1 1 0 0 0 0 0 1 0 1 0 0 1 0 1 0 1 0 1 0 0 1 0 0 0 0 0 0 1 1 1 1 1 1 1\n",
            " 1 0 1 1 0 1 0 1 0 1 0 0 1 1 1 1 0 0 1 0 1 1 0 1 1 0 0 1 1 1 1 1 0 1 0 1 1\n",
            " 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 0 1 1 0 1 1 1 0 1 1 0 1 0 1 0 1 1 1 1 0 1\n",
            " 1 0 1 0 1 1 1 0 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 0 0 0 1 1 0 1 0 0 1 0 0 1 0\n",
            " 1 1 1 0 0 1 0 1 1 1 1 0 1 0 1 1 0 0 0 0 0 1 1 1 1 1 1 0 0 0 1 1 1 1 0 1 0\n",
            " 0 0 1 0 0 0 1 1 0 0 0 1 1 1 0 1 0 0 0 1 1 1 0 1 1 1 1 1 1 1 1 0 0 1 1 0 1\n",
            " 0 1 1 1 1 1 0 1 1 0 0 0 0 1 1 0 1 0 1 1 0 1 1 0 1 0 1 1 1 1 1 0 1 1 1 1 1\n",
            " 1 1 1 1 1 0 0 1 0 1 1 1 1 1 1 1 1 1 0 0 0 1 1 0 1 0 1 0 1 1 1 0 1 1 1 0 1\n",
            " 0 1 1 1 0 0 1 0 0 1 0 0 1 0 1 0 1 1 1 1 1 1 0 0 1 1 0 1 1 0 1 1 1 0 1 1 1\n",
            " 0 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 0 1 1 0\n",
            " 0 0 1 1 0 1 1 1 0 0 1 1 0 0 1 0 1 1 1 1 0 0 1 1 1 1 0 0 1 0 1 0 1 1 1 1 1\n",
            " 0 0 0 0 0 1 0 1 1 1 0 0 1 0 0 1 0 1 0 1 0 0 0 1 0 1 1 1 0 0 1 0 0 1 0 1 1\n",
            " 1 0 0 0 1 1 0 0 1 0 1 1 1 1 0 0 1 0 0 0 0 0 1 0 0 1 1 1 1 0 1 0 0 1 0 0 0\n",
            " 0 0 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 0 1 0 0 0 0 1 1 1 1 0 0 0 0 0\n",
            " 1 0 1 0 1 1 0 1 1 0 0 1 0 1 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1 0 0 1 1 0 1 0 1\n",
            " 1 1 1 1 1 0 0 1 1 1 1 0 1 1 0 1 1 1 0 0 0 1 0 1 1 1 0 0 0 1 0 1 0 1 0 1 0\n",
            " 1 1 1 1 1 1 0 1 0 1 0 1 1 0 1 0 1 0 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 1 1\n",
            " 1 0 0 0]\n",
            "std (892,) [40. 10. 50. 40. 20. 30. 20. 30. 30. 50. 20. 40. 40. 40. 30. 20. 20. 10.\n",
            " 20. 20. 10. 30. 20. 20. 10. 40. 10. 20. 10. 30. 30. 20. 40. 20. 40. 40.\n",
            " 50. 10. 40. 30. 40. 10. 50. 30. 20. 20. 40. 20. 30. 40. 40. 40. 30. 40.\n",
            " 20. 20. 20. 30. 40. 30. 20. 40. 30. 50. 20. 40. 50. 30. 30. 40. 40. 50.\n",
            " 30. 30. 30. 30. 30. 30. 40. 50. 30. 40. 30. 30. 30. 20. 20. 30. 30. 20.\n",
            " 40. 50. 40. 40. 30. 40. 40. 30. 30. 40. 20. 20. 30. 20. 30. 30. 40. 30.\n",
            " 40. 50. 30. 30. 20. 50. 20. 20. 30. 30. 20. 10. 50. 50. 30. 20. 30. 10.\n",
            " 10. 20. 30. 30. 40. 40. 30. 20. 30. 20. 30. 50. 50. 20. 20. 20. 40. 30.\n",
            " 30. 20. 40. 50. 30. 40. 20. 30. 20. 30. 40. 40. 40. 10. 40. 30. 40. 20.\n",
            " 40. 30. 30. 40. 20. 30. 40. 30. 30. 30. 20. 30. 20. 30. 40. 30. 20. 30.\n",
            " 30. 40. 30. 30. 30. 30. 30. 40. 30. 40. 40. 40. 20. 40. 30. 40. 50. 40.\n",
            " 30. 30. 40. 40. 40. 20. 30. 30. 40. 20. 10. 50. 20. 40. 40. 30. 30. 40.\n",
            " 20. 30. 30. 40. 30. 30. 40. 20. 30. 30. 50. 40. 40. 30. 30. 40. 30. 30.\n",
            " 30. 30. 30. 20. 20. 30. 40. 20. 40. 30. 40. 30. 30. 20. 30. 40. 30. 20.\n",
            " 40. 40. 30. 20. 30. 40. 20. 40. 40. 40. 50. 40. 20. 30. 20. 20. 50. 20.\n",
            " 50. 40. 30. 10. 30. 30. 40. 20. 40. 10. 20. 20. 40. 10.  0. 30. 30. 40.\n",
            " 30. 40. 30. 40. 40. 30. 20. 40. 30. 20. 30. 40. 40. 30. 20. 50. 30. 50.\n",
            " 40. 40. 30. 40. 40. 20. 30. 50. 50. 40. 30. 50. 30. 20. 20. 30. 50. 40.\n",
            " 40. 20. 40. 40. 40. 50. 30. 30. 50. 30. 50. 20. 30. 30. 40. 50. 50. 20.\n",
            " 10. 30. 50. 30. 30. 30. 40. 40. 50. 20. 40. 20. 20. 20. 20. 50. 30. 20.\n",
            " 20. 20. 50. 40. 40. 10. 40. 30. 30. 50. 30. 40. 40. 20. 10. 10. 30. 10.\n",
            " 30. 20. 40. 20. 50. 40. 30. 50. 40. 20. 40. 20. 40. 40. 40. 20. 20. 20.\n",
            " 30. 30. 40. 30. 20. 20. 50. 30. 20. 20. 20. 30. 40. 40. 30. 30. 40. 10.\n",
            " 30. 20. 30. 30. 40. 30. 50. 40. 50. 30. 40. 20. 20. 20. 30. 40. 30. 30.\n",
            " 20. 40. 40. 30. 50. 20. 40. 20. 10. 40. 50. 50. 20. 20. 50. 20. 40. 50.\n",
            " 30. 30. 30. 20. 20. 40. 10. 30. 30. 30. 40. 10. 30. 50. 40. 50. 30. 30.\n",
            " 40. 40. 40. 30. 20. 30. 40. 50. 30. 40. 30. 30. 50. 40. 30. 40. 30. 40.\n",
            " 30. 30. 40. 40. 30. 10. 20. 40. 40. 40. 30. 40. 30. 30. 30. 30. 30. 40.\n",
            " 30. 40. 40. 50. 30. 20. 30. 50. 10. 30. 40. 40. 30. 30. 20. 50. 40. 50.\n",
            " 30. 40. 40. 30. 30. 50. 30. 30. 30. 30. 30. 50. 20. 40. 40. 40. 20. 30.\n",
            " 40. 30. 30. 20. 50. 40. 40. 50. 50. 30. 30. 50. 30.  0. 50. 10. 50. 40.\n",
            " 40. 30. 20. 20. 30. 20. 40. 40. 40. 50. 20. 30. 30. 30. 50. 40. 50. 30.\n",
            " 30. 30. 40. 30. 10. 30. 30. 50. 40. 50. 40. 50. 30. 30. 50. 30. 40. 30.\n",
            " 20. 30. 40. 50. 30. 40. 20. 50. 20. 30. 30. 10. 20. 30. 20. 40. 30. 30.\n",
            " 40. 50. 20. 40. 50. 30. 50. 30. 30. 20. 20. 40. 40. 40. 30. 40. 20. 20.\n",
            " 20. 40. 30. 10. 30. 50. 40. 20. 10. 20. 40. 40. 40. 50. 40. 10. 50. 10.\n",
            " 20. 10. 50. 20. 40. 20. 40. 30. 40. 50. 30. 40. 20. 10. 40. 40. 50. 40.\n",
            " 40. 20. 40. 20. 50. 20. 30. 40. 30. 50. 30. 20. 20. 40. 40. 50. 20. 50.\n",
            " 30. 10. 30. 20. 50. 30. 40. 40. 40. 20. 20. 30. 30. 40. 30. 30. 10. 30.\n",
            " 20. 40. 40. 40. 20. 30. 30. 40. 40. 30. 20. 50. 50. 40. 40. 20. 50. 30.\n",
            " 30. 30. 40. 40. 50. 30. 30. 20. 50. 40. 30. 40. 40. 30. 20. 40. 30. 40.\n",
            " 30. 40. 20. 20. 40. 40. 30. 20. 30. 30. 20. 30. 10. 20. 30. 50. 30. 20.\n",
            " 40. 30. 30. 50. 40. 30. 30. 30. 30. 20. 30. 20. 50. 30. 20. 40. 40. 40.\n",
            " 30. 20. 10. 40. 30. 20. 20. 30. 40. 30. 50. 40. 20. 30. 20. 30. 20. 20.\n",
            " 30. 50. 50. 20. 30. 30. 50. 30. 30. 20. 50. 30. 40. 50. 40. 30. 50. 20.\n",
            " 30. 20. 30. 40. 40. 20. 20. 30. 30. 20. 20. 30. 30. 30. 20. 30. 30. 30.\n",
            " 40. 50. 50. 50. 10. 20. 30. 20. 40. 40. 50. 50. 30. 30. 20. 30. 30. 40.\n",
            " 30. 30. 20. 50. 40. 20. 40. 40. 40. 50. 40. 20. 30. 20. 50. 30. 30. 30.\n",
            " 30. 10. 20. 50. 20. 30. 40. 40. 20. 40. 20. 20. 40. 10. 20. 30. 30. 20.\n",
            " 40. 40. 20. 30. 40. 50. 40. 30. 30. 40.]\n",
            "selection [284 553 647 645 440 649 119  37 877 832] (10,) [ 0.  0. 10. 10. 10. 10. 10. 10. 10. 10.]\n",
            "trainset before adding uncertain samples (410, 10) (410,)\n",
            "trainset after adding uncertain samples (420, 10) (420,)\n",
            "updated train set: (420, 10) (420,) unique(labels): [213 207] [0 1]\n",
            "val set: (882, 10) (882,)\n",
            "\n",
            "Train set: (420, 10)\n",
            "Validation set: (882, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 42\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.102 s \n",
            "\n",
            "Accuracy rate is 80.645161 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.89      0.87       321\n",
            "           1       0.65      0.57      0.60       113\n",
            "\n",
            "    accuracy                           0.81       434\n",
            "   macro avg       0.75      0.73      0.74       434\n",
            "weighted avg       0.80      0.81      0.80       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[286  35]\n",
            " [ 49  64]]\n",
            "--------------------------------\n",
            "val predicted: (882,) [1 0 1 1 0 0 1 0 0 1 1 1 1 0 1 0 1 0 0 1 0 0 1 0 1 1 1 0 1 1 1 0 0 1 1 0 0\n",
            " 1 0 1 0 0 1 1 1 1 0 1 1 1 1 0 1 0 0 1 0 0 1 1 1 1 1 1 1 1 0 1 0 1 1 0 0 0\n",
            " 0 1 0 1 1 1 1 0 1 0 0 0 1 1 1 0 0 1 0 0 1 0 1 0 1 1 1 1 0 1 0 0 1 0 0 1 0\n",
            " 0 1 1 1 1 0 1 0 1 1 0 0 1 1 1 0 1 1 1 1 1 0 1 0 1 1 0 0 0 1 1 0 1 1 1 0 1\n",
            " 0 0 0 1 0 1 1 0 1 1 1 1 0 1 0 1 1 0 1 1 1 0 0 0 1 0 0 1 1 1 0 0 0 0 0 0 1\n",
            " 0 0 1 0 0 1 0 1 1 0 1 1 0 0 1 1 0 0 0 0 0 1 1 0 1 1 1 1 1 1 1 1 0 0 1 1 0\n",
            " 1 0 1 1 1 1 1 0 1 1 0 1 1 1 0 1 1 0 1 0 1 1 1 1 1 0 0 1 1 0 1 0 0 1 1 1 1\n",
            " 1 1 0 0 0 0 0 1 0 1 0 0 1 0 1 0 1 0 1 0 0 1 0 0 0 0 0 1 1 1 1 1 1 1 1 0 1\n",
            " 1 0 1 0 1 0 1 0 0 1 1 1 1 0 0 1 0 1 1 0 1 1 0 0 1 1 1 1 1 0 1 0 1 1 1 1 1\n",
            " 1 1 1 1 1 1 0 1 1 1 1 0 0 0 1 1 0 1 1 1 0 1 1 0 1 0 1 0 1 1 1 1 0 1 1 0 1\n",
            " 0 1 1 1 0 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 0 0 0 1 1 0 1 0 0 1 0 0 1 0 1 1 1\n",
            " 0 0 1 0 1 1 1 1 0 1 0 1 1 0 0 0 0 0 1 1 1 1 1 1 0 0 0 1 1 1 0 1 0 0 0 1 0\n",
            " 0 0 1 1 0 0 0 1 1 1 0 1 0 0 0 1 1 1 0 1 1 1 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1\n",
            " 1 1 0 1 1 0 0 0 0 1 1 0 1 0 1 1 0 1 1 0 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1\n",
            " 1 0 0 1 0 1 1 1 1 1 1 1 1 1 0 0 0 1 1 0 1 0 1 0 1 1 1 0 1 1 1 1 0 1 1 1 0\n",
            " 0 1 0 0 1 0 0 1 0 1 0 1 1 1 1 1 1 0 0 1 1 0 1 1 0 1 1 1 0 1 1 1 0 1 1 0 1\n",
            " 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 0 1 1 0 0 0 1 1 0\n",
            " 1 1 1 0 0 1 1 0 0 1 0 1 1 0 1 1 1 1 0 0 1 0 1 0 1 1 1 1 1 0 0 0 0 0 1 0 1\n",
            " 1 1 0 0 1 0 0 1 0 1 0 1 0 0 0 1 0 1 1 1 0 0 1 0 0 1 0 1 1 1 0 0 0 1 1 0 0\n",
            " 1 0 1 1 1 1 0 0 1 0 0 0 0 0 1 0 0 1 1 1 1 0 1 0 0 1 0 0 0 0 0 1 1 1 1 1 1\n",
            " 1 1 1 1 0 1 0 0 1 1 1 1 1 1 0 1 0 0 0 0 1 1 1 1 0 0 0 0 0 1 0 1 0 1 1 0 1\n",
            " 1 0 0 1 0 1 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1 0 0 1 1 0 1 0 1 1 1 1 1 1 0 0 1\n",
            " 1 1 1 0 1 1 0 1 1 1 0 0 1 0 1 1 1 0 0 0 1 0 1 0 1 0 1 0 1 1 1 1 1 1 0 1 0\n",
            " 1 0 1 1 0 1 0 1 0 1 1 1 1 0 0 1 1 0 1 1 0 0 1 1 0 1 1 1 0 0 0]\n",
            "probabilities: (882, 2) \n",
            " [1 0 1 1 0 0 1 0 0 1 1 1 1 0 1 0 1 0 0 1 0 0 1 0 1 1 1 0 1 1 1 0 0 1 1 0 0\n",
            " 1 0 1 0 0 1 1 1 1 0 1 1 1 1 0 1 0 0 1 0 0 1 1 1 1 1 1 1 1 0 1 0 1 1 0 0 0\n",
            " 0 1 0 1 1 1 1 0 1 0 0 0 1 1 1 0 0 1 0 0 1 0 1 0 1 1 1 1 0 1 0 0 1 0 0 1 0\n",
            " 0 1 1 1 1 0 1 0 1 1 0 0 1 1 1 0 1 1 1 1 1 0 1 0 1 1 0 0 0 1 1 0 1 1 1 0 1\n",
            " 0 0 0 1 0 1 1 0 1 1 1 1 0 1 0 1 1 0 1 1 1 0 0 0 1 0 0 1 1 1 0 0 0 0 0 0 1\n",
            " 0 0 1 0 0 1 0 1 1 0 1 1 0 0 1 1 0 0 0 0 0 1 1 0 1 1 1 1 1 1 1 1 0 0 1 1 0\n",
            " 1 0 1 1 1 1 1 0 1 1 0 1 1 1 0 1 1 0 1 0 1 1 1 1 1 0 0 1 1 0 1 0 0 1 1 1 1\n",
            " 1 1 0 0 0 0 0 1 0 1 0 0 1 0 1 0 1 0 1 0 0 1 0 0 0 0 0 1 1 1 1 1 1 1 1 0 1\n",
            " 1 0 1 0 1 0 1 0 0 1 1 1 1 0 0 1 0 1 1 0 1 1 0 0 1 1 1 1 1 0 1 0 1 1 1 1 1\n",
            " 1 1 1 1 1 1 0 1 1 1 1 0 0 0 1 1 0 1 1 1 0 1 1 0 1 0 1 0 1 1 1 1 0 1 1 0 1\n",
            " 0 1 1 1 0 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 0 0 0 1 1 0 1 0 0 1 0 0 1 0 1 1 1\n",
            " 0 0 1 0 1 1 1 1 0 1 0 1 1 0 0 0 0 0 1 1 1 1 1 1 0 0 0 1 1 1 0 1 0 0 0 1 0\n",
            " 0 0 1 1 0 0 0 1 1 1 0 1 0 0 0 1 1 1 0 1 1 1 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1\n",
            " 1 1 0 1 1 0 0 0 0 1 1 0 1 0 1 1 0 1 1 0 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1\n",
            " 1 0 0 1 0 1 1 1 1 1 1 1 1 1 0 0 0 1 1 0 1 0 1 0 1 1 1 0 1 1 1 1 0 1 1 1 0\n",
            " 0 1 0 0 1 0 0 1 0 1 0 1 1 1 1 1 1 0 0 1 1 0 1 1 0 1 1 1 0 1 1 1 0 1 1 0 1\n",
            " 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 0 1 1 0 0 0 1 1 0\n",
            " 1 1 1 0 0 1 1 0 0 1 0 1 1 0 1 1 1 1 0 0 1 0 1 0 1 1 1 1 1 0 0 0 0 0 1 0 1\n",
            " 1 1 0 0 1 0 0 1 0 1 0 1 0 0 0 1 0 1 1 1 0 0 1 0 0 1 0 1 1 1 0 0 0 1 1 0 0\n",
            " 1 0 1 1 1 1 0 0 1 0 0 0 0 0 1 0 0 1 1 1 1 0 1 0 0 1 0 0 0 0 0 1 1 1 1 1 1\n",
            " 1 1 1 1 0 1 0 0 1 1 1 1 1 1 0 1 0 0 0 0 1 1 1 1 0 0 0 0 0 1 0 1 0 1 1 0 1\n",
            " 1 0 0 1 0 1 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1 0 0 1 1 0 1 0 1 1 1 1 1 1 0 0 1\n",
            " 1 1 1 0 1 1 0 1 1 1 0 0 1 0 1 1 1 0 0 0 1 0 1 0 1 0 1 0 1 1 1 1 1 1 0 1 0\n",
            " 1 0 1 1 0 1 0 1 0 1 1 1 1 0 0 1 1 0 1 1 0 0 1 1 0 1 1 1 0 0 0]\n",
            "std (882,) [40. 10. 50. 40. 20. 30. 20. 30. 30. 50. 20. 40. 40. 40. 30. 20. 20. 10.\n",
            " 20. 20. 10. 30. 20. 20. 10. 40. 20. 20. 10. 30. 30. 20. 40. 20. 40. 40.\n",
            " 50. 40. 30. 40. 10. 50. 30. 20. 20. 40. 20. 30. 40. 40. 40. 30. 40. 20.\n",
            " 10. 10. 30. 40. 30. 20. 30. 30. 50. 20. 40. 50. 30. 30. 40. 40. 50. 30.\n",
            " 30. 30. 30. 30. 30. 40. 50. 30. 40. 30. 30. 30. 20. 20. 30. 30. 20. 40.\n",
            " 50. 40. 40. 40. 40. 30. 20. 30. 40. 20. 20. 30. 10. 30. 30. 40. 30. 40.\n",
            " 40. 20. 30. 20. 50. 20. 20. 30. 30. 20. 40. 50. 20. 20. 30. 10. 10. 20.\n",
            " 20. 20. 40. 40. 30. 10. 30. 30. 30. 50. 50. 20. 10. 20. 40. 30. 20. 20.\n",
            " 40. 50. 30. 40. 20. 30. 20. 30. 40. 40. 40. 10. 40. 30. 40. 20. 30. 30.\n",
            " 30. 40. 20. 30. 40. 30. 30. 30. 30. 30. 20. 20. 40. 30. 20. 30. 30. 40.\n",
            " 30. 20. 30. 30. 30. 40. 30. 40. 40. 40. 20. 50. 30. 40. 50. 40. 30. 30.\n",
            " 40. 40. 40. 20. 30. 40. 40. 20. 10. 50. 20. 40. 40. 30. 40. 40. 20. 20.\n",
            " 30. 40. 40. 30. 40. 20. 30. 30. 50. 40. 40. 30. 40. 40. 30. 40. 30. 30.\n",
            " 30. 20. 10. 30. 30. 20. 50. 20. 40. 30. 40. 20. 30. 40. 20. 20. 40. 40.\n",
            " 40. 20. 20. 40. 20. 40. 40. 40. 50. 40. 20. 30. 20. 20. 50. 20. 50. 40.\n",
            " 30. 10. 30. 30. 40. 20. 40. 10. 20. 20. 40. 10. 30. 30. 40. 40. 40. 30.\n",
            " 40. 40. 30. 20. 40. 30. 20. 30. 40. 40. 30. 20. 50. 30. 50. 30. 40. 30.\n",
            " 40. 40. 20. 40. 50. 50. 40. 30. 50. 30. 20. 20. 30. 50. 40. 40. 20. 40.\n",
            " 40. 40. 50. 40. 30. 50. 30. 50. 20. 30. 30. 40. 50. 50. 20. 10. 30. 50.\n",
            " 30. 30. 30. 40. 40. 50. 20. 40. 20. 30. 20. 10. 50. 30. 20. 20. 20. 50.\n",
            " 40. 40. 10. 40. 30. 30. 50. 30. 40. 40. 20. 10. 10. 40.  0. 30. 20. 40.\n",
            " 20. 40. 40. 30. 50. 30. 20. 50. 20. 40. 40. 40. 30. 20. 20. 30. 30. 30.\n",
            " 30. 10. 20. 50. 30. 20. 30. 20. 30. 40. 40. 30. 30. 40.  0. 30. 20. 30.\n",
            " 30. 40. 40. 50. 40. 50. 30. 40. 20. 20. 10. 30. 40. 30. 30. 20. 40. 40.\n",
            " 30. 50. 20. 40. 20. 20. 50. 50. 20. 20. 50. 20. 30. 50. 30. 30. 20. 20.\n",
            " 20. 40. 10. 30. 40. 30. 30. 10. 30. 50. 40. 50. 30. 30. 40. 40. 40. 30.\n",
            " 20. 30. 40. 50. 30. 40. 30. 30. 50. 40. 30. 40. 30. 40. 20. 30. 40. 40.\n",
            " 30. 10. 30. 40. 40. 40. 30. 40. 30. 30. 30. 30. 30. 40. 20. 40. 40. 50.\n",
            " 30. 20. 30. 40. 10. 30. 40. 40. 30. 30. 20. 50. 40. 50. 30. 40. 30. 30.\n",
            " 20. 50. 30. 20. 30. 30. 30. 50. 20. 40. 40. 40. 10. 30. 40. 30. 30. 10.\n",
            " 50. 40. 40. 50. 50. 30. 30. 50. 30. 50. 10. 50. 30. 40. 30. 20. 20. 30.\n",
            " 20. 40. 40. 40. 50. 20. 30. 30. 30. 50. 40. 50. 30. 30. 20. 40. 30. 10.\n",
            " 30. 30. 50. 40. 50. 40. 50. 20. 30. 50. 30. 40. 30. 20. 20. 40. 50. 30.\n",
            " 40. 20. 50. 20. 30. 20. 10. 30. 30. 20. 40. 20. 30. 40. 50. 20. 50. 40.\n",
            " 30. 50. 30. 20. 20. 20. 40. 40. 40. 30. 40. 10. 20. 20. 40. 30. 10. 40.\n",
            " 50. 40. 20. 10. 10. 40. 40. 40. 50. 40. 50. 20. 40. 20. 40. 20. 40. 30.\n",
            " 50. 50. 30. 40. 20. 10. 40. 30. 50. 40. 40. 20. 40. 20. 50. 20. 30. 40.\n",
            " 30. 50. 30. 20. 20. 40. 40. 50. 20. 50. 30. 20. 30. 20. 50. 30. 40. 40.\n",
            " 40. 20. 20. 30. 40. 40. 30. 30.  0. 30. 20. 40. 30. 40. 20. 30. 30. 30.\n",
            " 40. 30. 20. 50. 40. 40. 40. 20. 30. 30. 30. 30. 40. 40. 50. 30. 30. 20.\n",
            " 50. 40. 30. 40. 40. 30. 20. 40. 40. 40. 30. 40. 20. 20. 40. 40. 20. 20.\n",
            " 30. 30. 20. 30. 10. 20. 30. 50. 30. 20. 40. 30. 40. 50. 40. 30. 30. 30.\n",
            " 30. 20. 30. 20. 50. 30. 30. 40. 40. 40. 40. 20. 10. 40. 30. 20. 20. 30.\n",
            " 40. 30. 50. 40. 20. 30. 20. 30. 20. 20. 30. 50. 50. 20. 30. 20. 50. 30.\n",
            " 30. 20. 50. 30. 40. 50. 40. 30. 50. 20. 30. 20. 40. 40. 40. 20. 20. 30.\n",
            " 30. 10. 20. 30. 30. 30. 20. 30. 30. 30. 40. 40. 50. 50. 20. 30. 20. 30.\n",
            " 40. 50. 50. 30. 30. 20. 30. 20. 40. 30. 30. 20. 50. 40. 20. 40. 40. 40.\n",
            " 50. 40. 20. 30. 20. 50. 30. 30. 30. 30. 10. 20. 50. 20. 20. 40. 40. 20.\n",
            " 40. 20. 20. 40. 20. 30. 30. 20. 40. 40. 10. 30. 40. 50. 40. 30. 30. 40.]\n",
            "selection [410 692 374 600 534 277 236 397 742 155] (10,) [ 0.  0.  0. 10. 10. 10. 10. 10. 10. 10.]\n",
            "trainset before adding uncertain samples (420, 10) (420,)\n",
            "trainset after adding uncertain samples (430, 10) (430,)\n",
            "updated train set: (430, 10) (430,) unique(labels): [218 212] [0 1]\n",
            "val set: (872, 10) (872,)\n",
            "\n",
            "Train set: (430, 10)\n",
            "Validation set: (872, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 43\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.068 s \n",
            "\n",
            "Accuracy rate is 79.723502 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.88      0.87       321\n",
            "           1       0.62      0.56      0.59       113\n",
            "\n",
            "    accuracy                           0.80       434\n",
            "   macro avg       0.74      0.72      0.73       434\n",
            "weighted avg       0.79      0.80      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[283  38]\n",
            " [ 50  63]]\n",
            "--------------------------------\n",
            "val predicted: (872,) [1 0 1 1 0 0 1 0 0 1 1 1 1 0 1 0 1 0 0 1 0 0 1 0 1 1 1 0 1 1 1 0 0 1 1 0 0\n",
            " 1 0 1 0 0 1 1 1 1 0 1 1 1 1 0 1 0 0 1 0 0 1 1 1 1 1 1 1 1 0 1 0 1 1 0 0 0\n",
            " 0 1 0 1 1 1 1 0 1 0 0 0 1 1 1 0 0 1 0 0 1 0 1 0 1 1 1 1 0 1 0 0 1 0 0 1 0\n",
            " 0 1 1 1 1 0 1 0 1 1 0 0 1 1 1 0 1 1 1 1 1 0 1 0 1 1 0 0 0 1 1 0 1 1 1 0 1\n",
            " 0 0 0 1 0 1 1 1 1 1 1 0 1 0 1 1 0 1 1 1 0 0 0 1 0 0 1 1 1 0 0 0 0 0 0 1 0\n",
            " 0 1 0 0 1 0 1 1 0 1 1 0 0 1 1 0 0 0 0 0 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 0 1\n",
            " 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 0 1 0 1 1 1 1 1 0 0 1 1 0 1 0 0 1 1 1 1 1 1\n",
            " 0 0 0 0 0 1 0 1 0 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 1 1 1 1 1 1 1 1 0 1 1 0 1\n",
            " 0 1 0 1 0 0 1 1 1 1 0 0 1 0 1 1 0 1 1 0 0 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1\n",
            " 1 1 1 0 1 1 1 1 0 0 0 1 1 0 1 1 1 0 1 1 0 1 0 1 0 1 1 1 1 0 1 1 0 1 0 1 1\n",
            " 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 0 0 0 1 1 0 1 0 1 0 0 1 0 1 1 1 0 0 1 1 1\n",
            " 1 1 0 1 0 1 1 0 0 0 0 0 1 1 1 1 1 1 0 0 0 1 1 1 0 1 0 0 0 1 0 0 0 1 1 0 0\n",
            " 0 1 1 1 0 1 0 0 0 1 1 1 0 1 1 1 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 1 0 1 1 0\n",
            " 0 0 0 1 1 0 1 0 1 1 0 1 1 0 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1\n",
            " 1 1 1 1 1 1 1 1 0 0 1 1 0 1 0 1 0 1 1 1 0 1 1 1 1 0 1 1 1 0 0 1 0 0 1 0 0\n",
            " 1 0 1 0 1 1 1 1 1 1 0 0 1 1 0 1 1 0 1 1 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1\n",
            " 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 0 1 1 0 0 0 1 1 0 1 1 1 0 0 1 1 0\n",
            " 0 1 0 1 1 0 1 1 1 1 0 0 1 0 1 0 1 1 1 1 1 0 0 0 0 0 1 0 1 1 1 0 0 1 0 0 1\n",
            " 0 1 0 1 0 0 0 1 0 1 1 1 0 0 1 0 0 1 1 1 1 0 0 0 1 1 0 0 1 0 1 1 1 1 0 0 1\n",
            " 0 0 0 0 0 1 0 0 1 1 1 1 0 1 0 0 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 0 1 0 0 1 1\n",
            " 1 1 1 1 0 1 0 0 0 0 1 1 1 1 0 0 0 0 0 1 0 1 0 1 1 0 1 1 0 0 1 0 1 0 1 1 0\n",
            " 0 1 0 1 1 1 1 0 1 1 1 0 0 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 1 0 1 1 0 1 1 1\n",
            " 0 0 1 0 1 1 1 0 0 0 1 0 1 0 1 0 1 0 1 1 1 1 1 1 0 1 0 1 0 1 1 0 1 0 1 0 1\n",
            " 1 1 1 0 0 1 1 0 1 1 0 0 1 1 0 1 1 1 0 0 0]\n",
            "probabilities: (872, 2) \n",
            " [1 0 1 1 0 0 1 0 0 1 1 1 1 0 1 0 1 0 0 1 0 0 1 0 1 1 1 0 1 1 1 0 0 1 1 0 0\n",
            " 1 0 1 0 0 1 1 1 1 0 1 1 1 1 0 1 0 0 1 0 0 1 1 1 1 1 1 1 1 0 1 0 1 1 0 0 0\n",
            " 0 1 0 1 1 1 1 0 1 0 0 0 1 1 1 0 0 1 0 0 1 0 1 0 1 1 1 1 0 1 0 0 1 0 0 1 0\n",
            " 0 1 1 1 1 0 1 0 1 1 0 0 1 1 1 0 1 1 1 1 1 0 1 0 1 1 0 0 0 1 1 0 1 1 1 0 1\n",
            " 0 0 0 1 0 1 1 1 1 1 1 0 1 0 1 1 0 1 1 1 0 0 0 1 0 0 1 1 1 0 0 0 0 0 0 1 0\n",
            " 0 1 0 0 1 0 1 1 0 1 1 0 0 1 1 0 0 0 0 0 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 0 1\n",
            " 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 0 1 0 1 1 1 1 1 0 0 1 1 0 1 0 0 1 1 1 1 1 1\n",
            " 0 0 0 0 0 1 0 1 0 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 1 1 1 1 1 1 1 1 0 1 1 0 1\n",
            " 0 1 0 1 0 0 1 1 1 1 0 0 1 0 1 1 0 1 1 0 0 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1\n",
            " 1 1 1 0 1 1 1 1 0 0 0 1 1 0 1 1 1 0 1 1 0 1 0 1 0 1 1 1 1 0 1 1 0 1 0 1 1\n",
            " 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 0 0 0 1 1 0 1 0 1 0 0 1 0 1 1 1 0 0 1 1 1\n",
            " 1 1 0 1 0 1 1 0 0 0 0 0 1 1 1 1 1 1 0 0 0 1 1 1 0 1 0 0 0 1 0 0 0 1 1 0 0\n",
            " 0 1 1 1 0 1 0 0 0 1 1 1 0 1 1 1 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 1 0 1 1 0\n",
            " 0 0 0 1 1 0 1 0 1 1 0 1 1 0 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1\n",
            " 1 1 1 1 1 1 1 1 0 0 1 1 0 1 0 1 0 1 1 1 0 1 1 1 1 0 1 1 1 0 0 1 0 0 1 0 0\n",
            " 1 0 1 0 1 1 1 1 1 1 0 0 1 1 0 1 1 0 1 1 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1\n",
            " 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 0 1 1 0 0 0 1 1 0 1 1 1 0 0 1 1 0\n",
            " 0 1 0 1 1 0 1 1 1 1 0 0 1 0 1 0 1 1 1 1 1 0 0 0 0 0 1 0 1 1 1 0 0 1 0 0 1\n",
            " 0 1 0 1 0 0 0 1 0 1 1 1 0 0 1 0 0 1 1 1 1 0 0 0 1 1 0 0 1 0 1 1 1 1 0 0 1\n",
            " 0 0 0 0 0 1 0 0 1 1 1 1 0 1 0 0 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 0 1 0 0 1 1\n",
            " 1 1 1 1 0 1 0 0 0 0 1 1 1 1 0 0 0 0 0 1 0 1 0 1 1 0 1 1 0 0 1 0 1 0 1 1 0\n",
            " 0 1 0 1 1 1 1 0 1 1 1 0 0 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 1 0 1 1 0 1 1 1\n",
            " 0 0 1 0 1 1 1 0 0 0 1 0 1 0 1 0 1 0 1 1 1 1 1 1 0 1 0 1 0 1 1 0 1 0 1 0 1\n",
            " 1 1 1 0 0 1 1 0 1 1 0 0 1 1 0 1 1 1 0 0 0]\n",
            "std (872,) [40. 10. 50. 40. 10. 30. 20. 30. 30. 50. 20. 40. 40. 40. 30. 20. 10. 20.\n",
            " 20. 20. 10. 30. 20. 20. 10. 40. 30. 20. 10. 30. 30. 20. 40. 20. 40. 40.\n",
            " 50. 40. 30. 40. 10. 50. 30. 20. 20. 40. 20. 30. 40. 40. 40. 30. 40. 20.\n",
            "  0. 20. 30. 40. 30. 20. 40. 20. 50. 20. 40. 50. 30. 30. 50. 40. 50. 20.\n",
            " 30. 30. 30. 30. 30. 40. 50. 30. 40. 30. 30. 30. 20. 20. 30. 30. 20. 40.\n",
            " 40. 40. 40. 30. 40. 30. 20. 30. 40. 20. 20. 30. 20. 30. 30. 30. 30. 40.\n",
            " 40. 30. 30. 20. 50. 20. 20. 30. 30. 10. 40. 50. 30. 20. 30. 10. 10. 20.\n",
            " 20. 20. 40. 40. 30. 10. 30. 30. 30. 50. 50. 10. 10. 20. 40. 30. 10. 20.\n",
            " 40. 50. 30. 40. 10. 20. 10. 30. 40. 40. 40. 40. 30. 40. 20. 30. 30. 20.\n",
            " 40. 20. 30. 40. 30. 30. 30. 30. 30. 20. 20. 40. 30. 20. 30. 30. 30. 20.\n",
            " 20. 30. 30. 30. 30. 30. 40. 40. 40. 20. 40. 30. 40. 50. 40. 30. 30. 40.\n",
            " 40. 40. 20. 30. 30. 40. 20.  0. 50. 20. 40. 40. 30. 40. 40. 20. 20. 30.\n",
            " 50. 30. 30. 30. 20. 30. 30. 50. 40. 40. 30. 30. 40. 30. 40. 20. 30. 30.\n",
            " 20. 30. 30. 20. 50. 10. 40. 30. 40. 20. 30. 50. 20. 20. 30. 40. 40. 20.\n",
            " 30. 50. 20. 40. 40. 40. 50. 40. 20. 30. 20. 20. 50. 20. 50. 40. 30. 10.\n",
            " 30. 20. 30. 20. 40. 30. 20. 40. 10. 30. 30. 40. 40. 40. 30. 40. 40. 30.\n",
            " 20. 40. 30. 20. 30. 40. 50. 30. 30. 50. 30. 50. 40. 40. 30. 40. 40. 10.\n",
            " 40. 50. 50. 40. 30. 50. 30. 20. 20. 30. 50. 40. 50. 20. 40. 40. 40. 50.\n",
            " 30. 30. 50. 30. 50. 20. 30. 40. 40. 50. 50. 20. 10. 30. 50. 30. 30. 30.\n",
            " 40. 40. 50. 20. 40. 20. 30. 20. 10. 50. 30. 20. 20. 20. 50. 40. 40. 10.\n",
            " 40. 30. 30. 50. 30. 30. 40. 20. 10. 10. 40. 30. 20. 50. 20. 40. 40. 30.\n",
            " 50. 30. 20. 50. 20. 40. 40. 40. 30. 20. 20. 30. 30. 30. 30. 20. 50. 30.\n",
            " 20. 30. 20. 30. 40. 30. 30. 20. 40. 30. 20. 30. 30. 40. 30. 50. 40. 50.\n",
            " 30. 30. 20. 20. 10. 30. 40. 30. 20. 20. 40. 40. 30. 50. 20. 40. 20. 10.\n",
            " 50. 40. 20. 20. 50. 20. 20. 40. 30. 30. 20. 10. 20. 40. 10. 30. 40. 30.\n",
            " 30. 10. 20. 50. 40. 50. 30. 30. 40. 40. 40. 30. 20. 30. 40. 50. 30. 40.\n",
            " 40. 30. 50. 40. 30. 40. 30. 40. 20. 30. 30. 40. 30. 10. 20. 40. 40. 40.\n",
            " 20. 30. 40. 30. 30. 30. 30. 40.  0. 40. 40. 50. 30. 20. 30. 40. 10. 30.\n",
            " 40. 40. 30. 30. 20. 50. 30. 50. 40. 40. 30. 30. 20. 50. 30. 20. 30. 30.\n",
            " 30. 50. 20. 40. 40. 40. 20. 40. 30. 30.  0. 50. 40. 40. 50. 50. 30. 30.\n",
            " 50. 30. 50. 10. 50. 30. 40. 30. 20. 20. 20. 20. 40. 40. 40. 50. 20. 30.\n",
            " 30. 30. 50. 40. 50. 40. 30. 10. 40. 30. 10. 30. 30. 50. 40. 50. 40. 50.\n",
            " 20. 30. 50. 30. 40. 30. 20.  0. 40. 50. 30. 40. 20. 50. 20. 30. 30. 30.\n",
            " 30. 20. 40. 20. 40. 40. 50. 20. 50. 50. 30. 50. 30. 20. 20. 20. 40. 40.\n",
            " 40. 30. 40. 20. 20. 20. 40. 30. 10. 30. 50. 40. 20. 10. 10. 40. 40. 40.\n",
            " 40. 30. 50. 20. 30. 10. 40. 30. 40. 30. 50. 50. 30. 40. 20. 10. 40. 20.\n",
            " 50. 40. 40. 20. 40. 20. 40. 20. 20. 40. 30. 50. 30. 20. 20. 30. 40. 50.\n",
            " 20. 50. 40. 20. 30. 20. 50. 40. 40. 40. 40. 20. 30. 30. 40. 30. 30. 30.\n",
            " 30. 20. 40. 30. 40. 20. 30. 30. 30. 40. 30. 20. 50. 40. 40. 40. 20. 40.\n",
            " 30. 30. 30. 30. 40. 50. 30. 30. 20. 50. 40. 30. 40. 40. 30. 20. 40. 40.\n",
            " 40. 30. 40. 30. 20. 40. 40. 20. 20. 30. 30. 20. 20. 10. 30. 50. 30. 20.\n",
            " 40. 20. 40. 50. 40. 30. 20. 30. 30. 10. 30. 20. 50. 30. 30. 40. 40. 40.\n",
            " 40. 20.  0. 40. 30. 20. 20. 30. 40. 30. 50. 40. 10. 30. 20. 30. 20. 20.\n",
            " 30. 50. 40. 20. 30. 30. 40. 30. 30. 20. 50. 30. 40. 50. 40. 30. 50. 20.\n",
            " 30. 20. 40. 40. 40. 20. 20. 30. 30. 10. 20. 30. 30. 30. 10. 30. 30. 30.\n",
            " 40. 50. 50. 50. 20. 30. 20. 20. 40. 50. 50. 30. 30. 10. 30. 30. 40. 30.\n",
            " 30. 20. 40. 30. 20. 40. 40. 40. 50. 40. 20. 30. 20. 50. 30. 30. 30. 30.\n",
            " 10. 10. 50. 20. 20. 40. 40. 20. 40. 20. 20. 40. 20. 30. 30. 20. 40. 40.\n",
            " 10. 40. 40. 50. 40. 20. 30. 40.]\n",
            "selection [ 54 583 205 532 494 758 124  40 418 123] (10,) [ 0.  0.  0.  0.  0.  0. 10. 10. 10. 10.]\n",
            "trainset before adding uncertain samples (430, 10) (430,)\n",
            "trainset after adding uncertain samples (440, 10) (440,)\n",
            "updated train set: (440, 10) (440,) unique(labels): [225 215] [0 1]\n",
            "val set: (862, 10) (862,)\n",
            "\n",
            "Train set: (440, 10)\n",
            "Validation set: (862, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 44\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.074 s \n",
            "\n",
            "Accuracy rate is 79.953917 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.89      0.87       321\n",
            "           1       0.64      0.54      0.58       113\n",
            "\n",
            "    accuracy                           0.80       434\n",
            "   macro avg       0.74      0.72      0.73       434\n",
            "weighted avg       0.79      0.80      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[286  35]\n",
            " [ 52  61]]\n",
            "--------------------------------\n",
            "val predicted: (862,) [1 0 1 1 0 0 1 0 0 1 1 1 1 0 1 0 1 0 0 1 0 0 1 0 1 1 1 0 1 1 1 0 0 1 1 0 0\n",
            " 1 0 1 0 1 1 1 1 0 1 1 1 1 0 1 0 1 0 0 1 1 1 1 1 1 1 1 0 1 0 1 1 0 0 0 0 1\n",
            " 0 1 1 1 1 0 1 0 0 0 1 1 1 0 0 1 0 0 1 0 1 0 1 1 1 1 0 1 0 0 1 0 0 1 0 0 1\n",
            " 1 1 1 0 1 0 1 1 0 0 1 0 1 1 1 1 1 0 1 0 1 1 0 0 0 1 1 0 1 1 1 0 1 0 0 0 1\n",
            " 0 1 1 1 1 1 1 0 1 0 1 1 0 1 1 1 0 0 0 1 0 0 1 1 1 0 0 0 0 0 0 1 0 0 1 0 0\n",
            " 1 0 1 1 0 1 1 0 0 1 1 0 0 0 0 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1\n",
            " 1 0 1 1 0 1 1 1 1 1 0 1 0 1 1 1 1 1 0 0 1 1 0 1 0 0 1 1 1 1 1 1 0 0 0 0 0\n",
            " 1 0 1 0 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 1 1 1 1 1 1 1 1 0 1 1 0 1 0 1 0 1 0\n",
            " 0 1 1 1 1 0 0 1 0 1 1 0 1 1 0 0 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1\n",
            " 1 1 1 0 0 0 1 1 0 1 1 1 0 1 1 0 1 0 1 0 1 1 1 1 0 1 1 0 1 0 1 1 1 1 1 1 0\n",
            " 1 1 0 1 1 0 1 1 1 1 1 0 0 0 1 1 0 1 0 1 0 0 1 0 1 1 1 0 0 1 1 1 1 1 0 1 0\n",
            " 1 1 0 0 0 0 1 1 1 1 1 1 0 0 0 1 1 1 0 1 0 0 0 1 0 0 0 1 1 0 0 0 1 1 1 0 1\n",
            " 0 0 0 1 1 1 0 1 1 1 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 1 0 1 1 0 0 0 0 1 1 0\n",
            " 1 0 1 1 0 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1 1 1 1 1 1\n",
            " 1 0 0 1 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 0 0 1 0 0 1 0 0 1 0 1 0 1 1 1 1\n",
            " 1 1 0 0 1 1 0 1 1 0 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1\n",
            " 1 1 1 1 1 1 1 0 0 0 1 0 1 1 0 0 0 1 1 0 1 1 1 0 0 1 1 0 0 1 0 1 1 0 1 1 1\n",
            " 1 0 0 1 0 1 0 1 1 1 1 1 0 0 0 0 0 1 0 1 1 1 0 0 1 0 0 1 0 1 0 1 0 0 0 1 0\n",
            " 1 1 1 0 0 1 0 0 1 1 1 1 0 0 0 1 1 0 0 1 0 1 1 1 1 0 0 1 0 0 0 0 0 1 0 0 1\n",
            " 1 1 1 0 1 0 0 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 0 1 0 0 0\n",
            " 0 1 1 1 1 0 0 0 0 1 0 1 0 1 1 0 1 1 0 0 1 0 1 0 1 1 0 0 1 0 1 1 1 1 0 1 1\n",
            " 1 0 0 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 1 0 1 1 0 1 1 1 0 0 1 0 1 1 1 0 0 0\n",
            " 1 0 1 0 1 0 1 0 1 1 1 1 1 1 0 1 0 1 0 1 1 0 1 0 1 0 1 1 1 1 0 0 1 1 0 1 1\n",
            " 0 0 1 1 0 1 1 1 0 0 0]\n",
            "probabilities: (862, 2) \n",
            " [1 0 1 1 0 0 1 0 0 1 1 1 1 0 1 0 1 0 0 1 0 0 1 0 1 1 1 0 1 1 1 0 0 1 1 0 0\n",
            " 1 0 1 0 1 1 1 1 0 1 1 1 1 0 1 0 1 0 0 1 1 1 1 1 1 1 1 0 1 0 1 1 0 0 0 0 1\n",
            " 0 1 1 1 1 0 1 0 0 0 1 1 1 0 0 1 0 0 1 0 1 0 1 1 1 1 0 1 0 0 1 0 0 1 0 0 1\n",
            " 1 1 1 0 1 0 1 1 0 0 1 0 1 1 1 1 1 0 1 0 1 1 0 0 0 1 1 0 1 1 1 0 1 0 0 0 1\n",
            " 0 1 1 1 1 1 1 0 1 0 1 1 0 1 1 1 0 0 0 1 0 0 1 1 1 0 0 0 0 0 0 1 0 0 1 0 0\n",
            " 1 0 1 1 0 1 1 0 0 1 1 0 0 0 0 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1\n",
            " 1 0 1 1 0 1 1 1 1 1 0 1 0 1 1 1 1 1 0 0 1 1 0 1 0 0 1 1 1 1 1 1 0 0 0 0 0\n",
            " 1 0 1 0 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 1 1 1 1 1 1 1 1 0 1 1 0 1 0 1 0 1 0\n",
            " 0 1 1 1 1 0 0 1 0 1 1 0 1 1 0 0 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1\n",
            " 1 1 1 0 0 0 1 1 0 1 1 1 0 1 1 0 1 0 1 0 1 1 1 1 0 1 1 0 1 0 1 1 1 1 1 1 0\n",
            " 1 1 0 1 1 0 1 1 1 1 1 0 0 0 1 1 0 1 0 1 0 0 1 0 1 1 1 0 0 1 1 1 1 1 0 1 0\n",
            " 1 1 0 0 0 0 1 1 1 1 1 1 0 0 0 1 1 1 0 1 0 0 0 1 0 0 0 1 1 0 0 0 1 1 1 0 1\n",
            " 0 0 0 1 1 1 0 1 1 1 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 1 0 1 1 0 0 0 0 1 1 0\n",
            " 1 0 1 1 0 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1 1 1 1 1 1\n",
            " 1 0 0 1 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 0 0 1 0 0 1 0 0 1 0 1 0 1 1 1 1\n",
            " 1 1 0 0 1 1 0 1 1 0 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1\n",
            " 1 1 1 1 1 1 1 0 0 0 1 0 1 1 0 0 0 1 1 0 1 1 1 0 0 1 1 0 0 1 0 1 1 0 1 1 1\n",
            " 1 0 0 1 0 1 0 1 1 1 1 1 0 0 0 0 0 1 0 1 1 1 0 0 1 0 0 1 0 1 0 1 0 0 0 1 0\n",
            " 1 1 1 0 0 1 0 0 1 1 1 1 0 0 0 1 1 0 0 1 0 1 1 1 1 0 0 1 0 0 0 0 0 1 0 0 1\n",
            " 1 1 1 0 1 0 0 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 0 1 0 0 0\n",
            " 0 1 1 1 1 0 0 0 0 1 0 1 0 1 1 0 1 1 0 0 1 0 1 0 1 1 0 0 1 0 1 1 1 1 0 1 1\n",
            " 1 0 0 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 1 0 1 1 0 1 1 1 0 0 1 0 1 1 1 0 0 0\n",
            " 1 0 1 0 1 0 1 0 1 1 1 1 1 1 0 1 0 1 0 1 1 0 1 0 1 0 1 1 1 1 0 0 1 1 0 1 1\n",
            " 0 0 1 1 0 1 1 1 0 0 0]\n",
            "std (862,) [40. 10. 50. 40. 10. 30. 20. 30. 30. 50. 20. 40. 40. 30. 30. 20. 20. 20.\n",
            " 20. 20. 10. 30. 30. 20. 10. 40. 40. 20. 10. 30. 30. 20. 40. 20. 40. 40.\n",
            " 50. 40. 30. 40. 50. 30. 20. 30. 40. 20. 30. 40. 40. 40. 30. 40. 20. 20.\n",
            " 30. 40. 30. 20. 40. 20. 50. 10. 40. 50. 30. 30. 50. 40. 50. 20. 30. 30.\n",
            " 30. 30. 30. 40. 50. 30. 40. 30. 30. 30. 20. 20. 30. 20. 20. 50. 50. 40.\n",
            " 40. 30. 40. 30. 30. 40. 40. 20. 20. 30. 20. 30. 30. 30. 30. 40. 40. 30.\n",
            " 30. 20. 50. 20. 20. 30. 30. 10. 40. 50. 30. 20. 30. 30. 30. 20. 40. 40.\n",
            " 30. 30. 30. 30. 30. 50. 50. 10. 10. 20. 40. 30. 20. 20. 40. 50. 30. 40.\n",
            " 10. 30. 10. 30. 40. 40. 40. 50. 30. 40. 20. 40. 30. 30. 40. 20. 30. 40.\n",
            " 30. 30. 30. 30. 30. 20. 20. 40. 30. 20. 30. 30. 40. 30. 40. 30. 30. 30.\n",
            " 30. 30. 40. 40. 40. 20. 50. 30. 40. 50. 40. 30. 20. 40. 40. 40. 20. 30.\n",
            " 40. 40. 20. 50. 20. 40. 40. 30. 30. 40. 20. 30. 30. 40. 30. 30. 30. 20.\n",
            " 30. 30. 50. 40. 40. 30. 30. 40. 30. 40. 40. 30. 30. 20. 30. 30. 20. 50.\n",
            " 10. 40. 30. 40. 20. 30. 50. 40. 20. 30. 40. 40. 30. 30. 50. 20. 40. 50.\n",
            " 40. 50. 40. 20. 30. 20. 20. 50. 20. 50. 40. 30. 10. 30. 30. 30. 20. 40.\n",
            " 20. 20. 40. 10. 30. 30. 40. 40. 40. 30. 40. 40. 30. 20. 40. 30. 20. 30.\n",
            " 40. 50. 30. 30. 50. 30. 50. 30. 40. 30. 40. 40. 20. 30. 50. 50. 40. 30.\n",
            " 50. 30. 40. 20. 30. 50. 40. 50. 20. 50. 40. 40. 50. 30. 30. 50. 30. 50.\n",
            " 20. 30. 40. 40. 50. 50. 20. 10. 30. 50. 30. 30. 30. 40. 40. 50. 20. 40.\n",
            " 20. 30. 20. 10. 50. 30. 20. 20. 30. 50. 40. 40. 10. 40. 30. 30. 50. 30.\n",
            " 30. 50. 20. 10. 10. 50. 30. 20. 40. 20. 40. 50. 30. 50. 30. 20. 50. 20.\n",
            " 40. 40. 40. 30. 30. 20. 30. 30. 30. 30. 20. 50. 30. 20. 30. 20. 30. 40.\n",
            " 40. 30. 30. 40. 30. 20. 30. 30. 40. 30. 50. 40. 50. 30. 30. 20. 20. 30.\n",
            " 40. 30. 20. 20. 40. 40. 30. 50. 20. 40. 20. 20. 50. 40. 20. 30. 50. 20.\n",
            " 30. 40. 30. 30. 30. 20. 20. 40. 10. 30. 40. 30. 30. 10. 30. 50. 40. 50.\n",
            " 40. 30. 40. 40. 40. 40. 20. 30. 40. 50. 30. 40. 40. 30. 50. 40. 30. 40.\n",
            " 30. 40. 30. 30. 30. 40. 30. 10. 20. 40. 40. 40. 30. 30. 40. 30. 30. 30.\n",
            " 30. 40. 40. 40. 50. 30. 20. 30. 40. 10. 30. 40. 40. 30. 30. 20. 50. 30.\n",
            " 50. 30. 40. 40. 30. 30. 50. 40. 20. 30. 30. 30. 50. 20. 40. 40. 40. 30.\n",
            " 40. 30. 40. 50. 40. 40. 50. 50. 30. 30. 50. 30. 50. 20. 50. 30. 40. 30.\n",
            " 20. 20. 30. 20. 40. 30. 40. 50. 20. 30. 30. 30. 50. 40. 50. 30. 30. 20.\n",
            " 40. 30. 10. 30. 30. 50. 40. 50. 40. 50. 20. 40. 50. 40. 40. 30. 20. 40.\n",
            " 50. 30. 50. 20. 50. 30. 30. 30. 30. 30. 20. 40. 20. 30. 40. 50. 20. 50.\n",
            " 50. 30. 50. 30. 20. 20. 20. 40. 40. 40. 30. 40. 10. 20. 20. 40. 30. 10.\n",
            " 40. 50. 40. 20. 10. 10. 40. 40. 40. 40. 30. 50. 20. 30. 20. 40. 20. 40.\n",
            " 30. 50. 50. 30. 40. 20. 20. 40. 30. 50. 40. 40. 20. 40. 20. 40. 20. 30.\n",
            " 40. 30. 50. 30. 20. 30. 40. 40. 50. 20. 50. 40. 20. 30. 20. 50. 40. 40.\n",
            " 40. 40. 20. 30. 20. 40. 30. 30. 30. 30. 20. 40. 30. 40. 20. 30. 30. 40.\n",
            " 40. 30. 20. 50. 40. 40. 40. 20. 40. 30. 30. 40. 30. 40. 50. 30. 40. 20.\n",
            " 50. 40. 30. 40. 40. 30. 20. 40. 30. 40. 30. 30. 30. 20. 40. 40. 20. 20.\n",
            " 30. 30. 20. 20. 20. 30. 50. 30. 20. 40. 20. 40. 50. 40. 40. 20. 30. 30.\n",
            " 20. 40. 20. 50. 30. 30. 40. 40. 40. 30. 20. 40. 30. 20. 20. 30. 40. 30.\n",
            " 50. 40. 10. 30. 20. 30. 30. 20. 30. 50. 40. 20. 30. 40. 40. 30. 30. 20.\n",
            " 50. 30. 40. 50. 40. 30. 50. 20. 30. 20. 40. 40. 40. 20. 20. 30. 30. 20.\n",
            " 20. 30. 30. 30. 20. 30. 30. 30. 40. 50. 50. 50. 20. 30. 20. 30. 40. 50.\n",
            " 50. 30. 30. 20. 30. 30. 40. 30. 30. 20. 50. 30. 20. 40. 40. 40. 50. 40.\n",
            " 20. 30. 20. 50. 30. 30. 30. 30. 10. 20. 50. 20. 20. 40. 40. 20. 40. 20.\n",
            " 20. 40. 20. 30. 30. 30. 40. 40. 10. 40. 40. 50. 40. 20. 30. 30.]\n",
            "selection [133  20 115  24 354 331 836  28 363 364] (10,) [10. 10. 10. 10. 10. 10. 10. 10. 10. 10.]\n",
            "trainset before adding uncertain samples (440, 10) (440,)\n",
            "trainset after adding uncertain samples (450, 10) (450,)\n",
            "updated train set: (450, 10) (450,) unique(labels): [229 221] [0 1]\n",
            "val set: (852, 10) (852,)\n",
            "\n",
            "Train set: (450, 10)\n",
            "Validation set: (852, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 45\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.085 s \n",
            "\n",
            "Accuracy rate is 79.493088 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.88      0.86       321\n",
            "           1       0.62      0.54      0.58       113\n",
            "\n",
            "    accuracy                           0.79       434\n",
            "   macro avg       0.73      0.71      0.72       434\n",
            "weighted avg       0.79      0.79      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[284  37]\n",
            " [ 52  61]]\n",
            "--------------------------------\n",
            "val predicted: (852,) [1 0 1 1 0 0 1 0 0 1 1 1 1 0 1 0 1 0 0 1 0 1 0 1 1 0 1 1 0 0 1 1 0 0 1 0 1\n",
            " 0 1 1 1 1 0 1 1 1 1 0 1 0 1 0 0 1 1 1 1 1 1 1 1 0 1 0 1 1 0 0 0 0 1 0 1 1\n",
            " 1 1 0 1 0 0 0 1 1 1 0 0 1 0 0 1 0 1 0 1 1 1 1 0 1 0 0 1 0 0 1 0 0 1 1 1 1\n",
            " 0 0 1 1 0 0 1 0 1 1 1 1 1 0 1 0 1 1 0 0 1 1 0 1 1 1 0 1 0 0 0 1 0 1 1 1 1\n",
            " 1 1 0 1 0 1 1 0 1 1 1 0 0 0 1 0 0 1 1 1 0 0 0 0 0 0 1 0 0 1 0 0 1 0 1 1 0\n",
            " 1 1 0 0 1 1 0 0 0 0 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 1 0 1 1 0\n",
            " 1 1 1 1 1 0 1 0 1 1 1 1 1 0 0 1 1 0 1 0 0 1 1 1 1 1 1 0 0 0 0 0 1 0 1 0 0\n",
            " 1 0 1 0 1 0 0 0 1 0 0 0 0 0 1 1 1 1 1 1 1 1 0 1 1 0 1 0 1 0 1 0 0 1 1 1 1\n",
            " 0 0 1 0 1 1 0 1 1 0 0 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0\n",
            " 1 1 0 1 1 1 0 1 1 0 1 0 1 0 1 1 1 0 1 1 0 1 0 1 1 1 1 0 1 1 0 1 1 0 1 1 1\n",
            " 1 1 0 0 0 1 1 0 1 0 1 0 0 1 0 1 1 1 0 0 1 1 1 1 1 0 1 0 1 1 0 0 0 0 1 1 1\n",
            " 1 1 1 0 0 0 1 1 1 0 1 0 0 0 1 0 0 0 1 1 0 0 0 1 1 1 0 1 0 0 0 1 1 1 0 1 1\n",
            " 1 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 1 0 1 1 0 0 0 0 1 1 0 1 0 1 1 0 1 1 1 0\n",
            " 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1 1 1 1 1 1 1 0 0 1 1 0 1 1 0\n",
            " 1 1 1 0 1 1 1 1 0 1 1 1 0 0 1 0 0 1 0 0 1 0 1 0 1 1 1 1 1 1 0 0 1 1 0 1 1\n",
            " 0 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0\n",
            " 0 1 0 1 1 0 0 0 1 1 0 1 1 1 0 0 1 1 0 0 1 0 1 1 0 1 1 1 1 0 0 1 0 1 0 1 1\n",
            " 1 1 1 0 0 0 0 0 1 0 1 1 1 0 0 1 0 0 1 0 1 0 1 0 0 0 1 0 1 1 1 0 0 1 0 0 1\n",
            " 1 1 1 0 0 0 1 1 0 0 1 0 1 1 1 1 0 0 1 0 0 0 0 0 1 0 0 1 1 1 1 0 1 0 0 1 0\n",
            " 0 0 0 0 1 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 0 1 0 0 0 0 1 1 1 1 0 0 0 0\n",
            " 1 0 1 0 1 1 0 1 1 0 0 1 0 1 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1 0 0 1 1 0 1 0 1\n",
            " 1 1 1 1 1 0 0 1 1 1 1 0 1 1 0 1 1 1 0 0 1 0 1 1 1 0 0 0 1 0 1 0 1 0 1 0 1\n",
            " 1 1 1 1 1 0 1 0 1 0 1 1 0 0 1 0 1 1 1 1 0 0 1 1 0 1 1 0 0 1 1 0 1 1 1 0 0\n",
            " 0]\n",
            "probabilities: (852, 2) \n",
            " [1 0 1 1 0 0 1 0 0 1 1 1 1 0 1 0 1 0 0 1 0 1 0 1 1 0 1 1 0 0 1 1 0 0 1 0 1\n",
            " 0 1 1 1 1 0 1 1 1 1 0 1 0 1 0 0 1 1 1 1 1 1 1 1 0 1 0 1 1 0 0 0 0 1 0 1 1\n",
            " 1 1 0 1 0 0 0 1 1 1 0 0 1 0 0 1 0 1 0 1 1 1 1 0 1 0 0 1 0 0 1 0 0 1 1 1 1\n",
            " 0 0 1 1 0 0 1 0 1 1 1 1 1 0 1 0 1 1 0 0 1 1 0 1 1 1 0 1 0 0 0 1 0 1 1 1 1\n",
            " 1 1 0 1 0 1 1 0 1 1 1 0 0 0 1 0 0 1 1 1 0 0 0 0 0 0 1 0 0 1 0 0 1 0 1 1 0\n",
            " 1 1 0 0 1 1 0 0 0 0 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 1 0 1 1 0\n",
            " 1 1 1 1 1 0 1 0 1 1 1 1 1 0 0 1 1 0 1 0 0 1 1 1 1 1 1 0 0 0 0 0 1 0 1 0 0\n",
            " 1 0 1 0 1 0 0 0 1 0 0 0 0 0 1 1 1 1 1 1 1 1 0 1 1 0 1 0 1 0 1 0 0 1 1 1 1\n",
            " 0 0 1 0 1 1 0 1 1 0 0 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0\n",
            " 1 1 0 1 1 1 0 1 1 0 1 0 1 0 1 1 1 0 1 1 0 1 0 1 1 1 1 0 1 1 0 1 1 0 1 1 1\n",
            " 1 1 0 0 0 1 1 0 1 0 1 0 0 1 0 1 1 1 0 0 1 1 1 1 1 0 1 0 1 1 0 0 0 0 1 1 1\n",
            " 1 1 1 0 0 0 1 1 1 0 1 0 0 0 1 0 0 0 1 1 0 0 0 1 1 1 0 1 0 0 0 1 1 1 0 1 1\n",
            " 1 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 1 0 1 1 0 0 0 0 1 1 0 1 0 1 1 0 1 1 1 0\n",
            " 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1 1 1 1 1 1 1 0 0 1 1 0 1 1 0\n",
            " 1 1 1 0 1 1 1 1 0 1 1 1 0 0 1 0 0 1 0 0 1 0 1 0 1 1 1 1 1 1 0 0 1 1 0 1 1\n",
            " 0 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0\n",
            " 0 1 0 1 1 0 0 0 1 1 0 1 1 1 0 0 1 1 0 0 1 0 1 1 0 1 1 1 1 0 0 1 0 1 0 1 1\n",
            " 1 1 1 0 0 0 0 0 1 0 1 1 1 0 0 1 0 0 1 0 1 0 1 0 0 0 1 0 1 1 1 0 0 1 0 0 1\n",
            " 1 1 1 0 0 0 1 1 0 0 1 0 1 1 1 1 0 0 1 0 0 0 0 0 1 0 0 1 1 1 1 0 1 0 0 1 0\n",
            " 0 0 0 0 1 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 0 1 0 0 0 0 1 1 1 1 0 0 0 0\n",
            " 1 0 1 0 1 1 0 1 1 0 0 1 0 1 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1 0 0 1 1 0 1 0 1\n",
            " 1 1 1 1 1 0 0 1 1 1 1 0 1 1 0 1 1 1 0 0 1 0 1 1 1 0 0 0 1 0 1 0 1 0 1 0 1\n",
            " 1 1 1 1 1 0 1 0 1 0 1 1 0 0 1 0 1 1 1 1 0 0 1 1 0 1 1 0 0 1 1 0 1 1 1 0 0\n",
            " 0]\n",
            "std (852,) [40. 10. 50. 40. 10. 30. 20. 30. 30. 40. 20. 40. 40. 20. 40. 20. 20. 20.\n",
            " 20. 20. 30. 30. 20. 40. 40. 20. 30. 30. 20. 30. 20. 30. 40. 50. 40. 30.\n",
            " 40. 50. 30. 20. 20. 40. 20. 30. 40. 40. 40. 30. 40. 20. 10. 30. 40. 30.\n",
            " 20. 40. 20. 50. 20. 40. 50. 30. 30. 50. 40. 40. 20. 30. 30. 30. 30. 30.\n",
            " 40. 50. 20. 40. 30. 30. 30. 20. 20. 30. 20. 20. 50. 50. 40. 40. 30. 50.\n",
            " 30. 20. 40. 40. 20. 20. 20. 20. 30. 30. 30. 30. 40. 40. 30. 40. 30. 50.\n",
            " 20. 20. 40. 30. 40. 50. 30. 20. 30. 30. 30. 20. 40. 40. 30. 30. 30. 20.\n",
            " 30. 50. 50. 10. 20. 40. 30. 20. 20. 40. 50. 40. 40. 10. 30. 10. 30. 30.\n",
            " 40. 40. 50. 30. 50. 20. 40. 30. 30. 40. 20. 30. 40. 30. 30. 30. 30. 30.\n",
            " 20. 20. 40. 30. 20. 20. 30. 40. 30. 40. 30. 30. 30. 30. 30. 40. 40. 40.\n",
            " 20. 50. 30. 40. 50. 40. 30. 30. 40. 50. 40. 20. 30. 40. 40. 20. 50. 20.\n",
            " 40. 40. 30. 30. 40. 20. 30. 30. 40. 40. 30. 30. 20. 30. 30. 50. 40. 40.\n",
            " 30. 30. 40. 20. 40. 40. 30. 30. 30. 30. 30. 20. 50. 10. 40. 30. 40. 10.\n",
            " 30. 50. 40. 20. 30. 40. 40. 40. 30. 40. 20. 40. 50. 40. 50. 40. 20. 30.\n",
            " 20. 20. 50. 20. 50. 40. 30. 20. 30. 30. 30. 30. 40. 30. 20. 40. 10. 30.\n",
            " 30. 50. 40. 40. 40. 40. 40. 30. 20. 40. 30. 20. 30. 40. 50. 30. 30. 50.\n",
            " 30. 50. 30. 40. 30. 40. 40. 20. 30. 50. 50. 40. 30. 40. 30. 40. 20. 30.\n",
            " 50. 40. 50. 20. 50. 40. 40. 50. 40. 30. 50. 30. 50. 20. 30. 40. 40. 50.\n",
            " 50. 20. 30. 50. 30. 30. 30. 30. 40. 50. 20. 40. 20. 30. 20. 10. 50. 30.\n",
            " 20. 20. 30. 50. 40. 40. 40. 30. 30. 40. 20. 30. 50. 20. 50. 30. 20. 40.\n",
            " 20. 40. 50. 30. 50. 30. 20. 50. 20. 40. 40. 40. 30. 30. 20. 20. 20. 30.\n",
            " 30. 20. 50. 30. 20. 20. 20. 30. 40. 40. 30. 30. 40. 30. 20. 30. 30. 40.\n",
            " 30. 50. 40. 40. 30. 30. 20. 20. 30. 40. 30. 20. 20. 50. 40. 30. 50. 20.\n",
            " 40. 30. 20. 50. 40. 20. 30. 50. 20. 30. 40. 30. 30. 30. 30. 20. 40. 10.\n",
            " 30. 40. 30. 30. 10. 30. 40. 40. 50. 40. 30. 40. 40. 40. 40. 20. 30. 40.\n",
            " 50. 30. 40. 40. 30. 50. 40. 30. 40. 30. 40. 30. 30. 20. 40. 30. 10. 20.\n",
            " 40. 40. 40. 30. 30. 40. 30. 30. 30. 20. 40. 40. 40. 50. 30. 20. 30. 40.\n",
            " 10. 30. 40. 40. 20. 30. 20. 40. 30. 50. 30. 40. 40. 30. 30. 50. 40. 20.\n",
            " 30. 40. 20. 50. 20. 40. 40. 40. 20. 40. 30. 40. 50. 40. 30. 50. 50. 30.\n",
            " 30. 50. 30. 50. 20. 50. 30. 30. 30. 20. 20. 30. 20. 40. 30. 40. 50. 20.\n",
            " 30. 30. 30. 40. 40. 50. 30. 20. 20. 40. 30. 10. 30. 30. 40. 40. 50. 30.\n",
            " 50. 30. 40. 50. 40. 40. 30. 20. 40. 50. 20. 50. 30. 50. 30. 30. 30. 30.\n",
            " 30. 20. 40. 20. 40. 40. 50. 20. 50. 40. 40. 50. 30. 20. 20. 20. 40. 40.\n",
            " 40. 30. 40. 10. 20. 20. 40. 30. 10. 40. 40. 40. 20. 10. 10. 40. 40. 40.\n",
            " 40. 30. 50. 20. 30. 20. 40. 20. 40. 30. 50. 50. 30. 40. 20. 20. 40. 20.\n",
            " 50. 40. 40. 20. 40. 20. 50. 20. 30. 40. 30. 50. 30. 20. 30. 40. 40. 50.\n",
            " 20. 50. 40. 20. 30. 20. 50. 40. 40. 40. 40. 30. 30. 20. 40. 30. 30. 30.\n",
            " 30. 20. 30. 30. 40. 20. 30. 30. 40. 40. 20. 20. 50. 40. 40. 40. 20. 40.\n",
            " 30. 30. 40. 30. 40. 50. 30. 40. 20. 50. 40. 30. 30. 40. 30. 20. 40. 40.\n",
            " 40. 30. 30. 30. 20. 40. 40. 30. 20. 30. 30. 20. 20. 20. 30. 50. 30. 20.\n",
            " 40. 20. 40. 50. 40. 40. 20. 30. 30. 10. 30. 20. 50. 30. 30. 30. 40. 50.\n",
            " 30. 20. 40. 40. 20. 20. 30. 40. 30. 40. 40. 10. 30. 20. 30. 30. 20. 30.\n",
            " 50. 40. 20. 30. 40. 40. 30. 30. 20. 50. 30. 40. 50. 40. 30. 50. 20. 30.\n",
            " 20. 40. 40. 40. 20. 20. 30. 30. 20. 20. 30. 30. 40. 20. 30. 30. 40. 40.\n",
            " 40. 50. 50. 20. 30. 20. 30. 40. 50. 50. 30. 30. 20. 30. 30. 40. 30. 30.\n",
            " 20. 30. 30. 20. 40. 40. 40. 50. 40. 20. 30. 20. 50. 40. 30. 30. 30. 20.\n",
            " 50. 20. 20. 40. 40. 20. 40. 20. 20. 40. 20. 30. 30. 30. 40. 40. 20. 40.\n",
            " 40. 50. 40. 20. 30. 30.]\n",
            "selection [466 608 607  50 602 597 436 339 749 486] (10,) [10. 10. 10. 10. 10. 10. 10. 10. 10. 10.]\n",
            "trainset before adding uncertain samples (450, 10) (450,)\n",
            "trainset after adding uncertain samples (460, 10) (460,)\n",
            "updated train set: (460, 10) (460,) unique(labels): [236 224] [0 1]\n",
            "val set: (842, 10) (842,)\n",
            "\n",
            "Train set: (460, 10)\n",
            "Validation set: (842, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 46\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.123 s \n",
            "\n",
            "Accuracy rate is 79.953917 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.89      0.87       321\n",
            "           1       0.63      0.55      0.59       113\n",
            "\n",
            "    accuracy                           0.80       434\n",
            "   macro avg       0.74      0.72      0.73       434\n",
            "weighted avg       0.79      0.80      0.79       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[285  36]\n",
            " [ 51  62]]\n",
            "--------------------------------\n",
            "val predicted: (842,) [1 0 1 1 0 0 1 0 0 1 1 1 1 0 1 0 1 0 0 1 0 1 0 1 1 0 1 1 0 0 1 1 0 0 1 0 1\n",
            " 0 1 1 1 1 0 1 1 1 1 0 1 0 0 0 1 1 1 1 1 1 1 1 0 1 0 1 1 0 0 0 0 1 0 1 1 1\n",
            " 1 0 1 0 0 0 1 1 1 0 0 1 0 0 1 0 1 0 1 1 1 1 0 1 0 0 1 0 0 1 0 0 1 1 1 1 0\n",
            " 0 1 1 0 0 1 0 1 1 1 1 1 0 1 0 1 1 0 0 1 1 0 1 1 1 0 1 0 0 0 1 0 1 1 1 1 1\n",
            " 1 0 1 0 1 1 0 1 1 1 0 0 0 1 0 0 1 1 1 0 0 0 0 0 0 1 0 0 1 0 0 1 0 1 1 0 1\n",
            " 1 0 0 1 1 0 0 0 0 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 1 0 1 1 0 1\n",
            " 1 1 1 1 0 1 0 1 1 1 1 1 0 0 1 1 0 1 0 0 1 1 1 1 1 1 0 0 0 0 0 1 0 1 0 0 1\n",
            " 0 1 0 1 0 0 0 1 0 0 0 0 0 1 1 1 1 1 1 1 1 0 1 1 0 1 0 1 0 1 0 0 1 1 1 1 0\n",
            " 0 1 0 1 1 0 1 1 0 0 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1\n",
            " 1 0 1 1 1 1 1 0 1 0 1 0 1 1 1 0 1 1 0 1 0 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1\n",
            " 0 0 0 1 1 0 1 0 1 0 0 1 0 1 1 1 0 0 1 1 1 1 1 0 1 0 1 1 0 0 0 0 1 1 1 1 1\n",
            " 1 0 0 0 1 1 1 0 1 0 0 0 1 0 0 0 1 1 0 0 0 1 1 1 0 1 0 0 1 1 1 0 1 1 1 1 1\n",
            " 1 1 1 0 0 1 1 0 1 0 1 1 1 1 1 0 1 1 0 0 0 1 1 0 1 0 1 1 0 1 1 1 0 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1 1 1 1 1 1 1 0 0 1 1 0 1 1 0 1 1 1 0 1\n",
            " 1 1 1 0 1 1 1 0 0 1 0 0 1 0 0 1 0 1 0 1 1 1 1 1 1 0 0 1 1 0 1 1 0 1 1 1 0\n",
            " 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 0 1 1\n",
            " 0 0 1 1 1 1 1 0 1 0 0 1 0 1 1 0 1 1 1 1 0 0 1 0 1 0 1 1 1 1 1 0 0 0 0 0 1\n",
            " 0 1 1 1 0 0 1 0 0 1 0 1 0 1 0 0 0 1 0 1 1 1 0 0 1 0 0 1 1 1 1 0 0 0 1 1 0\n",
            " 0 1 0 1 1 1 1 0 0 1 0 0 0 0 0 1 0 0 1 1 1 1 0 1 0 0 1 0 0 0 0 0 1 1 1 1 1\n",
            " 1 1 1 1 0 1 0 0 1 1 1 1 1 1 0 1 0 0 0 0 1 1 1 1 0 0 0 0 1 0 1 0 1 1 0 1 1\n",
            " 0 1 0 1 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1 0 0 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1\n",
            " 1 0 1 1 0 1 1 1 0 0 1 0 1 1 1 0 0 0 1 0 1 0 1 0 1 0 1 1 1 1 1 1 0 1 0 1 0\n",
            " 1 1 0 0 1 0 1 1 1 1 0 0 1 1 0 1 1 0 0 1 1 0 1 1 1 0 0 0]\n",
            "probabilities: (842, 2) \n",
            " [1 0 1 1 0 0 1 0 0 1 1 1 1 0 1 0 1 0 0 1 0 1 0 1 1 0 1 1 0 0 1 1 0 0 1 0 1\n",
            " 0 1 1 1 1 0 1 1 1 1 0 1 0 0 0 1 1 1 1 1 1 1 1 0 1 0 1 1 0 0 0 0 1 0 1 1 1\n",
            " 1 0 1 0 0 0 1 1 1 0 0 1 0 0 1 0 1 0 1 1 1 1 0 1 0 0 1 0 0 1 0 0 1 1 1 1 0\n",
            " 0 1 1 0 0 1 0 1 1 1 1 1 0 1 0 1 1 0 0 1 1 0 1 1 1 0 1 0 0 0 1 0 1 1 1 1 1\n",
            " 1 0 1 0 1 1 0 1 1 1 0 0 0 1 0 0 1 1 1 0 0 0 0 0 0 1 0 0 1 0 0 1 0 1 1 0 1\n",
            " 1 0 0 1 1 0 0 0 0 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 1 0 1 1 0 1\n",
            " 1 1 1 1 0 1 0 1 1 1 1 1 0 0 1 1 0 1 0 0 1 1 1 1 1 1 0 0 0 0 0 1 0 1 0 0 1\n",
            " 0 1 0 1 0 0 0 1 0 0 0 0 0 1 1 1 1 1 1 1 1 0 1 1 0 1 0 1 0 1 0 0 1 1 1 1 0\n",
            " 0 1 0 1 1 0 1 1 0 0 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1\n",
            " 1 0 1 1 1 1 1 0 1 0 1 0 1 1 1 0 1 1 0 1 0 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1\n",
            " 0 0 0 1 1 0 1 0 1 0 0 1 0 1 1 1 0 0 1 1 1 1 1 0 1 0 1 1 0 0 0 0 1 1 1 1 1\n",
            " 1 0 0 0 1 1 1 0 1 0 0 0 1 0 0 0 1 1 0 0 0 1 1 1 0 1 0 0 1 1 1 0 1 1 1 1 1\n",
            " 1 1 1 0 0 1 1 0 1 0 1 1 1 1 1 0 1 1 0 0 0 1 1 0 1 0 1 1 0 1 1 1 0 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1 1 1 1 1 1 1 0 0 1 1 0 1 1 0 1 1 1 0 1\n",
            " 1 1 1 0 1 1 1 0 0 1 0 0 1 0 0 1 0 1 0 1 1 1 1 1 1 0 0 1 1 0 1 1 0 1 1 1 0\n",
            " 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 0 1 1\n",
            " 0 0 1 1 1 1 1 0 1 0 0 1 0 1 1 0 1 1 1 1 0 0 1 0 1 0 1 1 1 1 1 0 0 0 0 0 1\n",
            " 0 1 1 1 0 0 1 0 0 1 0 1 0 1 0 0 0 1 0 1 1 1 0 0 1 0 0 1 1 1 1 0 0 0 1 1 0\n",
            " 0 1 0 1 1 1 1 0 0 1 0 0 0 0 0 1 0 0 1 1 1 1 0 1 0 0 1 0 0 0 0 0 1 1 1 1 1\n",
            " 1 1 1 1 0 1 0 0 1 1 1 1 1 1 0 1 0 0 0 0 1 1 1 1 0 0 0 0 1 0 1 0 1 1 0 1 1\n",
            " 0 1 0 1 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1 0 0 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1\n",
            " 1 0 1 1 0 1 1 1 0 0 1 0 1 1 1 0 0 0 1 0 1 0 1 0 1 0 1 1 1 1 1 1 0 1 0 1 0\n",
            " 1 1 0 0 1 0 1 1 1 1 0 0 1 1 0 1 1 0 0 1 1 0 1 1 1 0 0 0]\n",
            "std (842,) [50. 10. 50. 40. 10. 30. 20. 30. 30. 40. 20. 40. 40. 40. 40. 20. 10. 20.\n",
            " 20. 20. 30. 20. 20. 40. 10. 20. 30. 30. 20. 30. 20. 30. 40. 50. 30. 40.\n",
            " 40. 40. 30. 20. 20. 40. 10. 30. 40. 40. 40. 30. 40. 20. 30. 40. 30. 20.\n",
            " 40. 20. 40. 20. 40. 50. 30. 30. 40. 40. 40. 20. 30. 30. 20. 30. 20. 40.\n",
            " 50. 20. 40. 30. 30. 30. 10. 20. 30. 20. 20. 40. 50. 40. 40. 30. 50. 30.\n",
            " 20. 40. 40. 20. 20. 30. 20. 30. 30. 30. 30. 40. 50. 30. 40. 30. 50. 20.\n",
            " 20. 30. 30. 50. 50. 30. 20. 30. 30. 20. 30. 40. 40. 30. 20. 30. 20. 20.\n",
            " 50. 50. 10. 20. 40. 30. 20. 20. 40. 50. 40. 40. 10. 30. 20. 30. 30. 40.\n",
            " 40. 50. 30. 50. 20. 40. 30. 30. 40. 20. 30. 50. 30. 30. 20. 30. 30. 20.\n",
            " 30. 40. 40. 20. 20. 30. 40. 30. 40. 30. 40. 30. 30. 30. 40. 50. 40. 20.\n",
            " 40. 30. 40. 50. 40. 30. 30. 40. 50. 40. 20. 30. 50. 40. 30. 50. 30. 40.\n",
            " 40. 30. 40. 40. 20. 30. 30. 50. 30. 30. 30. 20. 30. 30. 50. 40. 40. 30.\n",
            " 40. 50. 30. 40. 50. 30. 30. 20. 30. 30. 20. 50. 10. 40. 30. 40. 10. 30.\n",
            " 50. 40. 20. 40. 40. 40. 30. 30. 40. 20. 40. 40. 40. 50. 40. 20. 30. 20.\n",
            " 10. 50. 20. 50. 40. 30. 20. 40. 30. 30. 30. 40. 30. 30. 40. 10. 30. 30.\n",
            " 50. 40. 40. 30. 40. 40. 30. 20. 40. 30. 20. 30. 40. 40. 30. 30. 50. 30.\n",
            " 40. 40. 40. 30. 30. 40. 20. 30. 50. 50. 50. 30. 40. 30. 40. 20. 30. 50.\n",
            " 40. 50. 20. 50. 40. 40. 50. 30. 30. 50. 30. 50. 20. 30. 20. 40. 50. 50.\n",
            " 20. 20. 50. 30. 30. 30. 40. 30. 50. 20. 30. 20. 20. 20. 50. 30. 20. 20.\n",
            " 40. 50. 40. 40. 40. 30. 30. 40. 30. 30. 50. 20. 50. 30. 20. 50. 20. 40.\n",
            " 50. 20. 50. 30. 30. 50. 20. 40. 40. 40. 30. 30. 20. 20. 20. 30. 30. 20.\n",
            " 50. 30. 20. 30. 10. 30. 40. 30. 30. 30. 40. 30. 20. 30. 30. 50. 40. 50.\n",
            " 40. 40. 30. 30. 10. 20. 30. 40. 30. 20. 20. 40. 40. 30. 50. 20. 40. 20.\n",
            " 30. 50. 50. 20. 20. 40. 20. 30. 40. 30. 30. 20. 20. 20. 40. 10. 30. 40.\n",
            " 30. 30. 30. 40. 40. 50. 40. 30. 40. 40. 40. 40. 20. 30. 40. 50. 20. 40.\n",
            " 40. 30. 50. 50. 30. 40. 30. 40. 20. 30. 20. 40. 20. 10. 40. 40. 40. 20.\n",
            " 30. 40. 30. 30. 30. 20. 40. 40. 50. 50. 20. 20. 30. 40. 30. 40. 40. 30.\n",
            " 30. 20. 40. 30. 50. 30. 40. 40. 30. 30. 50. 30. 20. 30. 40. 20. 50. 20.\n",
            " 40. 40. 40. 20. 40. 30. 40. 50. 40. 30. 50. 50. 30. 30. 50. 30. 50. 20.\n",
            " 50. 30. 40. 30. 20. 20. 40. 20. 40. 30. 30. 40. 20. 30. 30. 30. 40. 40.\n",
            " 50. 30. 20. 20. 40. 30. 10. 20. 40. 40. 30. 50. 30. 50. 30. 40. 50. 40.\n",
            " 40. 30. 20. 40. 50. 20. 50. 30. 50. 30. 20. 30. 30. 30. 20. 30. 20. 30.\n",
            " 40. 50. 30. 50. 50. 40. 50. 30. 30. 20. 20. 40. 40. 40. 30. 40. 20. 20.\n",
            " 40. 30. 30. 40. 40. 30. 40. 40. 50. 40. 20. 50. 20. 40. 20. 40. 20. 40.\n",
            " 30. 40. 50. 30. 40. 20. 20. 40. 30. 50. 40. 40. 20. 40. 20. 40. 20. 30.\n",
            " 50. 30. 50. 30. 20. 20. 30. 40. 50. 20. 50. 40. 20. 30. 20. 50. 40. 40.\n",
            " 40. 40. 30. 30. 20. 30. 30. 30. 30. 30. 20. 30. 30. 40. 20. 30. 30. 30.\n",
            " 40. 10. 20. 50. 40. 40. 40. 20. 40. 30. 30. 30. 30. 40. 50. 30. 50. 20.\n",
            " 50. 40. 30. 30. 40. 20. 20. 40. 40. 40. 40. 40. 20. 20. 40. 40. 30. 10.\n",
            " 20. 30. 20. 20. 20. 20. 50. 30. 20. 40. 20. 40. 50. 40. 40. 20. 30. 30.\n",
            " 20. 40. 30. 50. 30. 30. 30. 40. 40. 40. 20. 40. 30. 20. 20. 30. 40. 40.\n",
            " 40. 40. 30. 20. 30. 20. 20. 30. 50. 50. 20. 30. 20. 40. 30. 30. 20. 50.\n",
            " 30. 40. 50. 40. 40. 50. 20. 30. 20. 30. 40. 40. 20. 20. 30. 30. 20. 20.\n",
            " 30. 30. 40. 20. 30. 30. 30. 40. 40. 50. 50. 20. 40. 20. 20. 40. 50. 50.\n",
            " 30. 30. 20. 30. 30. 50. 30. 30. 20. 30. 30. 10. 40. 40. 40. 50. 40. 20.\n",
            " 30. 20. 50. 40. 30. 30. 30. 20. 50. 20. 20. 40. 40. 20. 40. 20. 20. 40.\n",
            " 20. 30. 30. 40. 40. 40. 30. 40. 40. 50. 40. 30. 30. 30.]\n",
            "selection [128  42 803 463  24 400 267  16 546  78] (10,) [10. 10. 10. 10. 10. 10. 10. 10. 10. 10.]\n",
            "trainset before adding uncertain samples (460, 10) (460,)\n",
            "trainset after adding uncertain samples (470, 10) (470,)\n",
            "updated train set: (470, 10) (470,) unique(labels): [239 231] [0 1]\n",
            "val set: (832, 10) (832,)\n",
            "\n",
            "Train set: (470, 10)\n",
            "Validation set: (832, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 47\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.084 s \n",
            "\n",
            "Accuracy rate is 80.645161 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.88      0.87       321\n",
            "           1       0.64      0.58      0.61       113\n",
            "\n",
            "    accuracy                           0.81       434\n",
            "   macro avg       0.75      0.73      0.74       434\n",
            "weighted avg       0.80      0.81      0.80       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[284  37]\n",
            " [ 47  66]]\n",
            "--------------------------------\n",
            "val predicted: (832,) [1 0 1 1 0 0 1 0 0 1 1 1 1 0 1 0 0 0 1 0 1 0 1 0 1 1 0 0 1 1 0 0 1 0 1 0 1\n",
            " 1 1 1 1 1 1 1 0 1 0 0 0 1 1 1 1 1 1 1 1 0 1 0 1 1 0 0 0 0 1 0 1 1 1 1 0 1\n",
            " 0 0 1 1 1 0 0 1 0 0 1 0 1 0 1 1 1 1 0 1 0 0 1 0 0 1 0 0 1 1 1 1 0 0 1 1 0\n",
            " 0 1 0 1 1 1 1 1 0 1 0 1 1 0 1 1 0 1 1 1 0 1 0 0 0 1 0 1 1 1 1 1 1 0 1 0 1\n",
            " 1 0 1 1 1 0 0 0 1 0 0 1 1 1 0 0 0 0 0 0 1 0 0 1 0 0 1 0 1 1 0 1 1 0 0 1 1\n",
            " 0 0 0 0 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 0\n",
            " 1 0 1 1 1 1 1 0 0 1 1 0 1 0 0 1 1 1 1 1 1 0 0 0 0 0 1 0 1 0 0 1 0 1 0 1 0\n",
            " 0 0 1 0 0 0 0 1 1 1 1 1 1 1 1 0 1 1 0 1 0 1 0 1 0 0 1 1 1 1 0 0 1 0 1 1 0\n",
            " 1 1 0 0 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 0 1 1 1 1\n",
            " 1 0 1 0 1 0 1 1 1 0 1 1 0 1 0 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 0 0 0 1 1 0\n",
            " 1 0 1 0 0 1 0 1 1 1 0 0 1 1 1 1 1 0 1 0 1 1 0 0 0 1 1 1 1 1 1 0 0 0 1 1 1\n",
            " 0 1 0 0 0 1 0 0 0 1 1 0 0 0 1 1 1 0 1 0 0 1 1 1 0 1 1 1 1 1 1 1 1 0 0 1 1\n",
            " 0 1 0 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 0 0 1 0 1 1 1 1 1 1 1 1 1 0 0 1 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 0\n",
            " 0 1 0 0 1 0 0 1 0 1 0 1 1 1 1 1 1 0 0 1 0 1 1 0 1 1 1 0 1 1 1 0 1 1 1 1 1\n",
            " 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 0 1 1 0 0 1 1 1 1 1 0 1\n",
            " 0 0 1 0 1 1 0 1 1 1 1 0 0 1 0 1 0 1 1 1 1 1 0 0 0 0 0 1 0 1 1 1 0 0 1 0 0\n",
            " 1 0 1 0 1 0 0 0 1 0 1 1 1 0 0 1 0 0 1 1 1 1 0 0 0 1 1 0 0 1 0 1 1 1 1 0 0\n",
            " 1 0 0 0 0 0 1 0 0 1 1 1 1 0 1 0 0 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 0 1 0 0 1\n",
            " 1 1 1 1 1 0 1 0 0 0 0 1 1 1 1 0 0 0 0 1 0 1 0 1 1 0 1 1 0 1 0 1 0 1 1 0 0\n",
            " 1 0 1 1 1 1 0 1 1 1 0 0 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 1 0 1 1 0 1 1 1 0\n",
            " 0 1 0 1 1 1 0 0 0 1 0 1 0 1 0 1 0 1 1 1 1 1 0 1 0 1 0 1 1 0 0 1 0 1 1 1 1\n",
            " 0 0 1 1 0 1 1 0 0 1 1 0 1 1 1 0 0 0]\n",
            "probabilities: (832, 2) \n",
            " [1 0 1 1 0 0 1 0 0 1 1 1 1 0 1 0 0 0 1 0 1 0 1 0 1 1 0 0 1 1 0 0 1 0 1 0 1\n",
            " 1 1 1 1 1 1 1 0 1 0 0 0 1 1 1 1 1 1 1 1 0 1 0 1 1 0 0 0 0 1 0 1 1 1 1 0 1\n",
            " 0 0 1 1 1 0 0 1 0 0 1 0 1 0 1 1 1 1 0 1 0 0 1 0 0 1 0 0 1 1 1 1 0 0 1 1 0\n",
            " 0 1 0 1 1 1 1 1 0 1 0 1 1 0 1 1 0 1 1 1 0 1 0 0 0 1 0 1 1 1 1 1 1 0 1 0 1\n",
            " 1 0 1 1 1 0 0 0 1 0 0 1 1 1 0 0 0 0 0 0 1 0 0 1 0 0 1 0 1 1 0 1 1 0 0 1 1\n",
            " 0 0 0 0 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 0\n",
            " 1 0 1 1 1 1 1 0 0 1 1 0 1 0 0 1 1 1 1 1 1 0 0 0 0 0 1 0 1 0 0 1 0 1 0 1 0\n",
            " 0 0 1 0 0 0 0 1 1 1 1 1 1 1 1 0 1 1 0 1 0 1 0 1 0 0 1 1 1 1 0 0 1 0 1 1 0\n",
            " 1 1 0 0 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 0 1 1 1 1\n",
            " 1 0 1 0 1 0 1 1 1 0 1 1 0 1 0 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 0 0 0 1 1 0\n",
            " 1 0 1 0 0 1 0 1 1 1 0 0 1 1 1 1 1 0 1 0 1 1 0 0 0 1 1 1 1 1 1 0 0 0 1 1 1\n",
            " 0 1 0 0 0 1 0 0 0 1 1 0 0 0 1 1 1 0 1 0 0 1 1 1 0 1 1 1 1 1 1 1 1 0 0 1 1\n",
            " 0 1 0 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 0 0 1 0 1 1 1 1 1 1 1 1 1 0 0 1 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 0\n",
            " 0 1 0 0 1 0 0 1 0 1 0 1 1 1 1 1 1 0 0 1 0 1 1 0 1 1 1 0 1 1 1 0 1 1 1 1 1\n",
            " 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 0 1 1 0 0 1 1 1 1 1 0 1\n",
            " 0 0 1 0 1 1 0 1 1 1 1 0 0 1 0 1 0 1 1 1 1 1 0 0 0 0 0 1 0 1 1 1 0 0 1 0 0\n",
            " 1 0 1 0 1 0 0 0 1 0 1 1 1 0 0 1 0 0 1 1 1 1 0 0 0 1 1 0 0 1 0 1 1 1 1 0 0\n",
            " 1 0 0 0 0 0 1 0 0 1 1 1 1 0 1 0 0 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 0 1 0 0 1\n",
            " 1 1 1 1 1 0 1 0 0 0 0 1 1 1 1 0 0 0 0 1 0 1 0 1 1 0 1 1 0 1 0 1 0 1 1 0 0\n",
            " 1 0 1 1 1 1 0 1 1 1 0 0 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 1 0 1 1 0 1 1 1 0\n",
            " 0 1 0 1 1 1 0 0 0 1 0 1 0 1 0 1 0 1 1 1 1 1 0 1 0 1 0 1 1 0 0 1 0 1 1 1 1\n",
            " 0 0 1 1 0 1 1 0 0 1 1 0 1 1 1 0 0 0]\n",
            "std (832,) [50. 20. 50. 40. 10. 30. 20. 30. 30. 40. 20. 40. 40. 40. 40. 20. 20. 20.\n",
            " 20. 30. 20. 20. 40. 20. 30. 30. 20. 30. 30. 30. 40. 50. 30. 30. 40. 40.\n",
            " 30. 20. 20. 40. 30. 40. 40. 40. 40. 40. 20. 30. 40. 30. 20. 40. 20. 40.\n",
            " 20. 40. 50. 40. 30. 40. 40. 40. 20. 30. 20. 20. 30. 20. 40. 50. 20. 40.\n",
            " 30. 30. 30. 20. 30. 20. 20. 40. 50. 40. 40. 30. 50. 40. 20. 40. 40. 20.\n",
            " 20. 40. 20. 30. 30. 30. 30. 40. 50. 30. 40. 30. 50. 20. 20. 40. 30. 50.\n",
            " 50. 40. 20. 30. 30. 20. 20. 40. 40. 30. 20. 20. 30. 20. 50. 50. 20. 40.\n",
            " 40. 20. 30. 40. 50. 40. 40. 10. 30. 20. 30. 30. 40. 40. 50. 30. 50. 20.\n",
            " 40. 30. 30. 40. 20. 30. 50. 30. 30. 20. 30. 30. 20. 20. 40. 40. 20. 20.\n",
            " 30. 40. 30. 40. 30. 40. 30. 30. 30. 40. 50. 40. 20. 50. 30. 40. 50. 50.\n",
            " 30. 30. 40. 50. 40. 20. 30. 50. 40. 30. 50. 30. 40. 40. 30. 40. 40. 20.\n",
            " 30. 30. 50. 30. 30. 30. 20. 30. 30. 50. 40. 40. 30. 40. 50. 30. 40. 50.\n",
            " 30. 30. 20. 30. 40. 20. 50. 10. 40. 30. 40. 10. 20. 50. 40. 20. 40. 40.\n",
            " 40. 30. 30. 40. 20. 40. 40. 40. 50. 40. 20. 20. 20. 20. 50. 20. 50. 40.\n",
            " 30. 20. 40. 30. 30. 30. 40. 20. 30. 40. 20. 30. 50. 40. 40. 30. 40. 40.\n",
            " 30. 20. 40. 30. 20. 30. 50. 40. 30. 30. 50. 30. 40. 40. 30. 30. 40. 40.\n",
            " 20. 30. 50. 50. 50. 30. 40. 30. 40. 20. 30. 50. 40. 50. 20. 50. 40. 40.\n",
            " 50. 30. 30. 50. 40. 50. 20. 30. 30. 40. 50. 50. 20. 20. 50. 30. 30. 40.\n",
            " 40. 30. 50. 20. 30. 20. 20. 20. 50. 30. 20. 20. 40. 50. 40. 40. 40. 30.\n",
            " 30. 40. 30. 30. 50. 20. 50. 30. 20. 50. 20. 40. 50. 20. 50. 30. 30. 50.\n",
            " 20. 40. 40. 40. 30. 30. 20. 20. 20. 30. 30. 20. 50. 30. 10. 30. 10. 30.\n",
            " 40. 40. 20. 20. 40. 30. 20. 30. 30. 50. 40. 50. 40. 40. 30. 30. 10. 40.\n",
            " 40. 30. 20. 20. 50. 40. 20. 50. 20. 40. 20. 30. 50. 50. 20. 20. 40. 20.\n",
            " 20. 40. 30. 30. 20. 20. 20. 40. 10. 30. 40. 30. 30. 30. 40. 40. 50. 40.\n",
            " 30. 40. 40. 40. 40. 20. 30. 40. 50. 30. 40. 40. 40. 50. 50. 30. 40. 30.\n",
            " 40. 20. 30. 20. 40. 20. 40. 40. 40. 20. 30. 30. 30. 30. 30. 20. 40. 40.\n",
            " 50. 50. 20. 20. 30. 40. 30. 40. 40. 20. 30. 30. 40. 30. 50. 30. 30. 40.\n",
            " 30. 30. 50. 30. 20. 30. 40. 20. 50. 20. 50. 40. 40. 20. 40. 40. 50. 50.\n",
            " 40. 30. 50. 50. 30. 30. 50. 40. 50. 20. 50. 30. 40. 30. 20. 20. 40. 20.\n",
            " 40. 20. 40. 50. 20. 40. 20. 30. 40. 40. 50. 30. 20. 20. 40. 30. 30. 40.\n",
            " 40. 40. 50. 30. 50. 30. 40. 50. 40. 40. 30. 20. 40. 50. 20. 50. 30. 50.\n",
            " 30. 20. 30. 20. 30. 30. 30. 20. 30. 40. 50. 20. 50. 50. 40. 50. 30. 40.\n",
            " 10. 20. 40. 40. 40. 30. 40. 20. 20. 40. 30. 30. 40. 40. 30. 50. 40. 50.\n",
            " 40. 20. 50. 30. 40. 20. 40. 40. 40. 30. 40. 50. 40. 40. 20. 30. 40. 30.\n",
            " 50. 40. 40. 20. 30. 20. 40. 20. 30. 50. 30. 50. 30. 20. 20. 30. 40. 50.\n",
            " 20. 50. 40. 20. 30. 20. 50. 40. 40. 40. 40. 30. 30. 20. 30. 30. 20. 30.\n",
            " 30. 20. 30. 30. 40. 20. 40. 30. 40. 40. 10. 20. 50. 50. 40. 50. 20. 40.\n",
            " 40. 30. 30. 30. 40. 50. 30. 50. 20. 50. 40. 30. 30. 40. 20. 20. 40. 40.\n",
            " 40. 30. 40. 20. 20. 40. 40. 30. 10. 20. 30. 20. 20. 30. 20. 50. 30. 20.\n",
            " 40. 20. 40. 50. 40. 40. 20. 30. 30. 20. 30. 20. 50. 30. 30. 30. 40. 50.\n",
            " 30. 20. 40. 30. 20. 20. 30. 40. 40. 40. 40. 30. 20. 20. 20. 20. 40. 50.\n",
            " 40. 20. 30. 20. 40. 40. 30. 20. 50. 30. 40. 50. 40. 40. 50. 20. 30. 20.\n",
            " 30. 40. 40. 20. 20. 30. 30. 20. 20. 30. 30. 40. 20. 30. 30. 30. 40. 40.\n",
            " 50. 50. 20. 40. 20. 20. 40. 50. 50. 30. 30. 20. 30. 20. 50. 20. 30. 30.\n",
            " 40. 30. 40. 40. 40. 50. 40. 20. 30. 20. 50. 40. 30. 30. 20. 20. 50. 30.\n",
            " 30. 40. 40. 20. 40. 20. 20. 40. 20. 30. 30. 50. 40. 40. 30. 50. 40. 50.\n",
            " 40. 30. 20. 30.]\n",
            "selection [376 133 658 422 576 374 223 394 692 227] (10,) [10. 10. 10. 10. 10. 10. 10. 10. 10. 10.]\n",
            "trainset before adding uncertain samples (470, 10) (470,)\n",
            "trainset after adding uncertain samples (480, 10) (480,)\n",
            "updated train set: (480, 10) (480,) unique(labels): [247 233] [0 1]\n",
            "val set: (822, 10) (822,)\n",
            "\n",
            "Train set: (480, 10)\n",
            "Validation set: (822, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 48\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.087 s \n",
            "\n",
            "Accuracy rate is 80.414747 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.89      0.87       321\n",
            "           1       0.64      0.57      0.60       113\n",
            "\n",
            "    accuracy                           0.80       434\n",
            "   macro avg       0.75      0.73      0.74       434\n",
            "weighted avg       0.80      0.80      0.80       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[285  36]\n",
            " [ 49  64]]\n",
            "--------------------------------\n",
            "val predicted: (822,) [1 0 1 1 0 0 1 0 0 1 1 1 1 0 1 0 0 0 1 0 1 0 1 0 1 1 0 0 1 1 0 0 1 0 1 0 1\n",
            " 1 1 1 1 1 1 1 0 1 0 0 0 1 1 1 1 1 1 1 1 0 1 0 1 1 0 0 0 0 1 0 1 1 1 1 0 1\n",
            " 0 0 1 1 1 0 0 1 0 0 1 0 1 0 1 1 1 1 0 1 0 0 1 0 0 1 0 0 1 1 1 1 0 0 1 1 0\n",
            " 0 1 0 1 1 1 1 1 0 1 0 1 1 0 1 1 0 1 1 1 0 1 0 0 1 0 1 1 1 1 1 1 0 1 0 1 1\n",
            " 0 1 1 1 0 0 0 1 0 0 1 1 1 0 0 0 0 0 0 1 0 0 1 0 0 1 0 1 1 0 1 1 0 0 1 1 0\n",
            " 0 0 0 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 0 1\n",
            " 1 1 1 1 0 0 1 1 0 1 0 0 1 1 1 1 1 1 0 0 0 0 0 1 0 1 0 0 1 0 1 0 1 0 0 0 1\n",
            " 0 0 0 0 1 1 1 1 1 1 1 1 0 1 1 0 1 0 1 0 1 0 0 1 1 1 1 0 0 1 0 1 1 0 1 1 0\n",
            " 0 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 0 1 1 1 1 1 0 1\n",
            " 0 1 0 1 1 1 0 1 1 0 1 0 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 0 0 0 1 1 0 1 0 1\n",
            " 0 1 1 1 1 0 0 1 1 1 1 1 0 1 0 1 1 0 0 1 1 1 1 1 1 0 0 0 1 1 1 0 1 0 0 0 1\n",
            " 0 0 0 1 1 0 0 0 1 1 0 1 0 0 1 1 1 0 1 1 1 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1\n",
            " 1 0 1 1 0 0 1 1 0 1 0 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0\n",
            " 1 1 1 1 1 1 1 1 1 0 0 1 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 0 0 1 0 0 1 0 0\n",
            " 1 0 1 0 1 1 1 1 1 1 0 0 1 0 1 1 0 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1\n",
            " 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 0 0 1 1 1 1 1 0 1 0 0 1 0 1 1 0 1\n",
            " 1 1 1 0 0 1 0 1 0 1 1 1 1 1 0 0 0 0 0 1 0 1 1 1 0 0 1 0 0 1 0 1 0 1 0 0 0\n",
            " 1 0 1 1 1 0 0 1 0 0 1 1 1 1 0 0 0 1 1 0 0 0 1 1 1 1 0 0 1 0 0 0 0 0 1 0 0\n",
            " 1 1 1 1 0 1 0 0 1 0 0 0 0 0 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 0 1 0 0 0\n",
            " 0 1 1 1 1 0 0 0 0 1 0 1 0 1 1 0 1 1 0 1 0 1 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1\n",
            " 0 0 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 1 0 1 1 0 1 1 1 0 0 1 0 1 1 1 0 0 0 1\n",
            " 0 1 0 1 0 1 0 1 1 1 1 1 0 1 0 1 0 1 1 0 0 1 0 1 1 1 1 0 0 1 1 0 1 1 0 0 1\n",
            " 1 0 1 1 1 0 0 0]\n",
            "probabilities: (822, 2) \n",
            " [1 0 1 1 0 0 1 0 0 1 1 1 1 0 1 0 0 0 1 0 1 0 1 0 1 1 0 0 1 1 0 0 1 0 1 0 1\n",
            " 1 1 1 1 1 1 1 0 1 0 0 0 1 1 1 1 1 1 1 1 0 1 0 1 1 0 0 0 0 1 0 1 1 1 1 0 1\n",
            " 0 0 1 1 1 0 0 1 0 0 1 0 1 0 1 1 1 1 0 1 0 0 1 0 0 1 0 0 1 1 1 1 0 0 1 1 0\n",
            " 0 1 0 1 1 1 1 1 0 1 0 1 1 0 1 1 0 1 1 1 0 1 0 0 1 0 1 1 1 1 1 1 0 1 0 1 1\n",
            " 0 1 1 1 0 0 0 1 0 0 1 1 1 0 0 0 0 0 0 1 0 0 1 0 0 1 0 1 1 0 1 1 0 0 1 1 0\n",
            " 0 0 0 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 0 1\n",
            " 1 1 1 1 0 0 1 1 0 1 0 0 1 1 1 1 1 1 0 0 0 0 0 1 0 1 0 0 1 0 1 0 1 0 0 0 1\n",
            " 0 0 0 0 1 1 1 1 1 1 1 1 0 1 1 0 1 0 1 0 1 0 0 1 1 1 1 0 0 1 0 1 1 0 1 1 0\n",
            " 0 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 0 1 1 1 1 1 0 1\n",
            " 0 1 0 1 1 1 0 1 1 0 1 0 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 0 0 0 1 1 0 1 0 1\n",
            " 0 1 1 1 1 0 0 1 1 1 1 1 0 1 0 1 1 0 0 1 1 1 1 1 1 0 0 0 1 1 1 0 1 0 0 0 1\n",
            " 0 0 0 1 1 0 0 0 1 1 0 1 0 0 1 1 1 0 1 1 1 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1\n",
            " 1 0 1 1 0 0 1 1 0 1 0 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0\n",
            " 1 1 1 1 1 1 1 1 1 0 0 1 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 0 0 1 0 0 1 0 0\n",
            " 1 0 1 0 1 1 1 1 1 1 0 0 1 0 1 1 0 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1\n",
            " 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 0 0 1 1 1 1 1 0 1 0 0 1 0 1 1 0 1\n",
            " 1 1 1 0 0 1 0 1 0 1 1 1 1 1 0 0 0 0 0 1 0 1 1 1 0 0 1 0 0 1 0 1 0 1 0 0 0\n",
            " 1 0 1 1 1 0 0 1 0 0 1 1 1 1 0 0 0 1 1 0 0 0 1 1 1 1 0 0 1 0 0 0 0 0 1 0 0\n",
            " 1 1 1 1 0 1 0 0 1 0 0 0 0 0 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 0 1 0 0 0\n",
            " 0 1 1 1 1 0 0 0 0 1 0 1 0 1 1 0 1 1 0 1 0 1 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1\n",
            " 0 0 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 1 0 1 1 0 1 1 1 0 0 1 0 1 1 1 0 0 0 1\n",
            " 0 1 0 1 0 1 0 1 1 1 1 1 0 1 0 1 0 1 1 0 0 1 0 1 1 1 1 0 0 1 1 0 1 1 0 0 1\n",
            " 1 0 1 1 1 0 0 0]\n",
            "std (822,) [50. 20. 50. 40. 10. 30. 10. 30. 30. 30. 20. 40. 40. 40. 40. 20. 20. 20.\n",
            " 20. 30. 30. 20. 40. 20. 30. 30. 20. 40. 30. 30. 40. 50. 40. 30. 40. 40.\n",
            " 30. 20. 20. 40. 30. 40. 40. 50. 40. 40. 20. 30. 40. 30. 20. 40. 10. 40.\n",
            " 10. 30. 50. 40. 30. 40. 40. 40. 20. 30. 30. 20. 30. 20. 40. 50. 10. 40.\n",
            " 30. 30. 30. 20. 30. 20. 20. 40. 50. 40. 40. 40. 50. 40. 10. 40. 40. 20.\n",
            " 20. 30. 20. 30. 30. 30. 30. 40. 50. 30. 40. 30. 50. 10. 20. 40. 30. 50.\n",
            " 50. 40. 20. 30. 30. 20. 20. 40. 40. 30. 20. 30. 30. 20. 50. 50. 20. 40.\n",
            " 40. 20. 30. 40. 50. 40. 40. 30. 20. 20. 30. 40. 40. 50. 30. 50. 20. 40.\n",
            " 30. 30. 40. 20. 30. 50. 20. 30. 20. 30. 30. 10. 20. 40. 30. 10. 20. 30.\n",
            " 40. 30. 40. 30. 40. 30. 30. 30. 40. 50. 40. 20. 50. 30. 40. 50. 50. 30.\n",
            " 30. 40. 50. 40. 20. 30. 50. 40. 30. 50. 30. 40. 40. 30. 30. 40. 20. 30.\n",
            " 30. 50. 30. 30. 40. 20. 30. 30. 50. 40. 40. 30. 40. 50. 20. 40. 50. 20.\n",
            " 20. 10. 30. 40. 30. 50. 40. 30. 40. 20. 50. 40. 20. 40. 40. 40. 30. 30.\n",
            " 30. 20. 40. 40. 40. 50. 40. 20. 30. 20. 20. 50. 20. 40. 40. 30. 20. 40.\n",
            " 30. 30. 30. 40. 20. 30. 40. 20. 30. 50. 40. 40. 30. 40. 30. 30. 20. 40.\n",
            " 30. 20. 30. 50. 40. 30. 30. 50. 30. 40. 40. 30. 30. 40. 40. 20. 30. 50.\n",
            " 50. 50. 30. 30. 30. 30. 20. 30. 50. 40. 50. 20. 50. 40. 40. 50. 40. 30.\n",
            " 50. 40. 50. 20. 30. 30. 40. 50. 40. 20. 30. 50. 20. 30. 40. 40. 30. 50.\n",
            " 20. 40. 20. 20. 20. 50. 30. 20. 20. 40. 50. 40. 40. 40. 30. 30. 30. 30.\n",
            " 30. 50. 20. 50. 30. 20. 50. 20. 40. 50. 30. 50. 30. 20. 50. 10. 40. 40.\n",
            " 40. 30. 30. 20. 20. 20. 30. 30. 20. 50. 30. 20. 30. 40. 30. 20. 20. 40.\n",
            " 30. 20. 30. 30. 50. 40. 50. 40. 30. 30. 30. 40. 40. 20. 20. 20. 50. 40.\n",
            " 30. 50. 20. 40. 30. 30. 50. 50. 20. 30. 40. 20. 20. 40. 30. 30. 20. 20.\n",
            " 20. 40. 30. 40. 30. 30. 30. 30. 30. 50. 40. 30. 40. 40. 40. 40. 20. 30.\n",
            " 40. 50. 30. 40. 40. 40. 40. 50. 30. 40. 30. 30. 20. 30. 10. 40. 20. 40.\n",
            " 40. 40. 20. 30. 30. 30. 30. 30. 20. 40. 40. 50. 50. 20. 10. 30. 40. 30.\n",
            " 40. 40. 30. 30. 30. 30. 30. 50. 30. 30. 40. 30. 30. 50. 30. 20. 30. 40.\n",
            " 20. 50. 20. 50. 40. 40. 20. 40. 40. 50. 50. 40. 30. 50. 50. 30. 30. 50.\n",
            " 40. 50. 20. 50. 20. 30. 30. 20. 20. 40. 30. 40. 30. 40. 50. 20. 40. 20.\n",
            " 30. 30. 40. 50. 30. 10. 30. 50. 30. 30. 40. 40. 40. 50. 20. 50. 30. 40.\n",
            " 50. 40. 40. 30. 20. 40. 50. 10. 50. 30. 50. 30. 20. 30. 10. 30. 30. 30.\n",
            " 20. 30. 40. 40. 30. 50. 40. 30. 50. 30. 30. 20. 40. 40. 40. 30. 40. 20.\n",
            " 20. 40. 30. 30. 30. 40. 30. 50. 40. 50. 40. 20. 50. 30. 30. 20. 40. 40.\n",
            " 40. 30. 40. 50. 40. 40. 20. 30. 40. 30. 40. 40. 40. 20. 30. 20. 50. 20.\n",
            " 30. 50. 30. 50. 30. 20. 20. 30. 40. 50. 20. 50. 40. 20. 30. 20. 50. 40.\n",
            " 40. 40. 40. 30. 30. 30. 30. 30. 30. 30. 30. 10. 20. 30. 40. 20. 40. 30.\n",
            " 50. 40. 20. 50. 50. 40. 50. 20. 50. 40. 30. 30. 30. 40. 50. 30. 50. 20.\n",
            " 50. 40. 30. 20. 40. 20. 20. 40. 40. 40. 30. 40. 20. 20. 40. 40. 30. 20.\n",
            " 30. 20. 20. 30. 40. 50. 30. 20. 40. 20. 40. 50. 30. 40. 10. 30. 30. 20.\n",
            " 30. 20. 50. 30. 20. 20. 40. 50. 40. 30. 40. 30. 20. 20. 30. 40. 40. 40.\n",
            " 40. 30. 10. 30. 20. 20. 30. 40. 40. 20. 30. 20. 40. 40. 30. 20. 50. 30.\n",
            " 40. 50. 40. 40. 50. 20. 30. 20. 40. 40. 40. 10. 20. 30. 30. 20. 20. 30.\n",
            " 30. 40. 20. 30. 30. 30. 40. 30. 50. 50. 20. 40. 20. 20. 40. 40. 50. 30.\n",
            " 30. 20. 30. 20. 40. 30. 30. 30. 40. 30. 40. 40. 40. 50. 40. 20. 30. 30.\n",
            " 50. 40. 30. 30. 30. 20. 50. 20. 30. 40. 40. 20. 40. 20. 20. 30. 20. 40.\n",
            " 30. 50. 40. 30. 30. 50. 50. 50. 40. 20. 30. 40.]\n",
            "selection [217  70 722  54  52 698  86 357 641 464] (10,) [10. 10. 10. 10. 10. 10. 10. 10. 10. 10.]\n",
            "trainset before adding uncertain samples (480, 10) (480,)\n",
            "trainset after adding uncertain samples (490, 10) (490,)\n",
            "updated train set: (490, 10) (490,) unique(labels): [251 239] [0 1]\n",
            "val set: (812, 10) (812,)\n",
            "\n",
            "Train set: (490, 10)\n",
            "Validation set: (812, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 49\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.072 s \n",
            "\n",
            "Accuracy rate is 80.875576 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.90      0.87       321\n",
            "           1       0.66      0.54      0.60       113\n",
            "\n",
            "    accuracy                           0.81       434\n",
            "   macro avg       0.76      0.72      0.73       434\n",
            "weighted avg       0.80      0.81      0.80       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[290  31]\n",
            " [ 52  61]]\n",
            "--------------------------------\n",
            "val predicted: (812,) [1 0 1 1 0 0 1 0 0 1 1 1 1 0 1 0 0 0 1 0 1 0 1 0 1 1 0 0 1 1 0 0 1 0 1 0 1\n",
            " 1 1 1 1 1 1 1 0 1 0 0 0 1 1 1 1 1 1 0 1 0 1 1 0 0 0 0 1 0 1 1 1 0 1 0 0 1\n",
            " 1 1 0 0 1 0 0 1 0 0 1 1 1 1 0 1 0 0 1 0 0 1 0 0 1 0 1 1 0 0 1 1 0 0 1 0 1\n",
            " 1 1 1 1 0 1 0 1 1 0 1 1 0 1 1 1 0 1 0 0 1 0 1 1 1 1 1 1 0 1 0 1 1 0 1 0 1\n",
            " 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 1 0 0 1 0 0 1 0 1 1 0 1 1 0 0 1 1 0 0 0 0 0\n",
            " 1 0 1 1 1 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1 0 1 1 1 1 1 0\n",
            " 0 1 1 0 1 0 0 1 1 1 1 1 1 0 0 0 0 0 1 0 1 0 0 1 0 1 0 1 0 0 0 1 0 0 0 0 1\n",
            " 1 1 1 1 1 1 1 0 1 1 0 1 0 1 0 1 0 0 1 1 1 1 0 0 1 0 1 1 0 1 1 0 0 1 1 1 1\n",
            " 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 0 1 0 1 1 1 0 1 0 1 0 1 1\n",
            " 1 0 1 1 0 1 0 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1 0 0 0 1 1 0 1 0 1 0 1 1 1 1 0\n",
            " 0 1 1 1 1 1 0 1 0 1 1 0 0 1 1 1 1 1 1 0 0 0 1 1 1 0 1 0 0 0 1 0 0 0 1 1 0\n",
            " 0 0 1 1 0 1 0 0 1 1 1 0 1 1 1 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 1 0 1 1 0 0\n",
            " 1 1 0 1 0 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1 1 1 1 1\n",
            " 1 1 0 0 1 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 0 0 1 0 0 1 0 0 1 0 1 0 1 1 1\n",
            " 1 1 1 0 0 1 0 1 1 0 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1\n",
            " 1 1 1 1 1 1 1 0 0 1 0 1 1 0 0 1 1 1 1 1 0 1 0 0 1 0 1 1 0 1 1 1 1 0 0 1 0\n",
            " 1 0 1 1 1 1 1 0 0 0 0 0 1 0 1 1 1 0 0 1 0 0 1 0 1 0 1 0 0 0 1 0 1 1 1 0 0\n",
            " 1 0 0 1 1 1 0 0 0 1 1 0 0 0 1 1 1 1 0 0 1 0 0 0 0 0 1 0 0 1 1 1 1 0 1 0 0\n",
            " 1 0 0 0 0 0 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 0 0 0 0 1 1 0 1 0 0 0 0\n",
            " 1 0 1 0 1 1 0 1 1 0 0 1 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1 0 0 1 1 0 1 0 1 1 0\n",
            " 1 1 1 0 0 1 1 1 1 0 1 1 0 1 1 1 0 0 1 0 1 1 1 0 0 0 1 0 1 0 1 0 1 0 1 1 1\n",
            " 1 1 0 1 0 1 0 1 1 0 0 1 0 1 1 1 1 0 0 1 1 0 1 1 0 0 1 1 0 1 1 1 0 0 0]\n",
            "probabilities: (812, 2) \n",
            " [1 0 1 1 0 0 1 0 0 1 1 1 1 0 1 0 0 0 1 0 1 0 1 0 1 1 0 0 1 1 0 0 1 0 1 0 1\n",
            " 1 1 1 1 1 1 1 0 1 0 0 0 1 1 1 1 1 1 0 1 0 1 1 0 0 0 0 1 0 1 1 1 0 1 0 0 1\n",
            " 1 1 0 0 1 0 0 1 0 0 1 1 1 1 0 1 0 0 1 0 0 1 0 0 1 0 1 1 0 0 1 1 0 0 1 0 1\n",
            " 1 1 1 1 0 1 0 1 1 0 1 1 0 1 1 1 0 1 0 0 1 0 1 1 1 1 1 1 0 1 0 1 1 0 1 0 1\n",
            " 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 1 0 0 1 0 0 1 0 1 1 0 1 1 0 0 1 1 0 0 0 0 0\n",
            " 1 0 1 1 1 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1 0 1 1 1 1 1 0\n",
            " 0 1 1 0 1 0 0 1 1 1 1 1 1 0 0 0 0 0 1 0 1 0 0 1 0 1 0 1 0 0 0 1 0 0 0 0 1\n",
            " 1 1 1 1 1 1 1 0 1 1 0 1 0 1 0 1 0 0 1 1 1 1 0 0 1 0 1 1 0 1 1 0 0 1 1 1 1\n",
            " 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 0 1 0 1 1 1 0 1 0 1 0 1 1\n",
            " 1 0 1 1 0 1 0 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1 0 0 0 1 1 0 1 0 1 0 1 1 1 1 0\n",
            " 0 1 1 1 1 1 0 1 0 1 1 0 0 1 1 1 1 1 1 0 0 0 1 1 1 0 1 0 0 0 1 0 0 0 1 1 0\n",
            " 0 0 1 1 0 1 0 0 1 1 1 0 1 1 1 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 1 0 1 1 0 0\n",
            " 1 1 0 1 0 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1 1 1 1 1\n",
            " 1 1 0 0 1 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 0 0 1 0 0 1 0 0 1 0 1 0 1 1 1\n",
            " 1 1 1 0 0 1 0 1 1 0 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1\n",
            " 1 1 1 1 1 1 1 0 0 1 0 1 1 0 0 1 1 1 1 1 0 1 0 0 1 0 1 1 0 1 1 1 1 0 0 1 0\n",
            " 1 0 1 1 1 1 1 0 0 0 0 0 1 0 1 1 1 0 0 1 0 0 1 0 1 0 1 0 0 0 1 0 1 1 1 0 0\n",
            " 1 0 0 1 1 1 0 0 0 1 1 0 0 0 1 1 1 1 0 0 1 0 0 0 0 0 1 0 0 1 1 1 1 0 1 0 0\n",
            " 1 0 0 0 0 0 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 0 0 0 0 1 1 0 1 0 0 0 0\n",
            " 1 0 1 0 1 1 0 1 1 0 0 1 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1 0 0 1 1 0 1 0 1 1 0\n",
            " 1 1 1 0 0 1 1 1 1 0 1 1 0 1 1 1 0 0 1 0 1 1 1 0 0 0 1 0 1 0 1 0 1 0 1 1 1\n",
            " 1 1 0 1 0 1 0 1 1 0 0 1 0 1 1 1 1 0 0 1 1 0 1 1 0 0 1 1 0 1 1 1 0 0 0]\n",
            "std (812,) [50. 10. 50. 30. 10. 30. 10. 30. 30. 30. 20. 40. 40. 40. 40. 20. 20. 20.\n",
            " 20. 30. 20. 10. 50. 20. 30. 30. 20. 40. 30. 30. 40. 50. 30. 30. 40. 40.\n",
            " 30. 20. 20. 40. 30. 40. 40. 40. 40. 40. 20. 30. 40. 30. 20. 30. 40. 30.\n",
            " 50. 30. 30. 40. 40. 40. 20. 30. 30. 20. 30. 20. 40. 50. 30. 30. 30. 30.\n",
            " 20. 30. 20. 20. 40. 50. 40. 40. 40. 50. 30. 40. 40. 20. 20. 30. 20. 30.\n",
            " 30. 30. 30. 40. 50. 30. 40. 30. 50.  0. 20. 40. 30. 50. 50. 40. 20. 30.\n",
            " 30. 20. 20. 40. 40. 30. 20. 30. 30. 20. 50. 50. 20. 50. 40. 20. 30. 40.\n",
            " 50. 40. 40. 30. 20. 20. 30. 40. 40. 50. 30. 50. 20. 40. 30. 30. 50. 20.\n",
            " 30. 50.  0. 40. 20. 30. 30.  0. 20. 40. 30. 10. 20. 30. 40. 20. 40. 30.\n",
            " 40. 40. 30. 30. 40. 50. 40. 20. 40. 30. 40. 50. 50. 30. 30. 40. 40. 40.\n",
            " 20. 30. 50. 40. 30. 50. 30. 40. 40. 30. 40. 40. 20. 30. 30. 50. 20. 30.\n",
            " 40. 20. 30. 30. 50. 40. 30. 40. 40. 40. 20. 30. 50. 20. 40. 40. 40. 30.\n",
            " 50. 40. 20. 40. 20. 50. 40. 20. 40. 40. 40. 30. 30. 30. 10. 40. 40. 40.\n",
            " 40. 40. 20. 30. 20. 20. 50. 20. 40. 40. 30. 20. 40. 40. 40. 30. 40. 20.\n",
            " 30. 40. 20. 30. 50. 40. 40. 40. 40. 30. 30. 20. 40. 40. 20. 30. 40. 40.\n",
            " 50. 30. 50. 30. 40. 30. 30. 30. 30. 40. 20. 30. 50. 50. 50. 30. 40. 30.\n",
            " 30. 30. 30. 50. 40. 50. 20. 50. 40. 40. 50. 20. 30. 50. 40. 50. 20. 30.\n",
            " 30. 40. 50. 40. 10. 20. 50. 20. 30. 30. 40. 30. 50. 20. 30. 20.  0. 20.\n",
            " 50. 30. 20. 20. 40. 50. 40. 40. 40. 40. 30. 30. 40. 30. 50. 20. 50. 40.\n",
            " 30. 50. 20. 40. 40. 40. 50. 30. 20. 50. 40. 40. 50. 30. 30. 20. 20. 30.\n",
            " 30. 30. 20. 50. 30. 30. 30. 40. 30. 20. 20. 50. 30. 20. 30. 30. 50. 40.\n",
            " 50. 40. 30. 30. 30. 40. 40. 20. 20. 20. 50. 40. 30. 50. 20. 40. 30. 30.\n",
            " 50. 50. 20. 30. 40. 20. 20. 40. 30. 30. 20. 20. 20. 40. 20. 40. 20. 30.\n",
            " 30. 30. 30. 50. 30. 30. 40. 40. 40. 40. 20. 30. 40. 50. 30. 50. 40. 40.\n",
            " 50. 50. 40. 40. 30. 40. 20. 30. 20. 40. 20. 40. 40. 30. 20. 30. 30. 40.\n",
            " 30. 30. 20. 40. 40. 50. 50. 20. 20. 40. 10. 40. 40. 30. 30. 30. 30. 40.\n",
            " 50. 40. 40. 40. 40. 30. 50. 30. 20. 30. 30. 30. 50. 20. 40. 40. 40. 20.\n",
            " 40. 30. 50. 50. 40. 30. 50. 50. 30. 30. 50. 40. 50. 20. 50. 20. 50. 30.\n",
            " 20. 20. 40. 20. 40. 30. 40. 40. 20. 40. 20. 20. 30. 40. 50. 30. 20. 20.\n",
            " 50. 30. 30. 40. 40. 30. 50. 20. 50. 30. 40. 50. 40. 40. 30. 20. 40. 50.\n",
            " 40. 50. 30. 50. 30. 30. 30. 10. 30. 30. 30. 10. 30. 40. 40. 20. 50. 40.\n",
            " 30. 50. 30. 30. 20. 40. 40. 40. 30. 40. 20. 20. 40. 30. 30. 40. 30. 20.\n",
            " 50. 40. 50. 40. 20. 50. 30. 40. 20. 40. 40. 40. 30. 40. 50. 40. 40. 20.\n",
            " 20. 40. 30. 40. 40. 40. 20. 30. 20. 50. 30. 30. 50. 30. 50. 30. 20. 20.\n",
            " 30. 40. 50. 20. 50. 40. 20. 30. 20. 50. 40. 40. 40. 40. 30. 30. 30. 40.\n",
            " 30. 30. 30. 20. 20. 30. 40. 20. 30. 30. 40. 40. 20. 50. 50. 40. 50. 20.\n",
            " 40. 40. 30. 30. 40. 40. 50. 30. 50. 20. 50. 40. 30. 20. 40. 20. 20. 40.\n",
            " 40. 40. 40. 40. 20. 20. 40. 40. 30. 20. 30. 20. 20. 30. 40. 50. 20. 20.\n",
            " 40. 30. 40. 50. 30. 40. 20. 30. 20. 20. 20. 50. 30.  0. 20. 40. 40. 30.\n",
            " 30. 40. 30. 30. 20. 30. 40. 40. 40. 40. 30. 20. 20. 20. 30. 40. 50. 20.\n",
            " 30. 20. 40. 40. 30. 20. 50. 30. 40. 50. 40. 40. 50. 20. 40. 20. 40. 40.\n",
            " 40.  0. 20. 30. 30. 20. 30. 30. 30. 40. 20. 30. 30. 30. 40. 40. 50. 50.\n",
            " 20. 40. 20. 20. 50. 50. 50. 30. 30. 10. 30. 20. 40. 30. 30. 20. 50. 30.\n",
            " 40. 40. 40. 50. 40. 20. 30. 30. 50. 40. 30. 30. 30. 20. 50. 20. 30. 40.\n",
            " 40. 20. 40. 20. 20. 30. 20. 40. 30. 50. 40. 40. 30. 50. 50. 50. 40. 20.\n",
            " 30. 40.]\n",
            "selection [322 739 146 697  99 151 551 460  21 310] (10,) [ 0.  0.  0.  0.  0.  0. 10. 10. 10. 10.]\n",
            "trainset before adding uncertain samples (490, 10) (490,)\n",
            "trainset after adding uncertain samples (500, 10) (500,)\n",
            "updated train set: (500, 10) (500,) unique(labels): [253 247] [0 1]\n",
            "val set: (802, 10) (802,)\n",
            "\n",
            "Train set: (500, 10)\n",
            "Validation set: (802, 10)\n",
            "Test set: (434, 10)\n",
            "training KNN...\n",
            "--------------------------------\n",
            "Iteration: 50\n",
            "--------------------------------\n",
            "y-test set: (434,)\n",
            "Training run in 0.088 s \n",
            "\n",
            "Accuracy rate is 79.953917 \n",
            "Classification report for KNeighborsClassifier(n_jobs=-1, n_neighbors=10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.88      0.87       321\n",
            "           1       0.63      0.56      0.59       113\n",
            "\n",
            "    accuracy                           0.80       434\n",
            "   macro avg       0.74      0.72      0.73       434\n",
            "weighted avg       0.79      0.80      0.80       434\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[284  37]\n",
            " [ 50  63]]\n",
            "--------------------------------\n",
            "final active learning accuracies [73.963133640553, 67.74193548387096, 66.12903225806451, 76.72811059907833, 78.3410138248848, 75.11520737327189, 73.50230414746544, 75.80645161290323, 74.65437788018433, 76.26728110599078, 74.88479262672811, 76.72811059907833, 78.3410138248848, 77.41935483870968, 76.26728110599078, 76.72811059907833, 76.036866359447, 76.72811059907833, 76.26728110599078, 76.72811059907833, 77.41935483870968, 77.88018433179722, 77.88018433179722, 79.72350230414746, 79.03225806451613, 79.95391705069125, 80.18433179723502, 78.80184331797236, 79.49308755760369, 79.72350230414746, 80.18433179723502, 80.64516129032258, 80.4147465437788, 79.95391705069125, 80.64516129032258, 78.57142857142857, 79.26267281105991, 79.49308755760369, 79.72350230414746, 80.87557603686636, 81.33640552995391, 80.64516129032258, 79.72350230414746, 79.95391705069125, 79.49308755760369, 79.95391705069125, 80.64516129032258, 80.4147465437788, 80.87557603686636, 79.95391705069125]\n",
            "saved /Users/wenxuanhuang/Documents/Repo/ML-for-COVID-19-dataset/Results/Active-learning-experiment-40.pkl /Users/wenxuanhuang/Documents/Repo/ML-for-COVID-19-dataset ['Decision_tree.ipynb', 'dec_git.png', 'Logit_default_f10.pdf', 'Logistic.ipynb', 'SVC.ipynb', 'RF_f5e50_featureimp.pdf', 'log_al.png', 'dec_git.pdf', '.DS_Store', 'log_git.png', 'svm_git.png', 'Logistic_Scikit.ipynb', 'knn_git.pdf', 'knn_git.png', 'rf_al.png', 'Best classifier_RF_f5e50.pdf', 'KNN.ipynb', 'GBDC.ipynb', 'rf_git.png', 'README.md', 'all_training.csv', 'Results', 'svm_al.png', 'Log_ROC.png', 'Logit_default_f7(p_removal).pdf', 'Active_learning.ipynb', 'Random_forest.ipynb', 'Model_select.ipynb', 'gdbc_git.png', '.git', '.vscode', 'Untitled', 'RF_f5e50_modelselect.pdf', 'Logit_default_f8(std_removal).pdf']\n",
            "{\n",
            "  \"GDBCModel\": {\n",
            "    \"EntropySelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          65.2073732718894,\n",
            "          76.95852534562212,\n",
            "          75.11520737327189,\n",
            "          70.04608294930875,\n",
            "          72.35023041474655,\n",
            "          71.42857142857143,\n",
            "          77.41935483870968,\n",
            "          76.26728110599078,\n",
            "          77.41935483870968,\n",
            "          77.88018433179722,\n",
            "          78.57142857142857,\n",
            "          73.963133640553,\n",
            "          79.49308755760369,\n",
            "          79.03225806451613,\n",
            "          79.49308755760369,\n",
            "          79.26267281105991,\n",
            "          78.3410138248848,\n",
            "          78.57142857142857,\n",
            "          79.03225806451613,\n",
            "          80.18433179723502,\n",
            "          79.95391705069125,\n",
            "          80.18433179723502,\n",
            "          78.80184331797236,\n",
            "          79.49308755760369,\n",
            "          79.72350230414746,\n",
            "          80.18433179723502,\n",
            "          79.95391705069125,\n",
            "          81.5668202764977,\n",
            "          81.79723502304147,\n",
            "          81.5668202764977,\n",
            "          81.33640552995391,\n",
            "          80.64516129032258,\n",
            "          80.4147465437788,\n",
            "          81.10599078341014,\n",
            "          79.49308755760369,\n",
            "          80.64516129032258,\n",
            "          80.87557603686636,\n",
            "          80.87557603686636,\n",
            "          79.49308755760369,\n",
            "          80.18433179723502,\n",
            "          79.72350230414746,\n",
            "          79.95391705069125,\n",
            "          78.80184331797236,\n",
            "          79.72350230414746,\n",
            "          79.49308755760369,\n",
            "          80.4147465437788,\n",
            "          79.49308755760369,\n",
            "          80.4147465437788,\n",
            "          79.72350230414746,\n",
            "          79.95391705069125\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          77.41935483870968,\n",
            "          79.03225806451613,\n",
            "          80.64516129032258,\n",
            "          80.18433179723502\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          70.04608294930875,\n",
            "          76.49769585253456,\n",
            "          79.03225806451613,\n",
            "          78.57142857142857,\n",
            "          77.64976958525345,\n",
            "          78.80184331797236,\n",
            "          78.80184331797236,\n",
            "          77.41935483870968,\n",
            "          77.88018433179722,\n",
            "          77.64976958525345,\n",
            "          79.03225806451613,\n",
            "          77.88018433179722,\n",
            "          78.80184331797236,\n",
            "          78.80184331797236,\n",
            "          79.26267281105991,\n",
            "          79.72350230414746,\n",
            "          79.03225806451613,\n",
            "          79.72350230414746,\n",
            "          80.4147465437788,\n",
            "          80.87557603686636\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          78.57142857142857,\n",
            "          80.4147465437788\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          75.34562211981567,\n",
            "          80.64516129032258,\n",
            "          79.95391705069125,\n",
            "          79.03225806451613,\n",
            "          80.64516129032258,\n",
            "          80.18433179723502,\n",
            "          79.95391705069125,\n",
            "          79.49308755760369,\n",
            "          79.72350230414746,\n",
            "          79.49308755760369\n",
            "        ]\n",
            "      ]\n",
            "    },\n",
            "    \"MarginSamplingSelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          49.07834101382488,\n",
            "          63.133640552995395,\n",
            "          72.58064516129032,\n",
            "          68.89400921658986,\n",
            "          72.58064516129032,\n",
            "          76.036866359447,\n",
            "          75.34562211981567,\n",
            "          74.19354838709677,\n",
            "          74.65437788018433,\n",
            "          73.73271889400922,\n",
            "          75.11520737327189,\n",
            "          70.50691244239631,\n",
            "          75.57603686635944,\n",
            "          75.34562211981567,\n",
            "          75.11520737327189,\n",
            "          75.80645161290323,\n",
            "          76.72811059907833,\n",
            "          76.49769585253456,\n",
            "          77.41935483870968,\n",
            "          77.18894009216591,\n",
            "          77.41935483870968,\n",
            "          76.95852534562212,\n",
            "          78.80184331797236,\n",
            "          78.3410138248848,\n",
            "          78.57142857142857,\n",
            "          79.72350230414746,\n",
            "          79.72350230414746,\n",
            "          79.26267281105991,\n",
            "          79.49308755760369,\n",
            "          79.49308755760369,\n",
            "          79.26267281105991,\n",
            "          78.57142857142857,\n",
            "          79.03225806451613,\n",
            "          79.49308755760369,\n",
            "          79.95391705069125,\n",
            "          79.95391705069125,\n",
            "          80.18433179723502,\n",
            "          79.95391705069125,\n",
            "          80.64516129032258,\n",
            "          79.49308755760369,\n",
            "          78.57142857142857,\n",
            "          78.80184331797236,\n",
            "          78.57142857142857,\n",
            "          79.03225806451613,\n",
            "          79.26267281105991,\n",
            "          78.57142857142857,\n",
            "          79.26267281105991,\n",
            "          78.80184331797236,\n",
            "          79.26267281105991,\n",
            "          79.49308755760369\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          76.95852534562212,\n",
            "          78.80184331797236,\n",
            "          79.03225806451613,\n",
            "          81.10599078341014\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          74.65437788018433,\n",
            "          69.81566820276498,\n",
            "          80.18433179723502,\n",
            "          72.11981566820278,\n",
            "          72.81105990783409,\n",
            "          73.73271889400922,\n",
            "          73.50230414746544,\n",
            "          78.57142857142857,\n",
            "          78.57142857142857,\n",
            "          81.10599078341014,\n",
            "          80.64516129032258,\n",
            "          78.80184331797236,\n",
            "          79.26267281105991,\n",
            "          80.18433179723502,\n",
            "          79.72350230414746,\n",
            "          79.26267281105991,\n",
            "          79.95391705069125,\n",
            "          79.72350230414746,\n",
            "          79.95391705069125,\n",
            "          79.72350230414746\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          76.26728110599078,\n",
            "          79.26267281105991\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          78.11059907834101,\n",
            "          78.11059907834101,\n",
            "          78.57142857142857,\n",
            "          78.57142857142857,\n",
            "          80.4147465437788,\n",
            "          80.18433179723502,\n",
            "          79.95391705069125,\n",
            "          79.72350230414746,\n",
            "          79.49308755760369,\n",
            "          78.80184331797236\n",
            "        ]\n",
            "      ]\n",
            "    },\n",
            "    \"MinStdSelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          73.73271889400922,\n",
            "          77.18894009216591,\n",
            "          77.18894009216591,\n",
            "          76.72811059907833,\n",
            "          71.19815668202764,\n",
            "          76.49769585253456,\n",
            "          77.88018433179722,\n",
            "          78.11059907834101,\n",
            "          77.88018433179722,\n",
            "          77.88018433179722,\n",
            "          79.03225806451613,\n",
            "          79.03225806451613,\n",
            "          79.72350230414746,\n",
            "          78.57142857142857,\n",
            "          79.26267281105991,\n",
            "          79.26267281105991,\n",
            "          75.34562211981567,\n",
            "          73.50230414746544,\n",
            "          74.42396313364056,\n",
            "          73.963133640553,\n",
            "          74.19354838709677,\n",
            "          73.963133640553,\n",
            "          74.19354838709677,\n",
            "          74.42396313364056,\n",
            "          75.80645161290323,\n",
            "          75.80645161290323,\n",
            "          74.88479262672811,\n",
            "          74.65437788018433,\n",
            "          74.65437788018433,\n",
            "          75.34562211981567,\n",
            "          75.80645161290323,\n",
            "          80.87557603686636,\n",
            "          80.18433179723502,\n",
            "          80.64516129032258,\n",
            "          80.87557603686636,\n",
            "          81.10599078341014,\n",
            "          81.5668202764977,\n",
            "          81.5668202764977,\n",
            "          81.10599078341014,\n",
            "          81.33640552995391,\n",
            "          81.5668202764977,\n",
            "          82.7188940092166,\n",
            "          82.25806451612904,\n",
            "          82.25806451612904,\n",
            "          81.79723502304147,\n",
            "          80.4147465437788,\n",
            "          80.87557603686636,\n",
            "          81.10599078341014,\n",
            "          80.87557603686636,\n",
            "          81.33640552995391\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          78.3410138248848,\n",
            "          76.036866359447,\n",
            "          80.18433179723502,\n",
            "          79.72350230414746\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          77.64976958525345,\n",
            "          77.88018433179722,\n",
            "          73.04147465437788,\n",
            "          74.19354838709677,\n",
            "          80.64516129032258,\n",
            "          80.18433179723502,\n",
            "          79.72350230414746,\n",
            "          80.87557603686636,\n",
            "          81.33640552995391,\n",
            "          80.87557603686636,\n",
            "          79.49308755760369,\n",
            "          80.18433179723502,\n",
            "          80.87557603686636,\n",
            "          80.87557603686636,\n",
            "          80.87557603686636,\n",
            "          80.87557603686636,\n",
            "          81.33640552995391,\n",
            "          81.33640552995391,\n",
            "          80.18433179723502,\n",
            "          80.4147465437788\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          75.11520737327189,\n",
            "          79.26267281105991\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          79.95391705069125,\n",
            "          76.95852534562212,\n",
            "          80.18433179723502,\n",
            "          79.49308755760369,\n",
            "          79.26267281105991,\n",
            "          79.72350230414746,\n",
            "          79.95391705069125,\n",
            "          79.72350230414746,\n",
            "          79.72350230414746,\n",
            "          79.72350230414746\n",
            "        ]\n",
            "      ]\n",
            "    },\n",
            "    \"RandomSelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          63.36405529953917,\n",
            "          70.73732718894009,\n",
            "          61.29032258064516,\n",
            "          63.594470046082954,\n",
            "          74.65437788018433,\n",
            "          75.80645161290323,\n",
            "          76.49769585253456,\n",
            "          76.49769585253456,\n",
            "          77.41935483870968,\n",
            "          76.72811059907833,\n",
            "          78.3410138248848,\n",
            "          78.80184331797236,\n",
            "          77.41935483870968,\n",
            "          79.49308755760369,\n",
            "          77.64976958525345,\n",
            "          76.95852534562212,\n",
            "          77.18894009216591,\n",
            "          76.95852534562212,\n",
            "          77.64976958525345,\n",
            "          78.11059907834101,\n",
            "          78.11059907834101,\n",
            "          77.64976958525345,\n",
            "          77.64976958525345,\n",
            "          78.3410138248848,\n",
            "          78.57142857142857,\n",
            "          77.64976958525345,\n",
            "          77.64976958525345,\n",
            "          77.41935483870968,\n",
            "          77.88018433179722,\n",
            "          77.88018433179722,\n",
            "          77.88018433179722,\n",
            "          78.11059907834101,\n",
            "          77.64976958525345,\n",
            "          78.3410138248848,\n",
            "          78.80184331797236,\n",
            "          79.26267281105991,\n",
            "          78.57142857142857,\n",
            "          77.88018433179722,\n",
            "          77.64976958525345,\n",
            "          77.64976958525345,\n",
            "          78.11059907834101,\n",
            "          79.72350230414746,\n",
            "          79.72350230414746,\n",
            "          79.49308755760369,\n",
            "          79.03225806451613,\n",
            "          79.72350230414746,\n",
            "          78.80184331797236,\n",
            "          78.57142857142857,\n",
            "          79.49308755760369,\n",
            "          79.26267281105991\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          72.58064516129032,\n",
            "          72.58064516129032,\n",
            "          76.036866359447,\n",
            "          76.26728110599078\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          72.35023041474655,\n",
            "          72.11981566820278,\n",
            "          71.88940092165899,\n",
            "          73.04147465437788,\n",
            "          72.81105990783409,\n",
            "          75.11520737327189,\n",
            "          73.50230414746544,\n",
            "          76.036866359447,\n",
            "          76.26728110599078,\n",
            "          76.49769585253456,\n",
            "          76.72811059907833,\n",
            "          77.18894009216591,\n",
            "          76.72811059907833,\n",
            "          78.11059907834101,\n",
            "          78.3410138248848,\n",
            "          77.64976958525345,\n",
            "          79.72350230414746,\n",
            "          79.95391705069125,\n",
            "          80.18433179723502,\n",
            "          80.87557603686636\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          78.3410138248848,\n",
            "          79.95391705069125\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          69.35483870967742,\n",
            "          76.72811059907833,\n",
            "          78.3410138248848,\n",
            "          78.57142857142857,\n",
            "          78.80184331797236,\n",
            "          79.95391705069125,\n",
            "          79.26267281105991,\n",
            "          79.03225806451613,\n",
            "          79.03225806451613,\n",
            "          78.80184331797236\n",
            "        ]\n",
            "      ]\n",
            "    }\n",
            "  },\n",
            "  \"KnnModel\": {\n",
            "    \"EntropySelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          26.036866359447004,\n",
            "          33.87096774193548,\n",
            "          28.110599078341014,\n",
            "          27.64976958525346,\n",
            "          36.175115207373274,\n",
            "          36.405529953917046,\n",
            "          31.566820276497698,\n",
            "          31.566820276497698,\n",
            "          29.262672811059907,\n",
            "          33.6405529953917,\n",
            "          34.7926267281106,\n",
            "          41.244239631336406,\n",
            "          40.55299539170507,\n",
            "          41.244239631336406,\n",
            "          41.244239631336406,\n",
            "          41.474654377880185,\n",
            "          41.244239631336406,\n",
            "          42.3963133640553,\n",
            "          42.16589861751152,\n",
            "          42.3963133640553,\n",
            "          41.013824884792626,\n",
            "          41.935483870967744,\n",
            "          42.3963133640553,\n",
            "          41.705069124423964,\n",
            "          48.61751152073733,\n",
            "          44.23963133640553,\n",
            "          42.857142857142854,\n",
            "          41.935483870967744,\n",
            "          44.47004608294931,\n",
            "          44.70046082949309,\n",
            "          45.622119815668206,\n",
            "          44.23963133640553,\n",
            "          44.23963133640553,\n",
            "          45.852534562211986,\n",
            "          60.82949308755761,\n",
            "          58.06451612903226,\n",
            "          56.68202764976959,\n",
            "          54.60829493087558,\n",
            "          59.44700460829493,\n",
            "          73.27188940092167,\n",
            "          76.72811059907833,\n",
            "          76.26728110599078,\n",
            "          75.57603686635944,\n",
            "          75.57603686635944,\n",
            "          76.49769585253456,\n",
            "          76.95852534562212,\n",
            "          76.95852534562212,\n",
            "          76.72811059907833,\n",
            "          77.18894009216591,\n",
            "          77.18894009216591\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          78.11059907834101,\n",
            "          78.11059907834101,\n",
            "          79.72350230414746,\n",
            "          78.57142857142857\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          77.64976958525345,\n",
            "          76.036866359447,\n",
            "          77.64976958525345,\n",
            "          77.64976958525345,\n",
            "          77.18894009216591,\n",
            "          77.64976958525345,\n",
            "          77.41935483870968,\n",
            "          76.72811059907833,\n",
            "          76.26728110599078,\n",
            "          76.49769585253456,\n",
            "          74.65437788018433,\n",
            "          74.65437788018433,\n",
            "          74.88479262672811,\n",
            "          75.57603686635944,\n",
            "          75.57603686635944,\n",
            "          74.42396313364056,\n",
            "          74.65437788018433,\n",
            "          75.11520737327189,\n",
            "          75.57603686635944,\n",
            "          75.80645161290323\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          77.18894009216591,\n",
            "          77.88018433179722\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          79.72350230414746,\n",
            "          78.80184331797236,\n",
            "          78.80184331797236,\n",
            "          76.26728110599078,\n",
            "          76.26728110599078,\n",
            "          77.18894009216591,\n",
            "          78.80184331797236,\n",
            "          77.41935483870968,\n",
            "          78.11059907834101,\n",
            "          77.64976958525345\n",
            "        ]\n",
            "      ]\n",
            "    },\n",
            "    \"MarginSamplingSelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          26.036866359447004,\n",
            "          71.42857142857143,\n",
            "          76.036866359447,\n",
            "          78.3410138248848,\n",
            "          78.57142857142857,\n",
            "          77.64976958525345,\n",
            "          76.72811059907833,\n",
            "          77.41935483870968,\n",
            "          79.03225806451613,\n",
            "          78.11059907834101,\n",
            "          76.95852534562212,\n",
            "          78.57142857142857,\n",
            "          77.88018433179722,\n",
            "          79.26267281105991,\n",
            "          79.26267281105991,\n",
            "          79.72350230414746,\n",
            "          80.64516129032258,\n",
            "          81.10599078341014,\n",
            "          78.80184331797236,\n",
            "          78.3410138248848,\n",
            "          80.18433179723502,\n",
            "          79.49308755760369,\n",
            "          80.87557603686636,\n",
            "          80.4147465437788,\n",
            "          80.64516129032258,\n",
            "          80.64516129032258,\n",
            "          80.18433179723502,\n",
            "          79.72350230414746,\n",
            "          80.18433179723502,\n",
            "          80.18433179723502,\n",
            "          80.18433179723502,\n",
            "          80.87557603686636,\n",
            "          81.5668202764977,\n",
            "          80.64516129032258,\n",
            "          80.87557603686636,\n",
            "          81.5668202764977,\n",
            "          81.79723502304147,\n",
            "          79.03225806451613,\n",
            "          78.3410138248848,\n",
            "          79.03225806451613,\n",
            "          78.80184331797236,\n",
            "          78.57142857142857,\n",
            "          78.3410138248848,\n",
            "          78.3410138248848,\n",
            "          77.41935483870968,\n",
            "          78.3410138248848,\n",
            "          77.88018433179722,\n",
            "          78.80184331797236,\n",
            "          78.3410138248848,\n",
            "          78.11059907834101\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          77.18894009216591,\n",
            "          77.64976958525345,\n",
            "          78.57142857142857,\n",
            "          79.72350230414746\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          44.00921658986175,\n",
            "          77.88018433179722,\n",
            "          72.81105990783409,\n",
            "          80.4147465437788,\n",
            "          78.80184331797236,\n",
            "          76.72811059907833,\n",
            "          79.26267281105991,\n",
            "          80.18433179723502,\n",
            "          78.80184331797236,\n",
            "          79.03225806451613,\n",
            "          79.72350230414746,\n",
            "          79.49308755760369,\n",
            "          79.26267281105991,\n",
            "          78.11059907834101,\n",
            "          78.3410138248848,\n",
            "          80.4147465437788,\n",
            "          80.64516129032258,\n",
            "          81.10599078341014,\n",
            "          80.18433179723502,\n",
            "          79.72350230414746\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          77.88018433179722,\n",
            "          80.18433179723502\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          79.72350230414746,\n",
            "          75.11520737327189,\n",
            "          78.80184331797236,\n",
            "          79.26267281105991,\n",
            "          80.64516129032258,\n",
            "          79.49308755760369,\n",
            "          78.11059907834101,\n",
            "          78.57142857142857,\n",
            "          77.88018433179722,\n",
            "          78.3410138248848\n",
            "        ]\n",
            "      ]\n",
            "    },\n",
            "    \"MinStdSelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          73.963133640553,\n",
            "          67.74193548387096,\n",
            "          66.12903225806451,\n",
            "          76.72811059907833,\n",
            "          78.3410138248848,\n",
            "          75.11520737327189,\n",
            "          73.50230414746544,\n",
            "          75.80645161290323,\n",
            "          74.65437788018433,\n",
            "          76.26728110599078,\n",
            "          74.88479262672811,\n",
            "          76.72811059907833,\n",
            "          78.3410138248848,\n",
            "          77.41935483870968,\n",
            "          76.26728110599078,\n",
            "          76.72811059907833,\n",
            "          76.036866359447,\n",
            "          76.72811059907833,\n",
            "          76.26728110599078,\n",
            "          76.72811059907833,\n",
            "          77.41935483870968,\n",
            "          77.88018433179722,\n",
            "          77.88018433179722,\n",
            "          79.72350230414746,\n",
            "          79.03225806451613,\n",
            "          79.95391705069125,\n",
            "          80.18433179723502,\n",
            "          78.80184331797236,\n",
            "          79.49308755760369,\n",
            "          79.72350230414746,\n",
            "          80.18433179723502,\n",
            "          80.64516129032258,\n",
            "          80.4147465437788,\n",
            "          79.95391705069125,\n",
            "          80.64516129032258,\n",
            "          78.57142857142857,\n",
            "          79.26267281105991,\n",
            "          79.49308755760369,\n",
            "          79.72350230414746,\n",
            "          80.87557603686636,\n",
            "          81.33640552995391,\n",
            "          80.64516129032258,\n",
            "          79.72350230414746,\n",
            "          79.95391705069125,\n",
            "          79.49308755760369,\n",
            "          79.95391705069125,\n",
            "          80.64516129032258,\n",
            "          80.4147465437788,\n",
            "          80.87557603686636,\n",
            "          79.95391705069125\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          74.19354838709677,\n",
            "          79.03225806451613,\n",
            "          80.87557603686636,\n",
            "          79.26267281105991\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          77.41935483870968,\n",
            "          78.57142857142857,\n",
            "          77.18894009216591,\n",
            "          77.18894009216591,\n",
            "          77.41935483870968,\n",
            "          77.41935483870968,\n",
            "          78.3410138248848,\n",
            "          79.49308755760369,\n",
            "          79.95391705069125,\n",
            "          78.3410138248848,\n",
            "          79.03225806451613,\n",
            "          79.03225806451613,\n",
            "          79.03225806451613,\n",
            "          79.26267281105991,\n",
            "          78.11059907834101,\n",
            "          79.95391705069125,\n",
            "          79.49308755760369,\n",
            "          80.87557603686636,\n",
            "          79.49308755760369,\n",
            "          79.03225806451613\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          76.72811059907833,\n",
            "          80.64516129032258\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          76.95852534562212,\n",
            "          74.65437788018433,\n",
            "          78.11059907834101,\n",
            "          78.57142857142857,\n",
            "          77.41935483870968,\n",
            "          77.18894009216591,\n",
            "          78.3410138248848,\n",
            "          78.80184331797236,\n",
            "          80.18433179723502,\n",
            "          80.87557603686636\n",
            "        ]\n",
            "      ]\n",
            "    },\n",
            "    \"RandomSelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          26.036866359447004,\n",
            "          63.594470046082954,\n",
            "          72.58064516129032,\n",
            "          75.80645161290323,\n",
            "          73.73271889400922,\n",
            "          75.80645161290323,\n",
            "          76.26728110599078,\n",
            "          76.036866359447,\n",
            "          76.72811059907833,\n",
            "          77.18894009216591,\n",
            "          76.49769585253456,\n",
            "          74.88479262672811,\n",
            "          77.41935483870968,\n",
            "          76.49769585253456,\n",
            "          76.95852534562212,\n",
            "          76.72811059907833,\n",
            "          78.11059907834101,\n",
            "          77.64976958525345,\n",
            "          78.3410138248848,\n",
            "          77.18894009216591,\n",
            "          78.3410138248848,\n",
            "          78.57142857142857,\n",
            "          79.26267281105991,\n",
            "          78.80184331797236,\n",
            "          78.11059907834101,\n",
            "          77.88018433179722,\n",
            "          77.64976958525345,\n",
            "          77.64976958525345,\n",
            "          77.18894009216591,\n",
            "          76.95852534562212,\n",
            "          77.18894009216591,\n",
            "          77.18894009216591,\n",
            "          76.95852534562212,\n",
            "          77.41935483870968,\n",
            "          79.03225806451613,\n",
            "          78.57142857142857,\n",
            "          78.80184331797236,\n",
            "          78.3410138248848,\n",
            "          77.88018433179722,\n",
            "          77.88018433179722,\n",
            "          78.57142857142857,\n",
            "          78.80184331797236,\n",
            "          78.80184331797236,\n",
            "          78.11059907834101,\n",
            "          78.80184331797236,\n",
            "          78.80184331797236,\n",
            "          79.03225806451613,\n",
            "          78.57142857142857,\n",
            "          78.57142857142857,\n",
            "          78.57142857142857\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          76.036866359447,\n",
            "          77.18894009216591,\n",
            "          78.11059907834101,\n",
            "          78.3410138248848\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          71.88940092165899,\n",
            "          77.41935483870968,\n",
            "          74.19354838709677,\n",
            "          76.26728110599078,\n",
            "          77.41935483870968,\n",
            "          78.11059907834101,\n",
            "          77.64976958525345,\n",
            "          78.57142857142857,\n",
            "          78.80184331797236,\n",
            "          78.57142857142857,\n",
            "          78.80184331797236,\n",
            "          77.41935483870968,\n",
            "          77.18894009216591,\n",
            "          77.88018433179722,\n",
            "          78.11059907834101,\n",
            "          78.11059907834101,\n",
            "          77.41935483870968,\n",
            "          79.03225806451613,\n",
            "          78.57142857142857,\n",
            "          79.26267281105991\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          76.036866359447,\n",
            "          77.64976958525345\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          78.11059907834101,\n",
            "          77.88018433179722,\n",
            "          76.95852534562212,\n",
            "          77.18894009216591,\n",
            "          76.49769585253456,\n",
            "          76.95852534562212,\n",
            "          76.95852534562212,\n",
            "          78.11059907834101,\n",
            "          77.41935483870968,\n",
            "          78.57142857142857\n",
            "        ]\n",
            "      ]\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "---------------------------- FINISHED ---------------------------\n",
            "\n",
            "{'GDBCModel': {'RandomSelection': {'250': [[78.3410138248848, 79.95391705069125]], '125': [[72.58064516129032, 72.58064516129032, 76.036866359447, 76.26728110599078]], '50': [[69.35483870967742, 76.72811059907833, 78.3410138248848, 78.57142857142857, 78.80184331797236, 79.95391705069125, 79.26267281105991, 79.03225806451613, 79.03225806451613, 78.80184331797236]], '25': [[72.35023041474655, 72.11981566820278, 71.88940092165899, 73.04147465437788, 72.81105990783409, 75.11520737327189, 73.50230414746544, 76.036866359447, 76.26728110599078, 76.49769585253456, 76.72811059907833, 77.18894009216591, 76.72811059907833, 78.11059907834101, 78.3410138248848, 77.64976958525345, 79.72350230414746, 79.95391705069125, 80.18433179723502, 80.87557603686636]], '10': [[63.36405529953917, 70.73732718894009, 61.29032258064516, 63.594470046082954, 74.65437788018433, 75.80645161290323, 76.49769585253456, 76.49769585253456, 77.41935483870968, 76.72811059907833, 78.3410138248848, 78.80184331797236, 77.41935483870968, 79.49308755760369, 77.64976958525345, 76.95852534562212, 77.18894009216591, 76.95852534562212, 77.64976958525345, 78.11059907834101, 78.11059907834101, 77.64976958525345, 77.64976958525345, 78.3410138248848, 78.57142857142857, 77.64976958525345, 77.64976958525345, 77.41935483870968, 77.88018433179722, 77.88018433179722, 77.88018433179722, 78.11059907834101, 77.64976958525345, 78.3410138248848, 78.80184331797236, 79.26267281105991, 78.57142857142857, 77.88018433179722, 77.64976958525345, 77.64976958525345, 78.11059907834101, 79.72350230414746, 79.72350230414746, 79.49308755760369, 79.03225806451613, 79.72350230414746, 78.80184331797236, 78.57142857142857, 79.49308755760369, 79.26267281105991]]}, 'MarginSamplingSelection': {'250': [[76.26728110599078, 79.26267281105991]], '125': [[76.95852534562212, 78.80184331797236, 79.03225806451613, 81.10599078341014]], '50': [[78.11059907834101, 78.11059907834101, 78.57142857142857, 78.57142857142857, 80.4147465437788, 80.18433179723502, 79.95391705069125, 79.72350230414746, 79.49308755760369, 78.80184331797236]], '25': [[74.65437788018433, 69.81566820276498, 80.18433179723502, 72.11981566820278, 72.81105990783409, 73.73271889400922, 73.50230414746544, 78.57142857142857, 78.57142857142857, 81.10599078341014, 80.64516129032258, 78.80184331797236, 79.26267281105991, 80.18433179723502, 79.72350230414746, 79.26267281105991, 79.95391705069125, 79.72350230414746, 79.95391705069125, 79.72350230414746]], '10': [[49.07834101382488, 63.133640552995395, 72.58064516129032, 68.89400921658986, 72.58064516129032, 76.036866359447, 75.34562211981567, 74.19354838709677, 74.65437788018433, 73.73271889400922, 75.11520737327189, 70.50691244239631, 75.57603686635944, 75.34562211981567, 75.11520737327189, 75.80645161290323, 76.72811059907833, 76.49769585253456, 77.41935483870968, 77.18894009216591, 77.41935483870968, 76.95852534562212, 78.80184331797236, 78.3410138248848, 78.57142857142857, 79.72350230414746, 79.72350230414746, 79.26267281105991, 79.49308755760369, 79.49308755760369, 79.26267281105991, 78.57142857142857, 79.03225806451613, 79.49308755760369, 79.95391705069125, 79.95391705069125, 80.18433179723502, 79.95391705069125, 80.64516129032258, 79.49308755760369, 78.57142857142857, 78.80184331797236, 78.57142857142857, 79.03225806451613, 79.26267281105991, 78.57142857142857, 79.26267281105991, 78.80184331797236, 79.26267281105991, 79.49308755760369]]}, 'EntropySelection': {'250': [[78.57142857142857, 80.4147465437788]], '125': [[77.41935483870968, 79.03225806451613, 80.64516129032258, 80.18433179723502]], '50': [[75.34562211981567, 80.64516129032258, 79.95391705069125, 79.03225806451613, 80.64516129032258, 80.18433179723502, 79.95391705069125, 79.49308755760369, 79.72350230414746, 79.49308755760369]], '25': [[70.04608294930875, 76.49769585253456, 79.03225806451613, 78.57142857142857, 77.64976958525345, 78.80184331797236, 78.80184331797236, 77.41935483870968, 77.88018433179722, 77.64976958525345, 79.03225806451613, 77.88018433179722, 78.80184331797236, 78.80184331797236, 79.26267281105991, 79.72350230414746, 79.03225806451613, 79.72350230414746, 80.4147465437788, 80.87557603686636]], '10': [[65.2073732718894, 76.95852534562212, 75.11520737327189, 70.04608294930875, 72.35023041474655, 71.42857142857143, 77.41935483870968, 76.26728110599078, 77.41935483870968, 77.88018433179722, 78.57142857142857, 73.963133640553, 79.49308755760369, 79.03225806451613, 79.49308755760369, 79.26267281105991, 78.3410138248848, 78.57142857142857, 79.03225806451613, 80.18433179723502, 79.95391705069125, 80.18433179723502, 78.80184331797236, 79.49308755760369, 79.72350230414746, 80.18433179723502, 79.95391705069125, 81.5668202764977, 81.79723502304147, 81.5668202764977, 81.33640552995391, 80.64516129032258, 80.4147465437788, 81.10599078341014, 79.49308755760369, 80.64516129032258, 80.87557603686636, 80.87557603686636, 79.49308755760369, 80.18433179723502, 79.72350230414746, 79.95391705069125, 78.80184331797236, 79.72350230414746, 79.49308755760369, 80.4147465437788, 79.49308755760369, 80.4147465437788, 79.72350230414746, 79.95391705069125]]}, 'MinStdSelection': {'250': [[75.11520737327189, 79.26267281105991]], '125': [[78.3410138248848, 76.036866359447, 80.18433179723502, 79.72350230414746]], '50': [[79.95391705069125, 76.95852534562212, 80.18433179723502, 79.49308755760369, 79.26267281105991, 79.72350230414746, 79.95391705069125, 79.72350230414746, 79.72350230414746, 79.72350230414746]], '25': [[77.64976958525345, 77.88018433179722, 73.04147465437788, 74.19354838709677, 80.64516129032258, 80.18433179723502, 79.72350230414746, 80.87557603686636, 81.33640552995391, 80.87557603686636, 79.49308755760369, 80.18433179723502, 80.87557603686636, 80.87557603686636, 80.87557603686636, 80.87557603686636, 81.33640552995391, 81.33640552995391, 80.18433179723502, 80.4147465437788]], '10': [[73.73271889400922, 77.18894009216591, 77.18894009216591, 76.72811059907833, 71.19815668202764, 76.49769585253456, 77.88018433179722, 78.11059907834101, 77.88018433179722, 77.88018433179722, 79.03225806451613, 79.03225806451613, 79.72350230414746, 78.57142857142857, 79.26267281105991, 79.26267281105991, 75.34562211981567, 73.50230414746544, 74.42396313364056, 73.963133640553, 74.19354838709677, 73.963133640553, 74.19354838709677, 74.42396313364056, 75.80645161290323, 75.80645161290323, 74.88479262672811, 74.65437788018433, 74.65437788018433, 75.34562211981567, 75.80645161290323, 80.87557603686636, 80.18433179723502, 80.64516129032258, 80.87557603686636, 81.10599078341014, 81.5668202764977, 81.5668202764977, 81.10599078341014, 81.33640552995391, 81.5668202764977, 82.7188940092166, 82.25806451612904, 82.25806451612904, 81.79723502304147, 80.4147465437788, 80.87557603686636, 81.10599078341014, 80.87557603686636, 81.33640552995391]]}}, 'KnnModel': {'RandomSelection': {'250': [[76.036866359447, 77.64976958525345]], '125': [[76.036866359447, 77.18894009216591, 78.11059907834101, 78.3410138248848]], '50': [[78.11059907834101, 77.88018433179722, 76.95852534562212, 77.18894009216591, 76.49769585253456, 76.95852534562212, 76.95852534562212, 78.11059907834101, 77.41935483870968, 78.57142857142857]], '25': [[71.88940092165899, 77.41935483870968, 74.19354838709677, 76.26728110599078, 77.41935483870968, 78.11059907834101, 77.64976958525345, 78.57142857142857, 78.80184331797236, 78.57142857142857, 78.80184331797236, 77.41935483870968, 77.18894009216591, 77.88018433179722, 78.11059907834101, 78.11059907834101, 77.41935483870968, 79.03225806451613, 78.57142857142857, 79.26267281105991]], '10': [[26.036866359447004, 63.594470046082954, 72.58064516129032, 75.80645161290323, 73.73271889400922, 75.80645161290323, 76.26728110599078, 76.036866359447, 76.72811059907833, 77.18894009216591, 76.49769585253456, 74.88479262672811, 77.41935483870968, 76.49769585253456, 76.95852534562212, 76.72811059907833, 78.11059907834101, 77.64976958525345, 78.3410138248848, 77.18894009216591, 78.3410138248848, 78.57142857142857, 79.26267281105991, 78.80184331797236, 78.11059907834101, 77.88018433179722, 77.64976958525345, 77.64976958525345, 77.18894009216591, 76.95852534562212, 77.18894009216591, 77.18894009216591, 76.95852534562212, 77.41935483870968, 79.03225806451613, 78.57142857142857, 78.80184331797236, 78.3410138248848, 77.88018433179722, 77.88018433179722, 78.57142857142857, 78.80184331797236, 78.80184331797236, 78.11059907834101, 78.80184331797236, 78.80184331797236, 79.03225806451613, 78.57142857142857, 78.57142857142857, 78.57142857142857]]}, 'MarginSamplingSelection': {'250': [[77.88018433179722, 80.18433179723502]], '125': [[77.18894009216591, 77.64976958525345, 78.57142857142857, 79.72350230414746]], '50': [[79.72350230414746, 75.11520737327189, 78.80184331797236, 79.26267281105991, 80.64516129032258, 79.49308755760369, 78.11059907834101, 78.57142857142857, 77.88018433179722, 78.3410138248848]], '25': [[44.00921658986175, 77.88018433179722, 72.81105990783409, 80.4147465437788, 78.80184331797236, 76.72811059907833, 79.26267281105991, 80.18433179723502, 78.80184331797236, 79.03225806451613, 79.72350230414746, 79.49308755760369, 79.26267281105991, 78.11059907834101, 78.3410138248848, 80.4147465437788, 80.64516129032258, 81.10599078341014, 80.18433179723502, 79.72350230414746]], '10': [[26.036866359447004, 71.42857142857143, 76.036866359447, 78.3410138248848, 78.57142857142857, 77.64976958525345, 76.72811059907833, 77.41935483870968, 79.03225806451613, 78.11059907834101, 76.95852534562212, 78.57142857142857, 77.88018433179722, 79.26267281105991, 79.26267281105991, 79.72350230414746, 80.64516129032258, 81.10599078341014, 78.80184331797236, 78.3410138248848, 80.18433179723502, 79.49308755760369, 80.87557603686636, 80.4147465437788, 80.64516129032258, 80.64516129032258, 80.18433179723502, 79.72350230414746, 80.18433179723502, 80.18433179723502, 80.18433179723502, 80.87557603686636, 81.5668202764977, 80.64516129032258, 80.87557603686636, 81.5668202764977, 81.79723502304147, 79.03225806451613, 78.3410138248848, 79.03225806451613, 78.80184331797236, 78.57142857142857, 78.3410138248848, 78.3410138248848, 77.41935483870968, 78.3410138248848, 77.88018433179722, 78.80184331797236, 78.3410138248848, 78.11059907834101]]}, 'EntropySelection': {'250': [[77.18894009216591, 77.88018433179722]], '125': [[78.11059907834101, 78.11059907834101, 79.72350230414746, 78.57142857142857]], '50': [[79.72350230414746, 78.80184331797236, 78.80184331797236, 76.26728110599078, 76.26728110599078, 77.18894009216591, 78.80184331797236, 77.41935483870968, 78.11059907834101, 77.64976958525345]], '25': [[77.64976958525345, 76.036866359447, 77.64976958525345, 77.64976958525345, 77.18894009216591, 77.64976958525345, 77.41935483870968, 76.72811059907833, 76.26728110599078, 76.49769585253456, 74.65437788018433, 74.65437788018433, 74.88479262672811, 75.57603686635944, 75.57603686635944, 74.42396313364056, 74.65437788018433, 75.11520737327189, 75.57603686635944, 75.80645161290323]], '10': [[26.036866359447004, 33.87096774193548, 28.110599078341014, 27.64976958525346, 36.175115207373274, 36.405529953917046, 31.566820276497698, 31.566820276497698, 29.262672811059907, 33.6405529953917, 34.7926267281106, 41.244239631336406, 40.55299539170507, 41.244239631336406, 41.244239631336406, 41.474654377880185, 41.244239631336406, 42.3963133640553, 42.16589861751152, 42.3963133640553, 41.013824884792626, 41.935483870967744, 42.3963133640553, 41.705069124423964, 48.61751152073733, 44.23963133640553, 42.857142857142854, 41.935483870967744, 44.47004608294931, 44.70046082949309, 45.622119815668206, 44.23963133640553, 44.23963133640553, 45.852534562211986, 60.82949308755761, 58.06451612903226, 56.68202764976959, 54.60829493087558, 59.44700460829493, 73.27188940092167, 76.72811059907833, 76.26728110599078, 75.57603686635944, 75.57603686635944, 76.49769585253456, 76.95852534562212, 76.95852534562212, 76.72811059907833, 77.18894009216591, 77.18894009216591]]}, 'MinStdSelection': {'250': [[76.72811059907833, 80.64516129032258]], '125': [[74.19354838709677, 79.03225806451613, 80.87557603686636, 79.26267281105991]], '50': [[76.95852534562212, 74.65437788018433, 78.11059907834101, 78.57142857142857, 77.41935483870968, 77.18894009216591, 78.3410138248848, 78.80184331797236, 80.18433179723502, 80.87557603686636]], '25': [[77.41935483870968, 78.57142857142857, 77.18894009216591, 77.18894009216591, 77.41935483870968, 77.41935483870968, 78.3410138248848, 79.49308755760369, 79.95391705069125, 78.3410138248848, 79.03225806451613, 79.03225806451613, 79.03225806451613, 79.26267281105991, 78.11059907834101, 79.95391705069125, 79.49308755760369, 80.87557603686636, 79.49308755760369, 79.03225806451613]], '10': [[73.963133640553, 67.74193548387096, 66.12903225806451, 76.72811059907833, 78.3410138248848, 75.11520737327189, 73.50230414746544, 75.80645161290323, 74.65437788018433, 76.26728110599078, 74.88479262672811, 76.72811059907833, 78.3410138248848, 77.41935483870968, 76.26728110599078, 76.72811059907833, 76.036866359447, 76.72811059907833, 76.26728110599078, 76.72811059907833, 77.41935483870968, 77.88018433179722, 77.88018433179722, 79.72350230414746, 79.03225806451613, 79.95391705069125, 80.18433179723502, 78.80184331797236, 79.49308755760369, 79.72350230414746, 80.18433179723502, 80.64516129032258, 80.4147465437788, 79.95391705069125, 80.64516129032258, 78.57142857142857, 79.26267281105991, 79.49308755760369, 79.72350230414746, 80.87557603686636, 81.33640552995391, 80.64516129032258, 79.72350230414746, 79.95391705069125, 79.49308755760369, 79.95391705069125, 80.64516129032258, 80.4147465437788, 80.87557603686636, 79.95391705069125]]}}}\n",
            "{'GDBCModel': {'EntropySelection': {'10': [[65.2073732718894, 76.95852534562212, 75.11520737327189, 70.04608294930875, 72.35023041474655, 71.42857142857143, 77.41935483870968, 76.26728110599078, 77.41935483870968, 77.88018433179722, 78.57142857142857, 73.963133640553, 79.49308755760369, 79.03225806451613, 79.49308755760369, 79.26267281105991, 78.3410138248848, 78.57142857142857, 79.03225806451613, 80.18433179723502, 79.95391705069125, 80.18433179723502, 78.80184331797236, 79.49308755760369, 79.72350230414746, 80.18433179723502, 79.95391705069125, 81.5668202764977, 81.79723502304147, 81.5668202764977, 81.33640552995391, 80.64516129032258, 80.4147465437788, 81.10599078341014, 79.49308755760369, 80.64516129032258, 80.87557603686636, 80.87557603686636, 79.49308755760369, 80.18433179723502, 79.72350230414746, 79.95391705069125, 78.80184331797236, 79.72350230414746, 79.49308755760369, 80.4147465437788, 79.49308755760369, 80.4147465437788, 79.72350230414746, 79.95391705069125]], '125': [[77.41935483870968, 79.03225806451613, 80.64516129032258, 80.18433179723502]], '25': [[70.04608294930875, 76.49769585253456, 79.03225806451613, 78.57142857142857, 77.64976958525345, 78.80184331797236, 78.80184331797236, 77.41935483870968, 77.88018433179722, 77.64976958525345, 79.03225806451613, 77.88018433179722, 78.80184331797236, 78.80184331797236, 79.26267281105991, 79.72350230414746, 79.03225806451613, 79.72350230414746, 80.4147465437788, 80.87557603686636]], '250': [[78.57142857142857, 80.4147465437788]], '50': [[75.34562211981567, 80.64516129032258, 79.95391705069125, 79.03225806451613, 80.64516129032258, 80.18433179723502, 79.95391705069125, 79.49308755760369, 79.72350230414746, 79.49308755760369]]}, 'MarginSamplingSelection': {'10': [[49.07834101382488, 63.133640552995395, 72.58064516129032, 68.89400921658986, 72.58064516129032, 76.036866359447, 75.34562211981567, 74.19354838709677, 74.65437788018433, 73.73271889400922, 75.11520737327189, 70.50691244239631, 75.57603686635944, 75.34562211981567, 75.11520737327189, 75.80645161290323, 76.72811059907833, 76.49769585253456, 77.41935483870968, 77.18894009216591, 77.41935483870968, 76.95852534562212, 78.80184331797236, 78.3410138248848, 78.57142857142857, 79.72350230414746, 79.72350230414746, 79.26267281105991, 79.49308755760369, 79.49308755760369, 79.26267281105991, 78.57142857142857, 79.03225806451613, 79.49308755760369, 79.95391705069125, 79.95391705069125, 80.18433179723502, 79.95391705069125, 80.64516129032258, 79.49308755760369, 78.57142857142857, 78.80184331797236, 78.57142857142857, 79.03225806451613, 79.26267281105991, 78.57142857142857, 79.26267281105991, 78.80184331797236, 79.26267281105991, 79.49308755760369]], '125': [[76.95852534562212, 78.80184331797236, 79.03225806451613, 81.10599078341014]], '25': [[74.65437788018433, 69.81566820276498, 80.18433179723502, 72.11981566820278, 72.81105990783409, 73.73271889400922, 73.50230414746544, 78.57142857142857, 78.57142857142857, 81.10599078341014, 80.64516129032258, 78.80184331797236, 79.26267281105991, 80.18433179723502, 79.72350230414746, 79.26267281105991, 79.95391705069125, 79.72350230414746, 79.95391705069125, 79.72350230414746]], '250': [[76.26728110599078, 79.26267281105991]], '50': [[78.11059907834101, 78.11059907834101, 78.57142857142857, 78.57142857142857, 80.4147465437788, 80.18433179723502, 79.95391705069125, 79.72350230414746, 79.49308755760369, 78.80184331797236]]}, 'MinStdSelection': {'10': [[73.73271889400922, 77.18894009216591, 77.18894009216591, 76.72811059907833, 71.19815668202764, 76.49769585253456, 77.88018433179722, 78.11059907834101, 77.88018433179722, 77.88018433179722, 79.03225806451613, 79.03225806451613, 79.72350230414746, 78.57142857142857, 79.26267281105991, 79.26267281105991, 75.34562211981567, 73.50230414746544, 74.42396313364056, 73.963133640553, 74.19354838709677, 73.963133640553, 74.19354838709677, 74.42396313364056, 75.80645161290323, 75.80645161290323, 74.88479262672811, 74.65437788018433, 74.65437788018433, 75.34562211981567, 75.80645161290323, 80.87557603686636, 80.18433179723502, 80.64516129032258, 80.87557603686636, 81.10599078341014, 81.5668202764977, 81.5668202764977, 81.10599078341014, 81.33640552995391, 81.5668202764977, 82.7188940092166, 82.25806451612904, 82.25806451612904, 81.79723502304147, 80.4147465437788, 80.87557603686636, 81.10599078341014, 80.87557603686636, 81.33640552995391]], '125': [[78.3410138248848, 76.036866359447, 80.18433179723502, 79.72350230414746]], '25': [[77.64976958525345, 77.88018433179722, 73.04147465437788, 74.19354838709677, 80.64516129032258, 80.18433179723502, 79.72350230414746, 80.87557603686636, 81.33640552995391, 80.87557603686636, 79.49308755760369, 80.18433179723502, 80.87557603686636, 80.87557603686636, 80.87557603686636, 80.87557603686636, 81.33640552995391, 81.33640552995391, 80.18433179723502, 80.4147465437788]], '250': [[75.11520737327189, 79.26267281105991]], '50': [[79.95391705069125, 76.95852534562212, 80.18433179723502, 79.49308755760369, 79.26267281105991, 79.72350230414746, 79.95391705069125, 79.72350230414746, 79.72350230414746, 79.72350230414746]]}, 'RandomSelection': {'10': [[63.36405529953917, 70.73732718894009, 61.29032258064516, 63.594470046082954, 74.65437788018433, 75.80645161290323, 76.49769585253456, 76.49769585253456, 77.41935483870968, 76.72811059907833, 78.3410138248848, 78.80184331797236, 77.41935483870968, 79.49308755760369, 77.64976958525345, 76.95852534562212, 77.18894009216591, 76.95852534562212, 77.64976958525345, 78.11059907834101, 78.11059907834101, 77.64976958525345, 77.64976958525345, 78.3410138248848, 78.57142857142857, 77.64976958525345, 77.64976958525345, 77.41935483870968, 77.88018433179722, 77.88018433179722, 77.88018433179722, 78.11059907834101, 77.64976958525345, 78.3410138248848, 78.80184331797236, 79.26267281105991, 78.57142857142857, 77.88018433179722, 77.64976958525345, 77.64976958525345, 78.11059907834101, 79.72350230414746, 79.72350230414746, 79.49308755760369, 79.03225806451613, 79.72350230414746, 78.80184331797236, 78.57142857142857, 79.49308755760369, 79.26267281105991]], '125': [[72.58064516129032, 72.58064516129032, 76.036866359447, 76.26728110599078]], '25': [[72.35023041474655, 72.11981566820278, 71.88940092165899, 73.04147465437788, 72.81105990783409, 75.11520737327189, 73.50230414746544, 76.036866359447, 76.26728110599078, 76.49769585253456, 76.72811059907833, 77.18894009216591, 76.72811059907833, 78.11059907834101, 78.3410138248848, 77.64976958525345, 79.72350230414746, 79.95391705069125, 80.18433179723502, 80.87557603686636]], '250': [[78.3410138248848, 79.95391705069125]], '50': [[69.35483870967742, 76.72811059907833, 78.3410138248848, 78.57142857142857, 78.80184331797236, 79.95391705069125, 79.26267281105991, 79.03225806451613, 79.03225806451613, 78.80184331797236]]}}, 'KnnModel': {'EntropySelection': {'10': [[26.036866359447004, 33.87096774193548, 28.110599078341014, 27.64976958525346, 36.175115207373274, 36.405529953917046, 31.566820276497698, 31.566820276497698, 29.262672811059907, 33.6405529953917, 34.7926267281106, 41.244239631336406, 40.55299539170507, 41.244239631336406, 41.244239631336406, 41.474654377880185, 41.244239631336406, 42.3963133640553, 42.16589861751152, 42.3963133640553, 41.013824884792626, 41.935483870967744, 42.3963133640553, 41.705069124423964, 48.61751152073733, 44.23963133640553, 42.857142857142854, 41.935483870967744, 44.47004608294931, 44.70046082949309, 45.622119815668206, 44.23963133640553, 44.23963133640553, 45.852534562211986, 60.82949308755761, 58.06451612903226, 56.68202764976959, 54.60829493087558, 59.44700460829493, 73.27188940092167, 76.72811059907833, 76.26728110599078, 75.57603686635944, 75.57603686635944, 76.49769585253456, 76.95852534562212, 76.95852534562212, 76.72811059907833, 77.18894009216591, 77.18894009216591]], '125': [[78.11059907834101, 78.11059907834101, 79.72350230414746, 78.57142857142857]], '25': [[77.64976958525345, 76.036866359447, 77.64976958525345, 77.64976958525345, 77.18894009216591, 77.64976958525345, 77.41935483870968, 76.72811059907833, 76.26728110599078, 76.49769585253456, 74.65437788018433, 74.65437788018433, 74.88479262672811, 75.57603686635944, 75.57603686635944, 74.42396313364056, 74.65437788018433, 75.11520737327189, 75.57603686635944, 75.80645161290323]], '250': [[77.18894009216591, 77.88018433179722]], '50': [[79.72350230414746, 78.80184331797236, 78.80184331797236, 76.26728110599078, 76.26728110599078, 77.18894009216591, 78.80184331797236, 77.41935483870968, 78.11059907834101, 77.64976958525345]]}, 'MarginSamplingSelection': {'10': [[26.036866359447004, 71.42857142857143, 76.036866359447, 78.3410138248848, 78.57142857142857, 77.64976958525345, 76.72811059907833, 77.41935483870968, 79.03225806451613, 78.11059907834101, 76.95852534562212, 78.57142857142857, 77.88018433179722, 79.26267281105991, 79.26267281105991, 79.72350230414746, 80.64516129032258, 81.10599078341014, 78.80184331797236, 78.3410138248848, 80.18433179723502, 79.49308755760369, 80.87557603686636, 80.4147465437788, 80.64516129032258, 80.64516129032258, 80.18433179723502, 79.72350230414746, 80.18433179723502, 80.18433179723502, 80.18433179723502, 80.87557603686636, 81.5668202764977, 80.64516129032258, 80.87557603686636, 81.5668202764977, 81.79723502304147, 79.03225806451613, 78.3410138248848, 79.03225806451613, 78.80184331797236, 78.57142857142857, 78.3410138248848, 78.3410138248848, 77.41935483870968, 78.3410138248848, 77.88018433179722, 78.80184331797236, 78.3410138248848, 78.11059907834101]], '125': [[77.18894009216591, 77.64976958525345, 78.57142857142857, 79.72350230414746]], '25': [[44.00921658986175, 77.88018433179722, 72.81105990783409, 80.4147465437788, 78.80184331797236, 76.72811059907833, 79.26267281105991, 80.18433179723502, 78.80184331797236, 79.03225806451613, 79.72350230414746, 79.49308755760369, 79.26267281105991, 78.11059907834101, 78.3410138248848, 80.4147465437788, 80.64516129032258, 81.10599078341014, 80.18433179723502, 79.72350230414746]], '250': [[77.88018433179722, 80.18433179723502]], '50': [[79.72350230414746, 75.11520737327189, 78.80184331797236, 79.26267281105991, 80.64516129032258, 79.49308755760369, 78.11059907834101, 78.57142857142857, 77.88018433179722, 78.3410138248848]]}, 'MinStdSelection': {'10': [[73.963133640553, 67.74193548387096, 66.12903225806451, 76.72811059907833, 78.3410138248848, 75.11520737327189, 73.50230414746544, 75.80645161290323, 74.65437788018433, 76.26728110599078, 74.88479262672811, 76.72811059907833, 78.3410138248848, 77.41935483870968, 76.26728110599078, 76.72811059907833, 76.036866359447, 76.72811059907833, 76.26728110599078, 76.72811059907833, 77.41935483870968, 77.88018433179722, 77.88018433179722, 79.72350230414746, 79.03225806451613, 79.95391705069125, 80.18433179723502, 78.80184331797236, 79.49308755760369, 79.72350230414746, 80.18433179723502, 80.64516129032258, 80.4147465437788, 79.95391705069125, 80.64516129032258, 78.57142857142857, 79.26267281105991, 79.49308755760369, 79.72350230414746, 80.87557603686636, 81.33640552995391, 80.64516129032258, 79.72350230414746, 79.95391705069125, 79.49308755760369, 79.95391705069125, 80.64516129032258, 80.4147465437788, 80.87557603686636, 79.95391705069125]], '125': [[74.19354838709677, 79.03225806451613, 80.87557603686636, 79.26267281105991]], '25': [[77.41935483870968, 78.57142857142857, 77.18894009216591, 77.18894009216591, 77.41935483870968, 77.41935483870968, 78.3410138248848, 79.49308755760369, 79.95391705069125, 78.3410138248848, 79.03225806451613, 79.03225806451613, 79.03225806451613, 79.26267281105991, 78.11059907834101, 79.95391705069125, 79.49308755760369, 80.87557603686636, 79.49308755760369, 79.03225806451613]], '250': [[76.72811059907833, 80.64516129032258]], '50': [[76.95852534562212, 74.65437788018433, 78.11059907834101, 78.57142857142857, 77.41935483870968, 77.18894009216591, 78.3410138248848, 78.80184331797236, 80.18433179723502, 80.87557603686636]]}, 'RandomSelection': {'10': [[26.036866359447004, 63.594470046082954, 72.58064516129032, 75.80645161290323, 73.73271889400922, 75.80645161290323, 76.26728110599078, 76.036866359447, 76.72811059907833, 77.18894009216591, 76.49769585253456, 74.88479262672811, 77.41935483870968, 76.49769585253456, 76.95852534562212, 76.72811059907833, 78.11059907834101, 77.64976958525345, 78.3410138248848, 77.18894009216591, 78.3410138248848, 78.57142857142857, 79.26267281105991, 78.80184331797236, 78.11059907834101, 77.88018433179722, 77.64976958525345, 77.64976958525345, 77.18894009216591, 76.95852534562212, 77.18894009216591, 77.18894009216591, 76.95852534562212, 77.41935483870968, 79.03225806451613, 78.57142857142857, 78.80184331797236, 78.3410138248848, 77.88018433179722, 77.88018433179722, 78.57142857142857, 78.80184331797236, 78.80184331797236, 78.11059907834101, 78.80184331797236, 78.80184331797236, 79.03225806451613, 78.57142857142857, 78.57142857142857, 78.57142857142857]], '125': [[76.036866359447, 77.18894009216591, 78.11059907834101, 78.3410138248848]], '25': [[71.88940092165899, 77.41935483870968, 74.19354838709677, 76.26728110599078, 77.41935483870968, 78.11059907834101, 77.64976958525345, 78.57142857142857, 78.80184331797236, 78.57142857142857, 78.80184331797236, 77.41935483870968, 77.18894009216591, 77.88018433179722, 78.11059907834101, 78.11059907834101, 77.41935483870968, 79.03225806451613, 78.57142857142857, 79.26267281105991]], '250': [[76.036866359447, 77.64976958525345]], '50': [[78.11059907834101, 77.88018433179722, 76.95852534562212, 77.18894009216591, 76.49769585253456, 76.95852534562212, 76.95852534562212, 78.11059907834101, 77.41935483870968, 78.57142857142857]]}}}\n"
          ]
        }
      ],
      "source": [
        "(X, y) = data_prep()\n",
        "(X_train_full, y_train_full, X_test, y_test) = split(trainset_size)\n",
        "print ('train:', X_train_full.shape, y_train_full.shape)\n",
        "print ('test :', X_test.shape, y_test.shape)\n",
        "classes = len(np.unique(y))\n",
        "print ('unique classes', classes)\n",
        "\n",
        "def pickle_save(fname, data):\n",
        "  filehandler = open(fname,\"wb\")\n",
        "  pickle.dump(data,filehandler)\n",
        "  filehandler.close() \n",
        "  print('saved', fname, os.getcwd(), os.listdir())\n",
        "\n",
        "def pickle_load(fname):\n",
        "  print(os.getcwd(), os.listdir())\n",
        "  file = open(fname,'rb')\n",
        "  data = pickle.load(file)\n",
        "  file.close()\n",
        "  print(data)\n",
        "  return data\n",
        "  \n",
        "def experiment(d, models, selection_functions, Ks, repeats, contfrom):\n",
        "    algos_temp = []\n",
        "    print ('stopping at:', max_queried)\n",
        "    count = 0\n",
        "    for model_object in models:\n",
        "      if model_object.__name__ not in d:\n",
        "          d[model_object.__name__] = {}\n",
        "      \n",
        "      for selection_function in selection_functions:\n",
        "        if selection_function.__name__ not in d[model_object.__name__]:\n",
        "            d[model_object.__name__][selection_function.__name__] = {}\n",
        "        \n",
        "        for k in Ks:\n",
        "            d[model_object.__name__][selection_function.__name__][str(k)] = []           \n",
        "            \n",
        "            for i in range(0, repeats):\n",
        "                count+=1\n",
        "                if count >= contfrom:\n",
        "                    print ('Count = %s, using model = %s, selection_function = %s, k = %s, iteration = %s.' % (count, model_object.__name__, selection_function.__name__, k, i))\n",
        "                    alg = TheAlgorithm(k, \n",
        "                                       model_object, \n",
        "                                       selection_function\n",
        "                                       )\n",
        "                    alg.run(X_train_full, y_train_full, X_test, y_test)\n",
        "                    d[model_object.__name__][selection_function.__name__][str(k)].append(alg.clf_model.accuracies)\n",
        "                    fname = '/Users/wenxuanhuang/Documents/Repo/ML-for-COVID-19-dataset/Results/Active-learning-experiment-' + str(count) + '.pkl'\n",
        "                    pickle_save(fname, d)\n",
        "                    if count % 5 == 0:\n",
        "                        print(json.dumps(d, indent=2, sort_keys=True))\n",
        "                    print ()\n",
        "                    print ('---------------------------- FINISHED ---------------------------')\n",
        "                    print ()\n",
        "    return d\n",
        "\n",
        "\n",
        "max_queried = 500 \n",
        "\n",
        "repeats = 1\n",
        "\n",
        "models = [GDBCModel, KnnModel] \n",
        "# models = [SvmModel, RfModel, LogModel] \n",
        "\n",
        "# selection_functions = [RandomSelection] \n",
        "selection_functions = [RandomSelection, MarginSamplingSelection, EntropySelection, MinStdSelection] \n",
        "\n",
        "Ks = [250,125,50,25,10] \n",
        "\n",
        "d = {}\n",
        "stopped_at = -1 \n",
        "\n",
        "# print('directory dump including pickle files:', os.getcwd(), np.sort(os.listdir()))  \n",
        "# d = pickle_load('Active-learning-experiment-' + str(stopped_at) + '.pkl')  \n",
        "# print(json.dumps(d, indent=2, sort_keys=True))\n",
        "\n",
        "d = experiment(d, models, selection_functions, Ks, repeats, stopped_at+1)\n",
        "print (d)\n",
        "results = json.loads(json.dumps(d, indent=2, sort_keys=True))\n",
        "print(results)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "So which is the better model? under the stopping condition and hyper parameters - random forest is the winner!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 432x288 with 1 Axes>",
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<svg height=\"334.439844pt\" version=\"1.1\" viewBox=\"0 0 384.83125 334.439844\" width=\"384.83125pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <metadata>\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2021-04-22T18:05:23.057109</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.4.1, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 334.439844 \nL 384.83125 334.439844 \nL 384.83125 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 33.2875 228.439219 \nL 368.0875 228.439219 \nL 368.0875 10.999219 \nL 33.2875 10.999219 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <path clip-path=\"url(#p05bfa37ed2)\" d=\"M 33.2875 228.439219 \nL 33.2875 10.999219 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_2\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"m8b84ce31a4\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#m8b84ce31a4\" y=\"228.439219\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 50 -->\n      <g transform=\"translate(26.925 243.037656)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 691 4666 \nL 3169 4666 \nL 3169 4134 \nL 1269 4134 \nL 1269 2991 \nQ 1406 3038 1543 3061 \nQ 1681 3084 1819 3084 \nQ 2600 3084 3056 2656 \nQ 3513 2228 3513 1497 \nQ 3513 744 3044 326 \nQ 2575 -91 1722 -91 \nQ 1428 -91 1123 -41 \nQ 819 9 494 109 \nL 494 744 \nQ 775 591 1075 516 \nQ 1375 441 1709 441 \nQ 2250 441 2565 725 \nQ 2881 1009 2881 1497 \nQ 2881 1984 2565 2268 \nQ 2250 2553 1709 2553 \nQ 1456 2553 1204 2497 \nQ 953 2441 691 2322 \nL 691 4666 \nz\n\" id=\"DejaVuSans-35\" transform=\"scale(0.015625)\"/>\n        <path d=\"M 2034 4250 \nQ 1547 4250 1301 3770 \nQ 1056 3291 1056 2328 \nQ 1056 1369 1301 889 \nQ 1547 409 2034 409 \nQ 2525 409 2770 889 \nQ 3016 1369 3016 2328 \nQ 3016 3291 2770 3770 \nQ 2525 4250 2034 4250 \nz\nM 2034 4750 \nQ 2819 4750 3233 4129 \nQ 3647 3509 3647 2328 \nQ 3647 1150 3233 529 \nQ 2819 -91 2034 -91 \nQ 1250 -91 836 529 \nQ 422 1150 422 2328 \nQ 422 3509 836 4129 \nQ 1250 4750 2034 4750 \nz\n\" id=\"DejaVuSans-30\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-35\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_3\">\n      <path clip-path=\"url(#p05bfa37ed2)\" d=\"M 70.4875 228.439219 \nL 70.4875 10.999219 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"70.4875\" xlink:href=\"#m8b84ce31a4\" y=\"228.439219\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 100 -->\n      <g transform=\"translate(60.94375 243.037656)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 794 531 \nL 1825 531 \nL 1825 4091 \nL 703 3866 \nL 703 4441 \nL 1819 4666 \nL 2450 4666 \nL 2450 531 \nL 3481 531 \nL 3481 0 \nL 794 0 \nL 794 531 \nz\n\" id=\"DejaVuSans-31\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_5\">\n      <path clip-path=\"url(#p05bfa37ed2)\" d=\"M 107.6875 228.439219 \nL 107.6875 10.999219 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"107.6875\" xlink:href=\"#m8b84ce31a4\" y=\"228.439219\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 150 -->\n      <g transform=\"translate(98.14375 243.037656)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-35\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_7\">\n      <path clip-path=\"url(#p05bfa37ed2)\" d=\"M 144.8875 228.439219 \nL 144.8875 10.999219 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"144.8875\" xlink:href=\"#m8b84ce31a4\" y=\"228.439219\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 200 -->\n      <g transform=\"translate(135.34375 243.037656)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 1228 531 \nL 3431 531 \nL 3431 0 \nL 469 0 \nL 469 531 \nQ 828 903 1448 1529 \nQ 2069 2156 2228 2338 \nQ 2531 2678 2651 2914 \nQ 2772 3150 2772 3378 \nQ 2772 3750 2511 3984 \nQ 2250 4219 1831 4219 \nQ 1534 4219 1204 4116 \nQ 875 4013 500 3803 \nL 500 4441 \nQ 881 4594 1212 4672 \nQ 1544 4750 1819 4750 \nQ 2544 4750 2975 4387 \nQ 3406 4025 3406 3419 \nQ 3406 3131 3298 2873 \nQ 3191 2616 2906 2266 \nQ 2828 2175 2409 1742 \nQ 1991 1309 1228 531 \nz\n\" id=\"DejaVuSans-32\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_9\">\n      <path clip-path=\"url(#p05bfa37ed2)\" d=\"M 182.0875 228.439219 \nL 182.0875 10.999219 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"182.0875\" xlink:href=\"#m8b84ce31a4\" y=\"228.439219\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 250 -->\n      <g transform=\"translate(172.54375 243.037656)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-35\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_11\">\n      <path clip-path=\"url(#p05bfa37ed2)\" d=\"M 219.2875 228.439219 \nL 219.2875 10.999219 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"219.2875\" xlink:href=\"#m8b84ce31a4\" y=\"228.439219\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 300 -->\n      <g transform=\"translate(209.74375 243.037656)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 2597 2516 \nQ 3050 2419 3304 2112 \nQ 3559 1806 3559 1356 \nQ 3559 666 3084 287 \nQ 2609 -91 1734 -91 \nQ 1441 -91 1130 -33 \nQ 819 25 488 141 \nL 488 750 \nQ 750 597 1062 519 \nQ 1375 441 1716 441 \nQ 2309 441 2620 675 \nQ 2931 909 2931 1356 \nQ 2931 1769 2642 2001 \nQ 2353 2234 1838 2234 \nL 1294 2234 \nL 1294 2753 \nL 1863 2753 \nQ 2328 2753 2575 2939 \nQ 2822 3125 2822 3475 \nQ 2822 3834 2567 4026 \nQ 2313 4219 1838 4219 \nQ 1578 4219 1281 4162 \nQ 984 4106 628 3988 \nL 628 4550 \nQ 988 4650 1302 4700 \nQ 1616 4750 1894 4750 \nQ 2613 4750 3031 4423 \nQ 3450 4097 3450 3541 \nQ 3450 3153 3228 2886 \nQ 3006 2619 2597 2516 \nz\n\" id=\"DejaVuSans-33\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-33\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_7\">\n     <g id=\"line2d_13\">\n      <path clip-path=\"url(#p05bfa37ed2)\" d=\"M 256.4875 228.439219 \nL 256.4875 10.999219 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_14\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"256.4875\" xlink:href=\"#m8b84ce31a4\" y=\"228.439219\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 350 -->\n      <g transform=\"translate(246.94375 243.037656)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-33\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-35\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_8\">\n     <g id=\"line2d_15\">\n      <path clip-path=\"url(#p05bfa37ed2)\" d=\"M 293.6875 228.439219 \nL 293.6875 10.999219 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_16\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"293.6875\" xlink:href=\"#m8b84ce31a4\" y=\"228.439219\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 400 -->\n      <g transform=\"translate(284.14375 243.037656)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 2419 4116 \nL 825 1625 \nL 2419 1625 \nL 2419 4116 \nz\nM 2253 4666 \nL 3047 4666 \nL 3047 1625 \nL 3713 1625 \nL 3713 1100 \nL 3047 1100 \nL 3047 0 \nL 2419 0 \nL 2419 1100 \nL 313 1100 \nL 313 1709 \nL 2253 4666 \nz\n\" id=\"DejaVuSans-34\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-34\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_9\">\n     <g id=\"line2d_17\">\n      <path clip-path=\"url(#p05bfa37ed2)\" d=\"M 330.8875 228.439219 \nL 330.8875 10.999219 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_18\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"330.8875\" xlink:href=\"#m8b84ce31a4\" y=\"228.439219\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 450 -->\n      <g transform=\"translate(321.34375 243.037656)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-34\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-35\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_10\">\n     <g id=\"line2d_19\">\n      <path clip-path=\"url(#p05bfa37ed2)\" d=\"M 368.0875 228.439219 \nL 368.0875 10.999219 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_20\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"368.0875\" xlink:href=\"#m8b84ce31a4\" y=\"228.439219\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 500 -->\n      <g transform=\"translate(358.54375 243.037656)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-35\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_21\">\n      <path clip-path=\"url(#p05bfa37ed2)\" d=\"M 33.2875 228.439219 \nL 368.0875 228.439219 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_22\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"m042783d635\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#m042783d635\" y=\"228.439219\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 40 -->\n      <g transform=\"translate(13.5625 232.238438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-34\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_23\">\n      <path clip-path=\"url(#p05bfa37ed2)\" d=\"M 33.2875 192.199219 \nL 368.0875 192.199219 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_24\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#m042783d635\" y=\"192.199219\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 50 -->\n      <g transform=\"translate(13.5625 195.998438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-35\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_25\">\n      <path clip-path=\"url(#p05bfa37ed2)\" d=\"M 33.2875 155.959219 \nL 368.0875 155.959219 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_26\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#m042783d635\" y=\"155.959219\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 60 -->\n      <g transform=\"translate(13.5625 159.758438)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 2113 2584 \nQ 1688 2584 1439 2293 \nQ 1191 2003 1191 1497 \nQ 1191 994 1439 701 \nQ 1688 409 2113 409 \nQ 2538 409 2786 701 \nQ 3034 994 3034 1497 \nQ 3034 2003 2786 2293 \nQ 2538 2584 2113 2584 \nz\nM 3366 4563 \nL 3366 3988 \nQ 3128 4100 2886 4159 \nQ 2644 4219 2406 4219 \nQ 1781 4219 1451 3797 \nQ 1122 3375 1075 2522 \nQ 1259 2794 1537 2939 \nQ 1816 3084 2150 3084 \nQ 2853 3084 3261 2657 \nQ 3669 2231 3669 1497 \nQ 3669 778 3244 343 \nQ 2819 -91 2113 -91 \nQ 1303 -91 875 529 \nQ 447 1150 447 2328 \nQ 447 3434 972 4092 \nQ 1497 4750 2381 4750 \nQ 2619 4750 2861 4703 \nQ 3103 4656 3366 4563 \nz\n\" id=\"DejaVuSans-36\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-36\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_27\">\n      <path clip-path=\"url(#p05bfa37ed2)\" d=\"M 33.2875 119.719219 \nL 368.0875 119.719219 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_28\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#m042783d635\" y=\"119.719219\"/>\n      </g>\n     </g>\n     <g id=\"text_14\">\n      <!-- 70 -->\n      <g transform=\"translate(13.5625 123.518438)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 525 4666 \nL 3525 4666 \nL 3525 4397 \nL 1831 0 \nL 1172 0 \nL 2766 4134 \nL 525 4134 \nL 525 4666 \nz\n\" id=\"DejaVuSans-37\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-37\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_29\">\n      <path clip-path=\"url(#p05bfa37ed2)\" d=\"M 33.2875 83.479219 \nL 368.0875 83.479219 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_30\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#m042783d635\" y=\"83.479219\"/>\n      </g>\n     </g>\n     <g id=\"text_15\">\n      <!-- 80 -->\n      <g transform=\"translate(13.5625 87.278438)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 2034 2216 \nQ 1584 2216 1326 1975 \nQ 1069 1734 1069 1313 \nQ 1069 891 1326 650 \nQ 1584 409 2034 409 \nQ 2484 409 2743 651 \nQ 3003 894 3003 1313 \nQ 3003 1734 2745 1975 \nQ 2488 2216 2034 2216 \nz\nM 1403 2484 \nQ 997 2584 770 2862 \nQ 544 3141 544 3541 \nQ 544 4100 942 4425 \nQ 1341 4750 2034 4750 \nQ 2731 4750 3128 4425 \nQ 3525 4100 3525 3541 \nQ 3525 3141 3298 2862 \nQ 3072 2584 2669 2484 \nQ 3125 2378 3379 2068 \nQ 3634 1759 3634 1313 \nQ 3634 634 3220 271 \nQ 2806 -91 2034 -91 \nQ 1263 -91 848 271 \nQ 434 634 434 1313 \nQ 434 1759 690 2068 \nQ 947 2378 1403 2484 \nz\nM 1172 3481 \nQ 1172 3119 1398 2916 \nQ 1625 2713 2034 2713 \nQ 2441 2713 2670 2916 \nQ 2900 3119 2900 3481 \nQ 2900 3844 2670 4047 \nQ 2441 4250 2034 4250 \nQ 1625 4250 1398 4047 \nQ 1172 3844 1172 3481 \nz\n\" id=\"DejaVuSans-38\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-38\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_31\">\n      <path clip-path=\"url(#p05bfa37ed2)\" d=\"M 33.2875 47.239219 \nL 368.0875 47.239219 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_32\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#m042783d635\" y=\"47.239219\"/>\n      </g>\n     </g>\n     <g id=\"text_16\">\n      <!-- 90 -->\n      <g transform=\"translate(13.5625 51.038438)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 703 97 \nL 703 672 \nQ 941 559 1184 500 \nQ 1428 441 1663 441 \nQ 2288 441 2617 861 \nQ 2947 1281 2994 2138 \nQ 2813 1869 2534 1725 \nQ 2256 1581 1919 1581 \nQ 1219 1581 811 2004 \nQ 403 2428 403 3163 \nQ 403 3881 828 4315 \nQ 1253 4750 1959 4750 \nQ 2769 4750 3195 4129 \nQ 3622 3509 3622 2328 \nQ 3622 1225 3098 567 \nQ 2575 -91 1691 -91 \nQ 1453 -91 1209 -44 \nQ 966 3 703 97 \nz\nM 1959 2075 \nQ 2384 2075 2632 2365 \nQ 2881 2656 2881 3163 \nQ 2881 3666 2632 3958 \nQ 2384 4250 1959 4250 \nQ 1534 4250 1286 3958 \nQ 1038 3666 1038 3163 \nQ 1038 2656 1286 2365 \nQ 1534 2075 1959 2075 \nz\n\" id=\"DejaVuSans-39\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-39\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_7\">\n     <g id=\"line2d_33\">\n      <path clip-path=\"url(#p05bfa37ed2)\" d=\"M 33.2875 10.999219 \nL 368.0875 10.999219 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_34\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#m042783d635\" y=\"10.999219\"/>\n      </g>\n     </g>\n     <g id=\"text_17\">\n      <!-- 100 -->\n      <g transform=\"translate(7.2 14.798438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_35\">\n    <path clip-path=\"url(#p05bfa37ed2)\" d=\"M -1 58.111219 \nL 368.0875 58.111219 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_36\">\n    <path clip-path=\"url(#p05bfa37ed2)\" d=\"M 182.0875 89.491385 \nL 368.0875 83.646223 \n\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_37\">\n    <path clip-path=\"url(#p05bfa37ed2)\" d=\"M 89.0875 110.366961 \nL 182.0875 110.366961 \nL 275.0875 97.841615 \nL 368.0875 97.006592 \n\" style=\"fill:none;stroke:#2ca02c;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_38\">\n    <path clip-path=\"url(#p05bfa37ed2)\" d=\"M 33.2875 122.057283 \nL 70.4875 95.336546 \nL 107.6875 89.491385 \nL 144.8875 88.656362 \nL 182.0875 87.821339 \nL 219.2875 83.646223 \nL 256.4875 86.151292 \nL 293.6875 86.986316 \nL 330.8875 86.986316 \nL 368.0875 87.821339 \n\" style=\"fill:none;stroke:#d62728;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_39\">\n    <path clip-path=\"url(#p05bfa37ed2)\" d=\"M 14.6875 111.201984 \nL 33.2875 112.037007 \nL 51.8875 112.87203 \nL 70.4875 108.696915 \nL 89.0875 109.531938 \nL 107.6875 101.181707 \nL 126.2875 107.026869 \nL 144.8875 97.841615 \nL 163.4875 97.006592 \nL 182.0875 96.171569 \nL 200.6875 95.336546 \nL 219.2875 93.6665 \nL 237.8875 95.336546 \nL 256.4875 90.326408 \nL 275.0875 89.491385 \nL 293.6875 91.996454 \nL 312.2875 84.481246 \nL 330.8875 83.646223 \nL 349.4875 82.8112 \nL 368.0875 80.306131 \n\" style=\"fill:none;stroke:#9467bd;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_40\">\n    <path clip-path=\"url(#p05bfa37ed2)\" d=\"M 3.5275 143.767882 \nL 10.9675 117.047145 \nL 18.4075 151.28309 \nL 25.8475 142.932859 \nL 33.2875 102.851753 \nL 40.7275 98.676638 \nL 48.1675 96.171569 \nL 55.6075 96.171569 \nL 63.0475 92.831477 \nL 70.4875 95.336546 \nL 77.9275 89.491385 \nL 85.3675 87.821339 \nL 92.8075 92.831477 \nL 100.2475 85.316269 \nL 107.6875 91.996454 \nL 115.1275 94.501523 \nL 122.5675 93.6665 \nL 130.0075 94.501523 \nL 137.4475 91.996454 \nL 144.8875 90.326408 \nL 152.3275 90.326408 \nL 159.7675 91.996454 \nL 167.2075 91.996454 \nL 174.6475 89.491385 \nL 182.0875 88.656362 \nL 189.5275 91.996454 \nL 196.9675 91.996454 \nL 204.4075 92.831477 \nL 211.8475 91.161431 \nL 219.2875 91.161431 \nL 226.7275 91.161431 \nL 234.1675 90.326408 \nL 241.6075 91.996454 \nL 249.0475 89.491385 \nL 256.4875 87.821339 \nL 263.9275 86.151292 \nL 271.3675 88.656362 \nL 278.8075 91.161431 \nL 286.2475 91.996454 \nL 293.6875 91.996454 \nL 301.1275 90.326408 \nL 308.5675 84.481246 \nL 316.0075 84.481246 \nL 323.4475 85.316269 \nL 330.8875 86.986316 \nL 338.3275 84.481246 \nL 345.7675 87.821339 \nL 353.2075 88.656362 \nL 360.6475 85.316269 \nL 368.0875 86.151292 \n\" style=\"fill:none;stroke:#8c564b;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_41\">\n    <path clip-path=\"url(#p05bfa37ed2)\" d=\"M 182.0875 97.006592 \nL 368.0875 86.151292 \n\" style=\"fill:none;stroke:#e377c2;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_42\">\n    <path clip-path=\"url(#p05bfa37ed2)\" d=\"M 89.0875 94.501523 \nL 182.0875 87.821339 \nL 275.0875 86.986316 \nL 368.0875 79.471108 \n\" style=\"fill:none;stroke:#7f7f7f;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_43\">\n    <path clip-path=\"url(#p05bfa37ed2)\" d=\"M 33.2875 90.326408 \nL 70.4875 90.326408 \nL 107.6875 88.656362 \nL 144.8875 88.656362 \nL 182.0875 81.976177 \nL 219.2875 82.8112 \nL 256.4875 83.646223 \nL 293.6875 84.481246 \nL 330.8875 85.316269 \nL 368.0875 87.821339 \n\" style=\"fill:none;stroke:#bcbd22;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_44\">\n    <path clip-path=\"url(#p05bfa37ed2)\" d=\"M 14.6875 102.851753 \nL 33.2875 120.387237 \nL 51.8875 82.8112 \nL 70.4875 112.037007 \nL 89.0875 109.531938 \nL 107.6875 106.191845 \nL 126.2875 107.026869 \nL 144.8875 88.656362 \nL 163.4875 88.656362 \nL 182.0875 79.471108 \nL 200.6875 81.141154 \nL 219.2875 87.821339 \nL 237.8875 86.151292 \nL 256.4875 82.8112 \nL 275.0875 84.481246 \nL 293.6875 86.151292 \nL 312.2875 83.646223 \nL 330.8875 84.481246 \nL 349.4875 83.646223 \nL 368.0875 84.481246 \n\" style=\"fill:none;stroke:#17becf;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_45\">\n    <path clip-path=\"url(#p05bfa37ed2)\" d=\"M 3.5275 195.539311 \nL 10.9675 144.602905 \nL 18.4075 110.366961 \nL 25.8475 123.727329 \nL 33.2875 110.366961 \nL 40.7275 97.841615 \nL 48.1675 100.346684 \nL 55.6075 104.521799 \nL 63.0475 102.851753 \nL 70.4875 106.191845 \nL 77.9275 101.181707 \nL 85.3675 117.882168 \nL 92.8075 99.511661 \nL 100.2475 100.346684 \nL 107.6875 101.181707 \nL 115.1275 98.676638 \nL 122.5675 95.336546 \nL 130.0075 96.171569 \nL 137.4475 92.831477 \nL 144.8875 93.6665 \nL 152.3275 92.831477 \nL 159.7675 94.501523 \nL 167.2075 87.821339 \nL 174.6475 89.491385 \nL 182.0875 88.656362 \nL 189.5275 84.481246 \nL 196.9675 84.481246 \nL 204.4075 86.151292 \nL 211.8475 85.316269 \nL 219.2875 85.316269 \nL 226.7275 86.151292 \nL 234.1675 88.656362 \nL 241.6075 86.986316 \nL 249.0475 85.316269 \nL 256.4875 83.646223 \nL 263.9275 83.646223 \nL 271.3675 82.8112 \nL 278.8075 83.646223 \nL 286.2475 81.141154 \nL 293.6875 85.316269 \nL 301.1275 88.656362 \nL 308.5675 87.821339 \nL 316.0075 88.656362 \nL 323.4475 86.986316 \nL 330.8875 86.151292 \nL 338.3275 88.656362 \nL 345.7675 86.151292 \nL 353.2075 87.821339 \nL 360.6475 86.151292 \nL 368.0875 85.316269 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_46\">\n    <path clip-path=\"url(#p05bfa37ed2)\" d=\"M 182.0875 88.656362 \nL 368.0875 81.976177 \n\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_47\">\n    <path clip-path=\"url(#p05bfa37ed2)\" d=\"M 89.0875 92.831477 \nL 182.0875 86.986316 \nL 275.0875 81.141154 \nL 368.0875 82.8112 \n\" style=\"fill:none;stroke:#2ca02c;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_48\">\n    <path clip-path=\"url(#p05bfa37ed2)\" d=\"M 33.2875 100.346684 \nL 70.4875 81.141154 \nL 107.6875 83.646223 \nL 144.8875 86.986316 \nL 182.0875 81.141154 \nL 219.2875 82.8112 \nL 256.4875 83.646223 \nL 293.6875 85.316269 \nL 330.8875 84.481246 \nL 368.0875 85.316269 \n\" style=\"fill:none;stroke:#d62728;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_49\">\n    <path clip-path=\"url(#p05bfa37ed2)\" d=\"M 14.6875 119.552214 \nL 33.2875 96.171569 \nL 51.8875 86.986316 \nL 70.4875 88.656362 \nL 89.0875 91.996454 \nL 107.6875 87.821339 \nL 126.2875 87.821339 \nL 144.8875 92.831477 \nL 163.4875 91.161431 \nL 182.0875 91.996454 \nL 200.6875 86.986316 \nL 219.2875 91.161431 \nL 237.8875 87.821339 \nL 256.4875 87.821339 \nL 275.0875 86.151292 \nL 293.6875 84.481246 \nL 312.2875 86.986316 \nL 330.8875 84.481246 \nL 349.4875 81.976177 \nL 368.0875 80.306131 \n\" style=\"fill:none;stroke:#9467bd;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_50\">\n    <path clip-path=\"url(#p05bfa37ed2)\" d=\"M 3.5275 137.087698 \nL 10.9675 94.501523 \nL 18.4075 101.181707 \nL 25.8475 119.552214 \nL 33.2875 111.201984 \nL 40.7275 114.542076 \nL 48.1675 92.831477 \nL 55.6075 97.006592 \nL 63.0475 92.831477 \nL 70.4875 91.161431 \nL 77.9275 88.656362 \nL 85.3675 105.356822 \nL 92.8075 85.316269 \nL 100.2475 86.986316 \nL 107.6875 85.316269 \nL 115.1275 86.151292 \nL 122.5675 89.491385 \nL 130.0075 88.656362 \nL 137.4475 86.986316 \nL 144.8875 82.8112 \nL 152.3275 83.646223 \nL 159.7675 82.8112 \nL 167.2075 87.821339 \nL 174.6475 85.316269 \nL 182.0875 84.481246 \nL 189.5275 82.8112 \nL 196.9675 83.646223 \nL 204.4075 77.801062 \nL 211.8475 76.966039 \nL 219.2875 77.801062 \nL 226.7275 78.636085 \nL 234.1675 81.141154 \nL 241.6075 81.976177 \nL 249.0475 79.471108 \nL 256.4875 85.316269 \nL 263.9275 81.141154 \nL 271.3675 80.306131 \nL 278.8075 80.306131 \nL 286.2475 85.316269 \nL 293.6875 82.8112 \nL 301.1275 84.481246 \nL 308.5675 83.646223 \nL 316.0075 87.821339 \nL 323.4475 84.481246 \nL 330.8875 85.316269 \nL 338.3275 81.976177 \nL 345.7675 85.316269 \nL 353.2075 81.976177 \nL 360.6475 84.481246 \nL 368.0875 83.646223 \n\" style=\"fill:none;stroke:#8c564b;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_51\">\n    <path clip-path=\"url(#p05bfa37ed2)\" d=\"M 182.0875 101.181707 \nL 368.0875 86.151292 \n\" style=\"fill:none;stroke:#e377c2;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_52\">\n    <path clip-path=\"url(#p05bfa37ed2)\" d=\"M 89.0875 89.491385 \nL 182.0875 97.841615 \nL 275.0875 82.8112 \nL 368.0875 84.481246 \n\" style=\"fill:none;stroke:#7f7f7f;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_53\">\n    <path clip-path=\"url(#p05bfa37ed2)\" d=\"M 33.2875 83.646223 \nL 70.4875 94.501523 \nL 107.6875 82.8112 \nL 144.8875 85.316269 \nL 182.0875 86.151292 \nL 219.2875 84.481246 \nL 256.4875 83.646223 \nL 293.6875 84.481246 \nL 330.8875 84.481246 \nL 368.0875 84.481246 \n\" style=\"fill:none;stroke:#bcbd22;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_54\">\n    <path clip-path=\"url(#p05bfa37ed2)\" d=\"M 14.6875 91.996454 \nL 33.2875 91.161431 \nL 51.8875 108.696915 \nL 70.4875 104.521799 \nL 89.0875 81.141154 \nL 107.6875 82.8112 \nL 126.2875 84.481246 \nL 144.8875 80.306131 \nL 163.4875 78.636085 \nL 182.0875 80.306131 \nL 200.6875 85.316269 \nL 219.2875 82.8112 \nL 237.8875 80.306131 \nL 256.4875 80.306131 \nL 275.0875 80.306131 \nL 293.6875 80.306131 \nL 312.2875 78.636085 \nL 330.8875 78.636085 \nL 349.4875 82.8112 \nL 368.0875 81.976177 \n\" style=\"fill:none;stroke:#17becf;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_55\">\n    <path clip-path=\"url(#p05bfa37ed2)\" d=\"M 3.5275 106.191845 \nL 10.9675 93.6665 \nL 18.4075 93.6665 \nL 25.8475 95.336546 \nL 33.2875 115.377099 \nL 40.7275 96.171569 \nL 48.1675 91.161431 \nL 55.6075 90.326408 \nL 63.0475 91.161431 \nL 70.4875 91.161431 \nL 77.9275 86.986316 \nL 85.3675 86.986316 \nL 92.8075 84.481246 \nL 100.2475 88.656362 \nL 107.6875 86.151292 \nL 115.1275 86.151292 \nL 122.5675 100.346684 \nL 130.0075 107.026869 \nL 137.4475 103.686776 \nL 144.8875 105.356822 \nL 152.3275 104.521799 \nL 159.7675 105.356822 \nL 167.2075 104.521799 \nL 174.6475 103.686776 \nL 182.0875 98.676638 \nL 189.5275 98.676638 \nL 196.9675 102.01673 \nL 204.4075 102.851753 \nL 211.8475 102.851753 \nL 219.2875 100.346684 \nL 226.7275 98.676638 \nL 234.1675 80.306131 \nL 241.6075 82.8112 \nL 249.0475 81.141154 \nL 256.4875 80.306131 \nL 263.9275 79.471108 \nL 271.3675 77.801062 \nL 278.8075 77.801062 \nL 286.2475 79.471108 \nL 293.6875 78.636085 \nL 301.1275 77.801062 \nL 308.5675 73.625947 \nL 316.0075 75.295993 \nL 323.4475 75.295993 \nL 330.8875 76.966039 \nL 338.3275 81.976177 \nL 345.7675 80.306131 \nL 353.2075 79.471108 \nL 360.6475 80.306131 \nL 368.0875 78.636085 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 33.2875 228.439219 \nL 33.2875 10.999219 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 368.0875 228.439219 \nL 368.0875 10.999219 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 33.2875 228.439219 \nL 368.0875 228.439219 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 33.2875 10.999219 \nL 368.0875 10.999219 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"legend_1\">\n    <g id=\"patch_7\">\n     <path d=\"M 116.590625 327.239844 \nL 361.0875 327.239844 \nQ 363.0875 327.239844 363.0875 325.239844 \nL 363.0875 17.999219 \nQ 363.0875 15.999219 361.0875 15.999219 \nL 116.590625 15.999219 \nQ 114.590625 15.999219 114.590625 17.999219 \nL 114.590625 325.239844 \nQ 114.590625 327.239844 116.590625 327.239844 \nz\n\" style=\"fill:#ffffff;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\n    </g>\n    <g id=\"line2d_56\">\n     <path d=\"M 118.590625 24.097656 \nL 138.590625 24.097656 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_57\"/>\n    <g id=\"text_18\">\n     <!-- algorithm-upper-bound -->\n     <g transform=\"translate(146.590625 27.597656)scale(0.1 -0.1)\">\n      <defs>\n       <path d=\"M 2194 1759 \nQ 1497 1759 1228 1600 \nQ 959 1441 959 1056 \nQ 959 750 1161 570 \nQ 1363 391 1709 391 \nQ 2188 391 2477 730 \nQ 2766 1069 2766 1631 \nL 2766 1759 \nL 2194 1759 \nz\nM 3341 1997 \nL 3341 0 \nL 2766 0 \nL 2766 531 \nQ 2569 213 2275 61 \nQ 1981 -91 1556 -91 \nQ 1019 -91 701 211 \nQ 384 513 384 1019 \nQ 384 1609 779 1909 \nQ 1175 2209 1959 2209 \nL 2766 2209 \nL 2766 2266 \nQ 2766 2663 2505 2880 \nQ 2244 3097 1772 3097 \nQ 1472 3097 1187 3025 \nQ 903 2953 641 2809 \nL 641 3341 \nQ 956 3463 1253 3523 \nQ 1550 3584 1831 3584 \nQ 2591 3584 2966 3190 \nQ 3341 2797 3341 1997 \nz\n\" id=\"DejaVuSans-61\" transform=\"scale(0.015625)\"/>\n       <path d=\"M 603 4863 \nL 1178 4863 \nL 1178 0 \nL 603 0 \nL 603 4863 \nz\n\" id=\"DejaVuSans-6c\" transform=\"scale(0.015625)\"/>\n       <path d=\"M 2906 1791 \nQ 2906 2416 2648 2759 \nQ 2391 3103 1925 3103 \nQ 1463 3103 1205 2759 \nQ 947 2416 947 1791 \nQ 947 1169 1205 825 \nQ 1463 481 1925 481 \nQ 2391 481 2648 825 \nQ 2906 1169 2906 1791 \nz\nM 3481 434 \nQ 3481 -459 3084 -895 \nQ 2688 -1331 1869 -1331 \nQ 1566 -1331 1297 -1286 \nQ 1028 -1241 775 -1147 \nL 775 -588 \nQ 1028 -725 1275 -790 \nQ 1522 -856 1778 -856 \nQ 2344 -856 2625 -561 \nQ 2906 -266 2906 331 \nL 2906 616 \nQ 2728 306 2450 153 \nQ 2172 0 1784 0 \nQ 1141 0 747 490 \nQ 353 981 353 1791 \nQ 353 2603 747 3093 \nQ 1141 3584 1784 3584 \nQ 2172 3584 2450 3431 \nQ 2728 3278 2906 2969 \nL 2906 3500 \nL 3481 3500 \nL 3481 434 \nz\n\" id=\"DejaVuSans-67\" transform=\"scale(0.015625)\"/>\n       <path d=\"M 1959 3097 \nQ 1497 3097 1228 2736 \nQ 959 2375 959 1747 \nQ 959 1119 1226 758 \nQ 1494 397 1959 397 \nQ 2419 397 2687 759 \nQ 2956 1122 2956 1747 \nQ 2956 2369 2687 2733 \nQ 2419 3097 1959 3097 \nz\nM 1959 3584 \nQ 2709 3584 3137 3096 \nQ 3566 2609 3566 1747 \nQ 3566 888 3137 398 \nQ 2709 -91 1959 -91 \nQ 1206 -91 779 398 \nQ 353 888 353 1747 \nQ 353 2609 779 3096 \nQ 1206 3584 1959 3584 \nz\n\" id=\"DejaVuSans-6f\" transform=\"scale(0.015625)\"/>\n       <path d=\"M 2631 2963 \nQ 2534 3019 2420 3045 \nQ 2306 3072 2169 3072 \nQ 1681 3072 1420 2755 \nQ 1159 2438 1159 1844 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1341 3275 1631 3429 \nQ 1922 3584 2338 3584 \nQ 2397 3584 2469 3576 \nQ 2541 3569 2628 3553 \nL 2631 2963 \nz\n\" id=\"DejaVuSans-72\" transform=\"scale(0.015625)\"/>\n       <path d=\"M 603 3500 \nL 1178 3500 \nL 1178 0 \nL 603 0 \nL 603 3500 \nz\nM 603 4863 \nL 1178 4863 \nL 1178 4134 \nL 603 4134 \nL 603 4863 \nz\n\" id=\"DejaVuSans-69\" transform=\"scale(0.015625)\"/>\n       <path d=\"M 1172 4494 \nL 1172 3500 \nL 2356 3500 \nL 2356 3053 \nL 1172 3053 \nL 1172 1153 \nQ 1172 725 1289 603 \nQ 1406 481 1766 481 \nL 2356 481 \nL 2356 0 \nL 1766 0 \nQ 1100 0 847 248 \nQ 594 497 594 1153 \nL 594 3053 \nL 172 3053 \nL 172 3500 \nL 594 3500 \nL 594 4494 \nL 1172 4494 \nz\n\" id=\"DejaVuSans-74\" transform=\"scale(0.015625)\"/>\n       <path d=\"M 3513 2113 \nL 3513 0 \nL 2938 0 \nL 2938 2094 \nQ 2938 2591 2744 2837 \nQ 2550 3084 2163 3084 \nQ 1697 3084 1428 2787 \nQ 1159 2491 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 4863 \nL 1159 4863 \nL 1159 2956 \nQ 1366 3272 1645 3428 \nQ 1925 3584 2291 3584 \nQ 2894 3584 3203 3211 \nQ 3513 2838 3513 2113 \nz\n\" id=\"DejaVuSans-68\" transform=\"scale(0.015625)\"/>\n       <path d=\"M 3328 2828 \nQ 3544 3216 3844 3400 \nQ 4144 3584 4550 3584 \nQ 5097 3584 5394 3201 \nQ 5691 2819 5691 2113 \nL 5691 0 \nL 5113 0 \nL 5113 2094 \nQ 5113 2597 4934 2840 \nQ 4756 3084 4391 3084 \nQ 3944 3084 3684 2787 \nQ 3425 2491 3425 1978 \nL 3425 0 \nL 2847 0 \nL 2847 2094 \nQ 2847 2600 2669 2842 \nQ 2491 3084 2119 3084 \nQ 1678 3084 1418 2786 \nQ 1159 2488 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1356 3278 1631 3431 \nQ 1906 3584 2284 3584 \nQ 2666 3584 2933 3390 \nQ 3200 3197 3328 2828 \nz\n\" id=\"DejaVuSans-6d\" transform=\"scale(0.015625)\"/>\n       <path d=\"M 313 2009 \nL 1997 2009 \nL 1997 1497 \nL 313 1497 \nL 313 2009 \nz\n\" id=\"DejaVuSans-2d\" transform=\"scale(0.015625)\"/>\n       <path d=\"M 544 1381 \nL 544 3500 \nL 1119 3500 \nL 1119 1403 \nQ 1119 906 1312 657 \nQ 1506 409 1894 409 \nQ 2359 409 2629 706 \nQ 2900 1003 2900 1516 \nL 2900 3500 \nL 3475 3500 \nL 3475 0 \nL 2900 0 \nL 2900 538 \nQ 2691 219 2414 64 \nQ 2138 -91 1772 -91 \nQ 1169 -91 856 284 \nQ 544 659 544 1381 \nz\nM 1991 3584 \nL 1991 3584 \nz\n\" id=\"DejaVuSans-75\" transform=\"scale(0.015625)\"/>\n       <path d=\"M 1159 525 \nL 1159 -1331 \nL 581 -1331 \nL 581 3500 \nL 1159 3500 \nL 1159 2969 \nQ 1341 3281 1617 3432 \nQ 1894 3584 2278 3584 \nQ 2916 3584 3314 3078 \nQ 3713 2572 3713 1747 \nQ 3713 922 3314 415 \nQ 2916 -91 2278 -91 \nQ 1894 -91 1617 61 \nQ 1341 213 1159 525 \nz\nM 3116 1747 \nQ 3116 2381 2855 2742 \nQ 2594 3103 2138 3103 \nQ 1681 3103 1420 2742 \nQ 1159 2381 1159 1747 \nQ 1159 1113 1420 752 \nQ 1681 391 2138 391 \nQ 2594 391 2855 752 \nQ 3116 1113 3116 1747 \nz\n\" id=\"DejaVuSans-70\" transform=\"scale(0.015625)\"/>\n       <path d=\"M 3597 1894 \nL 3597 1613 \nL 953 1613 \nQ 991 1019 1311 708 \nQ 1631 397 2203 397 \nQ 2534 397 2845 478 \nQ 3156 559 3463 722 \nL 3463 178 \nQ 3153 47 2828 -22 \nQ 2503 -91 2169 -91 \nQ 1331 -91 842 396 \nQ 353 884 353 1716 \nQ 353 2575 817 3079 \nQ 1281 3584 2069 3584 \nQ 2775 3584 3186 3129 \nQ 3597 2675 3597 1894 \nz\nM 3022 2063 \nQ 3016 2534 2758 2815 \nQ 2500 3097 2075 3097 \nQ 1594 3097 1305 2825 \nQ 1016 2553 972 2059 \nL 3022 2063 \nz\n\" id=\"DejaVuSans-65\" transform=\"scale(0.015625)\"/>\n       <path d=\"M 3116 1747 \nQ 3116 2381 2855 2742 \nQ 2594 3103 2138 3103 \nQ 1681 3103 1420 2742 \nQ 1159 2381 1159 1747 \nQ 1159 1113 1420 752 \nQ 1681 391 2138 391 \nQ 2594 391 2855 752 \nQ 3116 1113 3116 1747 \nz\nM 1159 2969 \nQ 1341 3281 1617 3432 \nQ 1894 3584 2278 3584 \nQ 2916 3584 3314 3078 \nQ 3713 2572 3713 1747 \nQ 3713 922 3314 415 \nQ 2916 -91 2278 -91 \nQ 1894 -91 1617 61 \nQ 1341 213 1159 525 \nL 1159 0 \nL 581 0 \nL 581 4863 \nL 1159 4863 \nL 1159 2969 \nz\n\" id=\"DejaVuSans-62\" transform=\"scale(0.015625)\"/>\n       <path d=\"M 3513 2113 \nL 3513 0 \nL 2938 0 \nL 2938 2094 \nQ 2938 2591 2744 2837 \nQ 2550 3084 2163 3084 \nQ 1697 3084 1428 2787 \nQ 1159 2491 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1366 3272 1645 3428 \nQ 1925 3584 2291 3584 \nQ 2894 3584 3203 3211 \nQ 3513 2838 3513 2113 \nz\n\" id=\"DejaVuSans-6e\" transform=\"scale(0.015625)\"/>\n       <path d=\"M 2906 2969 \nL 2906 4863 \nL 3481 4863 \nL 3481 0 \nL 2906 0 \nL 2906 525 \nQ 2725 213 2448 61 \nQ 2172 -91 1784 -91 \nQ 1150 -91 751 415 \nQ 353 922 353 1747 \nQ 353 2572 751 3078 \nQ 1150 3584 1784 3584 \nQ 2172 3584 2448 3432 \nQ 2725 3281 2906 2969 \nz\nM 947 1747 \nQ 947 1113 1208 752 \nQ 1469 391 1925 391 \nQ 2381 391 2643 752 \nQ 2906 1113 2906 1747 \nQ 2906 2381 2643 2742 \nQ 2381 3103 1925 3103 \nQ 1469 3103 1208 2742 \nQ 947 2381 947 1747 \nz\n\" id=\"DejaVuSans-64\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-61\"/>\n      <use x=\"61.279297\" xlink:href=\"#DejaVuSans-6c\"/>\n      <use x=\"89.0625\" xlink:href=\"#DejaVuSans-67\"/>\n      <use x=\"152.539062\" xlink:href=\"#DejaVuSans-6f\"/>\n      <use x=\"213.720703\" xlink:href=\"#DejaVuSans-72\"/>\n      <use x=\"254.833984\" xlink:href=\"#DejaVuSans-69\"/>\n      <use x=\"282.617188\" xlink:href=\"#DejaVuSans-74\"/>\n      <use x=\"321.826172\" xlink:href=\"#DejaVuSans-68\"/>\n      <use x=\"385.205078\" xlink:href=\"#DejaVuSans-6d\"/>\n      <use x=\"482.617188\" xlink:href=\"#DejaVuSans-2d\"/>\n      <use x=\"518.701172\" xlink:href=\"#DejaVuSans-75\"/>\n      <use x=\"582.080078\" xlink:href=\"#DejaVuSans-70\"/>\n      <use x=\"645.556641\" xlink:href=\"#DejaVuSans-70\"/>\n      <use x=\"709.033203\" xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"770.556641\" xlink:href=\"#DejaVuSans-72\"/>\n      <use x=\"805.294922\" xlink:href=\"#DejaVuSans-2d\"/>\n      <use x=\"841.378906\" xlink:href=\"#DejaVuSans-62\"/>\n      <use x=\"904.855469\" xlink:href=\"#DejaVuSans-6f\"/>\n      <use x=\"966.037109\" xlink:href=\"#DejaVuSans-75\"/>\n      <use x=\"1029.416016\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"1092.794922\" xlink:href=\"#DejaVuSans-64\"/>\n     </g>\n    </g>\n    <g id=\"line2d_58\">\n     <path d=\"M 118.590625 38.775781 \nL 138.590625 38.775781 \n\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_59\"/>\n    <g id=\"text_19\">\n     <!-- GDBCModel-RandomSelection-250 -->\n     <g transform=\"translate(146.590625 42.275781)scale(0.1 -0.1)\">\n      <defs>\n       <path d=\"M 3809 666 \nL 3809 1919 \nL 2778 1919 \nL 2778 2438 \nL 4434 2438 \nL 4434 434 \nQ 4069 175 3628 42 \nQ 3188 -91 2688 -91 \nQ 1594 -91 976 548 \nQ 359 1188 359 2328 \nQ 359 3472 976 4111 \nQ 1594 4750 2688 4750 \nQ 3144 4750 3555 4637 \nQ 3966 4525 4313 4306 \nL 4313 3634 \nQ 3963 3931 3569 4081 \nQ 3175 4231 2741 4231 \nQ 1884 4231 1454 3753 \nQ 1025 3275 1025 2328 \nQ 1025 1384 1454 906 \nQ 1884 428 2741 428 \nQ 3075 428 3337 486 \nQ 3600 544 3809 666 \nz\n\" id=\"DejaVuSans-47\" transform=\"scale(0.015625)\"/>\n       <path d=\"M 1259 4147 \nL 1259 519 \nL 2022 519 \nQ 2988 519 3436 956 \nQ 3884 1394 3884 2338 \nQ 3884 3275 3436 3711 \nQ 2988 4147 2022 4147 \nL 1259 4147 \nz\nM 628 4666 \nL 1925 4666 \nQ 3281 4666 3915 4102 \nQ 4550 3538 4550 2338 \nQ 4550 1131 3912 565 \nQ 3275 0 1925 0 \nL 628 0 \nL 628 4666 \nz\n\" id=\"DejaVuSans-44\" transform=\"scale(0.015625)\"/>\n       <path d=\"M 1259 2228 \nL 1259 519 \nL 2272 519 \nQ 2781 519 3026 730 \nQ 3272 941 3272 1375 \nQ 3272 1813 3026 2020 \nQ 2781 2228 2272 2228 \nL 1259 2228 \nz\nM 1259 4147 \nL 1259 2741 \nL 2194 2741 \nQ 2656 2741 2882 2914 \nQ 3109 3088 3109 3444 \nQ 3109 3797 2882 3972 \nQ 2656 4147 2194 4147 \nL 1259 4147 \nz\nM 628 4666 \nL 2241 4666 \nQ 2963 4666 3353 4366 \nQ 3744 4066 3744 3513 \nQ 3744 3084 3544 2831 \nQ 3344 2578 2956 2516 \nQ 3422 2416 3680 2098 \nQ 3938 1781 3938 1306 \nQ 3938 681 3513 340 \nQ 3088 0 2303 0 \nL 628 0 \nL 628 4666 \nz\n\" id=\"DejaVuSans-42\" transform=\"scale(0.015625)\"/>\n       <path d=\"M 4122 4306 \nL 4122 3641 \nQ 3803 3938 3442 4084 \nQ 3081 4231 2675 4231 \nQ 1875 4231 1450 3742 \nQ 1025 3253 1025 2328 \nQ 1025 1406 1450 917 \nQ 1875 428 2675 428 \nQ 3081 428 3442 575 \nQ 3803 722 4122 1019 \nL 4122 359 \nQ 3791 134 3420 21 \nQ 3050 -91 2638 -91 \nQ 1578 -91 968 557 \nQ 359 1206 359 2328 \nQ 359 3453 968 4101 \nQ 1578 4750 2638 4750 \nQ 3056 4750 3426 4639 \nQ 3797 4528 4122 4306 \nz\n\" id=\"DejaVuSans-43\" transform=\"scale(0.015625)\"/>\n       <path d=\"M 628 4666 \nL 1569 4666 \nL 2759 1491 \nL 3956 4666 \nL 4897 4666 \nL 4897 0 \nL 4281 0 \nL 4281 4097 \nL 3078 897 \nL 2444 897 \nL 1241 4097 \nL 1241 0 \nL 628 0 \nL 628 4666 \nz\n\" id=\"DejaVuSans-4d\" transform=\"scale(0.015625)\"/>\n       <path d=\"M 2841 2188 \nQ 3044 2119 3236 1894 \nQ 3428 1669 3622 1275 \nL 4263 0 \nL 3584 0 \nL 2988 1197 \nQ 2756 1666 2539 1819 \nQ 2322 1972 1947 1972 \nL 1259 1972 \nL 1259 0 \nL 628 0 \nL 628 4666 \nL 2053 4666 \nQ 2853 4666 3247 4331 \nQ 3641 3997 3641 3322 \nQ 3641 2881 3436 2590 \nQ 3231 2300 2841 2188 \nz\nM 1259 4147 \nL 1259 2491 \nL 2053 2491 \nQ 2509 2491 2742 2702 \nQ 2975 2913 2975 3322 \nQ 2975 3731 2742 3939 \nQ 2509 4147 2053 4147 \nL 1259 4147 \nz\n\" id=\"DejaVuSans-52\" transform=\"scale(0.015625)\"/>\n       <path d=\"M 3425 4513 \nL 3425 3897 \nQ 3066 4069 2747 4153 \nQ 2428 4238 2131 4238 \nQ 1616 4238 1336 4038 \nQ 1056 3838 1056 3469 \nQ 1056 3159 1242 3001 \nQ 1428 2844 1947 2747 \nL 2328 2669 \nQ 3034 2534 3370 2195 \nQ 3706 1856 3706 1288 \nQ 3706 609 3251 259 \nQ 2797 -91 1919 -91 \nQ 1588 -91 1214 -16 \nQ 841 59 441 206 \nL 441 856 \nQ 825 641 1194 531 \nQ 1563 422 1919 422 \nQ 2459 422 2753 634 \nQ 3047 847 3047 1241 \nQ 3047 1584 2836 1778 \nQ 2625 1972 2144 2069 \nL 1759 2144 \nQ 1053 2284 737 2584 \nQ 422 2884 422 3419 \nQ 422 4038 858 4394 \nQ 1294 4750 2059 4750 \nQ 2388 4750 2728 4690 \nQ 3069 4631 3425 4513 \nz\n\" id=\"DejaVuSans-53\" transform=\"scale(0.015625)\"/>\n       <path d=\"M 3122 3366 \nL 3122 2828 \nQ 2878 2963 2633 3030 \nQ 2388 3097 2138 3097 \nQ 1578 3097 1268 2742 \nQ 959 2388 959 1747 \nQ 959 1106 1268 751 \nQ 1578 397 2138 397 \nQ 2388 397 2633 464 \nQ 2878 531 3122 666 \nL 3122 134 \nQ 2881 22 2623 -34 \nQ 2366 -91 2075 -91 \nQ 1284 -91 818 406 \nQ 353 903 353 1747 \nQ 353 2603 823 3093 \nQ 1294 3584 2113 3584 \nQ 2378 3584 2631 3529 \nQ 2884 3475 3122 3366 \nz\n\" id=\"DejaVuSans-63\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-47\"/>\n      <use x=\"77.490234\" xlink:href=\"#DejaVuSans-44\"/>\n      <use x=\"154.492188\" xlink:href=\"#DejaVuSans-42\"/>\n      <use x=\"221.345703\" xlink:href=\"#DejaVuSans-43\"/>\n      <use x=\"291.169922\" xlink:href=\"#DejaVuSans-4d\"/>\n      <use x=\"377.449219\" xlink:href=\"#DejaVuSans-6f\"/>\n      <use x=\"438.630859\" xlink:href=\"#DejaVuSans-64\"/>\n      <use x=\"502.107422\" xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"563.630859\" xlink:href=\"#DejaVuSans-6c\"/>\n      <use x=\"591.414062\" xlink:href=\"#DejaVuSans-2d\"/>\n      <use x=\"627.498047\" xlink:href=\"#DejaVuSans-52\"/>\n      <use x=\"694.730469\" xlink:href=\"#DejaVuSans-61\"/>\n      <use x=\"756.009766\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"819.388672\" xlink:href=\"#DejaVuSans-64\"/>\n      <use x=\"882.865234\" xlink:href=\"#DejaVuSans-6f\"/>\n      <use x=\"944.046875\" xlink:href=\"#DejaVuSans-6d\"/>\n      <use x=\"1041.458984\" xlink:href=\"#DejaVuSans-53\"/>\n      <use x=\"1104.935547\" xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"1166.458984\" xlink:href=\"#DejaVuSans-6c\"/>\n      <use x=\"1194.242188\" xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"1255.765625\" xlink:href=\"#DejaVuSans-63\"/>\n      <use x=\"1310.746094\" xlink:href=\"#DejaVuSans-74\"/>\n      <use x=\"1349.955078\" xlink:href=\"#DejaVuSans-69\"/>\n      <use x=\"1377.738281\" xlink:href=\"#DejaVuSans-6f\"/>\n      <use x=\"1438.919922\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"1502.298828\" xlink:href=\"#DejaVuSans-2d\"/>\n      <use x=\"1538.382812\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"1602.005859\" xlink:href=\"#DejaVuSans-35\"/>\n      <use x=\"1665.628906\" xlink:href=\"#DejaVuSans-30\"/>\n     </g>\n    </g>\n    <g id=\"line2d_60\">\n     <path d=\"M 118.590625 53.453906 \nL 138.590625 53.453906 \n\" style=\"fill:none;stroke:#2ca02c;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_61\"/>\n    <g id=\"text_20\">\n     <!-- GDBCModel-RandomSelection-125 -->\n     <g transform=\"translate(146.590625 56.953906)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-47\"/>\n      <use x=\"77.490234\" xlink:href=\"#DejaVuSans-44\"/>\n      <use x=\"154.492188\" xlink:href=\"#DejaVuSans-42\"/>\n      <use x=\"221.345703\" xlink:href=\"#DejaVuSans-43\"/>\n      <use x=\"291.169922\" xlink:href=\"#DejaVuSans-4d\"/>\n      <use x=\"377.449219\" xlink:href=\"#DejaVuSans-6f\"/>\n      <use x=\"438.630859\" xlink:href=\"#DejaVuSans-64\"/>\n      <use x=\"502.107422\" xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"563.630859\" xlink:href=\"#DejaVuSans-6c\"/>\n      <use x=\"591.414062\" xlink:href=\"#DejaVuSans-2d\"/>\n      <use x=\"627.498047\" xlink:href=\"#DejaVuSans-52\"/>\n      <use x=\"694.730469\" xlink:href=\"#DejaVuSans-61\"/>\n      <use x=\"756.009766\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"819.388672\" xlink:href=\"#DejaVuSans-64\"/>\n      <use x=\"882.865234\" xlink:href=\"#DejaVuSans-6f\"/>\n      <use x=\"944.046875\" xlink:href=\"#DejaVuSans-6d\"/>\n      <use x=\"1041.458984\" xlink:href=\"#DejaVuSans-53\"/>\n      <use x=\"1104.935547\" xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"1166.458984\" xlink:href=\"#DejaVuSans-6c\"/>\n      <use x=\"1194.242188\" xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"1255.765625\" xlink:href=\"#DejaVuSans-63\"/>\n      <use x=\"1310.746094\" xlink:href=\"#DejaVuSans-74\"/>\n      <use x=\"1349.955078\" xlink:href=\"#DejaVuSans-69\"/>\n      <use x=\"1377.738281\" xlink:href=\"#DejaVuSans-6f\"/>\n      <use x=\"1438.919922\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"1502.298828\" xlink:href=\"#DejaVuSans-2d\"/>\n      <use x=\"1538.382812\" xlink:href=\"#DejaVuSans-31\"/>\n      <use x=\"1602.005859\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"1665.628906\" xlink:href=\"#DejaVuSans-35\"/>\n     </g>\n    </g>\n    <g id=\"line2d_62\">\n     <path d=\"M 118.590625 68.132031 \nL 138.590625 68.132031 \n\" style=\"fill:none;stroke:#d62728;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_63\"/>\n    <g id=\"text_21\">\n     <!-- GDBCModel-RandomSelection-50 -->\n     <g transform=\"translate(146.590625 71.632031)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-47\"/>\n      <use x=\"77.490234\" xlink:href=\"#DejaVuSans-44\"/>\n      <use x=\"154.492188\" xlink:href=\"#DejaVuSans-42\"/>\n      <use x=\"221.345703\" xlink:href=\"#DejaVuSans-43\"/>\n      <use x=\"291.169922\" xlink:href=\"#DejaVuSans-4d\"/>\n      <use x=\"377.449219\" xlink:href=\"#DejaVuSans-6f\"/>\n      <use x=\"438.630859\" xlink:href=\"#DejaVuSans-64\"/>\n      <use x=\"502.107422\" xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"563.630859\" xlink:href=\"#DejaVuSans-6c\"/>\n      <use x=\"591.414062\" xlink:href=\"#DejaVuSans-2d\"/>\n      <use x=\"627.498047\" xlink:href=\"#DejaVuSans-52\"/>\n      <use x=\"694.730469\" xlink:href=\"#DejaVuSans-61\"/>\n      <use x=\"756.009766\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"819.388672\" xlink:href=\"#DejaVuSans-64\"/>\n      <use x=\"882.865234\" xlink:href=\"#DejaVuSans-6f\"/>\n      <use x=\"944.046875\" xlink:href=\"#DejaVuSans-6d\"/>\n      <use x=\"1041.458984\" xlink:href=\"#DejaVuSans-53\"/>\n      <use x=\"1104.935547\" xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"1166.458984\" xlink:href=\"#DejaVuSans-6c\"/>\n      <use x=\"1194.242188\" xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"1255.765625\" xlink:href=\"#DejaVuSans-63\"/>\n      <use x=\"1310.746094\" xlink:href=\"#DejaVuSans-74\"/>\n      <use x=\"1349.955078\" xlink:href=\"#DejaVuSans-69\"/>\n      <use x=\"1377.738281\" xlink:href=\"#DejaVuSans-6f\"/>\n      <use x=\"1438.919922\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"1502.298828\" xlink:href=\"#DejaVuSans-2d\"/>\n      <use x=\"1538.382812\" xlink:href=\"#DejaVuSans-35\"/>\n      <use x=\"1602.005859\" xlink:href=\"#DejaVuSans-30\"/>\n     </g>\n    </g>\n    <g id=\"line2d_64\">\n     <path d=\"M 118.590625 82.810156 \nL 138.590625 82.810156 \n\" style=\"fill:none;stroke:#9467bd;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_65\"/>\n    <g id=\"text_22\">\n     <!-- GDBCModel-RandomSelection-25 -->\n     <g transform=\"translate(146.590625 86.310156)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-47\"/>\n      <use x=\"77.490234\" xlink:href=\"#DejaVuSans-44\"/>\n      <use x=\"154.492188\" xlink:href=\"#DejaVuSans-42\"/>\n      <use x=\"221.345703\" xlink:href=\"#DejaVuSans-43\"/>\n      <use x=\"291.169922\" xlink:href=\"#DejaVuSans-4d\"/>\n      <use x=\"377.449219\" xlink:href=\"#DejaVuSans-6f\"/>\n      <use x=\"438.630859\" xlink:href=\"#DejaVuSans-64\"/>\n      <use x=\"502.107422\" xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"563.630859\" xlink:href=\"#DejaVuSans-6c\"/>\n      <use x=\"591.414062\" xlink:href=\"#DejaVuSans-2d\"/>\n      <use x=\"627.498047\" xlink:href=\"#DejaVuSans-52\"/>\n      <use x=\"694.730469\" xlink:href=\"#DejaVuSans-61\"/>\n      <use x=\"756.009766\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"819.388672\" xlink:href=\"#DejaVuSans-64\"/>\n      <use x=\"882.865234\" xlink:href=\"#DejaVuSans-6f\"/>\n      <use x=\"944.046875\" xlink:href=\"#DejaVuSans-6d\"/>\n      <use x=\"1041.458984\" xlink:href=\"#DejaVuSans-53\"/>\n      <use x=\"1104.935547\" xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"1166.458984\" xlink:href=\"#DejaVuSans-6c\"/>\n      <use x=\"1194.242188\" xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"1255.765625\" xlink:href=\"#DejaVuSans-63\"/>\n      <use x=\"1310.746094\" xlink:href=\"#DejaVuSans-74\"/>\n      <use x=\"1349.955078\" xlink:href=\"#DejaVuSans-69\"/>\n      <use x=\"1377.738281\" xlink:href=\"#DejaVuSans-6f\"/>\n      <use x=\"1438.919922\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"1502.298828\" xlink:href=\"#DejaVuSans-2d\"/>\n      <use x=\"1538.382812\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"1602.005859\" xlink:href=\"#DejaVuSans-35\"/>\n     </g>\n    </g>\n    <g id=\"line2d_66\">\n     <path d=\"M 118.590625 97.488281 \nL 138.590625 97.488281 \n\" style=\"fill:none;stroke:#8c564b;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_67\"/>\n    <g id=\"text_23\">\n     <!-- GDBCModel-RandomSelection-10 -->\n     <g transform=\"translate(146.590625 100.988281)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-47\"/>\n      <use x=\"77.490234\" xlink:href=\"#DejaVuSans-44\"/>\n      <use x=\"154.492188\" xlink:href=\"#DejaVuSans-42\"/>\n      <use x=\"221.345703\" xlink:href=\"#DejaVuSans-43\"/>\n      <use x=\"291.169922\" xlink:href=\"#DejaVuSans-4d\"/>\n      <use x=\"377.449219\" xlink:href=\"#DejaVuSans-6f\"/>\n      <use x=\"438.630859\" xlink:href=\"#DejaVuSans-64\"/>\n      <use x=\"502.107422\" xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"563.630859\" xlink:href=\"#DejaVuSans-6c\"/>\n      <use x=\"591.414062\" xlink:href=\"#DejaVuSans-2d\"/>\n      <use x=\"627.498047\" xlink:href=\"#DejaVuSans-52\"/>\n      <use x=\"694.730469\" xlink:href=\"#DejaVuSans-61\"/>\n      <use x=\"756.009766\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"819.388672\" xlink:href=\"#DejaVuSans-64\"/>\n      <use x=\"882.865234\" xlink:href=\"#DejaVuSans-6f\"/>\n      <use x=\"944.046875\" xlink:href=\"#DejaVuSans-6d\"/>\n      <use x=\"1041.458984\" xlink:href=\"#DejaVuSans-53\"/>\n      <use x=\"1104.935547\" xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"1166.458984\" xlink:href=\"#DejaVuSans-6c\"/>\n      <use x=\"1194.242188\" xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"1255.765625\" xlink:href=\"#DejaVuSans-63\"/>\n      <use x=\"1310.746094\" xlink:href=\"#DejaVuSans-74\"/>\n      <use x=\"1349.955078\" xlink:href=\"#DejaVuSans-69\"/>\n      <use x=\"1377.738281\" xlink:href=\"#DejaVuSans-6f\"/>\n      <use x=\"1438.919922\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"1502.298828\" xlink:href=\"#DejaVuSans-2d\"/>\n      <use x=\"1538.382812\" xlink:href=\"#DejaVuSans-31\"/>\n      <use x=\"1602.005859\" xlink:href=\"#DejaVuSans-30\"/>\n     </g>\n    </g>\n    <g id=\"line2d_68\">\n     <path d=\"M 118.590625 112.166406 \nL 138.590625 112.166406 \n\" style=\"fill:none;stroke:#e377c2;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_69\"/>\n    <g id=\"text_24\">\n     <!-- GDBCModel-MarginSamplingSelection-250 -->\n     <g transform=\"translate(146.590625 115.666406)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-47\"/>\n      <use x=\"77.490234\" xlink:href=\"#DejaVuSans-44\"/>\n      <use x=\"154.492188\" xlink:href=\"#DejaVuSans-42\"/>\n      <use x=\"221.345703\" xlink:href=\"#DejaVuSans-43\"/>\n      <use x=\"291.169922\" xlink:href=\"#DejaVuSans-4d\"/>\n      <use x=\"377.449219\" xlink:href=\"#DejaVuSans-6f\"/>\n      <use x=\"438.630859\" xlink:href=\"#DejaVuSans-64\"/>\n      <use x=\"502.107422\" xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"563.630859\" xlink:href=\"#DejaVuSans-6c\"/>\n      <use x=\"591.414062\" xlink:href=\"#DejaVuSans-2d\"/>\n      <use x=\"627.498047\" xlink:href=\"#DejaVuSans-4d\"/>\n      <use x=\"713.777344\" xlink:href=\"#DejaVuSans-61\"/>\n      <use x=\"775.056641\" xlink:href=\"#DejaVuSans-72\"/>\n      <use x=\"814.419922\" xlink:href=\"#DejaVuSans-67\"/>\n      <use x=\"877.896484\" xlink:href=\"#DejaVuSans-69\"/>\n      <use x=\"905.679688\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"969.058594\" xlink:href=\"#DejaVuSans-53\"/>\n      <use x=\"1032.535156\" xlink:href=\"#DejaVuSans-61\"/>\n      <use x=\"1093.814453\" xlink:href=\"#DejaVuSans-6d\"/>\n      <use x=\"1191.226562\" xlink:href=\"#DejaVuSans-70\"/>\n      <use x=\"1254.703125\" xlink:href=\"#DejaVuSans-6c\"/>\n      <use x=\"1282.486328\" xlink:href=\"#DejaVuSans-69\"/>\n      <use x=\"1310.269531\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"1373.648438\" xlink:href=\"#DejaVuSans-67\"/>\n      <use x=\"1437.125\" xlink:href=\"#DejaVuSans-53\"/>\n      <use x=\"1500.601562\" xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"1562.125\" xlink:href=\"#DejaVuSans-6c\"/>\n      <use x=\"1589.908203\" xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"1651.431641\" xlink:href=\"#DejaVuSans-63\"/>\n      <use x=\"1706.412109\" xlink:href=\"#DejaVuSans-74\"/>\n      <use x=\"1745.621094\" xlink:href=\"#DejaVuSans-69\"/>\n      <use x=\"1773.404297\" xlink:href=\"#DejaVuSans-6f\"/>\n      <use x=\"1834.585938\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"1897.964844\" xlink:href=\"#DejaVuSans-2d\"/>\n      <use x=\"1934.048828\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"1997.671875\" xlink:href=\"#DejaVuSans-35\"/>\n      <use x=\"2061.294922\" xlink:href=\"#DejaVuSans-30\"/>\n     </g>\n    </g>\n    <g id=\"line2d_70\">\n     <path d=\"M 118.590625 126.844531 \nL 138.590625 126.844531 \n\" style=\"fill:none;stroke:#7f7f7f;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_71\"/>\n    <g id=\"text_25\">\n     <!-- GDBCModel-MarginSamplingSelection-125 -->\n     <g transform=\"translate(146.590625 130.344531)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-47\"/>\n      <use x=\"77.490234\" xlink:href=\"#DejaVuSans-44\"/>\n      <use x=\"154.492188\" xlink:href=\"#DejaVuSans-42\"/>\n      <use x=\"221.345703\" xlink:href=\"#DejaVuSans-43\"/>\n      <use x=\"291.169922\" xlink:href=\"#DejaVuSans-4d\"/>\n      <use x=\"377.449219\" xlink:href=\"#DejaVuSans-6f\"/>\n      <use x=\"438.630859\" xlink:href=\"#DejaVuSans-64\"/>\n      <use x=\"502.107422\" xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"563.630859\" xlink:href=\"#DejaVuSans-6c\"/>\n      <use x=\"591.414062\" xlink:href=\"#DejaVuSans-2d\"/>\n      <use x=\"627.498047\" xlink:href=\"#DejaVuSans-4d\"/>\n      <use x=\"713.777344\" xlink:href=\"#DejaVuSans-61\"/>\n      <use x=\"775.056641\" xlink:href=\"#DejaVuSans-72\"/>\n      <use x=\"814.419922\" xlink:href=\"#DejaVuSans-67\"/>\n      <use x=\"877.896484\" xlink:href=\"#DejaVuSans-69\"/>\n      <use x=\"905.679688\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"969.058594\" xlink:href=\"#DejaVuSans-53\"/>\n      <use x=\"1032.535156\" xlink:href=\"#DejaVuSans-61\"/>\n      <use x=\"1093.814453\" xlink:href=\"#DejaVuSans-6d\"/>\n      <use x=\"1191.226562\" xlink:href=\"#DejaVuSans-70\"/>\n      <use x=\"1254.703125\" xlink:href=\"#DejaVuSans-6c\"/>\n      <use x=\"1282.486328\" xlink:href=\"#DejaVuSans-69\"/>\n      <use x=\"1310.269531\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"1373.648438\" xlink:href=\"#DejaVuSans-67\"/>\n      <use x=\"1437.125\" xlink:href=\"#DejaVuSans-53\"/>\n      <use x=\"1500.601562\" xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"1562.125\" xlink:href=\"#DejaVuSans-6c\"/>\n      <use x=\"1589.908203\" xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"1651.431641\" xlink:href=\"#DejaVuSans-63\"/>\n      <use x=\"1706.412109\" xlink:href=\"#DejaVuSans-74\"/>\n      <use x=\"1745.621094\" xlink:href=\"#DejaVuSans-69\"/>\n      <use x=\"1773.404297\" xlink:href=\"#DejaVuSans-6f\"/>\n      <use x=\"1834.585938\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"1897.964844\" xlink:href=\"#DejaVuSans-2d\"/>\n      <use x=\"1934.048828\" xlink:href=\"#DejaVuSans-31\"/>\n      <use x=\"1997.671875\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"2061.294922\" xlink:href=\"#DejaVuSans-35\"/>\n     </g>\n    </g>\n    <g id=\"line2d_72\">\n     <path d=\"M 118.590625 141.522656 \nL 138.590625 141.522656 \n\" style=\"fill:none;stroke:#bcbd22;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_73\"/>\n    <g id=\"text_26\">\n     <!-- GDBCModel-MarginSamplingSelection-50 -->\n     <g transform=\"translate(146.590625 145.022656)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-47\"/>\n      <use x=\"77.490234\" xlink:href=\"#DejaVuSans-44\"/>\n      <use x=\"154.492188\" xlink:href=\"#DejaVuSans-42\"/>\n      <use x=\"221.345703\" xlink:href=\"#DejaVuSans-43\"/>\n      <use x=\"291.169922\" xlink:href=\"#DejaVuSans-4d\"/>\n      <use x=\"377.449219\" xlink:href=\"#DejaVuSans-6f\"/>\n      <use x=\"438.630859\" xlink:href=\"#DejaVuSans-64\"/>\n      <use x=\"502.107422\" xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"563.630859\" xlink:href=\"#DejaVuSans-6c\"/>\n      <use x=\"591.414062\" xlink:href=\"#DejaVuSans-2d\"/>\n      <use x=\"627.498047\" xlink:href=\"#DejaVuSans-4d\"/>\n      <use x=\"713.777344\" xlink:href=\"#DejaVuSans-61\"/>\n      <use x=\"775.056641\" xlink:href=\"#DejaVuSans-72\"/>\n      <use x=\"814.419922\" xlink:href=\"#DejaVuSans-67\"/>\n      <use x=\"877.896484\" xlink:href=\"#DejaVuSans-69\"/>\n      <use x=\"905.679688\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"969.058594\" xlink:href=\"#DejaVuSans-53\"/>\n      <use x=\"1032.535156\" xlink:href=\"#DejaVuSans-61\"/>\n      <use x=\"1093.814453\" xlink:href=\"#DejaVuSans-6d\"/>\n      <use x=\"1191.226562\" xlink:href=\"#DejaVuSans-70\"/>\n      <use x=\"1254.703125\" xlink:href=\"#DejaVuSans-6c\"/>\n      <use x=\"1282.486328\" xlink:href=\"#DejaVuSans-69\"/>\n      <use x=\"1310.269531\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"1373.648438\" xlink:href=\"#DejaVuSans-67\"/>\n      <use x=\"1437.125\" xlink:href=\"#DejaVuSans-53\"/>\n      <use x=\"1500.601562\" xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"1562.125\" xlink:href=\"#DejaVuSans-6c\"/>\n      <use x=\"1589.908203\" xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"1651.431641\" xlink:href=\"#DejaVuSans-63\"/>\n      <use x=\"1706.412109\" xlink:href=\"#DejaVuSans-74\"/>\n      <use x=\"1745.621094\" xlink:href=\"#DejaVuSans-69\"/>\n      <use x=\"1773.404297\" xlink:href=\"#DejaVuSans-6f\"/>\n      <use x=\"1834.585938\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"1897.964844\" xlink:href=\"#DejaVuSans-2d\"/>\n      <use x=\"1934.048828\" xlink:href=\"#DejaVuSans-35\"/>\n      <use x=\"1997.671875\" xlink:href=\"#DejaVuSans-30\"/>\n     </g>\n    </g>\n    <g id=\"line2d_74\">\n     <path d=\"M 118.590625 156.200781 \nL 138.590625 156.200781 \n\" style=\"fill:none;stroke:#17becf;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_75\"/>\n    <g id=\"text_27\">\n     <!-- GDBCModel-MarginSamplingSelection-25 -->\n     <g transform=\"translate(146.590625 159.700781)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-47\"/>\n      <use x=\"77.490234\" xlink:href=\"#DejaVuSans-44\"/>\n      <use x=\"154.492188\" xlink:href=\"#DejaVuSans-42\"/>\n      <use x=\"221.345703\" xlink:href=\"#DejaVuSans-43\"/>\n      <use x=\"291.169922\" xlink:href=\"#DejaVuSans-4d\"/>\n      <use x=\"377.449219\" xlink:href=\"#DejaVuSans-6f\"/>\n      <use x=\"438.630859\" xlink:href=\"#DejaVuSans-64\"/>\n      <use x=\"502.107422\" xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"563.630859\" xlink:href=\"#DejaVuSans-6c\"/>\n      <use x=\"591.414062\" xlink:href=\"#DejaVuSans-2d\"/>\n      <use x=\"627.498047\" xlink:href=\"#DejaVuSans-4d\"/>\n      <use x=\"713.777344\" xlink:href=\"#DejaVuSans-61\"/>\n      <use x=\"775.056641\" xlink:href=\"#DejaVuSans-72\"/>\n      <use x=\"814.419922\" xlink:href=\"#DejaVuSans-67\"/>\n      <use x=\"877.896484\" xlink:href=\"#DejaVuSans-69\"/>\n      <use x=\"905.679688\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"969.058594\" xlink:href=\"#DejaVuSans-53\"/>\n      <use x=\"1032.535156\" xlink:href=\"#DejaVuSans-61\"/>\n      <use x=\"1093.814453\" xlink:href=\"#DejaVuSans-6d\"/>\n      <use x=\"1191.226562\" xlink:href=\"#DejaVuSans-70\"/>\n      <use x=\"1254.703125\" xlink:href=\"#DejaVuSans-6c\"/>\n      <use x=\"1282.486328\" xlink:href=\"#DejaVuSans-69\"/>\n      <use x=\"1310.269531\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"1373.648438\" xlink:href=\"#DejaVuSans-67\"/>\n      <use x=\"1437.125\" xlink:href=\"#DejaVuSans-53\"/>\n      <use x=\"1500.601562\" xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"1562.125\" xlink:href=\"#DejaVuSans-6c\"/>\n      <use x=\"1589.908203\" xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"1651.431641\" xlink:href=\"#DejaVuSans-63\"/>\n      <use x=\"1706.412109\" xlink:href=\"#DejaVuSans-74\"/>\n      <use x=\"1745.621094\" xlink:href=\"#DejaVuSans-69\"/>\n      <use x=\"1773.404297\" xlink:href=\"#DejaVuSans-6f\"/>\n      <use x=\"1834.585938\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"1897.964844\" xlink:href=\"#DejaVuSans-2d\"/>\n      <use x=\"1934.048828\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"1997.671875\" xlink:href=\"#DejaVuSans-35\"/>\n     </g>\n    </g>\n    <g id=\"line2d_76\">\n     <path d=\"M 118.590625 170.878906 \nL 138.590625 170.878906 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_77\"/>\n    <g id=\"text_28\">\n     <!-- GDBCModel-MarginSamplingSelection-10 -->\n     <g transform=\"translate(146.590625 174.378906)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-47\"/>\n      <use x=\"77.490234\" xlink:href=\"#DejaVuSans-44\"/>\n      <use x=\"154.492188\" xlink:href=\"#DejaVuSans-42\"/>\n      <use x=\"221.345703\" xlink:href=\"#DejaVuSans-43\"/>\n      <use x=\"291.169922\" xlink:href=\"#DejaVuSans-4d\"/>\n      <use x=\"377.449219\" xlink:href=\"#DejaVuSans-6f\"/>\n      <use x=\"438.630859\" xlink:href=\"#DejaVuSans-64\"/>\n      <use x=\"502.107422\" xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"563.630859\" xlink:href=\"#DejaVuSans-6c\"/>\n      <use x=\"591.414062\" xlink:href=\"#DejaVuSans-2d\"/>\n      <use x=\"627.498047\" xlink:href=\"#DejaVuSans-4d\"/>\n      <use x=\"713.777344\" xlink:href=\"#DejaVuSans-61\"/>\n      <use x=\"775.056641\" xlink:href=\"#DejaVuSans-72\"/>\n      <use x=\"814.419922\" xlink:href=\"#DejaVuSans-67\"/>\n      <use x=\"877.896484\" xlink:href=\"#DejaVuSans-69\"/>\n      <use x=\"905.679688\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"969.058594\" xlink:href=\"#DejaVuSans-53\"/>\n      <use x=\"1032.535156\" xlink:href=\"#DejaVuSans-61\"/>\n      <use x=\"1093.814453\" xlink:href=\"#DejaVuSans-6d\"/>\n      <use x=\"1191.226562\" xlink:href=\"#DejaVuSans-70\"/>\n      <use x=\"1254.703125\" xlink:href=\"#DejaVuSans-6c\"/>\n      <use x=\"1282.486328\" xlink:href=\"#DejaVuSans-69\"/>\n      <use x=\"1310.269531\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"1373.648438\" xlink:href=\"#DejaVuSans-67\"/>\n      <use x=\"1437.125\" xlink:href=\"#DejaVuSans-53\"/>\n      <use x=\"1500.601562\" xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"1562.125\" xlink:href=\"#DejaVuSans-6c\"/>\n      <use x=\"1589.908203\" xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"1651.431641\" xlink:href=\"#DejaVuSans-63\"/>\n      <use x=\"1706.412109\" xlink:href=\"#DejaVuSans-74\"/>\n      <use x=\"1745.621094\" xlink:href=\"#DejaVuSans-69\"/>\n      <use x=\"1773.404297\" xlink:href=\"#DejaVuSans-6f\"/>\n      <use x=\"1834.585938\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"1897.964844\" xlink:href=\"#DejaVuSans-2d\"/>\n      <use x=\"1934.048828\" xlink:href=\"#DejaVuSans-31\"/>\n      <use x=\"1997.671875\" xlink:href=\"#DejaVuSans-30\"/>\n     </g>\n    </g>\n    <g id=\"line2d_78\">\n     <path d=\"M 118.590625 185.557031 \nL 138.590625 185.557031 \n\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_79\"/>\n    <g id=\"text_29\">\n     <!-- GDBCModel-EntropySelection-250 -->\n     <g transform=\"translate(146.590625 189.057031)scale(0.1 -0.1)\">\n      <defs>\n       <path d=\"M 628 4666 \nL 3578 4666 \nL 3578 4134 \nL 1259 4134 \nL 1259 2753 \nL 3481 2753 \nL 3481 2222 \nL 1259 2222 \nL 1259 531 \nL 3634 531 \nL 3634 0 \nL 628 0 \nL 628 4666 \nz\n\" id=\"DejaVuSans-45\" transform=\"scale(0.015625)\"/>\n       <path d=\"M 2059 -325 \nQ 1816 -950 1584 -1140 \nQ 1353 -1331 966 -1331 \nL 506 -1331 \nL 506 -850 \nL 844 -850 \nQ 1081 -850 1212 -737 \nQ 1344 -625 1503 -206 \nL 1606 56 \nL 191 3500 \nL 800 3500 \nL 1894 763 \nL 2988 3500 \nL 3597 3500 \nL 2059 -325 \nz\n\" id=\"DejaVuSans-79\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-47\"/>\n      <use x=\"77.490234\" xlink:href=\"#DejaVuSans-44\"/>\n      <use x=\"154.492188\" xlink:href=\"#DejaVuSans-42\"/>\n      <use x=\"221.345703\" xlink:href=\"#DejaVuSans-43\"/>\n      <use x=\"291.169922\" xlink:href=\"#DejaVuSans-4d\"/>\n      <use x=\"377.449219\" xlink:href=\"#DejaVuSans-6f\"/>\n      <use x=\"438.630859\" xlink:href=\"#DejaVuSans-64\"/>\n      <use x=\"502.107422\" xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"563.630859\" xlink:href=\"#DejaVuSans-6c\"/>\n      <use x=\"591.414062\" xlink:href=\"#DejaVuSans-2d\"/>\n      <use x=\"627.498047\" xlink:href=\"#DejaVuSans-45\"/>\n      <use x=\"690.681641\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"754.060547\" xlink:href=\"#DejaVuSans-74\"/>\n      <use x=\"793.269531\" xlink:href=\"#DejaVuSans-72\"/>\n      <use x=\"832.132812\" xlink:href=\"#DejaVuSans-6f\"/>\n      <use x=\"893.314453\" xlink:href=\"#DejaVuSans-70\"/>\n      <use x=\"956.791016\" xlink:href=\"#DejaVuSans-79\"/>\n      <use x=\"1015.970703\" xlink:href=\"#DejaVuSans-53\"/>\n      <use x=\"1079.447266\" xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"1140.970703\" xlink:href=\"#DejaVuSans-6c\"/>\n      <use x=\"1168.753906\" xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"1230.277344\" xlink:href=\"#DejaVuSans-63\"/>\n      <use x=\"1285.257812\" xlink:href=\"#DejaVuSans-74\"/>\n      <use x=\"1324.466797\" xlink:href=\"#DejaVuSans-69\"/>\n      <use x=\"1352.25\" xlink:href=\"#DejaVuSans-6f\"/>\n      <use x=\"1413.431641\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"1476.810547\" xlink:href=\"#DejaVuSans-2d\"/>\n      <use x=\"1512.894531\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"1576.517578\" xlink:href=\"#DejaVuSans-35\"/>\n      <use x=\"1640.140625\" xlink:href=\"#DejaVuSans-30\"/>\n     </g>\n    </g>\n    <g id=\"line2d_80\">\n     <path d=\"M 118.590625 200.235156 \nL 138.590625 200.235156 \n\" style=\"fill:none;stroke:#2ca02c;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_81\"/>\n    <g id=\"text_30\">\n     <!-- GDBCModel-EntropySelection-125 -->\n     <g transform=\"translate(146.590625 203.735156)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-47\"/>\n      <use x=\"77.490234\" xlink:href=\"#DejaVuSans-44\"/>\n      <use x=\"154.492188\" xlink:href=\"#DejaVuSans-42\"/>\n      <use x=\"221.345703\" xlink:href=\"#DejaVuSans-43\"/>\n      <use x=\"291.169922\" xlink:href=\"#DejaVuSans-4d\"/>\n      <use x=\"377.449219\" xlink:href=\"#DejaVuSans-6f\"/>\n      <use x=\"438.630859\" xlink:href=\"#DejaVuSans-64\"/>\n      <use x=\"502.107422\" xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"563.630859\" xlink:href=\"#DejaVuSans-6c\"/>\n      <use x=\"591.414062\" xlink:href=\"#DejaVuSans-2d\"/>\n      <use x=\"627.498047\" xlink:href=\"#DejaVuSans-45\"/>\n      <use x=\"690.681641\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"754.060547\" xlink:href=\"#DejaVuSans-74\"/>\n      <use x=\"793.269531\" xlink:href=\"#DejaVuSans-72\"/>\n      <use x=\"832.132812\" xlink:href=\"#DejaVuSans-6f\"/>\n      <use x=\"893.314453\" xlink:href=\"#DejaVuSans-70\"/>\n      <use x=\"956.791016\" xlink:href=\"#DejaVuSans-79\"/>\n      <use x=\"1015.970703\" xlink:href=\"#DejaVuSans-53\"/>\n      <use x=\"1079.447266\" xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"1140.970703\" xlink:href=\"#DejaVuSans-6c\"/>\n      <use x=\"1168.753906\" xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"1230.277344\" xlink:href=\"#DejaVuSans-63\"/>\n      <use x=\"1285.257812\" xlink:href=\"#DejaVuSans-74\"/>\n      <use x=\"1324.466797\" xlink:href=\"#DejaVuSans-69\"/>\n      <use x=\"1352.25\" xlink:href=\"#DejaVuSans-6f\"/>\n      <use x=\"1413.431641\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"1476.810547\" xlink:href=\"#DejaVuSans-2d\"/>\n      <use x=\"1512.894531\" xlink:href=\"#DejaVuSans-31\"/>\n      <use x=\"1576.517578\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"1640.140625\" xlink:href=\"#DejaVuSans-35\"/>\n     </g>\n    </g>\n    <g id=\"line2d_82\">\n     <path d=\"M 118.590625 214.913281 \nL 138.590625 214.913281 \n\" style=\"fill:none;stroke:#d62728;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_83\"/>\n    <g id=\"text_31\">\n     <!-- GDBCModel-EntropySelection-50 -->\n     <g transform=\"translate(146.590625 218.413281)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-47\"/>\n      <use x=\"77.490234\" xlink:href=\"#DejaVuSans-44\"/>\n      <use x=\"154.492188\" xlink:href=\"#DejaVuSans-42\"/>\n      <use x=\"221.345703\" xlink:href=\"#DejaVuSans-43\"/>\n      <use x=\"291.169922\" xlink:href=\"#DejaVuSans-4d\"/>\n      <use x=\"377.449219\" xlink:href=\"#DejaVuSans-6f\"/>\n      <use x=\"438.630859\" xlink:href=\"#DejaVuSans-64\"/>\n      <use x=\"502.107422\" xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"563.630859\" xlink:href=\"#DejaVuSans-6c\"/>\n      <use x=\"591.414062\" xlink:href=\"#DejaVuSans-2d\"/>\n      <use x=\"627.498047\" xlink:href=\"#DejaVuSans-45\"/>\n      <use x=\"690.681641\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"754.060547\" xlink:href=\"#DejaVuSans-74\"/>\n      <use x=\"793.269531\" xlink:href=\"#DejaVuSans-72\"/>\n      <use x=\"832.132812\" xlink:href=\"#DejaVuSans-6f\"/>\n      <use x=\"893.314453\" xlink:href=\"#DejaVuSans-70\"/>\n      <use x=\"956.791016\" xlink:href=\"#DejaVuSans-79\"/>\n      <use x=\"1015.970703\" xlink:href=\"#DejaVuSans-53\"/>\n      <use x=\"1079.447266\" xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"1140.970703\" xlink:href=\"#DejaVuSans-6c\"/>\n      <use x=\"1168.753906\" xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"1230.277344\" xlink:href=\"#DejaVuSans-63\"/>\n      <use x=\"1285.257812\" xlink:href=\"#DejaVuSans-74\"/>\n      <use x=\"1324.466797\" xlink:href=\"#DejaVuSans-69\"/>\n      <use x=\"1352.25\" xlink:href=\"#DejaVuSans-6f\"/>\n      <use x=\"1413.431641\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"1476.810547\" xlink:href=\"#DejaVuSans-2d\"/>\n      <use x=\"1512.894531\" xlink:href=\"#DejaVuSans-35\"/>\n      <use x=\"1576.517578\" xlink:href=\"#DejaVuSans-30\"/>\n     </g>\n    </g>\n    <g id=\"line2d_84\">\n     <path d=\"M 118.590625 229.591406 \nL 138.590625 229.591406 \n\" style=\"fill:none;stroke:#9467bd;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_85\"/>\n    <g id=\"text_32\">\n     <!-- GDBCModel-EntropySelection-25 -->\n     <g transform=\"translate(146.590625 233.091406)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-47\"/>\n      <use x=\"77.490234\" xlink:href=\"#DejaVuSans-44\"/>\n      <use x=\"154.492188\" xlink:href=\"#DejaVuSans-42\"/>\n      <use x=\"221.345703\" xlink:href=\"#DejaVuSans-43\"/>\n      <use x=\"291.169922\" xlink:href=\"#DejaVuSans-4d\"/>\n      <use x=\"377.449219\" xlink:href=\"#DejaVuSans-6f\"/>\n      <use x=\"438.630859\" xlink:href=\"#DejaVuSans-64\"/>\n      <use x=\"502.107422\" xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"563.630859\" xlink:href=\"#DejaVuSans-6c\"/>\n      <use x=\"591.414062\" xlink:href=\"#DejaVuSans-2d\"/>\n      <use x=\"627.498047\" xlink:href=\"#DejaVuSans-45\"/>\n      <use x=\"690.681641\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"754.060547\" xlink:href=\"#DejaVuSans-74\"/>\n      <use x=\"793.269531\" xlink:href=\"#DejaVuSans-72\"/>\n      <use x=\"832.132812\" xlink:href=\"#DejaVuSans-6f\"/>\n      <use x=\"893.314453\" xlink:href=\"#DejaVuSans-70\"/>\n      <use x=\"956.791016\" xlink:href=\"#DejaVuSans-79\"/>\n      <use x=\"1015.970703\" xlink:href=\"#DejaVuSans-53\"/>\n      <use x=\"1079.447266\" xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"1140.970703\" xlink:href=\"#DejaVuSans-6c\"/>\n      <use x=\"1168.753906\" xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"1230.277344\" xlink:href=\"#DejaVuSans-63\"/>\n      <use x=\"1285.257812\" xlink:href=\"#DejaVuSans-74\"/>\n      <use x=\"1324.466797\" xlink:href=\"#DejaVuSans-69\"/>\n      <use x=\"1352.25\" xlink:href=\"#DejaVuSans-6f\"/>\n      <use x=\"1413.431641\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"1476.810547\" xlink:href=\"#DejaVuSans-2d\"/>\n      <use x=\"1512.894531\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"1576.517578\" xlink:href=\"#DejaVuSans-35\"/>\n     </g>\n    </g>\n    <g id=\"line2d_86\">\n     <path d=\"M 118.590625 244.269531 \nL 138.590625 244.269531 \n\" style=\"fill:none;stroke:#8c564b;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_87\"/>\n    <g id=\"text_33\">\n     <!-- GDBCModel-EntropySelection-10 -->\n     <g transform=\"translate(146.590625 247.769531)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-47\"/>\n      <use x=\"77.490234\" xlink:href=\"#DejaVuSans-44\"/>\n      <use x=\"154.492188\" xlink:href=\"#DejaVuSans-42\"/>\n      <use x=\"221.345703\" xlink:href=\"#DejaVuSans-43\"/>\n      <use x=\"291.169922\" xlink:href=\"#DejaVuSans-4d\"/>\n      <use x=\"377.449219\" xlink:href=\"#DejaVuSans-6f\"/>\n      <use x=\"438.630859\" xlink:href=\"#DejaVuSans-64\"/>\n      <use x=\"502.107422\" xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"563.630859\" xlink:href=\"#DejaVuSans-6c\"/>\n      <use x=\"591.414062\" xlink:href=\"#DejaVuSans-2d\"/>\n      <use x=\"627.498047\" xlink:href=\"#DejaVuSans-45\"/>\n      <use x=\"690.681641\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"754.060547\" xlink:href=\"#DejaVuSans-74\"/>\n      <use x=\"793.269531\" xlink:href=\"#DejaVuSans-72\"/>\n      <use x=\"832.132812\" xlink:href=\"#DejaVuSans-6f\"/>\n      <use x=\"893.314453\" xlink:href=\"#DejaVuSans-70\"/>\n      <use x=\"956.791016\" xlink:href=\"#DejaVuSans-79\"/>\n      <use x=\"1015.970703\" xlink:href=\"#DejaVuSans-53\"/>\n      <use x=\"1079.447266\" xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"1140.970703\" xlink:href=\"#DejaVuSans-6c\"/>\n      <use x=\"1168.753906\" xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"1230.277344\" xlink:href=\"#DejaVuSans-63\"/>\n      <use x=\"1285.257812\" xlink:href=\"#DejaVuSans-74\"/>\n      <use x=\"1324.466797\" xlink:href=\"#DejaVuSans-69\"/>\n      <use x=\"1352.25\" xlink:href=\"#DejaVuSans-6f\"/>\n      <use x=\"1413.431641\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"1476.810547\" xlink:href=\"#DejaVuSans-2d\"/>\n      <use x=\"1512.894531\" xlink:href=\"#DejaVuSans-31\"/>\n      <use x=\"1576.517578\" xlink:href=\"#DejaVuSans-30\"/>\n     </g>\n    </g>\n    <g id=\"line2d_88\">\n     <path d=\"M 118.590625 258.947656 \nL 138.590625 258.947656 \n\" style=\"fill:none;stroke:#e377c2;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_89\"/>\n    <g id=\"text_34\">\n     <!-- GDBCModel-MinStdSelection-250 -->\n     <g transform=\"translate(146.590625 262.447656)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-47\"/>\n      <use x=\"77.490234\" xlink:href=\"#DejaVuSans-44\"/>\n      <use x=\"154.492188\" xlink:href=\"#DejaVuSans-42\"/>\n      <use x=\"221.345703\" xlink:href=\"#DejaVuSans-43\"/>\n      <use x=\"291.169922\" xlink:href=\"#DejaVuSans-4d\"/>\n      <use x=\"377.449219\" xlink:href=\"#DejaVuSans-6f\"/>\n      <use x=\"438.630859\" xlink:href=\"#DejaVuSans-64\"/>\n      <use x=\"502.107422\" xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"563.630859\" xlink:href=\"#DejaVuSans-6c\"/>\n      <use x=\"591.414062\" xlink:href=\"#DejaVuSans-2d\"/>\n      <use x=\"627.498047\" xlink:href=\"#DejaVuSans-4d\"/>\n      <use x=\"713.777344\" xlink:href=\"#DejaVuSans-69\"/>\n      <use x=\"741.560547\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"804.939453\" xlink:href=\"#DejaVuSans-53\"/>\n      <use x=\"868.416016\" xlink:href=\"#DejaVuSans-74\"/>\n      <use x=\"907.625\" xlink:href=\"#DejaVuSans-64\"/>\n      <use x=\"971.101562\" xlink:href=\"#DejaVuSans-53\"/>\n      <use x=\"1034.578125\" xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"1096.101562\" xlink:href=\"#DejaVuSans-6c\"/>\n      <use x=\"1123.884766\" xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"1185.408203\" xlink:href=\"#DejaVuSans-63\"/>\n      <use x=\"1240.388672\" xlink:href=\"#DejaVuSans-74\"/>\n      <use x=\"1279.597656\" xlink:href=\"#DejaVuSans-69\"/>\n      <use x=\"1307.380859\" xlink:href=\"#DejaVuSans-6f\"/>\n      <use x=\"1368.5625\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"1431.941406\" xlink:href=\"#DejaVuSans-2d\"/>\n      <use x=\"1468.025391\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"1531.648438\" xlink:href=\"#DejaVuSans-35\"/>\n      <use x=\"1595.271484\" xlink:href=\"#DejaVuSans-30\"/>\n     </g>\n    </g>\n    <g id=\"line2d_90\">\n     <path d=\"M 118.590625 273.625781 \nL 138.590625 273.625781 \n\" style=\"fill:none;stroke:#7f7f7f;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_91\"/>\n    <g id=\"text_35\">\n     <!-- GDBCModel-MinStdSelection-125 -->\n     <g transform=\"translate(146.590625 277.125781)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-47\"/>\n      <use x=\"77.490234\" xlink:href=\"#DejaVuSans-44\"/>\n      <use x=\"154.492188\" xlink:href=\"#DejaVuSans-42\"/>\n      <use x=\"221.345703\" xlink:href=\"#DejaVuSans-43\"/>\n      <use x=\"291.169922\" xlink:href=\"#DejaVuSans-4d\"/>\n      <use x=\"377.449219\" xlink:href=\"#DejaVuSans-6f\"/>\n      <use x=\"438.630859\" xlink:href=\"#DejaVuSans-64\"/>\n      <use x=\"502.107422\" xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"563.630859\" xlink:href=\"#DejaVuSans-6c\"/>\n      <use x=\"591.414062\" xlink:href=\"#DejaVuSans-2d\"/>\n      <use x=\"627.498047\" xlink:href=\"#DejaVuSans-4d\"/>\n      <use x=\"713.777344\" xlink:href=\"#DejaVuSans-69\"/>\n      <use x=\"741.560547\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"804.939453\" xlink:href=\"#DejaVuSans-53\"/>\n      <use x=\"868.416016\" xlink:href=\"#DejaVuSans-74\"/>\n      <use x=\"907.625\" xlink:href=\"#DejaVuSans-64\"/>\n      <use x=\"971.101562\" xlink:href=\"#DejaVuSans-53\"/>\n      <use x=\"1034.578125\" xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"1096.101562\" xlink:href=\"#DejaVuSans-6c\"/>\n      <use x=\"1123.884766\" xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"1185.408203\" xlink:href=\"#DejaVuSans-63\"/>\n      <use x=\"1240.388672\" xlink:href=\"#DejaVuSans-74\"/>\n      <use x=\"1279.597656\" xlink:href=\"#DejaVuSans-69\"/>\n      <use x=\"1307.380859\" xlink:href=\"#DejaVuSans-6f\"/>\n      <use x=\"1368.5625\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"1431.941406\" xlink:href=\"#DejaVuSans-2d\"/>\n      <use x=\"1468.025391\" xlink:href=\"#DejaVuSans-31\"/>\n      <use x=\"1531.648438\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"1595.271484\" xlink:href=\"#DejaVuSans-35\"/>\n     </g>\n    </g>\n    <g id=\"line2d_92\">\n     <path d=\"M 118.590625 288.303906 \nL 138.590625 288.303906 \n\" style=\"fill:none;stroke:#bcbd22;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_93\"/>\n    <g id=\"text_36\">\n     <!-- GDBCModel-MinStdSelection-50 -->\n     <g transform=\"translate(146.590625 291.803906)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-47\"/>\n      <use x=\"77.490234\" xlink:href=\"#DejaVuSans-44\"/>\n      <use x=\"154.492188\" xlink:href=\"#DejaVuSans-42\"/>\n      <use x=\"221.345703\" xlink:href=\"#DejaVuSans-43\"/>\n      <use x=\"291.169922\" xlink:href=\"#DejaVuSans-4d\"/>\n      <use x=\"377.449219\" xlink:href=\"#DejaVuSans-6f\"/>\n      <use x=\"438.630859\" xlink:href=\"#DejaVuSans-64\"/>\n      <use x=\"502.107422\" xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"563.630859\" xlink:href=\"#DejaVuSans-6c\"/>\n      <use x=\"591.414062\" xlink:href=\"#DejaVuSans-2d\"/>\n      <use x=\"627.498047\" xlink:href=\"#DejaVuSans-4d\"/>\n      <use x=\"713.777344\" xlink:href=\"#DejaVuSans-69\"/>\n      <use x=\"741.560547\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"804.939453\" xlink:href=\"#DejaVuSans-53\"/>\n      <use x=\"868.416016\" xlink:href=\"#DejaVuSans-74\"/>\n      <use x=\"907.625\" xlink:href=\"#DejaVuSans-64\"/>\n      <use x=\"971.101562\" xlink:href=\"#DejaVuSans-53\"/>\n      <use x=\"1034.578125\" xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"1096.101562\" xlink:href=\"#DejaVuSans-6c\"/>\n      <use x=\"1123.884766\" xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"1185.408203\" xlink:href=\"#DejaVuSans-63\"/>\n      <use x=\"1240.388672\" xlink:href=\"#DejaVuSans-74\"/>\n      <use x=\"1279.597656\" xlink:href=\"#DejaVuSans-69\"/>\n      <use x=\"1307.380859\" xlink:href=\"#DejaVuSans-6f\"/>\n      <use x=\"1368.5625\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"1431.941406\" xlink:href=\"#DejaVuSans-2d\"/>\n      <use x=\"1468.025391\" xlink:href=\"#DejaVuSans-35\"/>\n      <use x=\"1531.648438\" xlink:href=\"#DejaVuSans-30\"/>\n     </g>\n    </g>\n    <g id=\"line2d_94\">\n     <path d=\"M 118.590625 302.982031 \nL 138.590625 302.982031 \n\" style=\"fill:none;stroke:#17becf;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_95\"/>\n    <g id=\"text_37\">\n     <!-- GDBCModel-MinStdSelection-25 -->\n     <g transform=\"translate(146.590625 306.482031)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-47\"/>\n      <use x=\"77.490234\" xlink:href=\"#DejaVuSans-44\"/>\n      <use x=\"154.492188\" xlink:href=\"#DejaVuSans-42\"/>\n      <use x=\"221.345703\" xlink:href=\"#DejaVuSans-43\"/>\n      <use x=\"291.169922\" xlink:href=\"#DejaVuSans-4d\"/>\n      <use x=\"377.449219\" xlink:href=\"#DejaVuSans-6f\"/>\n      <use x=\"438.630859\" xlink:href=\"#DejaVuSans-64\"/>\n      <use x=\"502.107422\" xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"563.630859\" xlink:href=\"#DejaVuSans-6c\"/>\n      <use x=\"591.414062\" xlink:href=\"#DejaVuSans-2d\"/>\n      <use x=\"627.498047\" xlink:href=\"#DejaVuSans-4d\"/>\n      <use x=\"713.777344\" xlink:href=\"#DejaVuSans-69\"/>\n      <use x=\"741.560547\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"804.939453\" xlink:href=\"#DejaVuSans-53\"/>\n      <use x=\"868.416016\" xlink:href=\"#DejaVuSans-74\"/>\n      <use x=\"907.625\" xlink:href=\"#DejaVuSans-64\"/>\n      <use x=\"971.101562\" xlink:href=\"#DejaVuSans-53\"/>\n      <use x=\"1034.578125\" xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"1096.101562\" xlink:href=\"#DejaVuSans-6c\"/>\n      <use x=\"1123.884766\" xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"1185.408203\" xlink:href=\"#DejaVuSans-63\"/>\n      <use x=\"1240.388672\" xlink:href=\"#DejaVuSans-74\"/>\n      <use x=\"1279.597656\" xlink:href=\"#DejaVuSans-69\"/>\n      <use x=\"1307.380859\" xlink:href=\"#DejaVuSans-6f\"/>\n      <use x=\"1368.5625\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"1431.941406\" xlink:href=\"#DejaVuSans-2d\"/>\n      <use x=\"1468.025391\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"1531.648438\" xlink:href=\"#DejaVuSans-35\"/>\n     </g>\n    </g>\n    <g id=\"line2d_96\">\n     <path d=\"M 118.590625 317.660156 \nL 138.590625 317.660156 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_97\"/>\n    <g id=\"text_38\">\n     <!-- GDBCModel-MinStdSelection-10 -->\n     <g transform=\"translate(146.590625 321.160156)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-47\"/>\n      <use x=\"77.490234\" xlink:href=\"#DejaVuSans-44\"/>\n      <use x=\"154.492188\" xlink:href=\"#DejaVuSans-42\"/>\n      <use x=\"221.345703\" xlink:href=\"#DejaVuSans-43\"/>\n      <use x=\"291.169922\" xlink:href=\"#DejaVuSans-4d\"/>\n      <use x=\"377.449219\" xlink:href=\"#DejaVuSans-6f\"/>\n      <use x=\"438.630859\" xlink:href=\"#DejaVuSans-64\"/>\n      <use x=\"502.107422\" xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"563.630859\" xlink:href=\"#DejaVuSans-6c\"/>\n      <use x=\"591.414062\" xlink:href=\"#DejaVuSans-2d\"/>\n      <use x=\"627.498047\" xlink:href=\"#DejaVuSans-4d\"/>\n      <use x=\"713.777344\" xlink:href=\"#DejaVuSans-69\"/>\n      <use x=\"741.560547\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"804.939453\" xlink:href=\"#DejaVuSans-53\"/>\n      <use x=\"868.416016\" xlink:href=\"#DejaVuSans-74\"/>\n      <use x=\"907.625\" xlink:href=\"#DejaVuSans-64\"/>\n      <use x=\"971.101562\" xlink:href=\"#DejaVuSans-53\"/>\n      <use x=\"1034.578125\" xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"1096.101562\" xlink:href=\"#DejaVuSans-6c\"/>\n      <use x=\"1123.884766\" xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"1185.408203\" xlink:href=\"#DejaVuSans-63\"/>\n      <use x=\"1240.388672\" xlink:href=\"#DejaVuSans-74\"/>\n      <use x=\"1279.597656\" xlink:href=\"#DejaVuSans-69\"/>\n      <use x=\"1307.380859\" xlink:href=\"#DejaVuSans-6f\"/>\n      <use x=\"1368.5625\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"1431.941406\" xlink:href=\"#DejaVuSans-2d\"/>\n      <use x=\"1468.025391\" xlink:href=\"#DejaVuSans-31\"/>\n      <use x=\"1531.648438\" xlink:href=\"#DejaVuSans-30\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p05bfa37ed2\">\n   <rect height=\"217.44\" width=\"334.8\" x=\"33.2875\" y=\"10.999219\"/>\n  </clipPath>\n </defs>\n</svg>\n",
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 432x288 with 1 Axes>",
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<svg height=\"347.31875pt\" version=\"1.1\" viewBox=\"0 0 384.83125 347.31875\" width=\"384.83125pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <metadata>\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2021-04-22T18:05:23.842509</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.4.1, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 347.31875 \nL 384.83125 347.31875 \nL 384.83125 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 33.2875 323.440625 \nL 368.0875 323.440625 \nL 368.0875 106.000625 \nL 33.2875 106.000625 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <path clip-path=\"url(#pe6637c65f3)\" d=\"M 33.2875 323.440625 \nL 33.2875 106.000625 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_2\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"m0fdad92c66\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#m0fdad92c66\" y=\"323.440625\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 50 -->\n      <g transform=\"translate(26.925 338.039062)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 691 4666 \nL 3169 4666 \nL 3169 4134 \nL 1269 4134 \nL 1269 2991 \nQ 1406 3038 1543 3061 \nQ 1681 3084 1819 3084 \nQ 2600 3084 3056 2656 \nQ 3513 2228 3513 1497 \nQ 3513 744 3044 326 \nQ 2575 -91 1722 -91 \nQ 1428 -91 1123 -41 \nQ 819 9 494 109 \nL 494 744 \nQ 775 591 1075 516 \nQ 1375 441 1709 441 \nQ 2250 441 2565 725 \nQ 2881 1009 2881 1497 \nQ 2881 1984 2565 2268 \nQ 2250 2553 1709 2553 \nQ 1456 2553 1204 2497 \nQ 953 2441 691 2322 \nL 691 4666 \nz\n\" id=\"DejaVuSans-35\" transform=\"scale(0.015625)\"/>\n        <path d=\"M 2034 4250 \nQ 1547 4250 1301 3770 \nQ 1056 3291 1056 2328 \nQ 1056 1369 1301 889 \nQ 1547 409 2034 409 \nQ 2525 409 2770 889 \nQ 3016 1369 3016 2328 \nQ 3016 3291 2770 3770 \nQ 2525 4250 2034 4250 \nz\nM 2034 4750 \nQ 2819 4750 3233 4129 \nQ 3647 3509 3647 2328 \nQ 3647 1150 3233 529 \nQ 2819 -91 2034 -91 \nQ 1250 -91 836 529 \nQ 422 1150 422 2328 \nQ 422 3509 836 4129 \nQ 1250 4750 2034 4750 \nz\n\" id=\"DejaVuSans-30\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-35\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_3\">\n      <path clip-path=\"url(#pe6637c65f3)\" d=\"M 70.4875 323.440625 \nL 70.4875 106.000625 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"70.4875\" xlink:href=\"#m0fdad92c66\" y=\"323.440625\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 100 -->\n      <g transform=\"translate(60.94375 338.039062)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 794 531 \nL 1825 531 \nL 1825 4091 \nL 703 3866 \nL 703 4441 \nL 1819 4666 \nL 2450 4666 \nL 2450 531 \nL 3481 531 \nL 3481 0 \nL 794 0 \nL 794 531 \nz\n\" id=\"DejaVuSans-31\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_5\">\n      <path clip-path=\"url(#pe6637c65f3)\" d=\"M 107.6875 323.440625 \nL 107.6875 106.000625 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"107.6875\" xlink:href=\"#m0fdad92c66\" y=\"323.440625\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 150 -->\n      <g transform=\"translate(98.14375 338.039062)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-35\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_7\">\n      <path clip-path=\"url(#pe6637c65f3)\" d=\"M 144.8875 323.440625 \nL 144.8875 106.000625 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"144.8875\" xlink:href=\"#m0fdad92c66\" y=\"323.440625\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 200 -->\n      <g transform=\"translate(135.34375 338.039062)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 1228 531 \nL 3431 531 \nL 3431 0 \nL 469 0 \nL 469 531 \nQ 828 903 1448 1529 \nQ 2069 2156 2228 2338 \nQ 2531 2678 2651 2914 \nQ 2772 3150 2772 3378 \nQ 2772 3750 2511 3984 \nQ 2250 4219 1831 4219 \nQ 1534 4219 1204 4116 \nQ 875 4013 500 3803 \nL 500 4441 \nQ 881 4594 1212 4672 \nQ 1544 4750 1819 4750 \nQ 2544 4750 2975 4387 \nQ 3406 4025 3406 3419 \nQ 3406 3131 3298 2873 \nQ 3191 2616 2906 2266 \nQ 2828 2175 2409 1742 \nQ 1991 1309 1228 531 \nz\n\" id=\"DejaVuSans-32\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_9\">\n      <path clip-path=\"url(#pe6637c65f3)\" d=\"M 182.0875 323.440625 \nL 182.0875 106.000625 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"182.0875\" xlink:href=\"#m0fdad92c66\" y=\"323.440625\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 250 -->\n      <g transform=\"translate(172.54375 338.039062)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-35\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_11\">\n      <path clip-path=\"url(#pe6637c65f3)\" d=\"M 219.2875 323.440625 \nL 219.2875 106.000625 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"219.2875\" xlink:href=\"#m0fdad92c66\" y=\"323.440625\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 300 -->\n      <g transform=\"translate(209.74375 338.039062)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 2597 2516 \nQ 3050 2419 3304 2112 \nQ 3559 1806 3559 1356 \nQ 3559 666 3084 287 \nQ 2609 -91 1734 -91 \nQ 1441 -91 1130 -33 \nQ 819 25 488 141 \nL 488 750 \nQ 750 597 1062 519 \nQ 1375 441 1716 441 \nQ 2309 441 2620 675 \nQ 2931 909 2931 1356 \nQ 2931 1769 2642 2001 \nQ 2353 2234 1838 2234 \nL 1294 2234 \nL 1294 2753 \nL 1863 2753 \nQ 2328 2753 2575 2939 \nQ 2822 3125 2822 3475 \nQ 2822 3834 2567 4026 \nQ 2313 4219 1838 4219 \nQ 1578 4219 1281 4162 \nQ 984 4106 628 3988 \nL 628 4550 \nQ 988 4650 1302 4700 \nQ 1616 4750 1894 4750 \nQ 2613 4750 3031 4423 \nQ 3450 4097 3450 3541 \nQ 3450 3153 3228 2886 \nQ 3006 2619 2597 2516 \nz\n\" id=\"DejaVuSans-33\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-33\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_7\">\n     <g id=\"line2d_13\">\n      <path clip-path=\"url(#pe6637c65f3)\" d=\"M 256.4875 323.440625 \nL 256.4875 106.000625 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_14\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"256.4875\" xlink:href=\"#m0fdad92c66\" y=\"323.440625\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 350 -->\n      <g transform=\"translate(246.94375 338.039062)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-33\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-35\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_8\">\n     <g id=\"line2d_15\">\n      <path clip-path=\"url(#pe6637c65f3)\" d=\"M 293.6875 323.440625 \nL 293.6875 106.000625 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_16\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"293.6875\" xlink:href=\"#m0fdad92c66\" y=\"323.440625\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 400 -->\n      <g transform=\"translate(284.14375 338.039062)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 2419 4116 \nL 825 1625 \nL 2419 1625 \nL 2419 4116 \nz\nM 2253 4666 \nL 3047 4666 \nL 3047 1625 \nL 3713 1625 \nL 3713 1100 \nL 3047 1100 \nL 3047 0 \nL 2419 0 \nL 2419 1100 \nL 313 1100 \nL 313 1709 \nL 2253 4666 \nz\n\" id=\"DejaVuSans-34\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-34\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_9\">\n     <g id=\"line2d_17\">\n      <path clip-path=\"url(#pe6637c65f3)\" d=\"M 330.8875 323.440625 \nL 330.8875 106.000625 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_18\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"330.8875\" xlink:href=\"#m0fdad92c66\" y=\"323.440625\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 450 -->\n      <g transform=\"translate(321.34375 338.039062)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-34\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-35\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_10\">\n     <g id=\"line2d_19\">\n      <path clip-path=\"url(#pe6637c65f3)\" d=\"M 368.0875 323.440625 \nL 368.0875 106.000625 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_20\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"368.0875\" xlink:href=\"#m0fdad92c66\" y=\"323.440625\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 500 -->\n      <g transform=\"translate(358.54375 338.039062)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-35\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_21\">\n      <path clip-path=\"url(#pe6637c65f3)\" d=\"M 33.2875 323.440625 \nL 368.0875 323.440625 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_22\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"m3cccdd065b\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#m3cccdd065b\" y=\"323.440625\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 40 -->\n      <g transform=\"translate(13.5625 327.239844)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-34\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_23\">\n      <path clip-path=\"url(#pe6637c65f3)\" d=\"M 33.2875 287.200625 \nL 368.0875 287.200625 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_24\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#m3cccdd065b\" y=\"287.200625\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 50 -->\n      <g transform=\"translate(13.5625 290.999844)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-35\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_25\">\n      <path clip-path=\"url(#pe6637c65f3)\" d=\"M 33.2875 250.960625 \nL 368.0875 250.960625 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_26\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#m3cccdd065b\" y=\"250.960625\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 60 -->\n      <g transform=\"translate(13.5625 254.759844)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 2113 2584 \nQ 1688 2584 1439 2293 \nQ 1191 2003 1191 1497 \nQ 1191 994 1439 701 \nQ 1688 409 2113 409 \nQ 2538 409 2786 701 \nQ 3034 994 3034 1497 \nQ 3034 2003 2786 2293 \nQ 2538 2584 2113 2584 \nz\nM 3366 4563 \nL 3366 3988 \nQ 3128 4100 2886 4159 \nQ 2644 4219 2406 4219 \nQ 1781 4219 1451 3797 \nQ 1122 3375 1075 2522 \nQ 1259 2794 1537 2939 \nQ 1816 3084 2150 3084 \nQ 2853 3084 3261 2657 \nQ 3669 2231 3669 1497 \nQ 3669 778 3244 343 \nQ 2819 -91 2113 -91 \nQ 1303 -91 875 529 \nQ 447 1150 447 2328 \nQ 447 3434 972 4092 \nQ 1497 4750 2381 4750 \nQ 2619 4750 2861 4703 \nQ 3103 4656 3366 4563 \nz\n\" id=\"DejaVuSans-36\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-36\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_27\">\n      <path clip-path=\"url(#pe6637c65f3)\" d=\"M 33.2875 214.720625 \nL 368.0875 214.720625 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_28\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#m3cccdd065b\" y=\"214.720625\"/>\n      </g>\n     </g>\n     <g id=\"text_14\">\n      <!-- 70 -->\n      <g transform=\"translate(13.5625 218.519844)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 525 4666 \nL 3525 4666 \nL 3525 4397 \nL 1831 0 \nL 1172 0 \nL 2766 4134 \nL 525 4134 \nL 525 4666 \nz\n\" id=\"DejaVuSans-37\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-37\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_29\">\n      <path clip-path=\"url(#pe6637c65f3)\" d=\"M 33.2875 178.480625 \nL 368.0875 178.480625 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_30\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#m3cccdd065b\" y=\"178.480625\"/>\n      </g>\n     </g>\n     <g id=\"text_15\">\n      <!-- 80 -->\n      <g transform=\"translate(13.5625 182.279844)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 2034 2216 \nQ 1584 2216 1326 1975 \nQ 1069 1734 1069 1313 \nQ 1069 891 1326 650 \nQ 1584 409 2034 409 \nQ 2484 409 2743 651 \nQ 3003 894 3003 1313 \nQ 3003 1734 2745 1975 \nQ 2488 2216 2034 2216 \nz\nM 1403 2484 \nQ 997 2584 770 2862 \nQ 544 3141 544 3541 \nQ 544 4100 942 4425 \nQ 1341 4750 2034 4750 \nQ 2731 4750 3128 4425 \nQ 3525 4100 3525 3541 \nQ 3525 3141 3298 2862 \nQ 3072 2584 2669 2484 \nQ 3125 2378 3379 2068 \nQ 3634 1759 3634 1313 \nQ 3634 634 3220 271 \nQ 2806 -91 2034 -91 \nQ 1263 -91 848 271 \nQ 434 634 434 1313 \nQ 434 1759 690 2068 \nQ 947 2378 1403 2484 \nz\nM 1172 3481 \nQ 1172 3119 1398 2916 \nQ 1625 2713 2034 2713 \nQ 2441 2713 2670 2916 \nQ 2900 3119 2900 3481 \nQ 2900 3844 2670 4047 \nQ 2441 4250 2034 4250 \nQ 1625 4250 1398 4047 \nQ 1172 3844 1172 3481 \nz\n\" id=\"DejaVuSans-38\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-38\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_31\">\n      <path clip-path=\"url(#pe6637c65f3)\" d=\"M 33.2875 142.240625 \nL 368.0875 142.240625 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_32\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#m3cccdd065b\" y=\"142.240625\"/>\n      </g>\n     </g>\n     <g id=\"text_16\">\n      <!-- 90 -->\n      <g transform=\"translate(13.5625 146.039844)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 703 97 \nL 703 672 \nQ 941 559 1184 500 \nQ 1428 441 1663 441 \nQ 2288 441 2617 861 \nQ 2947 1281 2994 2138 \nQ 2813 1869 2534 1725 \nQ 2256 1581 1919 1581 \nQ 1219 1581 811 2004 \nQ 403 2428 403 3163 \nQ 403 3881 828 4315 \nQ 1253 4750 1959 4750 \nQ 2769 4750 3195 4129 \nQ 3622 3509 3622 2328 \nQ 3622 1225 3098 567 \nQ 2575 -91 1691 -91 \nQ 1453 -91 1209 -44 \nQ 966 3 703 97 \nz\nM 1959 2075 \nQ 2384 2075 2632 2365 \nQ 2881 2656 2881 3163 \nQ 2881 3666 2632 3958 \nQ 2384 4250 1959 4250 \nQ 1534 4250 1286 3958 \nQ 1038 3666 1038 3163 \nQ 1038 2656 1286 2365 \nQ 1534 2075 1959 2075 \nz\n\" id=\"DejaVuSans-39\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-39\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_7\">\n     <g id=\"line2d_33\">\n      <path clip-path=\"url(#pe6637c65f3)\" d=\"M 33.2875 106.000625 \nL 368.0875 106.000625 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_34\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#m3cccdd065b\" y=\"106.000625\"/>\n      </g>\n     </g>\n     <g id=\"text_17\">\n      <!-- 100 -->\n      <g transform=\"translate(7.2 109.799844)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_35\">\n    <path clip-path=\"url(#pe6637c65f3)\" d=\"M -1 153.112625 \nL 368.0875 153.112625 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_36\">\n    <path clip-path=\"url(#pe6637c65f3)\" d=\"M 182.0875 192.843021 \nL 368.0875 186.99786 \n\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_37\">\n    <path clip-path=\"url(#pe6637c65f3)\" d=\"M 89.0875 192.843021 \nL 182.0875 188.667906 \nL 275.0875 185.327814 \nL 368.0875 184.492791 \n\" style=\"fill:none;stroke:#2ca02c;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_38\">\n    <path clip-path=\"url(#pe6637c65f3)\" d=\"M 33.2875 185.327814 \nL 70.4875 186.162837 \nL 107.6875 189.502929 \nL 144.8875 188.667906 \nL 182.0875 191.172975 \nL 219.2875 189.502929 \nL 256.4875 189.502929 \nL 293.6875 185.327814 \nL 330.8875 187.832883 \nL 368.0875 183.657768 \n\" style=\"fill:none;stroke:#d62728;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_39\">\n    <path clip-path=\"url(#pe6637c65f3)\" d=\"M 14.6875 207.873436 \nL 33.2875 187.832883 \nL 51.8875 199.523206 \nL 70.4875 192.007998 \nL 89.0875 187.832883 \nL 107.6875 185.327814 \nL 126.2875 186.99786 \nL 144.8875 183.657768 \nL 163.4875 182.822745 \nL 182.0875 183.657768 \nL 200.6875 182.822745 \nL 219.2875 187.832883 \nL 237.8875 188.667906 \nL 256.4875 186.162837 \nL 275.0875 185.327814 \nL 293.6875 185.327814 \nL 312.2875 187.832883 \nL 330.8875 181.987722 \nL 349.4875 183.657768 \nL 368.0875 181.152699 \n\" style=\"fill:none;stroke:#9467bd;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_40\">\n    <path clip-path=\"url(#pe6637c65f3)\" d=\"M 4.933645 348.31875 \nL 10.9675 237.934266 \nL 18.4075 205.368367 \nL 25.8475 193.678044 \nL 33.2875 201.193252 \nL 40.7275 193.678044 \nL 48.1675 192.007998 \nL 55.6075 192.843021 \nL 63.0475 190.337952 \nL 70.4875 188.667906 \nL 77.9275 191.172975 \nL 85.3675 197.018137 \nL 92.8075 187.832883 \nL 100.2475 191.172975 \nL 107.6875 189.502929 \nL 115.1275 190.337952 \nL 122.5675 185.327814 \nL 130.0075 186.99786 \nL 137.4475 184.492791 \nL 144.8875 188.667906 \nL 152.3275 184.492791 \nL 159.7675 183.657768 \nL 167.2075 181.152699 \nL 174.6475 182.822745 \nL 182.0875 185.327814 \nL 189.5275 186.162837 \nL 196.9675 186.99786 \nL 204.4075 186.99786 \nL 211.8475 188.667906 \nL 219.2875 189.502929 \nL 226.7275 188.667906 \nL 234.1675 188.667906 \nL 241.6075 189.502929 \nL 249.0475 187.832883 \nL 256.4875 181.987722 \nL 263.9275 183.657768 \nL 271.3675 182.822745 \nL 278.8075 184.492791 \nL 286.2475 186.162837 \nL 293.6875 186.162837 \nL 301.1275 183.657768 \nL 308.5675 182.822745 \nL 316.0075 182.822745 \nL 323.4475 185.327814 \nL 330.8875 182.822745 \nL 338.3275 182.822745 \nL 345.7675 181.987722 \nL 353.2075 183.657768 \nL 360.6475 183.657768 \nL 368.0875 183.657768 \n\" style=\"fill:none;stroke:#8c564b;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_41\">\n    <path clip-path=\"url(#pe6637c65f3)\" d=\"M 182.0875 186.162837 \nL 368.0875 177.812607 \n\" style=\"fill:none;stroke:#e377c2;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_42\">\n    <path clip-path=\"url(#pe6637c65f3)\" d=\"M 89.0875 188.667906 \nL 182.0875 186.99786 \nL 275.0875 183.657768 \nL 368.0875 179.482653 \n\" style=\"fill:none;stroke:#7f7f7f;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_43\">\n    <path clip-path=\"url(#pe6637c65f3)\" d=\"M 33.2875 179.482653 \nL 70.4875 196.183113 \nL 107.6875 182.822745 \nL 144.8875 181.152699 \nL 182.0875 176.14256 \nL 219.2875 180.317676 \nL 256.4875 185.327814 \nL 293.6875 183.657768 \nL 330.8875 186.162837 \nL 368.0875 184.492791 \n\" style=\"fill:none;stroke:#bcbd22;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_44\">\n    <path clip-path=\"url(#pe6637c65f3)\" d=\"M 14.6875 308.911224 \nL 33.2875 186.162837 \nL 51.8875 204.533344 \nL 70.4875 176.977584 \nL 89.0875 182.822745 \nL 107.6875 190.337952 \nL 126.2875 181.152699 \nL 144.8875 177.812607 \nL 163.4875 182.822745 \nL 182.0875 181.987722 \nL 200.6875 179.482653 \nL 219.2875 180.317676 \nL 237.8875 181.152699 \nL 256.4875 185.327814 \nL 275.0875 184.492791 \nL 293.6875 176.977584 \nL 312.2875 176.14256 \nL 330.8875 174.472514 \nL 349.4875 177.812607 \nL 368.0875 179.482653 \n\" style=\"fill:none;stroke:#17becf;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_45\">\n    <path clip-path=\"url(#pe6637c65f3)\" d=\"M 4.69096 348.31875 \nL 10.9675 209.543482 \nL 18.4075 192.843021 \nL 25.8475 184.492791 \nL 33.2875 183.657768 \nL 40.7275 186.99786 \nL 48.1675 190.337952 \nL 55.6075 187.832883 \nL 63.0475 181.987722 \nL 70.4875 185.327814 \nL 77.9275 189.502929 \nL 85.3675 183.657768 \nL 92.8075 186.162837 \nL 100.2475 181.152699 \nL 107.6875 181.152699 \nL 115.1275 179.482653 \nL 122.5675 176.14256 \nL 130.0075 174.472514 \nL 137.4475 182.822745 \nL 144.8875 184.492791 \nL 152.3275 177.812607 \nL 159.7675 180.317676 \nL 167.2075 175.307537 \nL 174.6475 176.977584 \nL 182.0875 176.14256 \nL 189.5275 176.14256 \nL 196.9675 177.812607 \nL 204.4075 179.482653 \nL 211.8475 177.812607 \nL 219.2875 177.812607 \nL 226.7275 177.812607 \nL 234.1675 175.307537 \nL 241.6075 172.802468 \nL 249.0475 176.14256 \nL 256.4875 175.307537 \nL 263.9275 172.802468 \nL 271.3675 171.967445 \nL 278.8075 181.987722 \nL 286.2475 184.492791 \nL 293.6875 181.987722 \nL 301.1275 182.822745 \nL 308.5675 183.657768 \nL 316.0075 184.492791 \nL 323.4475 184.492791 \nL 330.8875 187.832883 \nL 338.3275 184.492791 \nL 345.7675 186.162837 \nL 353.2075 182.822745 \nL 360.6475 184.492791 \nL 368.0875 185.327814 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_46\">\n    <path clip-path=\"url(#pe6637c65f3)\" d=\"M 182.0875 188.667906 \nL 368.0875 186.162837 \n\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_47\">\n    <path clip-path=\"url(#pe6637c65f3)\" d=\"M 89.0875 185.327814 \nL 182.0875 185.327814 \nL 275.0875 179.482653 \nL 368.0875 183.657768 \n\" style=\"fill:none;stroke:#2ca02c;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_48\">\n    <path clip-path=\"url(#pe6637c65f3)\" d=\"M 33.2875 179.482653 \nL 70.4875 182.822745 \nL 107.6875 182.822745 \nL 144.8875 192.007998 \nL 182.0875 192.007998 \nL 219.2875 188.667906 \nL 256.4875 182.822745 \nL 293.6875 187.832883 \nL 330.8875 185.327814 \nL 368.0875 186.99786 \n\" style=\"fill:none;stroke:#d62728;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_49\">\n    <path clip-path=\"url(#pe6637c65f3)\" d=\"M 14.6875 186.99786 \nL 33.2875 192.843021 \nL 51.8875 186.99786 \nL 70.4875 186.99786 \nL 89.0875 188.667906 \nL 107.6875 186.99786 \nL 126.2875 187.832883 \nL 144.8875 190.337952 \nL 163.4875 192.007998 \nL 182.0875 191.172975 \nL 200.6875 197.85316 \nL 219.2875 197.85316 \nL 237.8875 197.018137 \nL 256.4875 194.513067 \nL 275.0875 194.513067 \nL 293.6875 198.688183 \nL 312.2875 197.85316 \nL 330.8875 196.183113 \nL 349.4875 194.513067 \nL 368.0875 193.678044 \n\" style=\"fill:none;stroke:#9467bd;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_50\">\n    <path clip-path=\"url(#pe6637c65f3)\" d=\"M 10.268722 348.31875 \nL 10.9675 345.652238 \nL 11.917838 348.31875 \nM 30.634569 348.31875 \nL 33.2875 337.302007 \nL 40.7275 336.466984 \nL 45.755997 348.31875 \nM 69.628634 348.31875 \nL 70.4875 346.487261 \nL 77.9275 342.312146 \nL 85.3675 318.931501 \nL 92.8075 321.43657 \nL 100.2475 318.931501 \nL 107.6875 318.931501 \nL 115.1275 318.096478 \nL 122.5675 318.931501 \nL 130.0075 314.756385 \nL 137.4475 315.591408 \nL 144.8875 314.756385 \nL 152.3275 319.766524 \nL 159.7675 316.426431 \nL 167.2075 314.756385 \nL 174.6475 317.261454 \nL 182.0875 292.210763 \nL 189.5275 308.076201 \nL 196.9675 313.086339 \nL 204.4075 316.426431 \nL 211.8475 307.241178 \nL 219.2875 306.406155 \nL 226.7275 303.066063 \nL 234.1675 308.076201 \nL 241.6075 308.076201 \nL 249.0475 302.23104 \nL 256.4875 247.954542 \nL 263.9275 257.974819 \nL 271.3675 262.984957 \nL 278.8075 270.500164 \nL 286.2475 252.96468 \nL 293.6875 202.863298 \nL 301.1275 190.337952 \nL 308.5675 192.007998 \nL 316.0075 194.513067 \nL 323.4475 194.513067 \nL 330.8875 191.172975 \nL 338.3275 189.502929 \nL 345.7675 189.502929 \nL 353.2075 190.337952 \nL 360.6475 188.667906 \nL 368.0875 188.667906 \n\" style=\"fill:none;stroke:#8c564b;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_51\">\n    <path clip-path=\"url(#pe6637c65f3)\" d=\"M 182.0875 190.337952 \nL 368.0875 176.14256 \n\" style=\"fill:none;stroke:#e377c2;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_52\">\n    <path clip-path=\"url(#pe6637c65f3)\" d=\"M 89.0875 199.523206 \nL 182.0875 181.987722 \nL 275.0875 175.307537 \nL 368.0875 181.152699 \n\" style=\"fill:none;stroke:#7f7f7f;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_53\">\n    <path clip-path=\"url(#pe6637c65f3)\" d=\"M 33.2875 189.502929 \nL 70.4875 197.85316 \nL 107.6875 185.327814 \nL 144.8875 183.657768 \nL 182.0875 187.832883 \nL 219.2875 188.667906 \nL 256.4875 184.492791 \nL 293.6875 182.822745 \nL 330.8875 177.812607 \nL 368.0875 175.307537 \n\" style=\"fill:none;stroke:#bcbd22;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_54\">\n    <path clip-path=\"url(#pe6637c65f3)\" d=\"M 14.6875 187.832883 \nL 33.2875 183.657768 \nL 51.8875 188.667906 \nL 70.4875 188.667906 \nL 89.0875 187.832883 \nL 107.6875 187.832883 \nL 126.2875 184.492791 \nL 144.8875 180.317676 \nL 163.4875 178.64763 \nL 182.0875 184.492791 \nL 200.6875 181.987722 \nL 219.2875 181.987722 \nL 237.8875 181.987722 \nL 256.4875 181.152699 \nL 275.0875 185.327814 \nL 293.6875 178.64763 \nL 312.2875 180.317676 \nL 330.8875 175.307537 \nL 349.4875 180.317676 \nL 368.0875 181.987722 \n\" style=\"fill:none;stroke:#17becf;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_55\">\n    <path clip-path=\"url(#pe6637c65f3)\" d=\"M 3.5275 200.358229 \nL 10.9675 222.903851 \nL 18.4075 228.749012 \nL 25.8475 190.337952 \nL 33.2875 184.492791 \nL 40.7275 196.183113 \nL 48.1675 202.028275 \nL 55.6075 193.678044 \nL 63.0475 197.85316 \nL 70.4875 192.007998 \nL 77.9275 197.018137 \nL 85.3675 190.337952 \nL 92.8075 184.492791 \nL 100.2475 187.832883 \nL 107.6875 192.007998 \nL 115.1275 190.337952 \nL 122.5675 192.843021 \nL 130.0075 190.337952 \nL 137.4475 192.007998 \nL 144.8875 190.337952 \nL 152.3275 187.832883 \nL 159.7675 186.162837 \nL 167.2075 186.162837 \nL 174.6475 179.482653 \nL 182.0875 181.987722 \nL 189.5275 178.64763 \nL 196.9675 177.812607 \nL 204.4075 182.822745 \nL 211.8475 180.317676 \nL 219.2875 179.482653 \nL 226.7275 177.812607 \nL 234.1675 176.14256 \nL 241.6075 176.977584 \nL 249.0475 178.64763 \nL 256.4875 176.14256 \nL 263.9275 183.657768 \nL 271.3675 181.152699 \nL 278.8075 180.317676 \nL 286.2475 179.482653 \nL 293.6875 175.307537 \nL 301.1275 173.637491 \nL 308.5675 176.14256 \nL 316.0075 179.482653 \nL 323.4475 178.64763 \nL 330.8875 180.317676 \nL 338.3275 178.64763 \nL 345.7675 176.14256 \nL 353.2075 176.977584 \nL 360.6475 175.307537 \nL 368.0875 178.64763 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 33.2875 323.440625 \nL 33.2875 106.000625 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 368.0875 323.440625 \nL 368.0875 106.000625 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 33.2875 323.440625 \nL 368.0875 323.440625 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 33.2875 106.000625 \nL 368.0875 106.000625 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"legend_1\">\n    <g id=\"patch_7\">\n     <path d=\"M 40.2875 318.440625 \nL 274.9 318.440625 \nQ 276.9 318.440625 276.9 316.440625 \nL 276.9 9.2 \nQ 276.9 7.2 274.9 7.2 \nL 40.2875 7.2 \nQ 38.2875 7.2 38.2875 9.2 \nL 38.2875 316.440625 \nQ 38.2875 318.440625 40.2875 318.440625 \nz\n\" style=\"fill:#ffffff;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\n    </g>\n    <g id=\"line2d_56\">\n     <path d=\"M 42.2875 15.298437 \nL 62.2875 15.298437 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_57\"/>\n    <g id=\"text_18\">\n     <!-- algorithm-upper-bound -->\n     <g transform=\"translate(70.2875 18.798437)scale(0.1 -0.1)\">\n      <defs>\n       <path d=\"M 2194 1759 \nQ 1497 1759 1228 1600 \nQ 959 1441 959 1056 \nQ 959 750 1161 570 \nQ 1363 391 1709 391 \nQ 2188 391 2477 730 \nQ 2766 1069 2766 1631 \nL 2766 1759 \nL 2194 1759 \nz\nM 3341 1997 \nL 3341 0 \nL 2766 0 \nL 2766 531 \nQ 2569 213 2275 61 \nQ 1981 -91 1556 -91 \nQ 1019 -91 701 211 \nQ 384 513 384 1019 \nQ 384 1609 779 1909 \nQ 1175 2209 1959 2209 \nL 2766 2209 \nL 2766 2266 \nQ 2766 2663 2505 2880 \nQ 2244 3097 1772 3097 \nQ 1472 3097 1187 3025 \nQ 903 2953 641 2809 \nL 641 3341 \nQ 956 3463 1253 3523 \nQ 1550 3584 1831 3584 \nQ 2591 3584 2966 3190 \nQ 3341 2797 3341 1997 \nz\n\" id=\"DejaVuSans-61\" transform=\"scale(0.015625)\"/>\n       <path d=\"M 603 4863 \nL 1178 4863 \nL 1178 0 \nL 603 0 \nL 603 4863 \nz\n\" id=\"DejaVuSans-6c\" transform=\"scale(0.015625)\"/>\n       <path d=\"M 2906 1791 \nQ 2906 2416 2648 2759 \nQ 2391 3103 1925 3103 \nQ 1463 3103 1205 2759 \nQ 947 2416 947 1791 \nQ 947 1169 1205 825 \nQ 1463 481 1925 481 \nQ 2391 481 2648 825 \nQ 2906 1169 2906 1791 \nz\nM 3481 434 \nQ 3481 -459 3084 -895 \nQ 2688 -1331 1869 -1331 \nQ 1566 -1331 1297 -1286 \nQ 1028 -1241 775 -1147 \nL 775 -588 \nQ 1028 -725 1275 -790 \nQ 1522 -856 1778 -856 \nQ 2344 -856 2625 -561 \nQ 2906 -266 2906 331 \nL 2906 616 \nQ 2728 306 2450 153 \nQ 2172 0 1784 0 \nQ 1141 0 747 490 \nQ 353 981 353 1791 \nQ 353 2603 747 3093 \nQ 1141 3584 1784 3584 \nQ 2172 3584 2450 3431 \nQ 2728 3278 2906 2969 \nL 2906 3500 \nL 3481 3500 \nL 3481 434 \nz\n\" id=\"DejaVuSans-67\" transform=\"scale(0.015625)\"/>\n       <path d=\"M 1959 3097 \nQ 1497 3097 1228 2736 \nQ 959 2375 959 1747 \nQ 959 1119 1226 758 \nQ 1494 397 1959 397 \nQ 2419 397 2687 759 \nQ 2956 1122 2956 1747 \nQ 2956 2369 2687 2733 \nQ 2419 3097 1959 3097 \nz\nM 1959 3584 \nQ 2709 3584 3137 3096 \nQ 3566 2609 3566 1747 \nQ 3566 888 3137 398 \nQ 2709 -91 1959 -91 \nQ 1206 -91 779 398 \nQ 353 888 353 1747 \nQ 353 2609 779 3096 \nQ 1206 3584 1959 3584 \nz\n\" id=\"DejaVuSans-6f\" transform=\"scale(0.015625)\"/>\n       <path d=\"M 2631 2963 \nQ 2534 3019 2420 3045 \nQ 2306 3072 2169 3072 \nQ 1681 3072 1420 2755 \nQ 1159 2438 1159 1844 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1341 3275 1631 3429 \nQ 1922 3584 2338 3584 \nQ 2397 3584 2469 3576 \nQ 2541 3569 2628 3553 \nL 2631 2963 \nz\n\" id=\"DejaVuSans-72\" transform=\"scale(0.015625)\"/>\n       <path d=\"M 603 3500 \nL 1178 3500 \nL 1178 0 \nL 603 0 \nL 603 3500 \nz\nM 603 4863 \nL 1178 4863 \nL 1178 4134 \nL 603 4134 \nL 603 4863 \nz\n\" id=\"DejaVuSans-69\" transform=\"scale(0.015625)\"/>\n       <path d=\"M 1172 4494 \nL 1172 3500 \nL 2356 3500 \nL 2356 3053 \nL 1172 3053 \nL 1172 1153 \nQ 1172 725 1289 603 \nQ 1406 481 1766 481 \nL 2356 481 \nL 2356 0 \nL 1766 0 \nQ 1100 0 847 248 \nQ 594 497 594 1153 \nL 594 3053 \nL 172 3053 \nL 172 3500 \nL 594 3500 \nL 594 4494 \nL 1172 4494 \nz\n\" id=\"DejaVuSans-74\" transform=\"scale(0.015625)\"/>\n       <path d=\"M 3513 2113 \nL 3513 0 \nL 2938 0 \nL 2938 2094 \nQ 2938 2591 2744 2837 \nQ 2550 3084 2163 3084 \nQ 1697 3084 1428 2787 \nQ 1159 2491 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 4863 \nL 1159 4863 \nL 1159 2956 \nQ 1366 3272 1645 3428 \nQ 1925 3584 2291 3584 \nQ 2894 3584 3203 3211 \nQ 3513 2838 3513 2113 \nz\n\" id=\"DejaVuSans-68\" transform=\"scale(0.015625)\"/>\n       <path d=\"M 3328 2828 \nQ 3544 3216 3844 3400 \nQ 4144 3584 4550 3584 \nQ 5097 3584 5394 3201 \nQ 5691 2819 5691 2113 \nL 5691 0 \nL 5113 0 \nL 5113 2094 \nQ 5113 2597 4934 2840 \nQ 4756 3084 4391 3084 \nQ 3944 3084 3684 2787 \nQ 3425 2491 3425 1978 \nL 3425 0 \nL 2847 0 \nL 2847 2094 \nQ 2847 2600 2669 2842 \nQ 2491 3084 2119 3084 \nQ 1678 3084 1418 2786 \nQ 1159 2488 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1356 3278 1631 3431 \nQ 1906 3584 2284 3584 \nQ 2666 3584 2933 3390 \nQ 3200 3197 3328 2828 \nz\n\" id=\"DejaVuSans-6d\" transform=\"scale(0.015625)\"/>\n       <path d=\"M 313 2009 \nL 1997 2009 \nL 1997 1497 \nL 313 1497 \nL 313 2009 \nz\n\" id=\"DejaVuSans-2d\" transform=\"scale(0.015625)\"/>\n       <path d=\"M 544 1381 \nL 544 3500 \nL 1119 3500 \nL 1119 1403 \nQ 1119 906 1312 657 \nQ 1506 409 1894 409 \nQ 2359 409 2629 706 \nQ 2900 1003 2900 1516 \nL 2900 3500 \nL 3475 3500 \nL 3475 0 \nL 2900 0 \nL 2900 538 \nQ 2691 219 2414 64 \nQ 2138 -91 1772 -91 \nQ 1169 -91 856 284 \nQ 544 659 544 1381 \nz\nM 1991 3584 \nL 1991 3584 \nz\n\" id=\"DejaVuSans-75\" transform=\"scale(0.015625)\"/>\n       <path d=\"M 1159 525 \nL 1159 -1331 \nL 581 -1331 \nL 581 3500 \nL 1159 3500 \nL 1159 2969 \nQ 1341 3281 1617 3432 \nQ 1894 3584 2278 3584 \nQ 2916 3584 3314 3078 \nQ 3713 2572 3713 1747 \nQ 3713 922 3314 415 \nQ 2916 -91 2278 -91 \nQ 1894 -91 1617 61 \nQ 1341 213 1159 525 \nz\nM 3116 1747 \nQ 3116 2381 2855 2742 \nQ 2594 3103 2138 3103 \nQ 1681 3103 1420 2742 \nQ 1159 2381 1159 1747 \nQ 1159 1113 1420 752 \nQ 1681 391 2138 391 \nQ 2594 391 2855 752 \nQ 3116 1113 3116 1747 \nz\n\" id=\"DejaVuSans-70\" transform=\"scale(0.015625)\"/>\n       <path d=\"M 3597 1894 \nL 3597 1613 \nL 953 1613 \nQ 991 1019 1311 708 \nQ 1631 397 2203 397 \nQ 2534 397 2845 478 \nQ 3156 559 3463 722 \nL 3463 178 \nQ 3153 47 2828 -22 \nQ 2503 -91 2169 -91 \nQ 1331 -91 842 396 \nQ 353 884 353 1716 \nQ 353 2575 817 3079 \nQ 1281 3584 2069 3584 \nQ 2775 3584 3186 3129 \nQ 3597 2675 3597 1894 \nz\nM 3022 2063 \nQ 3016 2534 2758 2815 \nQ 2500 3097 2075 3097 \nQ 1594 3097 1305 2825 \nQ 1016 2553 972 2059 \nL 3022 2063 \nz\n\" id=\"DejaVuSans-65\" transform=\"scale(0.015625)\"/>\n       <path d=\"M 3116 1747 \nQ 3116 2381 2855 2742 \nQ 2594 3103 2138 3103 \nQ 1681 3103 1420 2742 \nQ 1159 2381 1159 1747 \nQ 1159 1113 1420 752 \nQ 1681 391 2138 391 \nQ 2594 391 2855 752 \nQ 3116 1113 3116 1747 \nz\nM 1159 2969 \nQ 1341 3281 1617 3432 \nQ 1894 3584 2278 3584 \nQ 2916 3584 3314 3078 \nQ 3713 2572 3713 1747 \nQ 3713 922 3314 415 \nQ 2916 -91 2278 -91 \nQ 1894 -91 1617 61 \nQ 1341 213 1159 525 \nL 1159 0 \nL 581 0 \nL 581 4863 \nL 1159 4863 \nL 1159 2969 \nz\n\" id=\"DejaVuSans-62\" transform=\"scale(0.015625)\"/>\n       <path d=\"M 3513 2113 \nL 3513 0 \nL 2938 0 \nL 2938 2094 \nQ 2938 2591 2744 2837 \nQ 2550 3084 2163 3084 \nQ 1697 3084 1428 2787 \nQ 1159 2491 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1366 3272 1645 3428 \nQ 1925 3584 2291 3584 \nQ 2894 3584 3203 3211 \nQ 3513 2838 3513 2113 \nz\n\" id=\"DejaVuSans-6e\" transform=\"scale(0.015625)\"/>\n       <path d=\"M 2906 2969 \nL 2906 4863 \nL 3481 4863 \nL 3481 0 \nL 2906 0 \nL 2906 525 \nQ 2725 213 2448 61 \nQ 2172 -91 1784 -91 \nQ 1150 -91 751 415 \nQ 353 922 353 1747 \nQ 353 2572 751 3078 \nQ 1150 3584 1784 3584 \nQ 2172 3584 2448 3432 \nQ 2725 3281 2906 2969 \nz\nM 947 1747 \nQ 947 1113 1208 752 \nQ 1469 391 1925 391 \nQ 2381 391 2643 752 \nQ 2906 1113 2906 1747 \nQ 2906 2381 2643 2742 \nQ 2381 3103 1925 3103 \nQ 1469 3103 1208 2742 \nQ 947 2381 947 1747 \nz\n\" id=\"DejaVuSans-64\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-61\"/>\n      <use x=\"61.279297\" xlink:href=\"#DejaVuSans-6c\"/>\n      <use x=\"89.0625\" xlink:href=\"#DejaVuSans-67\"/>\n      <use x=\"152.539062\" xlink:href=\"#DejaVuSans-6f\"/>\n      <use x=\"213.720703\" xlink:href=\"#DejaVuSans-72\"/>\n      <use x=\"254.833984\" xlink:href=\"#DejaVuSans-69\"/>\n      <use x=\"282.617188\" xlink:href=\"#DejaVuSans-74\"/>\n      <use x=\"321.826172\" xlink:href=\"#DejaVuSans-68\"/>\n      <use x=\"385.205078\" xlink:href=\"#DejaVuSans-6d\"/>\n      <use x=\"482.617188\" xlink:href=\"#DejaVuSans-2d\"/>\n      <use x=\"518.701172\" xlink:href=\"#DejaVuSans-75\"/>\n      <use x=\"582.080078\" xlink:href=\"#DejaVuSans-70\"/>\n      <use x=\"645.556641\" xlink:href=\"#DejaVuSans-70\"/>\n      <use x=\"709.033203\" xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"770.556641\" xlink:href=\"#DejaVuSans-72\"/>\n      <use x=\"805.294922\" xlink:href=\"#DejaVuSans-2d\"/>\n      <use x=\"841.378906\" xlink:href=\"#DejaVuSans-62\"/>\n      <use x=\"904.855469\" xlink:href=\"#DejaVuSans-6f\"/>\n      <use x=\"966.037109\" xlink:href=\"#DejaVuSans-75\"/>\n      <use x=\"1029.416016\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"1092.794922\" xlink:href=\"#DejaVuSans-64\"/>\n     </g>\n    </g>\n    <g id=\"line2d_58\">\n     <path d=\"M 42.2875 29.976562 \nL 62.2875 29.976562 \n\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_59\"/>\n    <g id=\"text_19\">\n     <!-- KnnModel-RandomSelection-250 -->\n     <g transform=\"translate(70.2875 33.476562)scale(0.1 -0.1)\">\n      <defs>\n       <path d=\"M 628 4666 \nL 1259 4666 \nL 1259 2694 \nL 3353 4666 \nL 4166 4666 \nL 1850 2491 \nL 4331 0 \nL 3500 0 \nL 1259 2247 \nL 1259 0 \nL 628 0 \nL 628 4666 \nz\n\" id=\"DejaVuSans-4b\" transform=\"scale(0.015625)\"/>\n       <path d=\"M 628 4666 \nL 1569 4666 \nL 2759 1491 \nL 3956 4666 \nL 4897 4666 \nL 4897 0 \nL 4281 0 \nL 4281 4097 \nL 3078 897 \nL 2444 897 \nL 1241 4097 \nL 1241 0 \nL 628 0 \nL 628 4666 \nz\n\" id=\"DejaVuSans-4d\" transform=\"scale(0.015625)\"/>\n       <path d=\"M 2841 2188 \nQ 3044 2119 3236 1894 \nQ 3428 1669 3622 1275 \nL 4263 0 \nL 3584 0 \nL 2988 1197 \nQ 2756 1666 2539 1819 \nQ 2322 1972 1947 1972 \nL 1259 1972 \nL 1259 0 \nL 628 0 \nL 628 4666 \nL 2053 4666 \nQ 2853 4666 3247 4331 \nQ 3641 3997 3641 3322 \nQ 3641 2881 3436 2590 \nQ 3231 2300 2841 2188 \nz\nM 1259 4147 \nL 1259 2491 \nL 2053 2491 \nQ 2509 2491 2742 2702 \nQ 2975 2913 2975 3322 \nQ 2975 3731 2742 3939 \nQ 2509 4147 2053 4147 \nL 1259 4147 \nz\n\" id=\"DejaVuSans-52\" transform=\"scale(0.015625)\"/>\n       <path d=\"M 3425 4513 \nL 3425 3897 \nQ 3066 4069 2747 4153 \nQ 2428 4238 2131 4238 \nQ 1616 4238 1336 4038 \nQ 1056 3838 1056 3469 \nQ 1056 3159 1242 3001 \nQ 1428 2844 1947 2747 \nL 2328 2669 \nQ 3034 2534 3370 2195 \nQ 3706 1856 3706 1288 \nQ 3706 609 3251 259 \nQ 2797 -91 1919 -91 \nQ 1588 -91 1214 -16 \nQ 841 59 441 206 \nL 441 856 \nQ 825 641 1194 531 \nQ 1563 422 1919 422 \nQ 2459 422 2753 634 \nQ 3047 847 3047 1241 \nQ 3047 1584 2836 1778 \nQ 2625 1972 2144 2069 \nL 1759 2144 \nQ 1053 2284 737 2584 \nQ 422 2884 422 3419 \nQ 422 4038 858 4394 \nQ 1294 4750 2059 4750 \nQ 2388 4750 2728 4690 \nQ 3069 4631 3425 4513 \nz\n\" id=\"DejaVuSans-53\" transform=\"scale(0.015625)\"/>\n       <path d=\"M 3122 3366 \nL 3122 2828 \nQ 2878 2963 2633 3030 \nQ 2388 3097 2138 3097 \nQ 1578 3097 1268 2742 \nQ 959 2388 959 1747 \nQ 959 1106 1268 751 \nQ 1578 397 2138 397 \nQ 2388 397 2633 464 \nQ 2878 531 3122 666 \nL 3122 134 \nQ 2881 22 2623 -34 \nQ 2366 -91 2075 -91 \nQ 1284 -91 818 406 \nQ 353 903 353 1747 \nQ 353 2603 823 3093 \nQ 1294 3584 2113 3584 \nQ 2378 3584 2631 3529 \nQ 2884 3475 3122 3366 \nz\n\" id=\"DejaVuSans-63\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-4b\"/>\n      <use x=\"65.576172\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"128.955078\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"192.333984\" xlink:href=\"#DejaVuSans-4d\"/>\n      <use x=\"278.613281\" xlink:href=\"#DejaVuSans-6f\"/>\n      <use x=\"339.794922\" xlink:href=\"#DejaVuSans-64\"/>\n      <use x=\"403.271484\" xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"464.794922\" xlink:href=\"#DejaVuSans-6c\"/>\n      <use x=\"492.578125\" xlink:href=\"#DejaVuSans-2d\"/>\n      <use x=\"528.662109\" xlink:href=\"#DejaVuSans-52\"/>\n      <use x=\"595.894531\" xlink:href=\"#DejaVuSans-61\"/>\n      <use x=\"657.173828\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"720.552734\" xlink:href=\"#DejaVuSans-64\"/>\n      <use x=\"784.029297\" xlink:href=\"#DejaVuSans-6f\"/>\n      <use x=\"845.210938\" xlink:href=\"#DejaVuSans-6d\"/>\n      <use x=\"942.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      <use x=\"1006.099609\" xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"1067.623047\" xlink:href=\"#DejaVuSans-6c\"/>\n      <use x=\"1095.40625\" xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"1156.929688\" xlink:href=\"#DejaVuSans-63\"/>\n      <use x=\"1211.910156\" xlink:href=\"#DejaVuSans-74\"/>\n      <use x=\"1251.119141\" xlink:href=\"#DejaVuSans-69\"/>\n      <use x=\"1278.902344\" xlink:href=\"#DejaVuSans-6f\"/>\n      <use x=\"1340.083984\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"1403.462891\" xlink:href=\"#DejaVuSans-2d\"/>\n      <use x=\"1439.546875\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"1503.169922\" xlink:href=\"#DejaVuSans-35\"/>\n      <use x=\"1566.792969\" xlink:href=\"#DejaVuSans-30\"/>\n     </g>\n    </g>\n    <g id=\"line2d_60\">\n     <path d=\"M 42.2875 44.654687 \nL 62.2875 44.654687 \n\" style=\"fill:none;stroke:#2ca02c;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_61\"/>\n    <g id=\"text_20\">\n     <!-- KnnModel-RandomSelection-125 -->\n     <g transform=\"translate(70.2875 48.154687)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-4b\"/>\n      <use x=\"65.576172\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"128.955078\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"192.333984\" xlink:href=\"#DejaVuSans-4d\"/>\n      <use x=\"278.613281\" xlink:href=\"#DejaVuSans-6f\"/>\n      <use x=\"339.794922\" xlink:href=\"#DejaVuSans-64\"/>\n      <use x=\"403.271484\" xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"464.794922\" xlink:href=\"#DejaVuSans-6c\"/>\n      <use x=\"492.578125\" xlink:href=\"#DejaVuSans-2d\"/>\n      <use x=\"528.662109\" xlink:href=\"#DejaVuSans-52\"/>\n      <use x=\"595.894531\" xlink:href=\"#DejaVuSans-61\"/>\n      <use x=\"657.173828\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"720.552734\" xlink:href=\"#DejaVuSans-64\"/>\n      <use x=\"784.029297\" xlink:href=\"#DejaVuSans-6f\"/>\n      <use x=\"845.210938\" xlink:href=\"#DejaVuSans-6d\"/>\n      <use x=\"942.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      <use x=\"1006.099609\" xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"1067.623047\" xlink:href=\"#DejaVuSans-6c\"/>\n      <use x=\"1095.40625\" xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"1156.929688\" xlink:href=\"#DejaVuSans-63\"/>\n      <use x=\"1211.910156\" xlink:href=\"#DejaVuSans-74\"/>\n      <use x=\"1251.119141\" xlink:href=\"#DejaVuSans-69\"/>\n      <use x=\"1278.902344\" xlink:href=\"#DejaVuSans-6f\"/>\n      <use x=\"1340.083984\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"1403.462891\" xlink:href=\"#DejaVuSans-2d\"/>\n      <use x=\"1439.546875\" xlink:href=\"#DejaVuSans-31\"/>\n      <use x=\"1503.169922\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"1566.792969\" xlink:href=\"#DejaVuSans-35\"/>\n     </g>\n    </g>\n    <g id=\"line2d_62\">\n     <path d=\"M 42.2875 59.332812 \nL 62.2875 59.332812 \n\" style=\"fill:none;stroke:#d62728;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_63\"/>\n    <g id=\"text_21\">\n     <!-- KnnModel-RandomSelection-50 -->\n     <g transform=\"translate(70.2875 62.832812)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-4b\"/>\n      <use x=\"65.576172\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"128.955078\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"192.333984\" xlink:href=\"#DejaVuSans-4d\"/>\n      <use x=\"278.613281\" xlink:href=\"#DejaVuSans-6f\"/>\n      <use x=\"339.794922\" xlink:href=\"#DejaVuSans-64\"/>\n      <use x=\"403.271484\" xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"464.794922\" xlink:href=\"#DejaVuSans-6c\"/>\n      <use x=\"492.578125\" xlink:href=\"#DejaVuSans-2d\"/>\n      <use x=\"528.662109\" xlink:href=\"#DejaVuSans-52\"/>\n      <use x=\"595.894531\" xlink:href=\"#DejaVuSans-61\"/>\n      <use x=\"657.173828\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"720.552734\" xlink:href=\"#DejaVuSans-64\"/>\n      <use x=\"784.029297\" xlink:href=\"#DejaVuSans-6f\"/>\n      <use x=\"845.210938\" xlink:href=\"#DejaVuSans-6d\"/>\n      <use x=\"942.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      <use x=\"1006.099609\" xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"1067.623047\" xlink:href=\"#DejaVuSans-6c\"/>\n      <use x=\"1095.40625\" xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"1156.929688\" xlink:href=\"#DejaVuSans-63\"/>\n      <use x=\"1211.910156\" xlink:href=\"#DejaVuSans-74\"/>\n      <use x=\"1251.119141\" xlink:href=\"#DejaVuSans-69\"/>\n      <use x=\"1278.902344\" xlink:href=\"#DejaVuSans-6f\"/>\n      <use x=\"1340.083984\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"1403.462891\" xlink:href=\"#DejaVuSans-2d\"/>\n      <use x=\"1439.546875\" xlink:href=\"#DejaVuSans-35\"/>\n      <use x=\"1503.169922\" xlink:href=\"#DejaVuSans-30\"/>\n     </g>\n    </g>\n    <g id=\"line2d_64\">\n     <path d=\"M 42.2875 74.010937 \nL 62.2875 74.010937 \n\" style=\"fill:none;stroke:#9467bd;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_65\"/>\n    <g id=\"text_22\">\n     <!-- KnnModel-RandomSelection-25 -->\n     <g transform=\"translate(70.2875 77.510937)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-4b\"/>\n      <use x=\"65.576172\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"128.955078\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"192.333984\" xlink:href=\"#DejaVuSans-4d\"/>\n      <use x=\"278.613281\" xlink:href=\"#DejaVuSans-6f\"/>\n      <use x=\"339.794922\" xlink:href=\"#DejaVuSans-64\"/>\n      <use x=\"403.271484\" xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"464.794922\" xlink:href=\"#DejaVuSans-6c\"/>\n      <use x=\"492.578125\" xlink:href=\"#DejaVuSans-2d\"/>\n      <use x=\"528.662109\" xlink:href=\"#DejaVuSans-52\"/>\n      <use x=\"595.894531\" xlink:href=\"#DejaVuSans-61\"/>\n      <use x=\"657.173828\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"720.552734\" xlink:href=\"#DejaVuSans-64\"/>\n      <use x=\"784.029297\" xlink:href=\"#DejaVuSans-6f\"/>\n      <use x=\"845.210938\" xlink:href=\"#DejaVuSans-6d\"/>\n      <use x=\"942.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      <use x=\"1006.099609\" xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"1067.623047\" xlink:href=\"#DejaVuSans-6c\"/>\n      <use x=\"1095.40625\" xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"1156.929688\" xlink:href=\"#DejaVuSans-63\"/>\n      <use x=\"1211.910156\" xlink:href=\"#DejaVuSans-74\"/>\n      <use x=\"1251.119141\" xlink:href=\"#DejaVuSans-69\"/>\n      <use x=\"1278.902344\" xlink:href=\"#DejaVuSans-6f\"/>\n      <use x=\"1340.083984\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"1403.462891\" xlink:href=\"#DejaVuSans-2d\"/>\n      <use x=\"1439.546875\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"1503.169922\" xlink:href=\"#DejaVuSans-35\"/>\n     </g>\n    </g>\n    <g id=\"line2d_66\">\n     <path d=\"M 42.2875 88.689062 \nL 62.2875 88.689062 \n\" style=\"fill:none;stroke:#8c564b;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_67\"/>\n    <g id=\"text_23\">\n     <!-- KnnModel-RandomSelection-10 -->\n     <g transform=\"translate(70.2875 92.189062)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-4b\"/>\n      <use x=\"65.576172\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"128.955078\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"192.333984\" xlink:href=\"#DejaVuSans-4d\"/>\n      <use x=\"278.613281\" xlink:href=\"#DejaVuSans-6f\"/>\n      <use x=\"339.794922\" xlink:href=\"#DejaVuSans-64\"/>\n      <use x=\"403.271484\" xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"464.794922\" xlink:href=\"#DejaVuSans-6c\"/>\n      <use x=\"492.578125\" xlink:href=\"#DejaVuSans-2d\"/>\n      <use x=\"528.662109\" xlink:href=\"#DejaVuSans-52\"/>\n      <use x=\"595.894531\" xlink:href=\"#DejaVuSans-61\"/>\n      <use x=\"657.173828\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"720.552734\" xlink:href=\"#DejaVuSans-64\"/>\n      <use x=\"784.029297\" xlink:href=\"#DejaVuSans-6f\"/>\n      <use x=\"845.210938\" xlink:href=\"#DejaVuSans-6d\"/>\n      <use x=\"942.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      <use x=\"1006.099609\" xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"1067.623047\" xlink:href=\"#DejaVuSans-6c\"/>\n      <use x=\"1095.40625\" xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"1156.929688\" xlink:href=\"#DejaVuSans-63\"/>\n      <use x=\"1211.910156\" xlink:href=\"#DejaVuSans-74\"/>\n      <use x=\"1251.119141\" xlink:href=\"#DejaVuSans-69\"/>\n      <use x=\"1278.902344\" xlink:href=\"#DejaVuSans-6f\"/>\n      <use x=\"1340.083984\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"1403.462891\" xlink:href=\"#DejaVuSans-2d\"/>\n      <use x=\"1439.546875\" xlink:href=\"#DejaVuSans-31\"/>\n      <use x=\"1503.169922\" xlink:href=\"#DejaVuSans-30\"/>\n     </g>\n    </g>\n    <g id=\"line2d_68\">\n     <path d=\"M 42.2875 103.367187 \nL 62.2875 103.367187 \n\" style=\"fill:none;stroke:#e377c2;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_69\"/>\n    <g id=\"text_24\">\n     <!-- KnnModel-MarginSamplingSelection-250 -->\n     <g transform=\"translate(70.2875 106.867187)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-4b\"/>\n      <use x=\"65.576172\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"128.955078\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"192.333984\" xlink:href=\"#DejaVuSans-4d\"/>\n      <use x=\"278.613281\" xlink:href=\"#DejaVuSans-6f\"/>\n      <use x=\"339.794922\" xlink:href=\"#DejaVuSans-64\"/>\n      <use x=\"403.271484\" xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"464.794922\" xlink:href=\"#DejaVuSans-6c\"/>\n      <use x=\"492.578125\" xlink:href=\"#DejaVuSans-2d\"/>\n      <use x=\"528.662109\" xlink:href=\"#DejaVuSans-4d\"/>\n      <use x=\"614.941406\" xlink:href=\"#DejaVuSans-61\"/>\n      <use x=\"676.220703\" xlink:href=\"#DejaVuSans-72\"/>\n      <use x=\"715.583984\" xlink:href=\"#DejaVuSans-67\"/>\n      <use x=\"779.060547\" xlink:href=\"#DejaVuSans-69\"/>\n      <use x=\"806.84375\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"870.222656\" xlink:href=\"#DejaVuSans-53\"/>\n      <use x=\"933.699219\" xlink:href=\"#DejaVuSans-61\"/>\n      <use x=\"994.978516\" xlink:href=\"#DejaVuSans-6d\"/>\n      <use x=\"1092.390625\" xlink:href=\"#DejaVuSans-70\"/>\n      <use x=\"1155.867188\" xlink:href=\"#DejaVuSans-6c\"/>\n      <use x=\"1183.650391\" xlink:href=\"#DejaVuSans-69\"/>\n      <use x=\"1211.433594\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"1274.8125\" xlink:href=\"#DejaVuSans-67\"/>\n      <use x=\"1338.289062\" xlink:href=\"#DejaVuSans-53\"/>\n      <use x=\"1401.765625\" xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"1463.289062\" xlink:href=\"#DejaVuSans-6c\"/>\n      <use x=\"1491.072266\" xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"1552.595703\" xlink:href=\"#DejaVuSans-63\"/>\n      <use x=\"1607.576172\" xlink:href=\"#DejaVuSans-74\"/>\n      <use x=\"1646.785156\" xlink:href=\"#DejaVuSans-69\"/>\n      <use x=\"1674.568359\" xlink:href=\"#DejaVuSans-6f\"/>\n      <use x=\"1735.75\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"1799.128906\" xlink:href=\"#DejaVuSans-2d\"/>\n      <use x=\"1835.212891\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"1898.835938\" xlink:href=\"#DejaVuSans-35\"/>\n      <use x=\"1962.458984\" xlink:href=\"#DejaVuSans-30\"/>\n     </g>\n    </g>\n    <g id=\"line2d_70\">\n     <path d=\"M 42.2875 118.045312 \nL 62.2875 118.045312 \n\" style=\"fill:none;stroke:#7f7f7f;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_71\"/>\n    <g id=\"text_25\">\n     <!-- KnnModel-MarginSamplingSelection-125 -->\n     <g transform=\"translate(70.2875 121.545312)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-4b\"/>\n      <use x=\"65.576172\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"128.955078\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"192.333984\" xlink:href=\"#DejaVuSans-4d\"/>\n      <use x=\"278.613281\" xlink:href=\"#DejaVuSans-6f\"/>\n      <use x=\"339.794922\" xlink:href=\"#DejaVuSans-64\"/>\n      <use x=\"403.271484\" xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"464.794922\" xlink:href=\"#DejaVuSans-6c\"/>\n      <use x=\"492.578125\" xlink:href=\"#DejaVuSans-2d\"/>\n      <use x=\"528.662109\" xlink:href=\"#DejaVuSans-4d\"/>\n      <use x=\"614.941406\" xlink:href=\"#DejaVuSans-61\"/>\n      <use x=\"676.220703\" xlink:href=\"#DejaVuSans-72\"/>\n      <use x=\"715.583984\" xlink:href=\"#DejaVuSans-67\"/>\n      <use x=\"779.060547\" xlink:href=\"#DejaVuSans-69\"/>\n      <use x=\"806.84375\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"870.222656\" xlink:href=\"#DejaVuSans-53\"/>\n      <use x=\"933.699219\" xlink:href=\"#DejaVuSans-61\"/>\n      <use x=\"994.978516\" xlink:href=\"#DejaVuSans-6d\"/>\n      <use x=\"1092.390625\" xlink:href=\"#DejaVuSans-70\"/>\n      <use x=\"1155.867188\" xlink:href=\"#DejaVuSans-6c\"/>\n      <use x=\"1183.650391\" xlink:href=\"#DejaVuSans-69\"/>\n      <use x=\"1211.433594\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"1274.8125\" xlink:href=\"#DejaVuSans-67\"/>\n      <use x=\"1338.289062\" xlink:href=\"#DejaVuSans-53\"/>\n      <use x=\"1401.765625\" xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"1463.289062\" xlink:href=\"#DejaVuSans-6c\"/>\n      <use x=\"1491.072266\" xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"1552.595703\" xlink:href=\"#DejaVuSans-63\"/>\n      <use x=\"1607.576172\" xlink:href=\"#DejaVuSans-74\"/>\n      <use x=\"1646.785156\" xlink:href=\"#DejaVuSans-69\"/>\n      <use x=\"1674.568359\" xlink:href=\"#DejaVuSans-6f\"/>\n      <use x=\"1735.75\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"1799.128906\" xlink:href=\"#DejaVuSans-2d\"/>\n      <use x=\"1835.212891\" xlink:href=\"#DejaVuSans-31\"/>\n      <use x=\"1898.835938\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"1962.458984\" xlink:href=\"#DejaVuSans-35\"/>\n     </g>\n    </g>\n    <g id=\"line2d_72\">\n     <path d=\"M 42.2875 132.723437 \nL 62.2875 132.723437 \n\" style=\"fill:none;stroke:#bcbd22;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_73\"/>\n    <g id=\"text_26\">\n     <!-- KnnModel-MarginSamplingSelection-50 -->\n     <g transform=\"translate(70.2875 136.223437)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-4b\"/>\n      <use x=\"65.576172\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"128.955078\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"192.333984\" xlink:href=\"#DejaVuSans-4d\"/>\n      <use x=\"278.613281\" xlink:href=\"#DejaVuSans-6f\"/>\n      <use x=\"339.794922\" xlink:href=\"#DejaVuSans-64\"/>\n      <use x=\"403.271484\" xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"464.794922\" xlink:href=\"#DejaVuSans-6c\"/>\n      <use x=\"492.578125\" xlink:href=\"#DejaVuSans-2d\"/>\n      <use x=\"528.662109\" xlink:href=\"#DejaVuSans-4d\"/>\n      <use x=\"614.941406\" xlink:href=\"#DejaVuSans-61\"/>\n      <use x=\"676.220703\" xlink:href=\"#DejaVuSans-72\"/>\n      <use x=\"715.583984\" xlink:href=\"#DejaVuSans-67\"/>\n      <use x=\"779.060547\" xlink:href=\"#DejaVuSans-69\"/>\n      <use x=\"806.84375\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"870.222656\" xlink:href=\"#DejaVuSans-53\"/>\n      <use x=\"933.699219\" xlink:href=\"#DejaVuSans-61\"/>\n      <use x=\"994.978516\" xlink:href=\"#DejaVuSans-6d\"/>\n      <use x=\"1092.390625\" xlink:href=\"#DejaVuSans-70\"/>\n      <use x=\"1155.867188\" xlink:href=\"#DejaVuSans-6c\"/>\n      <use x=\"1183.650391\" xlink:href=\"#DejaVuSans-69\"/>\n      <use x=\"1211.433594\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"1274.8125\" xlink:href=\"#DejaVuSans-67\"/>\n      <use x=\"1338.289062\" xlink:href=\"#DejaVuSans-53\"/>\n      <use x=\"1401.765625\" xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"1463.289062\" xlink:href=\"#DejaVuSans-6c\"/>\n      <use x=\"1491.072266\" xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"1552.595703\" xlink:href=\"#DejaVuSans-63\"/>\n      <use x=\"1607.576172\" xlink:href=\"#DejaVuSans-74\"/>\n      <use x=\"1646.785156\" xlink:href=\"#DejaVuSans-69\"/>\n      <use x=\"1674.568359\" xlink:href=\"#DejaVuSans-6f\"/>\n      <use x=\"1735.75\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"1799.128906\" xlink:href=\"#DejaVuSans-2d\"/>\n      <use x=\"1835.212891\" xlink:href=\"#DejaVuSans-35\"/>\n      <use x=\"1898.835938\" xlink:href=\"#DejaVuSans-30\"/>\n     </g>\n    </g>\n    <g id=\"line2d_74\">\n     <path d=\"M 42.2875 147.401562 \nL 62.2875 147.401562 \n\" style=\"fill:none;stroke:#17becf;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_75\"/>\n    <g id=\"text_27\">\n     <!-- KnnModel-MarginSamplingSelection-25 -->\n     <g transform=\"translate(70.2875 150.901562)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-4b\"/>\n      <use x=\"65.576172\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"128.955078\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"192.333984\" xlink:href=\"#DejaVuSans-4d\"/>\n      <use x=\"278.613281\" xlink:href=\"#DejaVuSans-6f\"/>\n      <use x=\"339.794922\" xlink:href=\"#DejaVuSans-64\"/>\n      <use x=\"403.271484\" xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"464.794922\" xlink:href=\"#DejaVuSans-6c\"/>\n      <use x=\"492.578125\" xlink:href=\"#DejaVuSans-2d\"/>\n      <use x=\"528.662109\" xlink:href=\"#DejaVuSans-4d\"/>\n      <use x=\"614.941406\" xlink:href=\"#DejaVuSans-61\"/>\n      <use x=\"676.220703\" xlink:href=\"#DejaVuSans-72\"/>\n      <use x=\"715.583984\" xlink:href=\"#DejaVuSans-67\"/>\n      <use x=\"779.060547\" xlink:href=\"#DejaVuSans-69\"/>\n      <use x=\"806.84375\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"870.222656\" xlink:href=\"#DejaVuSans-53\"/>\n      <use x=\"933.699219\" xlink:href=\"#DejaVuSans-61\"/>\n      <use x=\"994.978516\" xlink:href=\"#DejaVuSans-6d\"/>\n      <use x=\"1092.390625\" xlink:href=\"#DejaVuSans-70\"/>\n      <use x=\"1155.867188\" xlink:href=\"#DejaVuSans-6c\"/>\n      <use x=\"1183.650391\" xlink:href=\"#DejaVuSans-69\"/>\n      <use x=\"1211.433594\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"1274.8125\" xlink:href=\"#DejaVuSans-67\"/>\n      <use x=\"1338.289062\" xlink:href=\"#DejaVuSans-53\"/>\n      <use x=\"1401.765625\" xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"1463.289062\" xlink:href=\"#DejaVuSans-6c\"/>\n      <use x=\"1491.072266\" xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"1552.595703\" xlink:href=\"#DejaVuSans-63\"/>\n      <use x=\"1607.576172\" xlink:href=\"#DejaVuSans-74\"/>\n      <use x=\"1646.785156\" xlink:href=\"#DejaVuSans-69\"/>\n      <use x=\"1674.568359\" xlink:href=\"#DejaVuSans-6f\"/>\n      <use x=\"1735.75\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"1799.128906\" xlink:href=\"#DejaVuSans-2d\"/>\n      <use x=\"1835.212891\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"1898.835938\" xlink:href=\"#DejaVuSans-35\"/>\n     </g>\n    </g>\n    <g id=\"line2d_76\">\n     <path d=\"M 42.2875 162.079687 \nL 62.2875 162.079687 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_77\"/>\n    <g id=\"text_28\">\n     <!-- KnnModel-MarginSamplingSelection-10 -->\n     <g transform=\"translate(70.2875 165.579687)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-4b\"/>\n      <use x=\"65.576172\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"128.955078\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"192.333984\" xlink:href=\"#DejaVuSans-4d\"/>\n      <use x=\"278.613281\" xlink:href=\"#DejaVuSans-6f\"/>\n      <use x=\"339.794922\" xlink:href=\"#DejaVuSans-64\"/>\n      <use x=\"403.271484\" xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"464.794922\" xlink:href=\"#DejaVuSans-6c\"/>\n      <use x=\"492.578125\" xlink:href=\"#DejaVuSans-2d\"/>\n      <use x=\"528.662109\" xlink:href=\"#DejaVuSans-4d\"/>\n      <use x=\"614.941406\" xlink:href=\"#DejaVuSans-61\"/>\n      <use x=\"676.220703\" xlink:href=\"#DejaVuSans-72\"/>\n      <use x=\"715.583984\" xlink:href=\"#DejaVuSans-67\"/>\n      <use x=\"779.060547\" xlink:href=\"#DejaVuSans-69\"/>\n      <use x=\"806.84375\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"870.222656\" xlink:href=\"#DejaVuSans-53\"/>\n      <use x=\"933.699219\" xlink:href=\"#DejaVuSans-61\"/>\n      <use x=\"994.978516\" xlink:href=\"#DejaVuSans-6d\"/>\n      <use x=\"1092.390625\" xlink:href=\"#DejaVuSans-70\"/>\n      <use x=\"1155.867188\" xlink:href=\"#DejaVuSans-6c\"/>\n      <use x=\"1183.650391\" xlink:href=\"#DejaVuSans-69\"/>\n      <use x=\"1211.433594\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"1274.8125\" xlink:href=\"#DejaVuSans-67\"/>\n      <use x=\"1338.289062\" xlink:href=\"#DejaVuSans-53\"/>\n      <use x=\"1401.765625\" xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"1463.289062\" xlink:href=\"#DejaVuSans-6c\"/>\n      <use x=\"1491.072266\" xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"1552.595703\" xlink:href=\"#DejaVuSans-63\"/>\n      <use x=\"1607.576172\" xlink:href=\"#DejaVuSans-74\"/>\n      <use x=\"1646.785156\" xlink:href=\"#DejaVuSans-69\"/>\n      <use x=\"1674.568359\" xlink:href=\"#DejaVuSans-6f\"/>\n      <use x=\"1735.75\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"1799.128906\" xlink:href=\"#DejaVuSans-2d\"/>\n      <use x=\"1835.212891\" xlink:href=\"#DejaVuSans-31\"/>\n      <use x=\"1898.835938\" xlink:href=\"#DejaVuSans-30\"/>\n     </g>\n    </g>\n    <g id=\"line2d_78\">\n     <path d=\"M 42.2875 176.757812 \nL 62.2875 176.757812 \n\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_79\"/>\n    <g id=\"text_29\">\n     <!-- KnnModel-EntropySelection-250 -->\n     <g transform=\"translate(70.2875 180.257812)scale(0.1 -0.1)\">\n      <defs>\n       <path d=\"M 628 4666 \nL 3578 4666 \nL 3578 4134 \nL 1259 4134 \nL 1259 2753 \nL 3481 2753 \nL 3481 2222 \nL 1259 2222 \nL 1259 531 \nL 3634 531 \nL 3634 0 \nL 628 0 \nL 628 4666 \nz\n\" id=\"DejaVuSans-45\" transform=\"scale(0.015625)\"/>\n       <path d=\"M 2059 -325 \nQ 1816 -950 1584 -1140 \nQ 1353 -1331 966 -1331 \nL 506 -1331 \nL 506 -850 \nL 844 -850 \nQ 1081 -850 1212 -737 \nQ 1344 -625 1503 -206 \nL 1606 56 \nL 191 3500 \nL 800 3500 \nL 1894 763 \nL 2988 3500 \nL 3597 3500 \nL 2059 -325 \nz\n\" id=\"DejaVuSans-79\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-4b\"/>\n      <use x=\"65.576172\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"128.955078\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"192.333984\" xlink:href=\"#DejaVuSans-4d\"/>\n      <use x=\"278.613281\" xlink:href=\"#DejaVuSans-6f\"/>\n      <use x=\"339.794922\" xlink:href=\"#DejaVuSans-64\"/>\n      <use x=\"403.271484\" xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"464.794922\" xlink:href=\"#DejaVuSans-6c\"/>\n      <use x=\"492.578125\" xlink:href=\"#DejaVuSans-2d\"/>\n      <use x=\"528.662109\" xlink:href=\"#DejaVuSans-45\"/>\n      <use x=\"591.845703\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"655.224609\" xlink:href=\"#DejaVuSans-74\"/>\n      <use x=\"694.433594\" xlink:href=\"#DejaVuSans-72\"/>\n      <use x=\"733.296875\" xlink:href=\"#DejaVuSans-6f\"/>\n      <use x=\"794.478516\" xlink:href=\"#DejaVuSans-70\"/>\n      <use x=\"857.955078\" xlink:href=\"#DejaVuSans-79\"/>\n      <use x=\"917.134766\" xlink:href=\"#DejaVuSans-53\"/>\n      <use x=\"980.611328\" xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"1042.134766\" xlink:href=\"#DejaVuSans-6c\"/>\n      <use x=\"1069.917969\" xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"1131.441406\" xlink:href=\"#DejaVuSans-63\"/>\n      <use x=\"1186.421875\" xlink:href=\"#DejaVuSans-74\"/>\n      <use x=\"1225.630859\" xlink:href=\"#DejaVuSans-69\"/>\n      <use x=\"1253.414062\" xlink:href=\"#DejaVuSans-6f\"/>\n      <use x=\"1314.595703\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"1377.974609\" xlink:href=\"#DejaVuSans-2d\"/>\n      <use x=\"1414.058594\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"1477.681641\" xlink:href=\"#DejaVuSans-35\"/>\n      <use x=\"1541.304688\" xlink:href=\"#DejaVuSans-30\"/>\n     </g>\n    </g>\n    <g id=\"line2d_80\">\n     <path d=\"M 42.2875 191.435937 \nL 62.2875 191.435937 \n\" style=\"fill:none;stroke:#2ca02c;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_81\"/>\n    <g id=\"text_30\">\n     <!-- KnnModel-EntropySelection-125 -->\n     <g transform=\"translate(70.2875 194.935937)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-4b\"/>\n      <use x=\"65.576172\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"128.955078\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"192.333984\" xlink:href=\"#DejaVuSans-4d\"/>\n      <use x=\"278.613281\" xlink:href=\"#DejaVuSans-6f\"/>\n      <use x=\"339.794922\" xlink:href=\"#DejaVuSans-64\"/>\n      <use x=\"403.271484\" xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"464.794922\" xlink:href=\"#DejaVuSans-6c\"/>\n      <use x=\"492.578125\" xlink:href=\"#DejaVuSans-2d\"/>\n      <use x=\"528.662109\" xlink:href=\"#DejaVuSans-45\"/>\n      <use x=\"591.845703\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"655.224609\" xlink:href=\"#DejaVuSans-74\"/>\n      <use x=\"694.433594\" xlink:href=\"#DejaVuSans-72\"/>\n      <use x=\"733.296875\" xlink:href=\"#DejaVuSans-6f\"/>\n      <use x=\"794.478516\" xlink:href=\"#DejaVuSans-70\"/>\n      <use x=\"857.955078\" xlink:href=\"#DejaVuSans-79\"/>\n      <use x=\"917.134766\" xlink:href=\"#DejaVuSans-53\"/>\n      <use x=\"980.611328\" xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"1042.134766\" xlink:href=\"#DejaVuSans-6c\"/>\n      <use x=\"1069.917969\" xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"1131.441406\" xlink:href=\"#DejaVuSans-63\"/>\n      <use x=\"1186.421875\" xlink:href=\"#DejaVuSans-74\"/>\n      <use x=\"1225.630859\" xlink:href=\"#DejaVuSans-69\"/>\n      <use x=\"1253.414062\" xlink:href=\"#DejaVuSans-6f\"/>\n      <use x=\"1314.595703\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"1377.974609\" xlink:href=\"#DejaVuSans-2d\"/>\n      <use x=\"1414.058594\" xlink:href=\"#DejaVuSans-31\"/>\n      <use x=\"1477.681641\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"1541.304688\" xlink:href=\"#DejaVuSans-35\"/>\n     </g>\n    </g>\n    <g id=\"line2d_82\">\n     <path d=\"M 42.2875 206.114062 \nL 62.2875 206.114062 \n\" style=\"fill:none;stroke:#d62728;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_83\"/>\n    <g id=\"text_31\">\n     <!-- KnnModel-EntropySelection-50 -->\n     <g transform=\"translate(70.2875 209.614062)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-4b\"/>\n      <use x=\"65.576172\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"128.955078\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"192.333984\" xlink:href=\"#DejaVuSans-4d\"/>\n      <use x=\"278.613281\" xlink:href=\"#DejaVuSans-6f\"/>\n      <use x=\"339.794922\" xlink:href=\"#DejaVuSans-64\"/>\n      <use x=\"403.271484\" xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"464.794922\" xlink:href=\"#DejaVuSans-6c\"/>\n      <use x=\"492.578125\" xlink:href=\"#DejaVuSans-2d\"/>\n      <use x=\"528.662109\" xlink:href=\"#DejaVuSans-45\"/>\n      <use x=\"591.845703\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"655.224609\" xlink:href=\"#DejaVuSans-74\"/>\n      <use x=\"694.433594\" xlink:href=\"#DejaVuSans-72\"/>\n      <use x=\"733.296875\" xlink:href=\"#DejaVuSans-6f\"/>\n      <use x=\"794.478516\" xlink:href=\"#DejaVuSans-70\"/>\n      <use x=\"857.955078\" xlink:href=\"#DejaVuSans-79\"/>\n      <use x=\"917.134766\" xlink:href=\"#DejaVuSans-53\"/>\n      <use x=\"980.611328\" xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"1042.134766\" xlink:href=\"#DejaVuSans-6c\"/>\n      <use x=\"1069.917969\" xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"1131.441406\" xlink:href=\"#DejaVuSans-63\"/>\n      <use x=\"1186.421875\" xlink:href=\"#DejaVuSans-74\"/>\n      <use x=\"1225.630859\" xlink:href=\"#DejaVuSans-69\"/>\n      <use x=\"1253.414062\" xlink:href=\"#DejaVuSans-6f\"/>\n      <use x=\"1314.595703\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"1377.974609\" xlink:href=\"#DejaVuSans-2d\"/>\n      <use x=\"1414.058594\" xlink:href=\"#DejaVuSans-35\"/>\n      <use x=\"1477.681641\" xlink:href=\"#DejaVuSans-30\"/>\n     </g>\n    </g>\n    <g id=\"line2d_84\">\n     <path d=\"M 42.2875 220.792187 \nL 62.2875 220.792187 \n\" style=\"fill:none;stroke:#9467bd;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_85\"/>\n    <g id=\"text_32\">\n     <!-- KnnModel-EntropySelection-25 -->\n     <g transform=\"translate(70.2875 224.292187)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-4b\"/>\n      <use x=\"65.576172\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"128.955078\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"192.333984\" xlink:href=\"#DejaVuSans-4d\"/>\n      <use x=\"278.613281\" xlink:href=\"#DejaVuSans-6f\"/>\n      <use x=\"339.794922\" xlink:href=\"#DejaVuSans-64\"/>\n      <use x=\"403.271484\" xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"464.794922\" xlink:href=\"#DejaVuSans-6c\"/>\n      <use x=\"492.578125\" xlink:href=\"#DejaVuSans-2d\"/>\n      <use x=\"528.662109\" xlink:href=\"#DejaVuSans-45\"/>\n      <use x=\"591.845703\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"655.224609\" xlink:href=\"#DejaVuSans-74\"/>\n      <use x=\"694.433594\" xlink:href=\"#DejaVuSans-72\"/>\n      <use x=\"733.296875\" xlink:href=\"#DejaVuSans-6f\"/>\n      <use x=\"794.478516\" xlink:href=\"#DejaVuSans-70\"/>\n      <use x=\"857.955078\" xlink:href=\"#DejaVuSans-79\"/>\n      <use x=\"917.134766\" xlink:href=\"#DejaVuSans-53\"/>\n      <use x=\"980.611328\" xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"1042.134766\" xlink:href=\"#DejaVuSans-6c\"/>\n      <use x=\"1069.917969\" xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"1131.441406\" xlink:href=\"#DejaVuSans-63\"/>\n      <use x=\"1186.421875\" xlink:href=\"#DejaVuSans-74\"/>\n      <use x=\"1225.630859\" xlink:href=\"#DejaVuSans-69\"/>\n      <use x=\"1253.414062\" xlink:href=\"#DejaVuSans-6f\"/>\n      <use x=\"1314.595703\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"1377.974609\" xlink:href=\"#DejaVuSans-2d\"/>\n      <use x=\"1414.058594\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"1477.681641\" xlink:href=\"#DejaVuSans-35\"/>\n     </g>\n    </g>\n    <g id=\"line2d_86\">\n     <path d=\"M 42.2875 235.470312 \nL 62.2875 235.470312 \n\" style=\"fill:none;stroke:#8c564b;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_87\"/>\n    <g id=\"text_33\">\n     <!-- KnnModel-EntropySelection-10 -->\n     <g transform=\"translate(70.2875 238.970312)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-4b\"/>\n      <use x=\"65.576172\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"128.955078\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"192.333984\" xlink:href=\"#DejaVuSans-4d\"/>\n      <use x=\"278.613281\" xlink:href=\"#DejaVuSans-6f\"/>\n      <use x=\"339.794922\" xlink:href=\"#DejaVuSans-64\"/>\n      <use x=\"403.271484\" xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"464.794922\" xlink:href=\"#DejaVuSans-6c\"/>\n      <use x=\"492.578125\" xlink:href=\"#DejaVuSans-2d\"/>\n      <use x=\"528.662109\" xlink:href=\"#DejaVuSans-45\"/>\n      <use x=\"591.845703\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"655.224609\" xlink:href=\"#DejaVuSans-74\"/>\n      <use x=\"694.433594\" xlink:href=\"#DejaVuSans-72\"/>\n      <use x=\"733.296875\" xlink:href=\"#DejaVuSans-6f\"/>\n      <use x=\"794.478516\" xlink:href=\"#DejaVuSans-70\"/>\n      <use x=\"857.955078\" xlink:href=\"#DejaVuSans-79\"/>\n      <use x=\"917.134766\" xlink:href=\"#DejaVuSans-53\"/>\n      <use x=\"980.611328\" xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"1042.134766\" xlink:href=\"#DejaVuSans-6c\"/>\n      <use x=\"1069.917969\" xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"1131.441406\" xlink:href=\"#DejaVuSans-63\"/>\n      <use x=\"1186.421875\" xlink:href=\"#DejaVuSans-74\"/>\n      <use x=\"1225.630859\" xlink:href=\"#DejaVuSans-69\"/>\n      <use x=\"1253.414062\" xlink:href=\"#DejaVuSans-6f\"/>\n      <use x=\"1314.595703\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"1377.974609\" xlink:href=\"#DejaVuSans-2d\"/>\n      <use x=\"1414.058594\" xlink:href=\"#DejaVuSans-31\"/>\n      <use x=\"1477.681641\" xlink:href=\"#DejaVuSans-30\"/>\n     </g>\n    </g>\n    <g id=\"line2d_88\">\n     <path d=\"M 42.2875 250.148437 \nL 62.2875 250.148437 \n\" style=\"fill:none;stroke:#e377c2;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_89\"/>\n    <g id=\"text_34\">\n     <!-- KnnModel-MinStdSelection-250 -->\n     <g transform=\"translate(70.2875 253.648437)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-4b\"/>\n      <use x=\"65.576172\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"128.955078\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"192.333984\" xlink:href=\"#DejaVuSans-4d\"/>\n      <use x=\"278.613281\" xlink:href=\"#DejaVuSans-6f\"/>\n      <use x=\"339.794922\" xlink:href=\"#DejaVuSans-64\"/>\n      <use x=\"403.271484\" xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"464.794922\" xlink:href=\"#DejaVuSans-6c\"/>\n      <use x=\"492.578125\" xlink:href=\"#DejaVuSans-2d\"/>\n      <use x=\"528.662109\" xlink:href=\"#DejaVuSans-4d\"/>\n      <use x=\"614.941406\" xlink:href=\"#DejaVuSans-69\"/>\n      <use x=\"642.724609\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"706.103516\" xlink:href=\"#DejaVuSans-53\"/>\n      <use x=\"769.580078\" xlink:href=\"#DejaVuSans-74\"/>\n      <use x=\"808.789062\" xlink:href=\"#DejaVuSans-64\"/>\n      <use x=\"872.265625\" xlink:href=\"#DejaVuSans-53\"/>\n      <use x=\"935.742188\" xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"997.265625\" xlink:href=\"#DejaVuSans-6c\"/>\n      <use x=\"1025.048828\" xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"1086.572266\" xlink:href=\"#DejaVuSans-63\"/>\n      <use x=\"1141.552734\" xlink:href=\"#DejaVuSans-74\"/>\n      <use x=\"1180.761719\" xlink:href=\"#DejaVuSans-69\"/>\n      <use x=\"1208.544922\" xlink:href=\"#DejaVuSans-6f\"/>\n      <use x=\"1269.726562\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"1333.105469\" xlink:href=\"#DejaVuSans-2d\"/>\n      <use x=\"1369.189453\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"1432.8125\" xlink:href=\"#DejaVuSans-35\"/>\n      <use x=\"1496.435547\" xlink:href=\"#DejaVuSans-30\"/>\n     </g>\n    </g>\n    <g id=\"line2d_90\">\n     <path d=\"M 42.2875 264.826562 \nL 62.2875 264.826562 \n\" style=\"fill:none;stroke:#7f7f7f;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_91\"/>\n    <g id=\"text_35\">\n     <!-- KnnModel-MinStdSelection-125 -->\n     <g transform=\"translate(70.2875 268.326562)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-4b\"/>\n      <use x=\"65.576172\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"128.955078\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"192.333984\" xlink:href=\"#DejaVuSans-4d\"/>\n      <use x=\"278.613281\" xlink:href=\"#DejaVuSans-6f\"/>\n      <use x=\"339.794922\" xlink:href=\"#DejaVuSans-64\"/>\n      <use x=\"403.271484\" xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"464.794922\" xlink:href=\"#DejaVuSans-6c\"/>\n      <use x=\"492.578125\" xlink:href=\"#DejaVuSans-2d\"/>\n      <use x=\"528.662109\" xlink:href=\"#DejaVuSans-4d\"/>\n      <use x=\"614.941406\" xlink:href=\"#DejaVuSans-69\"/>\n      <use x=\"642.724609\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"706.103516\" xlink:href=\"#DejaVuSans-53\"/>\n      <use x=\"769.580078\" xlink:href=\"#DejaVuSans-74\"/>\n      <use x=\"808.789062\" xlink:href=\"#DejaVuSans-64\"/>\n      <use x=\"872.265625\" xlink:href=\"#DejaVuSans-53\"/>\n      <use x=\"935.742188\" xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"997.265625\" xlink:href=\"#DejaVuSans-6c\"/>\n      <use x=\"1025.048828\" xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"1086.572266\" xlink:href=\"#DejaVuSans-63\"/>\n      <use x=\"1141.552734\" xlink:href=\"#DejaVuSans-74\"/>\n      <use x=\"1180.761719\" xlink:href=\"#DejaVuSans-69\"/>\n      <use x=\"1208.544922\" xlink:href=\"#DejaVuSans-6f\"/>\n      <use x=\"1269.726562\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"1333.105469\" xlink:href=\"#DejaVuSans-2d\"/>\n      <use x=\"1369.189453\" xlink:href=\"#DejaVuSans-31\"/>\n      <use x=\"1432.8125\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"1496.435547\" xlink:href=\"#DejaVuSans-35\"/>\n     </g>\n    </g>\n    <g id=\"line2d_92\">\n     <path d=\"M 42.2875 279.504687 \nL 62.2875 279.504687 \n\" style=\"fill:none;stroke:#bcbd22;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_93\"/>\n    <g id=\"text_36\">\n     <!-- KnnModel-MinStdSelection-50 -->\n     <g transform=\"translate(70.2875 283.004687)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-4b\"/>\n      <use x=\"65.576172\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"128.955078\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"192.333984\" xlink:href=\"#DejaVuSans-4d\"/>\n      <use x=\"278.613281\" xlink:href=\"#DejaVuSans-6f\"/>\n      <use x=\"339.794922\" xlink:href=\"#DejaVuSans-64\"/>\n      <use x=\"403.271484\" xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"464.794922\" xlink:href=\"#DejaVuSans-6c\"/>\n      <use x=\"492.578125\" xlink:href=\"#DejaVuSans-2d\"/>\n      <use x=\"528.662109\" xlink:href=\"#DejaVuSans-4d\"/>\n      <use x=\"614.941406\" xlink:href=\"#DejaVuSans-69\"/>\n      <use x=\"642.724609\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"706.103516\" xlink:href=\"#DejaVuSans-53\"/>\n      <use x=\"769.580078\" xlink:href=\"#DejaVuSans-74\"/>\n      <use x=\"808.789062\" xlink:href=\"#DejaVuSans-64\"/>\n      <use x=\"872.265625\" xlink:href=\"#DejaVuSans-53\"/>\n      <use x=\"935.742188\" xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"997.265625\" xlink:href=\"#DejaVuSans-6c\"/>\n      <use x=\"1025.048828\" xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"1086.572266\" xlink:href=\"#DejaVuSans-63\"/>\n      <use x=\"1141.552734\" xlink:href=\"#DejaVuSans-74\"/>\n      <use x=\"1180.761719\" xlink:href=\"#DejaVuSans-69\"/>\n      <use x=\"1208.544922\" xlink:href=\"#DejaVuSans-6f\"/>\n      <use x=\"1269.726562\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"1333.105469\" xlink:href=\"#DejaVuSans-2d\"/>\n      <use x=\"1369.189453\" xlink:href=\"#DejaVuSans-35\"/>\n      <use x=\"1432.8125\" xlink:href=\"#DejaVuSans-30\"/>\n     </g>\n    </g>\n    <g id=\"line2d_94\">\n     <path d=\"M 42.2875 294.182812 \nL 62.2875 294.182812 \n\" style=\"fill:none;stroke:#17becf;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_95\"/>\n    <g id=\"text_37\">\n     <!-- KnnModel-MinStdSelection-25 -->\n     <g transform=\"translate(70.2875 297.682812)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-4b\"/>\n      <use x=\"65.576172\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"128.955078\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"192.333984\" xlink:href=\"#DejaVuSans-4d\"/>\n      <use x=\"278.613281\" xlink:href=\"#DejaVuSans-6f\"/>\n      <use x=\"339.794922\" xlink:href=\"#DejaVuSans-64\"/>\n      <use x=\"403.271484\" xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"464.794922\" xlink:href=\"#DejaVuSans-6c\"/>\n      <use x=\"492.578125\" xlink:href=\"#DejaVuSans-2d\"/>\n      <use x=\"528.662109\" xlink:href=\"#DejaVuSans-4d\"/>\n      <use x=\"614.941406\" xlink:href=\"#DejaVuSans-69\"/>\n      <use x=\"642.724609\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"706.103516\" xlink:href=\"#DejaVuSans-53\"/>\n      <use x=\"769.580078\" xlink:href=\"#DejaVuSans-74\"/>\n      <use x=\"808.789062\" xlink:href=\"#DejaVuSans-64\"/>\n      <use x=\"872.265625\" xlink:href=\"#DejaVuSans-53\"/>\n      <use x=\"935.742188\" xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"997.265625\" xlink:href=\"#DejaVuSans-6c\"/>\n      <use x=\"1025.048828\" xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"1086.572266\" xlink:href=\"#DejaVuSans-63\"/>\n      <use x=\"1141.552734\" xlink:href=\"#DejaVuSans-74\"/>\n      <use x=\"1180.761719\" xlink:href=\"#DejaVuSans-69\"/>\n      <use x=\"1208.544922\" xlink:href=\"#DejaVuSans-6f\"/>\n      <use x=\"1269.726562\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"1333.105469\" xlink:href=\"#DejaVuSans-2d\"/>\n      <use x=\"1369.189453\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"1432.8125\" xlink:href=\"#DejaVuSans-35\"/>\n     </g>\n    </g>\n    <g id=\"line2d_96\">\n     <path d=\"M 42.2875 308.860937 \nL 62.2875 308.860937 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_97\"/>\n    <g id=\"text_38\">\n     <!-- KnnModel-MinStdSelection-10 -->\n     <g transform=\"translate(70.2875 312.360937)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-4b\"/>\n      <use x=\"65.576172\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"128.955078\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"192.333984\" xlink:href=\"#DejaVuSans-4d\"/>\n      <use x=\"278.613281\" xlink:href=\"#DejaVuSans-6f\"/>\n      <use x=\"339.794922\" xlink:href=\"#DejaVuSans-64\"/>\n      <use x=\"403.271484\" xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"464.794922\" xlink:href=\"#DejaVuSans-6c\"/>\n      <use x=\"492.578125\" xlink:href=\"#DejaVuSans-2d\"/>\n      <use x=\"528.662109\" xlink:href=\"#DejaVuSans-4d\"/>\n      <use x=\"614.941406\" xlink:href=\"#DejaVuSans-69\"/>\n      <use x=\"642.724609\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"706.103516\" xlink:href=\"#DejaVuSans-53\"/>\n      <use x=\"769.580078\" xlink:href=\"#DejaVuSans-74\"/>\n      <use x=\"808.789062\" xlink:href=\"#DejaVuSans-64\"/>\n      <use x=\"872.265625\" xlink:href=\"#DejaVuSans-53\"/>\n      <use x=\"935.742188\" xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"997.265625\" xlink:href=\"#DejaVuSans-6c\"/>\n      <use x=\"1025.048828\" xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"1086.572266\" xlink:href=\"#DejaVuSans-63\"/>\n      <use x=\"1141.552734\" xlink:href=\"#DejaVuSans-74\"/>\n      <use x=\"1180.761719\" xlink:href=\"#DejaVuSans-69\"/>\n      <use x=\"1208.544922\" xlink:href=\"#DejaVuSans-6f\"/>\n      <use x=\"1269.726562\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"1333.105469\" xlink:href=\"#DejaVuSans-2d\"/>\n      <use x=\"1369.189453\" xlink:href=\"#DejaVuSans-31\"/>\n      <use x=\"1432.8125\" xlink:href=\"#DejaVuSans-30\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"pe6637c65f3\">\n   <rect height=\"217.44\" width=\"334.8\" x=\"33.2875\" y=\"106.000625\"/>\n  </clipPath>\n </defs>\n</svg>\n",
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "def performance_plot(fully_supervised_accuracy, dic, models, selection_functions, Ks, repeats):  \n",
        "    fig, ax = plt.subplots()\n",
        "    ax.plot([0,500],[fully_supervised_accuracy, fully_supervised_accuracy],label = 'algorithm-upper-bound')\n",
        "    for model_object in models:\n",
        "      for selection_function in selection_functions:\n",
        "        for idx, k in enumerate(Ks):\n",
        "            x = np.arange(float(Ks[idx]), 500 + float(Ks[idx]), float(Ks[idx]))            \n",
        "            Sum = np.array(dic[model_object][selection_function][k][0])\n",
        "            for i in range(1, repeats):\n",
        "                Sum = Sum + np.array(dic[model_object][selection_function][k][i])\n",
        "            mean = Sum / repeats\n",
        "            ax.plot(x, mean ,label = model_object + '-' + selection_function + '-' + str(k))\n",
        "    ax.legend()\n",
        "    ax.set_xlim([50,500])\n",
        "    ax.set_ylim([40,100])\n",
        "    ax.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "# models_str = ['SvmModel', 'RfModel', 'LogModel','GBDCModel','KnnModel']\n",
        "models_str = ['GBDCModel','KnnModel']\n",
        "selection_functions_str = ['RandomSelection', 'MarginSamplingSelection', 'EntropySelection', 'MinStdSelection']\n",
        "# selection_functions_str = ['RandomSelection']\n",
        "Ks_str = ['250','125','50','25','10'] \n",
        "repeats = 1\n",
        "random_forest_upper_bound = 89.\n",
        "svm_upper_bound = 87.\n",
        "log_upper_bound = 87.\n",
        "# gbdc_upper_bound = 86.\n",
        "# knn_upper_bound = 86.\n",
        "total_experiments = len(models_str) * len(selection_functions_str) * len(Ks_str) * repeats\n",
        "\n",
        "print('So which is the better model? under the stopping condition and hyper parameters - random forest is the winner!')\n",
        "# performance_plot(random_forest_upper_bound, d, ['RfModel'] , selection_functions_str    , Ks_str, 1)\n",
        "# performance_plot(svm_upper_bound, d, ['SvmModel'] , selection_functions_str    , Ks_str, 1)\n",
        "# performance_plot(log_upper_bound, d, ['LogModel'] , selection_functions_str    , Ks_str, 1)\n",
        "performance_plot(log_upper_bound, d, ['GDBCModel'] , selection_functions_str    , Ks_str, 1)\n",
        "performance_plot(log_upper_bound, d, ['KnnModel'] , selection_functions_str    , Ks_str, 1)"
      ]
    }
  ]
}